import pandas as pd
from tqdm import tqdm
tqdm.pandas()
from utils import *
import time
import json
import streamlit as st
import requests
from collections import defaultdict, namedtuple
import datetime
import numpy as np
import japanize_matplotlib

OPENAI_API_KEY = st.secrets['OPENAI_API_KEY']
DEEPL_API_KEY = st.secrets['DEEPL_API_KEY']
SemanticScholar_API_KEY = st.secrets['SEMANTICSCHOLAR_API_KEY']

st.set_page_config(
    page_title="Enlighten Authoring",
    initial_sidebar_state="auto")

def display_dataframe(df, title, topk, columns=None):
    st.write(
        f"<h5 style='text-align: left;'> {title} </h5>",
        unsafe_allow_html=True,
    )
    # st.subheader(title)
    if columns != None:
        df = df[columns]
    st.dataframe(df.head(topk))

def display_cluster_dataframe(df, title, topk):
    st.write(
        f"<h5 style='text-align: left;'> {title} </h5>",
        unsafe_allow_html=True,
    )
    # st.subheader(title)
    def get_journal_name(journal_info):
        try:
            if isinstance(journal_info, str):
                # journal_infoã‚’è¾æ›¸ã«å¤‰æ›ã—ã€'name'ã‚­ãƒ¼ã®å€¤ã‚’å–å¾—ã—ã¾ã™
                journal_info = ast.literal_eval(journal_info)
            return journal_info.get('name', '')
        except Exception as e:
            # æ–‡å­—åˆ—ãŒè¾æ›¸ã¨ã—ã¦è©•ä¾¡ã§ããªã„å ´åˆã‚„ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’è¿”ã—ã¾ã™
            return ""

    # 'journal'åˆ—ã®å„ã‚¨ãƒ³ãƒˆãƒªã«get_journal_nameé–¢æ•°ã‚’é©ç”¨ã—ã¦æ–°ã—ã„åˆ—ã‚’ä½œæˆã—ã¾ã™
    df['journal name'] = df['journal'].apply(get_journal_name)
    df['author names'] = df['authors'].apply(lambda x: [d.get('name') for d in x] if isinstance(x, list) else None)
    df['citation count'] = df['citationCount']
    df['published year'] = df['year'].apply(lambda x: str(x).replace('.0', ''))
    df = df[['Title', 'Importance', 'abstract', 'published year', 'citation count', 'journal name', 'author names']]
    df.columns = ['Title', 'Importance', 'Abstract', 'Published Year', 'Citation Count', 'Journal Name', 'Author Names']
    st.dataframe(df.head(topk), hide_index=True)

def display_dataframe_detail(df, title, topk):
    st.write(
        f"<h5 style='text-align: left;'> {title} </h5>",
        unsafe_allow_html=True,
    )
    # st.subheader(title)
    def get_journal_name(journal_info):
        try:
            if isinstance(journal_info, str):
                # journal_infoã‚’è¾æ›¸ã«å¤‰æ›ã—ã€'name'ã‚­ãƒ¼ã®å€¤ã‚’å–å¾—ã—ã¾ã™
                journal_info = ast.literal_eval(journal_info)
            return journal_info.get('name', '')
        except Exception as e:
            # æ–‡å­—åˆ—ãŒè¾æ›¸ã¨ã—ã¦è©•ä¾¡ã§ããªã„å ´åˆã‚„ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’è¿”ã—ã¾ã™
            return ""

    # 'journal'åˆ—ã®å„ã‚¨ãƒ³ãƒˆãƒªã«get_journal_nameé–¢æ•°ã‚’é©ç”¨ã—ã¦æ–°ã—ã„åˆ—ã‚’ä½œæˆã—ã¾ã™
    df['journal name'] = df['journal'].apply(get_journal_name)
    df['author names'] = df['authors'].apply(lambda x: [d.get('name') for d in x] if isinstance(x, list) else None)
    df['citation count'] = df['citationCount']
    df['published year'] = df['year'].apply(lambda x: str(x).replace('.0', ''))
    df = df[['title', 'abstract', 'published year', 'citation count', 'journal name', 'author names']]
    df.columns =  ['Title',  'Abstract', 'Published Year', 'Citation Count', 'Journal Name', 'Author Names']
    st.dataframe(df.head(topk), hide_index=True)

def display_title():
    st.title("Enlighten Authoring")
    st.markdown("<strong>è‡¨åºŠçš„ä½ç½®ã¥ã‘ç«‹æ¡ˆæ”¯æ´AI: å°‚é–€æƒ…å ±ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨æ–‡ç« ã¸ã®ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ä»˜ä¸ã‚’è¡Œã„ã¾ã™</strong>", unsafe_allow_html=True)


def display_list(text_list, size=4):
    if not isinstance(text_list, list):
        st.write("æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return

    for text in text_list:
        st.write(
            f"<h{size} style='text-align: left;'> {text} </h{size}>",
            unsafe_allow_html=True,
        )


def display_description(description_text = 'This is application description.', size=5):
    """Displays the description of the app."""
    # st.markdown("<h4 style='text-align: left;'>Get answers to your questions from 200M+ research papers from Semantic Scholar, summarized by ChatGPT</h4>", unsafe_allow_html=True)
    description_text = description_text.replace('#', '\n')
    st.write(
        f"<h{size} style='text-align: left;'> {description_text} </h{size}>",
        unsafe_allow_html=True,
    )


def display_warning(warning_text = 'This is a warning text.'):
    """Displays a warning message in small text"""
    st.write(
        f"<h8 style='text-align: left;'>âš ï¸ Warning: {warning_text}</h8>ï¸ âš ï¸",
        unsafe_allow_html=True,
    )


def display_error(error_text = 'This is a error text.'):
    st.write(
        f"<h8 style='text-align: left;'>ğŸš¨ ERROR: {error_text}</h8>ï¸ ğŸš¨",
        unsafe_allow_html=True,
    )


def display_spaces(repeat=1):
    for _ in range(repeat):
        st.markdown("<br>", unsafe_allow_html=True)


def display_references_list(references_list, size=7):
    with st.expander('å‚è€ƒæ–‡çŒ®ã‚’è¡¨ç¤º'):
        for reference_text in references_list:
            st.write(
                f"<h{size} style='text-align: left;'> {reference_text} </h{size}>",
                unsafe_allow_html=True,
            )

def display_language_toggle(unique_string):
    toggle = st.radio(
        f"{unique_string}ã§ä½¿ç”¨ã™ã‚‹è¨€èªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        [ 'æ—¥æœ¬èª', 'English']
    )
    return toggle

def display_cluster_years(df: pd.DataFrame):
    display_description("ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®è«–æ–‡å‡ºç‰ˆå¹´", 5)
    min_year, max_year, ave_year = df['year'].min(), df['year'].max(), df['year'].mean()
    min_year, max_year, ave_year = str(min_year).replace('.0', ''), str(max_year).replace('.0', ''), str(np.around(ave_year, 2))
    current_year = datetime.datetime.now().year
    recent_5_years_count = df[df['year'] > (current_year - 5)].shape[0]
    display_description(f"ç›´è¿‘ 5 å¹´ã«{recent_5_years_count}æœ¬ã®è«–æ–‡ãŒå‡ºç‰ˆã•ã‚Œã¦ã„ã¾ã™ã€‚", 6)
    display_description(f"å¹³å‡ {ave_year}å¹´ ({min_year}å¹´ã‹ã‚‰{max_year}å¹´)", 6)
    # Matplotlib ã§ã‚°ãƒ©ãƒ•ä½œæˆ
    # å¹´ã”ã¨ã®è«–æ–‡æ•°ã‚’è¨ˆç®—
    paper_count_by_year = df['year'].value_counts().sort_index()

    # æ¨ªè»¸ã®è¨­å®š
    x_ticks = range(int(paper_count_by_year.index.min()), current_year + 1)

    # Matplotlib ã§æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ä½œæˆ
    plt.figure(figsize=(12, 6))
    plt.plot(paper_count_by_year.index, paper_count_by_year.values, color='aqua', marker='o')
    plt.xlabel('å‡ºç‰ˆå¹´')
    plt.ylabel('è«–æ–‡æ•°[æœ¬]')
    plt.xticks(x_ticks, rotation=45)
    plt.yticks(np.arange(0, paper_count_by_year.values.max() + 1, step=1))

    # ã‚°ãƒ©ãƒ•ã®æ ç·šã‚’ä¸€ç•ªä¸‹ã®ç·šä»¥å¤–æ¶ˆã™
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    plt.gca().spines['left'].set_visible(False)

    # Streamlit ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.pyplot(plt)

def display_year_input():
    # ç¾åœ¨ã®å¹´ã‚’å–å¾—
    current_year = datetime.datetime.now().year

    # åˆ—ã‚’ä½œæˆ
    col1, col2 = st.columns(2)

    # é–‹å§‹å¹´ã¨çµ‚äº†å¹´ã‚’æ¨ªä¸¦ã³ã«è¡¨ç¤º
    with col1:
        start_year = st.selectbox("æ¤œç´¢ã®é–‹å§‹å¹´", range(1880, current_year + 1), 0)

    with col2:
        end_year = st.selectbox("æ¤œç´¢ã®çµ‚äº†å¹´", range(1880, current_year + 1), current_year - 1880)

    st.session_state['year'] = f"{start_year}-{end_year}"


def get_session_info():
    # get session info
    session = requests.get("http://ip-api.com/json").json()
    return session


# Call the function to get the session info
def dump_logs(query, response, success=True):

    # session = get_session_info()
    # Create a dictionary of query details
    query_details = {
        # "session": session,
        "timestamp": time.time(),
        "query": query,
        "response": response,
    }

    if success:
        # Append the query details to a JSON file
        with open("query_details.json", "a") as f:
            json.dump(query_details, f)
            f.write("\n")
    else:
        # Append the query details to a JSON file
        with open("query_details_error.json", "a") as f:
            json.dump(query_details, f)
            f.write("\n")



def reset_session(session_state):
    keys_to_remove = ['papers', 'papers_df', 'H', 'cluster_candidates', 'cluster_df', 'selected_number',
                      'cluster_response', 'summary_response']
    for key in keys_to_remove:
        if key in session_state:
            session_state.pop(key)


def app():
    # refresh_button = st.button('Refresh button')
    # if refresh_button:
    #     st.experimental_rerun()

    debug_mode = st.checkbox("Debug Mode", value=True)
    if debug_mode:
        st.session_state['debug'] = True
    else:
        st.session_state['debug'] = False

    #Queryã®ç®¡ç†
    display_title()

    if 'query' in st.session_state.keys():
        query = st.session_state['query']
    else:
        query = ""

    # Get the query from the user and sumit button
    query = st.text_input(
        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›",
        value = query,
        placeholder="e.g. \"pediatric epilepsy\" \"breast cancer\""
    )

    st.session_state['query'] = query

    #å¹´ã®æŒ‡å®šãƒœã‚¿ãƒ³
    display_year_input()

    #æ¤œç´¢ã®é–‹å§‹ãƒœã‚¿ãƒ³
    get_papers_button = st.button("Semantic Scholar ã§è«–æ–‡ã‚’æ¤œç´¢")

    display_spaces(1)

    #æ›´æ–°ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¦ã„ã‚‹ã¨ãã«å†åº¦æ¤œç´¢ã™ã‚‹ãŸã‚ã®è¨­å®š
    if 'update_papers' in st.session_state and st.session_state['update_papers']:
        get_papers_button = True
        display_description("Semantic Scholarã€€ã§æ¤œç´¢ã—ãŸè«–æ–‡ã‚’æ›´æ–°ã—ã¾ã™")
        st.session_state.pop('update_papers')

    # è«–æ–‡ã®å–å¾—, çµæœã®ä¿å­˜, æ˜”ã®æ¤œç´¢çµæœã®èª­ã¿è¾¼ã¿
    if query and get_papers_button:
        total_limit = 100
        with st.spinner("â³ Semantic Scholarã€€ã‹ã‚‰è«–æ–‡ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."):
            if os.path.exists(os.path.join(data_folder, f"{safe_filename(encode_to_filename(query))}.csv")) and st.session_state['debug']:
                display_description(f"{query} ã¯ Semantic Scholar ã§æ¤œç´¢æ¸ˆã¿ã§ã™ã€‚\n")
                papers_df = load_papers_dataframe(query)
                all_papers_df = load_papers_dataframe(query + '_all', [ 'authors'], ['title', 'abstract', 'year'])
                total = None
                st.session_state['update_papers'] = False
            else:
                display_description(f"{query} ã¯ Semantic Scholar ã§æ¤œç´¢ä¸­ã§ã™ã€‚\n")
                #Semantic Scholar ã«ã‚ˆã‚‹è«–æ–‡ã®ä¿å­˜
                #è‰¯ã„è«–æ–‡ã®100ä»¶ã®å–å¾—
                papers, total = get_papers(query, st.session_state['year'], total_limit=total_limit)
                # config ã¸ã®ä¿å­˜
                st.session_state['papers'] = papers
                if len(st.session_state['papers']) > 0:
                    papers_df = to_dataframe(st.session_state['papers'])
                    #all_papersã¸ã®å…¥åŠ›ã¯dataframe
                    all_papers_df = get_all_papers_from_references(papers_df)

        #æ¤œç´¢çµæœãŒãªã‹ã£ãŸå ´åˆã«ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‰Šé™¤ï¼
        if 'papers' in st.session_state and len(st.session_state['papers']) == 0:
            display_description("Semantic Scholar ã§ã®æ¤œç´¢çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            # reset_session(session_state=st.session_state)
            st.experimental_rerun()

        #csvã®ä¿å­˜
        if not os.path.exists(os.path.join(data_folder, f"{safe_filename(encode_to_filename(query))}.csv")):
            save_papers_dataframe(papers_df, query)
            save_papers_dataframe(all_papers_df, query + '_all' )
            papers_df = load_papers_dataframe(query)
            all_papers_df = load_papers_dataframe(query + '_all', ['authors'], ['title', 'abstract', 'year'])

        st.session_state['all_papers_df'] = all_papers_df
        st.session_state['papers_df'] = papers_df

        display_spaces(2)

        #æ¤œç´¢ã‹ã‚‰ã®çµæœã‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¦ã„ãŸçµæœã§ã‚ã‚‹ã“ã¨ã®è¡¨ç¤º
        if total:
            display_description(f"Semantic Scholar ã‹ã‚‰ã®æ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            display_description(f"{len(st.session_state['papers_df'])} / {total} ã®è«–æ–‡ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        else:
            display_description(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã¦ã„ãŸæ¤œç´¢çµæœã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            display_description(f"æ¤œç´¢å±¥æ­´ã‹ã‚‰ {len(st.session_state['papers_df'])} ä»¶ã®è«–æ–‡ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")


    display_spaces(2)

    #ã™ã§ã« papers ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Œã°ã€ãã‚Œã‚’è¡¨ç¤ºã™ã‚‹ã€‚
    if 'papers_df' in st.session_state:
        display_dataframe_detail(st.session_state['papers_df'],  f'è«–æ–‡æ¤œç´¢çµæœä¸Šä½ 20 ä»¶', 20)

    display_spaces(2)

    # è«–æ–‡ã®æ›´æ–°ï¼ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã¨å†æ¤œç´¢ã®ãŸã‚ã®è¨­å®šã‚’è¡Œã£ã¦ã„ã‚‹ï¼
    if 'update_papers' in st.session_state:
        display_description("Semantic Scholar ã§æ¤œç´¢ã—ãŸè«–æ–‡ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
        update_button = st.button("è«–æ–‡ã®æ›´æ–°")
        if update_button:
            csv_path = os.path.join(data_folder, f"{safe_filename(encode_to_filename(query))}.csv")
            all_csv_path = os.path.join(data_folder, f"{safe_filename(encode_to_filename(query))}_all.csv")
            if os.path.exists(csv_path):
                #ä¿å­˜ã—ã¦ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ï¼
                os.remove(csv_path)
            if os.path.exists(all_csv_path):
                os.remove(all_csv_path)
            st.session_state['update_papers'] = True
            st.experimental_rerun()


    if 'papers_df' in st.session_state:
        display_spaces(2)
        display_description("AI ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ", 3)

        st.session_state['number_of_review_papers'] = st.slider(
            f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ä½¿ç”¨ã™ã‚‹è«–æ–‡æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",   min_value=1, value=20,  max_value=min(100, len(st.session_state['papers_df'])), step=1)

        toggle = display_language_toggle(f'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ')

        topk_review_button = st.button(f"ä¸Šä½ {st.session_state['number_of_review_papers']} ä»¶ã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã€‚(æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)",)
        if topk_review_button:
            with st.spinner("â³ AIã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç”Ÿæˆä¸­ã§ã™ã€‚ ãŠå¾…ã¡ä¸‹ã•ã„..."):
                response, titles, caption = title_review_papers(st.session_state['papers_df'][:st.session_state['number_of_review_papers']], st.session_state['query'], model = 'gpt-4-32k', language=toggle)
                st.session_state['topk_review_caption'] = caption
                st.session_state['topk_review_response'] = response
                st.session_state['topk_review_titles'] = titles

                reference_indices = extract_reference_indices(response)
                references_list = [reference_text for i, reference_text in enumerate(titles) if i in reference_indices]
                st.session_state['topk_references_list'] = references_list

    #ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹ã®å¸¸æ™‚è¡¨ç¤º
    if 'papers_df' in st.session_state and 'topk_review_response' in st.session_state and 'topk_review_caption' in st.session_state and 'topk_references_list' in st.session_state:
        display_description(st.session_state['topk_review_caption'], size=5)
        display_spaces(1)
        display_list(st.session_state['topk_review_response'].replace('#', '').split('\n'), size=8)

        if len(st.session_state['topk_references_list']) > 0:
            display_description('å‚è€ƒæ–‡çŒ®ãƒªã‚¹ãƒˆ', size=6)
            display_references_list(st.session_state['topk_references_list'])


    #ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹è‰ç¨¿ã®å…¥åŠ›éƒ¨åˆ†
    if 'papers_df' in st.session_state and 'topk_review_response' in st.session_state and 'topk_references_list' in st.session_state:
        display_spaces(1)
        display_description(f"æ–‡ç« ã®è‰ç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¸Šä½ {st.session_state['number_of_review_papers']} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚Šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’ä»˜ä¸ã—ã¾ã™ã€‚", 5)
        #ãƒ‰ãƒ©ãƒ•ãƒˆã®å…¥åŠ›éƒ¨åˆ†
        draft_text = st.text_area(label='review draft input filed.', placeholder='Past your draft of review here.', label_visibility='hidden', height=300)

        toggle = display_language_toggle(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ä¸")

        write_summary_button = st.button(f"ä¸Šä½ {st.session_state['number_of_review_papers']} ä»¶ã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ä¸ã€‚(æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)", )

        if write_summary_button and len(draft_text) > 0:
            with st.spinner("â³ AIã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ä»˜ä¸ä¸­ã§ã™ã€‚ ãŠå¾…ã¡ä¸‹ã•ã„..."):
                topk_summary_response, caption = summery_writer_with_draft(st.session_state['topk_review_response'], draft_text, st.session_state['topk_references_list'], model = 'gpt-4-32k', language=toggle)
                display_description(caption)
                display_spaces(2)

                st.session_state['topk_summary_response'] = topk_summary_response

                reference_indices = extract_reference_indices(topk_summary_response)
                references_list = [reference_text for i, reference_text in enumerate(st.session_state['topk_references_list']) if
                                   i in reference_indices]
                st.session_state['topk_summary_references_list'] = references_list
        elif write_summary_button:
            display_description("å…¥åŠ›æ¬„ãŒç©ºç™½ã§ã™ã€‚è‰ç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    #è«–æ–‡ã®è‰ç¨¿ã‚’æ›¸ãç›´ã—ãŸçµæœã®å†è¡¨ç¤º
    if 'topk_summary_response' in st.session_state and 'topk_summary_references_list' in st.session_state:
        display_list(st.session_state['topk_summary_response'].replace('#', '').split('\n'), size=8)

        if len(st.session_state['topk_summary_references_list']) > 0:
            display_description('å‚è€ƒæ–‡çŒ®ãƒªã‚¹ãƒˆ', size=6)
            display_references_list(st.session_state['topk_summary_references_list'])

    #ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼
    display_spaces(3)

    #ã‚µãƒ–ã‚°ãƒ©ãƒ•(H)ã®æ§‹ç¯‰
    if 'papers_df' in st.session_state:
        display_description('æ–‡çŒ®ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°', size=2)
        display_description("æ–‡çŒ®ã®å¼•ç”¨é–¢ä¿‚ã«åŸºã¥ã„ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé–¢å¿ƒã«è¿‘ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™")
        display_spaces(1)

        with st.spinner("â³ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ä¸­ã§ã™..."):
            G = get_paper_graph(st.session_state['papers_df'])
            st.session_state['G'] = G

        with st.spinner("â³ ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ä¸­ã§ã™..."):
            H = extract_subgraph(G)
            st.session_state['H'] = H

        node_attributes = pd.DataFrame.from_dict(dict(H.nodes(data=True)), orient='index')
        node_attributes.index.name = "Node Name (Paper ID)"


        if len(H.nodes) == 0:
            display_error("ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€Semantic Scholar ã®æ¤œç´¢å†…å®¹ã‚’å¤‰æ›´ã—ã¦å†æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.pop('H')
            #ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ã“ã“ã§åœæ­¢ã™ã‚‹
            st.stop()

    if 'papers_df' in st.session_state and len(st.session_state['papers_df']) == 0:
        st.experimental_rerun()

    #cluster_df ã®æ§‹ç¯‰
    if 'H' in st.session_state:
        with st.spinner(f"â³ è«–æ–‡ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¸­ã§ã™..."):
            cluster_counts, cluster_df, partition, clustering_result = community_clustering(st.session_state['H'])
            #ãƒšãƒ¼ã‚¸ãƒ©ãƒ³ã‚¯ã«ã‚ˆã‚‹ã‚½ãƒ¼ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
            df_centrality = page_ranking_sort(st.session_state['H'])
            # ã™ã§ã«ä½œæˆã•ã‚Œã¦ã„ã‚‹ä¸­å¿ƒæ€§ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆdf_centralityï¼‰ã«çµåˆ
            df_centrality['Cluster'] = df_centrality['Node'].map(clustering_result)
            #ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã”ã¨ã® keyword ã‚’ä½œæˆ
            cluster_keywords = calc_tf_idf(df_centrality)
            st.session_state['df_centrality'] = df_centrality

            st.session_state['cluster_keywords'] = cluster_keywords

            cluster_df = df_centrality.groupby('Cluster').agg({
                'Node': 'count',
                'DegreeCentrality': 'mean',
                'PageRank': 'mean'
            })
            cluster_df["ClusterKeywords"] = cluster_df.index.map(lambda x: ', '.join(cluster_keywords[x]))
            st.session_state['cluster_df'] = cluster_df

            #Cluster ID ã‹ã‚‰ Paper ID ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ãƒªã‚¹ãƒˆ
            cluster_id_paper_ids = defaultdict(list)
            for key, value in partition.items():
                cluster_id_paper_ids[value].append(key)
            st.session_state['cluster_id_to_paper_ids'] = cluster_id_paper_ids

    if 'cluster_df' in st.session_state.keys():
        display_clusters = st.session_state['cluster_df'][st.session_state['cluster_df']['Node'] > 10]
        cluster_candidates = display_clusters.index.tolist()
        display_clusters = display_clusters.sort_values('Node', ascending=False)
        for cluster_number in display_clusters.index:
            selected_paper_ids = st.session_state['cluster_id_to_paper_ids'][cluster_number]
            extracted_df = st.session_state['papers_df'][st.session_state['papers_df']['paperId'].isin(selected_paper_ids)]
            display_clusters.loc[cluster_number, 'netNumberOfNodes'] = len(extracted_df)

        rename_columns = {
                'Node': "Number of Papers",
                "ClusterKeywords" : "Keywords"
            }
        display_clusters.rename(columns= rename_columns, inplace=True)

        display_dataframe(display_clusters, f'ã‚¯ãƒ©ã‚¹ã‚¿ã«å«ã¾ã‚Œã‚‹æ–‡çŒ®æ•°ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', len(display_clusters), list(rename_columns.values()))

        st.session_state['cluster_candidates'] = cluster_candidates
        st.session_state['cluster_keywords'] = display_clusters['Keywords'].values


    # # ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¤ã„ã¦,  nodeã‚’ã™ã¹ã¦å–ã‚Šå‡ºã™
    # # å–ã‚Šå‡ºã—ãŸ node ã‚’æŒã¤åˆ—ã«ã¤ã„ã¦ã€
    #
    if 'cluster_candidates' in st.session_state and 'H' in st.session_state and 'G' in st.session_state and 'cluster_id_to_paper_ids' in st.session_state :
        assert len(st.session_state['cluster_candidates']) == len(st.session_state['cluster_keywords']), f"{len(st.session_state['cluster_candidates'])} : {len(st.session_state['cluster_keywords'])}"
        detailed_cluster_dict = {f'{cluster_number} : {cluster_keyword}' : cluster_number for cluster_number, cluster_keyword in zip(st.session_state['cluster_candidates'] , st.session_state['cluster_keywords'])}
        selected_number_key = st.selectbox('è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚', detailed_cluster_dict.keys())
        display_spaces(2)
        selected_number = detailed_cluster_dict[selected_number_key]
        st.session_state['selected_number'] = selected_number

        cluster_df_detail = get_cluster_papers(st.session_state['G'], st.session_state['H'],
                                               st.session_state['cluster_id_to_paper_ids'][selected_number])
        st.session_state['cluster_df_detail'] = cluster_df_detail

        #ã“ã“ã§ï¼Œall_papers ã‹ã‚‰å¼•ã£å¼µã£ã¦ããŸæƒ…å ±ã‚’è¡¨ç¤ºã•ã›ã‚‹ï¼

        matched_papers_df = pd.merge(st.session_state['all_papers_df'], cluster_df_detail, left_on='paperId', right_on='Node', how='inner')
        # DegreeCentrality ã‚’çµåˆã™ã‚‹
        matched_papers_df['DegreeCentrality'] = matched_papers_df['Node'].map(
            cluster_df_detail.set_index('Node')['DegreeCentrality'])

        temp_cluster_df_detail =  matched_papers_df.rename(columns={'DegreeCentrality': "Importance"})
        temp_cluster_df_detail.index.name = 'Paper ID'
        temp_cluster_df_detail = temp_cluster_df_detail.sort_values('Importance', ascending=False)
        display_cluster_dataframe(temp_cluster_df_detail, f'ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå· {selected_number} å†…ã§ã®æ¤œç´¢çµæœä¸Šä½ 20 ä»¶', 20)

        #ã‚¯ãƒ©ã‚¹ã‚¿ã®å¹´æƒ…å ±ã®è¿½åŠ 
        display_cluster_years(temp_cluster_df_detail)

        display_spaces(2)
        display_description(f'ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·{selected_number}ã®å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', size=3)
        with st.spinner(f"â³ ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå· {selected_number} ã®ã‚°ãƒ©ãƒ•ã‚’æç”»ä¸­ã§ã™..."):
            plot_cluster_i(st.session_state['H'], selected_number, st.session_state['df_centrality'])

    #ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã‚ˆã‚‹è‰ç¨¿ã®ç·¨é›†

    if 'selected_number' in st.session_state and 'cluster_df_detail' in st.session_state and 'query' in st.session_state:
        display_spaces(2)
        display_description(f'AI ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ', size=2)

        cluster_df_detail = st.session_state['cluster_df_detail']

        st.session_state['number_of_cluster_review_papers'] = st.slider(
            f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ä½¿ç”¨ã™ã‚‹è«–æ–‡æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
                                                                    min_value=1,
                                                                      value=min(len(cluster_df_detail), 20),
                                                                      max_value=min(100, len(cluster_df_detail)), step=1)

        toggle = display_language_toggle(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ")

        #ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®çµæœã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
        selected_review_button = st.button(f"ã‚¯ãƒ©ã‚¹ã‚¿å†…ä¸Šä½{st.session_state['number_of_cluster_review_papers']}ã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆã€‚(æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)", )

        if selected_review_button:
            with st.spinner(f"â³ AIã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç”Ÿæˆä¸­ã§ã™ã€‚ ãŠå¾…ã¡ä¸‹ã•ã„..."):
                selected_cluster_paper_ids = cluster_df_detail['Node'].values.tolist()[:st.session_state['number_of_cluster_review_papers']]
                result_list, result_dict = get_papers_from_ids(selected_cluster_paper_ids)
                selected_papers = pd.DataFrame(result_dict)
                cluster_response, reference_titles, caption = title_review_papers(selected_papers, st.session_state['query'], model = 'gpt-4-32k', language=toggle)

                display_description(caption)
                display_spaces(1)
                st.session_state['cluster_response'] = cluster_response
                st.session_state['cluster_reference_titles'] = reference_titles

            #response ã«å«ã¾ã‚Œã¦ã„ã‚‹ Referenceã®è¡¨ç¤º
                reference_indices = extract_reference_indices(cluster_response)
                references_list = [reference_text for i, reference_text in enumerate(reference_titles) if i in reference_indices]
                st.session_state['cluster_references_list'] = references_list



    if 'cluster_response' in st.session_state and 'cluster_references_list' in st.session_state and 'cluster_reference_titles' in st.session_state and 'selected_number' in st.session_state:
        display_description(st.session_state['cluster_response'])

        if len(st.session_state['cluster_references_list']) > 0:
            display_description('å‚è€ƒæ–‡çŒ®ãƒªã‚¹ãƒˆ', size=6)
            display_references_list(st.session_state['cluster_references_list'])

        #çµ‚äº†æ™‚ã«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        display_spaces(2)
        display_description(f"æ–‡ç« ã®è‰ç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚¯ãƒ©ã‚¹ã‚¿å†…ä¸Šä½ {st.session_state['number_of_cluster_review_papers']} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚Šã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’ä»˜ä¸ã—ã¾ã™ã€‚", 3)
        #ãƒ‰ãƒ©ãƒ•ãƒˆã®å…¥åŠ›éƒ¨åˆ†
        draft_text = st.text_area(label='review draft input filed.', placeholder='Past your draft of review here!', label_visibility='hidden', height=300)

        toggle = display_language_toggle(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ä¸")

        write_summary_button = st.button(f"ã‚¯ãƒ©ã‚¹ã‚¿å†…ä¸Šä½{st.session_state['number_of_cluster_review_papers']}ã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ä¸ã€‚(æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)", )

        if write_summary_button and len(draft_text) > 0:
            with st.spinner("â³ AIã«ã‚ˆã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ä»˜ä¸ä¸­ã§ã™ã€‚ ãŠå¾…ã¡ä¸‹ã•ã„..."):
                summary_response, caption = summery_writer_with_draft(st.session_state['cluster_response'], draft_text, st.session_state['cluster_references_list'], model = 'gpt-4-32k', language=toggle)
                display_description(caption)
                display_spaces(1)

                st.session_state['summary_response'] = summary_response

                reference_indices = extract_reference_indices(summary_response)
                references_list = [reference_text for i, reference_text in enumerate(st.session_state['cluster_reference_titles']) if
                                   i in reference_indices]
                st.session_state['summary_references_list'] = references_list
        elif write_summary_button:
            display_description("å…¥åŠ›æ¬„ãŒç©ºç™½ã§ã™ã€‚è‰ç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    #æ¤œç´¢çµæœã®å†è¡¨ç¤º
    if 'summary_response' in st.session_state and 'summary_references_list' in st.session_state:
        display_list(st.session_state['summary_response'].replace('#', '').split('\n'), size=8)

        if len(st.session_state['summary_references_list']) > 0:
            display_description('å‚è€ƒæ–‡çŒ®ãƒªã‚¹ãƒˆ', size=6)
            display_references_list(st.session_state['summary_references_list'])


if __name__ == "__main__":
    app()
