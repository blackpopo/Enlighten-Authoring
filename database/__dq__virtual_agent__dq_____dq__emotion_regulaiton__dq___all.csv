,paperId,title,abstract,year,referenceCount,citationCount,isOpenAccess,openAccessPdf,journal,citationStyles,authors
0,00398dcea6a23be322066a48317edf74a9a816fd,Modulation of emotion by cognition and cognition by emotion,,2007.0,48.0,384.0,True,"{'url': 'https://europepmc.org/articles/pmc1862681?pdf=render', 'status': None}","{'volume': '35', 'pages': '430-440', 'name': 'NeuroImage'}","{'bibtex': '@Article{Blair2007ModulationOE,\n author = {Karina Blair and Bruce W. Smith and Derek G.V. Mitchell and John J. L. Morton and M. Vythilingam and Luiz Pessoa and Daniel J. Fridberg and Alan J. Zametkin and E. Nelson and Wayne C. Drevets and Daniel S. Pine and Alex Martin and R. Blair},\n journal = {NeuroImage},\n pages = {430-440},\n title = {Modulation of emotion by cognition and cognition by emotion},\n volume = {35},\n year = {2007}\n}\n'}","[{'authorId': '2248388724', 'name': 'Karina Blair'}, {'authorId': '2249063022', 'name': 'Bruce W. Smith'}, {'authorId': '2245628705', 'name': 'Derek G.V. Mitchell'}, {'authorId': '2237561890', 'name': 'John J. L. Morton'}, {'authorId': '2532122', 'name': 'M. Vythilingam'}, {'authorId': '2248384945', 'name': 'Luiz Pessoa'}, {'authorId': '2248384108', 'name': 'Daniel J. Fridberg'}, {'authorId': '2245353586', 'name': 'Alan J. Zametkin'}, {'authorId': '2149913124', 'name': 'E. Nelson'}, {'authorId': '2248385032', 'name': 'Wayne C. Drevets'}, {'authorId': '2242549569', 'name': 'Daniel S. Pine'}, {'authorId': '2249076797', 'name': 'Alex Martin'}, {'authorId': '2237561509', 'name': 'R. Blair'}]"
1,00513dcc609dc4bc4de8cf84970d6f75ac500440,"A Virtual Midas Touch? Touch, Compliance, and Confederate Bias in Mediated Communication",,2014.0,35.0,52.0,False,,"{'volume': '38', 'pages': '301-311', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Haans2014AVM,\n author = {A. Haans and R. D. Bruijn and W. IJsselsteijn},\n journal = {Journal of Nonverbal Behavior},\n pages = {301-311},\n title = {A Virtual Midas Touch? Touch, Compliance, and Confederate Bias in Mediated Communication},\n volume = {38},\n year = {2014}\n}\n'}","[{'authorId': '2366343', 'name': 'A. Haans'}, {'authorId': '134625213', 'name': 'R. D. Bruijn'}, {'authorId': '30175887', 'name': 'W. IJsselsteijn'}]"
2,0059dab998f4e1bb35c1ff609e90533aae104b24,A Survey of Exact Inference for Contingency Tables,"The past decade has seen substantial research on exact infer- ence for contingency tables, both in terms of developing new analyses and developing efficient algorithms for computations. Coupled with concomitant improvements in computer power, this research has re- sulted in a greater variety of exact procedures becoming feasible for practical use and a considerable increase in the size of data sets to which the procedures can be applied. For some basic analyses of contin- gency tables, it is unnecessary to use large-sample approximations to sampling distributions when their adequacy is in doubt. This article surveys the current theoretical and computational developments of exact methods for contingency tables. Primary attention is given to the exact conditional approach, which eliminates nuisance parameters by conditioning on their sufficient statistics. The presentation of various exact inferences is unified by expressing them in terms of parameters and their sufficient statistics in loglinear models. Exact approaches for many inferences are not yet addressed in the literature, particularly for multidimensional contingency tables, and this article also suggests additional research for the next decade that would make exact methods yet more widely applicable.",1992.0,162.0,1178.0,True,"{'url': 'https://projecteuclid.org/journals/statistical-science/volume-7/issue-1/A-Survey-of-Exact-Inference-for-Contingency-Tables/10.1214/ss/1177011454.pdf', 'status': None}","{'volume': '7', 'pages': '131-153', 'name': 'Statistical Science'}","{'bibtex': '@Article{Agresti1992ASO,\n author = {A. Agresti},\n journal = {Statistical Science},\n pages = {131-153},\n title = {A Survey of Exact Inference for Contingency Tables},\n volume = {7},\n year = {1992}\n}\n'}","[{'authorId': '2817272', 'name': 'A. Agresti'}]"
3,0063c26356c2a10b1f796e438a23e625e84f0f67,The Design and Impact of the Pedagogical Agent: A Systematic Literature Review,"A pedagogical agent is an anthropomorphic virtual character used in an online learning environment to serve instructional purposes. The design of pedagogical agents changes over time depending on the desired objectives for them. This article is a systematic review of the research from 2007 to 2017 related to the design factors of pedagogical agents and their impact on learning environments. The objective of this review is to identify and analyze pedagogical agents through the context in which they are constructed, the independent variables used in pedagogical agent research, and the impact of the pedagogical agent implementation. The review found that research on the design of pedagogical agents has different forms, namely text, voice, 2-D character, 3-D character, and human. The independent variables used in the studies are categorized into the appearance of agents and the role of agents. Moreover, the combination of pedagogical agent designs and role designs of pedagogical agents has significant positive impacts on student learning and student behavior. Recommendations are also provided at the end of this review.",2019.0,88.0,68.0,True,,{'name': 'The Journal of Educators Online'},"{'bibtex': '@Article{Martha2019TheDA,\n author = {Ati Suci Dian Martha and H. Santoso},\n journal = {The Journal of Educators Online},\n title = {The Design and Impact of the Pedagogical Agent: A Systematic Literature Review},\n year = {2019}\n}\n'}","[{'authorId': '30787277', 'name': 'Ati Suci Dian Martha'}, {'authorId': '1856399', 'name': 'H. Santoso'}]"
4,006fdeff6e1a81c404317ee4056d6cc72f9c0e50,Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph,"Analyzing human multimodal language is an emerging area of research in NLP. Intrinsically this language is multimodal (heterogeneous), sequential and asynchronous; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.",2018.0,64.0,586.0,True,"{'url': 'https://www.aclweb.org/anthology/P18-1208.pdf', 'status': None}",{'pages': '2236-2246'},"{'bibtex': '@Inproceedings{Zadeh2018MultimodalLA,\n author = {Amir Zadeh and P. Liang and Soujanya Poria and E. Cambria and Louis-Philippe Morency},\n pages = {2236-2246},\n title = {Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph},\n year = {2018}\n}\n'}","[{'authorId': '144802290', 'name': 'Amir Zadeh'}, {'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
6,008e10883a7e9914bb02f71ed62b41329378f8ae,Emotion and Time Perception: Effects of Film-Induced Mood,"Previous research into emotion and time perception has been designed to study the time perception of emotional events themselves (e.g., facial expression). Our aim was to investigate the effect of emotions per se on the subsequent time judgment of a neutral, non-affective event. In the present study, the participants were presented with films inducing a specific mood and were subsequently given a temporal bisection task. More precisely, the participants were given two temporal bisection tasks, one before and the other after viewing the emotional film. Three emotional films were tested: one eliciting fear, another sadness, and a neutral control film. In addition, the direct mood experience was assessed using the Brief Mood Introspective Scale that was administered to the participants at the beginning and the end of the session. The results showed that the perception of time did not change after viewing either the neutral control films or the sad films although the participants reported being sadder and less aroused after than before watching the sad film clips. In contrast, the stimulus durations were judged longer after than before viewing the frightening films that were judged to increase the emotion of fear and arousal level. In combination with findings from previous studies, our data suggest that the selective lengthening effect after watching frightening films was mediated by an effect of arousal on the speed of the internal clock system.",2011.0,68.0,139.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnint.2011.00033/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Integrative Neuroscience'}","{'bibtex': '@Article{Droit-Volet2011EmotionAT,\n author = {S. Droit-Volet and Sophie L. Fayolle and S. Gil},\n journal = {Frontiers in Integrative Neuroscience},\n title = {Emotion and Time Perception: Effects of Film-Induced Mood},\n volume = {5},\n year = {2011}\n}\n'}","[{'authorId': '1398007844', 'name': 'S. Droit-Volet'}, {'authorId': '4772400', 'name': 'Sophie L. Fayolle'}, {'authorId': '40422171', 'name': 'S. Gil'}]"
7,00c17b14a9618544af90e2089e831ebefbc864b1,MARC: a framework that features emotion models for facial animation during human–computer interaction,,2013.0,49.0,35.0,False,,"{'volume': '7', 'pages': '311-319', 'name': 'Journal on Multimodal User Interfaces'}","{'bibtex': '@Article{Courgeon2013MARCAF,\n author = {M. Courgeon and C. Clavel},\n journal = {Journal on Multimodal User Interfaces},\n pages = {311-319},\n title = {MARC: a framework that features emotion models for facial animation during human–computer interaction},\n volume = {7},\n year = {2013}\n}\n'}","[{'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '1724799', 'name': 'C. Clavel'}]"
8,00d3d6a56a1d989da8235019903e0415fd158771,Toward a General Theory of Acting: Cognitive Science and Performance,,2011.0,0.0,59.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lutterbie2011TowardAG,\n author = {J. Lutterbie},\n title = {Toward a General Theory of Acting: Cognitive Science and Performance},\n year = {2011}\n}\n'}","[{'authorId': '73507079', 'name': 'J. Lutterbie'}]"
9,00ee7355bd289a0e70e5090e0b31b685bb39d695,Visual/Acoustic Emotion Recognition,"To recognize and understand a person's emotion has been known as one of the most important issue in human-computer interaction. In this paper, we present a multimodal system that supports emotion recognition from both visual and acoustic feature analysis. Our main achievement is that with this bimodal method, we can effectively extend the recognized emotion categories compared to when only visual or acoustic feature analysis works alone. We also show that by carefully cooperating bimodal features, the recognition precision of each emotion category will exceed the limit set up by the single modality, both visual and acoustic. Moreover, we believe our system is closer to real human perception and experience and hence will make emotion recognition closer to practical application in the future",2005.0,11.0,32.0,False,,"{'pages': '1468-1471', 'name': '2005 IEEE International Conference on Multimedia and Expo'}","{'bibtex': '@Article{Chen2005VisualAcousticER,\n author = {Cheng-Yao Chen and Yue Huang and P. Cook},\n journal = {2005 IEEE International Conference on Multimedia and Expo},\n pages = {1468-1471},\n title = {Visual/Acoustic Emotion Recognition},\n year = {2005}\n}\n'}","[{'authorId': '3288141', 'name': 'Cheng-Yao Chen'}, {'authorId': '2108715669', 'name': 'Yue Huang'}, {'authorId': '1716507', 'name': 'P. Cook'}]"
10,00fa43776e890fbef5e1074b0b22e14b3b608e1d,Why and How to Build Emotion-Based Agent Architectures,,2015.0,0.0,12.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lisetti2015WhyAH,\n author = {Christine L. Lisetti and E. Hudlicka},\n title = {Why and How to Build Emotion-Based Agent Architectures},\n year = {2015}\n}\n'}","[{'authorId': '143607713', 'name': 'Christine L. Lisetti'}, {'authorId': '2348728', 'name': 'E. Hudlicka'}]"
11,01005b0cee748cefff2074912d23d6df46339463,A second chance.,"The results of a gene therapy trial for a disease called spinal muscular atrophy that gradually paralyzes infants have blown away gene therapy researchers, marking one of the once-troubled field9s most dramatic successes yet. All 15 babies treated, expected to die by age 2, are alive at 20 months or older, and most can sit up, according to a report this week. The news adds to the rising fortunes of gene therapy. But the study also breaks ground because it demonstrates the power of a virus carrying a therapeutic gene that, infused into a vein, can carry its genetic cargo straight to the central nervous system, across the so-called blood-brain barrier. The new treatment9s apparent safety and success is emboldening other researchers to use gene therapy delivered into a vein or the spine to treat rare childhood neurological and muscular diseases, and even common adult disorders such as Parkinson9s.",2017.0,0.0,15.0,False,,"{'volume': '358 6363', 'pages': '\n          582-585\n        ', 'name': 'Science'}","{'bibtex': '@Article{Kaiser2017ASC,\n author = {J. Kaiser},\n journal = {Science},\n pages = {\n          582-585\n        },\n title = {A second chance.},\n volume = {358 6363},\n year = {2017}\n}\n'}","[{'authorId': '144662861', 'name': 'J. Kaiser'}]"
12,01084f285f5112bcf9b85baefebd4e56b5bd7603,Authoring Issues beyond Tools,,2009.0,21.0,60.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:48231/ATTACHMENT01', 'status': None}",{'pages': '50-61'},"{'bibtex': '@Inproceedings{Spierling2009AuthoringIB,\n author = {Ulrike Spierling and N. Szilas},\n pages = {50-61},\n title = {Authoring Issues beyond Tools},\n year = {2009}\n}\n'}","[{'authorId': '1708038', 'name': 'Ulrike Spierling'}, {'authorId': '1691377', 'name': 'N. Szilas'}]"
13,010a070e57067a56271d8b4056fcd55a9fb54e9b,Traversable interfaces between real and virtual worlds,"Traversable interfaces establish the illusion that virtual and physical worlds are joined together and that users can physically cross from one to the other. Our design for a traversable interface combines work on tele-embodiment, mixed reality boundaries and virtual environments. It also exploits non-solid projection surfaces, of which we describe four examples. Our design accommodates the perspectives of users who traverse the interface and also observers who are present in the connected physical and virtual worlds, an important consideration for performance and entertainment applications. A demonstrator supports encounters between members of our laboratory and remote visitors.",2000.0,12.0,69.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/332040.332437', 'status': None}",{'name': 'Proceedings of the SIGCHI conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Koleva2000TraversableIB,\n author = {B. Koleva and Holger Schnädelbach and S. Benford and C. Greenhalgh},\n journal = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},\n title = {Traversable interfaces between real and virtual worlds},\n year = {2000}\n}\n'}","[{'authorId': '1711147', 'name': 'B. Koleva'}, {'authorId': '1683674', 'name': 'Holger Schnädelbach'}, {'authorId': '1738239', 'name': 'S. Benford'}, {'authorId': '145470354', 'name': 'C. Greenhalgh'}]"
14,010a73b65480dd48ac90b831630fb96c061ffff7,"Eliciting positive, negative and mixed emotional states: A film library for affective scientists","We describe the creation of a film library designed for researchers interested in positive (amusing), negative (repulsive), mixed (amusing and repulsive) and neutral emotional states. Three hundred 20- to 33-second film clips videotaped by amateurs were selected from video-hosting websites and screened in laboratory studies by 75 female participants on self-reported amusement and repulsion (Experiments 1 and 2). On the basis of pre-defined cut-off values, 51 positive, 39 negative, 59 mixed and 50 neutral film clips were selected. These film clips were then presented to 411 male and female participants in a large online study to identify film clips that reliably induced the target emotions (Experiment 3). Depending on the goal of the study, researchers may choose positive, negative, mixed or neutral emotional film clips on the basis of Experiments 1 and 2 or Experiment 3 ratings.",2016.0,35.0,100.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:97929/ATTACHMENT01', 'status': None}","{'volume': '30', 'pages': '827 - 856', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Samson2016ElicitingPN,\n author = {Andrea C. Samson and Sylvia D. Kreibig and Blake Soderstrom and A. Ayanna Wade and James J. Gross},\n journal = {Cognition and Emotion},\n pages = {827 - 856},\n title = {Eliciting positive, negative and mixed emotional states: A film library for affective scientists},\n volume = {30},\n year = {2016}\n}\n'}","[{'authorId': '2255000395', 'name': 'Andrea C. Samson'}, {'authorId': '3279362', 'name': 'Sylvia D. Kreibig'}, {'authorId': '47465771', 'name': 'Blake Soderstrom'}, {'authorId': '2255248464', 'name': 'A. Ayanna Wade'}, {'authorId': '2254966886', 'name': 'James J. Gross'}]"
15,012e38687170cbe081ebf52aba42ec4181d37154,German Translation of the Multimodal Presence Scale,,2018.0,0.0,6.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Volkmann2018GermanTO,\n author = {Torben Volkmann and Daniel Wessel and Nicole Jochems and T. Franke},\n title = {German Translation of the Multimodal Presence Scale},\n year = {2018}\n}\n'}","[{'authorId': '2912133', 'name': 'Torben Volkmann'}, {'authorId': '144487430', 'name': 'Daniel Wessel'}, {'authorId': '3175598', 'name': 'Nicole Jochems'}, {'authorId': '144935541', 'name': 'T. Franke'}]"
16,013589f4feac0ce46856c67e4f7cd2125376e68c,"Toward the holodeck: integrating graphics, sound, character and story","We describe an initial prototype of a holodeck- like environment that we have created for the Mission Rehearsal Exercise Project. The goal of the project is to create an experience learning system where the participants are immersed in an environment where they can encounter the sights, sounds, and circumstances of real-world scenarios. Virtual humans act as characters and coaches in an interactive story with pedagogical goals.",2001.0,17.0,280.0,False,,{'pages': '409-416'},"{'bibtex': '@Inproceedings{Hill2001TowardTH,\n author = {R. Hill and J. Gratch and W. Johnson and C. Kyriakakis and C. LaBore and Richard Lindheim and S. Marsella and D. Miraglia and B. Moore and Jackie Morie and J. Rickel and M. Thiébaux and Larry Tuch and R. Whitney and J. Douglas and W. Swartout},\n pages = {409-416},\n title = {Toward the holodeck: integrating graphics, sound, character and story},\n year = {2001}\n}\n'}","[{'authorId': '1812270', 'name': 'R. Hill'}, {'authorId': '69014762', 'name': 'J. Gratch'}, {'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '3074189', 'name': 'C. Kyriakakis'}, {'authorId': '2407818', 'name': 'C. LaBore'}, {'authorId': '2178316', 'name': 'Richard Lindheim'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '35080984', 'name': 'D. Miraglia'}, {'authorId': '118985925', 'name': 'B. Moore'}, {'authorId': '30625490', 'name': 'Jackie Morie'}, {'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '2096971', 'name': 'M. Thiébaux'}, {'authorId': '1879270', 'name': 'Larry Tuch'}, {'authorId': '143660353', 'name': 'R. Whitney'}, {'authorId': '47722403', 'name': 'J. Douglas'}, {'authorId': '1684040', 'name': 'W. Swartout'}]"
17,01396f643a02a6a04749da068adc266d9c23de99,Characteristics of personal space during obstacle circumvention in physical and virtual environments.,,2008.0,20.0,134.0,False,,"{'volume': '27 2', 'pages': '\n          239-47\n        ', 'name': 'Gait & posture'}","{'bibtex': '@Article{Gérin-Lajoie2008CharacteristicsOP,\n author = {Martin Gérin-Lajoie and C. Richards and J. Fung and B. McFadyen},\n journal = {Gait & posture},\n pages = {\n          239-47\n        },\n title = {Characteristics of personal space during obstacle circumvention in physical and virtual environments.},\n volume = {27 2},\n year = {2008}\n}\n'}","[{'authorId': '1422621837', 'name': 'Martin Gérin-Lajoie'}, {'authorId': '1852074', 'name': 'C. Richards'}, {'authorId': '40228054', 'name': 'J. Fung'}, {'authorId': '1862105', 'name': 'B. McFadyen'}]"
18,014391a96dac9a6b637ff2a0570bd30fae4a8d49,SimConnector: An approach to testing disaster-alerting systems using agent based simulation models,"The design, development and testing of intelligent disaster detection and alerting systems pose a set of non-trivial problems. Not only are such systems difficult to design as they need to accurately predict real-world outcomes using a distributed sensing of various parameters, they also need to generate an optimal number of timely alerts when the actual disaster strikes. In this paper, we propose the SimConnector Emulator, a novel approach for the testing of real-world systems using agent-based simulations as a means of validation. The basic idea is to use agent-based simulations to generate event data to allow the testing of responses of the software system to real-time events. As proof of concept, we have developed a Forest Fire Disaster Detection and Alerting System, which uses Intelligent Decision Support based on an internationally recognized Fire rating index, namely the Fire Weather Index (FWI). Results of extensive testing demonstrate the effectiveness of the SimCon-nector approach for the development and testing of real-time applications, in general and disaster detection/alerting systems, in particular.",2011.0,31.0,4.0,False,,"{'pages': '659-665', 'name': '2011 Federated Conference on Computer Science and Information Systems (FedCSIS)'}","{'bibtex': '@Article{Niazi2011SimConnectorAA,\n author = {M. Niazi and Qasim Siddique and A. Hussain and G. Fortino},\n journal = {2011 Federated Conference on Computer Science and Information Systems (FedCSIS)},\n pages = {659-665},\n title = {SimConnector: An approach to testing disaster-alerting systems using agent based simulation models},\n year = {2011}\n}\n'}","[{'authorId': '1795560', 'name': 'M. Niazi'}, {'authorId': '2073401', 'name': 'Qasim Siddique'}, {'authorId': '144664815', 'name': 'A. Hussain'}, {'authorId': '1691577', 'name': 'G. Fortino'}]"
19,0160f70c259a4febcc88b8326f994e2f6144bcc4,"Advanced statistics: bootstrapping confidence intervals for statistics with ""difficult"" distributions.","The use of confidence intervals in reporting results of research has increased dramatically and is now required or highly recommended by editors of many scientific journals. Many resources describe methods for computing confidence intervals for statistics with mathematically simple distributions. Computing confidence intervals for descriptive statistics with distributions that are difficult to represent mathematically is more challenging. The bootstrap is a computationally intensive statistical technique that allows the researcher to make inferences from data without making strong distributional assumptions about the data or the statistic being calculated. This allows the researcher to estimate confidence intervals for statistics that do not have simple sampling distributions (e.g., the median). The purposes of this article are to describe the concept of bootstrapping, to demonstrate how to estimate confidence intervals for the median and the Spearman rank correlation coefficient for non-normally-distributed data from a recent clinical study using two commonly used statistical software packages (SAS and Stata), and to discuss specific limitations of the bootstrap.",2005.0,12.0,345.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1197/j.aem.2004.11.018', 'status': None}","{'volume': '12 4', 'pages': '\n          360-5\n        ', 'name': 'Academic emergency medicine : official journal of the Society for Academic Emergency Medicine'}","{'bibtex': '@Article{Haukoos2005AdvancedSB,\n author = {J. Haukoos and R. Lewis},\n journal = {Academic emergency medicine : official journal of the Society for Academic Emergency Medicine},\n pages = {\n          360-5\n        },\n title = {Advanced statistics: bootstrapping confidence intervals for statistics with ""difficult"" distributions.},\n volume = {12 4},\n year = {2005}\n}\n'}","[{'authorId': '3595598', 'name': 'J. Haukoos'}, {'authorId': '46328172', 'name': 'R. Lewis'}]"
20,0173ca962e4ab3d084c89568345e06f67d3d7efc,Hyperparameter Search in Machine Learning,"We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.",2015.0,48.0,355.0,False,,"{'volume': 'abs/1502.02127', 'name': 'ArXiv'}","{'bibtex': '@Article{Claesen2015HyperparameterSI,\n author = {M. Claesen and B. Moor},\n journal = {ArXiv},\n title = {Hyperparameter Search in Machine Learning},\n volume = {abs/1502.02127},\n year = {2015}\n}\n'}","[{'authorId': '48461464', 'name': 'M. Claesen'}, {'authorId': '143750713', 'name': 'B. Moor'}]"
21,01899e2f860ce17249b1c7d0e007a8570bbc237c,A virtual agent to sustaining children's engagement in language learning,"In this thesis we aimed to explore the potential of gamification defined as “the use of game elements in non-game contexts” [30] in increasing children's (aged 5 to 6) engagement with the task. This is mainly due to the fact that our world is living a technological era, and videogames are an example of this engagement by being able to maintain children’s (and adults) engagement for hours straight. For the purpose of limiting complexity, we only addressed the feedback element by introducing it with an anthropomorphic virtual agent (human-like aspect), because research shows that virtual agents (VA’s) can influence behavioural change [17], or even induce emotions on humans both through the use of feedback provided and their facial expressions, which can interpreted in the same way as of humans’ [2]. By pairing the VA with the gamification concept, we wanted to 1) create a VA that is likely to be well-received by children (appearance and behaviour), and 2) have the immediate feedback that games have, so we can give children an assessment of their actions in real-time, as opposed to waiting for feedback from someone (traditional teaching), and with this give students more chances to succeed [32, 43]. Our final system consisted on a virtual environment, where children formed words that corresponded to a given image. In order to measure the impact that the VA had on engagement, the system was developed in two versions: one version of the system was limited to provide a simple feedback environment, where the VA provided feedback, by responding with simple phrases (i.e. “correct” or “incorrect”); for the second version, the VA had a more complex approach where it tried to encourage children to complete the word – a motivational feedback even when they weren’t succeeding. Lastly we conducted a field study with two groups of children, where one group tested the version with the simple feedback, and the other group tested the ‘motivational’ version of the system. We used a quantitative approach to analyze the collected data that measured the engagement, based on the number of tasks (words) completed and time spent with system. The results of the evaluation showed that the use of motivational feedback may carry a positive effect on engaging children.",2016.0,75.0,0.0,False,,"{'name': '', 'volume': ''}","{'bibtex': ""@Inproceedings{Abreu2016AVA,\n author = {Jhair Chisuikafue Amaya Abreu},\n title = {A virtual agent to sustaining children's engagement in language learning},\n year = {2016}\n}\n""}","[{'authorId': '119279125', 'name': 'Jhair Chisuikafue Amaya Abreu'}]"
22,01b36f49b6bb03a5cc51ca4deee2de9be88fc274,Evaluation of the Robot Assisted Sign Language Tutoring Using Video-Based Studies,,2012.0,20.0,40.0,False,,"{'volume': '4', 'pages': '273-283', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Kose-Bagci2012EvaluationOT,\n author = {H. Kose-Bagci and R. Yorganci and Esra H. Algan and D. Syrdal},\n journal = {International Journal of Social Robotics},\n pages = {273-283},\n title = {Evaluation of the Robot Assisted Sign Language Tutoring Using Video-Based Studies},\n volume = {4},\n year = {2012}\n}\n'}","[{'authorId': '1399283111', 'name': 'H. Kose-Bagci'}, {'authorId': '2529764', 'name': 'R. Yorganci'}, {'authorId': '2652930', 'name': 'Esra H. Algan'}, {'authorId': '1700812', 'name': 'D. Syrdal'}]"
23,01b9736851e561a3140b5f9e365cbbc3956ae221,How virtual reality training can win friends and influence people,,2013.0,1.0,17.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hart2013HowVR,\n author = {John Hart and J. Gratch and S. Marsella},\n title = {How virtual reality training can win friends and influence people},\n year = {2013}\n}\n'}","[{'authorId': '145074235', 'name': 'John Hart'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
24,02188f575123a175f9afb6edb91f845a8d2da8c4,"A Review on Mixed Reality: Current Trends, Challenges and Prospects","Currently, new technologies have enabled the design of smart applications that are used as decision-making tools in the problems of daily life. The key issue in designing such an application is the increasing level of user interaction. Mixed reality (MR) is an emerging technology that deals with maximum user interaction in the real world compared to other similar technologies. Developing an MR application is complicated, and depends on the different components that have been addressed in previous literature. In addition to the extraction of such components, a comprehensive study that presents a generic framework comprising all components required to develop MR applications needs to be performed. This review studies intensive research to obtain a comprehensive framework for MR applications. The suggested framework comprises five layers: the first layer considers system components; the second and third layers focus on architectural issues for component integration; the fourth layer is the application layer that executes the architecture; and the fifth layer is the user interface layer that enables user interaction. The merits of this study are as follows: this review can act as a proper resource for MR basic concepts, and it introduces MR development steps and analytical models, a simulation toolkit, system types, and architecture types, in addition to practical issues for stakeholders such as considering MR different domains.",2020.0,118.0,121.0,True,"{'url': 'https://www.mdpi.com/2076-3417/10/2/636/pdf?version=1579169182', 'status': None}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Rokhsaritalemi2020ARO,\n author = {Somaiieh Rokhsaritalemi and A. Sadeghi-Niaraki and Soo-Mi Choi},\n journal = {Applied Sciences},\n title = {A Review on Mixed Reality: Current Trends, Challenges and Prospects},\n year = {2020}\n}\n'}","[{'authorId': '1411298447', 'name': 'Somaiieh Rokhsaritalemi'}, {'authorId': '1403015408', 'name': 'A. Sadeghi-Niaraki'}, {'authorId': '7236280', 'name': 'Soo-Mi Choi'}]"
25,02437323ef3d0c500774818f8917abcad2d0429b,Video game therapy for emotional regulation and impulsivity control in a series of treated cases with bulimia nervosa.,"Although standard psychological treatments have been successful in treating several core features in eating disorders (ED), other characteristics such as emotional regulation or impulsivity appear to be more resistant to change. There is a growing body of evidence to support the efficacy of cognitive remediation for cognitive and emotional difficulties in ED. Playmancer/ Islands is a video game (VG) designed to specifically treat mental disorders, characterized by problems in impulse control. The objective of the game is to increase self-control over emotions, decision making and behaviours. The aim of this study is to describe the results from a consecutive series of nine bulimia nervosa patients who were treated with the VG in addition to cognitive behaviour therapy (CBT). The outcomes included clinical and psychopathological questionnaires, and physiological measures were obtained during the VG. Emotional regulation improved, heart rate variability increased, and respiratory rate and impulsivity measures reduced after the treatment. These findings suggest that VG training may enhance treatment for ED.",2013.0,55.0,68.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:72561/ATTACHMENT01', 'status': None}","{'volume': '21 6', 'pages': '\n          493-9\n        ', 'name': 'European eating disorders review : the journal of the Eating Disorders Association'}","{'bibtex': '@Article{Fagundo2013VideoGT,\n author = {A. B. Fagundo and J. Santamaría and L. Forcano and C. Giner-Bartolomé and S. Jiménez-Murcia and I. Sánchez and Roser Granero and M. Ben-Moussa and N. Magnenat-Thalmann and D. Konstantas and T. Lam and Mikkel Lucas and J. Nielsen and R. Bults and S. Tarrega and J. Menchón and R. de la Torre and V. Cardi and J. Treasure and F. Fernández-Aranda},\n journal = {European eating disorders review : the journal of the Eating Disorders Association},\n pages = {\n          493-9\n        },\n title = {Video game therapy for emotional regulation and impulsivity control in a series of treated cases with bulimia nervosa.},\n volume = {21 6},\n year = {2013}\n}\n'}","[{'authorId': '4026148', 'name': 'A. B. Fagundo'}, {'authorId': '36916560', 'name': 'J. Santamaría'}, {'authorId': '6380403', 'name': 'L. Forcano'}, {'authorId': '1401552881', 'name': 'C. Giner-Bartolomé'}, {'authorId': '1397920461', 'name': 'S. Jiménez-Murcia'}, {'authorId': '145765442', 'name': 'I. Sánchez'}, {'authorId': '2395388', 'name': 'Roser Granero'}, {'authorId': '1404822422', 'name': 'M. Ben-Moussa'}, {'authorId': '1387241200', 'name': 'N. Magnenat-Thalmann'}, {'authorId': '1724215', 'name': 'D. Konstantas'}, {'authorId': '144387064', 'name': 'T. Lam'}, {'authorId': '40084614', 'name': 'Mikkel Lucas'}, {'authorId': '143964702', 'name': 'J. Nielsen'}, {'authorId': '1840604', 'name': 'R. Bults'}, {'authorId': '2366468', 'name': 'S. Tarrega'}, {'authorId': '1786432', 'name': 'J. Menchón'}, {'authorId': '144110303', 'name': 'R. de la Torre'}, {'authorId': '5357010', 'name': 'V. Cardi'}, {'authorId': '144107180', 'name': 'J. Treasure'}, {'authorId': '1397920429', 'name': 'F. Fernández-Aranda'}]"
26,025ae915106e92d397dbc1f1486b56fe0212b339,Nudge nudge wink wink: elements of face-to-face conversation for embodied conversational agents,"It will not be possible to apply exactly the same teaching process to the machine as to a normal child. It will not, for instance, be provided with legs, so that it could not be asked to go out and fill the coal scuttle. Possibly it might not have eyes. But however well these deficiencies might be overcome by clever engineering, one could not send the creature to school without the other children making excessive fun of it. —Alan Turing, ""Computing Machinery and Intelligence,"" 1950",2001.0,55.0,284.0,False,,"{'volume': '', 'pages': '1-27', 'name': ''}","{'bibtex': '@Inproceedings{Cassell2001NudgeNW,\n author = {Justine Cassell},\n pages = {1-27},\n title = {Nudge nudge wink wink: elements of face-to-face conversation for embodied conversational agents},\n year = {2001}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}]"
27,025fe77b606e2c78bd4ba0865de0070d784f9420,LE MODELE SATISFACTION-ALTRUISME,"Le modele Satisfaction-Altruisme se situe a la rencontre du domaine des systemes multi-agents reactifs (SMAr) et de la robotique mobile. Il permet d'introduire des comportements cooperatifs individuels dans l'approche de resolution collective de probleme. Apres avoir defini ces differents concepts, nous analysons les situations de cooperation. Nous en deduisons deux etats de satisfaction de l'agent: la satisfaction personnelle, qui est une mesure de la progression des actions, et la satisfaction interactive qui evalue les interactions avec le voisinage (gene, aide). Les agents peuvent alors s'influencer en propageant des signaux repulsifs ou attractifs declencheurs de reactions altruistes. Cette architecture est evaluee en simulation sur des problemes distribues (conflits spatiaux, robots fourrageurs) montrant le caractere emergent et auto-adaptatif des solutions. Le modele est ensuite etendu par l'introduction d'un module d'apprentissage social. Dans le cadre d'une implementation reelle, nous proposons un protocole de communication generique dedie aux SMA situes. Enfin, le modele est valide experimentalement par la resolution de conflits spatiaux entre robots mobiles autonomes.",2010.0,0.0,1.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Simonin2010LEMS,\n author = {Olivier Simonin},\n title = {LE MODELE SATISFACTION-ALTRUISME},\n year = {2010}\n}\n'}","[{'authorId': '1807441', 'name': 'Olivier Simonin'}]"
28,025fed19700b79839ca32385b26ea55b55fdbcb3,Artificial Emotion Simulation Model and Agent Architecture: Extended,,2013.0,9.0,6.0,False,,"{'name': '', 'pages': '207-221', 'volume': ''}","{'bibtex': '@Inproceedings{Lungu2013ArtificialES,\n author = {Valentin Lungu},\n pages = {207-221},\n title = {Artificial Emotion Simulation Model and Agent Architecture: Extended},\n year = {2013}\n}\n'}","[{'authorId': '2993393', 'name': 'Valentin Lungu'}]"
29,02b0555613f38ffa99ce219509c0836d48cb546a,I Didn't Know That Virtual Agent Was Angry at Me: Investigating Effects of Gaze Direction on Emotion Recognition and Evaluation,,2013.0,10.0,9.0,False,,{'pages': '192-197'},"{'bibtex': ""@Article{Ruijten2013IDK,\n author = {Peter A. M. Ruijten and C. Midden and Jaap Ham},\n booktitle = {International Conference on Persuasive Technology},\n pages = {192-197},\n title = {I Didn't Know That Virtual Agent Was Angry at Me: Investigating Effects of Gaze Direction on Emotion Recognition and Evaluation},\n year = {2013}\n}\n""}","[{'authorId': '3098701', 'name': 'Peter A. M. Ruijten'}, {'authorId': '3026039', 'name': 'C. Midden'}, {'authorId': '145960497', 'name': 'Jaap Ham'}]"
30,02b508a34619732053f83fa122205c1c83bd97a7,Artificial intelligence moving serious gaming: Presenting reusable game AI components,,2019.0,97.0,39.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10639-019-09968-2.pdf', 'status': None}","{'volume': '25', 'pages': '351-380', 'name': 'Education and Information Technologies'}","{'bibtex': '@Article{Westera2019ArtificialIM,\n author = {W. Westera and R. Prada and S. Mascarenhas and P. A. Santos and João Dias and Manuel Guimarães and K. Georgiadis and E. Nyamsuren and Kiavash Bahreini and Zerrin Yumak and C. Christyowidiasmoro and M. Dascalu and Gabriel Gutu-Robu and Stefan Ruseti},\n journal = {Education and Information Technologies},\n pages = {351-380},\n title = {Artificial intelligence moving serious gaming: Presenting reusable game AI components},\n volume = {25},\n year = {2019}\n}\n'}","[{'authorId': '3235367', 'name': 'W. Westera'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '145255182', 'name': 'P. A. Santos'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '28004507', 'name': 'Manuel Guimarães'}, {'authorId': '48884082', 'name': 'K. Georgiadis'}, {'authorId': '3260155', 'name': 'E. Nyamsuren'}, {'authorId': '2565070', 'name': 'Kiavash Bahreini'}, {'authorId': '1730934', 'name': 'Zerrin Yumak'}, {'authorId': '73337627', 'name': 'C. Christyowidiasmoro'}, {'authorId': '151505823', 'name': 'M. Dascalu'}, {'authorId': '1410082815', 'name': 'Gabriel Gutu-Robu'}, {'authorId': '3164109', 'name': 'Stefan Ruseti'}]"
31,02c7c1dc65b2bc835f7cee2ec2eed47d81df06e2,"Associations Between Facial Emotion Recognition, Cognition and Alexithymia in Patients with Schizophrenia: Comparison of Photographic and Virtual Reality Presentations","Emotion recognition is known to be impaired in schizophrenia patients. Although cognitive deficits and symptomatology have been associated with this impairment there are other patient characteristics, such as alexithymia, which have not been widely explored. Emotion recognition is normally assessed by means of photographs, although they do not reproduce the dynamism of human expressions. Our group has designed and validated a virtual reality (VR) task to assess and subsequently train schizophrenia patients. The present study uses this VR task to evaluate the impaired recognition of facial affect in patients with schizophrenia and to examine its association with cognitive deficit and the patients' inability to express feelings. Thirty clinically stabilized outpatients with a well-established diagnosis of schizophrenia or schizoaffective disorder were assessed in neuropsychological, symptomatic and affective domains. They then performed the facial emotion recognition task. Statistical analyses revealed no significant differences between the two presentation conditions (photographs and VR) in terms of overall errors made. However, anger and fear were easier to recognize in VR than in photographs. Moreover, strong correlations were found between psychopathology and the errors made.",2012.0,0.0,8.0,False,,"{'volume': '181', 'pages': '\n          88-92\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Gutiérrez-Maldonado2012AssociationsBF,\n author = {J. Gutiérrez-Maldonado and M. Rus-Calafell and S. Márquez-Rejón and J. Ribas-Sabaté},\n journal = {Studies in health technology and informatics},\n pages = {\n          88-92\n        },\n title = {Associations Between Facial Emotion Recognition, Cognition and Alexithymia in Patients with Schizophrenia: Comparison of Photographic and Virtual Reality Presentations},\n volume = {181},\n year = {2012}\n}\n'}","[{'authorId': '1398030059', 'name': 'J. Gutiérrez-Maldonado'}, {'authorId': '1404488371', 'name': 'M. Rus-Calafell'}, {'authorId': '1432170198', 'name': 'S. Márquez-Rejón'}, {'authorId': '1403595798', 'name': 'J. Ribas-Sabaté'}]"
32,02d22791d734bf3224791e559cdd8e6a036707a9,Engagement by Looking: Behaviors for Robots When Collaborating with People,"This paper reports on research on develop-ing the ability for robots to engage with humans in a collaborative conversation for hosting activities. It defines the engagement process in collaborative conversation, and reports on our progress in creating a robot to perform hosting activities. The paper then presents the analysis of a study that tracks the looks between collaborators and dis-cusses rules that will allow a robot to track humans so that engagement is maintained.",2003.0,24.0,14.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sidner2003EngagementBL,\n author = {C. Sidner and Christopher Lee and N. Lesh},\n title = {Engagement by Looking: Behaviors for Robots When Collaborating with People},\n year = {2003}\n}\n'}","[{'authorId': '2668280', 'name': 'C. Sidner'}, {'authorId': '2115445335', 'name': 'Christopher Lee'}, {'authorId': '3012739', 'name': 'N. Lesh'}]"
33,02d4f7b476e2e4f2055505e0efed4f665bb42df2,From Annotated Multimodal Corpora to Simulated Human-Like Behaviors,,2006.0,41.0,26.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-540-79037-2_1.pdf', 'status': None}",{'pages': '1-17'},"{'bibtex': '@Inproceedings{Rehm2006FromAM,\n author = {M. Rehm and E. André},\n pages = {1-17},\n title = {From Annotated Multimodal Corpora to Simulated Human-Like Behaviors},\n year = {2006}\n}\n'}","[{'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '1742930', 'name': 'E. André'}]"
34,02e0421c0b986d9893b91322d1d50747b56e35ab,Region-based facial representation for real-time Action Units intensity detection across datasets,,2019.0,46.0,13.0,False,,"{'volume': '22', 'pages': '477-489', 'name': 'Pattern Analysis and Applications'}","{'bibtex': '@Article{Hupont2019RegionbasedFR,\n author = {I. Hupont and M. Chetouani},\n journal = {Pattern Analysis and Applications},\n pages = {477-489},\n title = {Region-based facial representation for real-time Action Units intensity detection across datasets},\n volume = {22},\n year = {2019}\n}\n'}","[{'authorId': '2321433', 'name': 'I. Hupont'}, {'authorId': '1680828', 'name': 'M. Chetouani'}]"
35,031acf0078a4e1b5343939ce07acda6a7d795a07,Premotor cortex and the recognition of motor actions.,,1996.0,59.0,4538.0,False,,"{'volume': '3 2', 'pages': '\n          131-41\n        ', 'name': 'Brain research. Cognitive brain research'}","{'bibtex': '@Article{Rizzolatti1996PremotorCA,\n author = {G. Rizzolatti and L. Fadiga and V. Gallese and L. Fogassi},\n journal = {Brain research. Cognitive brain research},\n pages = {\n          131-41\n        },\n title = {Premotor cortex and the recognition of motor actions.},\n volume = {3 2},\n year = {1996}\n}\n'}","[{'authorId': '2460061', 'name': 'G. Rizzolatti'}, {'authorId': '1824336', 'name': 'L. Fadiga'}, {'authorId': '2914469', 'name': 'V. Gallese'}, {'authorId': '2419400', 'name': 'L. Fogassi'}]"
36,032a0b8b70875a1115678cd732e924bf0cf04e78,Modelling of more realistic intelligent virtual agent in virtual and mixed reality,". This article presents different options for modelling and realization of realistic intelligent virtual agents (IVA) in virtual and mixed reality. In relation to that a natural language dialogue with the users has been implemented; information about the preferences of the users is obtained, as well as their emotions, goals and the way, in which they prefer to achieve their goals. Emphasis is placed on the method for modelling the visualization of IVA; the facial expressions and emotions, which can be conveyed; the gaze of the eyes; the mouth and lip-sync with the spoken words; the gait and gestures. Some results of conducted user dialogues when solving a particular problem; the selection of a goal and a way of achieving it are discussed.",2022.0,18.0,1.0,True,,{'name': '17TH INTERNATIONAL CONFERENCE ON CONCENTRATOR PHOTOVOLTAIC SYSTEMS (CPV-17)'},"{'bibtex': '@Conference{Budakova2022ModellingOM,\n author = {D. Budakova and Veselka Petrova-Dimitrova and V. Vasilev and L. Dakovski},\n booktitle = {17TH INTERNATIONAL CONFERENCE ON CONCENTRATOR PHOTOVOLTAIC SYSTEMS (CPV-17)},\n journal = {17TH INTERNATIONAL CONFERENCE ON CONCENTRATOR PHOTOVOLTAIC SYSTEMS (CPV-17)},\n title = {Modelling of more realistic intelligent virtual agent in virtual and mixed reality},\n year = {2022}\n}\n'}","[{'authorId': '1799528', 'name': 'D. Budakova'}, {'authorId': '1581448954', 'name': 'Veselka Petrova-Dimitrova'}, {'authorId': '1717047753', 'name': 'V. Vasilev'}, {'authorId': '1753312', 'name': 'L. Dakovski'}]"
37,033458b01affaba6a50b7452dca510b4c8c830e1,Multimodal Affective State Assessment Using fNIRS + EEG and Spontaneous Facial Expression,"Human facial expressions are regarded as a vital indicator of one’s emotion and intention, and even reveal the state of health and wellbeing. Emotional states have been associated with information processing within and between subcortical and cortical areas of the brain, including the amygdala and prefrontal cortex. In this study, we evaluated the relationship between spontaneous human facial affective expressions and multi-modal brain activity measured via non-invasive and wearable sensors: functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG) signals. The affective states of twelve male participants detected via fNIRS, EEG, and spontaneous facial expressions were investigated in response to both image-content stimuli and video-content stimuli. We propose a method to jointly evaluate fNIRS and EEG signals for affective state detection (emotional valence as positive or negative). Experimental results reveal a strong correlation between spontaneous facial affective expressions and the perceived emotional valence. Moreover, the affective states were estimated by the fNIRS, EEG, and fNIRS + EEG brain activity measurements. We show that the proposed EEG + fNIRS hybrid method outperforms fNIRS-only and EEG-only approaches. Our findings indicate that the dynamic (video-content based) stimuli triggers a larger affective response than the static (image-content based) stimuli. These findings also suggest joint utilization of facial expression and wearable neuroimaging, fNIRS, and EEG, for improved emotional analysis and affective brain–computer interface applications.",2020.0,76.0,18.0,True,"{'url': 'https://www.mdpi.com/2076-3425/10/2/85/pdf', 'status': None}","{'volume': '10', 'name': 'Brain Sciences'}","{'bibtex': '@Article{Sun2020MultimodalAS,\n author = {Yanjia Sun and H. Ayaz and A. Akansu},\n journal = {Brain Sciences},\n title = {Multimodal Affective State Assessment Using fNIRS + EEG and Spontaneous Facial Expression},\n volume = {10},\n year = {2020}\n}\n'}","[{'authorId': '1952126', 'name': 'Yanjia Sun'}, {'authorId': '1831769', 'name': 'H. Ayaz'}, {'authorId': '1741021', 'name': 'A. Akansu'}]"
38,0374b1b732ce2e5fba5b3d8b5ec50dbe2f02c64f,Internal Consistency and Reliability of the Networked Minds Social Presence Measure,"This study sought to develop and test a measure of social presence. The networked minds battery is proposed for a broad self-report measure of social presence. An experiment was conducted to test the internal consistency and criterion validity of the six constructs as determined by theory, specifically the ability of the measure to distinguish levels of social presence between (1) face-to-face interaction and mediated interaction, and (2) different levels of mediated interaction. The confirmatory factor analysis supports a model based upon a structure six distinct factors. In criterion validity tests the measure was generally sensitive to predicted differences between face-to-face and mediated interaction. On the other hand the measure was less sensitive to differences among low affordance and high affordance media, although the differences suggesting that text rated higher on perceived message and emotional understanding may provide some insight into the communication effectiveness of print media.",2006.0,5.0,93.0,False,,,"{'bibtex': '@Inproceedings{Harms2006InternalCA,\n author = {Chad Harms and F. Biocca},\n title = {Internal Consistency and Reliability of the Networked Minds Social Presence Measure},\n year = {2006}\n}\n'}","[{'authorId': '34303570', 'name': 'Chad Harms'}, {'authorId': '1726689', 'name': 'F. Biocca'}]"
39,037af053a367777c6d4560a5680b91d4cbcdd57b,The impact of social context on mimicry,,2008.0,70.0,401.0,False,,"{'volume': '77', 'pages': '343-352', 'name': 'Biological Psychology'}","{'bibtex': '@Article{Bourgeois2008TheIO,\n author = {P. Bourgeois and U. Hess},\n journal = {Biological Psychology},\n pages = {343-352},\n title = {The impact of social context on mimicry},\n volume = {77},\n year = {2008}\n}\n'}","[{'authorId': '20955552', 'name': 'P. Bourgeois'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
40,037b59ab816c00d55bd4f03c4efd61d316a6e3b9,Measuring facial expressions by computer image analysis.,"Facial expressions provide an important behavioral measure for the study of emotion, cognitive processes, and social interaction. The Facial Action Coding System (Ekman & Friesen, 1978) is an objective method for quantifying facial movement in terms of component actions. We applied computer image analysis to the problem of automatically detecting facial actions in sequences of images. Three approaches were compared: holistic spatial analysis, explicit measurement of features such as wrinkles, and estimation of motion flow fields. The three methods were combined in a hybrid system that classified six upper facial actions with 91% accuracy. The hybrid system outperformed human nonexperts on this task and performed as well as highly trained experts. An automated system would make facial expression measurement more widely accessible as a research tool in behavioral science and investigations of the neural substrates of emotion.",1999.0,66.0,442.0,True,"{'url': 'http://papers.cnl.salk.edu/PDFs/Measuring%20Facial%20Expressions%20by%20Computer%20Image%20Analysis%201999-3557.pdf', 'status': None}","{'volume': '36 2', 'pages': '\n          253-63\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Bartlett1999MeasuringFE,\n author = {M. Bartlett and M. Bartlett and Joseph C. Hager and P. Ekman and T. Sejnowski and T. Sejnowski},\n journal = {Psychophysiology},\n pages = {\n          253-63\n        },\n title = {Measuring facial expressions by computer image analysis.},\n volume = {36 2},\n year = {1999}\n}\n'}","[{'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '2072657855', 'name': 'Joseph C. Hager'}, {'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '1714528', 'name': 'T. Sejnowski'}, {'authorId': '1714528', 'name': 'T. Sejnowski'}]"
41,037e97f35db0d3a4730ece11a9078a1f9ee2c913,Overlapping activity in anterior insula during interoception and emotional experience,,2012.0,53.0,386.0,True,"{'url': 'https://europepmc.org/articles/pmc6558972?pdf=render', 'status': None}","{'volume': '62', 'pages': '493-499', 'name': 'NeuroImage'}","{'bibtex': '@Article{Zaki2012OverlappingAI,\n author = {Jamil Zaki and J. Davis and K. Ochsner},\n journal = {NeuroImage},\n pages = {493-499},\n title = {Overlapping activity in anterior insula during interoception and emotional experience},\n volume = {62},\n year = {2012}\n}\n'}","[{'authorId': '2268731', 'name': 'Jamil Zaki'}, {'authorId': '2076737', 'name': 'J. Davis'}, {'authorId': '2669604', 'name': 'K. Ochsner'}]"
42,03c656b7010b3a13d5c50a538903141f338b08b5,Autonomous pedestrians,"We address the difficult open problem of emulating the rich complexity of real pedestrians in urban environments. Our artificial life approach integrates motor, perceptual, behavioral, and cognitive components within a model of pedestrians as individuals. Our comprehensive model feature innovations in these components, as well as in their combination, yielding results of unprecedented fidelity and complexity for fully autonomous multi-human simulation in a large urban environment. We represent the environment using hierarchical data structures, which efficiently support the perceptual queries of the autonomous pedestrians that drive their behavioral responses and sustain their ability to plan their actions on local and global scales.",2005.0,44.0,634.0,False,,{'pages': '19-28'},"{'bibtex': '@Inproceedings{Shao2005AutonomousP,\n author = {W. Shao and Demetri Terzopoulos},\n pages = {19-28},\n title = {Autonomous pedestrians},\n year = {2005}\n}\n'}","[{'authorId': '89267134', 'name': 'W. Shao'}, {'authorId': '1750924', 'name': 'Demetri Terzopoulos'}]"
44,03d43a1f53889b26edbd65776d9939846833a5e5,I Can See It in Your Eyes: Gaze as an Implicit Cue of Uncanniness and Task Performance in Repeated Interactions With Robots,"Over the past years, extensive research has been dedicated to developing robust platforms and data-driven dialog models to support long-term human-robot interactions. However, little is known about how people's perception of robots and engagement with them develop over time and how these can be accurately assessed through implicit and continuous measurement techniques. In this paper, we explore this by involving participants in three interaction sessions with multiple days of zero exposure in between. Each session consists of a joint task with a robot as well as two short social chats with it before and after the task. We measure participants' gaze patterns with a wearable eye-tracker and gauge their perception of the robot and engagement with it and the joint task using questionnaires. Results disclose that aversion of gaze in a social chat is an indicator of a robot's uncanniness and that the more people gaze at the robot in a joint task, the worse they perform. In contrast with most HRI literature, our results show that gaze toward an object of shared attention, rather than gaze toward a robotic partner, is the most meaningful predictor of engagement in a joint task. Furthermore, the analyses of gaze patterns in repeated interactions disclose that people's mutual gaze in a social chat develops congruently with their perceptions of the robot over time. These are key findings for the HRI community as they entail that gaze behavior can be used as an implicit measure of people's perception of robots in a social chat and of their engagement and task performance in a joint task.",2021.0,67.0,9.0,True,,"{'volume': '8', 'name': 'Frontiers in Robotics and AI'}","{'bibtex': '@Article{Perugia2021ICS,\n author = {G. Perugia and Maike Paetzel-Prüsmann and Madelene Alanenpää and Ginevra Castellano},\n journal = {Frontiers in Robotics and AI},\n title = {I Can See It in Your Eyes: Gaze as an Implicit Cue of Uncanniness and Task Performance in Repeated Interactions With Robots},\n volume = {8},\n year = {2021}\n}\n'}","[{'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '2047241817', 'name': 'Maike Paetzel-Prüsmann'}, {'authorId': '2047245362', 'name': 'Madelene Alanenpää'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
45,03d61a33796234b8bae5ac38de9b26c1c5ed9e2f,Automated Anatomical Labeling of Activations in SPM Using a Macroscopic Anatomical Parcellation of the MNI MRI Single-Subject Brain,"An anatomical parcellation of the spatially normalized single-subject high-resolution T1 volume provided by the Montreal Neurological Institute (MNI) (D. L. Collins et al., 1998, Trans. Med. Imag. 17, 463-468) was performed. The MNI single-subject main sulci were first delineated and further used as landmarks for the 3D definition of 45 anatomical volumes of interest (AVOI) in each hemisphere. This procedure was performed using a dedicated software which allowed a 3D following of the sulci course on the edited brain. Regions of interest were then drawn manually with the same software every 2 mm on the axial slices of the high-resolution MNI single subject. The 90 AVOI were reconstructed and assigned a label. Using this parcellation method, three procedures to perform the automated anatomical labeling of functional studies are proposed: (1) labeling of an extremum defined by a set of coordinates, (2) percentage of voxels belonging to each of the AVOI intersected by a sphere centered by a set of coordinates, and (3) percentage of voxels belonging to each of the AVOI intersected by an activated cluster. An interface with the Statistical Parametric Mapping package (SPM, J. Ashburner and K. J. Friston, 1999, Hum. Brain Mapp. 7, 254-266) is provided as a freeware to researchers of the neuroimaging community. We believe that this tool is an improvement for the macroscopical labeling of activated area compared to labeling assessed using the Talairach atlas brain in which deformations are well known. However, this tool does not alleviate the need for more sophisticated labeling strategies based on anatomical or cytoarchitectonic probabilistic maps.",2002.0,45.0,14324.0,False,,"{'volume': '15', 'pages': '273-289', 'name': 'NeuroImage'}","{'bibtex': '@Article{Tzourio-Mazoyer2002AutomatedAL,\n author = {N. Tzourio-Mazoyer and B. Landeau and D. Papathanassiou and F. Crivello and O. Etard and N. Delcroix and B. Mazoyer and M. Joliot},\n journal = {NeuroImage},\n pages = {273-289},\n title = {Automated Anatomical Labeling of Activations in SPM Using a Macroscopic Anatomical Parcellation of the MNI MRI Single-Subject Brain},\n volume = {15},\n year = {2002}\n}\n'}","[{'authorId': '1398099420', 'name': 'N. Tzourio-Mazoyer'}, {'authorId': '2043846', 'name': 'B. Landeau'}, {'authorId': '3310831', 'name': 'D. Papathanassiou'}, {'authorId': '2442129', 'name': 'F. Crivello'}, {'authorId': '48751540', 'name': 'O. Etard'}, {'authorId': '2580282', 'name': 'N. Delcroix'}, {'authorId': '2946115', 'name': 'B. Mazoyer'}, {'authorId': '2188749', 'name': 'M. Joliot'}]"
46,03d6502c0889b34f37a63869fe76ef6f0c8c974b,A Touching Sight SII/PV Activation during the Observation and Experience of Touch,,2004.0,40.0,821.0,True,"{'url': 'http://www.cell.com/article/S0896627304001564/pdf', 'status': None}","{'volume': '42', 'pages': '335-346', 'name': 'Neuron'}","{'bibtex': '@Article{Keysers2004ATS,\n author = {C. Keysers and B. Wicker and V. Gazzola and J. Anton and L. Fogassi and V. Gallese},\n journal = {Neuron},\n pages = {335-346},\n title = {A Touching Sight SII/PV Activation during the Observation and Experience of Touch},\n volume = {42},\n year = {2004}\n}\n'}","[{'authorId': '46646879', 'name': 'C. Keysers'}, {'authorId': '144109100', 'name': 'B. Wicker'}, {'authorId': '2091067', 'name': 'V. Gazzola'}, {'authorId': '31885367', 'name': 'J. Anton'}, {'authorId': '2419400', 'name': 'L. Fogassi'}, {'authorId': '2914469', 'name': 'V. Gallese'}]"
47,040792d23a489391dcc45be1aa0107cfae17b116,Beyond backchannels: co-construction of dyadic stancce by reciprocal reinforcement of smiles between virtual agents,"Beyond backchannels: co-construction of dyadic stance by reciprocal reinforcement of smiles between virtual agents. Ken Prepin (ken.prepin@telecom-paristech.fr) LTCI-CNRS/Telecom-ParisTech, 37-39 rue Dareau 75014 Paris, France Magalie Ochs (magalie.ochs@telecom-paristech.fr) LTCI-CNRS/Telecom-ParisTech, 37-39 rue Dareau 75014 Paris, France Catherine Pelachaud (catherine.pelachaud@telecom-paristech.fr) LTCI-CNRS/Telecom-ParisTech, 37-39 rue Dareau 75014 Paris, France Abstract dyadic stances can be inferred (Prepin, Ochs, & Pelachaud, 2012) from diachronic alignment between interactants. The effort of interlocutors to linguistically and non-verbally align through time is a marker of stance: it convey stance of mu- tual understanding, attention, agreement, interest and pleas- antness (Louwerse, Dale, Bard, & Jeuniaux, 2012). When two persons participate in a discussion, they not only exchange the concepts and ideas they are discussing, they also express attitudes, feelings and commitments regarding their partner: they express interpersonal stances. Endowed with backchannel model, several virtual agents are able to react to their partners’ behaviour through their non-verbal behaviour. In this paper, we go beyond this approach, proposing and test- ing a model that enables agents to express a dyadic stance, marker of effective communication: agents will naturally co- construct a shared dyadic stance if and only if their interper- sonal stance is reciprocally positive. We focus on smile, which conveys interpersonal stance and is a particularly efficient sig- nal for co-regulation of communication. With this model, a virtual agent, only capable to control its own individual pa- rameters, can, in fact, modulate and control the dyadic stance appearing when it interacts with its partner. The evaluation of the model through a user perceptive study has enabled us to validate that the dyadic stance is significantly perceived as more positive (mutual understanding, attention, agreement, in- terest, pleasantness) when reinforcement of smile is reciprocal. Keywords: dyadic interaction; interactive behaviours; dynam- ical systems; dyadic stance; smile; virtual agent; The description of stance has not only evolved toward a distinction between individual and co-constructed stance. It has also evolved from a uniquely linguistic description (DuBois, 2007; Kielsing, 2009) to a description implying in- teractants’ Non-Verbal Behaviours (NVBs) (Scherer, 2005; Prepin et al., 2012). The non-verbal behaviours participate in maintaining contact between interactants and facilitate ver- bal exchange: they are an integral part of the communication process (Paradowski, 2011). NVBs actively convey stances through paralinguistic features (such as tone of voice, dura- tion, loudness or prosody), facial expressions, and postures (Chindamo et al., 2012). Introduction When we consider verbal communication, interlocutors not only exchange the concepts and ideas which constitute the subject of their discussion, they also express feelings, judge- ments or commitments regarding this subject. This “atti- tude which, for some time, is expressed and sustained in- teractively in communication, in a unimodal or multi-modal manner” corresponds to the stance: Chindamo, Allwood, and Ahls´en (2012) review the existing definitions and descriptions of stance; they show how these definitions have evolved from a focus on individual expression of stance to a more interac- tive and social description. Individual stance refers to two types of stance: epistemic and interpersonal stance (Kielsing, 2009). The epistemic stance is the expression of the rela- tionship of a person to his/her own talk (for instance “cer- tain”). The interpersonal stances convey the relationship of a person to the interlocutor (for example “warm” or “polite”). Moreover, during an interaction, “stances are constructed across turns rather than being the product of a single turn” (Chindamo et al., 2012). When interactants with individ- ual epistemic and interpersonal stances are put in presence, Models of interactive agents have mainly explored the au- tomatic generation of virtual agent’s behaviour aligned on the interlocutor’s behaviour. Buschmeier, S., and Kopp (2010) combine a model of lexical alignment with a model gener- ating behaviours based on linguistic information. Bailenson and Yee (2005) model the NVBs alignment of a speaking virtual agent to a listening human. They propose a Digital Chameleon (in reference to the Chameleon effect described by Chartrand and Bargh (1999)). Bevacqua, Hyniewska, and Pelachaud (2010) model the NVBs alignment of a listen- ing agent to a speaking human: they propose a model of backchannels, i.e. NVBs aligned in time and nature, to fa- cilitate human users to tell a story. All these models focus on the adaptation of the virtual agent to its interlocutor, but do not take into account the recip- rocal adaptation of this interlocutor: behaviours are computed in reaction to partner’s behaviour, but not in interaction with partner’s behaviour; the dynamical coupling associated to the mutual engagement of interactants is not modelled, and crit- ical parameters of interaction such as synchrony and align- ment which appear as side effects of this coupling (Paolo,",2013.0,23.0,23.0,False,,"{'volume': '35', 'name': 'Cognitive Science'}","{'bibtex': '@Article{Prepin2013BeyondBC,\n author = {K. Prepin and M. Ochs and C. Pelachaud},\n journal = {Cognitive Science},\n title = {Beyond backchannels: co-construction of dyadic stancce by reciprocal reinforcement of smiles between virtual agents},\n volume = {35},\n year = {2013}\n}\n'}","[{'authorId': '2181003', 'name': 'K. Prepin'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
48,041326c202655cd60df276bf7a148f2ecddfc479,Cognitive architectures: Research issues and challenges,,2009.0,104.0,710.0,True,"{'url': 'http://cll.stanford.edu/~langley/papers/fin.arch.pdf', 'status': None}","{'volume': '10', 'pages': '141-160', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Langley2009CognitiveAR,\n author = {P. Langley and J. Laird and Seth Rogers},\n journal = {Cognitive Systems Research},\n pages = {141-160},\n title = {Cognitive architectures: Research issues and challenges},\n volume = {10},\n year = {2009}\n}\n'}","[{'authorId': '1713919', 'name': 'P. Langley'}, {'authorId': '1715438', 'name': 'J. Laird'}, {'authorId': '144476811', 'name': 'Seth Rogers'}]"
50,043248200e65e6be90de7136512dab672a526eba,"Emotionally Expressive Avatars for Chatting, Learning and Therapeutic Intervention",,2007.0,40.0,67.0,False,,{'pages': '275-285'},"{'bibtex': '@Inproceedings{Fabri2007EmotionallyEA,\n author = {M. Fabri and S. Y. A. Elzouki and D. Moore},\n pages = {275-285},\n title = {Emotionally Expressive Avatars for Chatting, Learning and Therapeutic Intervention},\n year = {2007}\n}\n'}","[{'authorId': '35033593', 'name': 'M. Fabri'}, {'authorId': '2111741', 'name': 'S. Y. A. Elzouki'}, {'authorId': '71268802', 'name': 'D. Moore'}]"
51,043b40f1d5ebc3c5257e0667d9bb8f044e18f978,Bringing tabletop technologies to kindergarten children,"Taking computer technology away from the desktop and into a more physical, manipulative space, is known that provide many benefits and is generally considered to result in a system that is easier to learn and more natural to use. This paper describes a design solution that allows kindergarten children to take the benefits of the new pedagogical possibilities that tangible interaction and tabletop technologies offer for manipulative learning. After analysis of children's cognitive and psychomotor skills, we have designed and tuned a prototype game that is suitable for children aged 3 to 4 years old. Our prototype uniquely combines low cost tangible interaction and tabletop technology with tutored learning. The design has been based on the observation of children using the technology, letting them freely play with the application during three play sessions. These observational sessions informed the design decisions for the game whilst also confirming the children's enjoyment of the prototype.",2009.0,36.0,74.0,True,"{'url': 'https://www.scienceopen.com/document_file/3c831984-45bf-43e6-977f-2c0372647074/ScienceOpen/103_Marco.pdf', 'status': None}",{'pages': '103-111'},"{'bibtex': '@Inproceedings{Marco2009BringingTT,\n author = {Javier Marco and E. Cerezo and S. Baldassarri and Emanuela Mazzone and J. Read},\n pages = {103-111},\n title = {Bringing tabletop technologies to kindergarten children},\n year = {2009}\n}\n'}","[{'authorId': '145663360', 'name': 'Javier Marco'}, {'authorId': '144046205', 'name': 'E. Cerezo'}, {'authorId': '1787072', 'name': 'S. Baldassarri'}, {'authorId': '1719018', 'name': 'Emanuela Mazzone'}, {'authorId': '1743424', 'name': 'J. Read'}]"
52,046795f142bfe550d53de6056458d7f4ec962d4f,Virtual Reality and EEG-Based Intelligent Agent in Older Adults With Subjective Cognitive Decline: A Feasibility Study for Effects on Emotion and Cognition,"Objectives: Immersive virtual reality has tremendous potential to improve cognition in populations with cognitive impairment. We conducted a feasibility and proof-of-concept study to assess the potential of virtual reality and electroencephalography, with or without an intelligent agent, that adapts the presented material to the emotions elicited by the environment. Method: Older adults with subjective cognitive decline recruited from the community received a virtual reality-based intervention taking place in one of two virtual environments, a train (Part 1, N = 19) or a music theatre, complemented by the intelligent agent (Part 2, N = 19). A comparative control group (N = 19) receiving no intervention was also included. All participants completed measures of affect and cognition before and after the intervention. The intervention groups completed measures of cybersickness and user experience after the intervention. Results: Participants did not suffer from increased cybersickness following either intervention. They also reported a positive to highly positive user experience concerning the following aspects: attractivity, hedonic quality-identity and hedonic quality-stimulation. The measures of affect showed no pre-post change when comparing either intervention to the control condition. However, a reduction of negative affect was observed following the train intervention for participants with a high self-reported negative affect at baseline. Finally, there was a significant improvement in working memory when comparing either intervention group to the control condition. Conclusion: Our results support the feasibility and tolerability of the technology, and a positive impact on cognition, paving the way for a larger-scale randomized clinical trial to confirm efficacy.",2022.0,45.0,1.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frvir.2021.807991/pdf', 'status': 'GOLD'}",{'volume': '2'},"{'bibtex': '@Article{Cuesta2022VirtualRA,\n author = {M. Cuesta and Lynn Valeyry Verty and H. Abdessalem and A. Byrns and M. Bruneau and C. Frasson and S. Belleville},\n booktitle = {Frontiers in Virtual Reality},\n title = {Virtual Reality and EEG-Based Intelligent Agent in Older Adults With Subjective Cognitive Decline: A Feasibility Study for Effects on Emotion and Cognition},\n volume = {2},\n year = {2022}\n}\n'}","[{'authorId': '47258254', 'name': 'M. Cuesta'}, {'authorId': '2017917021', 'name': 'Lynn Valeyry Verty'}, {'authorId': '28987363', 'name': 'H. Abdessalem'}, {'authorId': '68990793', 'name': 'A. Byrns'}, {'authorId': '34277926', 'name': 'M. Bruneau'}, {'authorId': '1788058', 'name': 'C. Frasson'}, {'authorId': '145580293', 'name': 'S. Belleville'}]"
53,0470202ebe4fc43048f729a3aa4a90805f4bd8ea,Interactive Control of Large-Crowd Navigation in Virtual Environments Using Vector Fields,"Providing interactive control is a hot topic in crowd-navigation research. Here, the authors propose a simple but effective way for authoring a crowd scene. With their governing tool, users can easily drive the flow of crowds by sketching velocities on anchor points in the scene. This approach is fast enough to allow on-the-fly modification of vector fields.",2008.0,16.0,59.0,False,,"{'volume': '28', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Jin2008InteractiveCO,\n author = {Xiaogang Jin and Jiayi Xu and Charlie C. L. Wang and Shengsheng Huang and Jun Zhang},\n journal = {IEEE Computer Graphics and Applications},\n title = {Interactive Control of Large-Crowd Navigation in Virtual Environments Using Vector Fields},\n volume = {28},\n year = {2008}\n}\n'}","[{'authorId': '144240366', 'name': 'Xiaogang Jin'}, {'authorId': '2154719265', 'name': 'Jiayi Xu'}, {'authorId': '50097074', 'name': 'Charlie C. L. Wang'}, {'authorId': '2110204524', 'name': 'Shengsheng Huang'}, {'authorId': '2155661615', 'name': 'Jun Zhang'}]"
54,0475cbed8c8fa313f69d6c673502308cde35c9d1,An approach to environmental psychology,"Environmental psychology, though a fast-growing field, is one of the most difficult to fit into the confines of scientific inquiry. Measuring such subjective data as reactions to color, heat, light, and sound would seem to be an almost impossible task; indeed, until now there has been no theory around which the research in this field could be organized. This volume represents a preliminary effort to identify the relevant variables involved and fit them into a systematic framework. Furthermore, it presents extensive sets of measures for investigating the theory and implementing it in a variety of everyday environments.Basically, the framework outlined here proposes that environmental stimuli are linked to behavioral responses by the primary emotional responses of arousal, pleasure, and dominance. By considering the impact of the environment on these basic emotional responses, the effects of diverse stimulus components within or across sense modalities can be readily compared. An additional concept, information rate, is used to compare the effects of different environments, each with stimulation in many sense modalities. In the final chapters the authors present a series of hypotheses which relate the emotional response variables to a diversity of behaviors such as physical approach, performance, affiliation, and verbally or nonverbally expressed preference.",1974.0,0.0,5904.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mehrabian1974AnAT,\n author = {A. Mehrabian and J. Russell},\n title = {An approach to environmental psychology},\n year = {1974}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}, {'authorId': '46367714', 'name': 'J. Russell'}]"
56,050bfb1e475de1de425949800d25d3e0cbbcca62,Simulation of individual spontaneous reactive behavior,"The context of this work is the search for realism and believability of Virtual Humans. Our contribution to achieve this goal is to enable Virtual Humans (VH) to react to spontaneous events in virtual environments (VE). In order to reflect the individuality of each VH, these reactions have to be expressive and unique. In this paper we present firstly a model of reaction based on personality traits. The model was defined using statistical analysis of real people reacting to unexpected events. We also consider that the emotional state is involved in the modulation of reactions, thus we integrate a model of emotion update. Secondly, we present a semantic-based methodology to compose reactive animation sequences using inverse kinematics (IK) and key frame (KF) interpolation animation techniques. Finally, we present an application that demonstrates how Virtual Humans can produce different movements as reaction to unexpected stimuli, depending on their personality traits and emotional state.",2008.0,31.0,16.0,False,,{'pages': '143-150'},"{'bibtex': '@Inproceedings{García-Rojas2008SimulationOI,\n author = {Alejandra García-Rojas and M. Gutiérrez and D. Thalmann},\n pages = {143-150},\n title = {Simulation of individual spontaneous reactive behavior},\n year = {2008}\n}\n'}","[{'authorId': '66173005', 'name': 'Alejandra García-Rojas'}, {'authorId': '144901415', 'name': 'M. Gutiérrez'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}]"
57,051722a89ea75583cfe58f6d218db373776b4c6e,Truth is beauty: researching embodied conversational agents,"(1941) argues that the sole criterion for excellent research is that the researcher produces "" beauty. "" While seemingly ineffable and frustratingly imprecise, Hardy instead suggests that creating beauty is straightforward. First, the work must be accurate: erroneous results are useless. Second, one's peers must recognize the work to be interesting, exciting, elegant, and "" cool. "" While this second criterion might seem arbitrary, there is generally good agreement between scholars in a given community about "" interesting "" work (see Cole and Cole 1973 for a discussion), so one need not survey numerous researchers to ensure research is beautiful; asking a couple is equivalent to asking them all. With certain caveats, the work in embodied conversational agents (ECA) can make claims to beauty. ECAs are phenomenologically "" accurate "" to the extent that the agent's outward appearance objectively matches the appearance, language, attitudes and behavior of humans. Thus, questions that address manifestation accuracy include "" Does the agent walk like a person walk? "" and "" Does the agent use language and make grammatical errors the same way a person does? "" An alternative approach to accuracy, generally associated more with the artificial intelligence literature than with the ECA literature, assesses the extent to which the processes that produce aspects of the ECA are the same as the processes in humans. For example, "" Does the muscle model of the character match how human muscles work? "" or",2001.0,36.0,266.0,False,,"{'volume': '', 'pages': '374-402', 'name': ''}","{'bibtex': '@Inproceedings{Nass2001TruthIB,\n author = {C. Nass and K. Isbister and Eun-Ju Lee},\n pages = {374-402},\n title = {Truth is beauty: researching embodied conversational agents},\n year = {2001}\n}\n'}","[{'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '1740889', 'name': 'K. Isbister'}, {'authorId': '47266165', 'name': 'Eun-Ju Lee'}]"
58,0534432de675f5a44335a3727a15a1f69fed09b9,Facial Expression and Experience of Emotions in Psychodynamic Interviews with Patients with PTSD in Comparison to Healthy Subjects,"Background: The facial affective behavior of traumatized patients and of a healthy control group was compared. Sampling and Methods: Data of 15 videotaped clinical interviews of traumatized inpatients and of 15 healthy women (absence of mental/psychiatric disorder according to ICD-10) were ascertained. The affective facial expression of both groups was coded with the Emotional Facial Acting Coding System. Afterwards, the mimic analysis was correlated with gazing behavior and the emotional experience. The patients reported their traumatic experiences and the healthy women their main complaints. Results: The traumatized patients showed neither a reduction of overall facial expressions nor a reduced frequency of facial affects in comparison to the healthy control group. The control group, however, showed significantly more ‘genuine joy’. The traumatized patients showed significantly more anger. Conclusions: The traumatized patients did not show a significant reduction of overall facial expression. A more detailed analysis showed that on the one hand, stabilizing elements of relationships, such as genuine joy, appear significantly less on the face of traumatized patients as compared with the healthy women. On the other hand, the expression of anger was brought into the relationship significantly more often by the traumatized patients during face-to-face interaction (clinical interview). This indicates the importance of distance regulation interaction patterns of traumatized patients.",2007.0,36.0,34.0,False,,"{'volume': '40', 'pages': '296 - 302', 'name': 'Psychopathology'}","{'bibtex': '@Article{Kirsch2007FacialEA,\n author = {A. Kirsch and S. Brunnhuber},\n journal = {Psychopathology},\n pages = {296 - 302},\n title = {Facial Expression and Experience of Emotions in Psychodynamic Interviews with Patients with PTSD in Comparison to Healthy Subjects},\n volume = {40},\n year = {2007}\n}\n'}","[{'authorId': '40005661', 'name': 'A. Kirsch'}, {'authorId': '48572086', 'name': 'S. Brunnhuber'}]"
59,053eab53e12c4c65f97d3fc41bdb8f71bc6334a1,Zara: An Empathetic Interactive Virtual Agent,"Zara, or ‘Zara the Supergirl’, is a virtual robot that can show empathy while interacting with an user, and at the end of a 5-10 minute conversation, it can give a personality analysis based on the user responses. It can display and share emotions with the aid of its built in sentiment analysis, facial and emotion recognition, and speech module. Being the first of its kind, it has successfully integrated an empathetic system along with the human emotion recognition and sharing, into an augmented humanrobot interaction system. Zara was also displayed at the World Economic Forum held at Dalian in September 2015.",2016.0,13.0,2.0,False,,{'pages': '1176-1177'},"{'bibtex': '@Article{Fung2016ZaraAE,\n author = {Pascale Fung and Anik Dey and Farhad Bin Siddique and Ruixi Lin and Yang Yang and Yan Wan and R. Chan},\n booktitle = {Interspeech},\n pages = {1176-1177},\n title = {Zara: An Empathetic Interactive Virtual Agent},\n year = {2016}\n}\n'}","[{'authorId': '1683412', 'name': 'Pascale Fung'}, {'authorId': '2198200', 'name': 'Anik Dey'}, {'authorId': '3407465', 'name': 'Farhad Bin Siddique'}, {'authorId': '2068166503', 'name': 'Ruixi Lin'}, {'authorId': '2152916959', 'name': 'Yang Yang'}, {'authorId': '2075389340', 'name': 'Yan Wan'}, {'authorId': '1748955', 'name': 'R. Chan'}]"
60,053f4a06847ba6ea551eaf7ef1fb5bda9f64108f,A Survey of Autonomous Human Affect Detection Methods for Social Robots Engaged in Natural HRI,,2016.0,221.0,86.0,False,,"{'volume': '82', 'pages': '101-133', 'name': 'Journal of Intelligent & Robotic Systems'}","{'bibtex': '@Article{McColl2016ASO,\n author = {D. McColl and A. Hong and Naoaki Hatakeyama and G. Nejat and B. Benhabib},\n journal = {Journal of Intelligent & Robotic Systems},\n pages = {101-133},\n title = {A Survey of Autonomous Human Affect Detection Methods for Social Robots Engaged in Natural HRI},\n volume = {82},\n year = {2016}\n}\n'}","[{'authorId': '144427848', 'name': 'D. McColl'}, {'authorId': '32418659', 'name': 'A. Hong'}, {'authorId': '2094257416', 'name': 'Naoaki Hatakeyama'}, {'authorId': '2497882', 'name': 'G. Nejat'}, {'authorId': '1719617', 'name': 'B. Benhabib'}]"
61,0559485c0b5eff8e7c4f3395b655b96cbc8ef884,Effects of age and task difficulty on recognition of facial affect.,"Current evidence suggests that older adults are less accurate than young adults in their ability to identify facial expressions of emotion. In the present study, young and older adults' ability to correctly recognize facial affect representative of 6 different emotions (happiness, surprise, disgust, fear, anger, and sadness) was examined in 3 conditions varying in difficulty. Task difficulty was measured by varying the number of labels available in a forced choice recognition task to 2, 4, and 6. Results showed that age differences were present in the 2 more difficult conditions for fear and sadness. Older adults were impaired in recognizing facial expressions of surprise only in the 4-label condition. Current findings suggest that task difficulty moderates age differences in emotion labeling. The present study has contributed to previous research by illuminating the conditions under which age differences in the accuracy of labeling of facial affect are more likely to be observed.",2010.0,16.0,46.0,True,"{'url': 'https://academic.oup.com/psychsocgerontology/article-pdf/65B/3/323/1804121/gbq007.pdf', 'status': None}","{'volume': '65B 3', 'pages': '\n          323-7\n        ', 'name': 'The journals of gerontology. Series B, Psychological sciences and social sciences'}","{'bibtex': '@Article{Orgeta2010EffectsOA,\n author = {V. Orgeta},\n journal = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n pages = {\n          323-7\n        },\n title = {Effects of age and task difficulty on recognition of facial affect.},\n volume = {65B 3},\n year = {2010}\n}\n'}","[{'authorId': '4828478', 'name': 'V. Orgeta'}]"
62,055c22ca9a35aef32b19364c02bd6b403c1700f3,Enhanced neural activity in response to dynamic facial expressions of emotion: an fMRI study.,,2004.0,55.0,416.0,False,,"{'volume': '20 1', 'pages': '\n          81-91\n        ', 'name': 'Brain research. Cognitive brain research'}","{'bibtex': '@Article{Sato2004EnhancedNA,\n author = {W. Sato and T. Kochiyama and S. Yoshikawa and E. Naito and M. Matsumura},\n journal = {Brain research. Cognitive brain research},\n pages = {\n          81-91\n        },\n title = {Enhanced neural activity in response to dynamic facial expressions of emotion: an fMRI study.},\n volume = {20 1},\n year = {2004}\n}\n'}","[{'authorId': '46581944', 'name': 'W. Sato'}, {'authorId': '1757663', 'name': 'T. Kochiyama'}, {'authorId': '2211534', 'name': 'S. Yoshikawa'}, {'authorId': '2028478', 'name': 'E. Naito'}, {'authorId': '46755394', 'name': 'M. Matsumura'}]"
63,05c5a9ba09f2914beb83fc57f4b6c1bd443c74c2,Recognizing emotion from facial expressions: psychological and neurological mechanisms.,"Recognizing emotion from facial expressions draws on diverse psychological processes implemented in a large array of neural structures. Studies using evoked potentials, lesions, and functional imaging have begun to elucidate some of the mechanisms. Early perceptual processing of faces draws on cortices in occipital and temporal lobes that construct detailed representations from the configuration of facial features. Subsequent recognition requires a set of structures, including amygdala and orbitofrontal cortex, that links perceptual representations of the face to the generation of knowledge about the emotion signaled, a complex set of mechanisms using multiple strategies. Although recent studies have provided a wealth of detail regarding these mechanisms in the adult human brain, investigations are also being extended to nonhuman primates, to infants, and to patients with psychiatric disorders.",2002.0,346.0,1327.0,True,"{'url': 'https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.135.9369&rep=rep1&type=pdf', 'status': None}","{'volume': '1 1', 'pages': '\n          21-62\n        ', 'name': 'Behavioral and cognitive neuroscience reviews'}","{'bibtex': '@Article{Adolphs2002RecognizingEF,\n author = {R. Adolphs},\n journal = {Behavioral and cognitive neuroscience reviews},\n pages = {\n          21-62\n        },\n title = {Recognizing emotion from facial expressions: psychological and neurological mechanisms.},\n volume = {1 1},\n year = {2002}\n}\n'}","[{'authorId': '46306086', 'name': 'R. Adolphs'}]"
64,05cd6420426d27ae4fc822202fb4b689a6129f19,Available online,,,0.0,1086.0,False,,,"{'bibtex': '@Misc{None,\n title = {Available online}\n}\n'}",[]
65,05e0f92d03b7c15d888a2160b20c69f0964da725,On seeing human: a three-factor theory of anthropomorphism.,"Anthropomorphism describes the tendency to imbue the real or imagined behavior of nonhuman agents with humanlike characteristics, motivations, intentions, or emotions. Although surprisingly common, anthropomorphism is not invariant. This article describes a theory to explain when people are likely to anthropomorphize and when they are not, focused on three psychological determinants--the accessibility and applicability of anthropocentric knowledge (elicited agent knowledge), the motivation to explain and understand the behavior of other agents (effectance motivation), and the desire for social contact and affiliation (sociality motivation). This theory predicts that people are more likely to anthropomorphize when anthropocentric knowledge is accessible and applicable, when motivated to be effective social agents, and when lacking a sense of social connection to other humans. These factors help to explain why anthropomorphism is so variable; organize diverse research; and offer testable predictions about dispositional, situational, developmental, and cultural influences on anthropomorphism. Discussion addresses extensions of this theory into the specific psychological processes underlying anthropomorphism, applications of this theory into robotics and human-computer interaction, and the insights offered by this theory into the inverse process of dehumanization.",2007.0,286.0,1980.0,False,,"{'volume': '114 4', 'pages': '\n          864-86\n        ', 'name': 'Psychological review'}","{'bibtex': '@Article{Epley2007OnSH,\n author = {Nicholas Epley and A. Waytz and J. Cacioppo},\n journal = {Psychological review},\n pages = {\n          864-86\n        },\n title = {On seeing human: a three-factor theory of anthropomorphism.},\n volume = {114 4},\n year = {2007}\n}\n'}","[{'authorId': '7007014', 'name': 'Nicholas Epley'}, {'authorId': '3377580', 'name': 'A. Waytz'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}]"
66,06041d2a5e0fdc38d38a0b5c93f5fb4a125698ec,"Studying social interactions through immersive virtual environment technology: virtues, pitfalls, and future challenges","The goal of the present review is to explain how immersive virtual environment technology (IVET) can be used for the study of social interactions and how the use of virtual humans in immersive virtual environments can advance research and application in many different fields. Researchers studying individual differences in social interactions are typically interested in keeping the behavior and the appearance of the interaction partner constant across participants. With IVET researchers have full control over the interaction partners, can standardize them while still keeping the simulation realistic. Virtual simulations are valid: growing evidence shows that indeed studies conducted with IVET can replicate some well-known findings of social psychology. Moreover, IVET allows researchers to subtly manipulate characteristics of the environment (e.g., visual cues to prime participants) or of the social partner (e.g., his/her race) to investigate their influences on participants’ behavior and cognition. Furthermore, manipulations that would be difficult or impossible in real life (e.g., changing participants’ height) can be easily obtained with IVET. Beside the advantages for theoretical research, we explore the most recent training and clinical applications of IVET, its integration with other technologies (e.g., social sensing) and future challenges for researchers (e.g., making the communication between virtual humans and participants smoother).",2015.0,83.0,102.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00869/pdf', 'status': None}","{'volume': '6', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Bombari2015StudyingSI,\n author = {Dario Bombari and M. Schmid Mast and Elena Cañadas and Manuel Bachmann},\n journal = {Frontiers in Psychology},\n title = {Studying social interactions through immersive virtual environment technology: virtues, pitfalls, and future challenges},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '5983047', 'name': 'Dario Bombari'}, {'authorId': '2284257', 'name': 'M. Schmid Mast'}, {'authorId': '4036594', 'name': 'Elena Cañadas'}, {'authorId': '2056606805', 'name': 'Manuel Bachmann'}]"
67,06177ec5a24b4bcea1a457c6015a7f73453762b9,A comparative analysis of machine learning methods for emotion recognition using EEG and peripheral physiological signals,,2020.0,41.0,70.0,False,,"{'volume': '7', 'pages': '1-21', 'name': 'Journal of Big Data'}","{'bibtex': '@Article{Doma2020ACA,\n author = {Vikrant Doma and Matin Pirouz},\n journal = {Journal of Big Data},\n pages = {1-21},\n title = {A comparative analysis of machine learning methods for emotion recognition using EEG and peripheral physiological signals},\n volume = {7},\n year = {2020}\n}\n'}","[{'authorId': '1557824014', 'name': 'Vikrant Doma'}, {'authorId': '145964270', 'name': 'Matin Pirouz'}]"
68,062360fa270e2b30739363f5a219114d9a1c2a9f,Eye Tracking Methodology Theory And Practice,,2016.0,0.0,146.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Winkel2016EyeTM,\n author = {A. Winkel},\n title = {Eye Tracking Methodology Theory And Practice},\n year = {2016}\n}\n'}","[{'authorId': '82301100', 'name': 'A. Winkel'}]"
69,0629b3489ad2e67211691ed9d07c0fd0ca1b5a73,Cross-Cultural Emotion Recognition among Canadian Ethnic Groups,"This study aims to investigate cultural differences in recognition accuracy as well as the in-group advantage hypothesis for emotion recognition among sub-Saharan African, Chinese, and French Canadian individuals living in Canada. The participants viewed expressions of happiness, anger, sadness, fear, disgust, and shame selected from the Montreal Set of Facial Displays of Emotion. These data did not support the in-group advantage hypothesis under the condition of stimulus equivalence. However, both encoder and decoder effects were found. Specifically, French Canadians were more accurate for the decoding of expressions of shame and sadness. Moreover, fear expressions were best recognized when shown by sub-Saharan Africans, suggesting an effect of salience of expressive cues due to morphological features of the face.",2005.0,35.0,285.0,False,,"{'volume': '36', 'pages': '355 - 370', 'name': 'Journal of Cross-Cultural Psychology'}","{'bibtex': '@Article{Beaupré2005CrossCulturalER,\n author = {Martin G. Beaupré and U. Hess},\n journal = {Journal of Cross-Cultural Psychology},\n pages = {355 - 370},\n title = {Cross-Cultural Emotion Recognition among Canadian Ethnic Groups},\n volume = {36},\n year = {2005}\n}\n'}","[{'authorId': '5868984', 'name': 'Martin G. Beaupré'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
70,062be145b254cc7b41f92fbf32df0de09de2e2a9,Unpleasantness of animated characters corresponds to increased viewer attention to faces,"Animated characters are frequently used in television programs, movies, and video games, but relatively little is known about how their characteristics affect attention and viewer opinions. We used eyetracking and questionnaires to examine the role of visual complexity and animation style on viewing patterns and ratings of video-recorded and animated movie clips. We created videos of an actress performing and describing a series of actions with blocks. Of the videos, one set included regular HD recordings of the actress. The remaining video sets were animated using motion capture data from that actress for three characters: realistic, cartoon, and robot. Increased facial looking time correlated with unpleasantness ratings for individual characters and clips, determining that animation styles have an effect on both viewing patterns and audience members' subjective opinions of characters. In addition, the method described in this paper can expand future research on character animation.",2013.0,26.0,20.0,False,,{'name': 'Proceedings of the ACM Symposium on Applied Perception'},"{'bibtex': '@Article{Carter2013UnpleasantnessOA,\n author = {E. Carter and Moshe Mahler and J. Hodgins},\n journal = {Proceedings of the ACM Symposium on Applied Perception},\n title = {Unpleasantness of animated characters corresponds to increased viewer attention to faces},\n year = {2013}\n}\n'}","[{'authorId': '32134175', 'name': 'E. Carter'}, {'authorId': '30303590', 'name': 'Moshe Mahler'}, {'authorId': '1788773', 'name': 'J. Hodgins'}]"
71,062ccad7d8882c662525b884c9fcd83f46839999,Interactive and adaptive data-driven crowd simulation,We present an adaptive data-driven algorithm for interactive crowd simulation. Our approach combines realistic trajectory behaviors extracted from videos with synthetic multi-agent algorithms to generate plausible simulations. We use statistical techniques to compute the movement patterns and motion dynamics from noisy 2D trajectories extracted from crowd videos. These learned pedestrian dynamic characteristics are used to generate collision-free trajectories of virtual pedestrians in slightly different environments or situations. The overall approach is robust and can generate perceptually realistic crowd movements at interactive rates in dynamic environments. We also present results from preliminary user studies that evaluate the trajectory behaviors generated by our algorithm.,2016.0,48.0,45.0,False,,"{'pages': '29-38', 'name': '2016 IEEE Virtual Reality (VR)'}","{'bibtex': '@Article{Kim2016InteractiveAA,\n author = {Sujeong Kim and Aniket Bera and A. Best and Rohan Chabra and Dinesh Manocha},\n journal = {2016 IEEE Virtual Reality (VR)},\n pages = {29-38},\n title = {Interactive and adaptive data-driven crowd simulation},\n year = {2016}\n}\n'}","[{'authorId': '52162164', 'name': 'Sujeong Kim'}, {'authorId': '2718563', 'name': 'Aniket Bera'}, {'authorId': '10817944', 'name': 'A. Best'}, {'authorId': '3428200', 'name': 'Rohan Chabra'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
72,0632ed2d7a9830bb3b09d8b2124b08a00b34adc3,Emotion Recognition and Its Applications,,2014.0,20.0,98.0,False,,"{'volume': '300', 'pages': '51-62', 'name': 'Advances in intelligent systems and computing'}","{'bibtex': '@Article{Kołakowska2014EmotionRA,\n author = {A. Kołakowska and A. Landowska and M. Szwoch and W. Szwoch and M. Wróbel},\n journal = {Advances in intelligent systems and computing},\n pages = {51-62},\n title = {Emotion Recognition and Its Applications},\n volume = {300},\n year = {2014}\n}\n'}","[{'authorId': '1809661', 'name': 'A. Kołakowska'}, {'authorId': '2414357', 'name': 'A. Landowska'}, {'authorId': '3271448', 'name': 'M. Szwoch'}, {'authorId': '3175073', 'name': 'W. Szwoch'}, {'authorId': '34487194', 'name': 'M. Wróbel'}]"
73,064887d3ca4532602c1212387d63e741a32ea909,Towards Behavioral Consistency in Animated Agents,,2000.0,39.0,21.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-0-306-47002-8_17.pdf', 'status': None}",{'pages': '191-205'},"{'bibtex': '@Inproceedings{Allbeck2000TowardsBC,\n author = {J. Allbeck and N. Badler},\n pages = {191-205},\n title = {Towards Behavioral Consistency in Animated Agents},\n year = {2000}\n}\n'}","[{'authorId': '1855748', 'name': 'J. Allbeck'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
74,0651fe99cc587614c660d9d962584b8265c22807,MURML: A Multimodal Utterance Representation Markup Language for Conversational Agents,"This paper presents work on an artificial anthropomorphic agent with multimodal interaction abilitities. It focuses on the development of a markup language, MURML, that bridges between the planning and the animation tasks in the production of multimodal utterances. This hierarchically structured notation provides flexible means of describing gestures in a form-based way and of explicitly experessing their relations to accompanying speech.",2002.0,0.0,109.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Kranstedt2002MURMLAM,\n author = {Alfred Kranstedt and S. Kopp and I. Wachsmuth},\n title = {MURML: A Multimodal Utterance Representation Markup Language for Conversational Agents},\n year = {2002}\n}\n'}","[{'authorId': '2165508', 'name': 'Alfred Kranstedt'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
75,067154497bfcc3cc369a61784155d5fa32b5966f,Treatment adherence therapy in people with psychotic disorders: randomised controlled trial.,"BACKGROUND
Interventions to improve adherence to treatment in people with psychotic disorders have produced inconclusive results. We developed a new treatment, treatment adherence therapy (TAT), whose intervention modules are tailored to the reasons for an individual's non-adherence.


AIMS
To examine the effectiveness of TAT with regard to service engagement and medication adherence in out-patients with psychotic disorders who engage poorly.


METHOD
Randomised controlled study of TAT v. treatment as usual (TAU) in 109 out-patients. Most outcome measurements were performed by masked assessors. We used intention-to-treat multivariate analyses (Dutch Trial Registry: NTR1159).


RESULTS
Treatment adherence therapy v. TAU significantly benefited service engagement (Cohen's d = 0.48) and medication adherence (Cohen's d = 0.43). Results remained significant at 6-month follow-up for medication adherence. Near-significant effects were also found regarding involuntary readmissions (1.9% v. 11.8%, P = 0.053). Symptoms and quality of life did not improve.


CONCLUSIONS
Treatment adherence therapy helps improve engagement and adherence, and may prevent involuntary admission.",2010.0,46.0,116.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/8D4D120315A952F661BD3C5B334F986D/S0007125000253804a.pdf/div-class-title-treatment-adherence-therapy-in-people-with-psychotic-disorders-randomised-controlled-trial-div.pdf', 'status': None}","{'volume': '197 6', 'pages': '\n          448-55\n        ', 'name': 'The British journal of psychiatry : the journal of mental science'}","{'bibtex': '@Article{Staring2010TreatmentAT,\n author = {A. Staring and M. Gaag and G. Koopmans and J. Selten and J. V. Beveren and M. Hengeveld and A. Loonen and C. Mulder},\n journal = {The British journal of psychiatry : the journal of mental science},\n pages = {\n          448-55\n        },\n title = {Treatment adherence therapy in people with psychotic disorders: randomised controlled trial.},\n volume = {197 6},\n year = {2010}\n}\n'}","[{'authorId': '5628900', 'name': 'A. Staring'}, {'authorId': '145958551', 'name': 'M. Gaag'}, {'authorId': '4003746', 'name': 'G. Koopmans'}, {'authorId': '48944283', 'name': 'J. Selten'}, {'authorId': '81751978', 'name': 'J. V. Beveren'}, {'authorId': '1994652', 'name': 'M. Hengeveld'}, {'authorId': '33615601', 'name': 'A. Loonen'}, {'authorId': '4372174', 'name': 'C. Mulder'}]"
76,0671a660167b7b9b925e4709c08a57da6d84d910,Evaluating the effect of emotion on gender recognition in virtual humans,"In this paper, we investigate the ability of humans to determine the gender of conversing characters, based on facial and body cues for emotion. We used a corpus of simultaneously captured facial and body motions from four male and four female actors. In our Gender Rating task, participants were asked to rate how male or female they considered the motions to be, under different emotional states. In our Emotion Recognition task, participants were asked to classify the emotions, in order to determine how accurately perceived those emotions were. We found that gender perception was affected by emotion, where certain emotions facilitated gender determination while others masked it. We also found that there was no correlation between how accurate an emotion was portrayed and how much gender information was present in that motion. Finally, we found that the model used to display the motion did not affect gender perception of motion but did alter emotion recognition.",2013.0,26.0,20.0,True,"{'url': 'http://people.rennes.inria.fr/Ludovic.Hoyet/Documents/Articles/SAP2013_EmotionGender.pdf', 'status': None}",{'name': 'Proceedings of the ACM Symposium on Applied Perception'},"{'bibtex': '@Article{Zibrek2013EvaluatingTE,\n author = {Katja Zibrek and Ludovic Hoyet and K. Ruhland and R. Mcdonnell},\n journal = {Proceedings of the ACM Symposium on Applied Perception},\n title = {Evaluating the effect of emotion on gender recognition in virtual humans},\n year = {2013}\n}\n'}","[{'authorId': '1710384', 'name': 'Katja Zibrek'}, {'authorId': '1869571', 'name': 'Ludovic Hoyet'}, {'authorId': '38592832', 'name': 'K. Ruhland'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
77,0672092ecc507fb41d81e82d2986cf86c4bff14f,A recognition-primed decision (RPD) model of rapid decision making.,"Traditional models of decision making do not take into account many critical aspects of operational settings, as described in Chapter 1. Deci­ sion makers in operational settings are usually very experienced, in contrast to the naive subjects used in laboratory studies. In this chap­ ter I present a recognitional model of decision making that shows how people can use experience to avoid some of the limitations of analytical strategies. This model explains how people can make decisions without having to compare options. It fuses two processes-situation assess· ment and mental simulation-and asserts that people Wle situation assessment to generate a plausible course of action and use mental simulation to evaluate that course of action. I believe this recognition. al model describes how decision making is usually carried out in real­ world settings. This conclusion is based on a series of studies in which it was found that recognitional decision malting is much more common than analytical decision making. Finally, I contrast the strengths and weaknesses of recognitional and analytical decision strategies.",1993.0,0.0,1172.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Klein1993ARD,\n author = {Gary Klein},\n title = {A recognition-primed decision (RPD) model of rapid decision making.},\n year = {1993}\n}\n'}","[{'authorId': '145320331', 'name': 'Gary Klein'}]"
78,0693cecba234b591169fdee7718116b4eb76fdca,A selective meta-analysis on the relative incidence of discrete affective states during learning with technology,"The last decade has witnessed considerable interest in the investigation of the affective dimensions of learning and in the development of advanced learning technologies that automatically detect and respond to student affect. Identifying the affective states that students experience in technology-enhanced learning contexts is a fundamental question in this area. This article provides an initial attempt to answer this question with a selective meta-analysis of 24 studies that utilized a mixture of methodologies (online self-reports, online observations, emote-aloud protocols, cued recall) and affect judges (students themselves, untrained peers, trained judges) for fine-grained monitoring of 14 discrete affective states of 1,740 middle school, high school, college, and adult students in 5 countries. Affective states occurred over the course of interactions with a range of learning technologies, including intelligent tutoring systems, serious games, simulation environments, and simple computer interfaces. Standardized effect sizes of relative frequency, computed by comparing the proportional occurrence of each affective state to the other states in each study, were modeled with random-effects models. Engagement/flow was consistently found to be relatively frequent (d+ = 2.5), and contempt, anger, disgust, sadness, anxiety, delight, fear, and surprise were consistently infrequent, with d+ ranging from −6.5 to −0.78. Effects for boredom (d+ = 0.19), confusion (d+ = 0.12), curiosity (d+ = −0.10), happiness (d+ = −0.13), and frustration (d+ = −2.5) varied substantially across studies. Mixed-effects models indicated that the source of the affect judgments (self vs. observers) and the authenticity of the learning contexts (classroom vs. laboratory) accounted for greater heterogeneity than the use of advanced learning technologies and training time. Theoretical and applied implications of the findings are discussed.",2013.0,102.0,238.0,False,,"{'volume': '105', 'pages': '1082-1099', 'name': 'Journal of Educational Psychology'}","{'bibtex': '@Article{D’Mello2013ASM,\n author = {S. D’Mello},\n journal = {Journal of Educational Psychology},\n pages = {1082-1099},\n title = {A selective meta-analysis on the relative incidence of discrete affective states during learning with technology},\n volume = {105},\n year = {2013}\n}\n'}","[{'authorId': '1383996606', 'name': 'S. D’Mello'}]"
79,069443f2bbeb2deedefb600c82ed59cde2137e60,"Analysis of emotion recognition using facial expressions, speech and multimodal information","The interaction between human beings and computers will be more natural if computers are able to perceive and respond to human non-verbal communication such as emotions. Although several approaches have been proposed to recognize human emotions based on facial expressions or speech, relatively limited work has been done to fuse these two, and other, modalities to improve the accuracy and robustness of the emotion recognition system. This paper analyzes the strengths and the limitations of systems based only on facial expressions or acoustic information. It also discusses two approaches used to fuse these two modalities: decision level and feature level integration. Using a database recorded from an actress, four emotions were classified: sadness, anger, happiness, and neutral state. By the use of markers on her face, detailed facial motions were captured with motion capture, in conjunction with simultaneous speech recordings. The results reveal that the system based on facial expression gave better performance than the system based on just acoustic information for the emotions considered. Results also show the complementarily of the two modalities and that when these two modalities are fused, the performance and the robustness of the emotion recognition system improve measurably.",2004.0,24.0,880.0,False,,{'pages': '205-211'},"{'bibtex': '@Inproceedings{Busso2004AnalysisOE,\n author = {C. Busso and Z. Deng and S. Yıldırım and M. Bulut and C. Lee and Ebrahim (Abe) Kazemzadeh and Sungbok Lee and U. Neumann and Shrikanth S. Narayanan},\n pages = {205-211},\n title = {Analysis of emotion recognition using facial expressions, speech and multimodal information},\n year = {2004}\n}\n'}","[{'authorId': '2106794', 'name': 'C. Busso'}, {'authorId': '145140508', 'name': 'Z. Deng'}, {'authorId': '1936287', 'name': 'S. Yıldırım'}, {'authorId': '38816202', 'name': 'M. Bulut'}, {'authorId': '2118656349', 'name': 'C. Lee'}, {'authorId': '1764265', 'name': 'Ebrahim (Abe) Kazemzadeh'}, {'authorId': '2108057415', 'name': 'Sungbok Lee'}, {'authorId': '143840663', 'name': 'U. Neumann'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
80,06980c9e81382b0b479358f1423a9553c22c1dd2,Regions of the MPFC differentially tuned to social and nonsocial affective evaluation,,2007.0,56.0,92.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/CABN.7.4.309.pdf', 'status': None}","{'volume': '7', 'pages': '309-316', 'name': 'Cognitive, Affective, & Behavioral Neuroscience'}","{'bibtex': '@Article{Harris2007RegionsOT,\n author = {L. Harris and Samuel M. McClure and W. Bos and J. Cohen and S. Fiske},\n journal = {Cognitive, Affective, & Behavioral Neuroscience},\n pages = {309-316},\n title = {Regions of the MPFC differentially tuned to social and nonsocial affective evaluation},\n volume = {7},\n year = {2007}\n}\n'}","[{'authorId': '3705092', 'name': 'L. Harris'}, {'authorId': '2751811', 'name': 'Samuel M. McClure'}, {'authorId': '39861124', 'name': 'W. Bos'}, {'authorId': '153564781', 'name': 'J. Cohen'}, {'authorId': '1885803', 'name': 'S. Fiske'}]"
81,06b3c99865869eec4ba54bd29de109b3ba153529,THE GENERALIZATION OF ‘STUDENT'S’ PROBLEM WHEN SEVERAL DIFFERENT POPULATION VARLANCES ARE INVOLVED,,1947.0,7.0,4038.0,False,,"{'volume': '34', 'pages': '28-35', 'name': 'Biometrika'}","{'bibtex': ""@Article{Bl1947THEGO,\n author = {Welch Bl},\n journal = {Biometrika},\n pages = {28-35},\n title = {THE GENERALIZATION OF ‘STUDENT'S’ PROBLEM WHEN SEVERAL DIFFERENT POPULATION VARLANCES ARE INVOLVED},\n volume = {34},\n year = {1947}\n}\n""}","[{'authorId': '66536451', 'name': 'Welch Bl'}]"
82,06c60807c9e95ce47770e1caff7f592760eeb78a,The Architecture of Why2-Atlas: A Coach for Qualitative Physics Essay Writing,,2002.0,25.0,249.0,False,,{'pages': '158-167'},"{'bibtex': '@Inproceedings{VanLehn2002TheAO,\n author = {K. VanLehn and Pamela W. Jordan and C. Rosé and Dumisizwe Bhembe and Michael Böttner and A. Gaydos and Maxim Makatchev and Umarani Pappuswamy and M. Ringenberg and Antonio Roque and Stephanie Siler and Ramesh Srivastava},\n pages = {158-167},\n title = {The Architecture of Why2-Atlas: A Coach for Qualitative Physics Essay Writing},\n year = {2002}\n}\n'}","[{'authorId': '1797292', 'name': 'K. VanLehn'}, {'authorId': '1730942', 'name': 'Pamela W. Jordan'}, {'authorId': '35959897', 'name': 'C. Rosé'}, {'authorId': '2888266', 'name': 'Dumisizwe Bhembe'}, {'authorId': '34612911', 'name': 'Michael Böttner'}, {'authorId': '47728940', 'name': 'A. Gaydos'}, {'authorId': '2200378', 'name': 'Maxim Makatchev'}, {'authorId': '2590575', 'name': 'Umarani Pappuswamy'}, {'authorId': '2267026', 'name': 'M. Ringenberg'}, {'authorId': '145753983', 'name': 'Antonio Roque'}, {'authorId': '2508756', 'name': 'Stephanie Siler'}, {'authorId': '2066943347', 'name': 'Ramesh Srivastava'}]"
83,06d754c74be430f56646055fbe5e6646777a9dd9,Tag Interactions in MultiAgent Systems: Environment Support,"Tag interactions are agent interactions that complement and differ from speech act communication models. Tags are public information that agents expose to others in the system to allow two types of interactions. Tag monitoring interactions let agents observe the tags of others actively. Tag fortuitous interactions make agents realize the tag of others with unrequested and application-dependent messages. In this paper we model tag interactions based on the agent environment and computational bodies to enact, maintain, and regulate their execution. We discuss the model and we identify further issues in the current state of the research. An example application is described in detail to show the potential of introducing tag interactions.",2006.0,29.0,23.0,False,,{'pages': '270-281'},"{'bibtex': '@Inproceedings{Platon2006TagII,\n author = {E. Platon and N. Sabouret and S. Honiden},\n pages = {270-281},\n title = {Tag Interactions in MultiAgent Systems: Environment Support},\n year = {2006}\n}\n'}","[{'authorId': '145697442', 'name': 'E. Platon'}, {'authorId': '1731432', 'name': 'N. Sabouret'}, {'authorId': '1720917', 'name': 'S. Honiden'}]"
84,06ee8b438d144c5db1f722f5143ecaaef63bcd46,"The positive and negative affect schedule (PANAS): construct validity, measurement properties and normative data in a large non-clinical sample.","OBJECTIVES
To evaluate the reliability and validity of the PANAS (Watson, Clark, & Tellegen, 1988b) and provide normative data.


DESIGN
Cross-sectional and correlational.


METHOD
The PANAS was administered to a non-clinical sample, broadly representative of the general adult UK population (N = 1,003). Competing models of the latent structure of the PANAS were evaluated using confirmatory factor analysis. Regression and correlational analysis were used to determine the influence of demographic variables on PANAS scores as well as the relationship between the PANAS with measures of depression and anxiety (the HADS and the DASS).


RESULTS
The best-fitting model (robust comparative fit index = .94) of the latent structure of the PANAS consisted of two correlated factors corresponding to the PA and NA scales, and permitted correlated error between items drawn from the same mood subcategories (Zevon & Tellegen, 1982). Demographic variables had only very modest influences on PANAS scores and the PANAS exhibited measurement invariance across demographic subgroups. The reliability of the PANAS was high, and the pattern of relationships between the PANAS and the DASS and HADS were consistent with tripartite theory.


CONCLUSION
The PANAS is a reliable and valid measure of the constructs it was intended to assess, although the hypothesis of complete independence between PA and NA must be rejected. The utility of this measure is enhanced by the provision of large-scale normative data.",2004.0,49.0,2608.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1348/0144665031752934', 'status': None}","{'volume': '43 Pt 3', 'pages': '\n          245-65\n        ', 'name': 'The British journal of clinical psychology'}","{'bibtex': '@Article{Crawford2004ThePA,\n author = {J. Crawford and J. Henry},\n journal = {The British journal of clinical psychology},\n pages = {\n          245-65\n        },\n title = {The positive and negative affect schedule (PANAS): construct validity, measurement properties and normative data in a large non-clinical sample.},\n volume = {43 Pt 3},\n year = {2004}\n}\n'}","[{'authorId': '144723673', 'name': 'J. Crawford'}, {'authorId': '2149900272', 'name': 'J. Henry'}]"
85,07052d964fb858cf4b982100a4c7d8b00add3efc,Examining the impact of emotion and agency on negotiator behavior,"Virtual human expressions can shape user behavior [1, 2, 3], yet in negotiation, findings have been underwhelming. For example, human negotiators can use anger to claim value (i.e., extract concessions) [4], but anger has no effect when exhibited by a virtual human [5]. Other psychological work suggests that emotions can create value (e.g., happy negotiators can better discover tradeoffs across issues that ""grow the pie""), but little research has examined how virtual human expressions shape value creation. Here we present an agent architecture and pilot study that examines differences between how the emotional expressions of human and virtual-human opponents shape value claiming and value creation. We replicate the finding that virtual human anger fails to influence value claiming but discover counter-intuitive findings on value creation. We argue these findings highlight the potential for intelligent virtual humans to yield insight into human psychology.",2022.0,10.0,0.0,False,,{'name': 'Proceedings of the 22nd ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Lee2022ExaminingTI,\n author = {Eugene Lee and Zachary McNulty and Alex Gentle and Prerak Tusharkumar Pradhan and J. Gratch},\n booktitle = {International Conference on Intelligent Virtual Agents},\n journal = {Proceedings of the 22nd ACM International Conference on Intelligent Virtual Agents},\n title = {Examining the impact of emotion and agency on negotiator behavior},\n year = {2022}\n}\n'}","[{'authorId': '2149209253', 'name': 'Eugene Lee'}, {'authorId': '2132855226', 'name': 'Zachary McNulty'}, {'authorId': '2183389468', 'name': 'Alex Gentle'}, {'authorId': '2183390749', 'name': 'Prerak Tusharkumar Pradhan'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
86,073973452ca9198831f0be1be0b8398005c13e7d,Optimal and efficient path planning for partially-known environments,"The task of planning trajectories for a mobile robot has received considerable attention in the research literature. Most of the work assumes the robot has a complete and accurate model of its environment before it begins to move; less attention has been paid to the problem of partially known environments. This situation occurs for an exploratory robot or one that must move to a goal location without the benefit of a floorplan or terrain map. Existing approaches plan an initial path based on known information and then modify the plan locally or replan the entire path as the robot discovers obstacles with its sensors, sacrificing optimality or computational efficiency respectively. This paper introduces a new algorithm, D*, capable of planning paths in unknown, partially known, and changing environments in an efficient, optimal, and complete manner.<<ETX>>",1994.0,14.0,1597.0,False,,"{'pages': '3310-3317 vol.4', 'name': 'Proceedings of the 1994 IEEE International Conference on Robotics and Automation'}","{'bibtex': '@Article{Stentz1994OptimalAE,\n author = {A. Stentz},\n journal = {Proceedings of the 1994 IEEE International Conference on Robotics and Automation},\n pages = {3310-3317 vol.4},\n title = {Optimal and efficient path planning for partially-known environments},\n year = {1994}\n}\n'}","[{'authorId': '1722938', 'name': 'A. Stentz'}]"
87,07496ef7c5f66957b9951e78d5e27009e89c101d,Social touch: stimuli-imitation protocol and automated recognition,"Touch plays an important role in socio-emotional communication: a loving hug from a spouse, a comforting tap on the back by friend, a push from a stranger convey efficiently an emotion or an intent, specially when combined with other modalities such as audition and vision. In a parent-child relationship, the frequency of maternal touch is positively correlated to the a child early social development. In addition, Touch occurs frequently in patient care situation: a massage therapy, for instance, reduces chronic pain and alleviates anxiety when properly applied by a nurse. Underexplored by the human-machine-interaction and the affective computing literature, the purpose of this thesis is to integrate the sense of touch into interactive systems. In this paper we introduce a novel data collection framework for social touch and present the social touch recognition pipeline.",2019.0,34.0,1.0,False,,"{'pages': '11-15', 'name': '2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)'}","{'bibtex': '@Article{Elbani2019SocialTS,\n author = {Wail Elbani},\n journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)},\n pages = {11-15},\n title = {Social touch: stimuli-imitation protocol and automated recognition},\n year = {2019}\n}\n'}","[{'authorId': '1455993465', 'name': 'Wail Elbani'}]"
88,074e8a7bece079f6c8b4110273f3de1614f5075d,A knowledge infused context driven dialogue agent for disease diagnosis using hierarchical reinforcement learning,,2022.0,16.0,16.0,False,,"{'volume': '242', 'pages': '108292', 'name': 'Knowl. Based Syst.'}","{'bibtex': '@Article{Tiwari2022AKI,\n author = {Abhisek Tiwari and S. Saha and P. Bhattacharyya},\n journal = {Knowl. Based Syst.},\n pages = {108292},\n title = {A knowledge infused context driven dialogue agent for disease diagnosis using hierarchical reinforcement learning},\n volume = {242},\n year = {2022}\n}\n'}","[{'authorId': '2063522518', 'name': 'Abhisek Tiwari'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
89,0768149ce1170691bcde8b4539153a282f0cc74c,Does Gamification Work? -- A Literature Review of Empirical Studies on Gamification,"This paper reviews peer-reviewed empirical studies on gamification. We create a framework for examining the effects of gamification by drawing from the definitions of gamification and the discussion on motivational affordances. The literature review covers results, independent variables (examined motivational affordances), dependent variables (examined psychological/behavioral outcomes from gamification), the contexts of gamification, and types of studies performed on the gamified systems. The paper examines the state of current research on the topic and points out gaps in existing literature. The review indicates that gamification provides positive effects, however, the effects are greatly dependent on the context in which the gamification is being implemented, as well as on the users using it. The findings of the review provide insight for further studies as well as for the design of gamified systems.",2014.0,48.0,3263.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6751593/6758592/06758978.pdf', 'status': None}","{'pages': '3025-3034', 'name': '2014 47th Hawaii International Conference on System Sciences'}","{'bibtex': '@Article{Hamari2014DoesGW,\n author = {Juho Hamari and Jonna Koivisto and Harri Sarsa},\n journal = {2014 47th Hawaii International Conference on System Sciences},\n pages = {3025-3034},\n title = {Does Gamification Work? -- A Literature Review of Empirical Studies on Gamification},\n year = {2014}\n}\n'}","[{'authorId': '2095817', 'name': 'Juho Hamari'}, {'authorId': '2791914', 'name': 'Jonna Koivisto'}, {'authorId': '3054816', 'name': 'Harri Sarsa'}]"
90,077ceadb36ffee8bca90a1980742538721784c7c,How reward modulates mimicry: EMG evidence of greater facial mimicry of more rewarding happy faces.,"Spontaneous mimicry is a marker of empathy. Conditions characterized by reduced spontaneous mimicry (e.g., autism) also display deficits in sensitivity to social rewards. We tested if spontaneous mimicry of socially rewarding stimuli (happy faces) depends on the reward value of stimuli in 32 typical participants. An evaluative conditioning paradigm was used to associate different reward values with neutral target faces. Subsequently, electromyographic activity over the Zygomaticus Major was measured whilst participants watched video clips of the faces making happy expressions. Higher Zygomaticus Major activity was found in response to happy faces conditioned with high reward versus low reward. Moreover, autistic traits in the general population modulated the extent of spontaneous mimicry of happy faces. This suggests a link between reward and spontaneous mimicry and provides a possible underlying mechanism for the reduced response to social rewards seen in autism.",2012.0,62.0,81.0,False,,"{'volume': '49 7', 'pages': '\n          998-1004\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Sims2012HowRM,\n author = {Thomas B. Sims and C. V. van Reekum and T. Johnstone and B. Chakrabarti},\n journal = {Psychophysiology},\n pages = {\n          998-1004\n        },\n title = {How reward modulates mimicry: EMG evidence of greater facial mimicry of more rewarding happy faces.},\n volume = {49 7},\n year = {2012}\n}\n'}","[{'authorId': '2786578', 'name': 'Thomas B. Sims'}, {'authorId': '79538426', 'name': 'C. V. van Reekum'}, {'authorId': '30361732', 'name': 'T. Johnstone'}, {'authorId': '3102450', 'name': 'B. Chakrabarti'}]"
91,077f8329a7b6fa3b7c877a57b81eb6c18b5f87de,RoBERTa: A Robustly Optimized BERT Pretraining Approach,"Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.",2019.0,68.0,15886.0,False,,"{'volume': 'abs/1907.11692', 'name': 'ArXiv'}","{'bibtex': '@Article{Liu2019RoBERTaAR,\n author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n journal = {ArXiv},\n title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n volume = {abs/1907.11692},\n year = {2019}\n}\n'}","[{'authorId': '11323179', 'name': 'Yinhan Liu'}, {'authorId': '40511414', 'name': 'Myle Ott'}, {'authorId': '39589154', 'name': 'Naman Goyal'}, {'authorId': '3048577', 'name': 'Jingfei Du'}, {'authorId': '144863691', 'name': 'Mandar Joshi'}, {'authorId': '50536468', 'name': 'Danqi Chen'}, {'authorId': '39455775', 'name': 'Omer Levy'}, {'authorId': '35084211', 'name': 'M. Lewis'}, {'authorId': '1982950', 'name': 'Luke Zettlemoyer'}, {'authorId': '1759422', 'name': 'Veselin Stoyanov'}]"
92,078316fb9d89b243b04e5497bd2ce36d1ddb567c,Drum-mate: interaction dynamics and gestures in human–humanoid drumming experiments,"This article investigates the role of interaction kinesics in human–robot interaction (HRI). We adopted a bottom-up, synthetic approach towards interactive competencies in robots using simple, minimal computational models underlying the robot's interaction dynamics. We present two empirical, exploratory studies investigating a drumming experience with a humanoid robot (KASPAR) and a human. In the first experiment, the turn-taking behaviour of the humanoid is deterministic and the non-verbal gestures of the robot accompany its drumming to assess the impact of non-verbal gestures on the interaction. The second experiment studies a computational framework that facilitates emergent turn-taking dynamics, whereby the particular dynamics of turn-taking emerge from the social interaction between the human and the humanoid. The results from the HRI experiments are presented and analysed qualitatively (in terms of the participants’ subjective experiences) and quantitatively (concerning the drumming performance of the human–robot pair). The results point out a trade-off between the subjective evaluation of the drumming experience from the perspective of the participants and the objective evaluation of the drumming performance. A certain number of gestures was preferred as a motivational factor in the interaction. The participants preferred the models underlying the robot's turn-taking which enable the robot and human to interact more and provide turn-taking closer to ‘natural’ human–human conversations, despite differences in objective measures of drumming behaviour. The results are consistent with the temporal behaviour matching hypothesis previously proposed in the literature which concerns the effect that the participants adapt their own interaction dynamics to the robot's.",2010.0,78.0,40.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/09540090903383189?needAccess=true&role=button', 'status': None}","{'volume': '22', 'pages': '103 - 134', 'name': 'Connection Science'}","{'bibtex': '@Article{Kose-Bagci2010DrummateID,\n author = {H. Kose-Bagci and K. Dautenhahn and D. Syrdal and Chrystopher L. Nehaniv},\n journal = {Connection Science},\n pages = {103 - 134},\n title = {Drum-mate: interaction dynamics and gestures in human–humanoid drumming experiments},\n volume = {22},\n year = {2010}\n}\n'}","[{'authorId': '1399283111', 'name': 'H. Kose-Bagci'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '1700812', 'name': 'D. Syrdal'}, {'authorId': '1718528', 'name': 'Chrystopher L. Nehaniv'}]"
93,078765aee88112d417c355b2887b23538da468cd,Expression of Emotion in Virtual Crowds:Investigating Emotion Contagion and Perception of Emotional Behaviour in Crowd Simulation,"Emotional behaviour in the context of crowd simulationis a topic that is gaining particular interest in the area of artificial intelligence. Recent efforts in this domain havelooked for the modelling of emotional emergence and socialinteraction inside a crowd of virtual agents, but further investigation is still needed in aspects such as simulation of emotional awareness and emotion contagion. Also, in relation to perception of emotions, many questions remain about perception of emotional behaviour in the context of virtual crowds.This thesis investigates the current state-of-the-art of emotional characters in virtual crowds and presents the implementation of a computational model able to generate expressive full-body motion behaviour and emotion contagion in a crowd of virtual agents. Also, as a second part of the thesis, this project presents a perceptual study in which the perception of emotional behaviour is investigated in the context of virtual crowds. The results of this thesis reveal some interesting findings in relation to the perception and modelling of virtual crowds, including some relevant effectsin relation to the influence of emotional crowd behaviourin viewers, specially when virtual crowds are not the mainfocus of a particular scene. These results aim to contribute for the further development of this interdisciplinary area of computer graphics, artificial intelligence and psychology.",2014.0,42.0,3.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Carretero2014ExpressionOE,\n author = {M. R. Carretero},\n title = {Expression of Emotion in Virtual Crowds:Investigating Emotion Contagion and Perception of Emotional Behaviour in Crowd Simulation},\n year = {2014}\n}\n'}","[{'authorId': '38188266', 'name': 'M. R. Carretero'}]"
94,078c02fd5dac303021884c378dc766edb49e8583,Strategies for Using Repetition as a Powerful Teaching Tool,"Brain research indicates that repetition is of vital importance in the learning process. Repetition is an especially useful tool in the area of music education. The success of repetition can be enhanced by accurate and timely feedback. From “simple repetition” to “repetition with the addition or subtraction of degrees of freedom,” there are many forms of repetition that can be successfully adapted to music education. Descriptions of each form of repetition are provided, along with accompanying rehearsal strategies that can be implemented in the classroom. Music teachers can avoid the pitfalls of boredom and mindless repetition by constantly shifting teaching strategies and including new goals and framing techniques. Using these strategies wisely, music educators can provide meaningful, refreshed, and powerful teaching and learning opportunities for both themselves and their students.",2011.0,0.0,28.0,False,,"{'volume': '98', 'pages': '69 - 75', 'name': 'Music Educators Journal'}","{'bibtex': '@Article{Saville2011StrategiesFU,\n author = {Kirt Saville},\n journal = {Music Educators Journal},\n pages = {69 - 75},\n title = {Strategies for Using Repetition as a Powerful Teaching Tool},\n volume = {98},\n year = {2011}\n}\n'}","[{'authorId': '1453347563', 'name': 'Kirt Saville'}]"
95,07989cb0093eeaa0185eea50ac49a9dac8bda820,"Pedagogical Agent Design: The Impact of Agent Realism, Gender, Ethnicity, and Instructional Role",,2004.0,48.0,240.0,False,,{'pages': '592-603'},"{'bibtex': '@Inproceedings{Baylor2004PedagogicalAD,\n author = {A. L. Baylor and Yanghee Kim},\n pages = {592-603},\n title = {Pedagogical Agent Design: The Impact of Agent Realism, Gender, Ethnicity, and Instructional Role},\n year = {2004}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '32964910', 'name': 'Yanghee Kim'}]"
96,07a525836aab4ee18708b2a029e95a9b83e1ec7e,From the Selectedworks of Marcel Adam Just the Organization of Thinking: What Functional Brain Imaging Reveals about the Neuroarchitecture of Complex Cognition,,,122.0,193.0,False,,,"{'bibtex': '@Misc{None,\n author = {M. Just},\n title = {From the Selectedworks of Marcel Adam Just the Organization of Thinking: What Functional Brain Imaging Reveals about the Neuroarchitecture of Complex Cognition}\n}\n'}","[{'authorId': '2065109', 'name': 'M. Just'}]"
97,07c4dab8f604cf56172ed931c329c56aa07f15e5,Cumulative Development of Attentional Theory.,"This article describes current work in selective attention within a framework derived from important findings extending back over a century. The contributions of Danders, Helmholtz, Pavlov, Sokolov, and Wundt, for example, are deeply embedded in current methods for studying selectivity. The cumulative nature of work on attention is not widely appreciated, in part because of a failure to recognize that the methods used in current studies arose in empirical findings of the past and also because attention is a concept that can be studied at many levels. There is evidence that findings at the level of performance, subjective experience, and neural systems can be linked, even though they are not yet reducible to a single theory. Studies to date reveal some properties of a complex neural mechanism involved in our awareness of a stimulus. The time course of operation of this mechanism can be studied objectively and shown to be related both to changes in performance and to subjective experience. This attentional mechanism is involved in the skilled performance of daily life, but many other systems are also important in determining the degree to which natural tasks can be time shared. The goal of every science is a cumulative development of its theoretical structure so that a larger part of its subject matter is explicable in terms of simpler principles. This traditional view of science has been challenged in psychology from many sources. One argument has been that it is better to view psychology in terms of shifting paradigms (Kuhn, 1962). It often seems to be accepted, almost as a matter of course, that in psychology no cumulative development will take place. A different challenge to the view of psychology as a cumulative science is the notion that nothing new is discovered while the views of Helmholtz, Wundt, or some other elder of the field are being reworked, with no apparent gain in either insight or scope. These two challenges to the cumulative nature of psychological theory are persuasive, but they are hot consistent. If we shift from paradigm to paradigm, it seems puzzling that the current paradigm would so exactly mirror that of 100 years ago. On the other hand, if the solutions of 100 years ago remain, what has happened to paradigm shifts? Another criticism that has been applied to the 168 • FEBRUARY 1982 • AMERICAN PSYCHOLOGIST study of attention is that psychological theories are sterile, in that they do not illuminate important natural behavior or provide a perspective on the nature of mind (Neisser, 1976). The contention in this article is that one can see emerging from psychological research in the area of attention a cumulative development of theoretical concepts that rely on principles, some over 100 years old, that are now elaborated in ways that were essentially unavailable to earlier researchers. Moreover, taken as a whole these ideas do provide insight into the skills of daily life. If this contention is correct, why is it that the cumulative development of psychological theories of attention arfe so obscure, even to/ researchers in the field? I believe that several facts about the nature of psychological inquiry make its cumulative development obscure even to those who read the psychological literature. The first difficulty in perceiving the cumulative nature of theories arises because much work in psychology is fueled by tests between complex theoretical views that differ in only subtle ways. These theories often have common assumptions, but similarities between them that amount to a common core of agreed principles are overlooked. The view of experiments as tests among competing, wellspecified theories can be contrasted with the more cumulative theoretical approach outlined by Broadbent (1958): The proper road for progress then is to set up theories which are not at first detailed, although they must be capable of disproof. As research advances the theory will become continually more detailed, until one reaches the stage at which further advance is made by giving exact values to constants previously left unspecified in equaThis article was presented as a Distinguished Scientific Contribution Award address at the meeting of the' American Psychological Association, Los Angeles, September 1981. This work was supported by a series of National Science Foundation grants to the University of Oregon. I am most grateful to the many students and colleagues who have contributed to this work, and to Mary R'othbart for assistance in writing it. Requests for reprints should be sent to Michael I. Posner, Department of Psychology, University of Oregon, Eugene, Or-",1982.0,54.0,328.0,True,"{'url': 'http://www.uk.sagepub.com/upm-data/28033_Chap02.pdf', 'status': None}","{'volume': '37', 'pages': '168-179', 'name': 'American Psychologist'}","{'bibtex': '@Article{Posner1982CumulativeDO,\n author = {M. Posner},\n journal = {American Psychologist},\n pages = {168-179},\n title = {Cumulative Development of Attentional Theory.},\n volume = {37},\n year = {1982}\n}\n'}","[{'authorId': '2262729', 'name': 'M. Posner'}]"
98,07cc4371c8d3ddf7de0189f73227c3f0d896d66d,Potential field methods and their inherent limitations for mobile robot navigation,"Based on a rigorous mathematical analysis, the authors present a systematic overview and a critical discussion of the inherent problems of potential field methods (PFMs). The authors previously (1989) developed a PFM called the virtual force field (VFF) method. Much insight has been gained into the strengths and weaknesses of this method. Four distinct drawbacks with PFMs are identified. Because of these drawbacks, the authors abandoned potential field methods and developed a new method for fast obstacle avoidance. This method, called the vector field histogram method, produces smooth, nonoscillatory motion, while sampling time and hardware are identical to those used in the VFF method.<<ETX>>",1991.0,12.0,1754.0,False,,"{'pages': '1398-1404 vol.2', 'name': 'Proceedings. 1991 IEEE International Conference on Robotics and Automation'}","{'bibtex': '@Article{Koren1991PotentialFM,\n author = {Y. Koren and J. Borenstein},\n journal = {Proceedings. 1991 IEEE International Conference on Robotics and Automation},\n pages = {1398-1404 vol.2},\n title = {Potential field methods and their inherent limitations for mobile robot navigation},\n year = {1991}\n}\n'}","[{'authorId': '1687718', 'name': 'Y. Koren'}, {'authorId': '34767446', 'name': 'J. Borenstein'}]"
99,07ccd119ff7ace675f1f9075708f32a634d542a5,How gestures can become like words,,1988.0,0.0,312.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Kendon1988HowGC,\n author = {A. Kendon},\n title = {How gestures can become like words},\n year = {1988}\n}\n'}","[{'authorId': '47985333', 'name': 'A. Kendon'}]"
100,07f2fdd1851146dcd954d643703b6adce3882692,Could a virtual agent be warm and competent? investigating user's impressions of agent's non-verbal behaviours,"In this abstract we introduce the design of an experiment aimed at investigating how users' impressions of an embodied conversational agent are influenced by agent's non-verbal behaviour. We focus on impressions of warmth and competence, the two fundamental dimensions of social perception. Agent's gestures, arms rest poses and smile frequency are manipulated, as well as users' expectations about agent's competence. We hypothesize that user's judgments will differ according to his expectations, by following the Expectancy Violation Theory proposed by Burgoon and colleagues. We also hypothesize to replicate the results found in our previous study concerning human-human interaction, for example high frequency of smiles will elicit higher warmth and lower competence impressions compared to low frequency of smiles, while arms crossed will elicit low competence and low warmth impressions.",2017.0,16.0,10.0,False,,{'name': 'Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents'},"{'bibtex': ""@Article{Biancardi2017CouldAV,\n author = {Béatrice Biancardi and Angelo Cafaro and C. Pelachaud},\n journal = {Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents},\n title = {Could a virtual agent be warm and competent? investigating user's impressions of agent's non-verbal behaviours},\n year = {2017}\n}\n""}","[{'authorId': '23567239', 'name': 'Béatrice Biancardi'}, {'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
101,07fd19b3b9aa930f0a85776d9e1b94b37f7fc318,"For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1988","This program of experiments examined heart rate responses to mental arithmetic and a video game. Attention first focused on their metabolic relevance. Comparison with heart rate/oxygen consumption regression equations generated from isotonic exercise data revealed that the heart rate increases of certain individuals were considerably in excess of those necessitated by contemporary metabolic demand. Both temporal and intertask consistency of reaction were explored, and supportive evidence was obtained. The relationship between laboratory and real-world reactions was investigated, and preliminary evidence found suggesting that in-laboratory responses are indicative of responses to more naturalistic stressors. Finally, twin studies examining the genetic and environmental determinants of individual differences in heart rate change during the tasks revealed a substantial genetic component for these responses.",1989.0,39.0,49.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1469-8986.1989.tb00701.x', 'status': None}","{'volume': '26', 'pages': '497-505', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Turner1989ForDE,\n author = {J. Turner},\n journal = {Psychophysiology},\n pages = {497-505},\n title = {For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1988},\n volume = {26},\n year = {1989}\n}\n'}","[{'authorId': '2151553', 'name': 'J. Turner'}]"
102,083c93ebe25b84745ad6fbf6685581f4d70e6eee,"""Artificial humans"": Psychology and neuroscience perspectives on embodiment and nonverbal communication",,2010.0,238.0,66.0,False,,"{'volume': '23 8-9', 'pages': '\n          1077-90\n        ', 'name': 'Neural networks : the official journal of the International Neural Network Society'}","{'bibtex': '@Article{Vogeley2010ArtificialHP,\n author = {K. Vogeley and G. Bente},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          1077-90\n        },\n title = {""Artificial humans"": Psychology and neuroscience perspectives on embodiment and nonverbal communication},\n volume = {23 8-9},\n year = {2010}\n}\n'}","[{'authorId': '2051580', 'name': 'K. Vogeley'}, {'authorId': '2487649', 'name': 'G. Bente'}]"
103,086d2543f4aa74266542db3266d253e91a16b932,Dynamic 3D avatar creation from hand-held video input,"We present a complete pipeline for creating fully rigged, personalized 3D facial avatars from hand-held video. Our system faithfully recovers facial expression dynamics of the user by adapting a blendshape template to an image sequence of recorded expressions using an optimization that integrates feature tracking, optical flow, and shape from shading. Fine-scale details such as wrinkles are captured separately in normal maps and ambient occlusion maps. From this user- and expression-specific data, we learn a regressor for on-the-fly detail synthesis during animation to enhance the perceptual realism of the avatars. Our system demonstrates that the use of appropriate reconstruction priors yields compelling face rigs even with a minimalistic acquisition system and limited user assistance. This facilitates a range of new applications in computer animation and consumer-level online communication based on personalized avatars. We present realtime application demos to validate our method.",2015.0,61.0,231.0,True,"{'url': 'https://infoscience.epfl.ch/record/210237/files/avatars_sg2015_paper.pdf', 'status': None}","{'volume': '34', 'pages': '1 - 14', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Ichim2015Dynamic3A,\n author = {A. Ichim and Sofien Bouaziz and M. Pauly},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 14},\n title = {Dynamic 3D avatar creation from hand-held video input},\n volume = {34},\n year = {2015}\n}\n'}","[{'authorId': '1906981', 'name': 'A. Ichim'}, {'authorId': '35119991', 'name': 'Sofien Bouaziz'}, {'authorId': '143674021', 'name': 'M. Pauly'}]"
104,086ef3944e7ca805d9f8bf8af7f4b66e43495c0c,Face processing in children with autism,"Recent eye tracking studies of face processing have produced differing accounts of how and whether children with autism differ from their typically developing peers. The two groups' gaze patterns appear to differ for dynamic videos of social scenes, but not for static photos of isolated individuals. The present study replicated and extended previous research by comparing the gaze patterns of individuals with and without autism for four types of stimuli: social dynamic, social static, isolated dynamic, and isolated static. Participants with autism differed from their typically developing peers only for social-dynamic stimuli; fixation durations were decreased for eye regions and increased for body regions. Further, these fixation durations predicted scores on a measure of social responsiveness. These findings reconcile differences in previous reports by identifying the specific social and dynamic task components associated with autism-related face processing impairments.",2007.0,23.0,344.0,False,,"{'volume': '11', 'pages': '265 - 277', 'name': 'Autism'}","{'bibtex': '@Article{Speer2007FacePI,\n author = {Leslie L. Speer and A. E. Cook and W. McMahon and E. Clark},\n journal = {Autism},\n pages = {265 - 277},\n title = {Face processing in children with autism},\n volume = {11},\n year = {2007}\n}\n'}","[{'authorId': '33434026', 'name': 'Leslie L. Speer'}, {'authorId': '2622551', 'name': 'A. E. Cook'}, {'authorId': '2241753', 'name': 'W. McMahon'}, {'authorId': '2072399105', 'name': 'E. Clark'}]"
105,0897c6b842ecd5e511b434407c35ff32724a9978,Integrating pedagogical capabilities in a virtual environment agent,"Virtual environments are a promising milieu for education and training, because they allow students to practice their skills in 3D simulations of work settings. Autonomous agents can improve the eeectiveness of such e n vironments by assisting and collaborating with students as appropriate. This paper describes an autonomous pedagogical agent called Steve that can support the training of procedural skills such as operating or repairing complex equipment. Steve's architecture permits him to sense and manipulate dynamic virtual worlds. The architecture also enables Steve to assume alternative realizations, either as a full, articulated, human gure or as abstract pointers and disembodied hands. Steve employs a combination of intelligent capabilities in his interactions with students and the environment: plan revision and execution, explanation, and student monitoring. These capabilities are employed in multiple ways in order to support alternative pedagogical styles. Steve's knowledge representation is designed so that agent capabilities can be authored without detailed knowledge of agent architectures and languages.",1997.0,26.0,163.0,False,,{'pages': '30-38'},"{'bibtex': '@Inproceedings{None,\n pages = {30-38},\n title = {Integrating pedagogical capabilities in a virtual environment agent},\n year = {1997}\n}\n'}",[]
106,08a005912a72800e4cc632be3d2e559547f48ac2,An End-to-End Conversational Style Matching Agent,"We present an end-to-end voice-based conversational agent that is able to engage in naturalistic multi-turn dialogue and align with the interlocutor's conversational style. The system uses a series of deep neural network components for speech recognition, dialogue generation, prosodic analysis and speech synthesis to generate language and prosodic expression with qualities that match those of the user. We conducted a user study (N=30) in which participants talked with the agent for 15 to 20 minutes, resulting in over 8 hours of natural interaction data. Users with high consideration conversational styles reported the agent to be more trustworthy when it matched their conversational style. Whereas, users with high involvement conversational styles were indifferent. Finally, we provide design guidelines for multi-turn dialogue interactions using conversational style adaptation.",2019.0,43.0,46.0,True,"{'url': 'https://arxiv.org/pdf/1904.02760', 'status': None}",{'name': 'Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Hoegen2019AnEC,\n author = {Rens Hoegen and Deepali Aneja and Daniel J. McDuff and M. Czerwinski},\n journal = {Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents},\n title = {An End-to-End Conversational Style Matching Agent},\n year = {2019}\n}\n'}","[{'authorId': '2065815350', 'name': 'Rens Hoegen'}, {'authorId': '2494850', 'name': 'Deepali Aneja'}, {'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '1817251', 'name': 'M. Czerwinski'}]"
107,0908779b9ec4233739a5297e56b36f91896e7d04,The Effectiveness of Social Stories on Decreasing Disruptive Behaviors of Children with Autism: Three Case Studies,,2008.0,26.0,67.0,False,,"{'volume': '38', 'pages': '1689-1696', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Ozdemir2008TheEO,\n author = {Selda Ozdemir},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {1689-1696},\n title = {The Effectiveness of Social Stories on Decreasing Disruptive Behaviors of Children with Autism: Three Case Studies},\n volume = {38},\n year = {2008}\n}\n'}","[{'authorId': '4506321', 'name': 'Selda Ozdemir'}]"
108,090eb1e0e972a0b13f1a50eb9ee62d90379a4e44,Emotion Recognition using Multimodal Residual LSTM Network,"Various studies have shown that the temporal information captured by conventional long-short-term memory (LSTM) networks is very useful for enhancing multimodal emotion recognition using encephalography (EEG) and other physiological signals. However, the dependency among multiple modalities and high-level temporal-feature learning using deeper LSTM networks is yet to be investigated. Thus, we propose a multimodal residual LSTM (MMResLSTM) network for emotion recognition. The MMResLSTM network shares the weights across the modalities in each LSTM layer to learn the correlation between the EEG and other physiological signals. It contains both the spatial shortcut paths provided by the residual network and temporal shortcut paths provided by LSTM for efficiently learning emotion-related high-level features. The proposed network was evaluated using a publicly available dataset for EEG-based emotion recognition, DEAP. The experimental results indicate that the proposed MMResLSTM network yielded a promising result, with a classification accuracy of 92.87% for arousal and 92.30% for valence.",2019.0,39.0,105.0,False,,{'name': 'Proceedings of the 27th ACM International Conference on Multimedia'},"{'bibtex': '@Article{Ma2019EmotionRU,\n author = {Jia-Xin Ma and Hao Tang and Wei-Long Zheng and Bao-Liang Lu},\n journal = {Proceedings of the 27th ACM International Conference on Multimedia},\n title = {Emotion Recognition using Multimodal Residual LSTM Network},\n year = {2019}\n}\n'}","[{'authorId': '2913745', 'name': 'Jia-Xin Ma'}, {'authorId': '2109238481', 'name': 'Hao Tang'}, {'authorId': '3108302', 'name': 'Wei-Long Zheng'}, {'authorId': '1715839', 'name': 'Bao-Liang Lu'}]"
109,091b8067d4955f820caebe8f51a5559c5e94699b,CapsuleNet for Micro-Expression Recognition,"Facial micro-expression recognition has attracted researchers in terms of its objectiveness to reveal the true emotion of a person. However, the limited number of publicly available datasets on micro-expression and its low intensity of facial movements have posed a great challenge to training robust data-driven models for recognition task. In 2019, Facial Micro-Expression Grand Challenge combines three popular datasets, i.e. SMIC, CASME II, and SAMM into a single cross-database which requires the generalization of proposed method on a wider range of subject characteristics. In this paper, we propose a simple yet effective CapsuleNet for micro-expression recognition. The effectiveness of our proposed methods was evaluated on the cross-database micro-expression benchmark using the Leave-One-Object-Out cross-validation. The experiments show that our method achieved superiorly higher results than the baseline method (LBP-TOP) provided and other state-of-the-art CNN models.",2019.0,35.0,69.0,False,,"{'pages': '1-7', 'name': '2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)'}","{'bibtex': '@Article{Quang2019CapsuleNetFM,\n author = {N. Quang and Jinhee Chun and T. Tokuyama},\n journal = {2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)},\n pages = {1-7},\n title = {CapsuleNet for Micro-Expression Recognition},\n year = {2019}\n}\n'}","[{'authorId': '1934712', 'name': 'N. Quang'}, {'authorId': '4085936', 'name': 'Jinhee Chun'}, {'authorId': '34901251', 'name': 'T. Tokuyama'}]"
110,092bdb6b5e61a81465c2413733efa0dec8f8908c,Virtual Humans in the Mission Rehearsal Exercise System,"How can simulation be made more compelling and effective as a tool for learning? This is the question thatthe Institute for Creative Technologies (ICT) set out to answer when it was formed at the University ofSouthern California in 1999, to serve as a nexus between the simulation and entertainment communities.The ultimate goal of the ICT is to create the Experience Learning System (ELS), which will advance thestate of the art in virtual reality immersion through use of high-resolution graphics, immersive audio,virtual humans and story-based scenarios. Once fully realized, ELS will make it possible for participants toenter places in time and space where they can interact with believable characters capable of conversationand action, and where they can observe and participate in events that are accessible only throughsimulation.",2003.0,41.0,155.0,False,,"{'volume': '17', 'pages': '5-', 'name': 'Künstliche Intell.'}","{'bibtex': '@Article{Hill2003VirtualHI,\n author = {R. Hill and J. Gratch and S. Marsella and J. Rickel and W. Swartout and D. Traum},\n journal = {Künstliche Intell.},\n pages = {5-},\n title = {Virtual Humans in the Mission Rehearsal Exercise System},\n volume = {17},\n year = {2003}\n}\n'}","[{'authorId': '1812270', 'name': 'R. Hill'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '1684040', 'name': 'W. Swartout'}, {'authorId': '144518646', 'name': 'D. Traum'}]"
111,093d7bdce1f2270b6e0d69ad5680fce6c5c98e2f,Facial electromyography and emotional reactions.,"The aim of this paper is to review data from my laboratory, which were collected in an attempt to determine whether the facial EMG response is a general component of the emotional reaction. In a number of studies it was found that facial reactions: first, are spontaneously elicited and differ according to the kind of emotional stimuli to which subjects are exposed; second, are sensitive to learning; third, are consistent with how the subjects perceive the stimuli and their own specific emotions; fourth, are congruent with autonomic responses; fifth, are more pronounced for females than for males; and finally, differ among subjects with specific fears. These data converge to indicate that facial muscle activity is a general component of the emotional reaction and demonstrate that the facial EMG technique is a sensitive tool for measuring emotional reactions.",1990.0,32.0,355.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1469-8986.1990.tb01962.x', 'status': None}","{'volume': '27 5', 'pages': '\n          481-94\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Dimberg1990FacialEA,\n author = {U. Dimberg},\n journal = {Psychophysiology},\n pages = {\n          481-94\n        },\n title = {Facial electromyography and emotional reactions.},\n volume = {27 5},\n year = {1990}\n}\n'}","[{'authorId': '4583182', 'name': 'U. Dimberg'}]"
112,0950e823eef8f5632bfcb3fb879d5e4b4b3ac285,Referring as a collaborative process,,1986.0,50.0,1241.0,False,,"{'volume': '22', 'pages': '1-39', 'name': 'Cognition'}","{'bibtex': '@Article{Clark1986ReferringAA,\n author = {H. H. Clark and Deanna Wilkes-Gibbs},\n journal = {Cognition},\n pages = {1-39},\n title = {Referring as a collaborative process},\n volume = {22},\n year = {1986}\n}\n'}","[{'authorId': '29224904', 'name': 'H. H. Clark'}, {'authorId': '118315489', 'name': 'Deanna Wilkes-Gibbs'}]"
113,0956a3c628959afcf870f5d7ec581160a4aa5221,LIFEisGAME Prototype: A Serious Game about Emotions for Children with Autism Spectrum Disorders,"This paper presents the LIFEisGAME prototype-Ipad version – a serious game that proposes to enhance facial and emotional recognition skills in children with Autism Spectrum Disorders (ASD). We assess the prototype game regarding motivation to play and game usability, and also participants’ emotional recognition abilities and technology usage. People with autism are less likely to gaze at faces and are also impaired in face discrimination tasks. Recently, technology plays an active role in helping these individuals to understand emotions and recognise facial expressions. LIFEisGAME prototype was played during a 15 minute game session by 11 children with ASD, with ages varying from 5-15 years old (M=9.27, SD=2.97), 91% were male and 9% were female, 82% were verbal ASD and 18% were non-verbal ASD. We video recorded each child and the footage was analysed according to game usability and motivation to play. Parents (n=11) filled out a parental consent form and a questionnaire about their child ́s technology usage and their emotional understanding. Therapists' opinions (n=8) about the game were given during an unstructured interview. The game was presented on an Ipad 4 (9.7 inches, 2048x1536). Participants enjoyed the prototype but it still needs to be simplified. All participants had experience with computer games. Fear, disgust and surprise were the most challenging emotions to recognise. Parents suggested adding musical stimuli to promote motivation and therapists recommended to include visual game instructions. Technology is a useful resource for autism and LIFEisGAME utilises technology to promote emotional understanding, bringing positive outcomes to quality of life for children with autism. Keywords: autism, emotions, prototype-game, children, Ipad Paper Received 26/06/2013; received in revised form 29/11/2013; accepted 20/12/2013. Cite as: Alves, S., Marques, A., Queirós, C. & Orvalho, V. (2013). LIFEisGAME Prototype: A Serious Game about Emotions for Children with Autism Spectrum Disorders. PsychNology Journal, 11(3), 191 – 211. Retrieved [month] [day], [year], from www.psychnology.org. Corresponding Author: Cristina Queirós Faculty of Psychology and Educational Sciences, Porto University Psychosocial Rehabilitation Laboratory. Rua Alfredo Allen, 4200-135 Porto, Portugal E-mail: cqueiros@fpce.up.pt S.	  Alves,	  A.	  Marques,	  C.	  Queirós,	  V.	  Orvalho",2013.0,53.0,48.0,False,,"{'volume': '11', 'pages': '191-211', 'name': 'PsychNology J.'}","{'bibtex': '@Article{Alves2013LIFEisGAMEPA,\n author = {Samanta Alves and A. Marques and C. Queirós and V. Orvalho},\n journal = {PsychNology J.},\n pages = {191-211},\n title = {LIFEisGAME Prototype: A Serious Game about Emotions for Children with Autism Spectrum Disorders},\n volume = {11},\n year = {2013}\n}\n'}","[{'authorId': '40423538', 'name': 'Samanta Alves'}, {'authorId': '50453251', 'name': 'A. Marques'}, {'authorId': '1897745560', 'name': 'C. Queirós'}, {'authorId': '2087332', 'name': 'V. Orvalho'}]"
115,09f1a254c78ba0fefb01a75be971340d29d2c036,Persuasive technology: using computers to change what we think and do,Mother Nature knows best--How engineered organizations of the future will resemble natural-born systems.,2002.0,139.0,4421.0,True,"{'url': 'http://dl.acm.org/ft_gateway.cfm?id=763957&type=pdf', 'status': None}","{'volume': '2002', 'pages': '5', 'name': 'Ubiquity'}","{'bibtex': '@Article{Kalbach2002PersuasiveTU,\n author = {James Kalbach},\n journal = {Ubiquity},\n pages = {5},\n title = {Persuasive technology: using computers to change what we think and do},\n volume = {2002},\n year = {2002}\n}\n'}","[{'authorId': '2263157709', 'name': 'James Kalbach'}]"
117,0a1590b4cb21c0348822808e73187280941fdb18,User Modeling in Human–Computer Interaction,,2001.0,62.0,805.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1023/A:1011145532042.pdf', 'status': None}","{'volume': '11', 'pages': '65-86', 'name': 'User Modeling and User-Adapted Interaction'}","{'bibtex': '@Article{Fischer2001UserMI,\n author = {G. Fischer},\n journal = {User Modeling and User-Adapted Interaction},\n pages = {65-86},\n title = {User Modeling in Human–Computer Interaction},\n volume = {11},\n year = {2001}\n}\n'}","[{'authorId': '144902560', 'name': 'G. Fischer'}]"
118,0a1cb36283d43b5610572043259c8f07d525cf50,On the Analysis of Fingertip Photoplethysmogram Signals,"Photoplethysmography (PPG) is used to estimate the skin blood flow using infrared light. Researchers from different domains of science have become increasingly interested in PPG because of its advantages as non-invasive, inexpensive, and convenient diagnostic tool. Traditionally, it measures the oxygen saturation, blood pressure, cardiac output, and for assessing autonomic functions. Moreover, PPG is a promising technique for early screening of various atherosclerotic pathologies and could be helpful for regular GP-assessment but a full understanding of the diagnostic value of the different features is still lacking. Recent studies emphasise the potential information embedded in the PPG waveform signal and it deserves further attention for its possible applications beyond pulse oximetry and heart-rate calculation. Therefore, this overview discusses different types of artifact added to PPG signal, characteristic features of PPG waveform, and existing indexes to evaluate for diagnoses.",2012.0,85.0,864.0,True,"{'url': 'https://europepmc.org/articles/pmc3394104?pdf=render', 'status': None}","{'volume': '8', 'pages': '14 - 25', 'name': 'Current Cardiology Reviews'}","{'bibtex': '@Article{Elgendi2012OnTA,\n author = {M. Elgendi},\n journal = {Current Cardiology Reviews},\n pages = {14 - 25},\n title = {On the Analysis of Fingertip Photoplethysmogram Signals},\n volume = {8},\n year = {2012}\n}\n'}","[{'authorId': '1934350', 'name': 'M. Elgendi'}]"
119,0a4d9913a15355816818bef68ec78af2aeff6fbc,A Mood Driven Computational Model for Gross Emotion Regulation Process Paradigm,"Judgments, preferences, and other cognitive tasks entail an emotional foundation and cannot function in an emotional vacuum. This essential emotional component how- ever, needs to be continuously monitored. Emotion regulation strategies target the potential risk of having inappropriate level of emotions in the process of decision making. This study is a follow-up on a formerly proposed computational model for emotion regulation strategies based on Gross theory and applies several enhancements to it. In particular, we extend the dynamism and realism of the original model by considering a dynamic environment in which we study the effect of emotion eliciting events such as psychiatric therapies or traumas occurring during the simulation period. Furthermore, the new model uses an emotion-dependent regulation process based on the mood of individuals. This approach is consistent with human behavior in the real life. In addition, some key pa- rameters in our proposed computational model, such as emotion persistence factor were made adaptive. Results obtained from the simulation experiments using our proposed model show further consistency with the base theory.",2012.0,22.0,6.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Soleimani2012AMD,\n author = {Ahmad Soleimani and Ziad Kobti},\n title = {A Mood Driven Computational Model for Gross Emotion Regulation Process Paradigm},\n year = {2012}\n}\n'}","[{'authorId': '9458014', 'name': 'Ahmad Soleimani'}, {'authorId': '1763459', 'name': 'Ziad Kobti'}]"
120,0aafeae87b3691314407fbbb7ccf4829f94e20df,Varieties of Affect and the CogAff Architecture Schema,"In the last decade and a half, the amount of work on affect in general and emotion in particular has grown, in empirical psychology, cognitive science and AI, both for scientific purposes and for the purpose of designing synthetic characters, e.g. in games and entertainments. Such work understandably starts from concepts of ordinary language (e.g. “emotion”, “feeling”, “mood”, etc.). However, these concepts can be deceptive: the words appear to have clear meanings but are used in very imprecise and systematically ambiguous ways. This is often because of explicit or implicit pre-scientific theories about mental states and process. More sophisticated theories can provide a basis for deeper and more precise concepts, as has happened in physics and chemistry. In the Cognition and Affect project we have been attempting to explore the benefits of developing architecture-based concepts, i.e. starting with specifications of architectures for complete agents and then finding out what sorts of states and processes are supported by those architectures. So, instead of presupposing one theory of the architecture and explicitly or implicitly basing concepts on that, we define a space of architectures generated by the CogAff architecture schema, where each supports different collections of concepts. In that space we focus on one architecture H-Cogaff, a particularly rich instance of the CogAff architecture schema, conjectured as a theory of normal adult human information processing. The architecture-based concepts that it supports provide a framework for defining with greater precision than previously a host of mental concepts, including affective concepts. We then find that these map more or less loosely onto various pre-theoretical concepts, such as “emotion”, etc. We indicate some of the variety of emotion concepts generated by the H-Cogaff architecture A different architecture, supporting a different range of mental concepts might be appropriate for exploring affective states of other animals, for instance insects, reptiles, or other mammals, and young children.",2001.0,41.0,117.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sloman2001VarietiesOA,\n author = {A. Sloman},\n title = {Varieties of Affect and the CogAff Architecture Schema},\n year = {2001}\n}\n'}","[{'authorId': '145788442', 'name': 'A. Sloman'}]"
121,0ab5005b3eeeccdb8c3655652e2d80f1fda9bea5,Caricaturing facial expressions,,2000.0,40.0,115.0,False,,"{'volume': '76', 'pages': '105-146', 'name': 'Cognition'}","{'bibtex': '@Article{Calder2000CaricaturingFE,\n author = {A. Calder and D. Rowland and A. Young and I. Nimmo-Smith and Jill Keane and D. Perrett},\n journal = {Cognition},\n pages = {105-146},\n title = {Caricaturing facial expressions},\n volume = {76},\n year = {2000}\n}\n'}","[{'authorId': '2825775', 'name': 'A. Calder'}, {'authorId': '12739398', 'name': 'D. Rowland'}, {'authorId': '2423497', 'name': 'A. Young'}, {'authorId': '1401859312', 'name': 'I. Nimmo-Smith'}, {'authorId': '40020056', 'name': 'Jill Keane'}, {'authorId': '1695074', 'name': 'D. Perrett'}]"
122,0abd78ca51a0c8fee6c1ed4756360961a1419a13,Conceptualizing Willingness to Communicate in a L2: A Situational Model of L2 Confidence and Affiliation,"Why do some students seek, while others avoid, second language (L2) communication? Many language teachers have encountered students high in linguistic competence who are unwilling to use their L2 for communication whereas other students, with only minimal linguistic knowledge, seem to communicate in the L2 whenever possible. Despite excellent communicative competence, spontaneous and sustained use of the L2 is not ensured. A colleague, who teaches a L2 and whose L2 competence is excellent, is well known to avoid “like the plague” L2 communication in social settings. A related observation is that many learners have noticed that their willingness to communicate (WTC) varies considerably over time and across situations. Our aim in this article is twofold. First we wish to provide an account of the linguistic, communicative, and social psychological variables that might affect one's “willingness to communicate.” As demonstrated in the text below, and examination of WTC offers the opportunity to integrate psychological, linguistic, and communicative approaches to L2 research that typically have been independent of each other. We view the WTC model as having the potential to provide a useful interface between these disparate lines of inquiry. Our second goal is to suggest potential relations among these variables by outlining a comprehensive conceptual model that may be useful in describing, explaining, and predicting L2 communication. In an effort to move beyond linguistic or communicative competence as the primary goal of language instruction, this article represents an overt attempt to combine these disparate approaches in a common theme, that is, proposing WTC as the primary goal of language instruction.",1998.0,92.0,1672.0,False,,"{'volume': '82', 'pages': '545-562', 'name': 'The Modern Language Journal'}","{'bibtex': '@Article{MacIntyre1998ConceptualizingWT,\n author = {P. MacIntyre and Z. Dörnyei and R. Clément and K. Noels},\n journal = {The Modern Language Journal},\n pages = {545-562},\n title = {Conceptualizing Willingness to Communicate in a L2: A Situational Model of L2 Confidence and Affiliation},\n volume = {82},\n year = {1998}\n}\n'}","[{'authorId': '40447483', 'name': 'P. MacIntyre'}, {'authorId': '8142683', 'name': 'Z. Dörnyei'}, {'authorId': '144637030', 'name': 'R. Clément'}, {'authorId': '2018388', 'name': 'K. Noels'}]"
123,0ae7e526fd50102fbad4f781105afac0cb5c06e4,Gestures Over Video Streams to Support Remote Collaboration on Physical Tasks,"This article considers tools to support remote gesture in video systems being used to complete collaborative physical tasks-tasks in which two or more individuals work together manipulating three-dimensional objects in the real world. We first discuss the process of conversational grounding during collaborative physical tasks, particularly the role of two types of gestures in the grounding process: pointing gestures, which are used to refer to task objects and locations, and representational gestures, which are used to represent the form of task objects and the nature of actions to be used with those objects. We then consider ways in which both pointing and representational gestures can be instantiated in systems for remote collaboration on physical tasks. We present the results of two studies that use a ""surrogate"" approach to remote gesture, in which images are intended to express the meaning of gestures through visible embodiments, rather than direct views of the hands. In Study 1, we compare performance with a cursor-based pointing device that allows remote partners to point to objects in a video feed of the work area to performance side-by-side or with the video system alone. In Study 2, we compare performance with two variations of a pen-based drawing tool that allows for both pointing and representational gestures to performance with video alone. The results suggest that simple surrogate gesture tools can be used to convey gestures from remote sites, but that the tools need to be able to convey representational as well as pointing gestures to be effective. The results further suggest that an automatic erasure function, in which drawings disappear a few seconds after they were created, is more beneficial for collaboration than tools requiring manual erasure. We conclude with a discussion of the theoretical and practical implications of the results, as well as several areas for future research.",2004.0,54.0,329.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Gestures_Over_Video_Streams_to_Support_Remote_Collaboration_on_Physical_Tasks/6470090/1/files/11898644.pdf', 'status': None}","{'volume': '19', 'pages': '273 - 309', 'name': 'Human–Computer Interaction'}","{'bibtex': '@Article{Fussell2004GesturesOV,\n author = {Susan R. Fussell and Leslie D. Setlock and Jie Yang and Jiazhi Ou and Elizabeth Mauer and Adam D. I. Kramer},\n journal = {Human–Computer Interaction},\n pages = {273 - 309},\n title = {Gestures Over Video Streams to Support Remote Collaboration on Physical Tasks},\n volume = {19},\n year = {2004}\n}\n'}","[{'authorId': '1692772', 'name': 'Susan R. Fussell'}, {'authorId': '3190175', 'name': 'Leslie D. Setlock'}, {'authorId': '2118579343', 'name': 'Jie Yang'}, {'authorId': '1962473', 'name': 'Jiazhi Ou'}, {'authorId': '2075606633', 'name': 'Elizabeth Mauer'}, {'authorId': '1845400', 'name': 'Adam D. I. Kramer'}]"
124,0b1a7a22c8985db5767b36edf82afa04f5a972b2,Corrigendum: Virtual Avatar for Emotion Recognition in Patients with Schizophrenia: A Pilot Study,"[This corrects the article on p. 421 in vol. 10, PMID: 27616987.].",2016.0,73.0,5.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnhum.2016.00554/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Human Neuroscience'}","{'bibtex': '@Article{Marcos-Pablos2016CorrigendumVA,\n author = {Samuel Marcos-Pablos and E. González-Pablos and C. Martín-Lorenzo and Luis A. Flores and Jaime Gómez-García-Bermejo and E. Zalama},\n journal = {Frontiers in Human Neuroscience},\n title = {Corrigendum: Virtual Avatar for Emotion Recognition in Patients with Schizophrenia: A Pilot Study},\n volume = {10},\n year = {2016}\n}\n'}","[{'authorId': '1403618495', 'name': 'Samuel Marcos-Pablos'}, {'authorId': '82496356', 'name': 'E. González-Pablos'}, {'authorId': '1405311698', 'name': 'C. Martín-Lorenzo'}, {'authorId': '2067504239', 'name': 'Luis A. Flores'}, {'authorId': '1402134394', 'name': 'Jaime Gómez-García-Bermejo'}, {'authorId': '6220406', 'name': 'E. Zalama'}]"
125,0b40f19c46ad30c77eeb5b453989d2c9f4f76e26,Virtual reality sickness questionnaire (VRSQ): Motion sickness measurement index in a virtual reality environment.,,2018.0,42.0,401.0,False,,"{'volume': '69', 'pages': '\n          66-73\n        ', 'name': 'Applied ergonomics'}","{'bibtex': '@Article{Kim2018VirtualRS,\n author = {Hyun K. Kim and Jaehyun Park and Yeongcheol Choi and Mungyeong Choe},\n journal = {Applied ergonomics},\n pages = {\n          66-73\n        },\n title = {Virtual reality sickness questionnaire (VRSQ): Motion sickness measurement index in a virtual reality environment.},\n volume = {69},\n year = {2018}\n}\n'}","[{'authorId': '2115441351', 'name': 'Hyun K. Kim'}, {'authorId': '9256567', 'name': 'Jaehyun Park'}, {'authorId': '35561450', 'name': 'Yeongcheol Choi'}, {'authorId': '47189916', 'name': 'Mungyeong Choe'}]"
126,0b5696a31de431b0f8f86b2ff9c5ef17ef5a97b8,A probabilistic multimodal approach for predicting listener backchannels,,2009.0,40.0,162.0,True,"{'url': 'https://ris.utwente.nl/ws/files/6425721/morency_2009_probabilistic.pdf', 'status': None}","{'volume': '20', 'pages': '70-84', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Morency2009APM,\n author = {Louis-Philippe Morency and I. D. Kok and J. Gratch},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {70-84},\n title = {A probabilistic multimodal approach for predicting listener backchannels},\n volume = {20},\n year = {2009}\n}\n'}","[{'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '8112579', 'name': 'I. D. Kok'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
127,0bb0ffdd3e6f1fbf1df15de84b88ff788ec77400,Emotional empathy and associated individual differences,,1988.0,67.0,210.0,False,,"{'volume': '7', 'pages': '221-240', 'name': 'Current Psychology'}","{'bibtex': '@Article{Mehrabian1988EmotionalEA,\n author = {A. Mehrabian and Andrew Young and S. Sato},\n journal = {Current Psychology},\n pages = {221-240},\n title = {Emotional empathy and associated individual differences},\n volume = {7},\n year = {1988}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}, {'authorId': '2114900598', 'name': 'Andrew Young'}, {'authorId': '152639768', 'name': 'S. Sato'}]"
128,0bb35c411a2c1d2ba4cb295cc158c2f7b101d097,Are Computer-Generated Emotions and Moods Plausible to Humans?,,2006.0,30.0,45.0,False,,{'pages': '343-356'},"{'bibtex': '@Inproceedings{Gebhard2006AreCE,\n author = {Patrick Gebhard and K. Kipp},\n pages = {343-356},\n title = {Are Computer-Generated Emotions and Moods Plausible to Humans?},\n year = {2006}\n}\n'}","[{'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '2349057', 'name': 'K. Kipp'}]"
129,0bb42638f79b37ad75eccea4826e75c85b5defe5,ElectronixTutor: an intelligent tutoring system with multiple learning resources for electronics,,2018.0,113.0,50.0,True,"{'url': 'https://stemeducationjournal.springeropen.com/track/pdf/10.1186/s40594-018-0110-y', 'status': None}","{'volume': '5', 'name': 'International Journal of Stem Education'}","{'bibtex': '@Article{Graesser2018ElectronixTutorAI,\n author = {A. Graesser and Xiangen Hu and Benjamin D. Nye and K. VanLehn and Rohit Kumar and Cristina Heffernan and N. Heffernan and B. Woolf and A. Olney and V. Rus and F. Andrasik and Philip I. Pavlik and Zhiqiang Cai and Jon Wetzel and Brent Morgan and Andrew J. Hampton and A. Lippert and Lijia Wang and Qinyu Cheng and Joseph E. Vinson and Craig Kelly and Cadarrius McGlown and Charvi A. Majmudar and B. Morshed and Whitney O. Baer},\n journal = {International Journal of Stem Education},\n title = {ElectronixTutor: an intelligent tutoring system with multiple learning resources for electronics},\n volume = {5},\n year = {2018}\n}\n'}","[{'authorId': '1769251', 'name': 'A. Graesser'}, {'authorId': '3350316', 'name': 'Xiangen Hu'}, {'authorId': '66257841', 'name': 'Benjamin D. Nye'}, {'authorId': '1797292', 'name': 'K. VanLehn'}, {'authorId': '2143787510', 'name': 'Rohit Kumar'}, {'authorId': '2775572', 'name': 'Cristina Heffernan'}, {'authorId': '1686529', 'name': 'N. Heffernan'}, {'authorId': '3325410', 'name': 'B. Woolf'}, {'authorId': '1731622', 'name': 'A. Olney'}, {'authorId': '145154896', 'name': 'V. Rus'}, {'authorId': '4347107', 'name': 'F. Andrasik'}, {'authorId': '2505989', 'name': 'Philip I. Pavlik'}, {'authorId': '13799500', 'name': 'Zhiqiang Cai'}, {'authorId': '48622587', 'name': 'Jon Wetzel'}, {'authorId': '144139743', 'name': 'Brent Morgan'}, {'authorId': '31941584', 'name': 'Andrew J. Hampton'}, {'authorId': '2334267', 'name': 'A. Lippert'}, {'authorId': '2118354111', 'name': 'Lijia Wang'}, {'authorId': None, 'name': 'Qinyu Cheng'}, {'authorId': '2067524428', 'name': 'Joseph E. Vinson'}, {'authorId': '2056691866', 'name': 'Craig Kelly'}, {'authorId': '3490033', 'name': 'Cadarrius McGlown'}, {'authorId': '3149507', 'name': 'Charvi A. Majmudar'}, {'authorId': '2022173', 'name': 'B. Morshed'}, {'authorId': '3490006', 'name': 'Whitney O. Baer'}]"
130,0be65aae866333be580185a356960406ebbf239d,Interference: The relationship between response latency and response accuracy.,,1981.0,29.0,85.0,False,,"{'volume': '7', 'pages': '326-343', 'name': 'Journal of Experimental Psychology: Human Learning & Memory'}","{'bibtex': '@Article{Anderson1981InterferenceTR,\n author = {John R. Anderson},\n journal = {Journal of Experimental Psychology: Human Learning & Memory},\n pages = {326-343},\n title = {Interference: The relationship between response latency and response accuracy.},\n volume = {7},\n year = {1981}\n}\n'}","[{'authorId': '2158597261', 'name': 'John R. Anderson'}]"
131,0bfbd54c2ed38d580fd8c6fb2baf5ee59525dabc,Domain Authoring Assistant for Intelligent Virtual Agents,"Developing intelligent virtual characters has attracted a lot of attention in the recent years. The process of creating such characters often involves a team of creative authors who describe different aspects of the characters in natural language, and planning experts that translate this description into a planning domain. This can be quite challenging as the team of creative authors should diligently define every aspect of the character especially if it contains complex human-like behavior. Also a team of engineers has to manually translate the natural language description of a character's personality into the planning domain knowledge. This can be extremely time and resource demanding and can be an obstacle to author's creativity. The goal of this paper is to introduce an authoring assistant tool to automate the process of domain generation from natural language description of virtual characters, thus bridging between the creative authoring team and the planning domain experts. More- over, the proposed tool also identifies possible missing information in the domain description and iteratively makes suggestions to the author.",2019.0,46.0,14.0,False,,"{'volume': 'abs/1904.03266', 'name': 'ArXiv'}","{'bibtex': '@Article{Janghorbani2019DomainAA,\n author = {Sepehr Janghorbani and Ashutosh Modi and Jakob Buhmann and Mubbasir Kapadia},\n journal = {ArXiv},\n title = {Domain Authoring Assistant for Intelligent Virtual Agents},\n volume = {abs/1904.03266},\n year = {2019}\n}\n'}","[{'authorId': '51057369', 'name': 'Sepehr Janghorbani'}, {'authorId': '2477939', 'name': 'Ashutosh Modi'}, {'authorId': '51147349', 'name': 'Jakob Buhmann'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
132,0bfff1ee8f14815d847fe7ecb9d7d2c0e52e6e38,Repetition Facilitates Retrieval Opportunity in Vocabulary Learning,"As in most of secondary schools in Indonesia tend to focus on words list in vocabulary lesson which is easily forgotten by learners, providing retrieval opportunity to strengthen their memory about words can be effective since the retrieval is one of the psychological processes to make the students remember the words. Accordingly, providing retrieval opportunity during vocabulary learning is encouraged in this essay. After reviewing some literature related to retrieval process, repetition is one effective way to promote retrieval process. Since repeated encounters of the words facilitate the students to access the words-related information in their mind, repetition activity will be the effective solution for this context. The spaced repetition as proposed by Baddley (1990) can be appropriate for this context since learners will not be bored about the repetition. This idea is then developed by providing students with Southeast Sulawesi folklore as the reading material in order to obtain target words. It is believed that this kind of reading material can enhance the students’ active engagement in the classroom as well.",2018.0,16.0,5.0,True,,"{'volume': '175', 'name': 'IOP Conference Series: Earth and Environmental Science'}","{'bibtex': '@Article{Atikah2018RepetitionFR,\n author = {D. Atikah and Anita Rezki},\n journal = {IOP Conference Series: Earth and Environmental Science},\n title = {Repetition Facilitates Retrieval Opportunity in Vocabulary Learning},\n volume = {175},\n year = {2018}\n}\n'}","[{'authorId': '82317834', 'name': 'D. Atikah'}, {'authorId': '84164742', 'name': 'Anita Rezki'}]"
133,0c0393be8cb3bf99880c4f798894b2cfb9309338,Subject-Independent Emotion Recognition During Music Listening Based on EEG Using Deep Convolutional Neural Networks,"Emotion recognition during music listening using electroencephalogram (EEG) has gained more attention from researchers, recently. Many studies focused on accuracy on one subject while subject-independent performance evaluation was still unclear. In this paper, the objective is to create an emotion recognition model that can be applied to multiple subjects. By adopting convolutional neural networks (CNNs), advantage could be gained from utilizing information from electrodes and time steps. Using CNNs also does not need feature extraction which might leave out other related but unobserved features. CNNs with three to seven convolutional layers were deployed in this research. We measured their performance with a binary classification task for compositions of emotions including arousal and valence. The results showed that our method captured EEG signal patterns from numerous subjects by 10-fold cross validation with 81.54% and 86.87% accuracy from arousal and valence respectively. The method also showed a higher capability of generalization to unseen subjects than the previous method as can be observed from the results of leave-one-subject-out validation.",2019.0,26.0,14.0,True,"{'url': 'https://ris.utwente.nl/ws/files/172323395/08696054.pdf', 'status': None}","{'pages': '21-26', 'name': '2019 IEEE 15th International Colloquium on Signal Processing & Its Applications (CSPA)'}","{'bibtex': '@Article{Keelawat2019SubjectIndependentER,\n author = {Panayu Keelawat and Nattapong Thammasan and B. Kijsirikul and M. Numao},\n journal = {2019 IEEE 15th International Colloquium on Signal Processing & Its Applications (CSPA)},\n pages = {21-26},\n title = {Subject-Independent Emotion Recognition During Music Listening Based on EEG Using Deep Convolutional Neural Networks},\n year = {2019}\n}\n'}","[{'authorId': '108480443', 'name': 'Panayu Keelawat'}, {'authorId': '2280801', 'name': 'Nattapong Thammasan'}, {'authorId': '1683540', 'name': 'B. Kijsirikul'}, {'authorId': '9136228', 'name': 'M. Numao'}]"
134,0c2756bf713fdbf216e89cdaf96cc993619b56b8,Designing a collaborative virtual reality system to assess social inclusion among neurodiverse students,The following article presents a collaborative VR system designed to assess social inclusion among neurodiverse students. Students can join virtual environments to communicate and collaborate in a virtual supermarket shopping trip. A virtual classroom is developed in which students can be introduced to their task and the basic concepts of shopping. An overview of related literature in inclusion research is presented and used to discuss how the VR system can be used in future studies to measure social inclusion.,2021.0,28.0,2.0,False,,"{'pages': '353-357', 'name': '2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)'}","{'bibtex': '@Article{Thomsen2021DesigningAC,\n author = {L. Thomsen and Ali Adjorlu},\n journal = {2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},\n pages = {353-357},\n title = {Designing a collaborative virtual reality system to assess social inclusion among neurodiverse students},\n year = {2021}\n}\n'}","[{'authorId': '30995887', 'name': 'L. Thomsen'}, {'authorId': '20410106', 'name': 'Ali Adjorlu'}]"
135,0c39d5bff97454425cd593f201f887391ae07511,Developing the Concept of Money by Interactive Computer Games for Autistic Children,"Autism is a general term used to describe a group of complex developmental brain disorders known as Pervasive Developmental Disorders (PDD). It is a life-long disability that prevents people from understanding what they see, hear, and sense. This results in severe problems with social relationships, communications, and behavior. Autism is typically diagnosed between the ages of two and six, although variations of ASD (Autism Spectrum Disorders) can sometimes be diagnosed earlier or later [1]. Children with learning disability such as autism who have serious impairments with social, emotional and communication skills require high degree of personalization in using the educational software developed for them. In this paper we present a personalized game based on digital story-telling concept that helps the children of age ranging from 9 to 14 years old with autism to understand the use of money. It also teaches the autistic children the social behavior appropriate while shopping. The game is developed on BYOB (Build Your Own Block, an advanced offshoot of the game engine Scratch).",2011.0,17.0,40.0,False,,"{'pages': '559-564', 'name': '2011 IEEE International Symposium on Multimedia'}","{'bibtex': '@Article{Hassan2011DevelopingTC,\n author = {Arshia Zernab Hassan and Bushra Tasnim Zahed and F. Zohora and Johra Muhammad Moosa and Tasmiha Salam and Md. Mustafizur Rahman and H. Ferdous and Syed Ishtiaque Ahmed},\n journal = {2011 IEEE International Symposium on Multimedia},\n pages = {559-564},\n title = {Developing the Concept of Money by Interactive Computer Games for Autistic Children},\n year = {2011}\n}\n'}","[{'authorId': '2919623', 'name': 'Arshia Zernab Hassan'}, {'authorId': '50329323', 'name': 'Bushra Tasnim Zahed'}, {'authorId': '3146994', 'name': 'F. Zohora'}, {'authorId': '2891139', 'name': 'Johra Muhammad Moosa'}, {'authorId': '2317403', 'name': 'Tasmiha Salam'}, {'authorId': '2116362251', 'name': 'Md. Mustafizur Rahman'}, {'authorId': '2144919', 'name': 'H. Ferdous'}, {'authorId': '2109148675', 'name': 'Syed Ishtiaque Ahmed'}]"
136,0c3f276c4857e30f70854f5ed215502dba7d2bf7,RCS: A cognitive architecture for intelligent multi-agent systems☆,,2004.0,32.0,44.0,False,,"{'volume': '29', 'pages': '87-99', 'name': 'Annual Reviews in Control'}","{'bibtex': '@Article{Albus2004RCSAC,\n author = {J. Albus and A. Barbera},\n journal = {Annual Reviews in Control},\n pages = {87-99},\n title = {RCS: A cognitive architecture for intelligent multi-agent systems☆},\n volume = {29},\n year = {2004}\n}\n'}","[{'authorId': '3259367', 'name': 'J. Albus'}, {'authorId': '145667472', 'name': 'A. Barbera'}]"
137,0c5afb209b647456e99ce42a6d9d177764f9a0dd,Recognizing Action Units for Facial Expression Analysis,"Most automatic expression analysis systems attempt to recognize a small set of prototypic expressions, such as happiness, anger, surprise, and fear. Such prototypic expressions, however, occur rather infrequently. Human emotions and intentions are more often communicated by changes in one or a few discrete facial features. In this paper, we develop an Automatic Face Analysis (AFA) system to analyze facial expressions based on both permanent facial features (brows, eyes, mouth) and transient facial features (deepening of facial furrows) in a nearly frontal-view face image sequence. The AFA system recognizes fine-grained changes in facial expression into action units (AUs) of the Facial Action Coding System (FACS), instead of a few prototypic expressions. Multistate face and facial component models are proposed for tracking and modeling the various facial features, including lips, eyes, brows, cheeks, and furrows. During tracking, detailed parametric descriptions of the facial features are extracted. With these parameters as the inputs, a group of action units (neutral expression, six upper face AUs and 10 lower face AUs) are recognized whether they occur alone or in combinations. The system has achieved average recognition rates of 96.4 percent (95.4 percent if neutral expressions are excluded) for upper face AUs and 96.7 percent (95.6 percent with neutral expressions excluded) for lower face AUs. The generalizability of the system has been tested by using independent image databases collected and FACS-coded for ground-truth by different research teams.",2001.0,54.0,1837.0,True,"{'url': 'https://europepmc.org/articles/pmc4157835?pdf=render', 'status': None}","{'volume': '23 2', 'pages': '\n          97-115\n        ', 'name': 'IEEE transactions on pattern analysis and machine intelligence'}","{'bibtex': '@Article{Tian2001RecognizingAU,\n author = {Ying-li Tian and T. Kanade and J. Cohn},\n journal = {IEEE transactions on pattern analysis and machine intelligence},\n pages = {\n          97-115\n        },\n title = {Recognizing Action Units for Facial Expression Analysis},\n volume = {23 2},\n year = {2001}\n}\n'}","[{'authorId': '40383812', 'name': 'Ying-li Tian'}, {'authorId': '1733113', 'name': 'T. Kanade'}, {'authorId': '1737918', 'name': 'J. Cohn'}]"
138,0c7492a870c73eed22c19fb4b827dd581be27d3e,Child and adolescent mental illness during COVID-19: A rapid review,,2020.0,10.0,252.0,True,,"{'volume': '292', 'pages': '113307 - 113307', 'name': 'Psychiatry Research'}","{'bibtex': '@Article{Racine2020ChildAA,\n author = {N. Racine and J. Cooke and Rachel Eirich and D. Korczak and B. McArthur and S. Madigan},\n journal = {Psychiatry Research},\n pages = {113307 - 113307},\n title = {Child and adolescent mental illness during COVID-19: A rapid review},\n volume = {292},\n year = {2020}\n}\n'}","[{'authorId': '4834966', 'name': 'N. Racine'}, {'authorId': '116630031', 'name': 'J. Cooke'}, {'authorId': '66852066', 'name': 'Rachel Eirich'}, {'authorId': '48503019', 'name': 'D. Korczak'}, {'authorId': '39578140', 'name': 'B. McArthur'}, {'authorId': '4017256', 'name': 'S. Madigan'}]"
139,0ca31ced65b55f47f7cec53456376dff8ac6643f,A meta-analysis and systematic literature review of virtual reality rehabilitation programs,,2017.0,79.0,297.0,False,,"{'volume': '70', 'pages': '317-327', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Howard2017AMA,\n author = {Matt C. Howard},\n journal = {Comput. Hum. Behav.},\n pages = {317-327},\n title = {A meta-analysis and systematic literature review of virtual reality rehabilitation programs},\n volume = {70},\n year = {2017}\n}\n'}","[{'authorId': '153492041', 'name': 'Matt C. Howard'}]"
140,0cab531faa123491630b49da3290eb2b7eceeb17,LESSONS FROM EMOTION PSYCHOLOGY FOR THE DESIGN OF LIFELIKE CHARACTERS,"ABSTRACT This special issue describes a number of applications that utilize lifelike characters that teach indirectly, by playing some role in a social interaction with a user. The design of such systems reflects a compromise between competing, sometimes unarticulated, demands: They must realistically exhibit the behaviors and characteristics of their role, they must facilitate the desired learning, and they must work within the limitations of current technology, and there is little theoretical or empirical guidance on the impact of these compromises on learning. Our perspective on this problem is shaped by our interest in the role of emotion and emotional behaviors in such forms of learning. In recent years, there has been an explosion of interest in the role of emotion in the design of virtual humans. The techniques and motivations underlying these various efforts can seem, from an outsider's perspective, as bewildering and multifaceted as the concept of emotion itself is generally accused of being. Drawing on insights from emotion psychology, this article attempts to clarify for the designers of educational agents the various theoretical perspectives on the concept of emotion with the aim of giving guidance to designers of educational agents.",2005.0,88.0,96.0,False,,"{'volume': '19', 'pages': '215 - 233', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Gratch2005LESSONSFE,\n author = {J. Gratch and S. Marsella},\n journal = {Applied Artificial Intelligence},\n pages = {215 - 233},\n title = {LESSONS FROM EMOTION PSYCHOLOGY FOR THE DESIGN OF LIFELIKE CHARACTERS},\n volume = {19},\n year = {2005}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
142,0cde9b1a50611eab21381ab4bf934f71c9057e1c,Combined analysis of GSR and EEG signals for emotion recognition,"An article presents the results of research related to the detection of emotions using combined analysis of galvanic skin response (GSR) and electroencephalographic (EEG) signals. Twenty seven volunteers participated in the experiment. Emotions were evoked by presentation of a set of twenty one movies. Emotions, evoked by individual movies, were later rated by participants according to valence and arousal. GSR signal was used to indicate the most stimulating movies, then features extracted from EEG signal were used to classify emotions. To determine the features EEG signal was analyzed in the frequency domain using fast Fourier transform (FFT) algorithm. For classifying emotions, according to valence and arousal, two classifiers were implemented: support vector machine (SVM) and k-nearest neighbors (k-NN).",2018.0,21.0,20.0,False,,"{'pages': '137-141', 'name': '2018 International Interdisciplinary PhD Workshop (IIPhDW)'}","{'bibtex': '@Article{Tarnowski2018CombinedAO,\n author = {P. Tarnowski and M. Kołodziej and A. Majkowski and R. Rak},\n journal = {2018 International Interdisciplinary PhD Workshop (IIPhDW)},\n pages = {137-141},\n title = {Combined analysis of GSR and EEG signals for emotion recognition},\n year = {2018}\n}\n'}","[{'authorId': '2518874', 'name': 'P. Tarnowski'}, {'authorId': '2483035', 'name': 'M. Kołodziej'}, {'authorId': '79693825', 'name': 'A. Majkowski'}, {'authorId': '35261781', 'name': 'R. Rak'}]"
143,0cf9c7bd93a7256717245e799b36eb5e689be3de,"The defining characteristics of intelligent tutoring systems research: ITSs care, precisely","his paper argues that, despite the changes in philosophies and techniques that have occurred since ITS research began, there are continuous threads running through this research which define its essential and distinctive nature. In particular, ITSs are computer-based learning systems which attempt to adapt to the needs of learners and are therefore the only such systems which attempt to 'care' about learners in that sense. Also, ITS research is the only part of the general IT and education field which has as its scientific goal to make computationally precise and explicit forms of educational, psychological and social knowledge which are often left implicit. (http://aied.inf.ed.ac.uk/members99/archive/vol_10/self_paper/full.html)",1998.0,22.0,273.0,False,,"{'volume': '10', 'pages': '350-364', 'name': ''}","{'bibtex': '@Inproceedings{Self1998TheDC,\n author = {J. Self},\n pages = {350-364},\n title = {The defining characteristics of intelligent tutoring systems research: ITSs care, precisely},\n volume = {10},\n year = {1998}\n}\n'}","[{'authorId': '1773413', 'name': 'J. Self'}]"
144,0d00b3dbcb6dd8321467516a62b62579c2d2b271,How Fast are the Leaked Facial Expressions: The Duration of Micro-Expressions,,2013.0,25.0,310.0,False,,"{'volume': '37', 'pages': '217-230', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Yan2013HowFA,\n author = {Wen-Jing Yan and Qi Wu and Jing Liang and Yu-Hsin Chen and Xiaolan Fu},\n journal = {Journal of Nonverbal Behavior},\n pages = {217-230},\n title = {How Fast are the Leaked Facial Expressions: The Duration of Micro-Expressions},\n volume = {37},\n year = {2013}\n}\n'}","[{'authorId': '9185305', 'name': 'Wen-Jing Yan'}, {'authorId': '2004801328', 'name': 'Qi Wu'}, {'authorId': '2118675609', 'name': 'Jing Liang'}, {'authorId': '2115868127', 'name': 'Yu-Hsin Chen'}, {'authorId': '144054357', 'name': 'Xiaolan Fu'}]"
145,0d02686296773fe5c70cff03eed434e816eea836,Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent,,2005.0,45.0,458.0,False,,"{'volume': '62', 'pages': '161-178', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Brave2005ComputersTC,\n author = {Scott Brave and C. Nass and Kevin Hutchinson},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {161-178},\n title = {Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent},\n volume = {62},\n year = {2005}\n}\n'}","[{'authorId': '2739604', 'name': 'Scott Brave'}, {'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '114107135', 'name': 'Kevin Hutchinson'}]"
146,0d091a0d217f4a4f9d744135f179efc24a776625,Neural basis of eye gaze processing deficits in autism.,"Impairments in using eye gaze to establish joint attention and to comprehend the mental states and intentions of other people are striking features of autism. Here, using event-related functional MRI (fMRI), we show that in autism, brain regions involved in gaze processing, including the superior temporal sulcus (STS) region, are not sensitive to intentions conveyed by observed gaze shifts. On congruent trials, subjects watched as a virtual actor looked towards a checkerboard that appeared in her visual field, confirming the subject's expectation regarding what the actor 'ought to do' in this context. On incongruent trials, she looked towards empty space, violating the subject's expectation. Consistent with a prior report from our laboratory that used this task in neurologically normal subjects, 'errors' (incongruent trials) evoked more activity in the STS and other brain regions linked to social cognition, indicating a strong effect of intention in typically developing subjects (n = 9). The same brain regions were activated during observation of gaze shifts in subjects with autism (n = 10), but did not differentiate congruent and incongruent trials, indicating that activity in these regions was not modulated by the context of the perceived gaze shift. These results demonstrate a difference in the response of brain regions underlying eye gaze processing in autism. We conclude that lack of modulation of the STS region by gaze shifts that convey different intentions contributes to the eye gaze processing deficits associated with autism.",2005.0,46.0,435.0,True,"{'url': 'https://academic.oup.com/brain/article-pdf/128/5/1038/13733713/awh404.pdf', 'status': None}","{'volume': '128 Pt 5', 'pages': '\n          1038-48\n        ', 'name': 'Brain : a journal of neurology'}","{'bibtex': '@Article{Pelphrey2005NeuralBO,\n author = {K. Pelphrey and James P. Morris and G. McCarthy},\n journal = {Brain : a journal of neurology},\n pages = {\n          1038-48\n        },\n title = {Neural basis of eye gaze processing deficits in autism.},\n volume = {128 Pt 5},\n year = {2005}\n}\n'}","[{'authorId': '9765768', 'name': 'K. Pelphrey'}, {'authorId': '2118077239', 'name': 'James P. Morris'}, {'authorId': '145984907', 'name': 'G. McCarthy'}]"
147,0d0efe3c8aa2f9e530a11b8c7ba9e681cc296ade,cARdLearner: Using Expressive Virtual Agents when Learning Vocabulary in Augmented Reality,"Augmented reality (AR) has a diverse range of applications, including language teaching. When studying a foreign language, one of the biggest challenges learners face is memorizing new vocabulary. While augmented holograms are a promising means of supporting this memorization process, few studies have explored their potential in the language learning context. We demonstrate the possibility of using flashcard along with an expressive holographic agent on vocabulary learning. Users scan a flashcard and play an animation that is connected with an emotion related to the word they are seeing. Our goal is to propose an alternative to the traditional use of flashcards, and also introduce another way of using AR in the association process.",2022.0,31.0,2.0,False,,{'name': 'CHI Conference on Human Factors in Computing Systems Extended Abstracts'},"{'bibtex': '@Article{Calepso2022cARdLearnerUE,\n author = {Aimée Sousa Calepso and Natalie Hube and Noah Berenguel Senn and Vincent Brandt and M. Sedlmair},\n booktitle = {CHI Extended Abstracts},\n journal = {CHI Conference on Human Factors in Computing Systems Extended Abstracts},\n title = {cARdLearner: Using Expressive Virtual Agents when Learning Vocabulary in Augmented Reality},\n year = {2022}\n}\n'}","[{'authorId': '1693399289', 'name': 'Aimée Sousa Calepso'}, {'authorId': '41159925', 'name': 'Natalie Hube'}, {'authorId': '2164042241', 'name': 'Noah Berenguel Senn'}, {'authorId': '2163479960', 'name': 'Vincent Brandt'}, {'authorId': '3020591', 'name': 'M. Sedlmair'}]"
148,0d1a655f31c0f66bdb533b7f0b1dbaf1ff95f532,Making sense by making sentient: effectance motivation increases anthropomorphism.,"People commonly anthropomorphize nonhuman agents, imbuing everything from computers to pets to gods with humanlike capacities and mental experiences. Although widely observed, the determinants of anthropomorphism are poorly understood and rarely investigated. We propose that people anthropomorphize, in part, to satisfy effectance motivation-the basic and chronic motivation to attain mastery of one's environment. Five studies demonstrated that increasing effectance motivation by manipulating the perceived unpredictability of a nonhuman agent or by increasing the incentives for mastery increases anthropomorphism. Neuroimaging data demonstrated that the neural correlates of this process are similar to those engaged when mentalizing other humans. A final study demonstrated that anthropomorphizing a stimulus makes it appear more predictable and understandable, suggesting that anthropomorphism satisfies effectance motivation. Anthropomorphizing nonhuman agents seems to satisfy the basic motivation to make sense of an otherwise uncertain environment.",2010.0,174.0,391.0,False,,"{'volume': '99 3', 'pages': '\n          410-35\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Waytz2010MakingSB,\n author = {A. Waytz and Carey K. Morewedge and Nicholas Epley and George Monteleone and Jianfeng Gao and J. Cacioppo},\n journal = {Journal of personality and social psychology},\n pages = {\n          410-35\n        },\n title = {Making sense by making sentient: effectance motivation increases anthropomorphism.},\n volume = {99 3},\n year = {2010}\n}\n'}","[{'authorId': '3377580', 'name': 'A. Waytz'}, {'authorId': '2295910', 'name': 'Carey K. Morewedge'}, {'authorId': '7007014', 'name': 'Nicholas Epley'}, {'authorId': '1969782', 'name': 'George Monteleone'}, {'authorId': '48441202', 'name': 'Jianfeng Gao'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}]"
149,0d3e55d2e736a32e610c633cb530016e8ff60521,E-learning: analysis of online discussion forums in promoting knowledge construction through collaborative learning,"Extensive discussions and debates about the advantages of using technology to create a shared space among learning participants have been presented in studies in the field of e-learning. One of the approaches in using or adopting technology for learning is through the use of online discussion forums, which as reported has beneficial impact on the teaching and learning process. Online discussion forum is also a form of learning through networking which provide opportunities for students to seek, obtain, and share information. Therefore, students' participation and interaction in the forum can provide some insight into how they learn about a course in a virtual environment. In addition, it is also essential to consider how online discussion forums may promote knowledge constructions in students. This study examines preliminary data of an online discussion forum in a course at Masters level (MA) in order to investigate if there is evidence of shared construction of knowledge among students through collaborative learning behaviours. The findings indicate that the students actively processed and reviewed the postings in the online discussion forums. They also relate their postings to what they have learned in the lectures, besides providing links to relevant websites for further reading. Therefore, there is evidence that the students worked collaboratively in order to respond to the postings based on the topics presented during the lecture and tutorial. Finally, analysis of the students' discourses indicate various phases of knowledge construction (based on the IAM model), which is a reflection of their cognitive thinking process.",2010.0,27.0,19.0,False,,"{'volume': '9', 'pages': '53-62', 'name': 'WSEAS TRANSACTIONS on COMMUNICATIONS archive'}","{'bibtex': '@Article{Nor2010ElearningAO,\n author = {Nor Fariza Mohd Nor and N. A. Razak and J. Aziz},\n journal = {WSEAS TRANSACTIONS on COMMUNICATIONS archive},\n pages = {53-62},\n title = {E-learning: analysis of online discussion forums in promoting knowledge construction through collaborative learning},\n volume = {9},\n year = {2010}\n}\n'}","[{'authorId': '31193206', 'name': 'Nor Fariza Mohd Nor'}, {'authorId': '9424889', 'name': 'N. A. Razak'}, {'authorId': '49215152', 'name': 'J. Aziz'}]"
150,0d3fb665cbf4a9e2d633e445c6f6fbb38dfb026a,A persona aware persuasive dialogue policy for dynamic and co-operative goal setting,,2022.0,38.0,3.0,False,,"{'volume': '195', 'pages': '116303', 'name': 'Expert Syst. Appl.'}","{'bibtex': '@Article{Tiwari2022APA,\n author = {Abhisek Tiwari and Tulika Saha and S. Saha and Shubhashis Sengupta and Anutosh Maitra and Roshni Ramnani and P. Bhattacharyya},\n journal = {Expert Syst. Appl.},\n pages = {116303},\n title = {A persona aware persuasive dialogue policy for dynamic and co-operative goal setting},\n volume = {195},\n year = {2022}\n}\n'}","[{'authorId': '2063522518', 'name': 'Abhisek Tiwari'}, {'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '2062808558', 'name': 'Shubhashis Sengupta'}, {'authorId': '40585053', 'name': 'Anutosh Maitra'}, {'authorId': '3040439', 'name': 'Roshni Ramnani'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
151,0d67f1542f86a1cde792701a9ae5c824a5fad3f9,Depressive Symptoms and Cognitive Decline in Community‐Dwelling Older Adults,OBJECTIVES: To examine the temporal association between depressive symptoms and cognitive functioning and estimate the effect measure modification of the apolipoprotein E (APOE) ɛ4 allele on this relationship.,2010.0,57.0,123.0,False,,"{'volume': '58', 'name': 'Journal of the American Geriatrics Society'}","{'bibtex': ""@Article{Köhler2010DepressiveSA,\n author = {S. Köhler and M. V. van Boxtel and J. van Os and Alan Thomas and John T. O'Brien and J. Jolles and Frans R J Verhey and J. Allardyce},\n journal = {Journal of the American Geriatrics Society},\n title = {Depressive Symptoms and Cognitive Decline in Community‐Dwelling Older Adults},\n volume = {58},\n year = {2010}\n}\n""}","[{'authorId': '145551891', 'name': 'S. Köhler'}, {'authorId': '34697200', 'name': 'M. V. van Boxtel'}, {'authorId': '2257662561', 'name': 'J. van Os'}, {'authorId': '2224732178', 'name': 'Alan Thomas'}, {'authorId': '2255183798', 'name': ""John T. O'Brien""}, {'authorId': '144438320', 'name': 'J. Jolles'}, {'authorId': '2253142888', 'name': 'Frans R J Verhey'}, {'authorId': '2073448603', 'name': 'J. Allardyce'}]"
152,0d7bd0c278162bfb69621439a3b8dd217478e76e,Learning from Gesture: How Our Hands Change Our Minds,,2015.0,46.0,100.0,True,"{'url': 'https://europepmc.org/articles/pmc4562024?pdf=render', 'status': None}","{'volume': '27', 'pages': '405 - 412', 'name': 'Educational Psychology Review'}","{'bibtex': '@Article{Novack2015LearningFG,\n author = {M. Novack and S. Goldin‐Meadow},\n journal = {Educational Psychology Review},\n pages = {405 - 412},\n title = {Learning from Gesture: How Our Hands Change Our Minds},\n volume = {27},\n year = {2015}\n}\n'}","[{'authorId': '7788375', 'name': 'M. Novack'}, {'authorId': '115377287', 'name': 'S. Goldin‐Meadow'}]"
153,0d9658d9e1ba9adc9e0f691347a251ed8335e030,The social psychology of telecommunications,,1976.0,0.0,5278.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Short1976TheSP,\n author = {John Short and Ederyn Williams and B. Christie},\n title = {The social psychology of telecommunications},\n year = {1976}\n}\n'}","[{'authorId': '144627382', 'name': 'John Short'}, {'authorId': '30111315', 'name': 'Ederyn Williams'}, {'authorId': '117015815', 'name': 'B. Christie'}]"
154,0d99b43f0116844052f31e34abb3e1e9dcee824a,Ecounsellor : an avatar for student exam stress management,,2012.0,0.0,9.0,False,,"{'volume': '', 'pages': '185-193', 'name': ''}","{'bibtex': '@Inproceedings{Li2012EcounsellorA,\n author = {Manning Li and M. Kavakli and T. Rudra},\n pages = {185-193},\n title = {Ecounsellor : an avatar for student exam stress management},\n year = {2012}\n}\n'}","[{'authorId': '40217188', 'name': 'Manning Li'}, {'authorId': '3247112', 'name': 'M. Kavakli'}, {'authorId': '12156140', 'name': 'T. Rudra'}]"
155,0dac8ec705eb251de270b39673f2752728bbaff0,One-on-one and small group conversations with an intelligent virtual science tutor,,2018.0,80.0,8.0,True,"{'url': 'http://manuscript.elsevier.com/S0885230816301413/pdf/S0885230816301413.pdf', 'status': None}","{'volume': '50', 'pages': '157-174', 'name': 'Comput. Speech Lang.'}","{'bibtex': '@Article{Cole2018OneononeAS,\n author = {R. Cole and Cindy Buchenroth-Martin and T. Weston and Liam Devine and Jeannine Myatt and Brandon Helding and Sameer Pradhan and Margaret G. McKeown and Samantha Messier and Jennifer Borum and Wayne H. Ward},\n journal = {Comput. Speech Lang.},\n pages = {157-174},\n title = {One-on-one and small group conversations with an intelligent virtual science tutor},\n volume = {50},\n year = {2018}\n}\n'}","[{'authorId': '8089863', 'name': 'R. Cole'}, {'authorId': '1403911433', 'name': 'Cindy Buchenroth-Martin'}, {'authorId': '3035147', 'name': 'T. Weston'}, {'authorId': '2072332505', 'name': 'Liam Devine'}, {'authorId': '1408443187', 'name': 'Jeannine Myatt'}, {'authorId': '3026361', 'name': 'Brandon Helding'}, {'authorId': '1735131', 'name': 'Sameer Pradhan'}, {'authorId': '1935567', 'name': 'Margaret G. McKeown'}, {'authorId': '47165157', 'name': 'Samantha Messier'}, {'authorId': '120772509', 'name': 'Jennifer Borum'}, {'authorId': '1866226', 'name': 'Wayne H. Ward'}]"
156,0daedaa2b6d3fbecccc444de3b2466720958d9e9,Rebooting Psychotherapy Research and Practice to Reduce the Burden of Mental Illness,"Psychological interventions to treat mental health issues have developed remarkably in the past few decades. Yet this progress often neglects a central goal—namely, to reduce the burden of mental illness and related conditions. The need for psychological services is enormous, and only a small proportion of individuals in need actually receive treatment. Individual psychotherapy, the dominant model of treatment delivery, is not likely to be able to meet this need. Despite advances, mental health professionals are not likely to reduce the prevalence, incidence, and burden of mental illness without a major shift in intervention research and clinical practice. A portfolio of models of delivery will be needed. We illustrate various models of delivery to convey opportunities provided by technology, special settings and nontraditional service providers, self-help interventions, and the media. Decreasing the burden of mental illness also will depend on integrating prevention and treatment, developing assessment and a national database for monitoring mental illness and its burdens, considering contextual issues that influence delivery of treatment, and addressing potential tensions within the mental health professions. Finally, opportunities for multidisciplinary collaborations are discussed as key considerations for reducing the burden of mental illness.",2011.0,194.0,1045.0,True,"{'url': 'http://sites.udel.edu/delawareproject/files/2011/10/PPS_Kazdin_and_Commentaries.pdf', 'status': None}","{'volume': '6', 'pages': '21 - 37', 'name': 'Perspectives on Psychological Science'}","{'bibtex': '@Article{Kazdin2011RebootingPR,\n author = {A. Kazdin and Stacey L Blase},\n journal = {Perspectives on Psychological Science},\n pages = {21 - 37},\n title = {Rebooting Psychotherapy Research and Practice to Reduce the Burden of Mental Illness},\n volume = {6},\n year = {2011}\n}\n'}","[{'authorId': '152319200', 'name': 'A. Kazdin'}, {'authorId': '7383948', 'name': 'Stacey L Blase'}]"
157,0e0fc36255b7129b5a03a52bc1df55722e02033c,Effects of Agent Appearance on Customer Buying Motivations on Online Shopping Sites,"Although product recommendation virtual agents (PRVAs) are used in a large number of online shopping websites, the optimal types of agents in this context remain unclear. In the present study, we tested whether agent appearance affects people's buying motivations and analyzed the key factors in persuading people to buy products. The experimental results confirmed that recommendation effects vary according to agent appearance. Furthermore, we obtained a partial order ranking of the agent types, representing the effectiveness of their recommendations. The factor analysis results indicated that the perceptions of familiarity and intelligence in relation to appearance are the key factors in persuading people to buy products.",2015.0,11.0,29.0,False,,{'name': 'Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems'},"{'bibtex': '@Article{Terada2015EffectsOA,\n author = {K. Terada and Liang Jing and S. Yamada},\n journal = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},\n title = {Effects of Agent Appearance on Customer Buying Motivations on Online Shopping Sites},\n year = {2015}\n}\n'}","[{'authorId': '145990834', 'name': 'K. Terada'}, {'authorId': '2113523161', 'name': 'Liang Jing'}, {'authorId': '1679243', 'name': 'S. Yamada'}]"
160,0e2c10aaf5274c662c9d35831b1180ff47ba097b,Virtual humans: back to the future,"This paper essentially tries to examine all the roles that Virtual Humans can play in empowering human expression, and the research challenges we have to face to make this possible. It starts with a short history of Virtual Humans and how we contribute to the foundations of this field. We then define six typical Virtual Humans: the Performing Virtual Human, the Physiological Virtual Human, the Learning Virtual Human, the Connected Virtual Human, the Secure Virtual Human, and the Anthropometric Virtual Human. For each category, we provide a definition and a few possible scenarios, then we try to identify the research challenges, the past experiences, and some unsolved core issues.",2012.0,23.0,3.0,False,,{'pages': '1-8'},"{'bibtex': '@Inproceedings{Magnenat-Thalmann2012VirtualHB,\n author = {N. Magnenat-Thalmann and D. Thalmann},\n pages = {1-8},\n title = {Virtual humans: back to the future},\n year = {2012}\n}\n'}","[{'authorId': '1387241200', 'name': 'N. Magnenat-Thalmann'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}]"
161,0e58cf436d1b2378c2dc9047755afddb75dc67c2,DSM-V: modifying the postpartum-onset specifier to include hypomania,,2010.0,19.0,359.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s00737-010-0182-2.pdf', 'status': None}","{'volume': '14', 'pages': '67 - 69', 'name': ""Archives of Women's Mental Health""}","{'bibtex': ""@Article{Sharma2010DSMVMT,\n author = {Verinder Sharma and V. Burt},\n journal = {Archives of Women's Mental Health},\n pages = {67 - 69},\n title = {DSM-V: modifying the postpartum-onset specifier to include hypomania},\n volume = {14},\n year = {2010}\n}\n""}","[{'authorId': '2257761566', 'name': 'Verinder Sharma'}, {'authorId': '10116166', 'name': 'V. Burt'}]"
162,0e6f5abd7e4738b765cd48f4c272093ecb5fd0bc,Impact of an augmented reality system on students' motivation for a visual art course,,2013.0,71.0,845.0,True,"{'url': 'https://e-archivo.uc3m.es/bitstream/10016/19114/1/impact_ibanez_kloos_CE_2013_ps.pdf', 'status': None}","{'volume': '68', 'pages': '586-596', 'name': 'Comput. Educ.'}","{'bibtex': ""@Article{Serio2013ImpactOA,\n author = {Angela Di Serio and M. Ibáñez-Espiga and C. D. Kloos},\n journal = {Comput. Educ.},\n pages = {586-596},\n title = {Impact of an augmented reality system on students' motivation for a visual art course},\n volume = {68},\n year = {2013}\n}\n""}","[{'authorId': '2389763', 'name': 'Angela Di Serio'}, {'authorId': '1447342257', 'name': 'M. Ibáñez-Espiga'}, {'authorId': '118042932', 'name': 'C. D. Kloos'}]"
163,0e9ac6580db68b1a275d94c356cdc9cd7f5961d8,Benefits of Virtual Characters in Computer Based Learning Environments: Claims and Evidence,"Pedagogical theory of today gives high priority to social components of learning. Within the field of computer supported learning there are many attempts to acknowledge this. One approach involves the addition of virtual characters to electronic learning environments. Such character enhanced systems are the focus of the present article. Firstly, a systematic overview is given of pedagogical benefits that have been proposed in the literature regarding character enhancement of electronic learning environments, for example increased motivation, stimulation of particular learning activities, enhanced flow of communication and fulfillment of a need for deeper personal relationships in learning. Secondly, I examine the empirical results presented in the literature with respect to the proposed positive pedagogical effects. Based on these reviews, I finally discuss possible directions for continued research and design in the field from a pedagogical point of view. I propose a research agenda for the near future and conclude with some reflections on a longer-term perspective.",2004.0,72.0,154.0,False,,"{'volume': '14', 'pages': '313-334', 'name': 'Int. J. Artif. Intell. Educ.'}","{'bibtex': '@Article{Gulz2004BenefitsOV,\n author = {Agneta Gulz},\n journal = {Int. J. Artif. Intell. Educ.},\n pages = {313-334},\n title = {Benefits of Virtual Characters in Computer Based Learning Environments: Claims and Evidence},\n volume = {14},\n year = {2004}\n}\n'}","[{'authorId': '1809089', 'name': 'Agneta Gulz'}]"
164,0eb5b4c065999d8191202429e665e97124634c80,Treatment engagement of individuals experiencing mental illness: review and update,"Individuals living with serious mental illness are often difficult to engage in ongoing treatment, with high dropout rates. Poor engagement may lead to worse clinical outcomes, with symptom relapse and rehospitalization. Numerous variables may affect level of treatment engagement, including therapeutic alliance, accessibility of care, and a client's trust that the treatment will address his/her own unique goals. As such, we have found that the concept of recovery‐oriented care, which prioritizes autonomy, empowerment and respect for the person receiving services, is a helpful framework in which to view tools and techniques to enhance treatment engagement. Specifically, person‐centered care, including shared decision making, is a treatment approach that focuses on an individual's unique goals and life circumstances. Use of person‐centered care in mental health treatment models has promising outcomes for engagement. Particular populations of people have historically been difficult to engage, such as young adults experiencing a first episode of psychosis, individuals with coexisting psychotic and substance use disorders, and those who are homeless. We review these populations and outline how various evidence‐based, recovery‐oriented treatment techniques have been shown to enhance engagement. Our review then turns to emerging treatment strategies that may improve engagement. We focus on use of electronics and Internet, involvement of peer providers in mental health treatment, and incorporation of the Cultural Formulation Interview to provide culturally competent, person‐centered care. Treatment engagement is complex and multifaceted, but optimizing recovery‐oriented skills and attitudes is essential in delivery of services to those with serious mental illness.",2016.0,77.0,356.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wps.20306', 'status': None}","{'volume': '15', 'name': 'World Psychiatry'}","{'bibtex': '@Article{Dixon2016TreatmentEO,\n author = {L. Dixon and Y. Holoshitz and Ilana Nossel},\n journal = {World Psychiatry},\n title = {Treatment engagement of individuals experiencing mental illness: review and update},\n volume = {15},\n year = {2016}\n}\n'}","[{'authorId': '1871022', 'name': 'L. Dixon'}, {'authorId': '5632834', 'name': 'Y. Holoshitz'}, {'authorId': '5569736', 'name': 'Ilana Nossel'}]"
165,0ef3fb7984291549367f7b6d8b8eb8e9dd63d6a5,Feel the Difference: A Guide with Attitude!,,2007.0,19.0,39.0,False,,{'pages': '317-330'},"{'bibtex': '@Inproceedings{Lim2007FeelTD,\n author = {M. Lim and R. Aylett},\n pages = {317-330},\n title = {Feel the Difference: A Guide with Attitude!},\n year = {2007}\n}\n'}","[{'authorId': '1783919', 'name': 'M. Lim'}, {'authorId': '1732377', 'name': 'R. Aylett'}]"
166,0f0604f991797c2eb234cd6c6a42db035146abf8,Emotions Revealed : Understanding Faces and Feelings,"Whatever culture we come from, emotions play a huge role in our lives and in every relationship within them. Whether anger, joy, fear or sorrow, they can be incredibly powerful things - but can be equally hard to understand or control. In ""Emotions Revealed"", Paul Ekman draws on a lifetime's study to take the reader on a complete tour of the emotional self. Against a background of specially commissioned photographs and forceful news images from around the world, he examines and explains how, when and why we become emotional and how far we can change what we get emotional about; why we sometimes get emotional when others don't; how to recognise and understand the subtlest signs of emotion both in ourselves and other people; and much more. This stunning volume contains a test to find out how good you are at spotting emotions, exercises to improve your awareness of the bodily sensations involved in each emotion and an explanation of how to apply all this information to enhance your daily life.",2003.0,0.0,249.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman2003EmotionsR,\n author = {P. Ekman},\n title = {Emotions Revealed : Understanding Faces and Feelings},\n year = {2003}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
167,0f0703500e5374cabd6089efcd1054edc7da2f5f,Pilot Study for Assessing the Behaviors of Patients with Schizophrenia towards a Virtual Avatar,"This study examined whether a virtual avatar could be perceived as a real human by patients with mental disease, especially schizophrenia, as well as whether a virtual avatar could be applied to acquiring patients' behavior characteristics in a short conversation situation. The virtual avatar has been used for various applications which need to communicate with other person or to train or educate by showing humanlike behavior. Recently, many researches have shown that the virtual avatar technology has been enhanced and the avatar could be perceived like real human. A virtual avatar, standing in a virtual room, was designed for this study. Tasks to approach, initiate a talk, and answer to avatar's questions was assigned to the 11 patients with schizophrenia. As behavioral parameters in the virtual environment, the interpersonal distance and the verbal response time were acquired. In addition, the Positive and Negative Syndrome Scale (PANSS) for patients was administered in order to investigate the relationship between patients' symptomatic characteristics and behavior parameters. The interpersonal distance was negatively correlated with the negative syndrome scale, a subscale of PANSS, which is consistent with previous research reporting the relationship between interpersonal distance and a real person's image. The verbal response time, however, was not correlated with any other subscale of PANSS. After analyzing subitems of the negative syndrome of PANSS, two positive correlations were found: one was with blunted affect and the other was with poor rapport. We concluded that the virtual avatar could be perceived as a real human by schizophrenic patients and the avatar could draw the schizophrenic patients' behavior characteristics.",2006.0,17.0,37.0,False,,"{'volume': '9 5', 'pages': '\n          531-9\n        ', 'name': 'Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society'}","{'bibtex': '@Article{Ku2006PilotSF,\n author = {J. Ku and H. Jang and K. Kim and Sung Hyouk Park and Jae-Jin Kim and Chan-Hyung Kim and San W. Nam and I. Kim and Sun I. Kim},\n journal = {Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},\n pages = {\n          531-9\n        },\n title = {Pilot Study for Assessing the Behaviors of Patients with Schizophrenia towards a Virtual Avatar},\n volume = {9 5},\n year = {2006}\n}\n'}","[{'authorId': '143720898', 'name': 'J. Ku'}, {'authorId': '3287618', 'name': 'H. Jang'}, {'authorId': '1973742', 'name': 'K. Kim'}, {'authorId': '2237307', 'name': 'Sung Hyouk Park'}, {'authorId': '2145449477', 'name': 'Jae-Jin Kim'}, {'authorId': '2897323', 'name': 'Chan-Hyung Kim'}, {'authorId': '153389335', 'name': 'San W. Nam'}, {'authorId': '2219074220', 'name': 'I. Kim'}, {'authorId': '1455996091', 'name': 'Sun I. Kim'}]"
168,0f2bc09a73311cbf5fc88b320f8ecf88e85edd81,A multifaceted intervention to improve treatment of depression in primary care.,"BACKGROUND
This research study evaluates the effectiveness of a multifaceted intervention program to improve the management of depression in primary care.


METHODS
One hundred fifty-three primary care patients with current depression were entered into a randomized controlled trial. Intervention patients received a structured depression treatment program in the primary care setting that included both behavioral treatment to increase use of adaptive coping strategies and counseling to improve medication adherence. Control patients received ""usual"" care by their primary care physicians. Outcome measures included adherence to antidepressant medication, satisfaction with care of depression and with antidepressant treatment, and reduction of depressive symptoms over time.


RESULTS
At 4-month follow-up, significantly more intervention patients with major and minor depression than usual care patients adhered to antidepressant medication and rated the quality of care they received for depression as good to excellent. Intervention patients with major depression demonstrated a significantly greater decrease in depression severity over time compared with usual care patients on all 4 outcome analyses. Intervention patients with minor depression were found to have a significant decrease over time in depression severity on only 1 of 4 study outcome analyses compared with usual care patients.


CONCLUSION
A multifaceted primary care intervention improved adherence to antidepressant regimens and satisfaction with care in patients with major and minor depression. The intervention consistently resulted in more favorable depression outcomes among patients with major depression, while outcome effects were ambiguous among patients with minor depression.",1996.0,33.0,825.0,False,,"{'volume': '53 10', 'pages': '\n          924-32\n        ', 'name': 'Archives of general psychiatry'}","{'bibtex': '@Article{Katon1996AMI,\n author = {W. Katon and P. Robinson and M. Korff and E. Lin and T. Bush and E. Ludman and G. Simon and E. Walker},\n journal = {Archives of general psychiatry},\n pages = {\n          924-32\n        },\n title = {A multifaceted intervention to improve treatment of depression in primary care.},\n volume = {53 10},\n year = {1996}\n}\n'}","[{'authorId': '7278840', 'name': 'W. Katon'}, {'authorId': '2149814695', 'name': 'P. Robinson'}, {'authorId': '3070235', 'name': 'M. Korff'}, {'authorId': '32312471', 'name': 'E. Lin'}, {'authorId': '145150830', 'name': 'T. Bush'}, {'authorId': '3409526', 'name': 'E. Ludman'}, {'authorId': '144839706', 'name': 'G. Simon'}, {'authorId': '2935195', 'name': 'E. Walker'}]"
169,0f3a546c62487e20d9aadd8d869f2ca7f0d68c7d,Social Robots as Embedded Reinforcers of Social Behavior in Children with Autism,,2013.0,55.0,392.0,False,,"{'volume': '43', 'pages': '1038-1049', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Kim2013SocialRA,\n author = {Elizabeth S. Kim and Lauren D. Berkovits and Emily P. Bernier and Dan Leyzberg and F. Shic and R. Paul and B. Scassellati},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {1038-1049},\n title = {Social Robots as Embedded Reinforcers of Social Behavior in Children with Autism},\n volume = {43},\n year = {2013}\n}\n'}","[{'authorId': '1748636', 'name': 'Elizabeth S. Kim'}, {'authorId': '39841151', 'name': 'Lauren D. Berkovits'}, {'authorId': '34255085', 'name': 'Emily P. Bernier'}, {'authorId': '2928756', 'name': 'Dan Leyzberg'}, {'authorId': '1693018', 'name': 'F. Shic'}, {'authorId': '72901767', 'name': 'R. Paul'}, {'authorId': '1792053', 'name': 'B. Scassellati'}]"
170,0f455b48022bb74eea54f5aafad43016805a2db3,Virtual reality for psychotherapy: Current reality and future possibilities.,,2003.0,42.0,153.0,False,,"{'volume': '40', 'pages': '55-67', 'name': 'Psychotherapy'}","{'bibtex': '@Article{Glanz2003VirtualRF,\n author = {K. Glanz and A. Rizzo and K. Graap},\n journal = {Psychotherapy},\n pages = {55-67},\n title = {Virtual reality for psychotherapy: Current reality and future possibilities.},\n volume = {40},\n year = {2003}\n}\n'}","[{'authorId': '50053632', 'name': 'K. Glanz'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '4702987', 'name': 'K. Graap'}]"
171,0f5ba457b6f44cb582d90f753334a474a403c60f,The Responses of People to Virtual Humans in an Immersive Virtual Environment,"This paper presents an experiment investigating the impact of behavior and responsiveness on social responses to virtual humans in an immersive virtual environment (IVE). A number of responses are investigated, including presence, copresence, and two physiological responsesheart rate and electrodermal activity (EDA). Our findings suggest that increasing agents' responsiveness even on a simple level can have a significant impact on certain aspects of people's social responses to human-oid agents. Despite being aware that the agents were computer-generated, participants with higher levels of social anxiety were significantly more likely to avoid disturbing them. This suggests that on some level people can respond to virtual humans as social actors even in the absence of complex interaction. Responses appear to be shaped both by the agents' behaviors and by people's expectations of the technology. Participants experienced a significantly higher sense of personal contact when the agents were visually responsive to them, as opposed to static or simply moving. However, this effect diminished with experienced computer users. Our preliminary analysis of objective heart-rate data reveals an identical pattern of responses.",2005.0,30.0,196.0,True,"{'url': 'http://discovery.ucl.ac.uk/688/1/688.pdf', 'status': None}","{'volume': '14', 'pages': '104-116', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Garau2005TheRO,\n author = {Maia Garau and M. Slater and David-Paul Pertaub and Sharif Razzaque},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {104-116},\n title = {The Responses of People to Virtual Humans in an Immersive Virtual Environment},\n volume = {14},\n year = {2005}\n}\n'}","[{'authorId': '11554704', 'name': 'Maia Garau'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '1921915', 'name': 'David-Paul Pertaub'}, {'authorId': '50590753', 'name': 'Sharif Razzaque'}]"
172,0f62e20489b8535e26e8e5f281353d97c394a348,A tutorial on kernel density estimation and recent advances,"ABSTRACT This tutorial provides a gentle introduction to kernel density estimation (KDE) and recent advances regarding confidence bands and geometric/topological features. We begin with a discussion of basic properties of KDE: the convergence rate under various metrics, density derivative estimation, and bandwidth selection. Then, we introduce common approaches to the construction of confidence intervals/bands, and we discuss how to handle bias. Next, we talk about recent advances in the inference of geometric and topological features of a density function using KDE. Finally, we illustrate how one can use KDE to estimate a cumulative distribution function and a receiver operating characteristic curve. We provide R implementations related to this tutorial at the end.",2017.0,131.0,296.0,True,"{'url': 'https://arxiv.org/pdf/1704.03924', 'status': None}","{'volume': '1', 'pages': '161 - 187', 'name': 'Biostatistics & Epidemiology'}","{'bibtex': '@Article{Chen2017ATO,\n author = {Yen-Chi Chen},\n journal = {Biostatistics & Epidemiology},\n pages = {161 - 187},\n title = {A tutorial on kernel density estimation and recent advances},\n volume = {1},\n year = {2017}\n}\n'}","[{'authorId': '50580372', 'name': 'Yen-Chi Chen'}]"
173,0f94b1b699f1320a5fadbb34d29e8e255da8942f,Analysis of CNN-based speech recognition system using raw speech as input,"Abstract Automaticspeechrecognitionsystemstypicallymodeltherela-tionship between the acoustic speech signal and the phones intwo separate steps: feature extraction and classier training. Inourrecentworks, wehaveshownthat, intheframeworkofcon-volutionalneuralnetworks(CNN),therelationshipbetweentheraw speech signal and the phones can be directly modeled andASR systems competitive to standard approach can be built. Inthis paper, we rst analyze and show that, between the rst twoconvolutional layers, the CNN learns (in parts) and models thephone-specic spectral envelope information of 2-4 ms speech.Given that we show that the CNN-based approach yields ASRtrends similar to standard short-term spectral based ASR sys-tem under mismatched (noisy) conditions, with the CNN-basedapproach being more robust.Index Terms: automatic speech recognition, convolutionalneural networks, raw signal, robust speech recognition. 1. Introduction State-of-the-art automatic speech recognition (ASR) systemstypically model the relationship between the acoustic speechsignal and the phones in two separate steps, which are op-timized in an independent manner [1]. In a rst step, thespeech signal is transformed into features, usually composed ofa dimensionality reduction phase and an information selectionphase, based on the task-specic knowledge of the phenomena.These two phases have been carefully hand-crafted, leading tostate-of-the-art features such as Mel frequency cepstral coef-cients(MFCCs)orperceptuallinearpredictioncepstralfeatures(PLPs). In a second step, the likelihood of subword units suchas, phonemes is estimated using generative models or discrimi-native models.In recent years, in the hybrid HMM/ANN framework [1],there has been growing interests in using intermediate rep-resentations instead of conventional features, such as cepstral-based features, as input for neural networks-based systems.ANNs with deep learning architectures, more precisely, deepneural networks (DNNs) [2, 3], which can yield better systemthan a single hidden layer MLP have been proposed to addressvarious aspects of acoustic modeling. More specically, useof context-dependent phonemes [4, 5]; use of spectral featuresas opposed to cepstral features [6, 7]; CNN-based system withMel lter bank energies as input [8, 9, 10]; combination of dif-ferent features [11], to name a few. Features learning from therawspeechsignalusingneuralnetworks-basedsystemshasalsobeen investigated in [12]. In all these approaches, the features",2015.0,27.0,271.0,True,"{'url': 'https://infoscience.epfl.ch/record/210039/files/Palaz_Idiap-RR-23-2015.pdf', 'status': None}",{'pages': '11-15'},"{'bibtex': '@Inproceedings{Palaz2015AnalysisOC,\n author = {Dimitri Palaz and M. Magimai.-Doss and Ronan Collobert},\n pages = {11-15},\n title = {Analysis of CNN-based speech recognition system using raw speech as input},\n year = {2015}\n}\n'}","[{'authorId': '2922874', 'name': 'Dimitri Palaz'}, {'authorId': '1398480065', 'name': 'M. Magimai.-Doss'}, {'authorId': '2939803', 'name': 'Ronan Collobert'}]"
174,0f979f91c1e9a85b1695cc52c75a156b24b33441,Pain assessment and treatment disparities: A virtual human technology investigation,,2009.0,71.0,94.0,True,"{'url': 'https://europepmc.org/articles/pmc2666785?pdf=render', 'status': None}","{'volume': '143', 'pages': '106-113', 'name': 'Pain'}","{'bibtex': '@Article{Hirsh2009PainAA,\n author = {A. Hirsh and S. George and M. Robinson},\n journal = {Pain},\n pages = {106-113},\n title = {Pain assessment and treatment disparities: A virtual human technology investigation},\n volume = {143},\n year = {2009}\n}\n'}","[{'authorId': '10101422', 'name': 'A. Hirsh'}, {'authorId': '3186088', 'name': 'S. George'}, {'authorId': '144011759', 'name': 'M. Robinson'}]"
175,0fb3f03e5e7f90665b9a5e1c65597116d872745e,Virtual reality exposure therapy in anxiety disorders: a quantitative meta‐analysis,"Virtual reality exposure therapy (VRET) is a promising intervention for the treatment of the anxiety disorders. The main objective of this meta‐analysis is to compare the efficacy of VRET, used in a behavioral or cognitive‐behavioral framework, with that of the classical evidence‐based treatments, in anxiety disorders. A comprehensive search of the literature identified 23 studies (n = 608) that were included in the final analysis. The results show that in the case of anxiety disorders, (1) VRET does far better than the waitlist control; (2) the post‐treatment results show similar efficacy between the behavioral and the cognitive behavioral interventions incorporating a virtual reality exposure component and the classical evidence‐based interventions, with no virtual reality exposure component; (3) VRET has a powerful real‐life impact, similar to that of the classical evidence‐based treatments; (4) VRET has a good stability of results over time, similar to that of the classical evidence‐based treatments; (5) there is a dose–response relationship for VRET; and (6) there is no difference in the dropout rate between the virtual reality exposure and the in vivo exposure. Implications are discussed. Depression and Anxiety 0:1–9, 2011.  © 2011 Wiley Periodicals, Inc.",2012.0,44.0,496.0,True,,"{'volume': '29', 'name': 'Depression and Anxiety'}","{'bibtex': '@Article{Opriş2012VirtualRE,\n author = {David Opriş and S. Pintea and A. García-Palacios and C. Botella and Ștefan Szamosközi and D. David},\n journal = {Depression and Anxiety},\n title = {Virtual reality exposure therapy in anxiety disorders: a quantitative meta‐analysis},\n volume = {29},\n year = {2012}\n}\n'}","[{'authorId': '40594619', 'name': 'David Opriş'}, {'authorId': '2413277', 'name': 'S. Pintea'}, {'authorId': '1404807497', 'name': 'A. García-Palacios'}, {'authorId': '145945543', 'name': 'C. Botella'}, {'authorId': '16096003', 'name': 'Ștefan Szamosközi'}, {'authorId': '144000444', 'name': 'D. David'}]"
176,0fb4fc357b0e7f9366809898d32680dacf82462e,Social Touch in Human–Computer Interaction,"Touch is our primary non-verbal communication channel for conveying intimate emotions and as such essential for our physical and emotional wellbeing. In our digital age, human social interaction is often mediated. However, even though there is increasing evidence that mediated touch affords affective communication, current communication systems (such as videoconferencing) still do not support communication through the sense of touch. As a result, mediated communication does not provide the intense affective experience of co-located communication. The need for ICT mediated or generated touch as an intuitive way of social communication is even further emphasized by the growing interest in the use of touch-enabled agents and robots for healthcare, teaching, and telepresence applications. Here, we review the important role of social touch in our daily life and the available evidence that affective touch can be mediated reliably between humans and between humans and digital agents. We base our observations on evidence from psychology, computer science, sociology, and neuroscience with focus on the first two. Our review shows that mediated affective touch can modulate physiological responses, increase trust and affection, help to establish bonds between humans and avatars or robots, and initiate pro-social behavior. We argue that ICT mediated or generated social touch can (a) intensify the perceived social presence of remote communication partners and (b) enable computer systems to more effectively convey affective information. However, this research field on the crossroads of ICT and psychology is still embryonic and we identify several topics that can help to mature the field in the following areas: establishing an overarching theoretical framework, employing better research methodologies, developing basic social touch building blocks, and solving specific ICT challenges.",2015.0,204.0,140.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fdigh.2015.00002/pdf', 'status': None}","{'volume': '2', 'pages': '2', 'name': 'Frontiers Digit. Humanit.'}","{'bibtex': '@Article{Erp2015SocialTI,\n author = {J. V. Erp and A. Toet},\n journal = {Frontiers Digit. Humanit.},\n pages = {2},\n title = {Social Touch in Human–Computer Interaction},\n volume = {2},\n year = {2015}\n}\n'}","[{'authorId': '118775648', 'name': 'J. V. Erp'}, {'authorId': '1944545', 'name': 'A. Toet'}]"
177,0fc334e7f5a4738fdd1e150db0c729851b0399e7,"Impact of personality on the recognition of emotion expressed via human, virtual, and robotic embodiments","In this paper, we describe the elaboration and the validation of a body and face database1, of 96 videos of 1 to 2 seconds of duration, expressing 4 emotions (i.e., anger, happiness, fear, and sadness) elicited through 4 platforms of increased visual complexity and level of embodiment. The final aim of this database is to develop an individualized training program designed for individuals suffering of autism in order to help them recognize various emotions on different test platforms: two robots, a virtual agent, and a human. Before assessing the recognition capabilities of individuals with ASD, we validated our video database on typically developed individuals (TD). Moreover, we also looked at the relationship between the recognition rate and their personality traits (extroverted (EX) vs. introverted (IN)). We found that the personality of our TD participants did not lead to a different recognition behavior. However, introverted individuals better recognized emotions from less visually complex characters than extroverted individuals.",2015.0,25.0,15.0,False,,"{'name': '2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)', 'pages': '229-234'}","{'bibtex': '@Article{Chevalier2015ImpactOP,\n author = {P. Chevalier and Jean-Claude Martin and B. Isableu and A. Tapus},\n booktitle = {IEEE International Symposium on Robot and Human Interactive Communication},\n journal = {2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {229-234},\n title = {Impact of personality on the recognition of emotion expressed via human, virtual, and robotic embodiments},\n year = {2015}\n}\n'}","[{'authorId': '40648373', 'name': 'P. Chevalier'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '2950863', 'name': 'B. Isableu'}, {'authorId': '1738469', 'name': 'A. Tapus'}]"
178,100b09552f77abba945a297cbbb1dce8ee3c986e,Context-Sensitive Twitter Sentiment Classification Using Neural Network,"
 
 Sentiment classification on Twitter has attracted increasing research in recent years.Most existing work focuses on feature engineering according to the tweet content itself.In this paper, we propose a context-based neural network model for Twitter sentiment analysis, incorporating contextualized features from relevant Tweets into the model in the form of word embedding vectors.Experiments on both balanced and unbalanced datasets show that our proposed models outperform the current state-of-the-art.
 
",2016.0,23.0,142.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/9974/9833', 'status': None}",{'pages': '215-221'},"{'bibtex': '@Inproceedings{Ren2016ContextSensitiveTS,\n author = {Yafeng Ren and Yue Zhang and Meishan Zhang and D. Ji},\n pages = {215-221},\n title = {Context-Sensitive Twitter Sentiment Classification Using Neural Network},\n year = {2016}\n}\n'}","[{'authorId': '3350168', 'name': 'Yafeng Ren'}, {'authorId': None, 'name': 'Yue Zhang'}, {'authorId': '2678094', 'name': 'Meishan Zhang'}, {'authorId': '1719916', 'name': 'D. Ji'}]"
179,1028d8562fec24d637292b4234a3d4b338eab602,Evaluating the emotional content of human motions on real and virtual characters,"In order to analyze the emotional content of motions portrayed by different characters, we created real and virtual replicas of an actor exhibiting six basic emotions: sadness, happiness, surprise, fear, anger and disgust. In addition to the video of the real actor, his actions were applied to five virtual body shapes: a low and high resolution virtual counterpart, a cartoon-like character, a wooden mannequin, and a zombie-like character (Figure 1). Participants were asked to rate the actions based on a list of 41 more complex emotions. We found that the perception of emotional actions is highly robust and to the most part independent of the character's body.",2008.0,20.0,66.0,False,,{'pages': '67-74'},"{'bibtex': ""@Inproceedings{Mcdonnell2008EvaluatingTE,\n author = {R. Mcdonnell and S. Jörg and J. McHugh and F. Newell and C. O'Sullivan},\n pages = {67-74},\n title = {Evaluating the emotional content of human motions on real and virtual characters},\n year = {2008}\n}\n""}","[{'authorId': '145795454', 'name': 'R. Mcdonnell'}, {'authorId': '144892110', 'name': 'S. Jörg'}, {'authorId': '52093924', 'name': 'J. McHugh'}, {'authorId': '1818330', 'name': 'F. Newell'}, {'authorId': '1404017833', 'name': ""C. O'Sullivan""}]"
181,105ee4960a2c51b20c89be7622b112bfbae80ee1,Artificial Intelligence-Mediated Interaction in Virtual Reality Art,"In entertainment applications, artificial intelligence techniques have most often been used to implement embodied agents or to automatically generate artistic content. A more recent development concerns using AI to support the user experience through new AI-based interactivity techniques. This is especially of interest for the development of artistic installations based on interactive 3D worlds. A major difficulty in developing such installations is to properly translate the artistic intention into actual elements of interactivity, which in turn determine the user experience. The starting point of this research was to facilitate the description of high-level behaviors for virtual worlds that would form part of virtual reality (VR) art installations. In our approach to interactivity, the consequences of user interaction can be dynamically computed to produce cascaded effects eliciting a specific kind of user experience. This chain of events is computed from first principles embedding elements of the artistic brief (the artist's initial conceptual description of the interactive installation and the intended user experience). In other words, AI techniques are used for their ability to represent actions and to compute analogical transformations on them to create a user experience",2006.0,15.0,12.0,False,,"{'volume': '21', 'pages': '54-62', 'name': 'IEEE Intelligent Systems'}","{'bibtex': '@Article{Lugrin2006ArtificialII,\n author = {Jean-Luc Lugrin and M. Cavazza and Mark Palmer and S. Crooks},\n journal = {IEEE Intelligent Systems},\n pages = {54-62},\n title = {Artificial Intelligence-Mediated Interaction in Virtual Reality Art},\n volume = {21},\n year = {2006}\n}\n'}","[{'authorId': '144315100', 'name': 'Jean-Luc Lugrin'}, {'authorId': '1696638', 'name': 'M. Cavazza'}, {'authorId': '67010268', 'name': 'Mark Palmer'}, {'authorId': '144431268', 'name': 'S. Crooks'}]"
182,107b3a8b92758e679fc6be4ab7c328463a45d161,Adherence to Long-Term Therapies: Evidence for Action,,2003.0,1.0,6252.0,False,,"{'volume': '2', 'pages': '323 - 323', 'name': 'European Journal of Cardiovascular Nursing'}","{'bibtex': '@Article{Geest2003AdherenceTL,\n author = {S. D. De Geest and E. Sabaté},\n journal = {European Journal of Cardiovascular Nursing},\n pages = {323 - 323},\n title = {Adherence to Long-Term Therapies: Evidence for Action},\n volume = {2},\n year = {2003}\n}\n'}","[{'authorId': '8390641', 'name': 'S. D. De Geest'}, {'authorId': '46714877', 'name': 'E. Sabaté'}]"
183,10b9509d6deac5f88746e8ffbe2e3b3834dede4c,Intimate Exchanges: Using Computers to Elicit Self-Disclosure from Consumers,This investigation examines the dynamics associated with soliciting intimate information from consumers via computers. Experiment 1 identifies two factors--reciprocity and sequence--that affect the likelihood that people will reveal intimate information about themselves via a computer. Experiment 2 provides evidence that intimate information exchanges can affect how consumers behave in subsequent interactions. Implications for marketing research and practice are discussed. Copyright 2000 by the University of Chicago.,2000.0,66.0,779.0,False,,"{'volume': '26', 'pages': '323-339', 'name': 'Journal of Consumer Research'}","{'bibtex': '@Article{Moon2000IntimateEU,\n author = {Youngme Moon},\n journal = {Journal of Consumer Research},\n pages = {323-339},\n title = {Intimate Exchanges: Using Computers to Elicit Self-Disclosure from Consumers},\n volume = {26},\n year = {2000}\n}\n'}","[{'authorId': '33875827', 'name': 'Youngme Moon'}]"
185,10cc2d53ff8349d3432b8f822d58e4ddee3d475e,Measuring individual differences in implicit cognition: the implicit association test.,"An implicit association test (IAT) measures differential association of 2 target concepts with an attribute. The 2 concepts appear in a 2-choice task (2-choice task (e.g., flower vs. insect names), and the attribute in a 2nd task (e.g., pleasant vs. unpleasant words for an evaluation attribute). When instructions oblige highly associated categories (e.g., flower + pleasant) to share a response key, performance is faster than when less associated categories (e.g., insect & pleasant) share a key. This performance difference implicitly measures differential association of the 2 concepts with the attribute. In 3 experiments, the IAT was sensitive to (a) near-universal evaluative differences (e.g., flower vs. insect), (b) expected individual differences in evaluative associations (Japanese + pleasant vs. Korean + pleasant for Japanese vs. Korean subjects), and (c) consciously disavowed evaluative differences (Black + pleasant vs. White + pleasant for self-described unprejudiced White subjects).",1998.0,29.0,10580.0,True,"{'url': 'https://meth.psychopen.eu/index.php/meth/article/download/7155/7155.pdf', 'status': None}","{'volume': '74 6', 'pages': '\n          1464-80\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Greenwald1998MeasuringID,\n author = {A. Greenwald and D. McGhee and Jordan L. K. Schwartz},\n journal = {Journal of personality and social psychology},\n pages = {\n          1464-80\n        },\n title = {Measuring individual differences in implicit cognition: the implicit association test.},\n volume = {74 6},\n year = {1998}\n}\n'}","[{'authorId': '3864246', 'name': 'A. Greenwald'}, {'authorId': '49986173', 'name': 'D. McGhee'}, {'authorId': '2072435656', 'name': 'Jordan L. K. Schwartz'}]"
186,10cfd9452d4147e07faf3b89556e84b5eee0dd37,Learning by doing and learning through play: an exploration of interactivity in virtual environments for children,"The development of interactive, participatory, multisensoryenvironments that combine the physical with the virtual comes as anatural continuation to the computer game industrys constant racefor more exciting user experiences. Specialized theme parks andvarious other leisure and entertainment centers worldwide areembracing the interactive promise that games have made usersexpect. This is not a trend limited to the entertainment domain;non-formal learning environments for children are also followingthis path, backed up by a theoretical notion of play as a coreactivity in a childs development. In this article we explore acentral thread in learning, play, as well as an essentialcharacteristic of virtual reality environments: interactivity. Acritical review of examples of immersive virtual reality worldscreated for children, with particular attention given to the roleand nature of interactivity, is attempted. Interactivity isexamined in relation to learning, play, narrative, and tocharacteristics inherent in virtual reality, such as immersion,presence, and the creation of illusion.",2004.0,39.0,400.0,False,,"{'volume': '2', 'pages': '10', 'name': 'Comput. Entertain.'}","{'bibtex': '@Article{Roussou2004LearningBD,\n author = {M. Roussou},\n journal = {Comput. Entertain.},\n pages = {10},\n title = {Learning by doing and learning through play: an exploration of interactivity in virtual environments for children},\n volume = {2},\n year = {2004}\n}\n'}","[{'authorId': '2779272', 'name': 'M. Roussou'}]"
187,111359c407e728dc0aa09a9279e6ab013b189246,Comparing Three Computational Models of Affect,,2010.0,19.0,18.0,False,,{'pages': '175-184'},"{'bibtex': '@Inproceedings{Bosse2010ComparingTC,\n author = {T. Bosse and J. Gratch and J. Hoorn and M. Pontier and G. F. Siddiqui},\n pages = {175-184},\n title = {Comparing Three Computational Models of Affect},\n year = {2010}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '71825175', 'name': 'J. Hoorn'}, {'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}]"
188,1123da519480f59b11133f21c15603cad388af2c,A Deep Convolutional Neural Network Based Virtual Elderly Companion Agent,"This study presents a Virtual Elderly Companion Agent that based on speech spectrograms and deep convolutional neural networks. The system can dynamically detect and analyze the user's emotion from the dialogue and give appropriate positive feedback. The proposed system architecture is divided into two parts. The client side supports Android operating system; the server side is implemented in python, and applied GoogleLeNet and AlexNet for emotion recognition. The system supports natural language speech input, and then analyzes the converted speech spectrogram to provide appropriate feedback.",2017.0,16.0,4.0,False,,{'name': 'Proceedings of the 8th ACM on Multimedia Systems Conference'},"{'bibtex': '@Article{Lee2017ADC,\n author = {Ming-Che Lee and Sheng-Cheng Yeh and Sheng Yu Chiu and Jia-Wei Chang},\n booktitle = {ACM SIGMM Conference on Multimedia Systems},\n journal = {Proceedings of the 8th ACM on Multimedia Systems Conference},\n title = {A Deep Convolutional Neural Network Based Virtual Elderly Companion Agent},\n year = {2017}\n}\n'}","[{'authorId': '47804134', 'name': 'Ming-Che Lee'}, {'authorId': '122305220', 'name': 'Sheng-Cheng Yeh'}, {'authorId': '1398665180', 'name': 'Sheng Yu Chiu'}, {'authorId': '2874892', 'name': 'Jia-Wei Chang'}]"
189,11422e12989048a336d86e643a4bd0b7a32e20dc,Emotion Regulation in Children and Adolescents With Autism Spectrum Disorder,"Emotion dysregulation is not a formal criterion for the diagnosis of autism spectrum disorder (ASD). However, parents and clinicians have long noted the importance of emotional problems in individuals with ASD (e.g. tantrums and “meltdowns”). In this study, 21 high‐functioning children and adolescents with ASD and 22 age and gender group‐matched typically developing (TD) controls completed a Reactivity and Regulation Situation Task. This task assesses emotional reactivity and spontaneous use of emotion regulation strategies (problem solving, cognitive reappraisal, avoidance, distraction, venting, suppression, and relaxation) in the context of age‐appropriate ambiguous and potentially threatening negative scenarios. After the concept of cognitive reappraisal was explained, the scenarios were presented again to participants, and they were prompted to use this strategy. Results indicated that individuals with ASD exhibited the same level of reactivity to negative stimuli as TD participants. Furthermore, youth with ASD had a different emotion regulation profile than TD individuals, characterized by a less frequent use of cognitive reappraisal and more frequent use of suppression. When prompted to use cognitive reappraisal, participants with ASD were less able to implement reappraisal, but benefitted from this strategy when they were able to generate a reappraisal. Findings from this study suggest that cognitive reappraisal strategies may be useful to children and adolescents with ASD. Therefore, the development of treatment programs that focus on enhancing the use of adaptive forms of emotion regulation might decrease emotional problems and optimize long‐term outcomes in youth with ASD. Autism Res 2015, 8: 9–18. © 2014 International Society for Autism Research, Wiley Periodicals, Inc.",2015.0,68.0,153.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:97939/ATTACHMENT01', 'status': None}","{'volume': '8', 'name': 'Autism Research'}","{'bibtex': '@Article{Samson2015EmotionRI,\n author = {Andrea C. Samson and A. Hardan and Rebecca W. Podell and Jennifer M. Phillips and J. Gross},\n journal = {Autism Research},\n title = {Emotion Regulation in Children and Adolescents With Autism Spectrum Disorder},\n volume = {8},\n year = {2015}\n}\n'}","[{'authorId': '38707445', 'name': 'Andrea C. Samson'}, {'authorId': '6760287', 'name': 'A. Hardan'}, {'authorId': '16161768', 'name': 'Rebecca W. Podell'}, {'authorId': '2536136', 'name': 'Jennifer M. Phillips'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
190,117b29deab1a7df71dd637a0847ba2db917783c4,An NVC Emotional Model for Conversational Virtual Humans in a 3D Chatting Environment,,2012.0,30.0,14.0,False,,{'pages': '47-57'},"{'bibtex': '@Inproceedings{Ahn2012AnNE,\n author = {Junghyun Ahn and S. Gobron and David García and Quentin Silvestre and D. Thalmann and R. Boulic},\n pages = {47-57},\n title = {An NVC Emotional Model for Conversational Virtual Humans in a 3D Chatting Environment},\n year = {2012}\n}\n'}","[{'authorId': '1683972', 'name': 'Junghyun Ahn'}, {'authorId': '1696846', 'name': 'S. Gobron'}, {'authorId': '144240725', 'name': 'David García'}, {'authorId': '2007169', 'name': 'Quentin Silvestre'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}, {'authorId': '1696973', 'name': 'R. Boulic'}]"
191,11c1c84cc2e8743ad585efd099fedccf938598af,A Serious Game for Android Devices to Help Educate Individuals with Autism on Basic First Aid,,2012.0,7.0,17.0,False,,{'pages': '609-616'},"{'bibtex': '@Inproceedings{Urturi2012ASG,\n author = {Zelai Sáez de Urturi and A. M. Zorrilla and B. G. Zapirain},\n pages = {609-616},\n title = {A Serious Game for Android Devices to Help Educate Individuals with Autism on Basic First Aid},\n year = {2012}\n}\n'}","[{'authorId': '2768853', 'name': 'Zelai Sáez de Urturi'}, {'authorId': '3823997', 'name': 'A. M. Zorrilla'}, {'authorId': '3415641', 'name': 'B. G. Zapirain'}]"
192,11cb471d20a300ec991ee634ffb8b63336c41a00,Computer anxiety in individuals with serious mental illness,,1999.0,20.0,17.0,False,,"{'volume': '15', 'pages': '735-745', 'name': 'Computers in Human Behavior'}","{'bibtex': '@Article{Safford1999ComputerAI,\n author = {S. Safford and J. Worthington},\n journal = {Computers in Human Behavior},\n pages = {735-745},\n title = {Computer anxiety in individuals with serious mental illness},\n volume = {15},\n year = {1999}\n}\n'}","[{'authorId': '102136449', 'name': 'S. Safford'}, {'authorId': '145890645', 'name': 'J. Worthington'}]"
193,11dcaddab76b153584471e6919ff25cabda92ace,3D statistical neuroanatomical models from 305 MRI volumes,"Recently, there has been a rapid growth in the use of 3D multi-modal correlative imaging for studies of the human brain. Regional cerebral blood flow (CBF) changes indicate brain areas involved in stimulus processing. These focal changes are often too small (<10%) to be discerned from a single subject and the experiment is repeated in a series of individuals. To investigate the extent of residual variability the authors have collected over 300 MRI volumetric datasets from normal individuals and transformed these datasets into stereotaxic space using a 3D linear re-sampling algorithm. The authors then generated a series of statistical measures which express this population nonlinear variability in the form of parametric volumes, e.g. mean intensity, intensity variance. A model for anatomical variability, expressed as the width of a Gaussian blurring kernel applied to an ideal single subject, was developed and tested against the observed data.<<ETX>>",1993.0,9.0,1569.0,False,,"{'pages': '1813-1817 vol.3', 'name': '1993 IEEE Conference Record Nuclear Science Symposium and Medical Imaging Conference'}","{'bibtex': '@Article{Evans19933DSN,\n author = {Alan C. Evans and D. Collins and S. R. Mills and E. D. Brown and R. L. Kelly and T. Peters},\n journal = {1993 IEEE Conference Record Nuclear Science Symposium and Medical Imaging Conference},\n pages = {1813-1817 vol.3},\n title = {3D statistical neuroanatomical models from 305 MRI volumes},\n year = {1993}\n}\n'}","[{'authorId': '144159535', 'name': 'Alan C. Evans'}, {'authorId': '2238288468', 'name': 'D. Collins'}, {'authorId': '114880105', 'name': 'S. R. Mills'}, {'authorId': '2072718024', 'name': 'E. D. Brown'}, {'authorId': '1406347926', 'name': 'R. L. Kelly'}, {'authorId': '1698185', 'name': 'T. Peters'}]"
194,11f49977e4680a74451db07308c1d8057923e287,An architecture for emotional decision-making agents,"Our research focuses on complex agents that are capable of interacting with their environments in ways that are increasingly similar to individual humans. In this article we describe a cognitive architecture for an interactive decision-making agent with emotions. The primary goal of this work is to make the decision-making process of complex agents more realistic with regard to the behavior moderators, including emotional factors that affect humans. Instead of uniform agents that rely entirely on a deterministic body of expertise to make their decisions, the decision making process of our agents will vary according to select emotional factors affecting the agent as well as the agent's parameterized emotional profile. The premise of this model is that emotions serve as a kind of automatic assessment system that can guide or otherwise influence the more deliberative decision making process. The primary components of this emotional system are pleasure/pain and clarity/confusion subsystems that differentiate between positive and negative states. These, in turn, feed into an arousal system that interfaces with the decision-making system. We are testing our model using synthetic special-forces agents in a reconnaissance simulation.",2002.0,5.0,24.0,True,"{'url': 'http://www.bowdoin.edu/~echown/papers/AAMAS02.pdf', 'status': None}",{'pages': '352-353'},"{'bibtex': '@Inproceedings{Chown2002AnAF,\n author = {E. Chown and Randolph M. Jones and Amy E. Henninger},\n pages = {352-353},\n title = {An architecture for emotional decision-making agents},\n year = {2002}\n}\n'}","[{'authorId': '2756158', 'name': 'E. Chown'}, {'authorId': '153788834', 'name': 'Randolph M. Jones'}, {'authorId': '8993685', 'name': 'Amy E. Henninger'}]"
195,11f7d9b2017abd46c756df533618d2c4326fd3cb,Structuring Content in the Façade Interactive Drama Architecture,"The process of building Façade, a first-person, real-time, one-act interactive drama, has involved three major research efforts: designing ways to deconstruct a dramatic narrative into a hierarchy of story and behavior pieces; engineering an AI system that responds to and integrates the player's moment-by-moment interactions to reconstruct a real-time dramatic performance from those pieces; and understanding how to write an engaging, compelling story within this new organizational framework. This paper provides an overview of the process of bringing our interactive drama to life as a coherent, engaging, high agency experience, including the design and programming of thousands of joint dialog behaviors in the reactive planning language ABL, and their higher level organization into a collection of story beats sequenced by a drama manager. The process of iteratively developing the architecture, its languages, authorial idioms, and varieties of story content structures are described. These content structures are designed to intermix to offer players a high degree of responsiveness and narrative agency. We conclude with design and implementation lessons learned and future directions for creating more generative architectures.",2005.0,16.0,266.0,True,"{'url': 'https://ojs.aaai.org/index.php/AIIDE/article/download/18722/18499', 'status': None}",{'pages': '93-98'},"{'bibtex': '@Inproceedings{Mateas2005StructuringCI,\n author = {Michael Mateas and A. Stern},\n pages = {93-98},\n title = {Structuring Content in the Façade Interactive Drama Architecture},\n year = {2005}\n}\n'}","[{'authorId': '114402462', 'name': 'Michael Mateas'}, {'authorId': '143727207', 'name': 'A. Stern'}]"
196,11fe5d0a8dca7810cebe0c8c1c07b1928b293999,End-to-end masked graph-based CRF for joint slot filling and intent detection,,2020.0,11.0,15.0,False,,"{'volume': '413', 'pages': '348-359', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Tang2020EndtoendMG,\n author = {Hao Tang and D. Ji and Qiji Zhou},\n journal = {Neurocomputing},\n pages = {348-359},\n title = {End-to-end masked graph-based CRF for joint slot filling and intent detection},\n volume = {413},\n year = {2020}\n}\n'}","[{'authorId': '2112389014', 'name': 'Hao Tang'}, {'authorId': '1719916', 'name': 'D. Ji'}, {'authorId': '92758499', 'name': 'Qiji Zhou'}]"
197,123062ea1c407f97f98e4f3337b93157890bd5a2,When did her smile drop? Facial mimicry and the influences of emotional state on the detection of change in emotional expression,"Participants in manipulated emotional states played computerised movies in which facial expressions of emotion changed into categorically different expressions. The participants' task was to detect the offset of the initial expression. An effect of emotional state was observed such that individuals in happy states saw the offset of happiness (changing into sadness) at an earlier point in the movies than did those in sad states. Similarly, sad condition participants detected the offset of a sad expression changing into a happy expression earlier than did happy condition participants. This result is consistent with a proposed role of facial mimicry in the perception of change in emotional expression. The results of a second experiment provide additional evidence for the mimicry account. The Discussion focuses on the relationship between motor behaviour and perception.",2001.0,38.0,379.0,False,,"{'volume': '15', 'pages': '853 - 864', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Niedenthal2001WhenDH,\n author = {P. Niedenthal and M. Brauer and J. Halberstadt and Åse Innes-Ker},\n journal = {Cognition and Emotion},\n pages = {853 - 864},\n title = {When did her smile drop? Facial mimicry and the influences of emotional state on the detection of change in emotional expression},\n volume = {15},\n year = {2001}\n}\n'}","[{'authorId': '1986858', 'name': 'P. Niedenthal'}, {'authorId': '40529687', 'name': 'M. Brauer'}, {'authorId': '3012562', 'name': 'J. Halberstadt'}, {'authorId': '1402996412', 'name': 'Åse Innes-Ker'}]"
198,1231456cefb7302e7d82a587557d58019f5f41a1,A motivation model for virtual characters,"Motivation is an important psychology characteristic for a virtual character. An autonomous virtual characterpsilas behavior and emotion are controlled by motivation and outer stimuli, setting up the computer model of motivation of virtual characters is a hot topic in computer game and human interface. The current state of research on mental models of virtual characters is reviewed. Based on psychology theory, formalization concepts on Maslowpsilas theory are set up. A new motivation model of virtual character is proposed. The model can integrate stimuli, motivation, behavior, emotion and personality together.",2008.0,26.0,10.0,False,,"{'volume': '5', 'pages': '2712-2717', 'name': '2008 International Conference on Machine Learning and Cybernetics'}","{'bibtex': '@Article{Liu2008AMM,\n author = {Zhen Liu and Yu Lu},\n journal = {2008 International Conference on Machine Learning and Cybernetics},\n pages = {2712-2717},\n title = {A motivation model for virtual characters},\n volume = {5},\n year = {2008}\n}\n'}","[{'authorId': '2109341502', 'name': 'Zhen Liu'}, {'authorId': '2145038074', 'name': 'Yu Lu'}]"
200,1241d84b8c013f3421e6097205ba0a6bf62324ad,Face to face: Blocking facial mimicry can selectively impair recognition of emotional expressions,"Abstract People spontaneously mimic a variety of behaviors, including emotional facial expressions. Embodied cognition theories suggest that mimicry reflects internal simulation of perceived emotion in order to facilitate its understanding. If so, blocking facial mimicry should impair recognition of expressions, especially of emotions that are simulated using facial musculature. The current research tested this hypothesis using four expressions (happy, disgust, fear, and sad) and two mimicry-interfering manipulations (1) biting on a pen and (2) chewing gum, as well as two control conditions. Experiment 1 used electromyography over cheek, mouth, and nose regions. The bite manipulation consistently activated assessed muscles, whereas the chew manipulation activated muscles only intermittently. Further, expressing happiness generated most facial action. Experiment 2 found that the bite manipulation interfered most with recognition of happiness. These findings suggest that facial mimicry differentially contributes to recognition of specific facial expressions, thus allowing for more refined predictions from embodied cognition theories.",2007.0,57.0,418.0,False,,"{'volume': '2', 'pages': '167 - 178', 'name': 'Social Neuroscience'}","{'bibtex': '@Article{Oberman2007FaceTF,\n author = {L. Oberman and P. Winkielman and V. Ramachandran},\n journal = {Social Neuroscience},\n pages = {167 - 178},\n title = {Face to face: Blocking facial mimicry can selectively impair recognition of emotional expressions},\n volume = {2},\n year = {2007}\n}\n'}","[{'authorId': '3478050', 'name': 'L. Oberman'}, {'authorId': '3122131', 'name': 'P. Winkielman'}, {'authorId': '1888069', 'name': 'V. Ramachandran'}]"
201,129cbad01be98ee88a930e31898cb76be79c41c1,How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation,"We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available. Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response. We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems.",2016.0,48.0,1168.0,True,"{'url': 'https://www.aclweb.org/anthology/D16-1230.pdf', 'status': None}","{'volume': 'abs/1603.08023', 'name': 'ArXiv'}","{'bibtex': '@Article{Liu2016HowNT,\n author = {Chia-Wei Liu and Ryan Lowe and Iulian Serban and Michael Noseworthy and Laurent Charlin and Joelle Pineau},\n journal = {ArXiv},\n title = {How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation},\n volume = {abs/1603.08023},\n year = {2016}\n}\n'}","[{'authorId': '2144634184', 'name': 'Chia-Wei Liu'}, {'authorId': '2054294', 'name': 'Ryan Lowe'}, {'authorId': '35224828', 'name': 'Iulian Serban'}, {'authorId': '38107789', 'name': 'Michael Noseworthy'}, {'authorId': '1778839', 'name': 'Laurent Charlin'}, {'authorId': '145134886', 'name': 'Joelle Pineau'}]"
202,12f1e9093c1799806064b7899a7682a60cefc16b,Impairment of social and moral behavior related to early damage in human prefrontal cortex,,1999.0,27.0,1467.0,False,,"{'volume': '2', 'pages': '1032-1037', 'name': 'Nature Neuroscience'}","{'bibtex': '@Article{Anderson1999ImpairmentOS,\n author = {S. Anderson and A. Bechara and H. Damasio and D. Tranel and A. Damasio},\n journal = {Nature Neuroscience},\n pages = {1032-1037},\n title = {Impairment of social and moral behavior related to early damage in human prefrontal cortex},\n volume = {2},\n year = {1999}\n}\n'}","[{'authorId': '32532116', 'name': 'S. Anderson'}, {'authorId': '1998849', 'name': 'A. Bechara'}, {'authorId': '144027810', 'name': 'H. Damasio'}, {'authorId': '2467200', 'name': 'D. Tranel'}, {'authorId': '2656777', 'name': 'A. Damasio'}]"
203,12f8a302ec2cf406abfc5b710ad46a2d64b3dcb5,Rapport and facial expression,"How to build virtual agents that establish rapport with human? According to Tickle-Degnen and Rosenthal [4], the three essential components of rapport are mutual attentiveness, positivity and coordination. In our previous work, we designed an embodied virtual agent to establish rapport with a human speaker by providing rapid and contingent nonverbal feedback [13] [22]. How do we know that a human speaker is feeling a sense of rapport? In this paper, we focus on the positivity component of rapport by investigating the relationship of human speakers' facial expressions on the establishment of rapport. We used an automatic facial expression coding tool called CERT to analyze the human dyad interactions and human-virtual human interactions. Results show that recognizing positive facial displays alone may be insufficient and that recognized negative facial displays was more diagnostic in assessing the level of rapport between participants.",2009.0,30.0,32.0,False,,"{'pages': '1-6', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Wang2009RapportAF,\n author = {Ning Wang and J. Gratch},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-6},\n title = {Rapport and facial expression},\n year = {2009}\n}\n'}","[{'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
204,12ff3eaa7b23970a284a711431523ac3378a351e,FearNot! - An Experiment in Emergent Narrative,,2005.0,22.0,316.0,False,,{'pages': '305-316'},"{'bibtex': '@Inproceedings{Aylett2005FearNotA,\n author = {R. Aylett and S. Louchart and João Dias and Ana Paiva and M. Vala},\n pages = {305-316},\n title = {FearNot! - An Experiment in Emergent Narrative},\n year = {2005}\n}\n'}","[{'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '2910576', 'name': 'S. Louchart'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '7306645', 'name': 'M. Vala'}]"
206,1347f1516a698d862bf8d9bb53be14f9f493193b,Can computer personalities be human personalities?,"The claim that computer personalities can be human personalities was tested by demonstrating that (1) computer personalities can be easily created using a minimal set of cues, and (2) that people will respond to these personalities in the same way they would respond to similar human personalities. The present study focused on the ""similarity-attraction hypothesis,"" which predicts that people will prefer to interact with others who are similar in personality. In a 2 × 2, balanced, between-subjects experiment (n = 48), dominant and submissive subjects were randomly matched with a computer that was endowed with the properties associated with dominance or submissiveness. Subjects recognized the computer's personality type, distinct from friendliness and competence. In addition, subjects not only preferred the similar computer, but they were more satisfied with the interaction. The findings demonstrate that personality does not require richly defined agents, sophisticated pictorial representations, nautral language processing, or artificial intelligence. Rather, even the most superficial manipulations are sufficient to exhibit personality, with powerful effects.",1995.0,5.0,756.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/223355.223538', 'status': None}",{'name': 'Conference Companion on Human Factors in Computing Systems'},"{'bibtex': '@Article{Nass1995CanCP,\n author = {C. Nass and Youngme Moon and B. Fogg and Byron Reeves and Chris Dryer},\n journal = {Conference Companion on Human Factors in Computing Systems},\n title = {Can computer personalities be human personalities?},\n year = {1995}\n}\n'}","[{'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '33875827', 'name': 'Youngme Moon'}, {'authorId': '145469150', 'name': 'B. Fogg'}, {'authorId': '143923082', 'name': 'Byron Reeves'}, {'authorId': '2223729202', 'name': 'Chris Dryer'}]"
208,1354744fb3d0bad19c9f0c25b38ee00233228098,Reducing relapse and recurrence in unipolar depression: a comparative meta-analysis of cognitive-behavioral therapy's effects.,"Relapse and recurrence following response to acute-phase treatment for major depressive disorder (MDD) are prevalent and costly. In a meta-analysis of 28 studies including 1,880 adults, the authors reviewed the world's published literature on cognitive-behavioral therapies (CT) aimed at preventing relapse-recurrence in MDD. Results indicate that after discontinuation of acute-phase treatment, many responders to CT relapse-recur (29% within 1 year and 54% within 2 years). These rates appear comparable to those associated with other depression-specific psychotherapies but lower than those associated with pharmacotherapy. Among acute-phase treatment responders, continuation-phase CT reduced relapse-recurrence compared with assessment only at the end of continuation treatment (21% reduction) and at follow-up (29% reduction). Continuation-phase CT also reduced relapse-recurrence compared with other active continuation treatments at the end of continuation treatment (12% reduction) and at follow-up (14% reduction). The authors discuss implications for research and patient care and suggest directions, with methodological refinements, for future studies.",2007.0,94.0,511.0,True,"{'url': 'https://europepmc.org/articles/pmc2630051?pdf=render', 'status': None}","{'volume': '75 3', 'pages': '\n          475-88\n        ', 'name': 'Journal of consulting and clinical psychology'}","{'bibtex': ""@Article{Vittengl2007ReducingRA,\n author = {J. Vittengl and L. Clark and T. Dunn and R. Jarrett},\n journal = {Journal of consulting and clinical psychology},\n pages = {\n          475-88\n        },\n title = {Reducing relapse and recurrence in unipolar depression: a comparative meta-analysis of cognitive-behavioral therapy's effects.},\n volume = {75 3},\n year = {2007}\n}\n""}","[{'authorId': '5365568', 'name': 'J. Vittengl'}, {'authorId': '10034636', 'name': 'L. Clark'}, {'authorId': '22330595', 'name': 'T. Dunn'}, {'authorId': '6824299', 'name': 'R. Jarrett'}]"
209,13df913dce520381c61acff04510a3cd16776707,Towards integrated microplanning of language and iconic gesture for multimodal output,"When talking about spatial domains, humans frequently accompany their explanations with iconic gestures to depict what they are referring to. For example, when giving directions, it is common to see people making gestures that indicate the shape of buildings, or outline a route to be taken by the listener, and these gestures are essential to the understanding of the directions. Based on results from an ongoing study on language and gesture in direction-giving, we propose a framework to analyze such gestural images into semantic units (image description features), and to link these units to morphological features (hand shape, trajectory, etc.). This feature-based framework allows us to generate novel iconic gestures for embodied conversational agents, without drawing on a lexicon of canned gestures. We present an integrated microplanner that derives the form of both coordinated natural language and iconic gesture directly from given communicative goals, and serves as input to the speech and gesture realization engine in our NUMACK project.",2004.0,30.0,127.0,True,"{'url': 'http://www.techfak.uni-bielefeld.de/~skopp/download/p232-kopp.pdf', 'status': None}",{'pages': '97-104'},"{'bibtex': '@Inproceedings{Kopp2004TowardsIM,\n author = {S. Kopp and Paul Tepper and Justine Cassell},\n pages = {97-104},\n title = {Towards integrated microplanning of language and iconic gesture for multimodal output},\n year = {2004}\n}\n'}","[{'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '46580865', 'name': 'Paul Tepper'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
210,140045e50443c216c63a7d6d23afbe464735c26c,Modeling parallel and reactive empathy in virtual agents: an inductive approach,"Humans continuously assess one another's situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another's affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient's and perhaps intended to alter negative affect). Because empathy is not yet sufficiently well understood, it is unclear as to which type of empathy is most effective and under what circumstances they should be applied. Devising empirically informed models of empathy from observations of ""empathy in action"" may lead to virtual agents that can accurately respond in social situations. 
 
This paper proposes a unified inductive framework for modeling parallel and reactive empathy. First, in training sessions, a trainer guides a virtual agent through a series of problem-solving tasks in a learning environment and encounters empathetic characters. The proposed inductive architecture tracks situational data including actions, visited locations, intentions, and the trainer's physiological responses to generate models of empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions. An empirical evaluation of the approach in an interactive learning environment suggests that the induced empathy models can accurately assess social contexts and generate appropriate empathetic responses for virtual agent control.",2008.0,29.0,68.0,False,,{'pages': '167-174'},"{'bibtex': '@Inproceedings{McQuiggan2008ModelingPA,\n author = {Scott W. McQuiggan and J. Robison and R. Phillips and James C. Lester},\n pages = {167-174},\n title = {Modeling parallel and reactive empathy in virtual agents: an inductive approach},\n year = {2008}\n}\n'}","[{'authorId': '2779835', 'name': 'Scott W. McQuiggan'}, {'authorId': '31942647', 'name': 'J. Robison'}, {'authorId': '2069956407', 'name': 'R. Phillips'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
211,14229e6b265a45a58ddc78fc3cffbb4cf7e61173,Exploring temporal representations by leveraging attention-based bidirectional LSTM-RNNs for multi-modal emotion recognition,,2020.0,32.0,110.0,False,,"{'volume': '57', 'pages': '102185', 'name': 'Inf. Process. Manag.'}","{'bibtex': '@Article{Li2020ExploringTR,\n author = {Chao Li and Zhongtian Bao and Linhao Li and Ziping Zhao},\n journal = {Inf. Process. Manag.},\n pages = {102185},\n title = {Exploring temporal representations by leveraging attention-based bidirectional LSTM-RNNs for multi-modal emotion recognition},\n volume = {57},\n year = {2020}\n}\n'}","[{'authorId': '2150357386', 'name': 'Chao Li'}, {'authorId': '121153870', 'name': 'Zhongtian Bao'}, {'authorId': '2128198994', 'name': 'Linhao Li'}, {'authorId': '143889734', 'name': 'Ziping Zhao'}]"
212,143d950f9d2db4207f0ba2b96d9c420ab59fcb35,A rule based control algorithm of connected vehicles in uncontrolled intersection,"Aiming to address the safety issue for the uncontrolled intersection, the existing schemes including design optimization of the intersection structure and additional traffic signal layout will waste lots of resources. With the rapid development of intelligent transportation, the technology of vehicle-vehicle communication provides a new way for this problem. The paper proposed a set of rules to clarify the sequence of vehicles to pass through uncontrolled intersection. The rules are planned based on the law of road traffic safety. According to the rules, each approaching car makes decision for preempting or yielding other cars based on the information from vehicle-vehicle communication. If the approaching car needs to yield other cars, we propose an algorithm to find a proper deceleration value to do yielding. The car brakes automatically using this deceleration value to avoid collision with other cars. After all, the tests were done to verify the effectiveness of the algorithm and demonstrate the function among the connected vehicles in intersection. The rule based collision avoidance algorithm can provide real-time collision detection and make safe deceleration for the cars crossing the uncontrolled intersection.",2014.0,25.0,32.0,False,,"{'pages': '115-120', 'name': '17th International IEEE Conference on Intelligent Transportation Systems (ITSC)'}","{'bibtex': '@Article{Lu2014ARB,\n author = {G. Lu and Lumiao Li and Yunpeng Wang and Ran Zhang and Zewen Bao and Haichong Chen},\n journal = {17th International IEEE Conference on Intelligent Transportation Systems (ITSC)},\n pages = {115-120},\n title = {A rule based control algorithm of connected vehicles in uncontrolled intersection},\n year = {2014}\n}\n'}","[{'authorId': '31459383', 'name': 'G. Lu'}, {'authorId': '8446882', 'name': 'Lumiao Li'}, {'authorId': '47903840', 'name': 'Yunpeng Wang'}, {'authorId': '2110044811', 'name': 'Ran Zhang'}, {'authorId': '8303550', 'name': 'Zewen Bao'}, {'authorId': '7314523', 'name': 'Haichong Chen'}]"
213,14624f972b1c14ecec3a3b1cebae8147943c0fa1,Comprehensive guidelines for emotion annotation,"Emotions are psychological traits which are associated with an individuals' thoughts, feelings, behavioral responses, and experiences of pleasure and displeasure. The ability to recognise a conversational partner's emotional state from their speech (and respond accordingly) is a longstanding requirement of a fully capable intelligent virtual agent. However, despite the fact that current approaches to emotion recognition primarily depend upon supervised machine learning models, there are no comprehensive guidelines for emotion label annotation of the corpora used to train such models. We present comprehensive guidelines for consistent and effective annotation of text corpora with emotion labels. In particular, our proposal directly addresses the requirements of multi-label emotion recognition, and we demonstrate how an implementation of our proposed guidelines led to substantially (30%) higher agreement score among human annotators.",2022.0,35.0,5.0,False,,{'name': 'Proceedings of the 22nd ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Book{Islam2022ComprehensiveGF,\n author = {Md. Adnanul Islam and Md. Saddam Hossain Mukta and P. Olivier and Md. Mahbubur Rahman},\n booktitle = {International Conference on Intelligent Virtual Agents},\n journal = {Proceedings of the 22nd ACM International Conference on Intelligent Virtual Agents},\n title = {Comprehensive guidelines for emotion annotation},\n year = {2022}\n}\n'}","[{'authorId': '7484275', 'name': 'Md. Adnanul Islam'}, {'authorId': '1806836', 'name': 'Md. Saddam Hossain Mukta'}, {'authorId': '145171812', 'name': 'P. Olivier'}, {'authorId': '2183393804', 'name': 'Md. Mahbubur Rahman'}]"
214,1485b5a20f4f876c46f5dfa4e1bf3caf2452e26f,Creating adaptive affective autonomous NPCs,,2012.0,63.0,68.0,True,"{'url': 'http://www.macs.hw.ac.uk/%7Emyl/Papers/JAAMAS2012.pdf', 'status': None}","{'volume': '24', 'pages': '287-311', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Lim2012CreatingAA,\n author = {M. Lim and João Dias and R. Aylett and Ana Paiva},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {287-311},\n title = {Creating adaptive affective autonomous NPCs},\n volume = {24},\n year = {2012}\n}\n'}","[{'authorId': '1783919', 'name': 'M. Lim'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
216,1486815229ab8ae405ece93aff2c82ba234258e2,Fundamental dimensions of social judgment: understanding the relations between judgments of competence and warmth.,"In seems there are two dimensions that underlie most judgments of traits, people, groups, and cultures. Although the definitions vary, the first makes reference to attributes such as competence, agency, and individualism, and the second to warmth, communality, and collectivism. But the relationship between the two dimensions seems unclear. In trait and person judgment, they are often positively related; in group and cultural stereotypes, they are often negatively related. The authors report 4 studies that examine the dynamic relationship between these two dimensions, experimentally manipulating the location of a target of judgment on one and examining the consequences for the other. In general, the authors' data suggest a negative dynamic relationship between the two, moderated by factors the impact of which they explore.",2005.0,55.0,903.0,False,,"{'volume': '89 6', 'pages': '\n          899-913\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Judd2005FundamentalDO,\n author = {C. Judd and Laurie James-Hawkins and V. Yzerbyt and Y. Kashima},\n journal = {Journal of personality and social psychology},\n pages = {\n          899-913\n        },\n title = {Fundamental dimensions of social judgment: understanding the relations between judgments of competence and warmth.},\n volume = {89 6},\n year = {2005}\n}\n'}","[{'authorId': '5672179', 'name': 'C. Judd'}, {'authorId': '1387239301', 'name': 'Laurie James-Hawkins'}, {'authorId': '4779221', 'name': 'V. Yzerbyt'}, {'authorId': '1996561', 'name': 'Y. Kashima'}]"
217,14904551131486eb17ad823b6c4308fea0655681,Interacting with Embodied Conversational Agents,,2010.0,104.0,63.0,False,,"{'volume': '', 'pages': '123-149', 'name': ''}","{'bibtex': '@Inproceedings{André2010InteractingWE,\n author = {E. André and C. Pelachaud},\n pages = {123-149},\n title = {Interacting with Embodied Conversational Agents},\n year = {2010}\n}\n'}","[{'authorId': '1742930', 'name': 'E. André'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
218,149db52a7d70a5ab45426facadd57e7be41830ff,Being There in the Midst of the Story: How Immersive Journalism Affects Our Perceptions and Cognitions,"Immersive journalism in the form of virtual reality (VR) headsets and 360°-video is becoming more mainstream and is much touted for inducing greater ""presence"" than traditional text. But, does this presence influence psychological outcomes of reading news, such as memory for story content, perceptions of credibility, and empathy felt toward story characters? We propose that two key technological affordances of VR (modality and interactivity) are responsible for triggering three presence-related cognitive heuristics (being-there, interaction, and realism), which influence news readers' memory and their perceptions of credibility, empathy, and story-sharing intentions. We report a 3 (storytelling medium: VR vs. 360°-video vs. Text) × 2 (story: ""The displaced"" and ""The click effect"") mixed-factorial experiment, in which participants (N = 129) experienced two New York Times stories (that differed in their emotional intensity) using one of the three mediums (VR, 360°-video, Text). Participants who experienced the stories using VR and 360°-video outperformed those who read the same stories using text with pictures, not only on such presence-related outcomes as being-there, interaction, and realism, but also on perceived source credibility, story-sharing intention, and feelings of empathy. Moreover, we found that senses of being-there, interaction, and realism mediated the relationship between storytelling medium and reader perceptions of credibility, story recall, and story-sharing intention. These findings have theoretical implications for the psychology of virtual reality, and practical applications for immersive journalism in particular and interactive media in general.",2017.0,55.0,132.0,False,,"{'volume': '20 11', 'pages': '\n          672-682\n        ', 'name': 'Cyberpsychology, behavior and social networking'}","{'bibtex': '@Article{Sundar2017BeingTI,\n author = {S. Sundar and Jin Kang and D. Oprean},\n journal = {Cyberpsychology, behavior and social networking},\n pages = {\n          672-682\n        },\n title = {Being There in the Midst of the Story: How Immersive Journalism Affects Our Perceptions and Cognitions},\n volume = {20 11},\n year = {2017}\n}\n'}","[{'authorId': '153638564', 'name': 'S. Sundar'}, {'authorId': '144259393', 'name': 'Jin Kang'}, {'authorId': '2635486', 'name': 'D. Oprean'}]"
219,14caf1d247a450960efcabaa934f8ec404b08714,Real-time Brain Assessment for Adaptive Virtual Reality Game : A Neurofeedback Approach,,2017.0,17.0,19.0,False,,{'pages': '133-143'},"{'bibtex': '@Inproceedings{Abdessalem2017RealtimeBA,\n author = {H. Abdessalem and C. Frasson},\n pages = {133-143},\n title = {Real-time Brain Assessment for Adaptive Virtual Reality Game : A Neurofeedback Approach},\n year = {2017}\n}\n'}","[{'authorId': '28987363', 'name': 'H. Abdessalem'}, {'authorId': '1788058', 'name': 'C. Frasson'}]"
220,14e53403a0055dbe5faaf9f1f3be96ca0e692a4d,Improved Boosting Algorithms Using Confidence-rated Predictions,,1998.0,35.0,3518.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1023/A:1007614523901.pdf', 'status': None}","{'volume': '37', 'pages': '297-336', 'name': 'Machine Learning'}","{'bibtex': '@Article{Schapire1998ImprovedBA,\n author = {R. Schapire and Y. Singer},\n journal = {Machine Learning},\n pages = {297-336},\n title = {Improved Boosting Algorithms Using Confidence-rated Predictions},\n volume = {37},\n year = {1998}\n}\n'}","[{'authorId': '1716301', 'name': 'R. Schapire'}, {'authorId': '1740765', 'name': 'Y. Singer'}]"
221,151fc3935a2a994c89d4261050216478fb865f40,Creating Personalities for Synthetic Actors: Towards Autonomous Personality Agents,"Why to create personalities for synthetic actors -- Dressing virtual humans -- Autonomous virtual actors based on virtual sensors -- Towards personalities for animated agents with reactive and planning behaviors -- IMPROV: A system for real-time animation of behavior-based interactive synthetic actors -- Multi-level control for animated autonomous agents: Do the right thing... Oh, not that... -- Tools for an interactive virtual cinema -- Acting in character -- Some requirements and approaches for natural language in a believable agent -- Personality parameters and programs -- What sort of control system is able to have a personality? -- Personalities for synthetic actors: Current issues and some perspectives -- Personalities for synthetic actors: A bibliography.",1997.0,0.0,115.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Petta1997CreatingPF,\n author = {P. Petta and R. Trappl},\n title = {Creating Personalities for Synthetic Actors: Towards Autonomous Personality Agents},\n year = {1997}\n}\n'}","[{'authorId': '1764052', 'name': 'P. Petta'}, {'authorId': '1691580', 'name': 'R. Trappl'}]"
222,1522f7812b2c7c183abcabe8e7f6710e048b3d8e,A Social Robot as a Card Game Player,"
 
 This paper describes a social robotic game player that is able to successfully play a team card game called Sueca. The question we will address in this paper is: how can we build a social robot player that is able to balance its ability to play the card game with natural and social behaviours towards its partner and its opponents. The first challenge we faced concerned the development of a competent artificial player for a hidden information game, whose time constraint is the average human decision time. To accomplish this requirement, the Perfect Information Monte Carlo (PIMC) algorithm was used. Further, we have performed an analysis of this algorithm's possible parametrizations for games trees that cannot be fully explored in a reasonable amount of time with a MinMax search. Additionally, given the nature of the Sueca game, such robotic player must master the social interactions both as a partner and as an opponent. To do that, an emotional agent framework (FAtiMA) was used to build the emotional and social behaviours of the robot. At each moment, the robot not only plays competitively but also appraises the situation and responds emotionally in a natural manner. To test the approach, we conducted a user study and compared the levels of trust participants attributed to the robots and to human partners. Results have shown that the robot team exhibited a winning rate of 60%. Concerning the social aspects, the results also showed that human players increased their trust in the robot as their game partners (similar to the way to the trust levels change towards human partners).
 
",2021.0,15.0,29.0,True,"{'url': 'https://ojs.aaai.org/index.php/AIIDE/article/download/12936/12784', 'status': None}",{'pages': '23-29'},"{'bibtex': '@Inproceedings{Correia2021ASR,\n author = {Filipa Correia and Patrícia Alves-Oliveira and T. Ribeiro and Francisco S. Melo and A. Paiva},\n pages = {23-29},\n title = {A Social Robot as a Card Game Player},\n year = {2021}\n}\n'}","[{'authorId': '144106225', 'name': 'Filipa Correia'}, {'authorId': '1401670338', 'name': 'Patrícia Alves-Oliveira'}, {'authorId': '145856842', 'name': 'T. Ribeiro'}, {'authorId': '145125979', 'name': 'Francisco S. Melo'}, {'authorId': '115420343', 'name': 'A. Paiva'}]"
223,154387fe1347664ed7433156f19f9ea29b0ceb33,The role of anterior insular cortex in social emotions,,2010.0,128.0,481.0,True,"{'url': 'https://www.zora.uzh.ch/id/eprint/39674/12/ZORA_NL_39674.pdf', 'status': None}","{'volume': '214', 'pages': '579-591', 'name': 'Brain Structure and Function'}","{'bibtex': '@Article{Lamm2010TheRO,\n author = {C. Lamm and T. Singer},\n journal = {Brain Structure and Function},\n pages = {579-591},\n title = {The role of anterior insular cortex in social emotions},\n volume = {214},\n year = {2010}\n}\n'}","[{'authorId': '2304832', 'name': 'C. Lamm'}, {'authorId': '47272511', 'name': 'T. Singer'}]"
224,1566cf20e2ba91ca8857c30083419bf7c127094b,Facial action coding system: a technique for the measurement of facial movement,,1978.0,0.0,4217.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1978FacialAC,\n author = {P. Ekman and Wallace V. Friesen},\n title = {Facial action coding system: a technique for the measurement of facial movement},\n year = {1978}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}]"
227,156a361e5a0ab5378b3057a6408d49eac36b97f0,"Emotion and narrative fiction: Interactive influences before, during, and after reading","Emotions are central to the experience of literary narrative fiction. Affect and mood can influence what book people choose, based partly on whether their goal is to change or maintain their current emotional state. Once having chosen a book, the narrative itself acts to evoke and transform emotions, both directly through the events and characters depicted and through the cueing of emotionally valenced memories. Once evoked by the story, these emotions can in turn influence a person's experience of the narrative. Lastly, emotions experienced during reading may have consequences after closing the covers of a book. This article reviews the current state of empirical research for each of these stages, providing a snapshot of what is known about the interaction between emotions and literary narrative fiction. With this, we can begin to sketch the outlines of what remains to be discovered.",2011.0,89.0,292.0,False,,"{'volume': '25', 'pages': '818 - 833', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Mar2011EmotionAN,\n author = {R. Mar and K. Oatley and Maja Djikic and J. Mullin},\n journal = {Cognition and Emotion},\n pages = {818 - 833},\n title = {Emotion and narrative fiction: Interactive influences before, during, and after reading},\n volume = {25},\n year = {2011}\n}\n'}","[{'authorId': '1829071', 'name': 'R. Mar'}, {'authorId': '2297721', 'name': 'K. Oatley'}, {'authorId': '3646643', 'name': 'Maja Djikic'}, {'authorId': '4044114', 'name': 'J. Mullin'}]"
228,15706a499f8cab8ea7db939a2a6d77145e7e241a,Dissemination of Exposure Therapy in Clinical Practice: How to Handle the Barriers?,,2012.0,47.0,9.0,False,,"{'volume': '', 'pages': '23-34', 'name': ''}","{'bibtex': '@Inproceedings{Neudeck2012DisseminationOE,\n author = {P. Neudeck and F. Einsle},\n pages = {23-34},\n title = {Dissemination of Exposure Therapy in Clinical Practice: How to Handle the Barriers?},\n year = {2012}\n}\n'}","[{'authorId': '38039926', 'name': 'P. Neudeck'}, {'authorId': '2072858074', 'name': 'F. Einsle'}]"
229,157ce1b1fb97dbb1c09a60f8907a5ccfe9b1fd04,Effects of Embodiment and Gestures on Social Interaction in Drumming Games with a Humanoid Robot,"We present results from an empirical study investigating the effect of embodiment and minimal gestures in an interactive drumming game consisting of an autonomous child-sized humanoid robot (KASPAR) playing with child participants. In this study, each participant played three games with a humanoid robot that played a drum whilst simultaneously making (or not making) head gestures. The three games included the participant interacting with the real robot (physical embodiment condition), interacting with a hidden robot when only the sound of the robot is heard (disembodiment condition; note that the term 'disembodiment' is used in this paper specifically to refer to an experimental condition where a physical robot produces the sound cues, but is not visible to the participants), or interacting with a real-time image of the robot (virtual embodiment condition). We used a mixed design where repeated measures were used to evaluate embodiment effects and independent-groups measures were used to study the gestures effects. Data from the implementation of a human–robot interaction experiment with 66 children are presented, and statistically analyzed in terms of participants' subjective experiences and drumming performance of the human–robot pair. The subjective experiences showed significant differences for the different embodiment conditions when gestures were used in terms of enjoyment of the game, and perceived intelligence and appearance of the robot. The drumming performance also differed significantly within the embodiment conditions and the presence of gestures increased these differences significantly. The presence of a physical, embodied robot enabled more interaction, better drumming and turn-taking, as well as enjoyment of the interaction, especially when the robot used gestures.",2009.0,61.0,120.0,False,,"{'volume': '23', 'pages': '1951 - 1996', 'name': 'Advanced Robotics'}","{'bibtex': '@Article{Kose-Bagci2009EffectsOE,\n author = {H. Kose-Bagci and E. Ferrari and K. Dautenhahn and D. Syrdal and Chrystopher L. Nehaniv},\n journal = {Advanced Robotics},\n pages = {1951 - 1996},\n title = {Effects of Embodiment and Gestures on Social Interaction in Drumming Games with a Humanoid Robot},\n volume = {23},\n year = {2009}\n}\n'}","[{'authorId': '1399283111', 'name': 'H. Kose-Bagci'}, {'authorId': '2083388', 'name': 'E. Ferrari'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '1700812', 'name': 'D. Syrdal'}, {'authorId': '1718528', 'name': 'Chrystopher L. Nehaniv'}]"
230,15870c7621a87c41cd8d087bbdc28ed1d9503919,The Mild Behavioral Impairment Checklist (MBI-C): A Rating Scale for Neuropsychiatric Symptoms in Pre-Dementia Populations.,"BACKGROUND
Mild behavioral impairment (MBI) is a construct that describes the emergence at ≥50 years of age of sustained and impactful neuropsychiatric symptoms (NPS), as a precursor to cognitive decline and dementia. MBI describes NPS of any severity, which are not captured by traditional psychiatric nosology, persist for at least 6 months, and occur in advance of or in concert with mild cognitive impairment. While the detection and description of MBI has been operationalized in the International Society to Advance Alzheimer's Research and Treatment - Alzheimer's Association (ISTAART-AA) research diagnostic criteria, there is no instrument that accurately reflects MBI as described.


OBJECTIVE
To develop an instrument based on ISTAART-AA MBI criteria.


METHODS
Eighteen subject matter experts participated in development using a modified Delphi process. An iterative process ensured items reflected the five MBI domains of 1) decreased motivation; 2) emotional dysregulation; 3) impulse dyscontrol; 4) social inappropriateness; and 5) abnormal perception or thought content. Instrument language was developed a priori to pertain to non-demented functionally independent older adults.


RESULTS
We present the Mild Behavioral Impairment Checklist (MBI-C), a 34-item instrument, which can easily be completed by a patient, close informant, or clinician.


CONCLUSION
The MBI-C provides the first measure specifically developed to assess the MBI construct as explicitly described in the criteria. Its utility lies in MBI case detection, and monitoring the emergence of MBI symptoms and domains over time. Studies are required to determine the prognostic value of MBI for dementia development, and for predicting different dementia subtypes.",2017.0,47.0,251.0,True,"{'url': 'https://europepmc.org/articles/pmc5652315?pdf=render', 'status': None}","{'volume': '56 3', 'pages': '\n          929-938\n        ', 'name': ""Journal of Alzheimer's disease : JAD""}","{'bibtex': ""@Article{Ismail2017TheMB,\n author = {Z. Ismail and L. Agüera-Ortiz and H. Brodaty and Alicja Cieslak and J. Cummings and Corinne E. Fischer and S. Gauthier and Y. Geda and N. Herrmann and J. Kanji and K. Lanctôt and David S. Miller and M. Mortby and C. Onyike and P. Rosenberg and Eric E. Smith and Gwenn S. Smith and D. Sultzer and C. Lyketsos},\n journal = {Journal of Alzheimer's disease : JAD},\n pages = {\n          929-938\n        },\n title = {The Mild Behavioral Impairment Checklist\xa0(MBI-C): A Rating Scale for\xa0Neuropsychiatric Symptoms in\xa0Pre-Dementia Populations.},\n volume = {56 3},\n year = {2017}\n}\n""}","[{'authorId': '2005479', 'name': 'Z. Ismail'}, {'authorId': '114185955', 'name': 'L. Agüera-Ortiz'}, {'authorId': '2914632', 'name': 'H. Brodaty'}, {'authorId': '40277466', 'name': 'Alicja Cieslak'}, {'authorId': '2084085', 'name': 'J. Cummings'}, {'authorId': '4004697', 'name': 'Corinne E. Fischer'}, {'authorId': '32720034', 'name': 'S. Gauthier'}, {'authorId': '3671316', 'name': 'Y. Geda'}, {'authorId': '144528209', 'name': 'N. Herrmann'}, {'authorId': '31458208', 'name': 'J. Kanji'}, {'authorId': '4797664', 'name': 'K. Lanctôt'}, {'authorId': '49971136', 'name': 'David S. Miller'}, {'authorId': '3035849', 'name': 'M. Mortby'}, {'authorId': '8474541', 'name': 'C. Onyike'}, {'authorId': '144889112', 'name': 'P. Rosenberg'}, {'authorId': '144765494', 'name': 'Eric E. Smith'}, {'authorId': '116848569', 'name': 'Gwenn S. Smith'}, {'authorId': '6007006', 'name': 'D. Sultzer'}, {'authorId': '1901398', 'name': 'C. Lyketsos'}]"
231,15b9f61decf351ec2bbf8027010814d31cad3449,Head-gestures mirroring detection in dyadic social interactions with computer vision-based wearable devices,,2016.0,78.0,23.0,False,,"{'volume': '175', 'pages': '866-876', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Terven2016HeadgesturesMD,\n author = {Juan R. Terven and B. Raducanu and M. Meza-de-Luna and Joaquin Salas},\n journal = {Neurocomputing},\n pages = {866-876},\n title = {Head-gestures mirroring detection in dyadic social interactions with computer vision-based wearable devices},\n volume = {175},\n year = {2016}\n}\n'}","[{'authorId': '3161727', 'name': 'Juan R. Terven'}, {'authorId': '3262395', 'name': 'B. Raducanu'}, {'authorId': '1409474833', 'name': 'M. Meza-de-Luna'}, {'authorId': '143861895', 'name': 'Joaquin Salas'}]"
232,15c8f2332cebc1b4d5f07083e3f586508747b65b,Verification & validation of an agent-based forest fire simulation model,"In this paper, we present the verification and validation of an agent-based model of forest fires. We use a combination of a Virtual Overlay Multi-Agent System (VOMAS) validation scheme with Fire Weather Index (FWI) to validate the forest fire Simulation. FWI is based on decades of real forest fire data and is now regarded as a standard index for fire probability with wide usage across Canada, New Zealand and Australia. VOMAS approach allows for flexible validation of agent-based simulation models. In the current work, it is used in the form of a simulation of a randomly deployed Wireless Sensor Network for forest monitoring. Here, each virtual ""sensor"" agent uses FWI to calculate fire probability and compares it with the simulation model. VOMAS verification and validation methodology for agent-based models allows for interactive design of Agent-Based Models involving both the Simulation Specialists as well as the Subject Matter Experts. The presented simulation model also uses weather parameters such as wind speed, rain, snow to calculate Indices such as Fire Weather Index (FWI), Build Up Index (BUI) and Initial Spread Index (ISI) in real time. We also study the effects of fires on the life of simulated VOMAS sensors. Using extensive simulations, we demonstrate the effectiveness and ease of use of VOMAS based Validation.",2010.0,43.0,36.0,False,,{'pages': '1'},"{'bibtex': '@Inproceedings{Niazi2010VerificationV,\n author = {M. Niazi and Qasim Siddique and A. Hussain and M. Kolberg},\n pages = {1},\n title = {Verification & validation of an agent-based forest fire simulation model},\n year = {2010}\n}\n'}","[{'authorId': '1795560', 'name': 'M. Niazi'}, {'authorId': '2073401', 'name': 'Qasim Siddique'}, {'authorId': '144664815', 'name': 'A. Hussain'}, {'authorId': '1796567', 'name': 'M. Kolberg'}]"
233,15ca9bcd5ff14f0699dde08bac5576796763238e,SRI International,,1982.0,0.0,968.0,False,,,"{'bibtex': '@Inproceedings{Stolcke1982SRII,\n author = {A. Stolcke and K. Ries and N. Coccaro and Elizabeth Shriberg and R. Bates and Dan Jurafsky and P. Taylor and Rachel Martin and C. V. Ess-Dykema and M. Meteer},\n title = {SRI International},\n year = {1982}\n}\n'}","[{'authorId': '1762744', 'name': 'A. Stolcke'}, {'authorId': '1758841', 'name': 'K. Ries'}, {'authorId': '145632116', 'name': 'N. Coccaro'}, {'authorId': '70422141', 'name': 'Elizabeth Shriberg'}, {'authorId': '2057063782', 'name': 'R. Bates'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '122297135', 'name': 'P. Taylor'}, {'authorId': '46776641', 'name': 'Rachel Martin'}, {'authorId': '1403242564', 'name': 'C. V. Ess-Dykema'}, {'authorId': '3227843', 'name': 'M. Meteer'}]"
234,15d0818521234bdfb661945cbff2ebc731d490d3,Can virtual reality exposure therapy gains be generalized to real-life? A meta-analysis of studies applying behavioral assessments.,,2015.0,31.0,331.0,False,,"{'volume': '74', 'pages': '\n          18-24\n        ', 'name': 'Behaviour research and therapy'}","{'bibtex': '@Article{Morina2015CanVR,\n author = {N. Morina and Hiske Ijntema and K. Meyerbröker and P. Emmelkamp},\n journal = {Behaviour research and therapy},\n pages = {\n          18-24\n        },\n title = {Can virtual reality exposure therapy gains be generalized to real-life? A meta-analysis of studies applying behavioral assessments.},\n volume = {74},\n year = {2015}\n}\n'}","[{'authorId': '145500304', 'name': 'N. Morina'}, {'authorId': '6061751', 'name': 'Hiske Ijntema'}, {'authorId': '4257503', 'name': 'K. Meyerbröker'}, {'authorId': '2282500', 'name': 'P. Emmelkamp'}]"
236,15d2cee6ca6838c26bf6d53df4d8ba765b34940e,Cultural Differences in Interpersonal Emotion Regulation,"Cultural differences exist in the use of emotion regulation (ER) strategies, but the focus to date has been on intrapersonal ER strategies such as cognitive reappraisal. An emerging literature highlights the importance of interpersonal ER, which utilizes social cues to facilitate the regulation of emotional states. In cultures that place high value on social interconnectedness as integral to their collectivistic self-construal, including East Asian cultures, interpersonal ER strategies may be particularly effective in reducing negative affect but this has not been previously tested. In this study, two groups comprising East Asian (n = 48) and Western European (n = 38) participants were randomly assigned to receive a priming narration depicting the use of either interpersonal (e.g., social modeling, perspective taking) or intrapersonal (e.g., cognitive reappraisal) ER strategies during a stressful experience. They were then instructed to utilize similar ER strategies in an emotion reactivity task during which they viewed high arousing negative pictorial stimuli while their heart rate (HR), heart rate variability (high frequency power – HF-HRV) and subjective affective states were measured. First we found that the East Asian group reported higher use of interpersonal ER strategies of social modeling and perspective taking in daily life. During the experimental interpersonal prime exposure, the East Asian group showed elevated HF-HRV (relative to baseline) compared to the Western European group, indicating more adaptive ER, but this pattern was not sustained during the reactivity or recovery phases. Instead, the East Asian group demonstrated increased HF-HRV and decreased HR across both prime conditions. The East Asian group also showed greater decreases in positive affect across the course of the experiment. Furthermore, individual differences in social modeling and individualistic self-construal moderated the effect of the ER prime in the East Asian group at trend levels, and main effects for perspective taking and reappraisal were observed in the Western European group. The findings support the notion that engaging in interpersonal ER strategies may be more beneficial for East Asian groups when immediately exposed to a stressful situation, as these strategies are congruent with cultural context and preferences, but our priming methodology may have limited the longer-term benefits.",2019.0,76.0,23.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00999/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Liddell2019CulturalDI,\n author = {B. Liddell and Emma Williams},\n journal = {Frontiers in Psychology},\n title = {Cultural Differences in Interpersonal Emotion Regulation},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '2742204', 'name': 'B. Liddell'}, {'authorId': '2070111205', 'name': 'Emma Williams'}]"
237,15febdbe5e34a230f58040e9f5db776b124b5f2b,SpaceTag: an overlaid virtual system and its applications,"SpaceTag is an object system on which each object called SpaceTag can be accessed only from limited locations and a limited time period. Its applications include entertainment systems, advertisement services, bulletin board systems, and personal communication systems. For one-way communication, they are broadcasted from the server; for two-way communication, users can cut and paste SpaceTags between their portable PCs and the real space. The SpaceTag system is a location-aware information system, as well as an augmented reality system because it attaches information to the real space. However, we categorize it as an overlaid virtual system, because it has no direct link to real objects. It can be realized as a public service without causing drastic change of this society, and without much cost.",1999.0,10.0,53.0,False,,"{'volume': '1', 'pages': '207-212 vol.1', 'name': 'Proceedings IEEE International Conference on Multimedia Computing and Systems'}","{'bibtex': '@Article{Tarumi1999SpaceTagAO,\n author = {H. Tarumi and K. Morishita and M. Nakao and Y. Kambayashi},\n journal = {Proceedings IEEE International Conference on Multimedia Computing and Systems},\n pages = {207-212 vol.1},\n title = {SpaceTag: an overlaid virtual system and its applications},\n volume = {1},\n year = {1999}\n}\n'}","[{'authorId': '1692859', 'name': 'H. Tarumi'}, {'authorId': '1989890', 'name': 'K. Morishita'}, {'authorId': '2138792', 'name': 'M. Nakao'}, {'authorId': '1736726', 'name': 'Y. Kambayashi'}]"
238,1602763cc31b9de3fdb007c0705b1b69a1184721,Adapting Software with Affective Computing: A Systematic Review,"Strategies aimed at keeping the user's interest in using computer applications are being studied to provide greater user engagement, and can influence how people interact with computers. One of the approaches that can promote user engagement is Affective Computing (AC), based on the premise of recognizing the user's emotional state and adjusting the computer application to respond to such state in real-time. Although it is a relatively new area, over the past few years many research works have investigated the use of AC in various activities and objectives. To provide an overview on the use of AC in computer applications, this article presents a systematic literature review based on available articles on the main scientific databases of the Computer Science area. The main contribution of this review is the analysis of different types of applications. Based on the 58 articles analyzed, the main emotion recognition techniques and approaches to the adaptation of computer applications, as well as the limitations and challenges to be overcome were compiled. Our conclusions present the limitations and challenges still to be overcome in the area of automatic adaptation of computer applications by means of AC.",2019.0,0.0,35.0,False,,"{'volume': '12', 'pages': '883-899', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Aranha2019AdaptingSW,\n author = {R. V. Aranha and C. G. Corrêa and Fátima L. S. Nunes},\n journal = {IEEE Transactions on Affective Computing},\n pages = {883-899},\n title = {Adapting Software with Affective Computing: A Systematic Review},\n volume = {12},\n year = {2019}\n}\n'}","[{'authorId': '9190345', 'name': 'R. V. Aranha'}, {'authorId': '35087278', 'name': 'C. G. Corrêa'}, {'authorId': '143753143', 'name': 'Fátima L. S. Nunes'}]"
239,1612a6053c7f017dd0897d26971a1dd9cd1bebc1,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",2018.0,30.0,164.0,True,"{'url': 'https://arxiv.org/pdf/1810.12541', 'status': None}","{'pages': '4303-4309', 'name': '2019 International Conference on Robotics and Automation (ICRA)'}","{'bibtex': '@Article{Yoon2018RobotsLS,\n author = {Youngwoo Yoon and Woo-Ri Ko and Minsu Jang and Jaeyeon Lee and Jaehong Kim and Geehyuk Lee},\n journal = {2019 International Conference on Robotics and Automation (ICRA)},\n pages = {4303-4309},\n title = {Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots},\n year = {2018}\n}\n'}","[{'authorId': '145215929', 'name': 'Youngwoo Yoon'}, {'authorId': '38108552', 'name': 'Woo-Ri Ko'}, {'authorId': '145416765', 'name': 'Minsu Jang'}, {'authorId': None, 'name': 'Jaeyeon Lee'}, {'authorId': '1684726', 'name': 'Jaehong Kim'}, {'authorId': '1717371', 'name': 'Geehyuk Lee'}]"
240,1636d468d11873743d046ce57a9547fb35075daf,Affective interaction: How emotional agents affect users,,2009.0,50.0,254.0,False,,"{'volume': '67', 'pages': '755-776', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Beale2009AffectiveIH,\n author = {R. Beale and C. Creed},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {755-776},\n title = {Affective interaction: How emotional agents affect users},\n volume = {67},\n year = {2009}\n}\n'}","[{'authorId': '144189909', 'name': 'R. Beale'}, {'authorId': '3134697', 'name': 'C. Creed'}]"
243,16692e28df1e81080755d6a99b604fe225c13107,Simulation of the Dynamics of Nonplayer Characters' Emotions and Social Relations in Games,"One of the main challenges faced by the video game industry is to give life to believable nonplayer characters (NPCs). Research shows that emotions play a key role in determining the behavior of individuals. In order to improve the believability of NPCs' behavior, we propose in this paper a model of the dynamics of emotions taking into account the personality and the social relations of the character. First, we present work from the literature on emotions, personality, and social relations in computer science and in human and social sciences. We focus on the influence of personality on the triggering of emotions, and the influence of emotions on the dynamics of social relations. Based on this work, we propose a dynamic model of the socioemotional state and its implementation as part of a tool for game programmers. This tool aims at the simulation of the evolution of emotions and social relations of NPCs based on their personality and roles.",2009.0,59.0,86.0,False,,"{'volume': '1', 'pages': '281-297', 'name': 'IEEE Transactions on Computational Intelligence and AI in Games'}","{'bibtex': ""@Article{Ochs2009SimulationOT,\n author = {M. Ochs and N. Sabouret and V. Corruble},\n journal = {IEEE Transactions on Computational Intelligence and AI in Games},\n pages = {281-297},\n title = {Simulation of the Dynamics of Nonplayer Characters' Emotions and Social Relations in Games},\n volume = {1},\n year = {2009}\n}\n""}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1731432', 'name': 'N. Sabouret'}, {'authorId': '1841984', 'name': 'V. Corruble'}]"
246,16b07a6beae0d0b9b81e016128d5c87e4c6121e4,Virtual environments and autism: a developmental psychopathological approach,"Individuals with autism spectrum disorders supposedly have an affinity with information and communication technology (ICT), making it an ideally suited media for this population. Virtual environments (VEs) ‐ both two-dimensional and immersive ‐ represent a particular kind of ICT that might be of special benefit. Specifically, this paper discusses the importance of psychological theory for VE designed for this population. I describe the contribution that different theories of autism (e.g., theory of mind, executive function, weak central coherence theory) have made and can make, as well as the potential of other non-autism-specific theories (e.g., embodied cognition). These technologies not only illuminate our understanding of autism, but they can also be used to develop new technologies for people without autism. So, as well as being an area of specialism, I argue that VE research in autism has extended ‐ and will go onto ‐ the boundaries of human‐computer interaction more generally. This is because autism provides a unique window into human social communication and learning. Further, this field offers a chance for better inclusivity for individuals with autism within a digital society.",2013.0,104.0,63.0,False,,"{'volume': '29', 'pages': '334-347', 'name': 'J. Comput. Assist. Learn.'}","{'bibtex': '@Article{Rajendran2013VirtualEA,\n author = {Gnanathusharan Rajendran},\n journal = {J. Comput. Assist. Learn.},\n pages = {334-347},\n title = {Virtual environments and autism: a developmental psychopathological approach},\n volume = {29},\n year = {2013}\n}\n'}","[{'authorId': '34939513', 'name': 'Gnanathusharan Rajendran'}]"
247,16c9368a9874f1825a140578335be72360f7725a,Vocal and Facial Imitation of Humans Interacting with Virtual Agents,"Socially-aware virtual agents may guide the design and deployment of future computing systems. This paper addresses unconscious affect recognition in the context of social interaction between agents and humans. An experiment is performed in which participants interact visually and verbally with virtual embodied agents. During the interaction, both the vocal pitch and the affective facial expressions of the agent are manipulated and the consecutive vocal and facial expressions of the participants are registered. Manual and computational analyses of the expressions reveal vocal and facial imitation as a sign of unconscious affect recognition and social engagement.",2013.0,32.0,8.0,False,,"{'pages': '815-820', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Mattheij2013VocalAF,\n author = {R.J.H. Mattheij and M. Postma and E. Postma},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {815-820},\n title = {Vocal and Facial Imitation of Humans Interacting with Virtual Agents},\n year = {2013}\n}\n'}","[{'authorId': '153696301', 'name': 'R.J.H. Mattheij'}, {'authorId': '36365492', 'name': 'M. Postma'}, {'authorId': '1729457', 'name': 'E. Postma'}]"
248,1711b34c4c4596ce800da57e1c06dc59eef790ea,Reducing Risk of Rollover in Curve for Heavy-Duty Vehicles with an Agent-Based Advanced Driver Assistance System,"In Brazil, highway transportation is responsible for 58% of cargo transport. A relevant problem associated to cargo transport are the accidents. Incompatible speed and fatigue were pointed out as main causes of accidents. The adoption of an advanced driver assistance system (ADAS) for anticipating warning of overspeed for a curve may reduce rollover risks. In other words, it would mitigate the problem by helping the driver to maintain the vehicle in a safe speed, through customized alerts just in time that allow the driver to take corrective maneuvers in case of unsafe state. In this paper, we present an agent-based approach to address this problem.",2016.0,17.0,5.0,False,,"{'pages': '65-72', 'name': '2016 IEEE International Conference on Computer and Information Technology (CIT)'}","{'bibtex': '@Article{Tiengo2016ReducingRO,\n author = {Willy Tiengo and E. Costa and J. Fechine},\n journal = {2016 IEEE International Conference on Computer and Information Technology (CIT)},\n pages = {65-72},\n title = {Reducing Risk of Rollover in Curve for Heavy-Duty Vehicles with an Agent-Based Advanced Driver Assistance System},\n year = {2016}\n}\n'}","[{'authorId': '1996733', 'name': 'Willy Tiengo'}, {'authorId': '1723140', 'name': 'E. Costa'}, {'authorId': '3184282', 'name': 'J. Fechine'}]"
249,1762ba0802e0540cb55c335850119836c5cdc1ff,Towards modeling embodied conversational agent character profiles using appraisal theory predictions in expression synthesis,,2009.0,21.0,36.0,False,,"{'volume': '30', 'pages': '58-64', 'name': 'Applied Intelligence'}","{'bibtex': '@Article{Malatesta2009TowardsME,\n author = {Lori Malatesta and A. Raouzaiou and K. Karpouzis and S. Kollias},\n journal = {Applied Intelligence},\n pages = {58-64},\n title = {Towards modeling embodied conversational agent character profiles using appraisal theory predictions in expression synthesis},\n volume = {30},\n year = {2009}\n}\n'}","[{'authorId': '2185181', 'name': 'Lori Malatesta'}, {'authorId': '3346592', 'name': 'A. Raouzaiou'}, {'authorId': '1715144', 'name': 'K. Karpouzis'}, {'authorId': '1707243', 'name': 'S. Kollias'}]"
250,1773d10515f6c7010fe6f1e5cfaa2e9dcfefc724,Embodiment in conversational interfaces: Rea,"In this paper, we argue for embodied corrversational charactersas the logical extension of the metaphor of human - computerinteraction as a conversation. We argue that the only way to fullymodel the richness of human I&+ to-face communication is torely on conversational analysis that describes sets ofconversational behaviors as fi~lfilling conversational functions,both interactional and propositional. We demonstrate how toimplement this approach in Rea, an embodied conversational agentthat is capable of both multimodal input understanding and outputgeneration in a limited application domain. Rea supports bothsocial and task-oriented dialogue. We discuss issues that need tobe addressed in creating embodied conversational agents, anddescribe the architecture of the Rea interface.",1999.0,36.0,585.0,False,,{'pages': '520-527'},"{'bibtex': '@Inproceedings{Cassell1999EmbodimentIC,\n author = {Justine Cassell and T. Bickmore and M. Billinghurst and L. Campbell and K. Chang and H. Vilhjálmsson and Hao Yan},\n pages = {520-527},\n title = {Embodiment in conversational interfaces: Rea},\n year = {1999}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}, {'authorId': '2053167846', 'name': 'L. Campbell'}, {'authorId': '2107804338', 'name': 'K. Chang'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '2116562196', 'name': 'Hao Yan'}]"
251,1781ecf58d2dc897ae8f5bbeca7c547bd6a09658,Virtual reality training applications for the mining industry,"Virtual reality is a rapidly growing technology which utilises the ever-increasing power of computers to simulate real-world and imaginary environments and situations with a high degree of realism and interactiveness. Safety in the South African mining industry is a vital issue. On average, one worker dies every working day, and about 16 are injured in mine-related accidents. Inadequate or insufficient training is often cited as a root cause for many mining fatalities. However, training outside the direct working environment provides only limited real-life opportunities and may fail to make a significant impact within the tense working environment itself. Virtual reality-based training tools can, by contrast, provide simulated exposure to real-world working conditions without the associated risks. This paper discusses contextual requirements and constraints for virtual reality application development, applied to safety training in mines. The results of the contextual analysis were applied to the design and development of several prototypes of VR training systems. The paper also reports on how realism can be enhanced in simulation training systems.",2009.0,24.0,140.0,True,"{'url': 'https://uir.unisa.ac.za/bitstream/10500/13166/1/Afrigraph%2009.pdf', 'status': None}",{'pages': '53-63'},"{'bibtex': '@Inproceedings{Wyk2009VirtualRT,\n author = {E. V. Wyk and R. D. Villiers},\n pages = {53-63},\n title = {Virtual reality training applications for the mining industry},\n year = {2009}\n}\n'}","[{'authorId': '2813669', 'name': 'E. V. Wyk'}, {'authorId': '2567639', 'name': 'R. D. Villiers'}]"
253,179b4994253174a9122fecfa9155935ef2d169b7,A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces,"The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces.",2007.0,70.0,225.0,True,"{'url': 'http://vhil.stanford.edu/pubs/2007/yee-meta.pdf', 'status': None}",{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Yee2007AMO,\n author = {N. Yee and J. Bailenson and K. Rickertsen},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces},\n year = {2007}\n}\n'}","[{'authorId': '38811484', 'name': 'N. Yee'}, {'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '1693115', 'name': 'K. Rickertsen'}]"
254,17ab4f6a0cd5c275ca0aab4a8d3ab60704ec3b6a,Gaze and eye contact: a research review.,"Research on gaze and eye contact was organized within the framework of Patterson's (1982) sequential functional model of nonverbal exchange. Studies were reviewed showing how gaze functions to (a) provide information, (b) regulate interaction, (c) express intimacy, (d) exercise social control, and (",1986.0,326.0,1383.0,False,,"{'volume': '100 1', 'pages': '\n          78-100\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Kleinke1986GazeAE,\n author = {C. Kleinke},\n journal = {Psychological bulletin},\n pages = {\n          78-100\n        },\n title = {Gaze and eye contact: a research review.},\n volume = {100 1},\n year = {1986}\n}\n'}","[{'authorId': '4215358', 'name': 'C. Kleinke'}]"
255,17b8edb23479e3f0f621b3f0ac72d4483da65670,Real-time dynamic wrinkles,"This paper proposes a new method for designing dynamic wrinkles that appear and disappear according to the underlying deformation of tissues. The user positions and orients wrinkling tools on a mesh. During animation, geometric wrinkles are generated in real-time in the regions covered by the tools, mimicking resistance to compression of tissues. The wrinkling feature can be added to any existing animation. When the local resolution of the mesh is not sufficient, our tool refines it according to the wrinkle's finest feature. As our results show, the technique can be applied to a variety of situations such as facial expression wrinkles, joint wrinkles or garment wrinkles",2004.0,18.0,75.0,True,"{'url': 'https://hal.inria.fr/inria-00537455/file/larboulette04.pdf', 'status': None}","{'pages': '522-525', 'name': 'Proceedings Computer Graphics International, 2004.'}","{'bibtex': '@Article{Larboulette2004RealtimeDW,\n author = {Caroline Larboulette and Marie-Paule Cani},\n journal = {Proceedings Computer Graphics International, 2004.},\n pages = {522-525},\n title = {Real-time dynamic wrinkles},\n year = {2004}\n}\n'}","[{'authorId': '1967184', 'name': 'Caroline Larboulette'}, {'authorId': '1710314', 'name': 'Marie-Paule Cani'}]"
256,17b9a770ad1a5def6e0f85da01a4bd4f3cf790e6,The Origins and Social Significance of Empathy-Related Responding. A Review of Empathy and Moral Development: Implications for Caring and Justice by M. L. Hoffman,,2001.0,100.0,90.0,False,,"{'volume': '14', 'pages': '95-120', 'name': 'Social Justice Research'}","{'bibtex': '@Article{Eisenberg2001TheOA,\n author = {N. Eisenberg and A. Morris},\n journal = {Social Justice Research},\n pages = {95-120},\n title = {The Origins and Social Significance of Empathy-Related Responding. A Review of Empathy and Moral Development: Implications for Caring and Justice by M. L. Hoffman},\n volume = {14},\n year = {2001}\n}\n'}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}, {'authorId': '2041146', 'name': 'A. Morris'}]"
257,17cd97086715c5bb266939108431e114f48b4b20,Emotion Regulation in Adulthood: Timing Is Everything,"Emotions seem to come and go as they please. However, we actually hold considerable sway over our emotions: We influence which emotions we have and how we experience and express these emotions. The process model of emotion regulation described here suggests that how we regulate our emotions matters. Regulatory strategies that act early in the emotion-generative process should have quite different outcomes than strategies that act later. This review focuses on two widely used strategies for down-regulating emotion. The first, reappraisal, comes early in the emotion-generative process. It consists of changing how we think about a situation in order to decrease its emotional impact. The second, suppression, comes later in the emotion-generative process. It involves inhibiting the outward signs of emotion. Theory and research suggest that reappraisal is more effective than suppression. Reappraisal decreases the experience and behavioral expression of emotion, and has no impact on memory. By contrast, suppression decreases behavioral expression, but fails to decrease the experience of emotion, and actually impairs memory. Suppression also increases physiological responding in both the suppressors and their social partners.",2001.0,13.0,52.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mellers2001EmotionRI,\n author = {A. Mellers},\n title = {Emotion Regulation in Adulthood: Timing Is Everything},\n year = {2001}\n}\n'}","[{'authorId': '112991450', 'name': 'A. Mellers'}]"
258,17d429b405a0951ebf3c729570a476977e412000,#MeTooMaastricht: Building a chatbot to assist survivors of sexual harassment,,2019.0,25.0,16.0,True,"{'url': 'https://arxiv.org/pdf/1909.02809', 'status': None}",{'pages': '503-521'},"{'bibtex': '@Inproceedings{Bauer2019MeTooMaastrichtBA,\n author = {T. Bauer and Emre Devrim and Misha Glazunov and William Lopez Jaramillo and Balaganesh Mohan and Gerasimos Spanakis},\n pages = {503-521},\n title = {#MeTooMaastricht: Building a chatbot to assist survivors of sexual harassment},\n year = {2019}\n}\n'}","[{'authorId': '48079792', 'name': 'T. Bauer'}, {'authorId': '1388561389', 'name': 'Emre Devrim'}, {'authorId': '1388561328', 'name': 'Misha Glazunov'}, {'authorId': '1388561303', 'name': 'William Lopez Jaramillo'}, {'authorId': '152667007', 'name': 'Balaganesh Mohan'}, {'authorId': '3266578', 'name': 'Gerasimos Spanakis'}]"
259,17e1642976544ec8ed2d84e7f3de74b257197f71,MMZ: A Study on the Implementation of Mathematical Game-based Learning Tool,"— Mathematic has always been one of the hardest subject to be learnt during school. This is the very same issue that student have been facing no matter the level of education that they are in, and this is the reason why Math Maze Zone or also known as MMZ had been developed. MMZ is a mathematical game-based learning tool for primary school students to help them prepare for their final examination for the mathematics subject. The proposed game will consist of mathematical questions and the game design will be focusing on a maze where user will have to search for a way out from the maze while going through the checkpoint within the maze. The checkpoint will consist of mathematical questions and when user answered correctly, they will be able to continue their journey to explore the maze. MMZ focused on 1 chapter only for now which is Chapter 8: Space and Shape. Although the game only consists of one-chapter, primary school students can play the game to enhance their knowledge and to help them to be more engaged with mathematics subject by playing the game. The results will be taken from the perspective of adult who have close relationship with standard six students. Five main sections will also be identified along with MMZ to ensure getting a good result.",2023.0,18.0,2.0,True,"{'url': 'http://thesai.org/Downloads/Volume14No1/Paper_25-MMZ_A_Study_on_the_Implementation_of_Mathematical_Game.pdf', 'status': None}",{'name': 'International Journal of Advanced Computer Science and Applications'},"{'bibtex': '@Article{Sulaiman2023MMZAS,\n author = {Nur Syaheera Binti Sulaiman and H. Sulaiman and Nor Saradatul Akmar Zulkifli and Tuty Asmawanty Binti Abdul Kadir},\n journal = {International Journal of Advanced Computer Science and Applications},\n title = {MMZ: A Study on the Implementation of Mathematical Game-based Learning Tool},\n year = {2023}\n}\n'}","[{'authorId': '2204220791', 'name': 'Nur Syaheera Binti Sulaiman'}, {'authorId': '1831838', 'name': 'H. Sulaiman'}, {'authorId': '80580067', 'name': 'Nor Saradatul Akmar Zulkifli'}, {'authorId': '2204131866', 'name': 'Tuty Asmawanty Binti Abdul Kadir'}]"
260,17e5f11f32f9de8263ea3fed72f677de0bd9ebed,Measuring individual differences in empathy: Evidence for a multidimensional approach.,To facilitate a multidimensional approach to empathy the Interpersonal Reactivity Index (IRI) includes 4 subscales: Perspective-Taking (PT) Fantasy (FS) Empathic Concern (EC) and Personal Distress (PD). The aim of the present study was to establish the convergent and discriminant validity of these 4 subscales. Hypothesized relationships among the IRI subscales between the subscales and measures of other psychological constructs (social functioning self-esteem emotionality and sensitivity to others) and between the subscales and extant empathy measures were examined. Study subjects included 677 male and 667 female students enrolled in undergraduate psychology classes at the University of Texas. The IRI scales not only exhibited the predicted relationships among themselves but also were related in the expected manner to other measures. Higher PT scores were consistently associated with better social functioning and higher self-esteem; in contrast Fantasy scores were unrelated to these 2 characteristics. High EC scores were positively associated with shyness and anxiety but negatively linked to egotism. The most substantial relationships in the study involved the PD scale. PD scores were strongly linked with low self-esteem and poor interpersonal functioning as well as a constellation of vulnerability uncertainty and fearfulness. These findings support a multidimensional approach to empathy by providing evidence that the 4 qualities tapped by the IRI are indeed separate constructs each related in specific ways to other psychological measures.,1983.0,26.0,8517.0,False,,"{'volume': '44', 'pages': '113-126', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Davis1983MeasuringID,\n author = {Mark H. Davis},\n journal = {Journal of Personality and Social Psychology},\n pages = {113-126},\n title = {Measuring individual differences in empathy: Evidence for a multidimensional approach.},\n volume = {44},\n year = {1983}\n}\n'}","[{'authorId': '47994338', 'name': 'Mark H. Davis'}]"
261,17e8741ef94522e9a67dc07fcca887ff93ddf249,Atypical Face Gaze in Autism,"An eye-tracking study of face and object recognition was conducted to clarify the character of face gaze in autistic spectrum disorders. Experimental participants were a group of individuals diagnosed with Asperger's disorder or high-functioning autistic disorder according to their medical records and confirmed by the Autism Diagnostic Interview-Revised (ADI-R). Controls were selected on the basis of age, gender, and educational level to be comparable to the experimental group. In order to maintain attentional focus, stereoscopic images were presented in a virtual reality (VR) headset in which the eye-tracking system was installed. Preliminary analyses show impairment in face recognition, in contrast with equivalent and even superior performance in object recognition among participants with autism-related diagnoses, relative to controls. Experimental participants displayed less fixation on the central face than did control-group participants. The findings, within the limitations of the small number of subjects and technical difficulties encountered in utilizing the helmet-mounted display, suggest an impairment in face processing on the part of the individuals in the experimental group. This is consistent with the hypothesis of disruption in the first months of life, a period that may be critical to typical social and cognitive development, and has important implications for selection of appropriate targets of intervention.",2002.0,20.0,108.0,False,,"{'volume': '5 3', 'pages': '\n          213-7\n        ', 'name': 'Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society'}","{'bibtex': '@Article{Trepagnier2002AtypicalFG,\n author = {C. Trepagnier and M. Sebrechts and R. Peterson},\n journal = {Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},\n pages = {\n          213-7\n        },\n title = {Atypical Face Gaze in Autism},\n volume = {5 3},\n year = {2002}\n}\n'}","[{'authorId': '2280143', 'name': 'C. Trepagnier'}, {'authorId': '1718208', 'name': 'M. Sebrechts'}, {'authorId': '2061402704', 'name': 'R. Peterson'}]"
262,17eb496543b004b9c4215ab51380aae2640d5695,On getting a word in edgewise,,1970.0,0.0,940.0,False,,"{'volume': '', 'pages': '567-578', 'name': ''}","{'bibtex': '@Inproceedings{Yngve1970OnGA,\n author = {V. Yngve},\n pages = {567-578},\n title = {On getting a word in edgewise},\n year = {1970}\n}\n'}","[{'authorId': '2928409', 'name': 'V. Yngve'}]"
263,17f2e1534727f84ab6c053d709a0e0b097b18fa8,A Large-Scale Dataset for Motivational Dialogue System: An Application of Natural Language Generation to Mental Health,"Major Depressive Disorder is one of the most serious mental health concerns haunting human kind. While there have been enough global efforts to reduce clinical depression, it is still not sufficient considering the grim statistics in terms of mental health. With the lopsided distribution of Mental Health Professionals (MHPs) to patients, initiatives should be taken to develop automated systems to assist MHPs in combating this grievous mental illness. In this paper, we propose a Virtual Assistant (VA) acting as a first point of contact for depressed or discouraged users. The VA should be capable of generating motivational and affirmative responses, provide users with a safe environment to share thoughts and seek help and advice anonymously. For addressing these multiple aspects, we curate a large-scale dataset, MotiVAte, consisting of dyadic conversations between the depressed user and the VA (imparting hope and motivation). The proposed dataset is evaluated on state of the art generative models. Empirical results both automatic and human evaluation based are reported for the same. To the best of our knowledge, this is the first application of Natural Language Generation to mental health.",2021.0,0.0,9.0,False,,"{'pages': '1-8', 'name': '2021 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Saha2021ALD,\n author = {Tulika Saha and Saraansh Chopra and S. Saha and P. Bhattacharyya and Pankaj Kumar},\n journal = {2021 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {A Large-Scale Dataset for Motivational Dialogue System: An Application of Natural Language Generation to Mental Health},\n year = {2021}\n}\n'}","[{'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '121415924', 'name': 'Saraansh Chopra'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}, {'authorId': '2139310198', 'name': 'Pankaj Kumar'}]"
264,17f5c7411eeeeedf25b0db99a9130aa353aee4ba,Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models,"
 
 We investigate the task of building open domain, conversational dialogue systems based on large dialogue corpora using generative models. Generative models produce system responses that are autonomously generated word-by-word, opening up the possibility for realistic, flexible interactions. In support of this goal, we extend the recently proposed hierarchical recurrent encoder-decoder neural network to the dialogue domain, and demonstrate that this model is competitive with state-of-the-art neural language models and back-off n-gram models. We investigate the limitations of this and similar approaches, and show how its performance can be improved by bootstrapping the learning from a larger question-answer pair corpus and from pretrained word embeddings.
 
",2015.0,54.0,1655.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/9883/9742', 'status': None}",{'pages': '3776-3784'},"{'bibtex': '@Inproceedings{Serban2015BuildingED,\n author = {Iulian Serban and Alessandro Sordoni and Yoshua Bengio and Aaron C. Courville and Joelle Pineau},\n pages = {3776-3784},\n title = {Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models},\n year = {2015}\n}\n'}","[{'authorId': '35224828', 'name': 'Iulian Serban'}, {'authorId': '2041695', 'name': 'Alessandro Sordoni'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}, {'authorId': '1760871', 'name': 'Aaron C. Courville'}, {'authorId': '145134886', 'name': 'Joelle Pineau'}]"
265,1813310dfc92dcadc8bf2fadfb7408a8900169ec,Fixing Our Focus: Training Attention to Regulate Emotion,"Empirical studies have frequently linked negative attentional biases with attentional dysfunction and negative moods; however, far less research has focused on how attentional deployment can be an adaptive strategy that regulates emotional experience. The authors argue that attention may be an invaluable tool for promoting emotion regulation. Accordingly, they present evidence that selective attention to positive information reflects emotion regulation and that regulating attention is a critical component of the emotion regulatory process. Furthermore, attentional regulation can be successfully trained through repeated practice. The authors ultimately propose a model of attention training methodologies integrating attention-dependent emotion regulation strategies with attention networks. Although additional interdisciplinary research is needed to bolster these nascent findings, meditative practices appear to be among the most effective training methodologies in enhancing emotional well-being. Further exploration of the positive and therapeutic qualities of attention warrants the empirical attention of social and personality psychologists.",2011.0,220.0,329.0,True,"{'url': 'https://europepmc.org/articles/pmc2970710?pdf=render', 'status': None}","{'volume': '15', 'pages': '102 - 75', 'name': 'Personality and Social Psychology Review'}","{'bibtex': '@Article{Wadlinger2011FixingOF,\n author = {H. A. Wadlinger and D. Isaacowitz},\n journal = {Personality and Social Psychology Review},\n pages = {102 - 75},\n title = {Fixing Our Focus: Training Attention to Regulate Emotion},\n volume = {15},\n year = {2011}\n}\n'}","[{'authorId': '4797931', 'name': 'H. A. Wadlinger'}, {'authorId': '1919851', 'name': 'D. Isaacowitz'}]"
266,1869846ed84aa27fa243c74ebcfabaeda1ab2070,Neuropsychological Assessment Using Virtual Environments: Enhanced Assessment Technology for Improved Ecological Validity,,2011.0,81.0,74.0,True,"{'url': 'http://psychology.unt.edu/%7Etparsons/PDF/Parsons%28CH13%29_Neuropsychological%20Assessment%20Using%20VR.pdf', 'status': None}","{'volume': '', 'pages': '271-289', 'name': ''}","{'bibtex': '@Inproceedings{Parsons2011NeuropsychologicalAU,\n author = {T. Parsons},\n pages = {271-289},\n title = {Neuropsychological Assessment Using Virtual Environments: Enhanced Assessment Technology for Improved Ecological Validity},\n year = {2011}\n}\n'}","[{'authorId': '145842705', 'name': 'T. Parsons'}]"
267,1879ded191b91edbd35e40aafa7f35867d6e6dcd,MACH: my automated conversation coach,"MACH--My Automated Conversation coacH--is a novel system that provides ubiquitous access to social skills training. The system includes a virtual agent that reads facial expressions, speech, and prosody and responds with verbal and nonverbal behaviors in real time. This paper presents an application of MACH in the context of training for job interviews. During the training, MACH asks interview questions, automatically mimics certain behavior issued by the user, and exhibit appropriate nonverbal behaviors. Following the interaction, MACH provides visual feedback on the user's performance. The development of this application draws on data from 28 interview sessions, involving employment-seeking students and career counselors. The effectiveness of MACH was assessed through a weeklong trial with 90 MIT undergraduates. Students who interacted with MACH were rated by human experts to have improved in overall interview performance, while the ratings of students in control groups did not improve. Post-experiment interviews indicate that participants found the interview experience informative about their behaviors and expressed interest in using MACH in the future.",2013.0,37.0,287.0,True,"{'url': 'https://dspace.mit.edu/bitstream/1721.1/92442/1/Picard_MACH.pdf', 'status': None}",{'name': 'Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing'},"{'bibtex': '@Article{Hoque2013MACHMA,\n author = {Ehsan Hoque and M. Courgeon and Jean-Claude Martin and Bilge Mutlu and Rosalind W. Picard},\n journal = {Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing},\n title = {MACH: my automated conversation coach},\n year = {2013}\n}\n'}","[{'authorId': '144619896', 'name': 'Ehsan Hoque'}, {'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
268,1895ec065c80479c228ca0f0dbfd8c43d874e72f,Designing Trustworthy Product Recommendation Virtual Agents Operating Positive Emotion and Having Copious Amount of Knowledge,"Anthropomorphic agents used in online-shopping need to be trusted by users so that users feel comfortable buying products. In this paper, we propose a model for designing trustworthy agents by assuming two factors of trust, that is, emotion and knowledgeableness perceived. Our hypothesis is that when a user feels happy and perceives an agent as being highly knowledgeable, a high level of trust results between the user and agent. We conducted four experiments with participants to verify this hypothesis by preparing transition operators utilizing emotional contagion and knowledgeable utterances. As a result, we verified that users' internal states transitioned as expected and that the two factors significantly influenced their trust states.",2019.0,40.0,15.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00675/pdf', 'status': 'GOLD'}","{'name': 'Frontiers in Psychology', 'volume': '10'}","{'bibtex': '@Article{Matsui2019DesigningTP,\n author = {T. Matsui and S. Yamada},\n booktitle = {Frontiers in Psychology},\n journal = {Frontiers in Psychology},\n title = {Designing Trustworthy Product Recommendation Virtual Agents Operating Positive Emotion and Having Copious Amount of Knowledge},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '49201495', 'name': 'T. Matsui'}, {'authorId': '1679243', 'name': 'S. Yamada'}]"
269,18ab703c9959fbea7ad253a4062eb705b245552c,Efficient trajectory extraction and parameter learning for data-driven crowd simulation,"We present a trajectory extraction and behavior-learning algorithm for data-driven crowd simulation. Our formulation is based on incrementally learning pedestrian motion models and behaviors from crowd videos. We combine this learned crowd-simulation model with an online tracker based on particle filtering to compute accurate, smooth pedestrian trajectories. We refine this motion model using an optimization technique to estimate the agents' simulation parameters. We highlight the benefits of our approach for improved data-driven crowd simulation, including crowd replication from videos and merging the behavior of pedestrians from multiple videos. We highlight our algorithm's performance in various test scenarios containing tens of human-like agents.",2015.0,35.0,43.0,False,,{'pages': '65-72'},"{'bibtex': '@Inproceedings{Bera2015EfficientTE,\n author = {Aniket Bera and Sujeong Kim and Dinesh Manocha},\n pages = {65-72},\n title = {Efficient trajectory extraction and parameter learning for data-driven crowd simulation},\n year = {2015}\n}\n'}","[{'authorId': '2718563', 'name': 'Aniket Bera'}, {'authorId': '52162164', 'name': 'Sujeong Kim'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
270,18ad13cd015cf6bf32e2aaea476eb030adfb1093,A Virtual Agent Toolkit for Serious Games Developers,"The design of serious games requires developers to tackle pedagogical challenges calling for advanced solutions that the entertainment industry might deem too risky to pursue. One such challenge is the creation of autonomous socially intelligent characters with whom players can practice different social skills. Although there are several architectures in the field of virtual agents that are designed specifically to enable more human-like interactions, they are still not widely adopted by game studios that develop serious games, in particular for learning. In this paper, we present a virtual agent toolkit that was specifically developed with the intent of making agent-based solutions more accessible and reliable to game developers. To this end, a collaborative effort was established with a game studio that has used the toolkit to develop two different serious games. Among other advantages, the toolkit facilitated the inclusion of a dynamic model of emotions that affects not just how the character looks and acts but also how the player’s performance is determined.",2018.0,22.0,17.0,True,"{'url': 'https://research.ou.nl/files/8349959/VAT_CIG.pdf', 'status': 'GREEN'}","{'name': '2018 IEEE Conference on Computational Intelligence and Games (CIG)', 'pages': '1-7'}","{'bibtex': '@Article{Mascarenhas2018AVA,\n author = {S. Mascarenhas and Manuel Guimarães and R. Prada and João Dias and P. A. Santos and Kam Star and Ben Hirsh and Ellis Spice and Rob Kommeren},\n booktitle = {IEEE Conference on Computational Intelligence and Games},\n journal = {2018 IEEE Conference on Computational Intelligence and Games (CIG)},\n pages = {1-7},\n title = {A Virtual Agent Toolkit for Serious Games Developers},\n year = {2018}\n}\n'}","[{'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '28004507', 'name': 'Manuel Guimarães'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145255182', 'name': 'P. A. Santos'}, {'authorId': '2065199', 'name': 'Kam Star'}, {'authorId': '80549358', 'name': 'Ben Hirsh'}, {'authorId': '81303160', 'name': 'Ellis Spice'}, {'authorId': '1854340', 'name': 'Rob Kommeren'}]"
271,18b07146d8d6f631d17fb90c50f8affdf3a527f6,Not all anger is created equal: the impact of the expresser's culture on the social effects of anger in negotiations.,"The influence of culture on the social effects of emotions in negotiations has recently gained the attention of researchers, but to date this research has focused exclusively on the cultural background of the perceiver of the emotion expression. The current research offers the first investigation of how the cultural background of the expresser influences negotiation outcomes. On the basis of the stereotype that East Asians are emotionally inexpressive and European Americans are emotionally expressive, we predicted that anger will have a stronger signaling value when East Asians rather than European American negotiators express it. Specifically, we predicted that angry East Asian negotiators will be perceived as tougher and more threatening and therefore elicit great cooperation from counterparts compared with angry European American negotiators. Results from 4 negotiation studies supported our predictions. In Study 1, angry East Asian negotiators elicited greater cooperation than angry European American and Hispanic negotiators. In Study 2, angry East Asian negotiators elicited greater cooperation than angry European American ones, but emotionally neutral East Asian and European American negotiators elicited the same level of cooperation. Study 3 showed that this effect holds for both East Asian and European American perceivers and that it is mediated by angry East Asian negotiators being perceived as tougher and more threatening than angry European American negotiators. Finally, Study 4 demonstrated that the effect emerges only when negotiators hold the stereotype of East Asians being emotionally inexpressive and European Americans being emotionally expressive. We discuss implications for our understanding of culture, emotions, and negotiations.",2013.0,67.0,61.0,False,,"{'volume': '98 5', 'pages': '\n          785-98\n        ', 'name': 'The Journal of applied psychology'}","{'bibtex': ""@Article{Adam2013NotAA,\n author = {Hajo Adam and Aiwa Shirako},\n journal = {The Journal of applied psychology},\n pages = {\n          785-98\n        },\n title = {Not all anger is created equal: the impact of the expresser's culture on the social effects of anger in negotiations.},\n volume = {98 5},\n year = {2013}\n}\n""}","[{'authorId': '3826921', 'name': 'Hajo Adam'}, {'authorId': '5732160', 'name': 'Aiwa Shirako'}]"
272,18be87938536db985d9528c6090b39dd951d6b1e,"Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later",,2016.0,42.0,151.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s40593-015-0065-9.pdf', 'status': None}","{'volume': '26', 'pages': '25-36', 'name': 'International Journal of Artificial Intelligence in Education'}","{'bibtex': '@Article{Johnson2016FacetoFaceIW,\n author = {W. Lewis Johnson and James C. Lester},\n journal = {International Journal of Artificial Intelligence in Education},\n pages = {25-36},\n title = {Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later},\n volume = {26},\n year = {2016}\n}\n'}","[{'authorId': '2244212899', 'name': 'W. Lewis Johnson'}, {'authorId': '2244281299', 'name': 'James C. Lester'}]"
274,18cdd07ab28306da04c1b7b27c2c1a1b928b4c1d,The Cambridge Handbook of Personality Psychology: The Five-Factor Model of personality traits: consensus and controversy,,2009.0,0.0,92.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{McCrae2009TheCH,\n author = {R. McCrae},\n title = {The Cambridge Handbook of Personality Psychology: The Five-Factor Model of personality traits: consensus and controversy},\n year = {2009}\n}\n'}","[{'authorId': '6206591', 'name': 'R. McCrae'}]"
275,18d079a6d72e3f0b0c9214f597b6b178265b05ee,Identifying Agreement and Disagreement in Conversational Speech: Use of Bayesian Networks to Model Pragmatic Dependencies,"We describe a statistical approach for modeling agreements and disagreements in conversational interaction. Our approach first identifies adjacency pairs using maximum entropy ranking based on a set of lexical, durational, and structural features that look both forward and backward in the discourse. We then classify utterances as agreement or disagreement using these adjacency pairs and features that represent various pragmatic influences of previous agreement or disagreement on the current utterance. Our approach achieves 86.9% accuracy, a 4.9% increase over previous work.",2004.0,19.0,240.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.3115/1218955.1219040', 'status': None}",{'pages': '669-676'},"{'bibtex': '@Inproceedings{Galley2004IdentifyingAA,\n author = {Michel Galley and K. McKeown and Julia Hirschberg and Elizabeth Shriberg},\n pages = {669-676},\n title = {Identifying Agreement and Disagreement in Conversational Speech: Use of Bayesian Networks to Model Pragmatic Dependencies},\n year = {2004}\n}\n'}","[{'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '145590324', 'name': 'K. McKeown'}, {'authorId': '144049352', 'name': 'Julia Hirschberg'}, {'authorId': '70422141', 'name': 'Elizabeth Shriberg'}]"
276,18e34a102238311f0b95440f0aedb340cedc8c1c,Facial and vocal expressions of emotion.,"A flurry of theoretical and empirical work concerning the production of and response to facial and vocal expressions has occurred in the past decade. That emotional expressions express emotions is a tautology but may not be a fact. Debates have centered on universality, the nature of emotion, and the link between emotions and expressions. Modern evolutionary theory is informing more models, emphasizing that expressions are directed at a receiver, that the interests of sender and receiver can conflict, that there are many determinants of sending an expression in addition to emotion, that expressions influence the receiver in a variety of ways, and that the receiver's response is more than simply decoding a message.",2003.0,154.0,763.0,False,,"{'volume': '54', 'pages': '\n          329-49\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Russell2003FacialAV,\n author = {J. Russell and J. Bachorowski and J. Fernández-Dols},\n journal = {Annual review of psychology},\n pages = {\n          329-49\n        },\n title = {Facial and vocal expressions of emotion.},\n volume = {54},\n year = {2003}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '145525513', 'name': 'J. Bachorowski'}, {'authorId': '1412884931', 'name': 'J. Fernández-Dols'}]"
277,1904cd3f1d32aade2a1abf5ad34912b5ecf451ed,Social Consequences of the Internet for Adolescents,"Adolescents are currently the defining users of the Internet. They spend more time online than adults do, and they use the Internet for social interaction more often than adults do. This article discusses the state of the literature on the consequences of online communication technologies (e.g., instant messaging) for adolescents' social connectedness and well-being. Whereas several studies in the 1990s suggested that Internet use is detrimental, recent studies tend to report opposite effects. We first explain why the results of more recent studies diverge from those of earlier studies. Then, we discuss a viable hypothesis to explain the recent findings: the Internet-enhanced self-disclosure hypothesis. Finally, we discuss some contingent factors that may deserve special attention in future research.",2009.0,27.0,790.0,False,,"{'volume': '18', 'pages': '1 - 5', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Valkenburg2009SocialCO,\n author = {P. Valkenburg and J. Peter},\n journal = {Current Directions in Psychological Science},\n pages = {1 - 5},\n title = {Social Consequences of the Internet for Adolescents},\n volume = {18},\n year = {2009}\n}\n'}","[{'authorId': '1903278', 'name': 'P. Valkenburg'}, {'authorId': '1869830', 'name': 'J. Peter'}]"
278,1905a578b8f1eb78128c5e2176a78f82355b1b96,Modeling the Personal Space of Virtual Agents for Behavior Simulation,"In this paper we propose a mathematical model for the concept of Personal Space (PS) and apply it to simulate the non-verbal communication between agents in virtual worlds. The distance between two persons reflects the type of their relationship. Human-like autonomous virtual agents should be equipped with such capability to simulate natural interactions. We define three types of relationships; (1) stranger relationship, (2) business relationship, and (3) friendly relationship. First we model the space around an agent as a probability distribution function which reflects at each point in the space the importance of that point to the agent. The agent updates dynamically this function according to(1) his relation with the other agent, (2) his face orientation, and(3) the evolution of the relationship over time as a stranger agent may become a friend. We demonstrate the concept on a multi-agent platform and show that space-aware agents exhibit better natural behavior.",2009.0,15.0,23.0,True,"{'url': 'https://researchrepository.murdoch.edu.au/id/eprint/33611/1/modeling%20personal%20space.pdf', 'status': None}","{'pages': '364-370', 'name': '2009 International Conference on CyberWorlds'}","{'bibtex': '@Article{Amaoka2009ModelingTP,\n author = {Toshitaka Amaoka and Hamid Laga and M. Nakajima},\n journal = {2009 International Conference on CyberWorlds},\n pages = {364-370},\n title = {Modeling the Personal Space of Virtual Agents for Behavior Simulation},\n year = {2009}\n}\n'}","[{'authorId': '2965739', 'name': 'Toshitaka Amaoka'}, {'authorId': '47028380', 'name': 'Hamid Laga'}, {'authorId': '2865018', 'name': 'M. Nakajima'}]"
279,19137d74a765614fd4057c4473d1b9dbb3707756,Audiovisual Detection of Behavioural Mimicry,"Human mimicry is a behavioural cue occurring during social interaction that can inform us about the participants' inter-personal states and attitudes. It occurs when a participant in an interaction exhibits some behaviour as a result of a co-participants prior display of that signal, and occurs on both short and long time-scales. To develop a detection method for such behaviour, we use a method based on feature prediction, where we train an ensemble of regression models from one subject's features to the co-subject's features, for each class. The ensemble of models with lowest reconstruction error is used to detect mimicry and non-mimicry, using continuous audiovisual streams. As mimicry events are dynamical phenomena, we use a temporal regression model (long short-term memory neural networks) to capture sequential dependencies in the data. On a data set of ten 12-minute dyadic interaction episodes, our method gave average positive and negative recall rates of 77.5% and 60.0% respectively, on data with significant class imbalances, due to the relative sparsity of mimicry samples when doing continuous detection.",2013.0,28.0,32.0,True,"{'url': 'http://ibug.doc.ic.ac.uk/media/uploads/documents/bilakhiapetridispantic_acii2013.pdf', 'status': None}","{'pages': '123-128', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Bilakhia2013AudiovisualDO,\n author = {Sanjay Bilakhia and Stavros Petridis and M. Pantic},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {123-128},\n title = {Audiovisual Detection of Behavioural Mimicry},\n year = {2013}\n}\n'}","[{'authorId': '2831374', 'name': 'Sanjay Bilakhia'}, {'authorId': '2403354', 'name': 'Stavros Petridis'}, {'authorId': '145387780', 'name': 'M. Pantic'}]"
280,192340d54b6c38f4fd18ba72051f53478e205779,Perceptual user interfaces,,2000.0,24.0,207.0,True,"{'url': 'http://www.cs.ucsb.edu/~mturk/Papers/CACM2000.pdf', 'status': None}","{'volume': '', 'pages': '39-51', 'name': ''}","{'bibtex': '@Inproceedings{Turk2000PerceptualUI,\n author = {M. Turk},\n pages = {39-51},\n title = {Perceptual user interfaces},\n year = {2000}\n}\n'}","[{'authorId': '144097660', 'name': 'M. Turk'}]"
281,198e484e73d291994be8e0ac6d165a60dde37a5f,"In dialogue with an avatar, language behavior is identical to dialogue with a human partner",,2015.0,50.0,64.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/s13428-015-0688-7.pdf', 'status': None}","{'volume': '49', 'pages': '46 - 60', 'name': 'Behavior Research Methods'}","{'bibtex': '@Article{Heyselaar2015InDW,\n author = {Evelien Heyselaar and P. Hagoort and K. Segaert},\n journal = {Behavior Research Methods},\n pages = {46 - 60},\n title = {In dialogue with an avatar, language behavior is identical to dialogue with a human partner},\n volume = {49},\n year = {2015}\n}\n'}","[{'authorId': '9760933', 'name': 'Evelien Heyselaar'}, {'authorId': '2608476', 'name': 'P. Hagoort'}, {'authorId': '3365604', 'name': 'K. Segaert'}]"
282,19a954e8aab0ecba00d2aad48e63738c0d7db467,"ESCAPES: evacuation simulation with children, authorities, parents, emotions, and social comparison","In creating an evacuation simulation for training and planning, realistic agents that reproduce known phenomenon are required. Evacuation simulation in the airport domain requires additional features beyond most simulations, including the unique behaviors of first-time visitors who have incomplete knowledge of the area and families that do not necessarily adhere to often-assumed pedestrian behaviors. Evacuation simulations not customized for the airport domain do not incorporate the factors important to it, leading to inaccuracies when applied to it. 
 
In this paper, we describe ESCAPES, a multiagent evacuation simulation tool that incorporates four key features: (i) different agent types; (ii) emotional interactions; (iii) informational interactions; (iv) behavioral interactions. Our simulator reproduces phenomena observed in existing studies on evacuation scenarios and the features we incorporate substantially impact escape time. We use ESCAPES to model the International Terminal at Los Angeles International Airport (LAX) and receive high praise from security officials.",2011.0,24.0,178.0,False,,{'pages': '457-464'},"{'bibtex': '@Inproceedings{Tsai2011ESCAPESES,\n author = {J. Tsai and N. Fridman and E. Bowring and Matthew Brown and S. Epstein and G. Kaminka and S. Marsella and A. Ogden and Inbal Rika and Ankur Sheel and Matthew E. Taylor and Xuezhi Wang and Avishay Zilka and Milind Tambe},\n pages = {457-464},\n title = {ESCAPES: evacuation simulation with children, authorities, parents, emotions, and social comparison},\n year = {2011}\n}\n'}","[{'authorId': '145009779', 'name': 'J. Tsai'}, {'authorId': '144447024', 'name': 'N. Fridman'}, {'authorId': '1740910', 'name': 'E. Bowring'}, {'authorId': '2023945041', 'name': 'Matthew Brown'}, {'authorId': '48134644', 'name': 'S. Epstein'}, {'authorId': '1725049', 'name': 'G. Kaminka'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2063035943', 'name': 'A. Ogden'}, {'authorId': '1765821', 'name': 'Inbal Rika'}, {'authorId': '35307122', 'name': 'Ankur Sheel'}, {'authorId': '39286677', 'name': 'Matthew E. Taylor'}, {'authorId': '2108181066', 'name': 'Xuezhi Wang'}, {'authorId': '39336230', 'name': 'Avishay Zilka'}, {'authorId': '143736701', 'name': 'Milind Tambe'}]"
285,19afec957119e1f726e8a8ac39003779cfbc55f0,Generic personality and emotion simulation for conversational agents,"This paper describes a generic model for personality, mood and emotion simulation for conversational virtual humans. We present a generic model for updating the parameters related to emotional behaviour, as well as a linear implementation of the generic update mechanisms. We explore how existing theories for appraisal can be integrated into the framework. Then we describe a prototype system that uses the described models in combination with a dialogue system and a talking head with synchronized speech and facial expressions. Copyright © 2004 John Wiley & Sons, Ltd.",2004.0,20.0,205.0,True,"{'url': 'https://dspace.library.uu.nl/bitstream/handle/1874/31247/egges_04_Generic%20Personality.pdf?sequence=1&isAllowed=y', 'status': None}","{'volume': '15', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Egges2004GenericPA,\n author = {A. Egges and S. Kshirsagar and N. Magnenat-Thalmann},\n journal = {Computer Animation and Virtual Worlds},\n title = {Generic personality and emotion simulation for conversational agents},\n volume = {15},\n year = {2004}\n}\n'}","[{'authorId': '2479558', 'name': 'A. Egges'}, {'authorId': '144243072', 'name': 'S. Kshirsagar'}, {'authorId': '1387241200', 'name': 'N. Magnenat-Thalmann'}]"
286,19ba0249dcada4bbdc3366d37e1f3362f324e904,Region of interest analysis using an SPM toolbox,"Most functional imaging studies use analyses that look for effects anywhere in the brain. The standard approach is to calculate a statistic relating the experimental effect of interest to the data for each brain voxel. This method has the advantage that it can detect strong effects without apriori constraint on the area that activation will occur. Problems arise when we wish to ask the question whether a particular brain area has been activated: if we know the shape and location of the expected activity, then voxel by voxel approaches have low power, because of the multiple comparisons across voxels. Whole brain analyses usually use image smoothing in order to increase signal to noise; however, the best smoothing filter will depend on the shape of the activation, which may well not be matched by a standard kernel such as a Gaussian. The most direct answer to the question ""has this area been activated"" is to use a region of interest analysis. Here we define a region, and perform the statistical test on the mean time course of the voxels within the region. The contribution of the voxels may be weighted using the expected shape of the activation. This approach has two advantages. First, we increase power by avoiding the multiple comparison problem. Second, if we are correct about the shape and location of the region, the process of taking the mean is equivalent to using the best smoothing kernel to recover the signal. This method has proved very powerful in analysing the activation in well defined regions. For example, Kanwisher et al have used screening tasks and voxel by voxel statistics to define regions of interest, and used these regions to investigate the nature of the original activation in further experiments of visual analysis of faces, scenes, objects and body parts. We have implemented a toolbox called ""MarsBar"" for region of interest analysis within the SPM99 software package (available for free download from http://www.mrc-cbu.cam.ac.uk/Imaging/marsbar.html). The user can define regions using activations from previous SPM analyses, binary or weighted images, or simple shapes (boxes or spheres). Regions can be combined using a full range of algebra to give new regions. Functions include overlap between regions (logical and) or combination (logical or). The software can then extract raw or filtered time courses from the region for futher analysis outside SPM. It can also use new or previous SPM analysis files to analyze the regional time course. t or F statistics for multiple regions can be computed, and the results plotted using the SPM graphical interface. We are currently working on estimation of percentage signal change for the region data. Region of interest analyses are likely to become more important as prior hypotheses about the location of activation become more specific. This may have many advantages in terms of statistical power and the ease of interpretation of neuroimaging data. We hope that this toolbox will make such analyses simpler to implement.",2010.0,0.0,2893.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Brett2010RegionOI,\n author = {M. Brett and J. Anton and R. Valabrègue and J B Poline},\n title = {Region of interest analysis using an SPM toolbox},\n year = {2010}\n}\n'}","[{'authorId': '144082394', 'name': 'M. Brett'}, {'authorId': '31885367', 'name': 'J. Anton'}, {'authorId': '1828848', 'name': 'R. Valabrègue'}, {'authorId': '1802033', 'name': 'J B Poline'}]"
287,19eb0bfb9724e15abc16a1f8c354f5c239dff581,Authentic Design Thinking for Special Education Teachers: Two Case Studies with a Special Focus on Autism,"Design thinking is a useful analytic tool that special education (SpEd) teachers can use to solve challenges they encounter in their daily work. It has five phases: discovery (how to approach a challenge), interpretation (how to interpret the challenge), ideation (what idea can be created to tackle the challenge), experimentation (how to use the idea to tackle the challenge) and evolution (how to evolve the idea and improve it). When the word “authentic” is added to the term design thinking, the original definition of design thinking has been extended and changed. It becomes a creative process that provides SpEd teachers a sense of confidence which they can involve in creating a more desirable future as well as taking action in face of a difficult challenge during their work. It helps SpEd teachers to design meaningful solutions to deal with their challenges ranging in scope and scale from curriculum to physical space and resources to processes and systems and to address problems in classroom, throughout the school and even across an entire district. It engages SpEd teachers in opportunities to experiment, create and prototype models, gather feedback, and redesign their lessons to enhance their students’ learning and/or behaviour.",2015.0,31.0,2.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Iosr2015AuthenticDT,\n author = {Journals Iosr and Kok Hwee Chia Noel and E. Saranya},\n title = {Authentic Design Thinking for Special Education Teachers: Two Case Studies with a Special Focus on Autism},\n year = {2015}\n}\n'}","[{'authorId': '152517902', 'name': 'Journals Iosr'}, {'authorId': '114224059', 'name': 'Kok Hwee Chia Noel'}, {'authorId': '2083191690', 'name': 'E. Saranya'}]"
288,19f8896f8adde68edddfbca97d92437230273ce5,Psychosocial skills training on social functioning and quality of life in the treatment of schizophrenia: a controlled study in Turkey,"OBJECTIVE This study assessed the impact of a psychosocial skills training program, consisting of psychoeducation, interpersonal group therapy and family education incorporated into social skills training, as an integrative approach on social functioning and quality of life of patients with schizophrenia, in comparison to standard care for an 8-month period. METHOD Thirty patients with DSM-IV schizophrenia were included in the study. Patients were assessed using the Positive and Negative Syndrome Scale (PANSS), Quality of Life Scale (QLS), Social Functioning Scale (SFS), and Global Assessment of Function (GAF) at baseline. Fifteen patients underwent an 8-month psychosocial skills training group program and another fifteen patients (waiting list) continued in standard care. Both groups were reassessed and analyzed at the end of the study. RESULTS Two groups were not statistically different in terms of total PANSS, QLS, SFS, GAF scores, and demographic characteristics at baseline. However, there was a significant improvement in the mean total QLS, SFS, GAF, and even in total PANSS scores (respectively from 64.46±19.58 to 89.67±24.10, P<0.001, from 93.20±22.85 to 132.60±33.85, P<0.002, from 57.40±8.78 to 63.86±7.57, P<0.012, and from 63.53±14.48 to 53.33±15.71, P<0.029) for those who underwent the PSST program, but there was no statistically significant change for those on standard care at the end of the study. CONCLUSION This study highlights the ‘social functioning’ and ‘quality of life’ benefits of the psychosocial skills training program for patients with schizophrenia. It can be concluded that this comprehensive psychosocial skills training program might be an important contribution to the functioning of the patients.",2004.0,52.0,49.0,False,,"{'volume': '8', 'pages': '219 - 225', 'name': 'International Journal of Psychiatry in Clinical Practice'}","{'bibtex': '@Article{Yıldız2004PsychosocialST,\n author = {M. Yıldız and B. Veznedaroğlu and A. Eryavuz and B. Kayahan},\n journal = {International Journal of Psychiatry in Clinical Practice},\n pages = {219 - 225},\n title = {Psychosocial skills training on social functioning and quality of life in the treatment of schizophrenia: a controlled study in Turkey},\n volume = {8},\n year = {2004}\n}\n'}","[{'authorId': '144542346', 'name': 'M. Yıldız'}, {'authorId': '3717574', 'name': 'B. Veznedaroğlu'}, {'authorId': '4150856', 'name': 'A. Eryavuz'}, {'authorId': '143939717', 'name': 'B. Kayahan'}]"
289,1a0b41815766b5952dbabb04cfbde5be6d536ac0,Evaluating a realistic agent in an advice-giving task,,2005.0,34.0,124.0,False,,"{'volume': '63', 'pages': '304-327', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Berry2005EvaluatingAR,\n author = {D. Berry and L. Butler and F. D. Rosis},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {304-327},\n title = {Evaluating a realistic agent in an advice-giving task},\n volume = {63},\n year = {2005}\n}\n'}","[{'authorId': '31057244', 'name': 'D. Berry'}, {'authorId': '31793441', 'name': 'L. Butler'}, {'authorId': '1807752', 'name': 'F. D. Rosis'}]"
290,1a238b8472cf2790b380d8be1030d589412ca7ac,Do You See What I See? The Impact of Delsarte on Silent Film Acting,"Synopsis Delsarte’s influence over American oratory, theatrical training, and dance has long been established. Should cinema be added to this list of fields shaped by American Delsartism? Those who received Delsartean training, either professionally or in public school oratory classes, most certainly found their way into filmmaking, as actors and directors. An examination of the context into which Americans enthusiastically embraced Delsarte’s ideas reveals that Americans shared the following precepts regarding the experience and representation of human emotions: emotions have universal expression; the job of the artist is to study these universal expressions; hitting upon a universal emotional expression is the quickest route to exciting an audience’s emotions; and finally, the primary role of art is the stirring of emotions. As long as these ideas flourish, so do the performance practices that aim to meet these goals. A review of Griffith’s feature films demonstrates a persistence of gestures, pantomime, and postures common to acting and oratory manuals and handbooks that profess to help the student discover universal human expressions. These findings demonstrate a greater endurance of conventional acting styles than is currently represented in film scholarship and recommend further research into Delsarte’s influence upon cinematic acting practices of the silent era. DOI 10.5642/mimejournal.20052301.11 First Page 184 Last Page 199 Rights © 2005 Mime Journal, Pomona College, Claremont Colleges Terms of Use & License Information http://creativecommons.org/licenses/by-nc-nd/4.0/ Recommended Citation Hart, Hilary (2005) ""Do You See What I See? The Impact of Delsarte on Silent Film Acting,"" Mime Journal: Vol. 23, Article 11. DOI: 10.5642/mimejournal.20052301.11 Available at: https://scholarship.claremont.edu/mimejournal/vol23/iss1/11  Download",2005.0,2.0,3.0,True,"{'url': 'https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1031&context=mimejournal', 'status': None}","{'volume': '23', 'pages': '184-199', 'name': ''}","{'bibtex': '@Inproceedings{Hart2005DoYS,\n author = {Hilary Hart},\n pages = {184-199},\n title = {Do You See What I See? The Impact of Delsarte on Silent Film Acting},\n volume = {23},\n year = {2005}\n}\n'}","[{'authorId': '146892628', 'name': 'Hilary Hart'}]"
291,1a3c8c958eb46b28c9222501295bcbe9fad9ad43,Computational models of attachment and self-attachment,"We explore, using a variety of models grounded in computational neuroscience, the dynamics of attachment formation and change. In the first part of the thesis we consider the formation of the traditional organised forms of attachment (as defined by Mary Ainsworth) within the context of the free energy principle, showing how each type of attachment might arise in infant agents who minimise free energy over interoceptive states while interacting with caregivers with varying responsiveness. We show how exteroceptive cues (in the form of disrupted affective communication from the caregiver) can result in disorganised forms of attachment (as first uncovered by Mary Main) in infants of caregivers who consistently increase stress on approach, but can have an organising (towards ambivalence) effect in infants of inconsistent caregivers. The second part of the thesis concerns Self-Attachment: a new self-administrable attachment-based psychotherapy recently introduced by Abbas Edalat, which aims to induce neural plasticity in order to retrain an individual’s suboptimal attachment schema. We begin with a model of the hypothesised neurobiological underpinnings of the Self-Attachment bonding protocols, which are concerned with the formation of an abstract, self-directed bond. Finally, using neuroscientific findings related to empathy and the self-other distinction within the context of pain, we propose a simple spiking neural model for how empathic states might serve to motivate application of the aforementioned bonding protocols.",2016.0,399.0,4.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cittern2016ComputationalMO,\n author = {David Cittern},\n title = {Computational models of attachment and self-attachment},\n year = {2016}\n}\n'}","[{'authorId': '2585368', 'name': 'David Cittern'}]"
292,1a725cdfc61d90be7a8318193cd7c571f374c3d2,A statistical similarity measure for aggregate crowd dynamics,"We present an information-theoretic method to measure the similarity between a given set of observed, real-world data and visual simulation technique for aggregate crowd motions of a complex system consisting of many individual agents. This metric uses a two-step process to quantify a simulator's ability to reproduce the collective behaviors of the whole system, as observed in the recorded real-world data. First, Bayesian inference is used to estimate the simulation states which best correspond to the observed data, then a maximum likelihood estimator is used to approximate the prediction errors. This process is iterated using the EM-algorithm to produce a robust, statistical estimate of the magnitude of the prediction error as measured by its entropy (smaller is better). This metric serves as a simulator-to-data similarity measurement. We evaluated the metric in terms of robustness to sensor noise, consistency across different datasets and simulation methods, and correlation to perceptual metrics.",2012.0,42.0,138.0,True,"{'url': 'http://www-users.cs.umn.edu/%7Esjguy/papers/EntropyMetric.pdf', 'status': None}","{'volume': '31', 'pages': '1 - 11', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Guy2012ASS,\n author = {S. Guy and J. V. D. Berg and Wenxi Liu and Rynson W. H. Lau and M. Lin and Dinesh Manocha},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 11},\n title = {A statistical similarity measure for aggregate crowd dynamics},\n volume = {31},\n year = {2012}\n}\n'}","[{'authorId': '35170565', 'name': 'S. Guy'}, {'authorId': '144721873', 'name': 'J. V. D. Berg'}, {'authorId': '143800486', 'name': 'Wenxi Liu'}, {'authorId': '1726262', 'name': 'Rynson W. H. Lau'}, {'authorId': '144247566', 'name': 'M. Lin'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
293,1a77364873c68df4e2dcff57b609a9438f75afb4,"A construct divided: prosocial behavior as helping, sharing, and comforting subtypes","The development and maintenance of prosocial, other-oriented behaviors has been of considerable recent interest. Though it is clear that prosocial behaviors emerge early and play a uniquely important role in the social lives of humans, there is less consensus regarding the mechanisms that underlie and maintain these fundamental acts. The goal of this paper is to clarify inconsistencies in our understanding of the early emergence and development of prosocial behavior by proposing a taxonomy of prosocial behavior anchored in the social-cognitive constraints that underlie the ability to act on behalf of others. I will argue that within the general domain of prosocial behavior, other-oriented actions can be categorized into three distinct types (helping, sharing, and comforting) that reflect responses to three distinct negative states (instrumental need, unmet material desire, and emotional distress). In support of this proposal, I will demonstrate that the three varieties of prosocial behavior show unique ages of onset, uncorrelated patterns of production, and distinct patterns of individual differences. Importantly, by differentiating specific varieties of prosocial behavior within the general category, we can begin to explain inconsistencies in the past literature and provide a framework for directing future research into the ontogenetic origins of these essential social behaviors.",2014.0,156.0,239.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00958/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Dunfield2014ACD,\n author = {Kristen A. Dunfield},\n journal = {Frontiers in Psychology},\n title = {A construct divided: prosocial behavior as helping, sharing, and comforting subtypes},\n volume = {5},\n year = {2014}\n}\n'}","[{'authorId': '34456947', 'name': 'Kristen A. Dunfield'}]"
294,1a77e19441f3a0e030998fb2d11d9dd774582403,Advances in functional and structural MR image analysis and implementation as FSL,,2004.0,51.0,12080.0,True,"{'url': 'http://www.fmrib.ox.ac.uk/analysis/techrep/tr04ss2/tr04ss2.pdf', 'status': None}","{'volume': '23', 'pages': 'S208-S219', 'name': 'NeuroImage'}","{'bibtex': '@Article{Smith2004AdvancesIF,\n author = {Stephen M. Smith and M. Jenkinson and M. Woolrich and C. Beckmann and Timothy Edward John Behrens and H. Johansen-Berg and P. Bannister and M. D. Luca and I. Drobnjak and D. Flitney and R. Niazy and James Saunders and J. Vickers and Yongyue Zhang and N. Stefano and J. Brady and P. Matthews},\n journal = {NeuroImage},\n pages = {S208-S219},\n title = {Advances in functional and structural MR image analysis and implementation as FSL},\n volume = {23},\n year = {2004}\n}\n'}","[{'authorId': '2162210436', 'name': 'Stephen M. Smith'}, {'authorId': '1733095', 'name': 'M. Jenkinson'}, {'authorId': '1813998', 'name': 'M. Woolrich'}, {'authorId': '2683150', 'name': 'C. Beckmann'}, {'authorId': '2591098', 'name': 'Timothy Edward John Behrens'}, {'authorId': '1392848204', 'name': 'H. Johansen-Berg'}, {'authorId': '2076556', 'name': 'P. Bannister'}, {'authorId': '144739224', 'name': 'M. D. Luca'}, {'authorId': '2431102', 'name': 'I. Drobnjak'}, {'authorId': '3514783', 'name': 'D. Flitney'}, {'authorId': '2146541', 'name': 'R. Niazy'}, {'authorId': '2059100876', 'name': 'James Saunders'}, {'authorId': '2060535089', 'name': 'J. Vickers'}, {'authorId': '2108002908', 'name': 'Yongyue Zhang'}, {'authorId': '8434785', 'name': 'N. Stefano'}, {'authorId': '2061193806', 'name': 'J. Brady'}, {'authorId': '1851342', 'name': 'P. Matthews'}]"
295,1a948795c60ce136e265112b6cf5594c7d29048a,From good and bad to can and must: subjective necessity of acts associated with positively and negatively valued stimuli,"In Study 1, 24 participants generated sentences expressing ways of dealing with positively and negatively valued noun stimuli (objects and humans). They were instructed to begin each sentence with One + auxiliary verb. The auxiliary was to be selected from a set including auxiliaries expressing high (must) and low (can) necessity. As predicted on the basis of a minimal nonsocial model of behavioral adaptation, higher necessity was associated with negative stimuli than with positive stimuli. In Study 2, this effect was replicated using trait adjectives as stimuli. Consistent with the model, the effect was produced by stimulus valences belonging to an approach-avoidance related evaluative dimension ‘other-profitability’. However, additional effects, involving an alternative evaluative dimension ‘self-profitability’, were not fully accounted for by the model. They suggested that genuine social factors were involved that, however, were only required to explain some marginal effects. Copyright © 2002 John Wiley & Sons, Ltd.",2002.0,25.0,117.0,True,"{'url': 'https://lirias.kuleuven.be/bitstream/123456789/115085/1/2002EJSPnecessity.pdf', 'status': None}","{'volume': '32', 'pages': '125-136', 'name': 'European Journal of Social Psychology'}","{'bibtex': '@Article{Peeters2002FromGA,\n author = {Guido Peeters},\n journal = {European Journal of Social Psychology},\n pages = {125-136},\n title = {From good and bad to can and must: subjective necessity of acts associated with positively and negatively valued stimuli},\n volume = {32},\n year = {2002}\n}\n'}","[{'authorId': '115425028', 'name': 'Guido Peeters'}]"
296,1ab2e4277db71b0a4e1a3f202e0de4d0980ea4ee,Handbook of Literacy and Technology : Transformations in A Post-typographic World,"Contents: D. Reinking, Introduction: Synthesizing Technological Transformations of Literacy in a Post-Typographic World. Part I:Transforming Text. J.D. Bolter, Hypertext and the Question of Visual Literacy. L. Anderson-Inman, M.A. Horney, Transforming Text for At-Risk Readers. M.C. McKenna, Electronic Texts and the Transformation of Beginning Reading. Part II:Transforming Readers and Writers. J. Myers, R. Hammett, A.M. McKillop, Opportunities for Critical Literacy and Pedagogy in Student-Authored Hypermedia. L.D. Labbo, M. Kuhn, Electronic-Symbol Making: Young Children's Computer-Related Emerging Concepts About Literacy. R. Beach, D. Lundell, Early Adolescents' Use of Computer-Mediated Communication in Writing and Reading. Part III:Transforming Schools and Classrooms. G. Fawcett, S. Snyder, Transforming Schools Through Systemic Change: New Work, New Knowledge, New Technology. L. Neilsen, Coding the Light: Rethinking Generational Authority in a Rural High School Telecommunications Project. R.D. Kieffer, M.E. Hale, A. Templeton, Electronic Literacy Portfolios: Technology Transformations in a First-Grade Classroom. Part IV:Transforming Instruction. E.N. Askov, B. Bixler, Transforming Adult Literacy Instruction Through Computer-Assisted Instruction. C.K. Kinzer, V.J. Risko, Multimedia and Enhanced Learning: Transforming Preservice Education. D.J. Leu, M. Hillinger, P.H. Loseby, M.L. Balcom, J. Dinkin, M.L. Eckels, J. Johnson, K. Matthews, R. Raegler, Grounding the Design of New Technologies for Literacy and Learning in Teachers' Instructional Needs. R. Garner, M. Gillingham, The Internet in the Classroom: Is It the End of Transmission-Oriented Pedagogy? Part V:Transforming Society. A. Purves, Files in the Web of Hypertext. R. Tierney, S. Damarin, Technology as Enfranchisement and Cultural Development: Crisscrossing Symbol Systems, Paradigm Shifts, and Social-Cultural Considerations. B.C. Bruce, M.P. Hogan, The Disappearance of Technology: Toward an Ecological Model of Literacy. J.L. Lemke, Metamedia Literacy: Transforming Meanings and Media. L. Mikulecky, J.R. Kirkley, Changing Workplaces, Changing Classes: The New Role of Technology in Workplace Literacy. Part VI:Transforming Literacy Research. M.L. Kamil, D.M. Lane, Researching the Relationship Between Technology and Literacy: An Agenda for the 21st Century. L. Miller, J. Olson, Literacy Research Oriented Toward Features of Technology and Classrooms.",1998.0,0.0,427.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Reinking1998HandbookOL,\n author = {D. Reinking and Michael C. Mckenna and L. Labbo and R. Kieffer},\n title = {Handbook of Literacy and Technology : Transformations in A Post-typographic World},\n year = {1998}\n}\n'}","[{'authorId': '66295841', 'name': 'D. Reinking'}, {'authorId': '49607854', 'name': 'Michael C. Mckenna'}, {'authorId': '52641148', 'name': 'L. Labbo'}, {'authorId': '52493111', 'name': 'R. Kieffer'}]"
297,1ab38e55ed557f4dd03158268235fd2050baa730,The Nature of Emotions,,2001.0,0.0,735.0,False,,{'name': 'American Scientist'},"{'bibtex': '@Article{Plutchik2001TheNO,\n author = {R. Plutchik},\n journal = {American Scientist},\n title = {The Nature of Emotions},\n year = {2001}\n}\n'}","[{'authorId': '84527386', 'name': 'R. Plutchik'}]"
298,1ab4a7fe5e624a8de30966aefeb7a38dee84287e,Virtual Humans and Persuasion: The Effects of Agency and Behavioral Realism,"Two studies examined whether participant attitudes would change toward positions advocated by an ingroup member even if the latter was known to be an embodied agent; that is, a human-like representation of a computer algorithm. While immersed in a virtual environment, participants listened to a persuasive communication from a digital representation of another student. The latter was actually an embodied agent (a computer-controlled digital representation of a human). Study 1 examined the extent to which gender of the virtual human, participant gender, and the agent's behavior affected attitude change. Results revealed gender-based ingroup favoritism in the form of greater attitude change for same gender virtual humans. Study 2 examined behavioral realism and agency beliefs; that is, whether participants believed the other to be an agent or an avatar (an online representation of an actual person). Results supported Blascovich and colleague's model of social influence within immersive virtual environments. Specifically, the prediction that virtual humans high in behavioral realism would be more influential than those low in behavioral realism was supported, but this effect was moderated by the gender of the virtual human and the research participant. Implications of these findings for the model are discussed.",2007.0,35.0,307.0,False,,"{'volume': '10', 'pages': '1 - 22', 'name': 'Media Psychology'}","{'bibtex': '@Article{Guadagno2007VirtualHA,\n author = {R. Guadagno and J. Blascovich and J. Bailenson and C. McCall},\n journal = {Media Psychology},\n pages = {1 - 22},\n title = {Virtual Humans and Persuasion: The Effects of Agency and Behavioral Realism},\n volume = {10},\n year = {2007}\n}\n'}","[{'authorId': '1715525', 'name': 'R. Guadagno'}, {'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '143682925', 'name': 'C. McCall'}]"
299,1abb2c3bf0dab6ceb720494516362133fba5fd7e,iATTAC: A System for Autonomous Agents and Dynamic Social Interactions - The Architecture,,2015.0,21.0,5.0,False,,{'pages': '135-146'},"{'bibtex': '@Inproceedings{Cebolledo2015iATTACAS,\n author = {Edgar Cebolledo and Olga De Troyer},\n pages = {135-146},\n title = {iATTAC: A System for Autonomous Agents and Dynamic Social Interactions - The Architecture},\n year = {2015}\n}\n'}","[{'authorId': '2605715', 'name': 'Edgar Cebolledo'}, {'authorId': '1745846', 'name': 'Olga De Troyer'}]"
300,1abcc5349eeec3608f87caa32fcdb9baa24a3265,Conversational agents in healthcare: a systematic review,"Abstract Objective Our objective was to review the characteristics, current applications, and evaluation measures of conversational agents with unconstrained natural language input capabilities used for health-related purposes. Methods We searched PubMed, Embase, CINAHL, PsycInfo, and ACM Digital using a predefined search strategy. Studies were included if they focused on consumers or healthcare professionals; involved a conversational agent using any unconstrained natural language input; and reported evaluation measures resulting from user interaction with the system. Studies were screened by independent reviewers and Cohen’s kappa measured inter-coder agreement. Results The database search retrieved 1513 citations; 17 articles (14 different conversational agents) met the inclusion criteria. Dialogue management strategies were mostly finite-state and frame-based (6 and 7 conversational agents, respectively); agent-based strategies were present in one type of system. Two studies were randomized controlled trials (RCTs), 1 was cross-sectional, and the remaining were quasi-experimental. Half of the conversational agents supported consumers with health tasks such as self-care. The only RCT evaluating the efficacy of a conversational agent found a significant effect in reducing depression symptoms (effect size d = 0.44, p = .04). Patient safety was rarely evaluated in the included studies. Conclusions The use of conversational agents with unconstrained natural language input capabilities for health-related purposes is an emerging field of research, where the few published studies were mainly quasi-experimental, and rarely evaluated efficacy or safety. Future studies would benefit from more robust experimental designs and standardized reporting. Protocol Registration The protocol for this systematic review is registered at PROSPERO with the number CRD42017065917.",2018.0,63.0,584.0,True,"{'url': 'https://academic.oup.com/jamia/article-pdf/25/9/1248/34150600/ocy072.pdf', 'status': None}","{'volume': '25', 'pages': '1248 - 1258', 'name': 'Journal of the American Medical Informatics Association : JAMIA'}","{'bibtex': '@Article{Laranjo2018ConversationalAI,\n author = {L. Laranjo and A. Dunn and H. L. Tong and A. B. Kocaballi and Jessica A. Chen and R. Bashir and Didi Surian and B. Gallego and F. Magrabi and A. Lau and E. Coiera},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {1248 - 1258},\n title = {Conversational agents in healthcare: a systematic review},\n volume = {25},\n year = {2018}\n}\n'}","[{'authorId': '3314963', 'name': 'L. Laranjo'}, {'authorId': '34318729', 'name': 'A. Dunn'}, {'authorId': '32260194', 'name': 'H. L. Tong'}, {'authorId': '51374066', 'name': 'A. B. Kocaballi'}, {'authorId': '2115896431', 'name': 'Jessica A. Chen'}, {'authorId': '10280969', 'name': 'R. Bashir'}, {'authorId': '2609488', 'name': 'Didi Surian'}, {'authorId': '145497572', 'name': 'B. Gallego'}, {'authorId': '2817191', 'name': 'F. Magrabi'}, {'authorId': '144417710', 'name': 'A. Lau'}, {'authorId': '145948914', 'name': 'E. Coiera'}]"
301,1ac1326157dda043d15092c1ae0d34131359169e,Virtual General Game Playing Agent,,2016.0,14.0,4.0,False,,{'pages': '464-469'},"{'bibtex': '@Inproceedings{Helgadóttir2016VirtualGG,\n author = {H. Helgadóttir and Svanhvít Jónsdóttir and Andri Már Sigurdsson and Stephan Schiffel and H. Vilhjálmsson},\n pages = {464-469},\n title = {Virtual General Game Playing Agent},\n year = {2016}\n}\n'}","[{'authorId': '3489989', 'name': 'H. Helgadóttir'}, {'authorId': '2042414488', 'name': 'Svanhvít Jónsdóttir'}, {'authorId': '40153988', 'name': 'Andri Már Sigurdsson'}, {'authorId': '1903594', 'name': 'Stephan Schiffel'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}]"
302,1b114e2086b356b9a29ec93d8f4c72a1fb5bca73,Feeling and Reasoning: A Computational Model for Emotional Characters,,2005.0,25.0,288.0,False,,{'pages': '127-140'},"{'bibtex': '@Inproceedings{Dias2005FeelingAR,\n author = {João Dias and Ana Paiva},\n pages = {127-140},\n title = {Feeling and Reasoning: A Computational Model for Emotional Characters},\n year = {2005}\n}\n'}","[{'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
306,1b1fd7f2ac71a7366f11c16cf5c7d67bbb35f35e,Front View vs. Side View of Facial and Postural Expressions of Emotions in a Virtual Character,,2011.0,31.0,20.0,False,,"{'volume': '6', 'pages': '132-143', 'name': 'Trans. Edutainment'}","{'bibtex': '@Article{Courgeon2011FrontVV,\n author = {M. Courgeon and C. Clavel and Ning Tan and Jean-Claude Martin},\n journal = {Trans. Edutainment},\n pages = {132-143},\n title = {Front View vs. Side View of Facial and Postural Expressions of Emotions in a Virtual Character},\n volume = {6},\n year = {2011}\n}\n'}","[{'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '1724799', 'name': 'C. Clavel'}, {'authorId': '2057776275', 'name': 'Ning Tan'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}]"
308,1b21686cc835f17707d14c410d746698860aecd6,Comparing Two Emotion Models for Deriving Affective States from Physiological Data,,2008.0,31.0,65.0,False,,{'pages': '35-50'},"{'bibtex': '@Inproceedings{Lichtenstein2008ComparingTE,\n author = {A. Lichtenstein and A. Oehme and S. Kupschick and Thomas Jürgensohn},\n pages = {35-50},\n title = {Comparing Two Emotion Models for Deriving Affective States from Physiological Data},\n year = {2008}\n}\n'}","[{'authorId': '35194984', 'name': 'A. Lichtenstein'}, {'authorId': '48062105', 'name': 'A. Oehme'}, {'authorId': '2521120', 'name': 'S. Kupschick'}, {'authorId': '69404042', 'name': 'Thomas Jürgensohn'}]"
309,1b226019015d6c64e7e20bb280f8d2b47cc1b0c4,Problèmes de représentation de la Langue des Signes Française en vue du traitement automatique,Nous proposons dans cet article une description de la Langue des Signes Française dans le but de traduire des énoncés courts du français et de les faire signer par un personnage de synthèse. Cette description pose en préalable la question de la transcription des éléments d’une langue dont le signal n’est pas linéaire. Il s’agit ensuite de repérer les différentes couches linguistiques et la forme de leurs unités constitutives en vue de la répartition des tâches informatiques : la synthèse de gestes nécessite un traitement des éléments constitutifs du geste et la génération syntaxique doit pouvoir manipuler des morphèmes.,2006.0,8.0,7.0,False,,{'pages': '670-679'},"{'bibtex': '@Inproceedings{Kervajan2006ProblèmesDR,\n author = {Loïc Kervajan},\n pages = {670-679},\n title = {Problèmes de représentation de la Langue des Signes Française en vue du traitement automatique},\n year = {2006}\n}\n'}","[{'authorId': '3167710', 'name': 'Loïc Kervajan'}]"
310,1b3b0f715da1d2988d078c53636730fa6a9769ad,BEAT: the Behavior Expression Animation Toolkit,"The Behavior Expression Animation Toolkit (BEAT) allows animators to input typed text that they wish to be spoken by an animated human figure, and to obtain as output appropriate and synchronized nonverbal behaviors and synthesized speech in a form that can be sent to a number of different animation systems. The nonverbal behaviors are assigned on the basis of actual linguistic and contextual analysis of the typed text, relying on rules derived from extensive research into human conversational behavior. The toolkit is extensible, so that new rules can be quickly added. It is designed to plug into larger systems that may also assign personality profiles, motion characteristics, scene constraints, or the animation styles of particular animators.",2001.0,40.0,926.0,False,,{'name': 'Proceedings of the 28th annual conference on Computer graphics and interactive techniques'},"{'bibtex': '@Article{Cassell2001BEATTB,\n author = {Justine Cassell and H. Vilhjálmsson and T. Bickmore},\n journal = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques},\n title = {BEAT: the Behavior Expression Animation Toolkit},\n year = {2001}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '1690448', 'name': 'T. Bickmore'}]"
312,1b5b3a5e052c96f591f19569ca29b972ab1f5738,The Cognitive Structure of Emotions,"More than 30 years after its initial publication, this new edition of The Cognitive Structure of Emotions refines and updates Ortony, Clore, and Collins's OCC model of emotions. Starting from a three-way classification of construals of the world––events, the attribution of responsibility for events, and objects––the authors propose a systematic account of emotion differentiation. Rejecting the oft-favored features of bodily feelings, emotion-related behaviors, and facial expressions as too intensity-dependent and insufficiently diagnostic, they provide a detailed analysis of emotion differentiation in terms of the cognitive underpinnings of emotion types. Using numerous examples, they explain how different variables influence emotion intensity, and show how emotions can be formalized for computational purposes. Now with a contributed chapter describing the OCC model's influence, this book will interest a wide audience in cognitive, clinical, and social psychology, as well as in artificial intelligence and affective computing, and other cognitive science disciplines.",1988.0,3.0,6711.0,True,"{'url': 'https://escholarship.org/content/qt1p81k62k/qt1p81k62k.pdf?t=ov3bph', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ortony1988TheCS,\n author = {A. Ortony and G. Clore and A. Collins},\n title = {The Cognitive Structure of Emotions},\n year = {1988}\n}\n'}","[{'authorId': '1802934', 'name': 'A. Ortony'}, {'authorId': '31458494', 'name': 'G. Clore'}, {'authorId': '31533192', 'name': 'A. Collins'}]"
327,1b9976fea3c1cf13f0a102a884f027d9d80a14b3,Building a game scenario to encourage children with autism to recognize and label emotions using a humanoid robot,"This paper presents an exploratory study in which children with autism interact with ZECA (Zeno Engaging Children with Autism). ZECA is a humanoid robot with a face covered with a material allowing the display of varied facial expressions. The study investigates a novel scenario for robot-assisted play, to help promoting labelling of emotions by children with autism spectrum disorders (ASD). The study was performed during three sessions with two boys diagnosed with ASD. The results obtained from the analysis of the children's behaviours while interacting with ZECA helped us improve several aspects of our game scenario such as the technical specificities of the game and its dynamics, and the experimental setup. The software produced for this study allows the robot to autonomously identify the answers of the child during the session. This automatic identification helped the fluidity of the game and freed the experimenter to participate in triadic interactions with the child. The evaluation of the game scenario that will be used in a future study was the main goal of this pilot study, rather than to quantify and evaluate the performance of the children. Overall, this exploratory study in teaching children about labelling emotions using a humanoid robot embedded in a game scenario demonstrated the possible positive outcomes this child-robot interaction can produce and highlighted the issues regarding data collection and their analysis that will inform future studies.",2014.0,18.0,16.0,True,"{'url': 'https://repositorium.sdum.uminho.pt/bitstream/1822/57084/1/Building%20a%20Game%20Scenario%20to%20Encourage%20Children%20with%20Autism%20to%20Recognize%20and%20Label%20Emotions%20using%20a%20Humanoid%20Robot.pdf', 'status': None}","{'pages': '820-825', 'name': 'The 23rd IEEE International Symposium on Robot and Human Interactive Communication'}","{'bibtex': '@Article{Costa2014BuildingAG,\n author = {S. Costa and F. Soares and Ana Paula Pereira Vieira and C. Santos and Antoine Hiolle},\n journal = {The 23rd IEEE International Symposium on Robot and Human Interactive Communication},\n pages = {820-825},\n title = {Building a game scenario to encourage children with autism to recognize and label emotions using a humanoid robot},\n year = {2014}\n}\n'}","[{'authorId': '145794749', 'name': 'S. Costa'}, {'authorId': '2054291674', 'name': 'F. Soares'}, {'authorId': '40417709', 'name': 'Ana Paula Pereira Vieira'}, {'authorId': '145069229', 'name': 'C. Santos'}, {'authorId': '3171783', 'name': 'Antoine Hiolle'}]"
328,1ba244d1e11bea20eaa15a4c90b330201fe17d42,Can Virtual Humans Be More Engaging Than Real Ones?,,2007.0,51.0,109.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/978-3-540-73110-8_30.pdf', 'status': None}",{'pages': '286-297'},"{'bibtex': '@Inproceedings{Gratch2007CanVH,\n author = {J. Gratch and Ning Wang and A. Okhmatovskaia and François Lamothe and Mathieu Morales and R. J. V. D. Werf and Louis-Philippe Morency},\n pages = {286-297},\n title = {Can Virtual Humans Be More Engaging Than Real Ones?},\n year = {2007}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '1947943', 'name': 'A. Okhmatovskaia'}, {'authorId': '2058678292', 'name': 'François Lamothe'}, {'authorId': '35931377', 'name': 'Mathieu Morales'}, {'authorId': '2015385', 'name': 'R. J. V. D. Werf'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
330,1bc8d03103c93bbf3518f9bf05021021ad267f30,"Examining the Diversity of Prosocial Behavior: Helping, Sharing, and Comforting in Infancy.","Prosocial behaviors are a diverse group of actions that are integral to human social life. In this study, we examined the ability of 18- and 24-month-old infants to engage in three types of other-oriented behaviors, specifically helping, sharing, and comforting. Infants in both age groups engaged in more prosocial behavior on trials in which an unfamiliar adult experimenter required aid (experimental conditions) than on those in which she did not (control conditions) across two of the three prosocial tasks (i.e., helping and sharing). The infants engaged in these behaviors with similar frequency; however, there was no correlation between the tasks. The implications for the construct of prosocial behavior and the presence of a prosocial disposition are discussed.",2011.0,46.0,331.0,False,,"{'volume': '16 3', 'pages': '\n          227-247\n        ', 'name': 'Infancy : the official journal of the International Society on Infant Studies'}","{'bibtex': ""@Article{Dunfield2011ExaminingTD,\n author = {Kristen A. Dunfield and V. Kuhlmeier and Laura O'Connell and E. Kelley},\n journal = {Infancy : the official journal of the International Society on Infant Studies},\n pages = {\n          227-247\n        },\n title = {Examining the Diversity of Prosocial Behavior: Helping, Sharing, and Comforting in Infancy.},\n volume = {16 3},\n year = {2011}\n}\n""}","[{'authorId': '34456947', 'name': 'Kristen A. Dunfield'}, {'authorId': '5361244', 'name': 'V. Kuhlmeier'}, {'authorId': '1420162358', 'name': ""Laura O'Connell""}, {'authorId': '39694061', 'name': 'E. Kelley'}]"
331,1be002eee21901925fcf4c87d5ce102cafd70998,"Rapid heartbeat, but dry palms: reactions of heart rate and skin conductance levels to social rejection","Background: Social rejection elicits negative mood, emotional distress, and neural activity in networks that are associated with physical pain. However, studies assessing physiological reactions to social rejection are rare and results of these studies were found to be ambiguous. Therefore, the present study aimed to examine and specify physiological effects of social rejection. Methods: Participants (n = 50) were assigned to either a social exclusion or inclusion condition of a virtual ball-tossing game (Cyberball). Immediate and delayed physiological [skin conductance level (SCL) and heart rate] reactions were recorded. In addition, subjects reported levels of affect, emotional states, and fundamental needs. Results: Subjects who were socially rejected showed increased heart rates. However, social rejection had no effect on subjects' SCLs. Both conditions showed heightened arousal on this measurement. Furthermore, psychological consequences of social rejection indicated the validity of the paradigm. Conclusions: Our results reveal that social rejection evokes an immediate physiological reaction. Accelerated heart rates indicate that behavior activation rather than inhibition is associated with socially threatening events. In addition, results revealed gender-specific response patterns suggesting that sample characteristics such as differences in gender may account for ambiguous findings of physiological reactions to social rejection.",2014.0,84.0,49.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00956/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Iffland2014RapidHB,\n author = {Benjamin Iffland and L. M. Sansen and C. Catani and F. Neuner},\n journal = {Frontiers in Psychology},\n title = {Rapid heartbeat, but dry palms: reactions of heart rate and skin conductance levels to social rejection},\n volume = {5},\n year = {2014}\n}\n'}","[{'authorId': '4973279', 'name': 'Benjamin Iffland'}, {'authorId': '6999691', 'name': 'L. M. Sansen'}, {'authorId': '3781074', 'name': 'C. Catani'}, {'authorId': '5637208', 'name': 'F. Neuner'}]"
332,1be3feeb17c3520fbac6b5b652aa41feea596b2f,The Extended Mind,"Where does the mind stop and the rest of the world begin? The question invites two standard replies. Some accept the intuitive demarcations of skin and skull, and say that what is outside the body is outside the mind. Others are impressed by arguments suggesting that the meaning of our words ""just ain't in the head"", and hold that this externalism about meaning carries over into an externalism about mind. We propose to pursue a third position. We will advocate an externalism about mind, but one that is in no way grounded in the debatable role of external reference in fixing the contents of our mental states. Rather, we advocate an *active externalism*, based on the active role of the environment in driving cognitive processes.",1998.0,68.0,4708.0,False,,"{'volume': '58', 'pages': '7-19', 'name': 'Analysis'}","{'bibtex': '@Article{Clark1998TheEM,\n author = {A. Clark and D. Chalmers},\n journal = {Analysis},\n pages = {7-19},\n title = {The Extended Mind},\n volume = {58},\n year = {1998}\n}\n'}","[{'authorId': '37700983', 'name': 'A. Clark'}, {'authorId': '2072252', 'name': 'D. Chalmers'}]"
333,1beefd6c34e146c0dafbe7533ffd6da8dd9c8eea,Saying It with Light: A Pilot Study of Affective Communication Using the MIRO Robot,,2015.0,38.0,32.0,True,"{'url': 'http://eprints.whiterose.ac.uk/107018/1/collins2015lm.pdf', 'status': None}",{'pages': '243-255'},"{'bibtex': '@Inproceedings{Collins2015SayingIW,\n author = {Emily C. Collins and T. Prescott and B. Mitchinson},\n pages = {243-255},\n title = {Saying It with Light: A Pilot Study of Affective Communication Using the MIRO Robot},\n year = {2015}\n}\n'}","[{'authorId': '2082714', 'name': 'Emily C. Collins'}, {'authorId': '1750570', 'name': 'T. Prescott'}, {'authorId': '7514567', 'name': 'B. Mitchinson'}]"
334,1c2083514faa4991515064a41cafb99edda8fe7c,Verbal indicators of psychological distress in interactive dialogue with a virtual human,"We explore the presence of indicators of psychological distress in the linguistic behavior of subjects in a corpus of semistructured virtual human interviews. At the level of aggregate dialogue-level features, we identify several significant differences between subjects with depression and PTSD when compared to nondistressed subjects. At a more fine-grained level, we show that significant differences can also be found among features that represent subject behavior during specific moments in the dialogues. Finally, we present statistical classification results that suggest the potential for automatic assessment of psychological distress in individual interactions with a virtual human dialogue system.",2013.0,17.0,47.0,False,,{'pages': '193-202'},"{'bibtex': '@Inproceedings{DeVault2013VerbalIO,\n author = {D. DeVault and Kallirroi Georgila and Ron Artstein and Fabrizio Morbini and D. Traum and Stefan Scherer and A. Rizzo and Louis-Philippe Morency},\n pages = {193-202},\n title = {Verbal indicators of psychological distress in interactive dialogue with a virtual human},\n year = {2013}\n}\n'}","[{'authorId': '144662324', 'name': 'D. DeVault'}, {'authorId': '3194430', 'name': 'Kallirroi Georgila'}, {'authorId': '2038490', 'name': 'Ron Artstein'}, {'authorId': '2223582', 'name': 'Fabrizio Morbini'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
335,1c235f07773e3f7184b02957c1b34725d0220671,Embodied Conversational Agents,,2006.0,0.0,385.0,False,,,"{'bibtex': '@Inproceedings{André2006EmbodiedCA,\n author = {Blisabeth André and Thomas Rist and Susanne van Mulken},\n title = {Embodied Conversational Agents},\n year = {2006}\n}\n'}","[{'authorId': '2262168653', 'name': 'Blisabeth André'}, {'authorId': '2262189126', 'name': 'Thomas Rist'}, {'authorId': '2106252', 'name': 'Susanne van Mulken'}]"
336,1c428da05cc67ae3ad138936bf7ca615e6b183de,Computer facial animation,,1996.0,0.0,706.0,False,,"{'pages': 'I-XV, 1-365'}","{'bibtex': '@Inproceedings{Parke1996ComputerFA,\n author = {F. Parke and K. Waters},\n pages = {I-XV, 1-365},\n title = {Computer facial animation},\n year = {1996}\n}\n'}","[{'authorId': '2954206', 'name': 'F. Parke'}, {'authorId': '46398261', 'name': 'K. Waters'}]"
337,1c5024b54d2cc3e68800756d27ddcd34f039910f,Smart Broker Agent Learning How to Reach Appropriate Goal by Making Appropriate Compromises,"In this paper a new Smart Broker Learning Agent (SBLA) has been proposed, which trains to find the most acceptable solution to a given problem, according to the individual requirements and emotions of a particular user. For this purpose, a new structure of the agent has been proposed and reinforcement-learning algorithm has been used. When the scenarios and criteria under consideration are complex, and when mixed emotions arise, it may be necessary to compromise on certain criteria in order to achieve the goal. Then knowledge of the preferences and emotions of the particular user is needed. In these cases, the SBLA does not allow compromises that are unacceptable to this user. The structure and the way of acting of the agent have been considered. The knowledge that the SBLA must have and the process of its formation have been described. The scenarios for solving a specific task and the conducted experiments have been presented. Some contributions, arising from the use of the proposed agent’s architecture have been discussed, such as: the opportunity for the agent to explain decisions; to offer the most appropriate solution for each specific user; to avoid unacceptable compromises, to have empathy, and the greater approval of the offered solutions.",2021.0,19.0,1.0,True,,{'pages': '181-188'},"{'bibtex': '@Inproceedings{Budakova2021SmartBA,\n author = {D. Budakova and Veselka Petrova-Dimitrova and L. Dakovski},\n pages = {181-188},\n title = {Smart Broker Agent Learning How to Reach Appropriate Goal by Making Appropriate Compromises},\n year = {2021}\n}\n'}","[{'authorId': '1799528', 'name': 'D. Budakova'}, {'authorId': '1581448954', 'name': 'Veselka Petrova-Dimitrova'}, {'authorId': '1753312', 'name': 'L. Dakovski'}]"
338,1c74835002e7d5e689826a67c551147e941052d1,Emotion in Human-Computer Interaction,,2012.0,43.0,252.0,False,,{'pages': '239-262'},"{'bibtex': '@Inproceedings{Peter2012EmotionIH,\n author = {Christian Peter and B. Urban},\n pages = {239-262},\n title = {Emotion in Human-Computer Interaction},\n year = {2012}\n}\n'}","[{'authorId': '1878549', 'name': 'Christian Peter'}, {'authorId': '143921889', 'name': 'B. Urban'}]"
339,1c768358444c41fafc7321c6906e6e670b0dae5d,Emotional contagion: Behavioral induction in individuals and groups.,,1990.0,0.0,229.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Schoenewolf1990EmotionalCB,\n author = {G. Schoenewolf},\n title = {Emotional contagion: Behavioral induction in individuals and groups.},\n year = {1990}\n}\n'}","[{'authorId': '8594798', 'name': 'G. Schoenewolf'}]"
340,1c8e38974ae12d0c3b32a1493cb24e76bb47dcda,"Avatar and Sense of Embodiment: Studying the Relative Preference Between Appearance, Control and Point of View","In Virtual Reality, a number of studies have been conducted to assess the influence of avatar appearance, avatar control and user point of view on the Sense of Embodiment (SoE) towards a virtual avatar. However, such studies tend to explore each factor in isolation. This paper aims to better understand the inter-relations among these three factors by conducting a subjective matching experiment. In the presented experiment ($\mathrm{n}=40$), participants had to match a given “optimal” SoE avatar configuration (realistic avatar, full-body motion capture, first-person point of view), starting by a “minimal” SoE configuration (minimal avatar, no control, third-person point of view), by iteratively increasing the level of each factor. The choices of the participants provide insights about their preferences and perception over the three factors considered. Moreover, the subjective matching procedure was conducted in the context of four different interaction tasks with the goal of covering a wide range of actions an avatar can do in a VE. The paper also describes a baseline experiment ($\mathrm{n}=20$) which was used to define the number and order of the different levels for each factor, prior to the subjective matching experiment (e.g. different degrees of realism ranging from abstract to personalised avatars for the visual appearance). The results of the subjective matching experiment show that point of view and control levels were consistently increased by users before appearance levels when it comes to enhancing the SoE. Second, several configurations were identified with equivalent SoE as the one felt in the optimal configuration, but vary between the tasks. Taken together, our results provide valuable insights about which factors to prioritize in order to enhance the SoE towards an avatar in different tasks, and about configurations which lead to fulfilling SoE in VE.",2020.0,49.0,69.0,True,"{'url': 'https://hal.inria.fr/hal-02868067/file/X_Factors.pdf', 'status': None}","{'volume': '26', 'pages': '2062-2072', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Fribourg2020AvatarAS,\n author = {Rebecca Fribourg and F. Argelaguet and A. Lécuyer and Ludovic Hoyet},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {2062-2072},\n title = {Avatar and Sense of Embodiment: Studying the Relative Preference Between Appearance, Control and Point of View},\n volume = {26},\n year = {2020}\n}\n'}","[{'authorId': '51239337', 'name': 'Rebecca Fribourg'}, {'authorId': '1854224', 'name': 'F. Argelaguet'}, {'authorId': '1693899', 'name': 'A. Lécuyer'}, {'authorId': '1869571', 'name': 'Ludovic Hoyet'}]"
341,1cb9fc1f1c702f87e000399da97acc0d76ec6b8c,"Building an Educational Adventure Game: Theory, Design, and Lessons",,2001.0,0.0,102.0,False,,"{'volume': '12', 'pages': '249-263', 'name': 'The Journal of Interactive Learning Research'}","{'bibtex': '@Article{Amory2001BuildingAE,\n author = {A. Amory},\n journal = {The Journal of Interactive Learning Research},\n pages = {249-263},\n title = {Building an Educational Adventure Game: Theory, Design, and Lessons},\n volume = {12},\n year = {2001}\n}\n'}","[{'authorId': '3117301', 'name': 'A. Amory'}]"
342,1d1286676088884132cc41af051495f02fdb6bfd,"""I show how you feel"": Motor mimicry as a communicative act.",,1986.0,31.0,451.0,False,,"{'volume': '50', 'pages': '322-329', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Bavelas1986ISH,\n author = {J. Bavelas and A. Black and Charles R. Lemery and J. Mullett},\n journal = {Journal of Personality and Social Psychology},\n pages = {322-329},\n title = {""I show how you feel"": Motor mimicry as a communicative act.},\n volume = {50},\n year = {1986}\n}\n'}","[{'authorId': '2816755', 'name': 'J. Bavelas'}, {'authorId': '12566494', 'name': 'A. Black'}, {'authorId': '117243466', 'name': 'Charles R. Lemery'}, {'authorId': '49885938', 'name': 'J. Mullett'}]"
344,1d234383ee598986a8f06186fb02043001a31380,ECHOES: An intelligent serious game for fostering social communication in children with autism,,2014.0,67.0,240.0,False,,"{'volume': '264', 'pages': '41-60', 'name': 'Inf. Sci.'}","{'bibtex': '@Article{Bernardini2014ECHOESAI,\n author = {S. Bernardini and K. Porayska-Pomsta and T. Smith},\n journal = {Inf. Sci.},\n pages = {41-60},\n title = {ECHOES: An intelligent serious game for fostering social communication in children with autism},\n volume = {264},\n year = {2014}\n}\n'}","[{'authorId': '2282728', 'name': 'S. Bernardini'}, {'authorId': '1400276226', 'name': 'K. Porayska-Pomsta'}, {'authorId': '145165599', 'name': 'T. Smith'}]"
345,1d3701043cca09dddadf4b20ded2905eaa19a51b,Integrating social power into the decision-making of cognitive agents,,2016.0,80.0,32.0,True,,"{'volume': '241', 'pages': '1-44', 'name': 'Artif. Intell.'}","{'bibtex': '@Article{Pereira2016IntegratingSP,\n author = {G. Pereira and R. Prada and P. A. Santos},\n journal = {Artif. Intell.},\n pages = {1-44},\n title = {Integrating social power into the decision-making of cognitive agents},\n volume = {241},\n year = {2016}\n}\n'}","[{'authorId': '24891895', 'name': 'G. Pereira'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145255182', 'name': 'P. A. Santos'}]"
346,1d4a4ded46582e59ccafb3dcd576841a819f6b1e,Facial reactions: Rapidly evoked emotional responses,This study investigated how rapidly emotion specific facial muscle reactions are released when subjects are exposed to pictures of different categories of positively and negatively rated emotional stimuli. Facial electromyographic (EMG) activity was meas,1997.0,0.0,96.0,False,,"{'volume': '11', 'pages': '115-123', 'name': 'Journal of Psychophysiology'}","{'bibtex': '@Article{Dimberg1997FacialRR,\n author = {U. Dimberg},\n journal = {Journal of Psychophysiology},\n pages = {115-123},\n title = {Facial reactions: Rapidly evoked emotional responses},\n volume = {11},\n year = {1997}\n}\n'}","[{'authorId': '4583182', 'name': 'U. Dimberg'}]"
347,1d5b0ad40875c4f25bb4361a876324e434ecf2ed,"""Mood contagion"": the automatic transfer of mood between persons.","The current studies aimed to find out whether a nonintentional form of mood contagion exists and which mechanisms can account for it. In these experiments participants who expected to be tested for text comprehension listened to an affectively neutral speech that was spoken in a slightly sad or happy voice. The authors found that (a) the emotional expression induced a congruent mood state in the listeners, (b) inferential accounts to emotional sharing were not easily reconciled with the findings, (c) different affective experiences emerged from intentional and nonintentional forms of emotional sharing, and (d) findings suggest that a perception-behavior link (T. L. Chartrand & J. A. Bargh, 1999) can account for these findings, because participants who were required to repeat the philosophical speech spontaneously imitated the target person's vocal expression of emotion.",2000.0,63.0,754.0,True,"{'url': 'http://www.communicationcache.com/uploads/1/0/8/8/10887248/mood_contagion-_the_automatic_transfer_of_mood_between_persons..pdf', 'status': None}","{'volume': '79 2', 'pages': '\n          211-23\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Neumann2000MoodCT,\n author = {Roland Neumann and F. Strack},\n journal = {Journal of personality and social psychology},\n pages = {\n          211-23\n        },\n title = {""Mood contagion"": the automatic transfer of mood between persons.},\n volume = {79 2},\n year = {2000}\n}\n'}","[{'authorId': '47921749', 'name': 'Roland Neumann'}, {'authorId': '4574442', 'name': 'F. Strack'}]"
348,1d9f5cc0309c6994ed3bb2392b3a3b88178bcf12,Using Virtual Interactive Training Agents (ViTA) with Adults with Autism and Other Developmental Disabilities,,2018.0,19.0,87.0,False,,"{'volume': '48', 'pages': '905-912', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Burke2018UsingVI,\n author = {S. Burke and Tammy Bresnahan and Tan Li and K. Epnere and Albert A. Rizzo and Mary Partin and Robert M. Ahlness and Matthew Trimmer},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {905-912},\n title = {Using Virtual Interactive Training Agents (ViTA) with Adults with Autism and Other Developmental Disabilities},\n volume = {48},\n year = {2018}\n}\n'}","[{'authorId': '7930852', 'name': 'S. Burke'}, {'authorId': '48552907', 'name': 'Tammy Bresnahan'}, {'authorId': '48779330', 'name': 'Tan Li'}, {'authorId': '12283319', 'name': 'K. Epnere'}, {'authorId': '32772262', 'name': 'Albert A. Rizzo'}, {'authorId': '119281738', 'name': 'Mary Partin'}, {'authorId': '29825535', 'name': 'Robert M. Ahlness'}, {'authorId': '32810856', 'name': 'Matthew Trimmer'}]"
349,1da64b9055430fffdb388271761718a32aedfac0,Automatic imitation.,"""Automatic imitation"" is a type of stimulus-response compatibility effect in which the topographical features of task-irrelevant action stimuli facilitate similar, and interfere with dissimilar, responses. This article reviews behavioral, neurophysiological, and neuroimaging research on automatic imitation, asking in what sense it is ""automatic"" and whether it is ""imitation."" This body of research reveals that automatic imitation is a covert form of imitation, distinct from spatial compatibility. It also indicates that, although automatic imitation is subject to input modulation by attentional processes, and output modulation by inhibitory processes, it is mediated by learned, long-term sensorimotor associations that cannot be altered directly by intentional processes. Automatic imitation provides an important tool for the investigation of the mirror neuron system, motor mimicry, and complex forms of imitation. It is a new behavioral phenomenon, comparable with the Stroop and Simon effects, providing strong evidence that even healthy adult humans are prone, in an unwilled and unreasoned way, to copy the actions of others.",2011.0,130.0,464.0,False,,"{'volume': '137 3', 'pages': '\n          463-83\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Heyes2011AutomaticI,\n author = {C. Heyes},\n journal = {Psychological bulletin},\n pages = {\n          463-83\n        },\n title = {Automatic imitation.},\n volume = {137 3},\n year = {2011}\n}\n'}","[{'authorId': '31433567', 'name': 'C. Heyes'}]"
350,1dff919e51c262c22630955972968f38ba385d8a,Toward an affect-sensitive multimodal human-computer interaction,"The ability to recognize affective states of a person we are communicating with is the core of emotional intelligence. Emotional intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for successful interpersonal social interaction. This paper argues that next-generation human-computer interaction (HCI) designs need to include the essence of emotional intelligence - the ability to recognize a user's affective states-in order to become more human-like, more effective, and more efficient. Affective arousal modulates all nonverbal communicative cues (facial expressions, body movements, and vocal and physiological reactions). In a face-to-face interaction, humans detect and interpret those interactive signals of their communicator with little or no effort. Yet design and development of an automated system that accomplishes these tasks is rather difficult. This paper surveys the past work in solving these problems by a computer and provides a set of recommendations for developing the first part of an intelligent multimodal HCI-an automatic personalized analyzer of a user's nonverbal affective feedback.",2003.0,132.0,850.0,True,"{'url': 'https://repository.tudelft.nl/islandora/object/uuid%3A4f51cceb-1d54-426e-82ce-0e234f1ea32e/datastream/OBJ/download', 'status': None}","{'volume': '91', 'pages': '1370-1390', 'name': 'Proc. IEEE'}","{'bibtex': '@Article{Pantic2003TowardAA,\n author = {M. Pantic and L. Rothkrantz},\n journal = {Proc. IEEE},\n pages = {1370-1390},\n title = {Toward an affect-sensitive multimodal human-computer interaction},\n volume = {91},\n year = {2003}\n}\n'}","[{'authorId': '145387780', 'name': 'M. Pantic'}, {'authorId': '1713654', 'name': 'L. Rothkrantz'}]"
351,1e0e0369f8d5921c23c38a4d1e4df06448f3e998,A social gamification framework for a K-6 learning platform,,2013.0,37.0,731.0,False,,"{'volume': '29', 'pages': '345-353', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Simões2013ASG,\n author = {Jorge Simões and R. Redondo and Ana Fernández Vilas},\n journal = {Comput. Hum. Behav.},\n pages = {345-353},\n title = {A social gamification framework for a K-6 learning platform},\n volume = {29},\n year = {2013}\n}\n'}","[{'authorId': '145832709', 'name': 'Jorge Simões'}, {'authorId': '1719660', 'name': 'R. Redondo'}, {'authorId': '1683554', 'name': 'Ana Fernández Vilas'}]"
352,1e2355cea9da54478de58efdec1e4f8e995cf231,"Probe, count, and classify: categorizing hidden web databases","The contents of many valuable web-accessible databases are only accessible through search interfaces and are hence invisible to traditional web “crawlers.” Recent studies have estimated the size of this “hidden web” to be 500 billion pages, while the size of the “crawlable” web is only an estimated two billion pages. Recently, commercial web sites have started to manually organize web-accessible databases into Yahoo!-like hierarchical classification schemes. In this paper, we introduce a method for automating this classification process by using a small number of query probes. To classify a database, our algorithm does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of our technique over collections of real documents, including over one hundred web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",2001.0,30.0,186.0,False,,{'pages': '67-78'},"{'bibtex': '@Inproceedings{Ipeirotis2001ProbeCA,\n author = {Panagiotis G. Ipeirotis and L. Gravano and M. Sahami},\n pages = {67-78},\n title = {Probe, count, and classify: categorizing hidden web databases},\n year = {2001}\n}\n'}","[{'authorId': '2942126', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '1684012', 'name': 'L. Gravano'}, {'authorId': '1764547', 'name': 'M. Sahami'}]"
353,1e43c7084bdcb6b3102afaf301cce10faead2702,BioBERT: a pre-trained biomedical language representation model for biomedical text mining,"Abstract Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.",2019.0,45.0,3626.0,True,,"{'volume': '36', 'pages': '1234 - 1240', 'name': 'Bioinformatics'}","{'bibtex': '@Article{Lee2019BioBERTAP,\n author = {Jinhyuk Lee and Wonjin Yoon and Sungdong Kim and Donghyeon Kim and Sunkyu Kim and Chan Ho So and Jaewoo Kang},\n journal = {Bioinformatics},\n pages = {1234 - 1240},\n title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},\n volume = {36},\n year = {2019}\n}\n'}","[{'authorId': '46664096', 'name': 'Jinhyuk Lee'}, {'authorId': '51433082', 'name': 'Wonjin Yoon'}, {'authorId': '2829848', 'name': 'Sungdong Kim'}, {'authorId': '2145183568', 'name': 'Donghyeon Kim'}, {'authorId': '2144247125', 'name': 'Sunkyu Kim'}, {'authorId': '51435068', 'name': 'Chan Ho So'}, {'authorId': '144323862', 'name': 'Jaewoo Kang'}]"
354,1e61bc7abe5fd33102c5bc4e21ab8a1627cbcdfc,The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents,"Previous studies regarding the perception of emotions for embodied virtual agents have shown the effectiveness of using virtual characters in conveying emotions through interactions with humans. However, creating an autonomous embodied conversational agent with expressive behaviors presents two major challenges. The first challenge is the difficulty of synthesizing the conversational behaviors for each modality that are as expressive as real human behaviors. The second challenge is that the affects are modeled independently, which makes it difficult to generate multimodal responses with consistent emotions across all modalities. In this work, we propose a conceptual framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We have conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimodal behaviors that are consistent and inconsistent with respect to a driving affect. The result shows that among all model conditions, our affect-consistent framework receives the highest Likert scores for the perception of driving affects. Our statistical analysis suggests that making a modality affect-inconsistent significantly decreases the perception of driving affects. We also observe that multimodal behaviors conditioned on consistent affects are more expressive compared to behaviors with inconsistent affects. Therefore, we conclude that multimodal emotion conditioning and affect consistency are vital to enhancing the perception of affects for embodied conversational agents.",2023.0,68.0,1.0,True,"{'url': 'https://arxiv.org/pdf/2309.15311', 'status': 'GREEN'}",{'name': 'Proceedings of the 28th International Conference on Intelligent User Interfaces'},"{'bibtex': '@Article{Chang2023TheIO,\n author = {Che-Jui Chang and Samuel S. Sohn and Sen Zhang and R. Jayashankar and Muhammad Usman and M. Kapadia},\n booktitle = {International Conference on Intelligent User Interfaces},\n journal = {Proceedings of the 28th International Conference on Intelligent User Interfaces},\n title = {The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents},\n year = {2023}\n}\n'}","[{'authorId': '2152342254', 'name': 'Che-Jui Chang'}, {'authorId': '51118484', 'name': 'Samuel S. Sohn'}, {'authorId': '2175553614', 'name': 'Sen Zhang'}, {'authorId': '2089478166', 'name': 'R. Jayashankar'}, {'authorId': '145274939', 'name': 'Muhammad Usman'}, {'authorId': '143980997', 'name': 'M. Kapadia'}]"
355,1e7ae86a78a9b4860aa720fb0fd0bdc199b092c3,A Brief Review of Facial Emotion Recognition Based on Visual Information,"Facial emotion recognition (FER) is an important topic in the fields of computer vision and artificial intelligence owing to its significant academic and commercial potential. Although FER can be conducted using multiple sensors, this review focuses on studies that exclusively use facial images, because visual expressions are one of the main information channels in interpersonal communication. This paper provides a brief review of researches in the field of FER conducted over the past decades. First, conventional FER approaches are described along with a summary of the representative categories of FER systems and their main algorithms. Deep-learning-based FER approaches using deep networks enabling “end-to-end” learning are then presented. This review also focuses on an up-to-date hybrid deep-learning approach combining a convolutional neural network (CNN) for the spatial features of an individual frame and long short-term memory (LSTM) for temporal features of consecutive frames. In the later part of this paper, a brief review of publicly available evaluation metrics is given, and a comparison with benchmark results, which are a standard for a quantitative comparison of FER researches, is described. This review can serve as a brief guidebook to newcomers in the field of FER, providing basic knowledge and a general understanding of the latest state-of-the-art studies, as well as to experienced researchers looking for productive directions for future work.",2018.0,71.0,474.0,True,"{'url': 'https://www.mdpi.com/1424-8220/18/2/401/pdf?version=1517478090', 'status': None}","{'volume': '18', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Ko2018ABR,\n author = {ByoungChul Ko},\n journal = {Sensors (Basel, Switzerland)},\n title = {A Brief Review of Facial Emotion Recognition Based on Visual Information},\n volume = {18},\n year = {2018}\n}\n'}","[{'authorId': '144893429', 'name': 'ByoungChul Ko'}]"
356,1e9ac01955e4d6eb74b9a84d6db4d34ae4189139,Autonomic nervous system activity distinguishes among emotions.,"Emotion-specific activity in the autonomic nervous system was generated by constructing facial prototypes of emotion muscle by muscle and by reliving past emotional experiences. The autonomic activity produced distinguished not only between positive and negative emotions, but also among negative emotions. This finding challenges emotion theories that have proposed autonomic activity to be undifferentiated or that have failed to address the implications of autonomic differentiation in emotion.",1983.0,20.0,2203.0,False,,"{'volume': '221 4616', 'pages': '\n          1208-10\n        ', 'name': 'Science'}","{'bibtex': '@Article{Ekman1983AutonomicNS,\n author = {P. Ekman and R. Levenson and W. Friesen},\n journal = {Science},\n pages = {\n          1208-10\n        },\n title = {Autonomic nervous system activity distinguishes among emotions.},\n volume = {221 4616},\n year = {1983}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '2001910', 'name': 'R. Levenson'}, {'authorId': '1388284460', 'name': 'W. Friesen'}]"
357,1ea72869254a3ea03d76cdd27cf36ca1d5698efc,Interaction of affect and cognition in empathy.,,1985.0,0.0,511.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hoffman1985InteractionOA,\n author = {M. Hoffman},\n title = {Interaction of affect and cognition in empathy.},\n year = {1985}\n}\n'}","[{'authorId': '82128751', 'name': 'M. Hoffman'}]"
358,1eaf4944c6ffa38586942a18a4bedb429a31e1a5,The Importance of Interface Agent Visual Presence: Voice Alone Is Less Effective in Impacting Young Women's Attitudes Toward Engineering,,2007.0,20.0,26.0,False,,{'pages': '214-222'},"{'bibtex': ""@Inproceedings{Rosenberg-Kima2007TheIO,\n author = {Rinat B. Rosenberg-Kima and A. L. Baylor and E. Plant and Celeste E. Doerr},\n pages = {214-222},\n title = {The Importance of Interface Agent Visual Presence: Voice Alone Is Less Effective in Impacting Young Women's Attitudes Toward Engineering},\n year = {2007}\n}\n""}","[{'authorId': '1399253964', 'name': 'Rinat B. Rosenberg-Kima'}, {'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '145202321', 'name': 'E. Plant'}, {'authorId': '2977014', 'name': 'Celeste E. Doerr'}]"
359,1eb09fecd75eb27825dce4f964b97f4f5cc399d7,On the Properties of Neural Machine Translation: Encoder–Decoder Approaches,"Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",2014.0,15.0,5804.0,True,"{'url': 'https://aclanthology.org/W14-4012.pdf', 'status': None}",{'pages': '103-111'},"{'bibtex': '@Inproceedings{Cho2014OnTP,\n author = {Kyunghyun Cho and Bart van Merrienboer and Dzmitry Bahdanau and Yoshua Bengio},\n pages = {103-111},\n title = {On the Properties of Neural Machine Translation: Encoder–Decoder Approaches},\n year = {2014}\n}\n'}","[{'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '3158246', 'name': 'Bart van Merrienboer'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]"
360,1eb30effd2270bacad81d417293283441729056f,Influence by CG Agent in the Virtual Space to Emotion at the Time of Viewing Fear Video,"Recently, several systems have been proposed which display a virtual display in a VR space and provide a working environment equivalent to everyday life. In particular, “Mikulus”[15] provides an environment where a CG agent is always sitting next to users. In this paper, we focused on the experience of evoking fear and revealed the difference in emotional evoked from experience by CG agent in the virtual space. In the experiment, we used film to evoke fear emotion, we compared conditions for viewing with one participant with the condition of CG agent. We investigated the emotion evoked from the experience by rating the valence/arousal dimension scales and 18 emotion intensity scales. Experimental results showed that there is a difference in the emotion evoked from the experience by CG agent in the virtual space.",2016.0,2.0,0.0,False,,,"{'bibtex': '@Inproceedings{Takai2016InfluenceBC,\n author = {Nanako Takai and Homei Miyashita},\n title = {Influence by CG Agent in the Virtual Space to Emotion at the Time of Viewing Fear Video},\n year = {2016}\n}\n'}","[{'authorId': '2075020479', 'name': 'Nanako Takai'}, {'authorId': '1796760', 'name': 'Homei Miyashita'}]"
361,1ecf14d63f0e5f6868b111c8cc65325161b6a003,Integrating the OCC model of emotions in embodied characters,"The OCC (Ortony, Clore, & Collins, 1988) model has established itself as the standard model for emotion synthesis. A large number of studies employed the OCC model to generate emotions for their embodied characters. Many developers of such characters believe that the OCC model will be all they ever need to equip their character with emotions. This paper points out what the OCC model is able to do for an embodied emotional character and what it does not. Missing features include a history function, a personality designer and the interaction of the emotional categories.",2002.0,16.0,151.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bartneck2002IntegratingTO,\n author = {C. Bartneck},\n title = {Integrating the OCC model of emotions in embodied characters},\n year = {2002}\n}\n'}","[{'authorId': '1728894', 'name': 'C. Bartneck'}]"
362,1f2186c2a89c4b39ca370ecede10744f8b593073,The Expression of the Emotions in Man and Animals,,2009.0,0.0,643.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Messenger2009TheEO,\n author = {S. Messenger},\n title = {The Expression of the Emotions in Man and Animals},\n year = {2009}\n}\n'}","[{'authorId': '2240187143', 'name': 'S. Messenger'}]"
364,1f268af7aef9da4c87dbef6843d69ff7cfafdeb8,Psychological Parameters for Crowd Simulation: From Audiences to Mobs,"In the social psychology literature, crowds are classified as audiences and mobs. Audiences are passive crowds, whereas mobs are active crowds with emotional, irrational and seemingly homogeneous behavior. In this study, we aim to create a system that enables the specification of different crowd types ranging from audiences to mobs. In order to achieve this goal we parametrize the common properties of mobs to create collective misbehavior. Because mobs are characterized by emotionality, we describe a framework that associates psychological components with individual agents comprising a crowd and yields emergent behaviors in the crowd as a whole. To explore the effectiveness of our framework we demonstrate two scenarios simulating the behavior of distinct mob types.",2016.0,67.0,102.0,False,,"{'volume': '22', 'pages': '2145-2159', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Durupinar2016PsychologicalPF,\n author = {Funda Durupinar and U. Güdükbay and Aytek Aman and N. Badler},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {2145-2159},\n title = {Psychological Parameters for Crowd Simulation: From Audiences to Mobs},\n volume = {22},\n year = {2016}\n}\n'}","[{'authorId': '2643744', 'name': 'Funda Durupinar'}, {'authorId': '1746035', 'name': 'U. Güdükbay'}, {'authorId': '3435784', 'name': 'Aytek Aman'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
366,1f43724e9c47159c33dd3dbbb97efec885e9fab8,"EYE-CONTACT, DISTANCE AND AFFILIATION.","Previous evidence suggests that eye-contact serves a number of different functions in two-person encounters, of which one of the most important is gathering feed-back on the other person's reactions. It is further postulated that eye-contact is linked to affiliative motivation, and that approach and avoidance forces produce an equilibrium level of physical proximity, eyecontact and other aspects of intimacy. If one of these is disturbed, compensatory changes may occur along the other dimensions. Experiments are reported which suggest that people move towards an equilibrium distance, and adopt a particular level of eye-contact. As predicted, there was less eyecontact and glances were shorter, the closer two subjects were placed together (where one member of each pair was a confederate who gazed continuously at the other). The effect was greatest for opposite-sex pairs. In another experiment it was found that subjects would stand closer to a second person when his eyes were shut, as predicted by the theory.",1965.0,0.0,1739.0,False,,"{'volume': '28', 'pages': '\n          289-304\n        ', 'name': 'Sociometry'}","{'bibtex': '@Article{Argyle1965EYECONTACTDA,\n author = {M. Argyle and Janet B. Dean},\n journal = {Sociometry},\n pages = {\n          289-304\n        },\n title = {EYE-CONTACT, DISTANCE AND AFFILIATION.},\n volume = {28},\n year = {1965}\n}\n'}","[{'authorId': '2409411', 'name': 'M. Argyle'}, {'authorId': '11938736', 'name': 'Janet B. Dean'}]"
367,1f95ede26b61c14f685c3a65d601492b693cda5a,Effectiveness of an Empathic Chatbot in Combating Adverse Effects of Social Exclusion on Mood,"From past research it is well known that social exclusion has detrimental consequences for mental health. To deal with these adverse effects, socially excluded individuals frequently turn to other humans for emotional support. While chatbots can elicit social and emotional responses on the part of the human interlocutor, their effectiveness in the context of social exclusion has not been investigated. In the present study, we examined whether an empathic chatbot can serve as a buffer against the adverse effects of social ostracism. After experiencing exclusion on social media, participants were randomly assigned to either talk with an empathetic chatbot about it (e.g., “I’m sorry that this happened to you”) or a control condition where their responses were merely acknowledged (e.g., “Thank you for your feedback”). Replicating previous research, results revealed that experiences of social exclusion dampened the mood of participants. Interacting with an empathetic chatbot, however, appeared to have a mitigating impact. In particular, participants in the chatbot intervention condition reported higher mood than those in the control condition. Theoretical, methodological, and practical implications, as well as directions for future research are discussed.",2020.0,149.0,73.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.03061/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Gennaro2020EffectivenessOA,\n author = {Mauro de Gennaro and Eva G. Krumhuber and Gale M. Lucas},\n journal = {Frontiers in Psychology},\n title = {Effectiveness of an Empathic Chatbot in Combating Adverse Effects of Social Exclusion on Mood},\n volume = {10},\n year = {2020}\n}\n'}","[{'authorId': '1490663549', 'name': 'Mauro de Gennaro'}, {'authorId': '50755536', 'name': 'Eva G. Krumhuber'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}]"
368,1f997cae6989be7348492677554e84276f3c602b,Defining and quantifying the social phenotype in autism.,"OBJECTIVE
Genetic and neurofunctional research in autism has highlighted the need for improved characterization of the core social disorder defining the broad spectrum of syndrome manifestations.


METHOD
This article reviews the advantages and limitations of current methods for the refinement and quantification of this highly heterogeneous social phenotype.


RESULTS
The study of social visual pursuit by use of eye-tracking technology is offered as a paradigm for novel tools incorporating these requirements and as a research effort that builds on the emerging synergy of different branches of social neuroscience.


CONCLUSIONS
Advances in the area will require increased consideration of processes underlying experimental results and a closer approximation of experimental methods to the naturalistic demands inherent in real-life social situations.",2002.0,58.0,445.0,False,,"{'volume': '159 6', 'pages': '\n          895-908\n        ', 'name': 'The American journal of psychiatry'}","{'bibtex': '@Article{Klin2002DefiningAQ,\n author = {A. Klin and W. Jones and R. Schultz and F. Volkmar and D. Cohen},\n journal = {The American journal of psychiatry},\n pages = {\n          895-908\n        },\n title = {Defining and quantifying the social phenotype in autism.},\n volume = {159 6},\n year = {2002}\n}\n'}","[{'authorId': '6261339', 'name': 'A. Klin'}, {'authorId': '8137420', 'name': 'W. Jones'}, {'authorId': '145157155', 'name': 'R. Schultz'}, {'authorId': '2155644', 'name': 'F. Volkmar'}, {'authorId': '48858469', 'name': 'D. Cohen'}]"
369,1fc6a09dc106d5e5bbbb07da1d3bfaee425e872b,Moving Smiles: The Role of Dynamic Components for the Perception of the Genuineness of Smiles,,2005.0,35.0,181.0,False,,"{'volume': '29', 'pages': '3-24', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Krumhuber2005MovingST,\n author = {Eva G. Krumhuber and Arvid Kappas},\n journal = {Journal of Nonverbal Behavior},\n pages = {3-24},\n title = {Moving Smiles: The Role of Dynamic Components for the Perception of the Genuineness of Smiles},\n volume = {29},\n year = {2005}\n}\n'}","[{'authorId': '50755536', 'name': 'Eva G. Krumhuber'}, {'authorId': '1742554', 'name': 'Arvid Kappas'}]"
370,1fe2f8fdcb94c4872f78198310ea367bcb0e7160,Cognition and motivation in emotion.,"The role of cognition--and to some extent motivation--in emotion, the ways meaning is generated, unconscious appraising, and the implications of this way of thinking for life-span development are addressed. It is argued that appraisal is a necessary as well as sufficient cause of emotion and that knowledge is necessary but not sufficient. This position is examined in light of what is known about emotions in infants and young children, the effects of drugs on acute emotions and moods, and recent patterns of thought about the brain in emotions. The discussion of how meaning is generated is the core of the article. Automatic processing without awareness is contrasted with deliberate and conscious processing, and the concept of resonance between an animal's needs and what is encountered in the environment is examined. The idea that there is more than one way meaning is achieved strengthens and enriches the case for the role of appraisal in emotion and allows the consideration of what is meant by unconscious and preconscious appraisal and the examination of how they might work.",1991.0,103.0,1568.0,False,,"{'volume': '46 4', 'pages': '\n          352-67\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Lazarus1991CognitionAM,\n author = {R. Lazarus},\n journal = {The American psychologist},\n pages = {\n          352-67\n        },\n title = {Cognition and motivation in emotion.},\n volume = {46 4},\n year = {1991}\n}\n'}","[{'authorId': '5628684', 'name': 'R. Lazarus'}]"
371,1ff3c02d1d1f9183072a08e1c428dc8ad3840f3b,Memory: a contribution to experimental psychology.,"The first scientific text on the psychology of memory. Relating retention to repetition, describing the shape of the forgetting curve, and measuring strength of association, Hermann Ebbinghaus extended the province of systematic, experimental research to the higher mental processes.",1987.0,0.0,687.0,True,"{'url': 'https://europepmc.org/articles/pmc4117135?pdf=render', 'status': None}","{'volume': '20 4', 'pages': '\n          155-6\n        ', 'name': 'Annals of neurosciences'}","{'bibtex': '@Article{Ebbinghaus1987MemoryAC,\n author = {H. Ebbinghaus},\n journal = {Annals of neurosciences},\n pages = {\n          155-6\n        },\n title = {Memory: a contribution to experimental psychology.},\n volume = {20 4},\n year = {1987}\n}\n'}","[{'authorId': '70675558', 'name': 'H. Ebbinghaus'}]"
372,201f5453af05a0cdd847574f90dbcdbed7fbadfa,Global and local covert visual attention: Evidence from a bayesian hidden markov model,,2003.0,41.0,125.0,True,"{'url': 'http://deepblue.lib.umich.edu/bitstream/2027.42/45759/1/11336_2005_Article_BF02295608.pdf', 'status': None}","{'volume': '68', 'pages': '519-541', 'name': 'Psychometrika'}","{'bibtex': '@Article{Liechty2003GlobalAL,\n author = {J. Liechty and R. Pieters and M. Wedel},\n journal = {Psychometrika},\n pages = {519-541},\n title = {Global and local covert visual attention: Evidence from a bayesian hidden markov model},\n volume = {68},\n year = {2003}\n}\n'}","[{'authorId': '2713726', 'name': 'J. Liechty'}, {'authorId': '47134946', 'name': 'R. Pieters'}, {'authorId': '122115499', 'name': 'M. Wedel'}]"
373,20272d748f5502f34fc4988228fb2377f7dd29f7,Auton Agent Multi-Agent Syst DOI 10.1007/s10458-009-9093-x Modeling appraisal in theory of mind reasoning,,,0.0,70.0,False,,,"{'bibtex': '@Misc{None,\n title = {Auton Agent Multi-Agent Syst DOI 10.1007/s10458-009-9093-x Modeling appraisal in theory of mind reasoning}\n}\n'}",[]
375,204cbf99a359f38599ed0ebd0d84c6bc50c21c80,Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective Expression Learning,"We present a generative adversarial network to synthesize 3D pose sequences of co-speech upper-body gestures with appropriate affective expressions. Our network consists of two components: a generator to synthesize gestures from a joint embedding space of features encoded from the input speech and the seed poses, and a discriminator to distinguish between the synthesized pose sequences and real 3D pose sequences. We leverage the Mel-frequency cepstral coefficients and the text transcript computed from the input speech in separate encoders in our generator to learn the desired sentiments and the associated affective cues. We design an affective encoder using multi-scale spatial-temporal graph convolutions to transform 3D pose sequences into latent, pose-based affective features. We use our affective encoder in both our generator, where it learns affective features from the seed poses to guide the gesture synthesis, and our discriminator, where it enforces the synthesized gestures to contain the appropriate affective expressions. We perform extensive evaluations on two benchmark datasets for gesture synthesis from the speech, the TED Gesture Dataset and the GENEA Challenge 2020 Dataset. Compared to the best baselines, we improve the mean absolute joint error by 10-33%, the mean acceleration difference by 8-58%, and the Fréchet Gesture Distance by 21-34%. We also conduct a user study and observe that compared to the best current baselines, around 15.28% of participants indicated our synthesized gestures appear more plausible, and around 16.32% of participants felt the gestures had more appropriate affective expressions aligned with the speech.",2021.0,63.0,45.0,True,"{'url': 'https://arxiv.org/pdf/2108.00262', 'status': None}",{'name': 'Proceedings of the 29th ACM International Conference on Multimedia'},"{'bibtex': '@Article{Bhattacharya2021Speech2AffectiveGesturesSC,\n author = {Uttaran Bhattacharya and Elizabeth Childs and Nicholas Rewkowski and Dinesh Manocha},\n journal = {Proceedings of the 29th ACM International Conference on Multimedia},\n title = {Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective Expression Learning},\n year = {2021}\n}\n'}","[{'authorId': '50227009', 'name': 'Uttaran Bhattacharya'}, {'authorId': '2122327690', 'name': 'Elizabeth Childs'}, {'authorId': '10172108', 'name': 'Nicholas Rewkowski'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
376,204e3073870fae3d05bcbc2f6a8e263d9b72e776,Attention is All you Need,"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",2017.0,42.0,75629.0,False,,{'pages': '5998-6008'},"{'bibtex': '@Inproceedings{Vaswani2017AttentionIA,\n author = {Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},\n pages = {5998-6008},\n title = {Attention is All you Need},\n year = {2017}\n}\n'}","[{'authorId': '40348417', 'name': 'Ashish Vaswani'}, {'authorId': '1846258', 'name': 'Noam M. Shazeer'}, {'authorId': '3877127', 'name': 'Niki Parmar'}, {'authorId': '39328010', 'name': 'Jakob Uszkoreit'}, {'authorId': '145024664', 'name': 'Llion Jones'}, {'authorId': '19177000', 'name': 'Aidan N. Gomez'}, {'authorId': '40527594', 'name': 'Lukasz Kaiser'}, {'authorId': '3443442', 'name': 'Illia Polosukhin'}]"
379,207f821cb8374e615a5ad6cd902653411806a24b,SimCoach: an intelligent virtual human system for providing healthcare information and support,"Abstract Over the last 15 years, a virtual revolution has taken place in the use of Virtual Reality simulation technology for clinical purposes. Shifts in the social and scientific landscape have now set the stage for the next major movement in Clinical Virtual Reality with the “birth” of intelligent virtual humans. Seminal research and development has appeared in the creation of highly interactive, artificially intelligent and natural language capable virtual human agents that can engage real human users in a credible fashion. No longer at the level of a prop to add context or minimal faux interaction in a virtual world, virtual humans can be designed to perceive and act in a 3D virtual world, engage in spoken dialogs with real users and can be capable of exhibiting human-like emotional reactions. This paper will present an overview of the SimCoach project that aims to develop virtual human support agents to serve as online guides for promoting access to psychological healthcare information and for assisting military personnel and family members in breaking down barriers to initiating care. The SimCoach experience is being designed to attract and engage military Service Members, Veterans and their significant others who might not otherwise seek help with a live healthcare provider. It is expected that this experience will motivate users to take the first step – to empower themselves to seek advice and information regarding their healthcare and general personal welfare and encourage them to take the next step towards seeking other, more formal resources if needed.",2011.0,43.0,85.0,False,,"{'volume': '10', 'pages': '277 - 281'}","{'bibtex': '@Inproceedings{Rizzo2011SimCoachAI,\n author = {Albert Rizzo and Belinda Lange and J. Galen Buckwalter and Kenji Sagae and Julia Kim and Kenji Sagae and Josh Williams and J. Difede and B. Rothbaum and Greg Reger and Thomas Parsons and Patrick Kenny},\n pages = {277 - 281},\n title = {SimCoach: an intelligent virtual human system for providing healthcare information and support},\n volume = {10},\n year = {2011}\n}\n'}","[{'authorId': '2255096086', 'name': 'Albert Rizzo'}, {'authorId': '2255149426', 'name': 'Belinda Lange'}, {'authorId': '145024149', 'name': 'J. Galen Buckwalter'}, {'authorId': '1757166', 'name': 'Kenji Sagae'}, {'authorId': '2257313920', 'name': 'Julia Kim'}, {'authorId': '2257213198', 'name': 'Kenji Sagae'}, {'authorId': '2257375476', 'name': 'Josh Williams'}, {'authorId': '2572088', 'name': 'J. Difede'}, {'authorId': '1831766', 'name': 'B. Rothbaum'}, {'authorId': '2244890836', 'name': 'Greg Reger'}, {'authorId': '2244890070', 'name': 'Thomas Parsons'}, {'authorId': '2264170075', 'name': 'Patrick Kenny'}]"
380,2092d7d2154d6e28c4a27607d9702c296da35b3c,A gamified and adaptive learning system for neurodivergent workers in electronic assembling tasks,"Learning and work-oriented assistive systems are often designed to fit the workflow of neurotypical workers. Neurodivergent workers and individuals with learning disabilities often present cognitive and sensorimotor characteristics that are better accommodated with personalized learning and working processes. Therefore, we designed an adaptive learning system that combines an augmented interaction space with user-sensitive virtual assistance to support step-by-step guidance for neurodivergent workers in electronic assembling tasks. Gamified learning elements were also included in the interface to provide self-motivation and praise whenever users progress in their learning and work achievements.",2020.0,18.0,7.0,False,,{'name': 'Proceedings of Mensch und Computer 2020'},"{'bibtex': '@Article{Grund2020AGA,\n author = {Jonas Grund and Moritz Umfahrer and Lea Buchweitz and James Gay and A. Theil and Oliver Korn},\n journal = {Proceedings of Mensch und Computer 2020},\n title = {A gamified and adaptive learning system for neurodivergent workers in electronic assembling tasks},\n year = {2020}\n}\n'}","[{'authorId': '1932186671', 'name': 'Jonas Grund'}, {'authorId': '1780741096', 'name': 'Moritz Umfahrer'}, {'authorId': '71985197', 'name': 'Lea Buchweitz'}, {'authorId': '1780755254', 'name': 'James Gay'}, {'authorId': '1791011689', 'name': 'A. Theil'}, {'authorId': '50069571', 'name': 'Oliver Korn'}]"
381,20ae1a58249bb2fd4bc7f0b72f47f0e50cd6d26f,Treating complex traumatic stress disorders: An evidence-based guide.,"Herman, Foreword. Courtois, Ford, Introduction. Part I: Overview. Ford, Courtois, Defining and Understanding Complex Trauma and Complex Traumatic Stress Disorders. Ford, Neurobiological and Developmental Research: Clinical Implications. Ford, Cloitre, Best Practices in Psychotherapy for Children and Adolescents. Courtois, Ford, Cloitre, Best Practices in Psychotherapy for Adults. Briere, Spinazzola, Assessment of the Sequelae of Complex Trauma: Evidence-based Measures. Brown, Attachment and Abuse History, and Adult Attachment Style. Steele, van der Hart, Treating Dissociation. Brown, Cultural Competence. Kinsler, Courtois, Frankel, Therapeutic Alliance and Risk Management. Pearlman, Caringi, Living and Working Self-reflectively to Address Vicarious Trauma. Part II: Individual Treatment Approaches and Strategies. Gold, Contextual Therapy. Jackson, Nissenson, Cloitre, Cognitive-Behavioral Therapy. Follette, Iverson, Ford, Contextual Behavior Trauma Therapy. Fosha, Paivio, Gleiser, Ford, Experiential and Emotion-focused Therapy. Fisher, Ogden, Sensorimotor Psychotherapy. Opler, Grennan, Ford, Pharmacotherapy. Part III: Systemic Treatment Approaches and Strategies. R. C. Schwartz, M. F. Schwartz, Galperin, Internal Family Systems Therapy. Johnson, Courtois, Couple Therapy. Ford, Saltzman, Family Systems Therapy. Ford, Fallot, Harris, Group Therapy. Ford, Courtois, Conclusion: The Clinical Utility of a Complex Traumatic Stress Disorders Framework. van der Kolk, Afterword.",2009.0,6.0,639.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Courtois2009TreatingCT,\n author = {C. Courtois and Julian D. Norton-Ford and J. Herman and B. Kolk},\n title = {Treating complex traumatic stress disorders: An evidence-based guide.},\n year = {2009}\n}\n'}","[{'authorId': '1690921', 'name': 'C. Courtois'}, {'authorId': '1411956410', 'name': 'Julian D. Norton-Ford'}, {'authorId': '84268272', 'name': 'J. Herman'}, {'authorId': '5223699', 'name': 'B. Kolk'}]"
382,20aeb2357e9e215787c7e0d0acfe7a6b598c9103,ggplot2 - Elegant Graphics for Data Analysis,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009.0,2.0,31248.0,False,,"{'pages': 'I-VIII, 1-212'}","{'bibtex': '@Inproceedings{Wickham2009ggplot2E,\n author = {H. Wickham},\n pages = {I-VIII, 1-212},\n title = {ggplot2 - Elegant Graphics for Data Analysis},\n year = {2009}\n}\n'}","[{'authorId': '2768970', 'name': 'H. Wickham'}]"
383,20bd99f241af8de6afe4ad8e6a1bb9f8a3526d29,Being There: Participants and Spectators in Interactive Narrative,,2007.0,23.0,31.0,True,"{'url': 'http://www.macs.hw.ac.uk/~ruth/Papers/narrative/ICVS2007AylettLouchart.pdf', 'status': None}",{'pages': '117-128'},"{'bibtex': '@Inproceedings{Aylett2007BeingTP,\n author = {R. Aylett and S. Louchart},\n pages = {117-128},\n title = {Being There: Participants and Spectators in Interactive Narrative},\n year = {2007}\n}\n'}","[{'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '2910576', 'name': 'S. Louchart'}]"
384,20e46645368a96070d6ceb5198fe73ba170843f9,Can I Say Something? The Effects of Digital Game Play on Willingness to Communicate.,"Hayo Reinders, Unitec Institute of Technology Sorada Wattana, Dhurakij Pundit University This paper reports on a study into the effects of digital game play on learners’ Willingness to Communicate (WTC), or individuals’ “readiness to enter into discourse at a particular time with a specific person or persons, using a L2” (MacIntyre, Dörnyei, Clément, & Noels, 1998, p. 547). Thirty Thai learners of English as a foreign language enrolled in a University language course completed six 90–minute lessons playing Ragnarok Online, a popular online role–playing game. The game had been installed on a private server and was thus only available to participants in the study. We modified the game to include special instructions, or quests (missions that players are assigned to accomplish in order to get items and progress throughout the game), designed to encourage collaboration and communication. To gauge participants’ WTC, a series of questionnaires was designed, adapted from MacIntyre et al’s (2001) WTC scale and previous studies on language and communication anxiety (Horwitz, Horwitz, & Cope, 1986; McCroskey & Richmond, 1982) and perceived competence (Compton, 2004; MacIntyre & Charos, 1996). These asked respondents about their (own perceptions of their) willingness to use English, as well as their confidence, anxiety, and perceived communicative competence in communicating in English. The questionnaires were administered at the start of the course, and again after six gaming sessions. Results on the first set of questionnaires showed that students had low confidence, high anxiety, low perceived competence, and low WTC. The second set of results showed a marked and significant improvement, with participants feeling more confident, less anxious, more competent, and more willing to communicate. We argue that the careful construction of tasks that draw on the affordances of games can have a positive effect on the language learning process.",2014.0,62.0,158.0,False,,"{'volume': '18', 'pages': '101-123', 'name': 'Language Learning & Technology'}","{'bibtex': '@Article{Reinders2014CanIS,\n author = {H. Reinders and S. Wattana},\n journal = {Language Learning & Technology},\n pages = {101-123},\n title = {Can I Say Something? The Effects of Digital Game Play on Willingness to Communicate.},\n volume = {18},\n year = {2014}\n}\n'}","[{'authorId': '145665734', 'name': 'H. Reinders'}, {'authorId': '2466081', 'name': 'S. Wattana'}]"
385,20ec8a7397ad6c1b37b408037d9186145eab583e,The Lancet Commission on global mental health and sustainable development,,2018.0,272.0,1360.0,True,"{'url': 'https://kclpure.kcl.ac.uk/ws/files/102654274/The_Lancet_Commission_on_PATEL_Firstonline16October2018_GREEN_AAM_CC_BY_NC_ND_.pdf', 'status': None}","{'volume': '392', 'pages': '1553-1598', 'name': 'The Lancet'}","{'bibtex': '@Article{Patel2018TheLC,\n author = {V. Patel and S. Saxena and C. Lund and G. Thornicroft and F. Baingana and P. Bolton and D. Chisholm and P. Collins and J. Cooper and J. Eaton and H. Herrman and Mohammad M. Herzallah and Yueqin Huang and M. Jordans and A. Kleinman and M. Medina-Mora and E. Morgan and Unaiza Niaz and O. Omigbodun and M. Prince and A. Rahman and B. Saraceno and B. Sarkar and Mary J De Silva and I. Singh and Dan J Stein and C. Sunkel and J. Unützer},\n journal = {The Lancet},\n pages = {1553-1598},\n title = {The Lancet Commission on global mental health and sustainable development},\n volume = {392},\n year = {2018}\n}\n'}","[{'authorId': '48687370', 'name': 'V. Patel'}, {'authorId': '46708406', 'name': 'S. Saxena'}, {'authorId': '144573921', 'name': 'C. Lund'}, {'authorId': '5984519', 'name': 'G. Thornicroft'}, {'authorId': '2487998', 'name': 'F. Baingana'}, {'authorId': '145938826', 'name': 'P. Bolton'}, {'authorId': '120889812', 'name': 'D. Chisholm'}, {'authorId': '3602165', 'name': 'P. Collins'}, {'authorId': '144607720', 'name': 'J. Cooper'}, {'authorId': '39875915', 'name': 'J. Eaton'}, {'authorId': '4270012', 'name': 'H. Herrman'}, {'authorId': '3910191', 'name': 'Mohammad M. Herzallah'}, {'authorId': '2108715340', 'name': 'Yueqin Huang'}, {'authorId': '40235023', 'name': 'M. Jordans'}, {'authorId': '145566744', 'name': 'A. Kleinman'}, {'authorId': '102166921', 'name': 'M. Medina-Mora'}, {'authorId': '48281154', 'name': 'E. Morgan'}, {'authorId': '40504038', 'name': 'Unaiza Niaz'}, {'authorId': '153651466', 'name': 'O. Omigbodun'}, {'authorId': '3765838', 'name': 'M. Prince'}, {'authorId': '2148758359', 'name': 'A. Rahman'}, {'authorId': '6742564', 'name': 'B. Saraceno'}, {'authorId': '153676440', 'name': 'B. Sarkar'}, {'authorId': '144901343', 'name': 'Mary J De Silva'}, {'authorId': '46472839', 'name': 'I. Singh'}, {'authorId': '50497484', 'name': 'Dan J Stein'}, {'authorId': '4498538', 'name': 'C. Sunkel'}, {'authorId': '5105053', 'name': 'J. Unützer'}]"
386,20fd615a6ce1193db9260fe23914c73373611095,Multi-Task Learning with Language Modeling for Question Generation,"This paper explores the task of answer-aware questions generation. Based on the attention-based pointer generator model, we propose to incorporate an auxiliary task of language modeling to help question generation in a hierarchical multi-task learning structure. Our joint-learning model enables the encoder to learn a better representation of the input sequence, which will guide the decoder to generate more coherent and fluent questions. On both SQuAD and MARCO datasets, our multi-task learning model boosts the performance, achieving state-of-the-art results. Moreover, human evaluation further proves the high quality of our generated questions.",2019.0,27.0,27.0,True,"{'url': 'https://www.aclweb.org/anthology/D19-1337.pdf', 'status': None}",{'pages': '3392-3397'},"{'bibtex': '@Inproceedings{Zhou2019MultiTaskLW,\n author = {Wenjie Zhou and Minghua Zhang and Yunfang Wu},\n pages = {3392-3397},\n title = {Multi-Task Learning with Language Modeling for Question Generation},\n year = {2019}\n}\n'}","[{'authorId': '1637985357', 'name': 'Wenjie Zhou'}, {'authorId': '48985294', 'name': 'Minghua Zhang'}, {'authorId': '2477658', 'name': 'Yunfang Wu'}]"
387,210dfaa504414e5a98c1b013f86c66204dc614a7,Sentiment Adaptive End-to-End Dialog Systems,"End-to-end learning framework is useful for building dialog systems for its simplicity in training and efficiency in model updating. However, current end-to-end approaches only consider user semantic inputs in learning and under-utilize other user information. Therefore, we propose to include user sentiment obtained through multimodal information (acoustic, dialogic and textual), in the end-to-end learning framework to make systems more user-adaptive and effective. We incorporated user sentiment information in both supervised and reinforcement learning settings. In both settings, adding sentiment information reduced the dialog length and improved the task success rate on a bus information search task. This work is the first attempt to incorporate multimodal user information in the adaptive end-to-end dialog system training framework and attained state-of-the-art performance.",2018.0,47.0,73.0,True,"{'url': 'https://www.aclweb.org/anthology/P18-1140.pdf', 'status': None}",{'pages': '1509-1519'},"{'bibtex': '@Inproceedings{Shi2018SentimentAE,\n author = {Weiyan Shi and Zhou Yu},\n pages = {1509-1519},\n title = {Sentiment Adaptive End-to-End Dialog Systems},\n year = {2018}\n}\n'}","[{'authorId': '8299781', 'name': 'Weiyan Shi'}, {'authorId': '144007938', 'name': 'Zhou Yu'}]"
388,2124dc00971b1dfbfb67b831b960a6901b09393f,Using physiological signals for emotion recognition,,2013.0,0.0,45.0,False,,{'pages': '556-561'},"{'bibtex': '@Inproceedings{Szwoch2013UsingPS,\n author = {W. Szwoch},\n pages = {556-561},\n title = {Using physiological signals for emotion recognition},\n year = {2013}\n}\n'}","[{'authorId': '3175073', 'name': 'W. Szwoch'}]"
389,2154255e3f7d42687c71fcb94b66c5efa5516483,Empathy in Virtual Agents and Robots,"This article surveys the area of computational empathy, analysing different ways by which artificial agents can simulate and trigger empathy in their interactions with humans. Empathic agents can be seen as agents that have the capacity to place themselves into the position of a user’s or another agent’s emotional situation and respond appropriately. We also survey artificial agents that, by their design and behaviour, can lead users to respond emotionally as if they were experiencing the agent’s situation. In the course of this survey, we present the research conducted to date on empathic agents in light of the principles and mechanisms of empathy found in humans. We end by discussing some of the main challenges that this exciting area will be facing in the future.",2017.0,118.0,215.0,False,,"{'volume': '7', 'pages': '1 - 40', 'name': 'ACM Transactions on Interactive Intelligent Systems (TiiS)'}","{'bibtex': '@Article{Paiva2017EmpathyIV,\n author = {Ana Paiva and Iolanda Leite and Hana Boukricha and I. Wachsmuth},\n journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},\n pages = {1 - 40},\n title = {Empathy in Virtual Agents and Robots},\n volume = {7},\n year = {2017}\n}\n'}","[{'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '3262504', 'name': 'Hana Boukricha'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
392,21676cc3fbaea3e6044b2eef259c94b7515fe7b3,Robotic assistants in therapy and education of children with autism: can a small humanoid robot help encourage social interaction skills?,,2005.0,56.0,702.0,True,"{'url': 'https://infoscience.epfl.ch/record/113916/files/robins_et_al2005a.pdf', 'status': None}","{'volume': '4', 'pages': '105-120', 'name': 'Universal Access in the Information Society'}","{'bibtex': '@Article{Robins2005RoboticAI,\n author = {B. Robins and K. Dautenhahn and Te Boekhorst and A. Billard},\n journal = {Universal Access in the Information Society},\n pages = {105-120},\n title = {Robotic assistants in therapy and education of children with autism: can a small humanoid robot help encourage social interaction skills?},\n volume = {4},\n year = {2005}\n}\n'}","[{'authorId': '2100046', 'name': 'B. Robins'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '122175509', 'name': 'Te Boekhorst'}, {'authorId': '1807928', 'name': 'A. Billard'}]"
393,218bc4b63c57b7e1d12c6aa0b11de44a2905b4a8,Are Pedagogical Agents' External Regulation Effective in Fostering Learning with Intelligent Tutoring Systems?,,2016.0,12.0,38.0,False,,{'pages': '197-207'},"{'bibtex': ""@Inproceedings{Azevedo2016ArePA,\n author = {R. Azevedo and S. A. Martin and M. Taub and Nicholas V. Mudrick and Garrett C. Millar and Joseph F. Grafsgaard},\n pages = {197-207},\n title = {Are Pedagogical Agents' External Regulation Effective in Fostering Learning with Intelligent Tutoring Systems?},\n year = {2016}\n}\n""}","[{'authorId': '145394858', 'name': 'R. Azevedo'}, {'authorId': '50383455', 'name': 'S. A. Martin'}, {'authorId': '37057683', 'name': 'M. Taub'}, {'authorId': '3408438', 'name': 'Nicholas V. Mudrick'}, {'authorId': '3408655', 'name': 'Garrett C. Millar'}, {'authorId': '1931563', 'name': 'Joseph F. Grafsgaard'}]"
394,219d2f846cf898d1607b79733a1afc44a2606714,Evaluating the perception of group emotion from full body movements in the context of virtual crowds,"Simulating the behavior of crowds of artificial entities that have humanoid embodiments has become an important element in computer graphics and special effects. However, many important questions remain in relation to the perception of social behavior and expression of emotions in virtual crowds. Specifically, few studies have considered the role of background context on the perception of the full-body emotion expressed by sub-constituents of the crowd i.e. individuals and small groups. In this paper, we present the results of perceptual studies in which animated scenes of expressive virtual crowd behavior were rated in terms of their valence by participants. The behaviors of a task-irrelevant crowd in the background were altered between neutral, happy and sad in order to investigate effects on the perception of emotion from task-relevant individuals in the foreground. Effects of the task irrelevant background on ratings of foreground characters were found, including cases that accompanied negatively valenced stimuli.",2014.0,42.0,7.0,False,,{'name': 'Proceedings of the ACM Symposium on Applied Perception'},"{'bibtex': '@Article{Carretero2014EvaluatingTP,\n author = {M. R. Carretero and A. Qureshi and Christopher E. Peters},\n journal = {Proceedings of the ACM Symposium on Applied Perception},\n title = {Evaluating the perception of group emotion from full body movements in the context of virtual crowds},\n year = {2014}\n}\n'}","[{'authorId': '38188266', 'name': 'M. R. Carretero'}, {'authorId': '10649439', 'name': 'A. Qureshi'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}]"
395,21a08dabbb6605a9973da3b5517e702870d80196,Emotion Regulation: Current Status and Future Prospects,"One of the fastest growing areas within psychology is the field of emotion regulation. However, enthusiasm for this topic continues to outstrip conceptual clarity, and there remains considerable uncertainty as to what is even meant by “emotion regulation.” The goal of this review is to examine the current status and future prospects of this rapidly growing field. In the first section, I define emotion and emotion regulation and distinguish both from related constructs. In the second section, I use the process model of emotion regulation to selectively review evidence that different regulation strategies have different consequences. In the third section, I introduce the extended process model of emotion regulation; this model considers emotion regulation to be one type of valuation, and distinguishes three emotion regulation stages (identification, selection, implementation). In the final section, I consider five key growth points for the field of emotion regulation.",2015.0,253.0,2043.0,False,,"{'volume': '26', 'pages': '1 - 26', 'name': 'Psychological Inquiry'}","{'bibtex': '@Article{Gross2015EmotionRC,\n author = {J. Gross},\n journal = {Psychological Inquiry},\n pages = {1 - 26},\n title = {Emotion Regulation: Current Status and Future Prospects},\n volume = {26},\n year = {2015}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}]"
396,21c818c688d2106d03a8024ceba95981ba14581a,Multi-Agent Model For Mutual Absorption Of Emotions,"23rd European Conference on Modelling and Simulation (ECMS'09), Madrid, Spain, June 9th-12th, 2009",2009.0,19.0,65.0,True,"{'url': 'http://www.few.vu.nl/~wai/Papers/ECMS09emotioncontagion.pdf', 'status': None}",{'pages': '212-218'},"{'bibtex': '@Inproceedings{Bosse2009MultiAgentMF,\n author = {T. Bosse and R. Duell and Z. A. Memon and Jan Treur and C. N. V. D. Wal},\n pages = {212-218},\n title = {Multi-Agent Model For Mutual Absorption Of Emotions},\n year = {2009}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '2790338', 'name': 'R. Duell'}, {'authorId': '2468373', 'name': 'Z. A. Memon'}, {'authorId': '1726343', 'name': 'Jan Treur'}, {'authorId': '1881843', 'name': 'C. N. V. D. Wal'}]"
398,21cad882fea264facb716abf561b694e03b9c1f3,Recurrence plots for the analysis of complex systems,,2009.0,223.0,3031.0,False,,"{'volume': '', 'pages': '8792', 'name': ''}","{'bibtex': '@Inproceedings{Marwan2009RecurrencePF,\n author = {N. Marwan and M. Romano and M. Thiel and J. Kurths},\n pages = {8792},\n title = {Recurrence plots for the analysis of complex systems},\n year = {2009}\n}\n'}","[{'authorId': '3019359', 'name': 'N. Marwan'}, {'authorId': '143995301', 'name': 'M. Romano'}, {'authorId': '33599229', 'name': 'M. Thiel'}, {'authorId': '143842718', 'name': 'J. Kurths'}]"
399,21de89f776d17ae0c39d0ab0f37dd34fcdf61906,"Are physically embodied social agents better than disembodied social agents?: The effects of physical embodiment, tactile interaction, and people's loneliness in human-robot interaction",,2006.0,29.0,405.0,True,"{'url': 'https://dr.ntu.edu.sg/bitstream/10356/100910/1/IJHCS-S-05-00003.pdf', 'status': None}","{'volume': '64', 'pages': '962-973', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': ""@Article{Lee2006ArePE,\n author = {K. M. Lee and Younbo Jung and Jaywoo Kim and Sang Ryong Kim},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {962-973},\n title = {Are physically embodied social agents better than disembodied social agents?: The effects of physical embodiment, tactile interaction, and people's loneliness in human-robot interaction},\n volume = {64},\n year = {2006}\n}\n""}","[{'authorId': '2145232448', 'name': 'K. M. Lee'}, {'authorId': '3669749', 'name': 'Younbo Jung'}, {'authorId': '2109187332', 'name': 'Jaywoo Kim'}, {'authorId': '2109830893', 'name': 'Sang Ryong Kim'}]"
400,220a98e19e0da729476175f285360545541d2f9d,The Social Effects of Emotions are Functionally Equivalent Across Expressive Modalities,"Ever since the publication of Darwin's The Expression of the Emotions in Man and Animals in 1872, questions about the nature and purpose of emotional expressions have represented some of the most i...",2017.0,66.0,31.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/1047840X.2017.1338102?needAccess=true', 'status': None}","{'volume': '28', 'pages': '211 - 216', 'name': 'Psychological Inquiry'}","{'bibtex': '@Article{Kleef2017TheSE,\n author = {Gerben A. Van Kleef},\n journal = {Psychological Inquiry},\n pages = {211 - 216},\n title = {The Social Effects of Emotions are Functionally Equivalent Across Expressive Modalities},\n volume = {28},\n year = {2017}\n}\n'}","[{'authorId': '2238998768', 'name': 'Gerben A. Van Kleef'}]"
401,2237e945ad8e4589f96b7aa1fa5708d01c5b1590,Gain and loss of esteem as determinants of interpersonal attractiveness,,1965.0,16.0,346.0,False,,"{'volume': '1', 'pages': '156-171', 'name': 'Journal of Experimental Social Psychology'}","{'bibtex': '@Article{Aronson1965GainAL,\n author = {E. Aronson and D. Linder},\n journal = {Journal of Experimental Social Psychology},\n pages = {156-171},\n title = {Gain and loss of esteem as determinants of interpersonal attractiveness},\n volume = {1},\n year = {1965}\n}\n'}","[{'authorId': '48235291', 'name': 'E. Aronson'}, {'authorId': '39850782', 'name': 'D. Linder'}]"
402,2239973434ac6aee33212f00b6041077832d688f,Preventing depression: a global priority.,"Depressive disorders erode quality of life, productivity in the workplace, and fulfillment of social and familial roles. In today's knowledge- and service-driven economies, the population's mental capital (ie, cognitive, emotional, and social skills resources required for role functioning) becomes both more valuable and more vulnerable to the effects of depression. Depressive disorders, severe mental illnesses that should not be confused with normal mood variations, are part of a vicious circle of poverty, discrimination, and poor mental health in middle- and low-income countries.1 These realities also have major economic ramifications: treatment costs of depression are soaring but are only a fragment of the costs of reduced productivity due to depression.2 
 
More than half of those with depression develop a recurrent or chronic disorder after a first depressive episode and are likely to spend more than 20% of their life-time in a depressed condition. With a 12-month prevalence rate of more than 5% in most high-, middle-, and low-income countries and its occurrence at almost any age,3 depression generates substantial loss of quality of life and personal morbidity and despair. But it also leads to considerable additional damage through biological sequelae and maladaptive illness behaviors, thus increasing risk of cardiovascular disease, dementing illnesses, and early death while amplifying disability, complications, and health services use in those with coexisting chronic illnesses. Depression ranks third among disorders responsible for global disease burden, with all the concomitant economic costs to society, and will rank first in high-income countries by 2030.4",2012.0,7.0,288.0,True,"{'url': 'https://research.vu.nl/files/3138069/2012%20Cuijpers,%20prevention,%20JAMA.pdf', 'status': None}","{'volume': '307 10', 'pages': '\n          1033-4\n        ', 'name': 'JAMA'}","{'bibtex': '@Article{Cuijpers2012PreventingDA,\n author = {P. Cuijpers and A. Beekman and C. Reynolds},\n journal = {JAMA},\n pages = {\n          1033-4\n        },\n title = {Preventing depression: a global priority.},\n volume = {307 10},\n year = {2012}\n}\n'}","[{'authorId': '1802487', 'name': 'P. Cuijpers'}, {'authorId': '145388985', 'name': 'A. Beekman'}, {'authorId': '1743278', 'name': 'C. Reynolds'}]"
403,223ff753d4e63f12750fc26a8f9c897fb72fce25,FearNot! Involving Children in the Design of a Virtual Learning Environment,"This paper presents FearNot, a virtual learning environment populated by synthetic characters interacting in bullying scenarios, aimed at 8-12 year old children. FearNot was designed within the VICTEC project where a key aim was to ensure that children participated in the design process. A range of techniques were used to gain the children's input. This paper discusses the various techniques used within VICTEC and highlights some key examples of the results gained by using such techniques, challenges encountered, and the design implications.",2006.0,46.0,26.0,False,,"{'volume': '16', 'pages': '327-351', 'name': 'Int. J. Artif. Intell. Educ.'}","{'bibtex': '@Article{Hall2006FearNotIC,\n author = {L. Hall and Sarah N. Woods and R. Aylett},\n journal = {Int. J. Artif. Intell. Educ.},\n pages = {327-351},\n title = {FearNot! Involving Children in the Design of a Virtual Learning Environment},\n volume = {16},\n year = {2006}\n}\n'}","[{'authorId': '144160845', 'name': 'L. Hall'}, {'authorId': '2773308', 'name': 'Sarah N. Woods'}, {'authorId': '1732377', 'name': 'R. Aylett'}]"
404,225cfb48f28d74b40ac382d2c1120f6e0e4e372c,"In your face, robot! The influence of a character's embodiment on how users perceive its emotional expressions","The ability of artificial characters to express emotions is essential for the natural interaction with humans. Their absence could be interpreted as coldness towards the user. Artificial characters can have different embodiments. Screen characters and robotic characters are currently among the most widely used. This study investigates the influence of the character’s embodiment on how users perceive the character’s emotional expressions. The results show that there is no significant difference in the perceived intensity and recognition accuracy between a robotic character and a screen character. Another important aspect of the character is its ability to express different emotional intensity levels. Developers create different geometrical intensity levels of emotional expressions by equally dividing the spatial difference of each facial component between the neutral and maximum expression. However, the relationship between this geometrical intensity and the intensity perceived by the user might not be strictly linear. This study shows that also a quadratic trend is present in this relationship and that10% steps increase of geometrical intensity can often be distinguished whereas 20% steps can be distinguished almost all the time.",2004.0,36.0,148.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Bartneck2004InYF,\n author = {C. Bartneck and Juliane Reichenbach and Ajn Albert van Breemen},\n title = {In your face, robot! The influence of a character's embodiment on how users perceive its emotional expressions},\n year = {2004}\n}\n""}","[{'authorId': '1728894', 'name': 'C. Bartneck'}, {'authorId': '153346247', 'name': 'Juliane Reichenbach'}, {'authorId': '101207609', 'name': 'Ajn Albert van Breemen'}]"
405,2260975bc3a328911958d14a9a59caec270c7b8b,Objective versus Subjective Coordination in the Engineering of Agent Systems,,2003.0,43.0,87.0,False,,{'pages': '179-202'},"{'bibtex': '@Inproceedings{Omicini2003ObjectiveVS,\n author = {Andrea Omicini and Sascha Ossowski},\n pages = {179-202},\n title = {Objective versus Subjective Coordination in the Engineering of Agent Systems},\n year = {2003}\n}\n'}","[{'authorId': '3119182', 'name': 'Andrea Omicini'}, {'authorId': '1880804', 'name': 'Sascha Ossowski'}]"
406,2261a7515266befb023c7a6cffe991d329a5534c,Affect Dysregulation and Disorders of the Self,,2003.0,2.0,311.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Schore2003AffectDA,\n author = {A. Schore},\n title = {Affect Dysregulation and Disorders of the Self},\n year = {2003}\n}\n'}","[{'authorId': '6797545', 'name': 'A. Schore'}]"
407,2267d1761b181997e9927d5d3fcb2cee7daec970,Revealing the Invisible With Model and Data Shrinking for Composite-Database Micro-Expression Recognition,"Composite-database micro-expression recognition is attracting increasing attention as it is more practical for real-world applications. Though the composite database provides more sample diversity for learning good representation models, the important subtle dynamics are prone to disappearing in the domain shift such that the models greatly degrade their performance, especially for deep models. In this article, we analyze the influence of learning complexity, including input complexity and model complexity, and discover that the lower-resolution input data and shallower-architecture model are helpful to ease the degradation of deep models in composite-database task. Based on this, we propose a recurrent convolutional network (RCN) to explore the shallower-architecture and lower-resolution input data, shrinking model and input complexities simultaneously. Furthermore, we develop three parameter-free modules (i.e., wide expansion, shortcut connection and attention unit) to integrate with RCN without increasing any learnable parameters. These three modules can enhance the representation ability in various perspectives while preserving not-very-deep architecture for lower-resolution data. Besides, three modules can further be combined by an automatic strategy (a neural architecture search strategy) and the searched architecture becomes more robust. Extensive experiments on the MEGC2019 dataset (composited of existing SMIC, CASME II and SAMM datasets) have verified the influence of learning complexity and shown that RCNs with three modules and the searched combination outperform the state-of-the-art approaches.",2020.0,60.0,71.0,True,"{'url': 'http://jultika.oulu.fi/files/nbnfi-fe2020111089762.pdf', 'status': None}","{'volume': '29', 'pages': '8590-8605', 'name': 'IEEE Transactions on Image Processing'}","{'bibtex': '@Article{Xia2020RevealingTI,\n author = {Zhaoqiang Xia and Wei Peng and Huai-Qian Khor and Xiaoyi Feng and Guoying Zhao},\n journal = {IEEE Transactions on Image Processing},\n pages = {8590-8605},\n title = {Revealing the Invisible With Model and Data Shrinking for Composite-Database Micro-Expression Recognition},\n volume = {29},\n year = {2020}\n}\n'}","[{'authorId': '1917901', 'name': 'Zhaoqiang Xia'}, {'authorId': '2048021283', 'name': 'Wei Peng'}, {'authorId': '30470673', 'name': 'Huai-Qian Khor'}, {'authorId': '4729239', 'name': 'Xiaoyi Feng'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}]"
408,227901fca5cfb9aad3832b8cea56a96fcde30cfd,Enhancing emotion-regulation skills in police officers: results of a pilot controlled study.,,2010.0,56.0,166.0,False,,"{'volume': '41 3', 'pages': '\n          329-39\n        ', 'name': 'Behavior therapy'}","{'bibtex': '@Article{Berking2010EnhancingES,\n author = {M. Berking and C. Meier and Peggilee Wupperman},\n journal = {Behavior therapy},\n pages = {\n          329-39\n        },\n title = {Enhancing emotion-regulation skills in police officers: results of a pilot controlled study.},\n volume = {41 3},\n year = {2010}\n}\n'}","[{'authorId': '2581311', 'name': 'M. Berking'}, {'authorId': '2058160542', 'name': 'C. Meier'}, {'authorId': '6883965', 'name': 'Peggilee Wupperman'}]"
409,22870d00a8664a4dd55a2700b87dc0824cbc4922,Toward Agents that Recognize Emotion,"It is now easy to nd examples of interactive software agents and animated creatures that have the ability to express emotion; this paper describes research for giving them the ability to recognize emotion. The ability to recognize a per-son's emotions is a key aspect of human \emo-tional intelligence,"" which has been described by a number of scientists as being more important to success in life than are the traditional forms of mathematical and verbal intelligence. This paper describes research underway in emotion recognition at the MIT Media Lab, especially research involving new wearable interfaces.",1998.0,12.0,69.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Picard1998TowardAT,\n author = {Rosalind W. Picard},\n title = {Toward Agents that Recognize Emotion},\n year = {1998}\n}\n'}","[{'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
410,228d5c053f71c6da22e56e2a5ba93f4bdb5a787d,"A Survey of Expectations About the Role of Robots in Robot-Assisted Therapy for Children with ASD: Ethical Acceptability, Trust, Sociability, Appearance, and Attachment",,2015.0,53.0,172.0,False,,"{'volume': '22', 'pages': '47 - 65', 'name': 'Science and Engineering Ethics'}","{'bibtex': '@Article{Coeckelbergh2015ASO,\n author = {Mark Coeckelbergh and C. Pop and Ramona Simut and Andreea Peca and S. Pintea and Daniel O. David and B. Vanderborght},\n journal = {Science and Engineering Ethics},\n pages = {47 - 65},\n title = {A Survey of Expectations About the Role of Robots in Robot-Assisted Therapy for Children with ASD: Ethical Acceptability, Trust, Sociability, Appearance, and Attachment},\n volume = {22},\n year = {2015}\n}\n'}","[{'authorId': '46450294', 'name': 'Mark Coeckelbergh'}, {'authorId': '1718066', 'name': 'C. Pop'}, {'authorId': '1753188', 'name': 'Ramona Simut'}, {'authorId': '2333169', 'name': 'Andreea Peca'}, {'authorId': '2413277', 'name': 'S. Pintea'}, {'authorId': '48356644', 'name': 'Daniel O. David'}, {'authorId': '1687831', 'name': 'B. Vanderborght'}]"
411,22a3cc3fc0a3c1508c19f9c1d3b8afb6e88a5b15,Social use of internet in adolescents: Relationship with cyberbullying and levels of physical activity,"An unsuitable and abusive use of the Internet and the technologies that support it (e.g. mobile phones and computers) can be related to the appearance of different problems and risks during adolescence, such as addiction and cyberbullying (CB) (Armstrong et al., Saling, 2000; Carbonell et al., 2012; Tokunaga, 2010; Tsitsika et al., 2015). The objective of this research is to know about the use of social networks (SN) and communication applications, the degree of intrapersonal (IntraA) and interpersonal (InterA) addictions caused by the problematic Internet use, as well as the possible relations between dependence, CB and physical activity (PA) levels determined, in an objective manner, through the use of accelerometers. Results show that there is an IntraA of M = 2.21 (SD = 0.62) and an InterA of M = 1.97 (SD = 0.53), as it is the need of continuously checking the SN and WhatsApp (WAPP), the use of the Internet as a way of escaping from problems and the withdrawal from other activities in order to being connected to the Internet for a longer period of time. There is a relation between the Internet addiction and CB but not between the different levels of PA performance and these variables.",2018.0,53.0,3.0,True,"{'url': 'https://rua.ua.es/dspace/bitstream/10045/77470/1/JHSE_13_Proc2_05.pdf', 'status': None}","{'volume': '', 'pages': '209-220', 'name': 'Journal of Human Sport and Exercise'}","{'bibtex': '@Article{Chacón-Borrego2018SocialUO,\n author = {F. Chacón-Borrego and Carolina Castañeda-Vázquez and J. D. Pozo-Cruz and J. Corral-Pernía},\n journal = {Journal of Human Sport and Exercise},\n pages = {209-220},\n title = {Social use of internet in adolescents: Relationship with cyberbullying and levels of physical activity},\n year = {2018}\n}\n'}","[{'authorId': '1403709162', 'name': 'F. Chacón-Borrego'}, {'authorId': '1399628178', 'name': 'Carolina Castañeda-Vázquez'}, {'authorId': '1403368906', 'name': 'J. D. Pozo-Cruz'}, {'authorId': '1403588586', 'name': 'J. Corral-Pernía'}]"
412,22ba8e8442c9a3ba209368b9dd480ccae46ebd18,Towards a Cognitive Theory of Emotions,"Abstract A theory is proposed that emotions are cognitively based states which co-ordinate quasi-autonomous processes in the nervous system. Emotions provide a biological solution to certain problems of transition between plans, in systems with multiple goals. Their function is to accomplish and maintain these transitions, and to communicate them to ourselves and others. Transitions occur at significant junctures of plans when the evaluation of success in a plan changes. Complex emotions are derived from a small number of basic emotions and arise at junctures of social plans.",1987.0,45.0,1796.0,False,,"{'volume': '1', 'pages': '29-50', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Oatley1987TowardsAC,\n author = {K. Oatley and P. Johnson-Laird},\n journal = {Cognition & Emotion},\n pages = {29-50},\n title = {Towards a Cognitive Theory of Emotions},\n volume = {1},\n year = {1987}\n}\n'}","[{'authorId': '2297721', 'name': 'K. Oatley'}, {'authorId': '1384194899', 'name': 'P. Johnson-Laird'}]"
413,22d03e2d9ea2bdc9dc74d63c281959e0fc4be84c,Measuring facial movement,,1976.0,23.0,1024.0,False,,"{'volume': '1', 'pages': '56-75', 'name': 'Environmental psychology and nonverbal behavior'}","{'bibtex': '@Article{Ekman1976MeasuringFM,\n author = {P. Ekman and Wallace V. Friesen},\n journal = {Environmental psychology and nonverbal behavior},\n pages = {56-75},\n title = {Measuring facial movement},\n volume = {1},\n year = {1976}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}]"
414,22e2077034a4dc31a0f2cd125f604c3a4d656f59,A Meta-Analysis of Factors Affecting Trust in Human-Robot Interaction,"Objective: We evaluate and quantify the effects of human, robot, and environmental factors on perceived trust in human-robot interaction (HRI). Background: To date, reviews of trust in HRI have been qualitative or descriptive. Our quantitative review provides a fundamental empirical foundation to advance both theory and practice. Method: Meta-analytic methods were applied to the available literature on trust and HRI. A total of 29 empirical studies were collected, of which 10 met the selection criteria for correlational analysis and 11 for experimental analysis. These studies provided 69 correlational and 47 experimental effect sizes. Results: The overall correlational effect size for trust was r̄ = +0.26, with an experimental effect size of d̄ = +0.71. The effects of human, robot, and environmental characteristics were examined with an especial evaluation of the robot dimensions of performance and attribute-based factors. The robot performance and attributes were the largest contributors to the development of trust in HRI. Environmental factors played only a moderate role. Conclusion: Factors related to the robot itself, specifically, its performance, had the greatest current association with trust, and environmental factors were moderately associated. There was little evidence for effects of human-related factors. Application: The findings provide quantitative estimates of human, robot, and environmental factors influencing HRI trust. Specifically, the current summary provides effect size estimates that are useful in establishing design and training guidelines with reference to robot-related factors of HRI trust. Furthermore, results indicate that improper trust calibration may be mitigated by the manipulation of robot design. However, many future research needs are identified.",2011.0,67.0,1282.0,False,,"{'volume': '53', 'pages': '517 - 527', 'name': 'Human Factors: The Journal of Human Factors and Ergonomics Society'}","{'bibtex': '@Article{Hancock2011AMO,\n author = {P. Hancock and D. Billings and Kristin E. Schaefer and Jessie Y.C. Chen and E. D. Visser and R. Parasuraman},\n journal = {Human Factors: The Journal of Human Factors and Ergonomics Society},\n pages = {517 - 527},\n title = {A Meta-Analysis of Factors Affecting Trust in Human-Robot Interaction},\n volume = {53},\n year = {2011}\n}\n'}","[{'authorId': '143605034', 'name': 'P. Hancock'}, {'authorId': '34893594', 'name': 'D. Billings'}, {'authorId': '2907955', 'name': 'Kristin E. Schaefer'}, {'authorId': '1403068272', 'name': 'Jessie Y.C. Chen'}, {'authorId': '7848470', 'name': 'E. D. Visser'}, {'authorId': '3264674', 'name': 'R. Parasuraman'}]"
415,23175b146edaf762c446b245f4b1d82af41ade13,Multimodal human discourse: gesture and speech,"Gesture and speech combine to form a rich basis for human conversational interaction. To exploit these modalities in HCI, we need to understand the interplay between them and the way in which they support communication. We propose a framework for the gesture research done to date, and present our work on the cross-modal cues for discourse segmentation in free-form gesticulation accompanying speech in natural conversation as a new paradigm for such multimodal interaction. The basis for this integration is the psycholinguistic concept of the coequal generation of gesture and speech from the same semantic intent. We present a detailed case study of a gesture and speech elicitation experiment in which a subject describes her living space to an interlocutor. We perform two independent sets of analyses on the video and audio data: video and audio analysis to extract segmentation cues, and expert transcription of the speech and gesture data by microanalyzing the videotape using a frame-accurate videoplayer to correlate the speech with the gestural entities. We compare the results of both analyses to identify the cues accessible in the gestural and audio data that correlate well with the expert psycholinguistic analysis. We show that ""handedness"" and the kind of symmetry in two-handed gestures provide effective supersegmental discourse cues.",2002.0,45.0,322.0,False,,"{'volume': '9', 'pages': '171-193', 'name': 'ACM Trans. Comput. Hum. Interact.'}","{'bibtex': '@Article{Quek2002MultimodalHD,\n author = {Francis K. H. Quek and D. McNeill and R. Bryll and S. Duncan and Xin-Feng Ma and C. Kirbas and K. McCullough and R. Ansari},\n journal = {ACM Trans. Comput. Hum. Interact.},\n pages = {171-193},\n title = {Multimodal human discourse: gesture and speech},\n volume = {9},\n year = {2002}\n}\n'}","[{'authorId': '1740663', 'name': 'Francis K. H. Quek'}, {'authorId': '145493778', 'name': 'D. McNeill'}, {'authorId': '2387793', 'name': 'R. Bryll'}, {'authorId': '144346436', 'name': 'S. Duncan'}, {'authorId': '3073990', 'name': 'Xin-Feng Ma'}, {'authorId': '2156795', 'name': 'C. Kirbas'}, {'authorId': '2660294', 'name': 'K. McCullough'}, {'authorId': '143806517', 'name': 'R. Ansari'}]"
416,234a741a8bcdf25f5924101edc1f67f164f5277b,Cues to deception.,"Do people behave differently when they are lying compared with when they are telling the truth? The combined results of 1,338 estimates of 158 cues to deception are reported. Results show that in some ways, liars are less forthcoming than truth tellers, and they tell less compelling tales. They also make a more negative impression and are more tense. Their stories include fewer ordinary imperfections and unusual contents. However, many behaviors showed no discernible links, or only weak links, to deceit. Cues to deception were more pronounced when people were motivated to succeed, especially when the motivations were identity relevant rather than monetary or material. Cues to deception were also stronger when lies were about transgressions.",2003.0,321.0,2282.0,False,,"{'volume': '129 1', 'pages': '\n          74-118\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{DePaulo2003CuesTD,\n author = {B. DePaulo and James J. Lindsay and Brian E Malone and Laura Muhlenbruck and K. Charlton and Harris Cooper},\n journal = {Psychological bulletin},\n pages = {\n          74-118\n        },\n title = {Cues to deception.},\n volume = {129 1},\n year = {2003}\n}\n'}","[{'authorId': '5323704', 'name': 'B. DePaulo'}, {'authorId': '32593993', 'name': 'James J. Lindsay'}, {'authorId': '2054366525', 'name': 'Brian E Malone'}, {'authorId': '5488931', 'name': 'Laura Muhlenbruck'}, {'authorId': '145086047', 'name': 'K. Charlton'}, {'authorId': '2056025803', 'name': 'Harris Cooper'}]"
417,237218b1479984fcf1e88b31c9215e02609fd975,Auditory and visual cortex of primates: a comparison of two sensory systems,"A comparative view of the brain, comparing related functions across species and sensory systems, offers a number of advantages. In particular, it allows separation of the formal purpose of a model structure from its implementation in specific brains. Models of auditory cortical processing can be conceived by analogy to the visual cortex, incorporating neural mechanisms that are found in both the visual and auditory systems. Examples of such canonical features at the columnar level are direction selectivity, size/bandwidth selectivity, and receptive fields with segregated vs. overlapping ON and OFF subregions. On a larger scale, parallel processing pathways have been envisioned that represent the two main facets of sensory perception: (i) identification of objects; and (ii) processing of space. Expanding this model in terms of sensorimotor integration and control offers an overarching view of cortical function independently of sensory modality.",2015.0,54.0,38.0,True,"{'url': 'https://europepmc.org/articles/pmc4347938?pdf=render', 'status': None}","{'volume': '41', 'name': 'European Journal of Neuroscience'}","{'bibtex': '@Article{Rauschecker2015AuditoryAV,\n author = {J. Rauschecker},\n journal = {European Journal of Neuroscience},\n title = {Auditory and visual cortex of primates: a comparison of two sensory systems},\n volume = {41},\n year = {2015}\n}\n'}","[{'authorId': '1856522', 'name': 'J. Rauschecker'}]"
418,237525ba89488eace7698459a2b45e3343ed823d,Emotion-oriented requirements engineering: A case study in developing a smart home system for the elderly,,2019.0,64.0,64.0,False,,"{'volume': '147', 'pages': '215-229', 'name': 'J. Syst. Softw.'}","{'bibtex': '@Article{Curumsing2019EmotionorientedRE,\n author = {M. Curumsing and Niroshinie Fernando and Mohamed Abdelrazek and Rajesh Vasa and K. Mouzakis and J. Grundy},\n journal = {J. Syst. Softw.},\n pages = {215-229},\n title = {Emotion-oriented requirements engineering: A case study in developing a smart home system for the elderly},\n volume = {147},\n year = {2019}\n}\n'}","[{'authorId': '3292250', 'name': 'M. Curumsing'}, {'authorId': '2131391', 'name': 'Niroshinie Fernando'}, {'authorId': '47505933', 'name': 'Mohamed Abdelrazek'}, {'authorId': '33402434', 'name': 'Rajesh Vasa'}, {'authorId': '1845229', 'name': 'K. Mouzakis'}, {'authorId': '1687239', 'name': 'J. Grundy'}]"
419,237831f1ec93e537ca769091ba40df1c945281f8,Self disclosure on computer forms: meta-analysis and implications,"K e y w o r d s computer forms, computer interviews, electronic surveys, measurement, disclosure, response bias, electronic",1996.0,31.0,222.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Weisband1996SelfDO,\n author = {S. Weisband and S. Kiesler},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Self disclosure on computer forms: meta-analysis and implications},\n year = {1996}\n}\n'}","[{'authorId': '2453684', 'name': 'S. Weisband'}, {'authorId': '47198673', 'name': 'S. Kiesler'}]"
420,239da2f40faaeab0dcd4b48458cd2fd6d776078e,Handbook of emotion regulation,"Part 1. Foundations. J.J. Gross, R.A. Thompson, Emotion Regulation: Conceptual Foundations. Part 2. Biological Bases. G.J. Quirk, Prefrontal-Amygdala Interactions in the Regulation of Fear. R.J. Davidson, A. Fox, N.H. Kalin, Neural Bases of Emotion Regulation in Nonhuman Primates and Humans. J.S. Beer, M.V. Lombardo, Insights into Emotion Regulation from Neuropsychology. K.N. Ochsner, J.J. Gross, The Neural Architecture of Emotion Regulation. A.R. Hariri, E.E. Forbes, Genetics of Emotion Regulation. Part 3. Cognitive Foundations. P.D. Zelazo, W.A. Cunningham Executive Function: Mechanisms Underlying Emotion Regulation. C. Peterson, N. Park, Explanatory Style and Emotion Regulation. G. Loewenstein, Affective Regulation and Affective Forecasting. S.M. McClure, M.M. Botvinick, N. Yeung, J.D. Greene, J.D. Cohen, Conflict Monitoring in Cognition-Emotion Competition. Part 4. Developmental Approaches. S.D. Calkins, A. Hill, Caregiver Influences on Emerging Emotion Regulation: Biological and Environmental Transactions in Early Development. R.A. Thompson, S. Meyer, Socialization of Emotion Regulation in the Family. H. Stegge, M.M. Terwogt, Awareness and Regulation of Emotion in Typical and Atypical development. N. Eisenberg, C. Hofer, J. Vaughan, Effortful Control and Its Socioemotional Consequences. S.T. Charles, L.L. Carstensen, Emotion Regulation and Aging. Part 5. Personality Processes and Individual Differences. M.K. Rothbart, B.E. Sheese, Temperament and Emotion Regulation. O.P. John, J.J. Gross, Individual Differences in Emotion Regulation. D. Westen, P. Blagov, A Clinical-Empirical Model of Emotion Regulation: From Defense and Motivated Reasoning to Emotional Constraint Satisfaction. T. Wranik, L.F. Barrett, P. Salovey, Intelligent Emotion Regulation: Is Knowledge Power? R.F. Baumeister, A.L. Zell, D.M. Tice, How Emotions Facilitate and Impair Self-Regulation. Part 6. Social Approaches. J.A. Bargh, L.E. Williams, The Nonconscious Regulation of Emotion. P.R. Shaver, M. Mikulincer, Adult Attachment Strategies and the Regulation of Emotion. B. Rime, Interpersonal Emotion Regulation. B. Mesquita, D. Albert, The Cultural Regulation of Emotions. F. Watts, Emotion Regulation and Religion. Part 7. Clinical Applications. B.C. Mullin, S.P. Hinshaw, Emotion Regulation and Externalizing Disorders in Children and Adolescents. L. Campbell-Sills, D.H. Barlow, Incorporating Emotion Regulation into Conceptualizations and Treatments of Anxiety and Mood Disorders. K.J. Sher, E.R. Grekin, Alcohol and Affect Regulation. M.M. Linehan, M. Bohus, T.R. Lynch, Dialectical Behavior Therapy for Pervasive Emotion Dysregulation: Theoretical and Practical Underpinnings. R.M. Sapolsky, Stress, Stress-Related Disease, and Emotional Regulation.",2007.0,0.0,1268.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gross2007HandbookOE,\n author = {J. Gross},\n title = {Handbook of emotion regulation},\n year = {2007}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}]"
421,23c42b4a839200bf1e27dca0f8608c77f46e457d,Real-Time Multimodal Emotion Recognition in Conversation for Multi-Party Interactions,"In order to improve multi-party social interaction with artificial companions such as robots or virtual agents, real-time Emotion Recognition in Conversation (ERC) is required. In this context, ERC is a challenging task which involves multiple challenges, such as processing multimodal data over time, taking into account the multi-party context with any number of participants, understanding implied relevant commonsense knowledge during interaction and taking into account each participant’s emotional attitude. To deal with the aforementioned challenges, we design a multimodal off-the-shelf model that meets the requirements of real-life scenarios, specifically dyadic and multi-party interactions. We propose a Knowledge Aware Multi-Headed Network that integrates various sources including the dialog history and commonsense knowledge about the speaker and other participants. The weights of these pieces of information are modulated using a multi-head attention mechanism. The proposed model is learnt in a Multi-Task Learning framework which combines the ERC task with a Dialogue Act (DA) recognition task and an Emotion Shift (ES) detection task through a joint learning strategy. Our proposition obtains competitive and stable results on several benchmark datasets that vary in number of participants and length of conversations, and outperforms the state-of-the-art on one of these datasets. The importance of DA and ES prediction in determining the speaker’s current emotional state is investigated.",2022.0,26.0,2.0,False,,{'name': 'Proceedings of the 2022 International Conference on Multimodal Interaction'},"{'bibtex': '@Book{Rasendrasoa2022RealTimeME,\n author = {Sandratra Rasendrasoa and A. Pauchet and Julien Saunier and Sébastien Adam},\n booktitle = {International Conference on Multimodal Interaction},\n journal = {Proceedings of the 2022 International Conference on Multimodal Interaction},\n title = {Real-Time Multimodal Emotion Recognition in Conversation for Multi-Party Interactions},\n year = {2022}\n}\n'}","[{'authorId': '2183387981', 'name': 'Sandratra Rasendrasoa'}, {'authorId': '1736247', 'name': 'A. Pauchet'}, {'authorId': '1708997', 'name': 'Julien Saunier'}, {'authorId': '143680806', 'name': 'Sébastien Adam'}]"
422,23c9d63b68d71134def98c955663d3e67b8cac56,Predictors and subjective causes of loneliness in an aged population.,,2005.0,29.0,585.0,False,,"{'volume': '41 3', 'pages': '\n          223-33\n        ', 'name': 'Archives of gerontology and geriatrics'}","{'bibtex': '@Article{Savikko2005PredictorsAS,\n author = {N. Savikko and P. Routasalo and R. Tilvis and T. Strandberg and K. Pitkälä},\n journal = {Archives of gerontology and geriatrics},\n pages = {\n          223-33\n        },\n title = {Predictors and subjective causes of loneliness in an aged population.},\n volume = {41 3},\n year = {2005}\n}\n'}","[{'authorId': '47824687', 'name': 'N. Savikko'}, {'authorId': '3852893', 'name': 'P. Routasalo'}, {'authorId': '3976055', 'name': 'R. Tilvis'}, {'authorId': '6200225', 'name': 'T. Strandberg'}, {'authorId': '2991669', 'name': 'K. Pitkälä'}]"
423,23cdedc9871eff4499aa6f83ff18cfb24a701684,Emotion recognition from EEG based on multi-task learning with capsule network and attention mechanism,,2022.0,52.0,39.0,False,,"{'volume': '143', 'pages': '\n          105303\n        ', 'name': 'Computers in biology and medicine'}","{'bibtex': '@Article{Li2022EmotionRF,\n author = {Chang Li and Bin Wang and Shenmin Zhang and Yu Liu and Rencheng Song and Juan Cheng and Xun Chen},\n journal = {Computers in biology and medicine},\n pages = {\n          105303\n        },\n title = {Emotion recognition from EEG based on multi-task learning with capsule network and attention mechanism},\n volume = {143},\n year = {2022}\n}\n'}","[{'authorId': '144656120', 'name': 'Chang Li'}, {'authorId': '2152592977', 'name': 'Bin Wang'}, {'authorId': '38654394', 'name': 'Shenmin Zhang'}, {'authorId': '2146399587', 'name': 'Yu Liu'}, {'authorId': '1430708893', 'name': 'Rencheng Song'}, {'authorId': '46754596', 'name': 'Juan Cheng'}, {'authorId': '2144213500', 'name': 'Xun Chen'}]"
424,23d3170f4ec585795061bc8e0f2e0c406e5ae3ac,Constraint-Based Model for Synthesis of Multimodal Sequential Expressions of Emotions,"Emotional expressions play a very important role in the interaction between virtual agents and human users. In this paper, we present a new constraint-based approach to the generation of multimodal emotional displays. The displays generated with our method are not limited to the face, but are composed of different signals partially ordered in time and belonging to different modalities. We also describe the evaluation of the main features of our approach. We examine the role of multimodality, sequentiality, and constraints in the perception of synthesized emotional states. The results of our evaluation show that applying our algorithm improves the communication of a large spectrum of emotional states, while the believability of the agent animations increases with the use of constraints over the multimodal signals.",2011.0,36.0,52.0,False,,"{'volume': '2', 'pages': '134-146', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Niewiadomski2011ConstraintBasedMF,\n author = {Radoslaw Niewiadomski and S. Hyniewska and C. Pelachaud},\n journal = {IEEE Transactions on Affective Computing},\n pages = {134-146},\n title = {Constraint-Based Model for Synthesis of Multimodal Sequential Expressions of Emotions},\n volume = {2},\n year = {2011}\n}\n'}","[{'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '1783043', 'name': 'S. Hyniewska'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
425,23e498e565da52641126815a6d2c6ac4509d5c74,Human Behavior Models for Agents in Simulators and Games: Part II: Gamebot Engineering with PMFserv,"Many producers and consumers of legacy training simulator and game environments are beginning to envision a new era where psycho-socio-physiologic models could be interoperated to enhance their environments' simulation of human agents. This paper explores whether we could embed our behavior modeling framework (described in the companion paper, Part 1) behind a legacy first person shooter 3D game environment to recreate portions of the Black Hawk Down scenario. Section 1 amplifies the interoperability needs and challenges confronting the field, presents the questions that are examined, and describes the test scenario. Sections 2 and 3 review the software and knowledge engineering methodology, respectively, needed to create the system and populate it with bots. Results (Section 4) and discussion (Section 5) reveal that we were able to generate plausible and adaptive recreations of Somalian crowds, militia, women acting as shields, suicide bombers, and more. Also, there are specific lessons learned about ways to advance the field so that such interoperabilities will become more affordable and widespread.",2006.0,42.0,111.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/85f1efc4-547f-4216-b3e9-c22e5a8530d8/download', 'status': None}","{'volume': '15', 'pages': '163-185', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': ""@Article{Silverman2006HumanBM,\n author = {B. Silverman and Gnana Bharathy and Kevin O'Brien and Jason Cornwell},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {163-185},\n title = {Human Behavior Models for Agents in Simulators and Games: Part II: Gamebot Engineering with PMFserv},\n volume = {15},\n year = {2006}\n}\n""}","[{'authorId': '1714492', 'name': 'B. Silverman'}, {'authorId': '3201199', 'name': 'Gnana Bharathy'}, {'authorId': '2059261082', 'name': ""Kevin O'Brien""}, {'authorId': '2668493', 'name': 'Jason Cornwell'}]"
427,2418dc661f467ce41fa8ac330232303c520422cd,DelsArtMap: Applying Delsarte's Aesthetic System to Virtual Agents,,2010.0,20.0,8.0,False,,{'pages': '139-145'},"{'bibtex': ""@Inproceedings{Nixon2010DelsArtMapAD,\n author = {Michael Nixon and Philippe Pasquier and M. S. El-Nasr},\n pages = {139-145},\n title = {DelsArtMap: Applying Delsarte's Aesthetic System to Virtual Agents},\n year = {2010}\n}\n""}","[{'authorId': '145309281', 'name': 'Michael Nixon'}, {'authorId': '144380634', 'name': 'Philippe Pasquier'}, {'authorId': '1381933697', 'name': 'M. S. El-Nasr'}]"
428,243d784bdc333b44298b7189d030524f7b7bac6d,Emotion regulation and understanding: implications for child psychopathology and therapy.,,2002.0,254.0,530.0,True,"{'url': 'http://www.people.vcu.edu/~masouthamger/sg__k_2002.pdf', 'status': None}","{'volume': '22 2', 'pages': '\n          189-222\n        ', 'name': 'Clinical psychology review'}","{'bibtex': '@Article{Southam-Gerow2002EmotionRA,\n author = {M. Southam-Gerow and P. Kendall},\n journal = {Clinical psychology review},\n pages = {\n          189-222\n        },\n title = {Emotion regulation and understanding: implications for child psychopathology and therapy.},\n volume = {22 2},\n year = {2002}\n}\n'}","[{'authorId': '1399135436', 'name': 'M. Southam-Gerow'}, {'authorId': '2758630', 'name': 'P. Kendall'}]"
429,2452a20398502411ff37384a629e0aefd5754b75,Neuropsychiatric signs and symptoms of Alzheimer's disease: New treatment paradigms,,2017.0,122.0,229.0,True,"{'url': 'http://www.trci.alzdem.com/article/S2352873717300458/pdf', 'status': None}","{'volume': '3', 'pages': '440 - 449', 'name': ""Alzheimer's & Dementia : Translational Research & Clinical Interventions""}","{'bibtex': ""@Article{Lanctôt2017NeuropsychiatricSA,\n author = {K. Lanctôt and J. Amatniek and S. Ancoli-Israel and S. Arnold and C. Ballard and J. Cohen-Mansfield and Z. Ismail and C. Lyketsos and David S. Miller and E. Musiek and R. Osorio and P. Rosenberg and A. Satlin and D. Steffens and P. Tariot and L. Bain and M. Carrillo and James A. Hendrix and Heidi Jurgens and B. Boot},\n journal = {Alzheimer's & Dementia : Translational Research & Clinical Interventions},\n pages = {440 - 449},\n title = {Neuropsychiatric signs and symptoms of Alzheimer's disease: New treatment paradigms},\n volume = {3},\n year = {2017}\n}\n""}","[{'authorId': '4797664', 'name': 'K. Lanctôt'}, {'authorId': '3496547', 'name': 'J. Amatniek'}, {'authorId': '1396236343', 'name': 'S. Ancoli-Israel'}, {'authorId': '145601268', 'name': 'S. Arnold'}, {'authorId': '144956527', 'name': 'C. Ballard'}, {'authorId': '1397811791', 'name': 'J. Cohen-Mansfield'}, {'authorId': '2005479', 'name': 'Z. Ismail'}, {'authorId': '1901398', 'name': 'C. Lyketsos'}, {'authorId': '49971136', 'name': 'David S. Miller'}, {'authorId': '4843395', 'name': 'E. Musiek'}, {'authorId': '145734521', 'name': 'R. Osorio'}, {'authorId': '144889112', 'name': 'P. Rosenberg'}, {'authorId': '4250338', 'name': 'A. Satlin'}, {'authorId': '2138706', 'name': 'D. Steffens'}, {'authorId': '6323147', 'name': 'P. Tariot'}, {'authorId': '7535238', 'name': 'L. Bain'}, {'authorId': '2077654', 'name': 'M. Carrillo'}, {'authorId': '1992761937', 'name': 'James A. Hendrix'}, {'authorId': '1401877141', 'name': 'Heidi Jurgens'}, {'authorId': '4642584', 'name': 'B. Boot'}]"
430,247f9147f0fa07896e677549495fb6cd4a789cb4,"Human or Robot?: Investigating voice, appearance and gesture motion realism of conversational social agents","Research on creation of virtual humans enables increasing automatization of their behavior, including synthesis of verbal and nonverbal behavior. As the achievable realism of different aspects of agent design evolves asynchronously, it is important to understand if and how divergence in realism between behavioral channels can elicit negative user responses. Specifically, in this work, we investigate the question of whether autonomous virtual agents relying on synthetic text-to-speech voices should portray a corresponding level of realism in the non-verbal channels of motion and visual appearance, or if, alternatively, the best available realism of each channel should be used. In two perceptual studies, we assess how realism of voice, motion, and appearance influence the perceived match of speech and gesture motion, as well as the agent's likability and human-likeness. Our results suggest that maximizing realism of voice and motion is preferable even when this leads to realism mismatches, but for visual appearance, lower realism may be preferable. (A video abstract can be found at https://youtu.be/arfZZ-hxD1Y.)",2021.0,61.0,12.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3472306.3478338', 'status': None}",{'name': 'Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Ferstl2021HumanOR,\n author = {Ylva Ferstl and S. Thomas and Cédric Guiard and Cathy Ennis and R. Mcdonnell},\n journal = {Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents},\n title = {Human or Robot?: Investigating voice, appearance and gesture motion realism of conversational social agents},\n year = {2021}\n}\n'}","[{'authorId': '3430725', 'name': 'Ylva Ferstl'}, {'authorId': '145947976', 'name': 'S. Thomas'}, {'authorId': '2080984307', 'name': 'Cédric Guiard'}, {'authorId': '31894925', 'name': 'Cathy Ennis'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
431,2480142f614f424a33dc2c2e1bfbdc1d10214a8e,"MsEmoTTS: Multi-Scale Emotion Transfer, Prediction, and Control for Emotional Speech Synthesis","Expressive synthetic speech is essential for many human-computer interaction and audio broadcast scenarios, and thus synthesizing expressive speech has attracted much attention in recent years. Previous methods performed the expressive speech synthesis either with explicit labels or with a fixed-length style embedding extracted from reference audio, both of which can only learn an average style and thus ignores the multi-scale nature of speech prosody. In this paper, we propose MsEmoTTS, a multi-scale emotional speech synthesis framework, to model the emotion from different levels. Specifically, the proposed method is a typical attention-based sequence-to-sequence model and with proposed three modules, including global-level emotion presenting module (GM), utterance-level emotion presenting module (UM), and local-level emotion presenting module (LM), to model the global emotion category, utterance-level emotion variation, and syllable-level emotion strength, respectively. In addition to modeling the emotion from different levels, the proposed method also allows us to synthesize emotional speech in different ways, i.e., transferring the emotion from reference audio, predicting the emotion from input text, and controlling the emotion strength manually. Extensive experiments conducted on a Chinese emotional speech corpus demonstrate that the proposed method outperforms the compared reference audio-based and text-based emotional speech synthesis methods on the emotion transfer speech synthesis and text-based emotion prediction speech synthesis respectively. Besides, the experiments also show that the proposed method can control the emotion expressions flexibly. Detailed analysis shows the effectiveness of each module and the good design of the proposed method.",2022.0,51.0,35.0,True,"{'url': 'http://arxiv.org/pdf/2201.06460', 'status': None}","{'volume': '30', 'pages': '853-864', 'name': 'IEEE/ACM Transactions on Audio, Speech, and Language Processing'}","{'bibtex': '@Article{Lei2022MsEmoTTSME,\n author = {Yinjiao Lei and Shan Yang and Xinsheng Wang and Lei Xie},\n journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},\n pages = {853-864},\n title = {MsEmoTTS: Multi-Scale Emotion Transfer, Prediction, and Control for Emotional Speech Synthesis},\n volume = {30},\n year = {2022}\n}\n'}","[{'authorId': '51160531', 'name': 'Yinjiao Lei'}, {'authorId': '50591589', 'name': 'Shan Yang'}, {'authorId': '1519970315', 'name': 'Xinsheng Wang'}, {'authorId': '144206962', 'name': 'Lei Xie'}]"
432,2494294303492cc662a2c30def642c4826a98107,Diagnostic and Statistical Manual of Mental Disorders,,2011.0,14.0,90841.0,True,"{'url': 'https://europepmc.org/articles/pmc3547120?pdf=render', 'status': None}","{'volume': '189', 'pages': '158-159', 'name': 'Psychiatry Research'}","{'bibtex': '@Article{Mittal2011DiagnosticAS,\n author = {V. Mittal and E. Walker},\n journal = {Psychiatry Research},\n pages = {158-159},\n title = {Diagnostic and Statistical Manual of Mental Disorders},\n volume = {189},\n year = {2011}\n}\n'}","[{'authorId': '3315073', 'name': 'V. Mittal'}, {'authorId': '3472842', 'name': 'E. Walker'}]"
433,249ea01aa8b33ecb251c5b41f327a09eb1d74928,A COMPARISON OF THE REISS PROFILE WITH THE NEO PI-R ASSESSMENT OF PERSONALITY,"OF THESIS A COMPARISON OF THE REISS PROFILE WITH THE NEO PI-R ASSESSMENT OF PERSONALITY The purpose of this thesis was to determine whether the NEO Personality InventoryRevised (NEO PI-R) could account for significant variance within a measure of personality developed for the intellectually disabled (i.e., the Reiss Profile of Fundamental Motives), as well as to consider their comparative validity. The NEO PI-R and the Reiss Profile of Fundamental Motives were administered to 127 undergraduate students in conjunction with the Personality Research Form (PRF) and the Behavior Report Form (BRF). The NEO PI-R was able to account for a substantial amount of variance in the Reiss Profile scales, and the Reiss and the NEO accounted for approximately equivalent amounts of variance in the PRF and BRF. Implications for general personality research as well as additional research with a sample of adults with intellectual disability are discussed.",2010.0,70.0,2.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Boyd2010ACO,\n author = {Sara E. Boyd},\n title = {A COMPARISON OF THE REISS PROFILE WITH THE NEO PI-R ASSESSMENT OF PERSONALITY},\n year = {2010}\n}\n'}","[{'authorId': '144477794', 'name': 'Sara E. Boyd'}]"
434,24b1a870298497f963336372bea20537cffd14ab,Virtual Reality as an Adjunctive Non-pharmacologic Analgesic for Acute Burn Pain During Medical Procedures,,2011.0,67.0,473.0,True,"{'url': 'https://europepmc.org/articles/pmc4465767?pdf=render', 'status': None}","{'volume': '41', 'pages': '183-191', 'name': 'Annals of Behavioral Medicine'}","{'bibtex': '@Article{Hoffman2011VirtualRA,\n author = {H. Hoffman and Gloria T Chambers and W. Meyer and Lisa L. Arceneaux and W. J. Russell and E. Seibel and T. Richards and S. Sharar and D. Patterson},\n journal = {Annals of Behavioral Medicine},\n pages = {183-191},\n title = {Virtual Reality as an Adjunctive Non-pharmacologic Analgesic for Acute Burn Pain During Medical Procedures},\n volume = {41},\n year = {2011}\n}\n'}","[{'authorId': '1779275', 'name': 'H. Hoffman'}, {'authorId': '2054703703', 'name': 'Gloria T Chambers'}, {'authorId': '143931832', 'name': 'W. Meyer'}, {'authorId': '5329178', 'name': 'Lisa L. Arceneaux'}, {'authorId': '71058701', 'name': 'W. J. Russell'}, {'authorId': '3153418', 'name': 'E. Seibel'}, {'authorId': '3152109', 'name': 'T. Richards'}, {'authorId': '3348169', 'name': 'S. Sharar'}, {'authorId': '145902632', 'name': 'D. Patterson'}]"
435,24bbf001ea545b5cdbe55408fd25a75049380bdf,"Spontaneous inferences, implicit impressions, and implicit theories.","People make social inferences without intentions, awareness, or effort, i.e., spontaneously. We review recent findings on spontaneous social inferences (especially traits, goals, and causes) and closely related phenomena. We then describe current thinking on some of the most relevant processes, implicit knowledge, and theories. These include automatic and controlled processes and their interplay; embodied cognition, including mimicry; and associative versus rule-based processes. Implicit knowledge includes adult folk theories, conditions of personhood, self-knowledge to simulate others, and cultural and social class differences. Implicit theories concern Bayesian networks, recent attribution research, and questions about the utility of the disposition-situation dichotomy. Developmental research provides new insights. Spontaneous social inferences include a growing array of phenomena, but they have been insufficiently linked to other phenomena and theories. We hope the links suggested in this review begin to remedy this.",2008.0,206.0,418.0,False,,"{'volume': '59', 'pages': '\n          329-60\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Uleman2008SpontaneousII,\n author = {J. Uleman and S. Adil Saribay and C. M. Gonzalez},\n journal = {Annual review of psychology},\n pages = {\n          329-60\n        },\n title = {Spontaneous inferences, implicit impressions, and implicit theories.},\n volume = {59},\n year = {2008}\n}\n'}","[{'authorId': '4405440', 'name': 'J. Uleman'}, {'authorId': '6292637', 'name': 'S. Adil Saribay'}, {'authorId': '2148877392', 'name': 'C. M. Gonzalez'}]"
436,24c5de3c93aa8cdd779641c3172399ef5c092d1c,What Are Emotion Theories About,"This is a set of notes relating to an invited talk at the cross-disciplinary workshop on Architectures for Modeling Emotion at the AAAI Spring Symposium at Stanford University in March 2004. The organisers of the workshop note that work on emotions “is often carried out in anad hocmanner”, and hope to remedy this by focusing on two themes (a) validation of emotion models and architectures, and (b) relevance of recent findings from affective neuroscience research. I shall focus mainly on (a), but in a manner which, I hope is relevant to (b), by addressing the need for conceptual clarification to remove, or at least reduce, the adhocery, both in modelling and in empirical research. In particular I try to show how a design-based approach can provide an improved conceptual framework and sharpen empirical questions relating to the study of mind and brain. From this standpoint it turns out that what are normally called emotions are a somewhat fuzzy subset of a larger class of states and processes that can arise out of interactions between different mechanisms in an architecture. What exactly the architecture is will determine both the larger class and the subset, since different architectures support different classes of states and processes. In order to develop the design-based approach we need a good ontology for characterising varieties of architectures and the states and processes that can occur in them. At present this too is often a matter of much ad-hocery. We propose steps toward a remedy. Validation vstesting It is good to ask how theories can be validated, though I would rather ask how they can be t sted, and how they can becompared, in various dimensions, such as depth, clarity, generality, precision, explanatory power, etc., since most theories are incomplete, provisional, premature, vague, or just false. So validation is rarely to be expected, even when a theory is the best one available and provides a good basis for further research, a point that is familiar from the writings of Karl Popper (Popper 1934; Magee 1985), and work of Lakatos cited by Dean Petters in this symposium. Copyright c © 2004, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. There is, however, a kind of validation of theories of a type Popper did not (as far as I know) admit as science, and many scientists do not acknowledge, partly because of Popper’s influence, namely theories about what is possible (what can occur). Simple logic shows that even a single example validates such a theory. The importance of theories of what is possible and how they are presupposed by the search for laws and regularities which constrain what is possible, was discussed in Sloman (1978, Ch 2). See also (Boden 1990). In particular, contrary to wide-spread views on scientific method, the truth of a statement that something can occur is established by a singleexample – which could be world-shaking (e.g. the discovery that light of low intensity and small wavelength can trigger an electric current when high intensity large wavelength light fails (the photoelectric effect), the discovery in 1919 that light from a star can be deflected by passing near the sun, or Newton’s earlier discovery that white light passing through a prism can be split into beams different colours). However, checking that the description of the example is correct may be non-trivial, especially if it requires the use of concepts that are not yet generally understood or theories that are not yet accepted. For present purposes the study of architectures and the phenomena they support is part of the study of what can exist or occur (deep science) and why, rather than an attempt to discover any new laws about what happens when or what correlates with what (shallow science). But we need to know what we are talking about. What are we talking about? It is sometimes forgotten that the question whether a theory is true or false presupposes an answer to whether it makes sense at all. All theories use concepts , for these are the building blocks of propositions, but insofar as the concepts are obscure, confused, or vague, the theories, and even the questions to which the theories are answers, will be flawed. For instance, if our concept of ‘emotion’ is ambiguous then so also will many questions about emotions be ambiguous, e.g. how emotions evolved, what their functions are, which animals have them, which brain mechanisms produce them, what types there are, whether they are needed for intelligence, whether a foetus has them, etc. Alas, our everyday concept of ‘emotion’ mixes up motivations, attitudes, moods, and other affective states and processes, and is therefore is too deeply flawed to be a useful component of scientific questions and theories for reasons recounted elsewhere. 1 But that does not prevent scientists assuming that these concepts can be used to formulate clear, unambiguous scientific questions or theories. For instance, sometimes people who argue that emotions are needed for intelligence are merely defending the truism that motivation is needed for action, and preferences are needed for selecting between options. However, not everyone would call a motive or preference, however important, an emotion. Wishful thinking isn’t science Sometimes over-generalising the notion of ‘emotion’ is related to a desire to argue that emotions are important in ways not previously acknowledged, e.g. that they are a prerequisite for intelligence. This can be wishful thinking or a trivial truism. If ‘emotion’ is construed so broadly that it covers all goals and preferences the claim that emotions are needed for intelligence is vacuous. On the other hand if it refers more narrowly to the sorts of processes in which one subsystem interferes with or disrupts the normal functioning of another, as happens in many of the states in which people are described as being ‘emotional’ then it is false that emotions arerequiredfor intelligence: on the contrary, emotions of that sort can get in the way of sensible decisions and actions. Monica Croucher and I once argued in 1981 that mechanisms required for intelligence in resource-limited robots in fast-changing environments would inevitably produce thepossibility of emotional states, involving interruption or modulation of one process by another (where the latter is often a fast and therefore relatively stupid process) that detects an urgent need for some change, e.g. using reactive mechanisms labelled ‘alarms’ in Fig. 1. But saying that states of type X can occur as a side-effect of the operation of some mechanism M that is required for intelligence does not imply that states of type X are themselves required for intelligence. Many wishful thinkers misinterpreted that paper as claiming that emotions are requiredfor intelligence, just as they fail to see the obvious flaw in Damasio’s widely quoted reasoning (1994) from the premiss:Damage to frontal lobes impairs both intelligence and emotional capabilitiesto the conclusionEmotions are required for intelligence . A moment’s thought should show that two capabilities could presuppose some common mechanisms without either capability being required for the other. A research community with too much wishful thinking does not advance science. Of course, if I have misread such people and they are merely proposing the truism (noted by Hume, which needs no empirical evidence) that motivation and preferences are required for intelligent thought and actions then that is another manifestation of the ambiguity of the word ‘emotion’. E.g. in (Sloman 2002b; 2002a; 2001; Sloman, Chrisley, & Scheutz To Appear). Figure 1: The CogAff schema defines a crude first-draft division of mechanisms into 9 categories. A particular type of fast, patterndriven, reactive central mechanism, with inputs from and outputs to many other components of the architecture could function as an alarm mechanism able to produce global reorganisation very quickly. Different sorts of alarm systems can produce different sorts of emotions, depending on where the inputs come from where the outputs go, what kinds of decisions are taken and what kinds of output signals are sent. Slower, longer lasting, more easily suppressedispositionalmechanisms can produce long term emotions, such as grief or jealousy. We need finer-grained ontologies We should not put both (i) a general preference for saving effort, and (ii) fear produced by a stampeding herd, in the same conceptual basket when they have so very many differences, including the (relative) permanence of the first and the transience of the second. Or rather, we can put them in a more general basket labelled ‘affect’ which includes sub-categories which might be aptly labelled ‘emotion’, ‘desire’, ‘preference’, ‘attitude’, ‘value’, ‘mood’, etc. I am not claiming that all emotions are short-term (though many emotion theories have that consequence, often not noticed by their proponents). In Wright et al. (1996) we tried to show, at least in outline, how long-term emotions such as grief, could exist in the form of dispositions which only rarely manifest themselves, either because of external triggers (reminders) or because other competing attention-grabbers subside. Many states generally regarded as important human emotions that form the stuff of plays, novels and garden-gate gossip are long term largely dispositional states, including jealousy, vengefulness, family love, obsessive ambition, infatuation, fascination with a mathematical problem, etc. There are other long term affective states such as preferences, and attitudes that are not normally called emotions. Of course, someone who defines an emotion as an episodic state in which there are particular sorts of bodily changes or sensed changes in a body state map will not include some of these long term states as emotions. But that’s just another example of the terminological disarray. Non-vicious cycles of defining relationships We",2004.0,25.0,25.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sloman2004WhatAE,\n author = {A. Sloman},\n title = {What Are Emotion Theories About},\n year = {2004}\n}\n'}","[{'authorId': '145788442', 'name': 'A. Sloman'}]"
437,24d257fcc11a751d53188313ca7921cbddb3175e,Gaze and task performance in shared virtual environments,"Non-verbal behaviour, particularly gaze direction, plays a crucial function in regulating conversations and providing critical social information. In the current set of studies, we represented interactants in a shared immersive virtual environment. Interactants sat in physically remote rooms, entered a common virtual room and played games of 20 questions. The interactants were represented by one of three types of avatars: (1) human forms with head movements rendered in real time; (2) human forms without head movements rendered; or (3) human voice only (i.e., a conference call). The data demonstrated that interactants in the rendered head movement condition rated a higher level of co-presence, liked each other more, looked at each other's heads more, and spoke for a lower percentage of time during the game, compared to the other two conditions. We discuss implications for the design of shared virtual environments, the study of non-verbal behaviour and the goal of facilitating efficient task performance. Copyright # 2002 John Wiley & Sons, Ltd.",2002.0,32.0,140.0,False,,"{'volume': '13', 'pages': '313-320', 'name': 'Comput. Animat. Virtual Worlds'}","{'bibtex': '@Article{Bailenson2002GazeAT,\n author = {J. Bailenson and A. Beall and J. Blascovich},\n journal = {Comput. Animat. Virtual Worlds},\n pages = {313-320},\n title = {Gaze and task performance in shared virtual environments},\n volume = {13},\n year = {2002}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2307657', 'name': 'J. Blascovich'}]"
438,250576f2ec19924718bf621d34b75493e0d68618,CLARA: A Multifunctional Virtual Agent for Conference Support and Touristic Information,,2015.0,8.0,17.0,False,,{'pages': '233-239'},"{'bibtex': '@Inproceedings{D’Haro2015CLARAAM,\n author = {L. F. D’Haro and Seokhwan Kim and Kheng Hui Yeo and Ridong Jiang and Andreea Niculescu and Rafael E. Banchs and Haizhou Li},\n pages = {233-239},\n title = {CLARA: A Multifunctional Virtual Agent for Conference Support and Touristic Information},\n year = {2015}\n}\n'}","[{'authorId': '1405511901', 'name': 'L. F. D’Haro'}, {'authorId': '2047181', 'name': 'Seokhwan Kim'}, {'authorId': '3174155', 'name': 'Kheng Hui Yeo'}, {'authorId': '2847726', 'name': 'Ridong Jiang'}, {'authorId': '34573320', 'name': 'Andreea Niculescu'}, {'authorId': '1694652', 'name': 'Rafael E. Banchs'}, {'authorId': '2119251083', 'name': 'Haizhou Li'}]"
439,251c4e20bea350ba1c00f089809e27266f0ca80e,Virtual proximity and facial expressions of computer agents regulate human emotions and attention,"Emotion‐ and attention‐related subjective and physiological responses to virtual proximity and facial expressions of embodied computer agents (ECA) were studied. Thirty participants viewed female and male characters with a neutral, unpleasant, or pleasant facial expression. Agents' size was used to simulate three levels of proximity. Participants' electrical facial muscle and heart activity were registered, and subjective ratings of emotional and attentional experiences collected. Unpleasant and large (i.e., closer) agents were more alerting (i.e., unpleasant, arousing, and dominating) and attracted more stimulus‐driven attention than neutral, pleasant, and smaller (i.e., further away) agents. Pleasant agents attracted more voluntary attention than neutral and unpleasant agents. Heart rate (HR) responded to agent proximity, while the valence of the agent affected electrical facial muscle activity. Thus, the imitation of human social emotional cues in embodied computer agents (ECAs) could be used to regulate human–computer interaction. Copyright © 2010 John Wiley & Sons, Ltd.",2010.0,33.0,12.0,False,,"{'volume': '21', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Vanhala2010VirtualPA,\n author = {T. Vanhala and Veikko Surakka and H. Siirtola and Kari-Jouko Räihä and Benoît Morel and Laurent Ach},\n journal = {Computer Animation and Virtual Worlds},\n title = {Virtual proximity and facial expressions of computer agents regulate human emotions and attention},\n volume = {21},\n year = {2010}\n}\n'}","[{'authorId': '2011094', 'name': 'T. Vanhala'}, {'authorId': '1718377', 'name': 'Veikko Surakka'}, {'authorId': '1934593', 'name': 'H. Siirtola'}, {'authorId': '1724448', 'name': 'Kari-Jouko Räihä'}, {'authorId': '32214926', 'name': 'Benoît Morel'}, {'authorId': '2305305', 'name': 'Laurent Ach'}]"
440,25228b341fc7bbc2eee7d8f42e0bd38f947c3046,Toward an example-based machine translation from written text to ASL using virtual agent animation,"Modern computational linguistic software cannot produce important aspects of sign language translation. Using some researches we deduce that the majority of automatic sign language translation systems ignore many aspects when they generate animation; therefore the interpretation lost the truth information meaning. Our goals are: to translate written text from any language to ASL animation; to model maximum raw information using machine learning and computational techniques; and to produce a more adapted and expressive form to natural looking and understandable ASL animations. Our methods include linguistic annotation of initial text and semantic orientation to generate the facial expression. We use the genetic algorithms coupled to learning/recognized systems to produce the most natural form. To detect emotion we are based on fuzzy logic to produce the degree of interpolation between facial expressions. Roughly, we present a new expressive language Text Adapted Sign Modeling Language TASML that describes all maximum aspects related to a natural sign language interpretation. This paper is organized as follow: the next section is devoted to present the comprehension effect of using Space/Time/SVO form in ASL animation based on experimentation. In section 3, we describe our technical considerations. We present the general approach we adopted to develop our tool in section 4. Finally, we give some perspectives and future works.",2012.0,24.0,7.0,False,,"{'name': 'ArXiv', 'volume': 'abs/1203.3023'}","{'bibtex': '@Article{Boulares2012TowardAE,\n author = {Mehrez Boulares and M. Jemni},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Toward an example-based machine translation from written text to ASL using virtual agent animation},\n volume = {abs/1203.3023},\n year = {2012}\n}\n'}","[{'authorId': '2950670', 'name': 'Mehrez Boulares'}, {'authorId': '1696756', 'name': 'M. Jemni'}]"
441,2524e9fb27559cb505ceed996d377169d9430b57,"An Agent-Based Model of Mortality Shocks, Intergenerational Effects, and Urban Crime","Rational criminals choose crime over lawfulness because it pays better; hence poverty correlates to criminal behavior. This correlation is an insufficient historical explanation. An agent-based model of urban crime, mortality, and exogenous population shocks supplements the standard economic story, closing the gap with an empirical reality that often breaks from trend. Agent decision making within the model is built around a career maximization function, with life expectancy as the key independent variable. Rational choice takes the form of a local information heuristic, resulting in subjectively rational suboptimal decision making. The effects of population shocks are explored using the Crime and Mortality Simulation (CAMSIM), with effects demonstrated to persist across generations. Past social trauma are found to lead to higher crime rates which subsequently decline as the effect degrades, though 'aftershocks' are often experienced.",2006.0,52.0,27.0,False,,"{'volume': '9', 'name': 'J. Artif. Soc. Soc. Simul.'}","{'bibtex': '@Article{Makowsky2006AnAM,\n author = {M. Makowsky},\n journal = {J. Artif. Soc. Soc. Simul.},\n title = {An Agent-Based Model of Mortality Shocks, Intergenerational Effects, and Urban Crime},\n volume = {9},\n year = {2006}\n}\n'}","[{'authorId': '37484915', 'name': 'M. Makowsky'}]"
442,257f768056aae1c4d976334cde8ef2d2aec410d9,Spatiotemporal Recurrent Convolutional Networks for Recognizing Spontaneous Micro-Expressions,"Recently, the recognition task of spontaneous facial micro-expressions has attracted much attention with its various real-world applications. Plenty of handcrafted or learned features have been employed for a variety of classifiers and achieved promising performances for recognizing micro-expressions. However, the micro-expression recognition is still challenging due to the subtle spatiotemporal changes of micro-expressions. To exploit the merits of deep learning, we propose a novel deep recurrent convolutional networks based micro-expression recognition approach, capturing the spatiotemporal deformations of micro-expression sequence. Specifically, the proposed deep model is constituted of several recurrent convolutional layers for extracting visual features and a classificatory layer for recognition. It is optimized by an end-to-end manner and obviates manual feature design. To handle sequential data, we exploit two ways to extend the connectivity of convolutional networks across temporal domain, in which the spatiotemporal deformations are modeled in views of facial appearance and geometry separately. Besides, to overcome the shortcomings of limited and imbalanced training samples, two temporal data augmentation strategies as well as a balanced loss are jointly used for our deep network. By performing the experiments on three spontaneous micro-expression datasets, we verify the effectiveness of our proposed micro-expression recognition approach compared to the state-of-the-art methods.",2019.0,71.0,150.0,True,"{'url': 'http://jultika.oulu.fi/files/nbnfi-fe2019120345372.pdf', 'status': None}","{'volume': '22', 'pages': '626-640', 'name': 'IEEE Transactions on Multimedia'}","{'bibtex': '@Article{Xia2019SpatiotemporalRC,\n author = {Zhaoqiang Xia and Xiaopeng Hong and Xingyu Gao and Xiaoyi Feng and Guoying Zhao},\n journal = {IEEE Transactions on Multimedia},\n pages = {626-640},\n title = {Spatiotemporal Recurrent Convolutional Networks for Recognizing Spontaneous Micro-Expressions},\n volume = {22},\n year = {2019}\n}\n'}","[{'authorId': '1917901', 'name': 'Zhaoqiang Xia'}, {'authorId': '46761465', 'name': 'Xiaopeng Hong'}, {'authorId': '46757744', 'name': 'Xingyu Gao'}, {'authorId': '4729239', 'name': 'Xiaoyi Feng'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}]"
443,25830d039ed691cd1a65e617d69db20a9eb4af1c,Design of a Virtual Human Presenter,"We have created a virtual human presenter who accepts speech texts with embedded commands as inputs. The presenter acts in real-time 3D animation synchronized with speech. The system was developed on the Jack animated-agent system. Jack provides a 3D graphical environment for controlling articulated figures, including detailed human models.",2000.0,34.0,123.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/b3a58d45-c3ed-4c33-b93e-c0f83b66261d/download', 'status': None}","{'volume': '20', 'pages': '79-85', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Noma2000DesignOA,\n author = {T. Noma and Liwei Zhao and N. Badler},\n journal = {IEEE Computer Graphics and Applications},\n pages = {79-85},\n title = {Design of a Virtual Human Presenter},\n volume = {20},\n year = {2000}\n}\n'}","[{'authorId': '34664967', 'name': 'T. Noma'}, {'authorId': '2427954', 'name': 'Liwei Zhao'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
444,25932c162ac3e3cbf14d333277dfcc2b53b9bd0c,"Dynamic bayesian networks: representation, inference and learning","Dynamic Bayesian Networks: Representation, Inference and Learning by Kevin Patrick Murphy Doctor of Philosophy in Computer Science University of California, Berkeley Professor Stuart Russell, Chair Modelling sequential data is important in many areas of science and engineering. Hidden Markov models (HMMs) and Kalman filter models (KFMs) are popular for this because they are simple and flexible. For example, HMMs have been used for speech recognition and bio-sequence analysis, and KFMs have been used for problems ranging from tracking planes and missiles to predicting the economy. However, HMMs and KFMs are limited in their “expressive power”. Dynamic Bayesian Networks (DBNs) generalize HMMs by allowing the state space to be represented in factored form, instead of as a single discrete random variable. DBNs generalize KFMs by allowing arbitrary probability distributions, not just (unimodal) linear-Gaussian. In this thesis, I will discuss how to represent many different kinds of models as DBNs, how to perform exact and approximate inference in DBNs, and how to learn DBN models from sequential data. In particular, the main novel technical contributions of this thesis are as follows: a way of representing Hierarchical HMMs as DBNs, which enables inference to be done in O(T ) time instead of O(T ), where T is the length of the sequence; an exact smoothing algorithm that takes O(log T ) space instead of O(T ); a simple way of using the junction tree algorithm for online inference in DBNs; new complexity bounds on exact online inference in DBNs; a new deterministic approximate inference algorithm called factored frontier; an analysis of the relationship between the BK algorithm and loopy belief propagation; a way of applying Rao-Blackwellised particle filtering to DBNs in general, and the SLAM (simultaneous localization and mapping) problem in particular; a way of extending the structural EM algorithm to DBNs; and a variety of different applications of DBNs. However, perhaps the main value of the thesis is its catholic presentation of the field of sequential data modelling.",2002.0,425.0,2893.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Murphy2002DynamicBN,\n author = {Kevin P. Murphy and Stuart J. Russell},\n title = {Dynamic bayesian networks: representation, inference and learning},\n year = {2002}\n}\n'}","[{'authorId': '2056417995', 'name': 'Kevin P. Murphy'}, {'authorId': '145107462', 'name': 'Stuart J. Russell'}]"
445,25a4c9b4e67c8b173089c09be98bfeffc2877a7d,Financial Decision Making,"This assessment project is linked to the Guardian Scholars workshop held quarterly. Each quarter a workshop is held for our Guardian Scholars, former foster youth. In Fall 2012 we offered the group a Financial Decision Making workshop. The main purpose of this assessment project was to measure student learning outcomes taught in the Financial Decision Making workshop. Learning outcomes were assessed prior to the workshop using ipod touch devices and a post workshop survey was sent via email after the workshop. The post workshop survey included questions that gauged student satisfaction, and provided the opportunity for students to give suggestions. The results of this project have been used to improve the program, and to demonstrate the value of the Financial Decision Making workshop. As a result of participating in the Financial Decision Making workshop, students will be able to:-Understand that taking out a loan is a purchase, which is separate from the item purchased.-Explain how loan amortization is the calculation of how the loan amount decreases over time.-Learn via the examples used in the workshop that paying the minimum payment on a credit card results in high interest charges.-Understand through group discussion that discipline is very important in managing purchases.-Understand through group discussion that it is important to protect your investment when taking out a loan for a large purchase.",1968.0,0.0,76.0,False,,"{'volume': '', 'pages': '499', 'name': ''}","{'bibtex': '@Inproceedings{Mock1968FinancialDM,\n author = {E. Mock},\n pages = {499},\n title = {Financial Decision Making},\n year = {1968}\n}\n'}","[{'authorId': '6670646', 'name': 'E. Mock'}]"
446,25a58152b289a9e467c68873fd59b640e484031e,Design Thinking and 21st Century Skills,,2015.0,41.0,11.0,False,,"{'volume': '', 'pages': '33-46', 'name': ''}","{'bibtex': '@Inproceedings{Koh2015DesignTA,\n author = {J. Koh and C. Chai and B. Wong and Huang-Yao Hong},\n pages = {33-46},\n title = {Design Thinking and 21st Century Skills},\n year = {2015}\n}\n'}","[{'authorId': '5992336', 'name': 'J. Koh'}, {'authorId': '3225877', 'name': 'C. Chai'}, {'authorId': '48155911', 'name': 'B. Wong'}, {'authorId': '2045843', 'name': 'Huang-Yao Hong'}]"
447,25ba57fba0eb05b08273f6e448911842ca7041cc,Reliability of Ultra‐Short ECG Indices for Heart Rate Variability,Background: Heart rate variability (HRV) is an accepted and reliable means for assessing autonomic nervous system dysfunction. A 5‐minute measurement of HRV is considered methodologically adequate. Several studies have attempted to use shorter recordings of 1–2 minutes or 10 seconds. The aim of this study was to determine the reliability of HRV parameters calculated from ultra‐short electrocardiogram recordings.,2011.0,17.0,168.0,True,"{'url': 'https://europepmc.org/articles/pmc6932379?pdf=render', 'status': None}","{'volume': '16', 'name': 'Annals of Noninvasive Electrocardiology'}","{'bibtex': '@Article{Nussinovitch2011ReliabilityOU,\n author = {U. Nussinovitch and K. Elishkevitz and Keren Katz and M. Nussinovitch and S. Segev and B. Volovitz and N. Nussinovitch},\n journal = {Annals of Noninvasive Electrocardiology},\n title = {Reliability of Ultra‐Short ECG Indices for Heart Rate Variability},\n volume = {16},\n year = {2011}\n}\n'}","[{'authorId': '6623541', 'name': 'U. Nussinovitch'}, {'authorId': '7996656', 'name': 'K. Elishkevitz'}, {'authorId': '40248580', 'name': 'Keren Katz'}, {'authorId': '7322414', 'name': 'M. Nussinovitch'}, {'authorId': '3823238', 'name': 'S. Segev'}, {'authorId': '8592109', 'name': 'B. Volovitz'}, {'authorId': '7482777', 'name': 'N. Nussinovitch'}]"
448,26091c350b3a2883d10029d2161625d3108f0c21,An Affective Virtual Agent Providing Embodied Feedback in the Paired Associate Task: System Design and Evaluation,,2013.0,23.0,7.0,False,,{'pages': '406-415'},"{'bibtex': '@Article{Becker-Asano2013AnAV,\n author = {C. Becker-Asano and Philip Stahl and Marco Ragni and M. Courgeon and Jean-Claude Martin and B. Nebel},\n booktitle = {International Conference on Intelligent Virtual Agents},\n pages = {406-415},\n title = {An Affective Virtual Agent Providing Embodied Feedback in the Paired Associate Task: System Design and Evaluation},\n year = {2013}\n}\n'}","[{'authorId': '1403827243', 'name': 'C. Becker-Asano'}, {'authorId': '2073228979', 'name': 'Philip Stahl'}, {'authorId': '144381906', 'name': 'Marco Ragni'}, {'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '145304209', 'name': 'B. Nebel'}]"
449,261f46fb5a1e58fbbb0089ec3ac21bb87bdb11b3,IAGO: Interactive Arbitration Guide Online,,2016.0,0.0,34.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mell2016IAGOIA,\n author = {Johnathan Mell and J. Gratch},\n title = {IAGO: Interactive Arbitration Guide Online},\n year = {2016}\n}\n'}","[{'authorId': '3114187', 'name': 'Johnathan Mell'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
450,261fa69e3260296652e02d8757f9af16f7dd6ac9,Emotion Recognition in Children with Autism Spectrum Disorders: Relations to Eye Gaze and Autonomic State,,2010.0,70.0,555.0,False,,"{'volume': '40', 'pages': '358-370', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Bal2010EmotionRI,\n author = {Elgiz Bal and E. Harden and Damon G. Lamb and A. V. Van Hecke and John W. Denver and S. Porges},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {358-370},\n title = {Emotion Recognition in Children with Autism Spectrum Disorders: Relations to Eye Gaze and Autonomic State},\n volume = {40},\n year = {2010}\n}\n'}","[{'authorId': '4529011', 'name': 'Elgiz Bal'}, {'authorId': '39397887', 'name': 'E. Harden'}, {'authorId': '145018594', 'name': 'Damon G. Lamb'}, {'authorId': '40169180', 'name': 'A. V. Van Hecke'}, {'authorId': '2086256166', 'name': 'John W. Denver'}, {'authorId': '4226466', 'name': 'S. Porges'}]"
451,2628ef74935d0c2d54319bcaf43e734a456753bf,Roles of an intelligent tutor agent in a virtual society,"In this paper we investigate how agents can facilitate and mediate interaction, communication and cooperation among participants of spatially distributed teams. We illustrate the architecture of an agent mediated-collaborative system that can serve the role of a tutor within a virtual group. In the virtual group the software agent should play besides the tutoring role also the group management role. The group manager has the responsibility to control the coherence of the actual group in regard to the actual group structure definition. This research will highlight also the incorporation of social-filter algorithms to mental models of software animated agents. Those algorithms may qualify an agent's expression of its emotional state by the social context, thereby enhancing the agent's believability not only as a tutor but also as a conversational partner or virtual teammate.",2005.0,24.0,9.0,False,,"{'pages': '237-244', 'name': 'The 2005 Symposium on Applications and the Internet'}","{'bibtex': '@Article{Marin2005RolesOA,\n author = {B. Marin and A. Hunger and S. Werner and S. Meila and Christian Schuetz},\n journal = {The 2005 Symposium on Applications and the Internet},\n pages = {237-244},\n title = {Roles of an intelligent tutor agent in a virtual society},\n year = {2005}\n}\n'}","[{'authorId': '1824479', 'name': 'B. Marin'}, {'authorId': '1769376', 'name': 'A. Hunger'}, {'authorId': '48801263', 'name': 'S. Werner'}, {'authorId': '2495654', 'name': 'S. Meila'}, {'authorId': '2069483319', 'name': 'Christian Schuetz'}]"
452,263aa65ec7fc8631fb058420e4a4e9f95916d5b7,A classification of controlled interpersonal affect regulation strategies.,"Controlled interpersonal affect regulation refers to the deliberate regulation of someone else's affect. Building on existing research concerning this everyday process, the authors describe the development of a theoretical classification scheme that distinguishes between the types of strategy used to achieve interpersonal affect regulation. To test the theoretical classification, the authors generated a corpus of 378 distinct strategies using self-report questionnaires and diaries completed by student and working samples. Twenty participants then performed a card-sort of the strategies. Hierarchical cluster analysis was used to determine how well the theoretical classification represented spontaneous understandings of controlled interpersonal affect regulation. The final classification primarily distinguished between strategies used to improve versus those used to worsen others' affect, and between strategies that engaged the target in a situation or affective state versus relationship-oriented strategies. The classification provides a meaningful basis for organizing existing research and making future conceptual and empirical distinctions.",2009.0,57.0,275.0,True,"{'url': 'https://pure.manchester.ac.uk/ws/files/26355541/POST-PEER-REVIEW-PUBLISHERS.PDF', 'status': None}","{'volume': '9 4', 'pages': '\n          498-509\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Niven2009ACO,\n author = {Karen Niven and P. Totterdell and D. Holman},\n journal = {Emotion},\n pages = {\n          498-509\n        },\n title = {A classification of controlled interpersonal affect regulation strategies.},\n volume = {9 4},\n year = {2009}\n}\n'}","[{'authorId': '145276844', 'name': 'Karen Niven'}, {'authorId': '1993236', 'name': 'P. Totterdell'}, {'authorId': '78063653', 'name': 'D. Holman'}]"
454,26460b329a683f29f8fce6651237b2be6db2932f,Is virtual reality emotionally arousing? Investigating five emotion inducing virtual park scenarios,,2015.0,44.0,231.0,False,,"{'volume': '82', 'pages': '48-56', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Felnhofer2015IsVR,\n author = {A. Felnhofer and O. Kothgassner and Mareike Schmidt and Anna-Katharina Heinzle and Leon Beutl and H. Hlavacs and I. Kryspin-Exner},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {48-56},\n title = {Is virtual reality emotionally arousing? Investigating five emotion inducing virtual park scenarios},\n volume = {82},\n year = {2015}\n}\n'}","[{'authorId': '2144008', 'name': 'A. Felnhofer'}, {'authorId': '3136916', 'name': 'O. Kothgassner'}, {'authorId': '71639197', 'name': 'Mareike Schmidt'}, {'authorId': '2078805540', 'name': 'Anna-Katharina Heinzle'}, {'authorId': '2373231', 'name': 'Leon Beutl'}, {'authorId': '1743771', 'name': 'H. Hlavacs'}, {'authorId': '1398005104', 'name': 'I. Kryspin-Exner'}]"
455,2651821004f00566a0ec77d5ca434b64b49a9776,How the Ocean Personality Model Affects the Perception of Crowds,"This approach extends the HiDAC (High-Density Autonomous Crowds) system by providing each agent with a personality model based on the Ocean (openness, conscientiousness, extroversion, agreeableness, and neuroticism) personality model. Each personality trait has an associated nominal behavior. Specifying an agent's personality leads to an automation of low-level parameter tuning.",2011.0,16.0,146.0,False,,"{'volume': '31', 'pages': '22-31', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Durupinar2011HowTO,\n author = {Funda Durupinar and N. Pelechano and J. Allbeck and U. Güdükbay and N. Badler},\n journal = {IEEE Computer Graphics and Applications},\n pages = {22-31},\n title = {How the Ocean Personality Model Affects the Perception of Crowds},\n volume = {31},\n year = {2011}\n}\n'}","[{'authorId': '2643744', 'name': 'Funda Durupinar'}, {'authorId': '1746484', 'name': 'N. Pelechano'}, {'authorId': '1855748', 'name': 'J. Allbeck'}, {'authorId': '1746035', 'name': 'U. Güdükbay'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
457,269062740273fc30b87378720b3b902c3b7081a7,Development and validation of the Multimodal Presence Scale for virtual reality environments: A confirmatory factor analysis and item response theory approach,,2017.0,41.0,157.0,False,,"{'volume': '72', 'pages': '276-285', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Makransky2017DevelopmentAV,\n author = {G. Makransky and Lau Lilleholt and Anders Aaby},\n journal = {Comput. Hum. Behav.},\n pages = {276-285},\n title = {Development and validation of the Multimodal Presence Scale for virtual reality environments: A confirmatory factor analysis and item response theory approach},\n volume = {72},\n year = {2017}\n}\n'}","[{'authorId': '4274170', 'name': 'G. Makransky'}, {'authorId': '10790823', 'name': 'Lau Lilleholt'}, {'authorId': '10669579', 'name': 'Anders Aaby'}]"
458,26930c2ab244397c27017e1709079b2315d9022c,Investigating children's opinions of games: Fun Toolkit vs. This or That,"Over the past decade many new evaluation methods have emerged for evaluating user experience with children, but the results of these studies have tended to be reported in isolation of other techniques. This paper reports on a comparative analysis of 2 user experience evaluations methods with children. A within-subject design was adopted using 20 children aged between 7 and 8. The children played 2 different games on a tablet PCs and their experiences of each were captured using 2 evaluation methods which have been validated with children: the Fun Toolkit and This or That. The results showed that the Fun Toolkit and This or That method yielded similar results and were able to establish a preference for one game over the other. However, there were some inconsistencies between the results of individual tools within the Fun toolkit and some of the constructs being measured in the This or That method. Further research will try to identify any ordering effects within each method and redundancies within the questions.",2012.0,34.0,52.0,False,,{'pages': '70-77'},"{'bibtex': ""@Inproceedings{Sim2012InvestigatingCO,\n author = {G. Sim and M. Horton},\n pages = {70-77},\n title = {Investigating children's opinions of games: Fun Toolkit vs. This or That},\n year = {2012}\n}\n""}","[{'authorId': '143945613', 'name': 'G. Sim'}, {'authorId': '143998947', 'name': 'M. Horton'}]"
459,26a57c2a8b888c82dc3bbe0ad708a33a53299b38,"Synaesthesia? A window into perception, thought and language","We investigated grapheme–colour synaesthesia and found that: (1) The induced colours led to perceptual grouping and pop-out, (2) a grapheme rendered invisible through ‘crowding’ or lateral masking induced synaesthetic colours — a form of blindsight — and (3) peripherally presented graphemes did not induce colours even when they were clearly visible. Taken collectively, these and other experiments prove conclusively that synaesthesia is a genuine perceptual phenomenon, not an effect based on memory associations from childhood or on vague metaphorical speech. We identify different subtypes of number–colour synaesthesia and propose that they are caused by hyperconnectivity between colour and number areas at different stages in processing; lower synaesthetes may have cross-wiring (or cross-activation) within the fusiform gyrus, whereas higher synaesthetes may have cross-activation in the angular gyrus. This hyperconnectivity might be caused by a genetic mutation that causes defective pruning of connections between brain maps. The mutation may further be expressed selectively (due to transcription factors) in the fusiform or angular gyri, and this may explain the existence of different forms of synaesthesia. If expressed very diffusely, there may be extensive cross-wiring between brain regions that represent abstract concepts, which would explain the link between creativity, metaphor and synaesthesia (and the higher incidence of synaesthesia among artists and poets). Also, hyperconnectivity between the sensory cortex and amygdala would explain the heightened aversion synaesthetes experience when seeing numbers printed in the ‘wrong’ colour. Lastly, kindling (induced hyperconnectivity in the temporal lobes of temporal lobe epilepsy [TLE] patients) may explain the purported higher incidence of synaesthesia in these patients . We conclude with a synaesthesia-based theory of the evolution of language. Thus, our experiments on synaesthesia and our theoretical framework attempt to link several seemingly unrelated facts about the human mind. Far from being a mere curiosity, synaesthesia may provide a window into perception, thought and language. www.imprint-academic.com/rama copyright © Journal of Consciousness Studies, 8, No. 12, 2001, pp. 3–34 Correspondence: Center for Brain and Cognition, University of California, San Diego, 9500 Gilman Dr. 0109, La Jolla, CA 92093-0109, e-mail: vramacha@ucsd.edu",2001.0,128.0,1438.0,False,,"{'volume': '8', 'pages': '3-34', 'name': 'Journal of Consciousness Studies'}","{'bibtex': '@Article{Ramachandran2001SynaesthesiaAW,\n author = {V. Ramachandran and E. Hubbard},\n journal = {Journal of Consciousness Studies},\n pages = {3-34},\n title = {Synaesthesia? A window into perception, thought and language},\n volume = {8},\n year = {2001}\n}\n'}","[{'authorId': '1888069', 'name': 'V. Ramachandran'}, {'authorId': '29991885', 'name': 'E. Hubbard'}]"
460,26d552683397c7ef56f8e7b1db35d3c6fe39a190,A survey: facial micro-expression recognition,,2018.0,68.0,78.0,False,,"{'volume': '77', 'pages': '19301-19325', 'name': 'Multimedia Tools and Applications'}","{'bibtex': '@Article{Takalkar2018ASF,\n author = {M. Takalkar and Min Xu and Qiang Wu and Z. Chaczko},\n journal = {Multimedia Tools and Applications},\n pages = {19301-19325},\n title = {A survey: facial micro-expression recognition},\n volume = {77},\n year = {2018}\n}\n'}","[{'authorId': '29017625', 'name': 'M. Takalkar'}, {'authorId': '145093159', 'name': 'Min Xu'}, {'authorId': '144066903', 'name': 'Qiang Wu'}, {'authorId': '1684306', 'name': 'Z. Chaczko'}]"
461,26d8011bd3acea073ae6d3014f295928a0585f14,Age differences in emotion recognition skills and the visual scanning of emotion faces.,"Research suggests that a person's emotion recognition declines with advancing years. We examined whether or not this age-related decline was attributable to a tendency to overlook emotion information in the eyes. In Experiment 1, younger adults were significantly better than older adults at inferring emotions from full faces and eyes, though not from mouths. Using an eye tracker in Experiment 2, we found young adults, in comparison with older adults, to have superior emotion recognition performance and to look proportionately more to eyes than mouths. However, although better emotion recognition performance was significantly correlated with more eye looking in younger adults, the same was not true in older adults. We discuss these results in terms of brain changes with age.",2007.0,59.0,207.0,True,"{'url': 'https://academic.oup.com/psychsocgerontology/article-pdf/62/1/P53/1534688/P53.pdf', 'status': None}","{'volume': '62 1', 'pages': '\n          P53-60\n        ', 'name': 'The journals of gerontology. Series B, Psychological sciences and social sciences'}","{'bibtex': '@Article{Sullivan2007AgeDI,\n author = {Susan Sullivan and T. Ruffman and S. Hutton},\n journal = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n pages = {\n          P53-60\n        },\n title = {Age differences in emotion recognition skills and the visual scanning of emotion faces.},\n volume = {62 1},\n year = {2007}\n}\n'}","[{'authorId': '116432126', 'name': 'Susan Sullivan'}, {'authorId': '3890791', 'name': 'T. Ruffman'}, {'authorId': '2570066', 'name': 'S. Hutton'}]"
462,27130991e1649398d98a00746bdbd1616ca915ea,Where Do They Look? Gaze Behaviors of Multiple Users Interacting with an Embodied Conversational Agent,,2005.0,18.0,37.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/47272/47272.pdf', 'status': None}",{'pages': '241-252'},"{'bibtex': '@Inproceedings{Rehm2005WhereDT,\n author = {M. Rehm and E. André},\n pages = {241-252},\n title = {Where Do They Look? Gaze Behaviors of Multiple Users Interacting with an Embodied Conversational Agent},\n year = {2005}\n}\n'}","[{'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '1742930', 'name': 'E. André'}]"
463,271af3b3a3d054c7d6eb2da78635710445dcf0db,Autonomous collision avoidance system based on accurate knowledge of the vehicle surroundings,"In this study, a collision avoidance system is presented, based on the information provided by a laser-scanner sensor, in which two actions could be taken in case of danger. Firstly, the system tries to stop the vehicle in order to avoid the accident. If a reduction in speed is not sufficiently effective, the control system takes control of the steering and deviates the vehicle's trajectory in order to escape from the hazardous situation. The control system evaluates the situation and decides the most appropriate action in each case considering free areas on the surroundings using the information of a detailed digital map. This system has been implemented in a vehicle and has been tested with pedestrians and vehicles circulating along the private test track with satisfactory results.",2015.0,31.0,37.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-its.2013.0118', 'status': None}","{'volume': '9', 'pages': '105-117', 'name': 'Iet Intelligent Transport Systems'}","{'bibtex': '@Article{Jiménez2015AutonomousCA,\n author = {F. Jiménez and J. Naranjo and Óscar Gómez},\n journal = {Iet Intelligent Transport Systems},\n pages = {105-117},\n title = {Autonomous collision avoidance system based on accurate knowledge of the vehicle surroundings},\n volume = {9},\n year = {2015}\n}\n'}","[{'authorId': '143787360', 'name': 'F. Jiménez'}, {'authorId': '144721820', 'name': 'J. Naranjo'}, {'authorId': '144763950', 'name': 'Óscar Gómez'}]"
464,27276f51b124dcaf11d382ee9c193dda087eb237,Evaluating the Authoring Complexity of Interactive Narratives with Interactive Behaviour Trees,"This paper evaluates the use of Behavior Trees (BT) for authoring compelling narrative experiences with free-form user interaction. We systematically study extensions to traditionally BT representations, which decouple the monitoring of user input, the narrative, and how the user may influence the story outcome – referred to as Interactive Behavior Trees (IBT’s). By quantitatively evaluating the authoring complexity of BT formalisms with traditional story graph representations, we show that IBT’s better scale with the number of story arcs, and the degree and granularity of user input. Our theoretical estimate of authoring complexity is corroborated with a qualitative user study, which confirms that subjects take lesser time with reduced effort to author narratives using IBT’s. The subjective difficulty of IBT’s is also lower than traditional story graphs.",2015.0,34.0,14.0,False,,,"{'bibtex': '@Inproceedings{Kapadia2015EvaluatingTA,\n author = {M. Kapadia and Marcel Marti and M. Gross},\n title = {Evaluating the Authoring Complexity of Interactive Narratives with Interactive Behaviour Trees},\n year = {2015}\n}\n'}","[{'authorId': '143980997', 'name': 'M. Kapadia'}, {'authorId': '145658471', 'name': 'Marcel Marti'}, {'authorId': '2257153235', 'name': 'M. Gross'}]"
465,2728598e875568640698ee379148daa8c10a406b,"The impact of emotion on perception, attention, memory, and decision-making.","Reason and emotion have long been considered opposing forces. However, recent psychological and neuroscientific research has revealed that emotion and cognition are closely intertwined. Cognitive processing is needed to elicit emotional responses. At the same time, emotional responses modulate and guide cognition to enable adaptive responses to the environment. Emotion determines how we perceive our world, organise our memory, and make important decisions. In this review, we provide an overview of current theorising and research in the Affective Sciences. We describe how psychological theories of emotion conceptualise the interactions of cognitive and emotional processes. We then review recent research investigating how emotion impacts our perception, attention, memory, and decision-making. Drawing on studies with both healthy participants and clinical populations, we illustrate the mechanisms and neural substrates underlying the interactions of cognition and emotion.",2013.0,58.0,224.0,True,"{'url': 'https://smw.ch/resource/jf/journal/file/view/article/smw/en/smw.2013.13786/smw.2013.13786.pdf/', 'status': None}","{'volume': '143', 'pages': '\n          w13786\n        ', 'name': 'Swiss medical weekly'}","{'bibtex': '@Article{Brosch2013TheIO,\n author = {T. Brosch and K. Scherer and D. Grandjean and D. Sander},\n journal = {Swiss medical weekly},\n pages = {\n          w13786\n        },\n title = {The impact of emotion on perception, attention, memory, and decision-making.},\n volume = {143},\n year = {2013}\n}\n'}","[{'authorId': '2256291', 'name': 'T. Brosch'}, {'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '1797080', 'name': 'D. Grandjean'}, {'authorId': '143868107', 'name': 'D. Sander'}]"
466,2729b8906721af630ef346588f3e5b8fa87a12ea,"Review of “Persuasive technology: Using computers to change what we think and do by B. J. Fogg” Morgan Kaufmann, 2003",,2003.0,0.0,397.0,False,,"{'volume': '54', 'pages': '1168-1170', 'name': 'Journal of the Association for Information Science and Technology'}","{'bibtex': '@Article{Petrou2003ReviewO,\n author = {Anastasis D. Petrou},\n journal = {Journal of the Association for Information Science and Technology},\n pages = {1168-1170},\n title = {Review of “Persuasive technology: Using computers to change what we think and do by B. J. Fogg” Morgan Kaufmann, 2003},\n volume = {54},\n year = {2003}\n}\n'}","[{'authorId': '1935867', 'name': 'Anastasis D. Petrou'}]"
467,275d75260c96b0f5cef5118cbdbf5b94c13d2d00,How to Get There When You Are There Already? Defining Presence in Virtual Reality and the Importance of Perceived Realism,,2021.0,88.0,30.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.628298/pdf', 'status': None}","{'volume': '12', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Weber2021HowTG,\n author = {Stefan Weber and D. Weibel and F. Mast},\n journal = {Frontiers in Psychology},\n title = {How to Get There When You Are There Already? Defining Presence in Virtual Reality and the Importance of Perceived Realism},\n volume = {12},\n year = {2021}\n}\n'}","[{'authorId': '152203827', 'name': 'Stefan Weber'}, {'authorId': '145823332', 'name': 'D. Weibel'}, {'authorId': '3253323', 'name': 'F. Mast'}]"
468,279fc4fe94e5914b5570e5eb38f2785f2928d32a,Using reality mining to improve public health and medicine.,"We live our lives in digital networks. We wake up in the morning, check our e-mail, make a quick phone call, commute to work, buy lunch. Many of these transactions leave digital breadcrumbs--tiny records of our daily experiences. Reality mining, which pulls together these crumbs using statistical analysis and machine learning methods, offers an increasingly comprehensive picture of our lives, both individually and collectively, with the potential of transforming our understanding of ourselves, our organizations, and our society in a fashion that was barely conceivable just a few years ago. It is for this reason that reality mining was recently identified by Technology Review as one of ""10 emerging technologies that could change the world"". Many everyday devices provide the raw database upon which reality mining builds; sensors in mobile phones, cars, security cameras, RFID ('smart card') readers, and others, all allow for the measurement of human physical and social activity. Computational models based on such data have the potential to dramatically transform the arenas of both individual and community health. Reality mining can provide new opportunities with respect to diagnosis, patient and treatment monitoring, health services planning, surveillance of disease and risk factors, and public health investigation and disease control. Currently, the single most important source of reality mining data is the ubiquitous mobile phone. Every time a person uses a mobile phone, a few bits of information are left behind. The phone pings the nearest mobile-phone towers, revealing its location. The mobile phone service provider records the duration of the call and the number dialed. In the near future, mobile phones and other technologies will collect even more information about their users, recording everything from their physical activity to their conversational cadences. While such data pose a potential threat to individual privacy, they also offer great potential value both to individuals and communities. With the aid of data-mining algorithms, these data could shed light on individual patterns of behavior and even on the well-being of communities, creating new ways to improve public health and medicine. To illustrate, consider two examples of how reality mining may benefit individual health care. By taking advantage of special sensors in mobile phones, such as the microphone or the accelerometers built into newer devices such as Apple's iPhone, important diagnostic data can be captured. Clinical pilot data demonstrate that it may be possible to diagnose depression from the way a person talks--a depressed person tends to speak more slowly, a change that speech analysis software on a phone might recognize more readily than friends or family do. Similarly, monitoring a phone's motion sensors can also reveal small changes in gait, which could be an early indicator of ailments such as Parkinson's disease. Within the next few years reality mining will become more common, thanks in part to the proliferation and increasing sophistication of mobile phones. Many handheld devices now have the processing power of low-end desktop computers, and they can also collect more varied data, due to components such as GPS chips that track location. The Chief Technology Officer of EMC, a large digital storage company, estimates that this sort of personal sensor data will balloon from 10% of all stored information to 90% within the next decade. While the promise of reality mining is great, the idea of collecting so much personal information naturally raises many questions about privacy. It is crucial that behavior-logging technology not be forced on anyone. But legal statutes are lagging behind data collection capabilities, making it particularly important to begin discussing how the technology will and should be used. Therefore, an additional focus of this chapter will be the development of a legal and ethical framework concerning the data used by reality mining techniques.",2009.0,22.0,87.0,False,,"{'volume': '149', 'pages': '\n          93-102\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Pentland2009UsingRM,\n author = {A. Pentland and D. Lazer and Devon Brewer and T. Heibeck},\n journal = {Studies in health technology and informatics},\n pages = {\n          93-102\n        },\n title = {Using reality mining to improve public health and medicine.},\n volume = {149},\n year = {2009}\n}\n'}","[{'authorId': '1682773', 'name': 'A. Pentland'}, {'authorId': '3185333', 'name': 'D. Lazer'}, {'authorId': '2056661864', 'name': 'Devon Brewer'}, {'authorId': '3204796', 'name': 'T. Heibeck'}]"
469,27b99851aba18216d6a498c6f959d293dda78c88,Towards an Expressive Embodied Conversational Agent Utilizing Multi-Ethnicity to Augment Solution Focused Therapy,"In this article, we present ongoing research, EMO, an affective embodied conversational agent platform, aimed at depicting multi-ethnic, multi-modal communication patterns in a credible manner. We employ the methodology of integrating counseling concepts early in the design to effectively target a specific domain. The system is geared to augment solution focused therapy. We present a prototype of the architecture as proof of concept and evaluate the platform for affect portrayal.",2013.0,26.0,9.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Allison2013TowardsAE,\n author = {Mark Allison and Lynne Kendrick},\n title = {Towards an Expressive Embodied Conversational Agent Utilizing Multi-Ethnicity to Augment Solution Focused Therapy},\n year = {2013}\n}\n'}","[{'authorId': '145743883', 'name': 'Mark Allison'}, {'authorId': '143773676', 'name': 'Lynne Kendrick'}]"
470,27c4fd3a16b1c196c20c6ead6fd2de953970e10e,Interacting with Virtual Agents in Mixed Reality Interactive Storytelling,,2003.0,6.0,38.0,False,,{'pages': '231-235'},"{'bibtex': '@Inproceedings{Cavazza2003InteractingWV,\n author = {M. Cavazza and Olivier Martin and Fred Charles and Steven J. Mead and Xavier Marichal},\n pages = {231-235},\n title = {Interacting with Virtual Agents in Mixed Reality Interactive Storytelling},\n year = {2003}\n}\n'}","[{'authorId': '1696638', 'name': 'M. Cavazza'}, {'authorId': '145640468', 'name': 'Olivier Martin'}, {'authorId': '144553087', 'name': 'Fred Charles'}, {'authorId': '1788038', 'name': 'Steven J. Mead'}, {'authorId': '1806893', 'name': 'Xavier Marichal'}]"
471,27caf712eb6f7eb4525e5c0759c4f989f54e706b,Facial expression of emotion and perception of the Uncanny Valley in virtual characters,,2011.0,52.0,222.0,True,"{'url': 'https://vbn.aau.dk/ws/files/63140615/Facial_expression_of_emotion_and_perception.pdf', 'status': None}","{'volume': '27', 'pages': '741-749', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Tinwell2011FacialEO,\n author = {Angela Tinwell and M. Grimshaw-Aagaard and D. Nabi and Andrew Williams},\n journal = {Comput. Hum. Behav.},\n pages = {741-749},\n title = {Facial expression of emotion and perception of the Uncanny Valley in virtual characters},\n volume = {27},\n year = {2011}\n}\n'}","[{'authorId': '3188061', 'name': 'Angela Tinwell'}, {'authorId': '1778324', 'name': 'M. Grimshaw-Aagaard'}, {'authorId': '2875451', 'name': 'D. Nabi'}, {'authorId': '2110116607', 'name': 'Andrew Williams'}]"
472,28059b5dad91567ae0dde5827485803441e7dbbc,The effect of expression of anger and happiness in computer agents on negotiations with humans,"There is now considerable evidence in social psychology, economics, and related disciplines that emotion plays an important role in negotiation. For example, humans make greater concessions in negotiation to an opposing human who expresses anger, and they make fewer concessions to an opponent who expresses happiness, compared to a no-emotion-expression control. However, in AI, despite the wide interest in negotiation as a means to resolve differences between agents and humans, emotion has been largely ignored. This paper explores whether expression of anger or happiness by computer agents, in a multi-issue negotiation task, can produce effects that resemble effects seen in human-human negotiation. The paper presents an experiment where participants play with agents that express emotions (anger vs. happiness vs. control) through different modalities (text vs. facial displays). An important distinction in our experiment is that participants are aware that they negotiate with computer agents. The data indicate that the emotion effects observed in past work with humans also occur in agent-human negotiation, and occur independently of modality of expression. The implications of these results are discussed for the fields of automated negotiation, intelligent virtual agents and artificial intelligence.",2011.0,77.0,125.0,False,,{'pages': '937-944'},"{'bibtex': '@Inproceedings{Melo2011TheEO,\n author = {C. D. Melo and P. Carnevale and J. Gratch},\n pages = {937-944},\n title = {The effect of expression of anger and happiness in computer agents on negotiations with humans},\n year = {2011}\n}\n'}","[{'authorId': '1977901', 'name': 'C. D. Melo'}, {'authorId': '48755211', 'name': 'P. Carnevale'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
473,280c65b4d1b448a3e8456076e0b1e3df70624d4b,Agent vision in multi-agent based simulation systems,,2015.0,39.0,19.0,False,,"{'volume': '29', 'pages': '161-191', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Kuiper2015AgentVI,\n author = {Dane Kuiper and Rym Zalila-Wenkstern},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {161-191},\n title = {Agent vision in multi-agent based simulation systems},\n volume = {29},\n year = {2015}\n}\n'}","[{'authorId': '2216252', 'name': 'Dane Kuiper'}, {'authorId': '1397963104', 'name': 'Rym Zalila-Wenkstern'}]"
474,2823a1acbb4ca3fbb74608f6879dd2047fb5af6b,Commentary: Attention to Eyes Is Present but in Decline in 2–6-Month-Old Infants Later Diagnosed with Autism,"A recent Nature article provided preliminary evidence that infants age 2–6 months old, who were later diagnosed with Autism Spectrum Disorder (ASD), fixated more on the mouth than eyes and more at objects than people when viewing videos of typical childhood social scenes (1). While the sample was small, a reliable pattern of decline in eye fixation accurately predicted their level and classification of symptoms at age three suggesting that – for the first time – an infant could be assessed within the first 6 months of life for their potential of developing ASD (see Table ​Table11 for studies that used eye-tracking with infants 12 months and younger). These eye-tracking devices, which are currently in clinical trials, could provide access to an affordable and objective tool with the potential for extremely early intervention. Detecting ASD risk during the first 6 months of life presents unprecedented opportunities to intervene, providing children opportunities to build critical skills before autistic characteristics fully emerge. Because the eye-tracking device allows for a non-invasive, portable assessment, the device could also enable pediatricians to provide comparable screening services globally. With such promise, a near future where infants are placed into an eye-tracking device at routine pediatric visits is compelling, if not guaranteed.",2015.0,40.0,440.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpubh.2015.00272/pdf', 'status': None}","{'volume': '3', 'name': 'Frontiers in Public Health'}","{'bibtex': '@Article{Sarrett2015CommentaryAT,\n author = {Jennifer C. Sarrett and K. Rommelfanger},\n journal = {Frontiers in Public Health},\n title = {Commentary: Attention to Eyes Is Present but in Decline in 2–6-Month-Old Infants Later Diagnosed with Autism},\n volume = {3},\n year = {2015}\n}\n'}","[{'authorId': '4606462', 'name': 'Jennifer C. Sarrett'}, {'authorId': '4833221', 'name': 'K. Rommelfanger'}]"
475,282ba3822f8032614ab269b0b5c66b10ac4cc02e,Modelling basic needs as agent motivations,"Any autonomous agent behaviour generation mechanism should incorporate as a core module, a source of internal motivation that functions as a start point for agent behaviour to commence. Intelligent virtual agents are typically respondent to external stimuli, however, their behaviour becomes repetitive and trivial when these stimuli are missing. We argue that it is necessary for virtual agents to be equipped with intrinsic motivations that energise and direct their behaviour, in order to function in a coherent and believable way. Adopting the general principles of hierarchical motivation theories, in the current work, we attempt to model physiological needs as the lowest and basic level of motivations, in a layered motivational architecture. Based on readings from physiology, we present the mechanisms underlying the function of four basic needs and propose a model that allows the incorporation of plausible human-like needs in an intelligent virtual agent.",2013.0,46.0,1.0,False,,"{'volume': '2', 'pages': '52-75', 'name': 'Int. J. Comput. Intell. Stud.'}","{'bibtex': '@Article{Avradinis2013ModellingBN,\n author = {N. Avradinis and T. Panayiotopoulos and George Anastassakis},\n journal = {Int. J. Comput. Intell. Stud.},\n pages = {52-75},\n title = {Modelling basic needs as agent motivations},\n volume = {2},\n year = {2013}\n}\n'}","[{'authorId': '1943153', 'name': 'N. Avradinis'}, {'authorId': '1743830', 'name': 'T. Panayiotopoulos'}, {'authorId': '2619408', 'name': 'George Anastassakis'}]"
476,2834ba2bff4769a7298b8bb9d4de63d71c806d88,3D MODELLING AND VISUALIZATION BASED ON THE UNITY GAME ENGINE – ADVANTAGES AND CHALLENGES,"Abstract. 3D City modelling is increasingly popular and becoming valuable tools in managing big cities. Urban and energy planning, landscape, noise-sewage modelling, underground mapping and navigation are among the applications/fields which really depend on 3D modelling for their effectiveness operations. Several research areas and implementation projects had been carried out to provide the most reliable 3D data format for sharing and functionalities as well as visualization platform and analysis. For instance, BIMTAS company has recently completed a project to estimate potential solar energy on 3D buildings for the whole Istanbul and now focussing on 3D utility underground mapping for a pilot case study. The research and implementation standard on 3D City Model domain (3D data sharing and visualization schema) is based on CityGML schema version 2.0. However, there are some limitations and issues in implementation phase for large dataset. Most of the limitations were due to the visualization, database integration and analysis platform (Unity3D game engine) as highlighted in this paper.",2017.0,16.0,41.0,True,"{'url': 'https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-4-W4/161/2017/isprs-annals-IV-4-W4-161-2017.pdf', 'status': None}","{'volume': '4', 'pages': '161-166', 'name': 'ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences'}","{'bibtex': '@Article{Buyuksalih20173DMA,\n author = {I. Buyuksalih and S. Bayburt and G. Buyuksalih and A. Baskaraca and H. Karim and Alias Abdul Rahman and Bogazici Insaat Musavirlik and Eski Tuyap Binasi and S. Bayburt and G. Buyuksalih and A. Baskaraca},\n journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},\n pages = {161-166},\n title = {3D MODELLING AND VISUALIZATION BASED ON THE UNITY GAME ENGINE – ADVANTAGES AND CHALLENGES},\n volume = {4},\n year = {2017}\n}\n'}","[{'authorId': '73554914', 'name': 'I. Buyuksalih'}, {'authorId': '71753619', 'name': 'S. Bayburt'}, {'authorId': '31216519', 'name': 'G. Buyuksalih'}, {'authorId': '72068044', 'name': 'A. Baskaraca'}, {'authorId': '115258148', 'name': 'H. Karim'}, {'authorId': '2148758968', 'name': 'Alias Abdul Rahman'}, {'authorId': '2265527431', 'name': 'Bogazici Insaat Musavirlik'}, {'authorId': '2265526493', 'name': 'Eski Tuyap Binasi'}, {'authorId': '71753619', 'name': 'S. Bayburt'}, {'authorId': '31216519', 'name': 'G. Buyuksalih'}, {'authorId': '72068044', 'name': 'A. Baskaraca'}]"
477,2835fb7ffe5c6d5fad7b22a6e8eb553f20072b9a,TARDIS-A simulation platform with an affective virtual recruiter for job interviews,"The number of young people not in employment, education or training is increasing across Europe. These youngsters often lack self-confidence and the essential social skills needed to seek and secure employment. The TARDIS project aims to build a scenario-based serious-game simulation platform for young people at risk of exclusion to improve their social skills. This paper intends to propose a model for a socio-emotionally realistic virtual agent in the context of job interview simulations. Our model of affect is composed of emotions, moods, social attitudes and personality that intends to create a realistic virtual recruiter.",2013.0,33.0,20.0,False,,,"{'bibtex': '@Inproceedings{Lip2013TARDISASP,\n author = {Hazaël Jones Lip},\n title = {TARDIS-A simulation platform with an affective virtual recruiter for job interviews},\n year = {2013}\n}\n'}","[{'authorId': '2075858060', 'name': 'Hazaël Jones Lip'}]"
478,28738fd2b43d1463714dda4ff9face9988d37596,Virtual Reality in Mine Training,,,0.0,30.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Misc{None,\n author = {L. Mallett and R. Unger},\n title = {Virtual Reality in Mine Training}\n}\n'}","[{'authorId': '50725217', 'name': 'L. Mallett'}, {'authorId': '152978807', 'name': 'R. Unger'}]"
480,287dae5b1fc7a9ea70597ce393841d86a5916285,Chatbot for Healthcare System Using Artificial Intelligence,"The Chatbots are the computer programs that interact with the users using natural language. The chatbot stores the information in the database to identify the keywords from the sentences and make a decision for the query and answers the question. In this paper keyword, ranking and sentence similarity calculation is done using n-gram, TF-IDF and cosine similarity. From the given input sentence, the score will be obtained for each sentence and more similar sentences are obtained for the given query. The query posed to the bot which isn't comprehended or not present in the database is further processed by the third party, expert system.",2019.0,10.0,49.0,True,"{'url': 'https://doi.org/10.56726/irjmets34164', 'status': None}",{'name': 'International Research Journal of Modernization in Engineering Technology and Science'},"{'bibtex': '@Article{Kavitha2019ChatbotFH,\n author = {B. Kavitha and C. R. Murthy},\n journal = {International Research Journal of Modernization in Engineering Technology and Science},\n title = {Chatbot for Healthcare System Using Artificial Intelligence},\n year = {2019}\n}\n'}","[{'authorId': '144158655', 'name': 'B. Kavitha'}, {'authorId': '145379162', 'name': 'C. R. Murthy'}]"
481,288669f364c6108825b995579384ef10d99e6238,Immersive virtual training for substation electricians,"This research demonstration presents an Immersive Virtual Substation for Electricians Training. A substation is one of the most critical facilities of the electrical distribution system, so it is mandatory to keep its normal operation to deliver high standards of service, power quality and avoid blackouts to consumers. Therefore, it is necessary to give an effective training to the electricians who will operate the equipment in the substation and to prepare them to face emergencies on daily basis. The main purpose of the proposed Immersive Virtual Environment is to provide a realistic experience to trainees in a safe environment where they can interact with equipment, explore the facility and, mainly, practice basic and complex maneuvers to recover substation operations. Users can interact with this Immersive Virtual Environment using HMDs, joysticks or even an ordinary keyboard, mouse and monitor. Feedback from trainees and instructors who used the Immersive Virtual Environment was very positive, indicating that the objectives were fully achieved.",2017.0,5.0,12.0,False,,"{'pages': '451-452', 'name': '2017 IEEE Virtual Reality (VR)'}","{'bibtex': '@Article{Tanaka2017ImmersiveVT,\n author = {E. Tanaka and Juliana A. Paludo and R. Bacchetti and E. Gadbem and Leonardo R. Domingues and Carlúcio S. Cordeiro and Olavo Giraldi and Guilherme Alcarde Gallo and Adam Mendes da Silva and Marcos H. Cascone},\n journal = {2017 IEEE Virtual Reality (VR)},\n pages = {451-452},\n title = {Immersive virtual training for substation electricians},\n year = {2017}\n}\n'}","[{'authorId': '2075673', 'name': 'E. Tanaka'}, {'authorId': '2789743', 'name': 'Juliana A. Paludo'}, {'authorId': '3426644', 'name': 'R. Bacchetti'}, {'authorId': '3002681', 'name': 'E. Gadbem'}, {'authorId': '144753453', 'name': 'Leonardo R. Domingues'}, {'authorId': '3210085', 'name': 'Carlúcio S. Cordeiro'}, {'authorId': '51171242', 'name': 'Olavo Giraldi'}, {'authorId': '15516416', 'name': 'Guilherme Alcarde Gallo'}, {'authorId': '2109977907', 'name': 'Adam Mendes da Silva'}, {'authorId': '10131774', 'name': 'Marcos H. Cascone'}]"
482,288d7952b6648749fcbdcedabedf8f43cf7fda52,"Is it an Agent, or Just a Program?: A Taxonomy for Autonomous Agents",,1996.0,27.0,2840.0,False,,{'pages': '21-35'},"{'bibtex': '@Inproceedings{Franklin1996IsIA,\n author = {S. Franklin and A. Graesser},\n pages = {21-35},\n title = {Is it an Agent, or Just a Program?: A Taxonomy for Autonomous Agents},\n year = {1996}\n}\n'}","[{'authorId': '145796793', 'name': 'S. Franklin'}, {'authorId': '1769251', 'name': 'A. Graesser'}]"
483,288fcf20f4057c6eb7f244d1ea31879cc7767a8c,An intelligent tutoring system that generates a natural language dialogue using dynamic multi-level planning,,2006.0,102.0,55.0,False,,"{'volume': '38 1', 'pages': '\n          25-46\n        ', 'name': 'Artificial intelligence in medicine'}","{'bibtex': '@Article{Woo2006AnIT,\n author = {Chong-woo Woo and M. Evens and Reva Freedman and Michael Glass and L. Shim and Yuemei Zhang and Yujian Zhou and J. Michael},\n journal = {Artificial intelligence in medicine},\n pages = {\n          25-46\n        },\n title = {An intelligent tutoring system that generates a natural language dialogue using dynamic multi-level planning},\n volume = {38 1},\n year = {2006}\n}\n'}","[{'authorId': '1944058', 'name': 'Chong-woo Woo'}, {'authorId': '2186744', 'name': 'M. Evens'}, {'authorId': '21285711', 'name': 'Reva Freedman'}, {'authorId': '143742138', 'name': 'Michael Glass'}, {'authorId': '3121624', 'name': 'L. Shim'}, {'authorId': '2145914494', 'name': 'Yuemei Zhang'}, {'authorId': '11362180', 'name': 'Yujian Zhou'}, {'authorId': '144125007', 'name': 'J. Michael'}]"
484,28c340988929b61e2b2ccd403b5b00256e1ed0e1,"Data Analysis: A Model Comparison Approach To Regression, ANOVA, and Beyond, Third Edition",,2017.0,0.0,122.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Judd2017DataAA,\n author = {C. Judd and G. McClelland and C. Ryan},\n title = {Data Analysis: A Model Comparison Approach To Regression, ANOVA, and Beyond, Third Edition},\n year = {2017}\n}\n'}","[{'authorId': '5672179', 'name': 'C. Judd'}, {'authorId': '144822864', 'name': 'G. McClelland'}, {'authorId': '31642890', 'name': 'C. Ryan'}]"
485,290890ccb5465fb31fe7111fb80e69fb2e4a2361,"Evidence of a Relation Between Hippocampal Volume, White Matter Hyperintensities, and Cognition in Subjective Cognitive Decline and Mild Cognitive Impairment","Abstract Objective The concepts of mild cognitive impairment (MCI) and subjective cognitive decline (SCD) have been proposed to identify individuals in the early stages of Alzheimer’s disease (AD), or other neurodegenerative diseases. One approach to validate these concepts is to investigate the relationship between pathological brain markers and cognition in those individuals. Method We included 126 participants from the Consortium for the Early Identification of Alzheimer’s disease-Quebec (CIMA-Q) cohort (67 SCD, 29 MCI, and 30 cognitively healthy controls [CH]). All participants underwent a complete cognitive assessment and structural magnetic resonance imaging. Group comparisons were done using cognitive data, and then correlated with hippocampal volumes and white matter hyperintensities (WMHs). Results Significant differences were found between participants with MCI and CH on episodic and executive tasks, but no differences were found when comparing SCD and CH. Scores on episodic memory tests correlated with hippocampal volumes in both MCI and SCD, whereas performance on executive tests correlated with WMH in all of our groups. Discussion As expected, the SCD group was shown to be cognitively healthy on tasks where MCI participants showed impairment. However, SCD’s hippocampal volume related to episodic memory performances, and WMH to executive functions. Thus, SCD represents a valid research concept and should be used, alongside MCI, to better understand the preclinical/prodromal phase of AD.",2019.0,74.0,34.0,True,"{'url': 'https://academic.oup.com/psychsocgerontology/article-pdf/75/7/1382/33646281/gbz120.pdf', 'status': None}","{'volume': '75', 'pages': '1382 - 1392', 'name': 'The Journals of Gerontology Series B: Psychological Sciences and Social Sciences'}","{'bibtex': '@Article{Caillaud2019EvidenceOA,\n author = {Marie Caillaud and C. Hudon and Benjamin Boller and S. Brambati and S. Duchesne and D. Lorrain and J. Gagnon and Samantha Maltezos and S. Mellah and N. Phillips and S. Belleville},\n journal = {The Journals of Gerontology Series B: Psychological Sciences and Social Sciences},\n pages = {1382 - 1392},\n title = {Evidence of a Relation Between Hippocampal Volume, White Matter Hyperintensities, and Cognition in Subjective Cognitive Decline and Mild Cognitive Impairment},\n volume = {75},\n year = {2019}\n}\n'}","[{'authorId': '6730429', 'name': 'Marie Caillaud'}, {'authorId': '9164412', 'name': 'C. Hudon'}, {'authorId': '40589979', 'name': 'Benjamin Boller'}, {'authorId': '145348826', 'name': 'S. Brambati'}, {'authorId': '2873793', 'name': 'S. Duchesne'}, {'authorId': '35117286', 'name': 'D. Lorrain'}, {'authorId': '113135777', 'name': 'J. Gagnon'}, {'authorId': '2258422767', 'name': 'Samantha Maltezos'}, {'authorId': '2550138', 'name': 'S. Mellah'}, {'authorId': '2227151', 'name': 'N. Phillips'}, {'authorId': '145580293', 'name': 'S. Belleville'}]"
486,293a0c383a42550d640b6af141c5c10822900606,The social signal interpretation (SSI) framework: multimodal signal processing and recognition in real-time,"Automatic detection and interpretation of social signals carried by voice, gestures, mimics, etc. will play a key-role for next-generation interfaces as it paves the way towards a more intuitive and natural human-computer interaction. The paper at hand introduces Social Signal Interpretation (SSI), a framework for real-time recognition of social signals. SSI supports a large range of sensor devices, filter and feature algorithms, as well as, machine learning and pattern recognition tools. It encourages developers to add new components using SSI's C++ API, but also addresses front end users by offering an XML interface to build pipelines with a text editor. SSI is freely available under GPL at http://openssi.net.",2013.0,16.0,182.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/50530/50530.pdf', 'status': None}",{'name': 'Proceedings of the 21st ACM international conference on Multimedia'},"{'bibtex': '@Article{Wagner2013TheSS,\n author = {J. Wagner and Florian Lingenfelser and Tobias Baur and Ionut Damian and Felix Kistler and E. André},\n journal = {Proceedings of the 21st ACM international conference on Multimedia},\n title = {The social signal interpretation (SSI) framework: multimodal signal processing and recognition in real-time},\n year = {2013}\n}\n'}","[{'authorId': '6164138', 'name': 'J. Wagner'}, {'authorId': '2565410', 'name': 'Florian Lingenfelser'}, {'authorId': '2230836', 'name': 'Tobias Baur'}, {'authorId': '3048626', 'name': 'Ionut Damian'}, {'authorId': '2844803', 'name': 'Felix Kistler'}, {'authorId': '1742930', 'name': 'E. André'}]"
487,293fc9674b2404a1ae9b0f16778610c7849ea2b8,Benchmarks for evaluating socially assistive robotics,"Socially assistive robotics (SAR) is a growing area of research. Evaluating SAR systems presents novel challenges. Using a robot for a socially assistive task can have various benefits and ethical implications. Many questions are important to understanding whether a robot is effective for a given application domain. This paper describes several benchmarks for evaluating SAR systems. There exist numerous methods for evaluating the many factors involved in a robot’s design. Benchmarks from psychology, anthropology, medicine, and human–robot interaction are proposed as measures of success in evaluating a given SAR system and its impact on the user and broader population.",2007.0,52.0,132.0,True,"{'url': 'http://cres.usc.edu/pubdb_html/files_upload/537.pdf', 'status': None}","{'volume': '8', 'pages': '423-439', 'name': ''}","{'bibtex': '@Inproceedings{Feil-Seifer2007BenchmarksFE,\n author = {David Feil-Seifer and K. Skinner and M. Matarić},\n pages = {423-439},\n title = {Benchmarks for evaluating socially assistive robotics},\n volume = {8},\n year = {2007}\n}\n'}","[{'authorId': '1390033049', 'name': 'David Feil-Seifer'}, {'authorId': '49205966', 'name': 'K. Skinner'}, {'authorId': '1742183', 'name': 'M. Matarić'}]"
488,2953f89f0fd2b59262c8f8373b9d077fd9787f63,Coordinated movement and rapport in teacher-student interactions,,1988.0,23.0,521.0,False,,"{'volume': '12', 'pages': '120-138', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Bernieri1988CoordinatedMA,\n author = {Frank J. Bernieri},\n journal = {Journal of Nonverbal Behavior},\n pages = {120-138},\n title = {Coordinated movement and rapport in teacher-student interactions},\n volume = {12},\n year = {1988}\n}\n'}","[{'authorId': '2493710', 'name': 'Frank J. Bernieri'}]"
489,297d4613e9f65cf1ae74c02b7061b2dcdc4bfc66,Empathic Pedagogy: Community of Inquiry and the Development of Empathy,"Many Philosophy for Children advocates argue that the practice of communal philosophical dialogue develops students’ judgment making skills and facilitates the growth of reasonable subjects (Pritchard, 1996; Lipman & Sharp 1978; Lipman, 1991; Sprod, 2001, Sharp and Splitter, 1995). While these are appropriate avenues for exploring the moral education potential of the program, the literature can be further enriched by examining how Community of Inquiry supports the development of empathy. Previously I argued that any empathic pedagogy must provide students with a means of engaging across the boundaries of the subject in an intersubjective gestalt—i.e. it must allow for peer mediated inquiry-based interactions that support the sharing of affective states (Schertz, 2004). Given this conceptualization of empathic pedagogy, in this piece I will claim that Community of Inquiry is a crucial and paradigmatic means for promoting the further development of empathy. In order to reinforce the developmental soundness of the methodology, I will discuss it in light of Martin Hoffman’s (2000) empathic modes, which are distinct processes that promote the growth of what Hoffman calls the “mature empathizer” (pg. 63). Community of Inquiry enables students to conjointly explore philosophical concepts, personal anecdotes, and stories through a discursive structure that allows for and encourages the facilitation of these empathic modes through a dynamic system of interlocking subjectivities. The methodology enables students to direct their chosen discourse and promotes an intersubjective gestalt, allowing children to engage each other in affective communication in a discursive context that is also cognitive and metacognitive. Before I go on to examine Community of Inquiry in light of Hoffman’s theory, I want to briefly touch upon my reconceptualization of the phenomenon of empathy and then discuss the important role which dialogue plays in the development of the empathic subject. Previously I (Schertz, 2004) defined empathy as the mediation of emotional information between two body-consciousnesses that involves systemic communicative processes operating between subjects which are, by definition and structure, relational. In other words, empathy can be seen as a form of communication by which human beings interact in an intersubjective gestalt. An empathic episode can involve a variety of processes, from mimicry to role taking, depending on the interpersonal context and the developmental capabilities of the subjects. Research regarding the development of empathy indicates that the tenor of formative communicative experiences can have profound effects on a child’s nascent empathic abilities (Damon, 1998; Hoffman, 2000; Verducci, 1999). Effective development is largely dependent upon modeling by the parent, dialogically-based inductive interactions, and non-authoritarian and/or nonabusive adult behaviors. Similarly, the disciplinary practices used within the classroom, the child’s access to peer-mediated relations, and the chosen pedagogical style of the teacher can later impact the child’s ability to engage in systemic communicative processes (Schertz, 2004). In order to provide access to the intersubjective experience, Verducci (1999) discusses the importance of giving “programmatic attention” to role-taking activities, having students “practice imagining/perceiving another’s perspective” and providing students with “exposure to emotionally laden stimuli....These practices correlate with increases in empathy” (pg. 185). In terms of specific curricular activities and pedagogical techniques, “cooperative learning and cross-age and peer tutoring correlate with increases in empathy” (pg. 185). Verducci alleges that “attention to building communities is also important when considering cultivating empathy....This encompasses problem-solving through class meetings and expanding student participation in decision making” (pp. 186-187). Her adherence to engaged perspective taking, democratic community building, and cooperative",2006.0,19.0,16.0,False,,"{'volume': '26', 'name': 'Analytic Teaching'}","{'bibtex': '@Article{Schertz2006EmpathicPC,\n author = {M. Schertz},\n journal = {Analytic Teaching},\n title = {Empathic Pedagogy: Community of Inquiry and the Development of Empathy},\n volume = {26},\n year = {2006}\n}\n'}","[{'authorId': '49345111', 'name': 'M. Schertz'}]"
490,2988a73a148bba0420e983604bed7ef38a86bbbd,Improving Learning in Virtual Learning Environments Using Affective Pedagogical Agent,"Emotions are part of human life, and they are present on several occasions, like decision making and in social interactions. Computational identification of emotions in texts can be useful in many applications, especially in distance learning courses. This research introduces an animated pedagogic agent, integrated to a Moodle virtual learning environment, with the objective of assisting the tutor in accompanying students, helping the students to acquire knowledge, identifying their emotions, and motivating the student to participate in activities and discussions. As a way of assessing students' emotional state, an experiment was conducted using real data from a completed course, involving students. The results obtained are promising, evidencing the importance of knowing the emotional state of the students, contributing to the learning process.",2020.0,18.0,3.0,False,,"{'name': 'Int. J. Distance Educ. Technol.', 'pages': '1-16', 'volume': '18'}","{'bibtex': '@Article{Alencar2020ImprovingLI,\n author = {Márcio Alencar and J. F. Netto},\n booktitle = {International Journal of Distance Education Technologies},\n journal = {Int. J. Distance Educ. Technol.},\n pages = {1-16},\n title = {Improving Learning in Virtual Learning Environments Using Affective Pedagogical Agent},\n volume = {18},\n year = {2020}\n}\n'}","[{'authorId': '2062047342', 'name': 'Márcio Alencar'}, {'authorId': '2069106912', 'name': 'J. F. Netto'}]"
491,299b18527711595652a8775d7450a5bc16222502,A Multi-agent Model for Emotion Contagion Spirals Integrated within a Supporting Ambient Agent Model,,2009.0,25.0,77.0,True,"{'url': 'http://www.cs.vu.nl/~wai/Papers/PRIMA09emotioncontagionspirals.pdf', 'status': None}",{'pages': '48-67'},"{'bibtex': '@Inproceedings{Bosse2009AMM,\n author = {T. Bosse and R. Duell and Z. A. Memon and Jan Treur and C. N. V. D. Wal},\n pages = {48-67},\n title = {A Multi-agent Model for Emotion Contagion Spirals Integrated within a Supporting Ambient Agent Model},\n year = {2009}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '2790338', 'name': 'R. Duell'}, {'authorId': '2468373', 'name': 'Z. A. Memon'}, {'authorId': '1726343', 'name': 'Jan Treur'}, {'authorId': '1881843', 'name': 'C. N. V. D. Wal'}]"
493,29c727a94a99f756a96425fa7d523fd0f06cb660,Increasing self-esteem: Efficacy of a group intervention for individuals with severe mental disorders,,2009.0,35.0,70.0,False,,"{'volume': '24', 'pages': '307 - 316', 'name': 'European Psychiatry'}","{'bibtex': '@Article{Borras2009IncreasingSE,\n author = {L. Borras and Maria Grazia Boucherie and S. Mohr and T. Lecomte and N. Perroud and P. Huguelet},\n journal = {European Psychiatry},\n pages = {307 - 316},\n title = {Increasing self-esteem: Efficacy of a group intervention for individuals with severe mental disorders},\n volume = {24},\n year = {2009}\n}\n'}","[{'authorId': '3044281', 'name': 'L. Borras'}, {'authorId': '2230297111', 'name': 'Maria Grazia Boucherie'}, {'authorId': '6255686', 'name': 'S. Mohr'}, {'authorId': '2063789', 'name': 'T. Lecomte'}, {'authorId': '50779673', 'name': 'N. Perroud'}, {'authorId': '3977566', 'name': 'P. Huguelet'}]"
494,29ddc1f43f28af7c846515e32cc167bc66886d0c,Parameter-Efficient Transfer Learning for NLP,"Fine-tuning large pre-trained models is an effective transfer mechanism in NLP. However, in the presence of many downstream tasks, fine-tuning is parameter inefficient: an entire new model is required for every task. As an alternative, we propose transfer with adapter modules. Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task, and new tasks can be added without revisiting previous ones. The parameters of the original network remain fixed, yielding a high degree of parameter sharing. To demonstrate adapter's effectiveness, we transfer the recently proposed BERT Transformer model to 26 diverse text classification tasks, including the GLUE benchmark. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task. On GLUE, we attain within 0.4% of the performance of full fine-tuning, adding only 3.6% parameters per task. By contrast, fine-tuning trains 100% of the parameters per task.",2019.0,56.0,1866.0,False,,"{'volume': 'abs/1902.00751', 'name': 'ArXiv'}","{'bibtex': '@Article{Houlsby2019ParameterEfficientTL,\n author = {N. Houlsby and A. Giurgiu and Stanislaw Jastrzebski and Bruna Morrone and Quentin de Laroussilhe and Andrea Gesmundo and Mona Attariyan and S. Gelly},\n journal = {ArXiv},\n title = {Parameter-Efficient Transfer Learning for NLP},\n volume = {abs/1902.00751},\n year = {2019}\n}\n'}","[{'authorId': '2815290', 'name': 'N. Houlsby'}, {'authorId': '1911881', 'name': 'A. Giurgiu'}, {'authorId': '40569328', 'name': 'Stanislaw Jastrzebski'}, {'authorId': '68973833', 'name': 'Bruna Morrone'}, {'authorId': '51985388', 'name': 'Quentin de Laroussilhe'}, {'authorId': '2813347', 'name': 'Andrea Gesmundo'}, {'authorId': '2809991', 'name': 'Mona Attariyan'}, {'authorId': '1802148', 'name': 'S. Gelly'}]"
495,29e1a5ad5235d3500cd88cf174faa0edaa8722a5,The Effect of Virtual Agents' Emotion Displays and Appraisals on People's Decision Making in Negotiation,,2012.0,31.0,38.0,False,,{'pages': '53-66'},"{'bibtex': ""@Inproceedings{Melo2012TheEO,\n author = {C. D. Melo and P. Carnevale and J. Gratch},\n pages = {53-66},\n title = {The Effect of Virtual Agents' Emotion Displays and Appraisals on People's Decision Making in Negotiation},\n year = {2012}\n}\n""}","[{'authorId': '1977901', 'name': 'C. D. Melo'}, {'authorId': '48755211', 'name': 'P. Carnevale'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
496,2a13335bba46abe15afbf9d08b9caf72be90db30,"The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology","The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion. We propose that basic emotion theories no longer explain adequately the vast number of empirical observations from studies in affective neuroscience, and we suggest that a conceptual shift is needed in the empirical approaches taken to the study of emotion and affective psychopathologies. The circumplex model of affect is more consistent with many recent findings from behavioral, cognitive neuroscience, neuroimaging, and developmental studies of affect. Moreover, the model offers new theoretical and empirical approaches to studying the development of affective disorders as well as the genetic and cognitive underpinnings of affective processing within the central nervous system.This work was supported in part by NIMH Grants MH01232, MH59139, MH36197, MHK02-74677, and MH068318; a grant from the National Alliance for Research in Schizophrenia and Affective Disorders (NARSAD); NSF Grant BSC-0421702; and funding from the Thomas D. Klingenstein and Nancy D. Perlman Family Fund and the Suzanne Crosby Murphy Endowment at Columbia University.",2005.0,150.0,1952.0,True,"{'url': 'https://europepmc.org/articles/pmc2367156?pdf=render', 'status': None}","{'volume': '17', 'pages': '715 - 734', 'name': 'Development and Psychopathology'}","{'bibtex': '@Article{Posner2005TheCM,\n author = {J. Posner and J. Russell and B. Peterson},\n journal = {Development and Psychopathology},\n pages = {715 - 734},\n title = {The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology},\n volume = {17},\n year = {2005}\n}\n'}","[{'authorId': '49585246', 'name': 'J. Posner'}, {'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '3286633', 'name': 'B. Peterson'}]"
499,2a1d0640a3e92879b2b68bf0ca25ee19374c422f,“How was Your Stay?”: Exploring the Use of Robots for Gathering Customer Feedback in the Hospitality Industry,"This paper presents four exploratory studies of the potential use of robots for gathering customer feedback in the hospitality industry. To account for the viewpoints of both hotels and guests, we administered need finding interviews at five hotels and an online survey concerning hotel guest experiences with 60 participants. We then conducted the two deployment studies based on deploying software prototypes for Savioke Relay robots we designed to collect customer feedback: (i) a hotel deployment study (three hotels over three months) to explore the feasibility of robot use for gathering customer feedback as well as issues such deployment might pose and (ii) a hotel kitchen deployment study (at Savioke headquarters over three weeks) to explore the role of different robot behaviors (mobility and social attributes) in gathering feedback and understand the customers' thought process in the context that they experience a service. We found that hotels want to collect customer feedback in real-time to disseminate positive feedback immediately and to respond to unhappy customers while they are still on-site. Guests want to inform the hotel staff about their experiences without compromising their convenience and privacy. We also found that the robot users, e.g. hotel staff, use their domain knowledge to increase the response rate to customer feedback surveys at the hotels. Finally, environmental factors, such as robot's location in the building influenced customer response rates more than altering the behaviors of the robot collecting the feedback.",2018.0,30.0,21.0,False,,"{'pages': '947-954', 'name': '2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)'}","{'bibtex': '@Article{Chung2018HowWY,\n author = {M. Chung and M. Cakmak},\n journal = {2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {947-954},\n title = {“How was Your Stay?”: Exploring the Use of Robots for Gathering Customer Feedback in the Hospitality Industry},\n year = {2018}\n}\n'}","[{'authorId': '2677547', 'name': 'M. Chung'}, {'authorId': '35096370', 'name': 'M. Cakmak'}]"
500,2a1f8cc1c02897b0aaffb5c410c1a38c404771c6,Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism.,"BACKGROUND
Manifestations of core social deficits in autism are more pronounced in everyday settings than in explicit experimental tasks. To bring experimental measures in line with clinical observation, we report a novel method of quantifying atypical strategies of social monitoring in a setting that simulates the demands of daily experience. Enhanced ecological validity was intended to maximize between-group effect sizes and assess the predictive utility of experimental variables relative to outcome measures of social competence.


METHODS
While viewing social scenes, eye-tracking technology measured visual fixations in 15 cognitively able males with autism and 15 age-, sex-, and verbal IQ-matched control subjects. We reliably coded fixations on 4 regions: mouth, eyes, body, and objects. Statistical analyses compared fixation time on regions of interest between groups and correlation of fixation time with outcome measures of social competence (ie, standardized measures of daily social adjustment and degree of autistic social symptoms).


RESULTS
Significant between-group differences were obtained for all 4 regions. The best predictor of autism was reduced eye region fixation time. Fixation on mouths and objects was significantly correlated with social functioning: increased focus on mouths predicted improved social adjustment and less autistic social impairment, whereas more time on objects predicted the opposite relationship.


CONCLUSIONS
When viewing naturalistic social situations, individuals with autism demonstrate abnormal patterns of social visual pursuit consistent with reduced salience of eyes and increased salience of mouths, bodies, and objects. Fixation times on mouths and objects but not on eyes are strong predictors of degree of social competence.",2002.0,56.0,2001.0,True,"{'url': 'https://jamanetwork.com/journals/jamapsychiatry/articlepdf/206705/YOA10221.pdf', 'status': None}","{'volume': '59 9', 'pages': '\n          809-16\n        ', 'name': 'Archives of general psychiatry'}","{'bibtex': '@Article{Klin2002VisualFP,\n author = {A. Klin and W. Jones and R. Schultz and F. Volkmar and D. Cohen},\n journal = {Archives of general psychiatry},\n pages = {\n          809-16\n        },\n title = {Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism.},\n volume = {59 9},\n year = {2002}\n}\n'}","[{'authorId': '6261339', 'name': 'A. Klin'}, {'authorId': '8137420', 'name': 'W. Jones'}, {'authorId': '145157155', 'name': 'R. Schultz'}, {'authorId': '2155644', 'name': 'F. Volkmar'}, {'authorId': '48858469', 'name': 'D. Cohen'}]"
501,2a30e2fdab5a5ebff580a7935687490af6a2ef93,EEG-based emotion recognition via capsule network with channel-wise attention and LSTM models,,2021.0,44.0,8.0,False,,"{'volume': '3', 'pages': '425 - 435', 'name': 'CCF Transactions on Pervasive Computing and Interaction'}","{'bibtex': '@Article{Deng2021EEGbasedER,\n author = {L. Deng and Xiaoliang Wang and Frank Jiang and R. Doss},\n journal = {CCF Transactions on Pervasive Computing and Interaction},\n pages = {425 - 435},\n title = {EEG-based emotion recognition via capsule network with channel-wise attention and LSTM models},\n volume = {3},\n year = {2021}\n}\n'}","[{'authorId': '2114190990', 'name': 'L. Deng'}, {'authorId': '2145746050', 'name': 'Xiaoliang Wang'}, {'authorId': '1621103368', 'name': 'Frank Jiang'}, {'authorId': '2006159535', 'name': 'R. Doss'}]"
502,2a378dc326f8ece1b741390673dbe4657d422750,Virtual rap dancer: invitation to dance,"This paper presents a virtual rap dancer that is able to dance to the beat of music coming in from music recordings, beats obtained from music, voice or other input through a microphone, motion beats detected in the video stream of a human dancer, or motions detected from a dance mat. The rap dancer's moves are generated from a lexicon that was derived manually from the analysis of the video clips of rap songs performed by various rappers. The system allows for adaptation of the moves in the lexicon on the basis of style parameters. The rap dancer invites a user to dance along with the music.",2006.0,16.0,25.0,True,"{'url': 'https://ris.utwente.nl/ws/files/5421227/reidsma2006a.pdf', 'status': None}","{'name': ""CHI '06 Extended Abstracts on Human Factors in Computing Systems""}","{'bibtex': ""@Article{Reidsma2006VirtualRD,\n author = {D. Reidsma and A. Nijholt and R. Poppe and R. Rienks and H. Hondorp},\n journal = {CHI '06 Extended Abstracts on Human Factors in Computing Systems},\n title = {Virtual rap dancer: invitation to dance},\n year = {2006}\n}\n""}","[{'authorId': '2997504', 'name': 'D. Reidsma'}, {'authorId': '144483472', 'name': 'A. Nijholt'}, {'authorId': '1754666', 'name': 'R. Poppe'}, {'authorId': '6236777', 'name': 'R. Rienks'}, {'authorId': '2854168', 'name': 'H. Hondorp'}]"
503,2a4a30bfa20dca50b301dbfa98e05cda079cede7,Fetal testosterone and empathy,,2006.0,61.0,177.0,False,,"{'volume': '49', 'pages': '282-292', 'name': 'Hormones and Behavior'}","{'bibtex': '@Article{Knickmeyer2006FetalTA,\n author = {Rebecca C. Knickmeyer and S. Baron-Cohen and P. Raggatt and Kevin Taylor and G. Hackett},\n journal = {Hormones and Behavior},\n pages = {282-292},\n title = {Fetal testosterone and empathy},\n volume = {49},\n year = {2006}\n}\n'}","[{'authorId': '2626194', 'name': 'Rebecca C. Knickmeyer'}, {'authorId': '1390019127', 'name': 'S. Baron-Cohen'}, {'authorId': '4120811', 'name': 'P. Raggatt'}, {'authorId': '2067727594', 'name': 'Kevin Taylor'}, {'authorId': '50007883', 'name': 'G. Hackett'}]"
504,2a69e806a42bf401017c9c9b6b1c1efb1430c541,Effects of Virtual Human Appearance Fidelity on Emotion Contagion in Affective Inter-Personal Simulations,"Realistic versus stylized depictions of virtual humans in simulated inter-personal situations and their ability to elicit emotional responses in users has been an open question for artists and researchers alike. We empirically evaluated the effects of near visually realistic vs. non-realistic stylized appearance of virtual humans on the emotional response of participants in a medical virtual reality system that was designed to educate users in recognizing the signs and symptoms of patient deterioration. In a between-subjects experiment protocol, participants interacted with one of three different appearances of a virtual patient, namely visually realistic, cartoon-shaded and charcoal-sketch like conditions in a mixed reality simulation. Emotional impact were measured via a combination of quantitative objective measures were gathered using skin Electrodermal Activity (EDA) sensors, and quantitative subjective measures such as the Differential Emotion Survey (DES IV), Positive and Negative Affect Schedule (PANAS), and Social Presence questionnaire. The emotional states of the participants were analyzed across four distinct time steps during which the medical condition of the virtual patient deteriorated (an emotionally stressful interaction), and were contrasted to a baseline affective state. Objective EDA results showed that in all three conditions, male participants exhibited greater levels of arousal as compared to female participants. We found that negative affect levels were significantly lower in the visually realistic condition, as compared to the stylized appearance conditions. Furthermore, in emotional dimensions of interest-excitement, surprise, anger, fear and guilt participants in all conditions responded similarly. However, in social emotional constructs of shyness, presence, perceived personality, and enjoyment-joy, we found that participants responded differently in the visually realistic condition as compared to the cartoon and sketch conditions. Our study suggests that virtual human appearance can affect not only critical emotional reactions in affective inter-oersonal trainina scenarios. but also users' oerceotions of oersonalitv and social characteristic of the virtual interlocutors.",2016.0,39.0,96.0,False,,"{'volume': '22', 'pages': '1326-1335', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Volonte2016EffectsOV,\n author = {Matias Volonte and Sabarish V. Babu and H. Chaturvedi and Nathan D. Newsome and Elham Ebrahimi and Tania Roy and S. Daily and Tracy Fasolino},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {1326-1335},\n title = {Effects of Virtual Human Appearance Fidelity on Emotion Contagion in Affective Inter-Personal Simulations},\n volume = {22},\n year = {2016}\n}\n'}","[{'authorId': '51250937', 'name': 'Matias Volonte'}, {'authorId': '144403504', 'name': 'Sabarish V. Babu'}, {'authorId': '144291265', 'name': 'H. Chaturvedi'}, {'authorId': '2698078', 'name': 'Nathan D. Newsome'}, {'authorId': '2064300398', 'name': 'Elham Ebrahimi'}, {'authorId': '144455263', 'name': 'Tania Roy'}, {'authorId': '1959041', 'name': 'S. Daily'}, {'authorId': '3043236', 'name': 'Tracy Fasolino'}]"
505,2a75f34663a60ab1b04a0049ed1d14335129e908,Web-based database for facial expression analysis,"In the last decade, the research topic of automatic analysis of facial expressions has become a central topic in machine vision research. Nonetheless, there is a glaring lack of a comprehensive, readily accessible reference set of face images that could be used as a basis for benchmarks for efforts in the field. This lack of easily accessible, suitable, common testing resource forms the major impediment to comparing and extending the issues concerned with automatic facial expression analysis. In this paper, we discuss a number of issues that make the problem of creating a benchmark facial expression database difficult. We then present the MMI facial expression database, which includes more than 1500 samples of both static images and image sequences of faces in frontal and in profile view displaying various expressions of emotion, single and multiple facial muscle activation. It has been built as a Web-based direct-manipulation application, allowing easy access and easy search of the available images. This database represents the most comprehensive reference set of images for studies on facial expression analysis to date.",2005.0,59.0,1060.0,True,"{'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/5725/1/Pantic-ICME05-2.pdf', 'status': None}","{'pages': '5 pp.-', 'name': '2005 IEEE International Conference on Multimedia and Expo'}","{'bibtex': '@Article{Pantic2005WebbasedDF,\n author = {M. Pantic and M. Valstar and R. Rademaker and L. Maat},\n journal = {2005 IEEE International Conference on Multimedia and Expo},\n pages = {5 pp.-},\n title = {Web-based database for facial expression analysis},\n year = {2005}\n}\n'}","[{'authorId': '145387780', 'name': 'M. Pantic'}, {'authorId': '1795528', 'name': 'M. Valstar'}, {'authorId': '2503276', 'name': 'R. Rademaker'}, {'authorId': '153828376', 'name': 'L. Maat'}]"
507,2ab4bdd0477c70c680f5867d4ff45843bc21e27f,Designing effective gaze mechanisms for virtual agents,"Virtual agents hold great promise in human-computer interaction with their ability to afford embodied interaction using nonverbal human communicative cues. Gaze cues are particularly important to achieve significant high-level outcomes such as improved learning and feelings of rapport. Our goal is to explore how agents might achieve such outcomes through seemingly subtle changes in gaze behavior and what design variables for gaze might lead to such positive outcomes. Drawing on research in human physiology, we developed a model of gaze behavior to capture these key design variables. In a user study, we investigated how manipulations in these variables might improve affiliation with the agent and learning. The results showed that an agent using affiliative gaze elicited more positive feelings of connection, while an agent using referential gaze improved participants' learning. Our model and findings offer guidelines for the design of effective gaze behaviors for virtual agents.",2012.0,61.0,83.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Andrist2012DesigningEG,\n author = {Sean Andrist and T. Pejsa and Bilge Mutlu and Michael Gleicher},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Designing effective gaze mechanisms for virtual agents},\n year = {2012}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '2633572', 'name': 'T. Pejsa'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}]"
509,2b0f4b6d00cdb104b8bfe4fb367e47aea1f5bf66,Convergent and divergent responses to emotional displays of ingroup and outgroup.,"In the present research, we test the assumption that emotional mimicry and contagion are moderated by group membership. We report two studies using facial electromyography (EMG; Study 1), Facial Action Coding System (FACS; Study 2), and self-reported emotions (Study 2) as dependent measures. As predicted, both studies show that ingroup anger and fear displays were mimicked to a greater extent than outgroup displays of these emotions. The self-report data in Study 2 further showed specific divergent reactions to outgroup anger and fear displays. Outgroup anger evoked fear, and outgroup fear evoked aversion. Interestingly, mimicry increased liking for ingroup models but not for outgroup models. The findings are discussed in terms of the social functions of emotions in group contexts. (PsycINFO Database Record (c) 2011 APA, all rights reserved).",2011.0,53.0,231.0,False,,"{'volume': '11 2', 'pages': '\n          286-98\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Schalk2011ConvergentAD,\n author = {Job van der Schalk and A. Fischer and B. Doosje and D. Wigboldus and Skyler T. Hawk and M. Rotteveel and U. Hess},\n journal = {Emotion},\n pages = {\n          286-98\n        },\n title = {Convergent and divergent responses to emotional displays of ingroup and outgroup.},\n volume = {11 2},\n year = {2011}\n}\n'}","[{'authorId': '46845475', 'name': 'Job van der Schalk'}, {'authorId': '7444483', 'name': 'A. Fischer'}, {'authorId': '3534042', 'name': 'B. Doosje'}, {'authorId': '39854264', 'name': 'D. Wigboldus'}, {'authorId': '2390460', 'name': 'Skyler T. Hawk'}, {'authorId': '4837582', 'name': 'M. Rotteveel'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
510,2b5c5557d4ace8af2bef672309485cde27cb025c,A Gold Standard for Emotion Annotation in Stack Overflow,"Software developers experience and share a wide range of emotions throughout a rich ecosystem of communication channels. A recent trend that has emerged in empirical software engineering studies is leveraging sentiment analysis of developers' communication traces. We release a dataset of 4,800 questions, answers, and comments from Stack Overflow, manually annotated for emotions. Our dataset contributes to the building of a shared corpus of annotated resources to support research on emotion awareness in software development.",2018.0,20.0,53.0,True,"{'url': 'https://arxiv.org/pdf/1803.02300', 'status': None}","{'pages': '14-17', 'name': '2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)'}","{'bibtex': '@Article{Novielli2018AGS,\n author = {Nicole Novielli and Fabio Calefato and F. Lanubile},\n journal = {2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)},\n pages = {14-17},\n title = {A Gold Standard for Emotion Annotation in Stack Overflow},\n year = {2018}\n}\n'}","[{'authorId': '1750021', 'name': 'Nicole Novielli'}, {'authorId': '1810643', 'name': 'Fabio Calefato'}, {'authorId': '1743022', 'name': 'F. Lanubile'}]"
511,2b6765d728b920451dd5dc8a92d8613d0ce2733a,On the Origins of Human Emotions,,2000.0,0.0,33.0,False,,,"{'bibtex': '@Inproceedings{Turner2000OnTO,\n author = {J. Turner},\n title = {On the Origins of Human Emotions},\n year = {2000}\n}\n'}","[{'authorId': '118688586', 'name': 'J. Turner'}]"
512,2b6991269b8c0c02930ef36ed509457d7f07533e,Transfer Learning from Monolingual ASR to Transcription-free Cross-lingual Voice Conversion,"Cross-lingual voice conversion (VC) is a task that aims to synthesize target voices with the same content while source and target speakers speak in different languages. Its challenge lies in the fact that the source and target data are naturally non-parallel, and it is even difficult to bridge the gaps between languages with no transcriptions provided. In this paper, we focus on knowledge transfer from monolin-gual ASR to cross-lingual VC, in order to address the con-tent mismatch problem. To achieve this, we first train a monolingual acoustic model for the source language, use it to extract phonetic features for all the speech in the VC dataset, and then train a Seq2Seq conversion model to pre-dict the mel-spectrograms. We successfully address cross-lingual VC without any transcription or language-specific knowledge for foreign speech. We experiment this on Voice Conversion Challenge 2020 datasets and show that our speaker-dependent conversion model outperforms the zero-shot baseline, achieving MOS of 3.83 and 3.54 in speech quality and speaker similarity for cross-lingual conversion. When compared to Cascade ASR-TTS method, our proposed one significantly reduces the MOS drop be-tween intra- and cross-lingual conversion.",2020.0,28.0,4.0,False,,"{'volume': 'abs/2009.14668', 'name': 'ArXiv'}","{'bibtex': '@Article{Chang2020TransferLF,\n author = {Che-Jui Chang},\n journal = {ArXiv},\n title = {Transfer Learning from Monolingual ASR to Transcription-free Cross-lingual Voice Conversion},\n volume = {abs/2009.14668},\n year = {2020}\n}\n'}","[{'authorId': '2152342254', 'name': 'Che-Jui Chang'}]"
513,2b7cded7ef57579034870db4c3850f1245a8b94b,Perception Markup Language: Towards a Standardized Representation of Perceived Nonverbal Behaviors,,2012.0,25.0,72.0,False,,{'pages': '455-463'},"{'bibtex': '@Inproceedings{Scherer2012PerceptionML,\n author = {Stefan Scherer and S. Marsella and Giota Stratou and Yuyu Xu and Fabrizio Morbini and Alesia Egan and A. Rizzo and Louis-Philippe Morency},\n pages = {455-463},\n title = {Perception Markup Language: Towards a Standardized Representation of Perceived Nonverbal Behaviors},\n year = {2012}\n}\n'}","[{'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '1884967', 'name': 'Yuyu Xu'}, {'authorId': '2223582', 'name': 'Fabrizio Morbini'}, {'authorId': '2058717828', 'name': 'Alesia Egan'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
515,2b82475826449ba43e49664cd185eadd35fdebfe,The Challenge of Constructing Psychologically Believable Agents,"Embodied conversational agents (ECAs) are designed to provide natural and intuitive communication with a human user. One major current topic in agent design consequently is to enhance their believability, often by incorporating internal models of emotions or motivations. As psychological theories often lack the necessary details for direct implementation, many agent modelers currently rely on models that are rather marginal in current psychological research, or models that are created ad hoc with little theoretical and empirical foundation. The goal of this article is both to raise psychologists' awareness of the central challenges in the process of creating psychologically believable agents, and to recommend existing psychological frameworks to the virtual agents community that seem particularly useful for implementation in ECAs. Special attention is paid to a computationally detailed model of basic social motives that seems particularly useful for implementation: the Zurich model of social motivation.",2011.0,66.0,25.0,True,"{'url': 'https://epub.ub.uni-muenchen.de/13578/1/schoenbrodt_13578.pdf', 'status': None}","{'volume': '23', 'pages': '100-107', 'name': 'J. Media Psychol. Theor. Methods Appl.'}","{'bibtex': '@Article{Schönbrodt2011TheCO,\n author = {Felix D. Schönbrodt and J. Asendorpf},\n journal = {J. Media Psychol. Theor. Methods Appl.},\n pages = {100-107},\n title = {The Challenge of Constructing Psychologically Believable Agents},\n volume = {23},\n year = {2011}\n}\n'}","[{'authorId': '1844541', 'name': 'Felix D. Schönbrodt'}, {'authorId': '1901675', 'name': 'J. Asendorpf'}]"
516,2b847220cae3406b0e76239f320703d08321df9e,Neural substrates of shared attention as social memory: A hyperscanning functional magnetic resonance imaging study,,2016.0,79.0,139.0,True,,"{'volume': '125', 'pages': '401-412', 'name': 'NeuroImage'}","{'bibtex': '@Article{Koike2016NeuralSO,\n author = {T. Koike and H. Tanabe and S. Okazaki and E. Nakagawa and A. Sasaki and Koji Shimada and Sho K. Sugawara and Haruka K. Takahashi and Kazufumi Yoshihara and J. Bosch-Bayard and N. Sadato},\n journal = {NeuroImage},\n pages = {401-412},\n title = {Neural substrates of shared attention as social memory: A hyperscanning functional magnetic resonance imaging study},\n volume = {125},\n year = {2016}\n}\n'}","[{'authorId': '2816538', 'name': 'T. Koike'}, {'authorId': '34748885', 'name': 'H. Tanabe'}, {'authorId': '3176946', 'name': 'S. Okazaki'}, {'authorId': '38381724', 'name': 'E. Nakagawa'}, {'authorId': '3168697', 'name': 'A. Sasaki'}, {'authorId': '2066525320', 'name': 'Koji Shimada'}, {'authorId': '25569909', 'name': 'Sho K. Sugawara'}, {'authorId': '2015756', 'name': 'Haruka K. Takahashi'}, {'authorId': '2189057', 'name': 'Kazufumi Yoshihara'}, {'authorId': '1412683480', 'name': 'J. Bosch-Bayard'}, {'authorId': '1843699', 'name': 'N. Sadato'}]"
517,2b9315e0668a4cc674882d6450a8ba8d1aa78ac6,Learning Emotion Regulation Strategies: A Cognitive Agent Model,"Learning to cope with negative emotions is an important challenge, which has received considerable attention in domains like the military and law enforcement. Driven by the aim to develop better training in coping skills, this paper presents an adaptive computational model of emotion regulation strategies, which is inspired by recent neurological literature. The model can be used both to gain more insight in emotion regulation training itself and to develop intelligent virtual reality-based training environments. The behaviour of the model is illustrated by a number of simulation experiments and by a mathematical analysis. In addition, a preliminary validation points out that it is able to approximate empirical data obtained from an experiment with human participants.",2013.0,29.0,14.0,False,,"{'name': '2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)', 'pages': '245-252', 'volume': '2'}","{'bibtex': '@Article{Bosse2013LearningER,\n author = {T. Bosse and C. Gerritsen and J. D. Man and Jan Treur},\n booktitle = {2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},\n journal = {2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},\n pages = {245-252},\n title = {Learning Emotion Regulation Strategies: A Cognitive Agent Model},\n volume = {2},\n year = {2013}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '144668050', 'name': 'C. Gerritsen'}, {'authorId': '144287490', 'name': 'J. D. Man'}, {'authorId': '1726343', 'name': 'Jan Treur'}]"
518,2b942261c49553bba62c340b197cf6ef373fd5a4,Supervised Descent Method and Its Applications to Face Alignment,"Many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. It is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization of a general smooth function. However, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) The function might not be analytically differentiable and numerical approximations are impractical. (2) The Hessian might be large and not positive definite. To address these issues, this paper proposes a Supervised Descent Method (SDM) for minimizing a Non-linear Least Squares (NLS) function. During training, the SDM learns a sequence of descent directions that minimizes the mean of NLS functions sampled at different points. In testing, SDM minimizes the NLS objective using the learned descent directions without computing the Jacobian nor the Hessian. We illustrate the benefits of our approach in synthetic and real examples, and show how SDM achieves state-of-the-art performance in the problem of facial feature detection. The code is available at www.humansensing.cs. cmu.edu/intraface.",2013.0,33.0,2013.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Supervised_Descent_Method_and_Its_Applications_to_Face_Alignment/6561023/1/files/12043331.pdf', 'status': None}","{'pages': '532-539', 'name': '2013 IEEE Conference on Computer Vision and Pattern Recognition'}","{'bibtex': '@Article{Xiong2013SupervisedDM,\n author = {Xuehan Xiong and F. D. L. Torre},\n journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {532-539},\n title = {Supervised Descent Method and Its Applications to Face Alignment},\n year = {2013}\n}\n'}","[{'authorId': '3182065', 'name': 'Xuehan Xiong'}, {'authorId': '143867160', 'name': 'F. D. L. Torre'}]"
519,2b971138c0073e494788c89ba4c1fca9a901df4b,Mimicry and Prosocial Behavior,"Recent studies have shown that mimicry occurs unintentionally and even among strangers. In the present studies, we investigated the consequences of this automatic phenomenon in order to learn more about the adaptive function it serves. In three studies, we consistently found that mimicry increases pro-social behavior. Participants who had been mimicked were more helpful and generous toward other people than were non-mimicked participants. These beneficial consequences of mimicry were not restricted to behavior directed toward the mimicker, but included behavior directed toward people not directly involved in the mimicry situation. These results suggest that the effects of mimicry are not simply due to increased liking for the mimicker, but are due to increased prosocial orientation in general.",2004.0,17.0,656.0,False,,"{'volume': '15', 'pages': '71 - 74', 'name': 'Psychological Science'}","{'bibtex': '@Article{Baaren2004MimicryAP,\n author = {Rick B. van Baaren and R. Holland and Kerry Kawakami and A. van Knippenberg},\n journal = {Psychological Science},\n pages = {71 - 74},\n title = {Mimicry and Prosocial Behavior},\n volume = {15},\n year = {2004}\n}\n'}","[{'authorId': '113458595', 'name': 'Rick B. van Baaren'}, {'authorId': '39821405', 'name': 'R. Holland'}, {'authorId': '4891987', 'name': 'Kerry Kawakami'}, {'authorId': '6511503', 'name': 'A. van Knippenberg'}]"
520,2be5c3fe6d3edd464c8de74b017b148631631918,Intelligent Agents Living in Social Virtual Environments - Bringing Max into Second Life,,2008.0,13.0,27.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/2001976/2280469/WeitnauerEtAl.pdf', 'status': None}",{'pages': '552-553'},"{'bibtex': '@Inproceedings{Weitnauer2008IntelligentAL,\n author = {E. Weitnauer and Nick M. Thomas and F. Rabe and S. Kopp},\n pages = {552-553},\n title = {Intelligent Agents Living in Social Virtual Environments - Bringing Max into Second Life},\n year = {2008}\n}\n'}","[{'authorId': '2131908', 'name': 'E. Weitnauer'}, {'authorId': '2068865472', 'name': 'Nick M. Thomas'}, {'authorId': '40028251', 'name': 'F. Rabe'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
521,2bee525f3efbdf454cd2acd8b2e89041775490ed,FrankenFolk: distinctiveness and attractiveness of voice and motion,"It is common practice in movies and games to use different actors for the voice and body/face motion of a virtual character. What effect does the combination of these different modalities have on the perception of the viewer? In this article, we conduct a series of experiments to evaluate the distinctiveness and attractiveness of human motions (face and body) and voices. We also create combination characters called FrankenFolks, where we mix and match the voice, body motion, face motion, and avatar of different actors and ask which modality is most dominant when determining distinctiveness and attractiveness or whether the effects are cumulative.",2016.0,23.0,7.0,False,,{'name': 'Proceedings of the ACM Symposium on Applied Perception'},"{'bibtex': ""@Article{Ondřej2016FrankenFolkDA,\n author = {Jan Ondřej and Cathy Ennis and N. Merriman and C. O'Sullivan},\n journal = {Proceedings of the ACM Symposium on Applied Perception},\n title = {FrankenFolk: distinctiveness and attractiveness of voice and motion},\n year = {2016}\n}\n""}","[{'authorId': '2050262', 'name': 'Jan Ondřej'}, {'authorId': '31894925', 'name': 'Cathy Ennis'}, {'authorId': '47167841', 'name': 'N. Merriman'}, {'authorId': '1404017833', 'name': ""C. O'Sullivan""}]"
522,2bfbf07cf46958ad0f851117546c324379a9e731,Developmental differences.,,1980.0,0.0,134.0,False,,"{'volume': '207 4438', 'pages': '\n          1460-1\n        ', 'name': 'Science'}","{'bibtex': '@Article{Blackler1980DevelopmentalD,\n author = {A. Blackler},\n journal = {Science},\n pages = {\n          1460-1\n        },\n title = {Developmental differences.},\n volume = {207 4438},\n year = {1980}\n}\n'}","[{'authorId': '121139850', 'name': 'A. Blackler'}]"
523,2bfec947a52338c4da074ae8d5361923256aa3d8,"Social sharing of emotion, emotional recovery, and interpersonal aspects","Social sharing of emotion is a very common long-term consequence of emotional experiences. Despite the fact that it reactivates the emotions associated with the experience, people are prone to talk about the negative events they face. So, why do people share their emotions? From an intrapersonal perspective, a widespread belief exists that verbalising an emotion alleviates the impact of an emotional event. The purpose of our research was to examine whether verbalisation of emotions effectively contributed to the recovery from the emotion. We review the correlative and experimental studies that were conducted to test this hypothesis. They consistently failed to support the view that mere talking about an emotional memory can lower its emotional load. Nevertheless, participants generally reported that they perceived the sharing process as beneficial. The question then remains as to why people share their emotions and report it is a beneficial process, if it does not bring emotional recovery. To answer this question, we shifted perspective and studied the interpersonal factors implied in the social sharing process. In the following of the chapter, we suggest that the effects of social sharing depend on the social context in which it occurs. We first consider types of sharing partners that are commonly chosen both as a function of age and according to the type of emotional situation experienced. Then, the types of helpful responses from sharing partners are examined. Finally, recent studies on the effects of specific sharing partner’s reactions on affiliation and cognitive benefits are presented. In the conclusion of this chapter, implications of the research on social sharing for the field of emotion regulation are considered.",2004.0,92.0,42.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Zech2004SocialSO,\n author = {E. Zech and B. Rimé and F. Nils},\n title = {Social sharing of emotion, emotional recovery, and interpersonal aspects},\n year = {2004}\n}\n'}","[{'authorId': '4462136', 'name': 'E. Zech'}, {'authorId': '5722413', 'name': 'B. Rimé'}, {'authorId': '2083760609', 'name': 'F. Nils'}]"
524,2c02011c87565c77ce2048ab8192a105485a2f3d,Nonparametric Statistical Inference,,2020.0,236.0,2248.0,False,,{'pages': '977-979'},"{'bibtex': '@Inproceedings{Gibbons2020NonparametricSI,\n author = {J. Gibbons and S. Chakraborti},\n pages = {977-979},\n title = {Nonparametric Statistical Inference},\n year = {2020}\n}\n'}","[{'authorId': '69056502', 'name': 'J. Gibbons'}, {'authorId': '145692786', 'name': 'S. Chakraborti'}]"
525,2c0fc87bef123f5556a0a63959e0f004f7730b1e,"Facial Expressions of Emotion: New Findings, New Questions","The evidence on universals in facial expression of emotion, renewed controversy about that evidence, and new findings on cultural differences are reviewed. New findings on the capability for voluntarily made facial expressions to generate changes in both autonomic and central nervous system activity are discussed, and possible mechanisms by which this could occur are outlined. Finally, new work which has identified how to distinguish the smile of enjoyment from other types of smiling is described.",1992.0,70.0,697.0,False,,"{'volume': '3', 'pages': '34 - 38', 'name': 'Psychological Science'}","{'bibtex': '@Article{Ekman1992FacialEO,\n author = {P. Ekman},\n journal = {Psychological Science},\n pages = {34 - 38},\n title = {Facial Expressions of Emotion: New Findings, New Questions},\n volume = {3},\n year = {1992}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
526,2c28755adfb8ef67337a98b07dd4c80f96e82e83,Quantifying the Association Between Psychotherapy Content and Clinical Outcomes Using Deep Learning,"Key Points Question What aspects of psychotherapy content are significantly associated with clinical outcomes? Findings In this quality improvement study, a deep learning model was trained to automatically categorize therapist utterances from approximately 90 000 hours of internet-enabled cognitive behavior therapy (CBT). Increased quantities of CBT change methods were positively associated with reliable improvement in patient symptoms, and the quantity of nontherapy-related content showed a negative association. Meaning The findings support the key principles underlying CBT as a treatment and demonstrate that applying deep learning to large clinical data sets can provide valuable insights into the effectiveness of psychotherapy.",2019.0,36.0,63.0,True,"{'url': 'https://jamanetwork.com/journals/jamapsychiatry/articlepdf/2748757/jamapsychiatry_ewbank_2019_oi_190059.pdf', 'status': None}","{'volume': '77', 'pages': '35 - 43', 'name': 'JAMA Psychiatry'}","{'bibtex': '@Article{Ewbank2019QuantifyingTA,\n author = {M. Ewbank and R. Cummins and V. Tablan and S. Bateup and A. Catarino and Alan Martin and A. Blackwell},\n journal = {JAMA Psychiatry},\n pages = {35 - 43},\n title = {Quantifying the Association Between Psychotherapy Content and Clinical Outcomes Using Deep Learning},\n volume = {77},\n year = {2019}\n}\n'}","[{'authorId': '1984805', 'name': 'M. Ewbank'}, {'authorId': '153714664', 'name': 'R. Cummins'}, {'authorId': '2095029103', 'name': 'V. Tablan'}, {'authorId': '13827718', 'name': 'S. Bateup'}, {'authorId': '94314925', 'name': 'A. Catarino'}, {'authorId': '2111210811', 'name': 'Alan Martin'}, {'authorId': '7176472', 'name': 'A. Blackwell'}]"
527,2c54a65d48f9787523af6dabc6192e58cc0ef4ac,Evaluating the consequences of affective feedback in intelligent tutoring systems,"The link between affect and student learning has been the subject of increasing attention in recent years. Because of the possible impacts of affective state on learning, it is a goal of many intelligent tutoring systems to attempt to control student emotional states through affective interventions. While much work has gone into improving the quality of these interventions, we are only beginning to understand the complexities of the relationships between affect, learning, and feedback. This paper investigates the consequences associated with providing affective feedback. It represents a first step toward the long-term objective of designing intelligent tutoring systems that can utilize this information for analysis of the risks and benefits of affective intervention. It reports on the results of two studies that were conducted with students interacting with affect-informed virtual agents. The studies reveal that emotion-specific risk/reward information is associated with particular affective states and suggests that future systems might leverage this information to make determinations about affective interventions.",2009.0,26.0,127.0,False,,"{'pages': '1-6', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Robison2009EvaluatingTC,\n author = {J. Robison and Scott W. McQuiggan and James C. Lester},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-6},\n title = {Evaluating the consequences of affective feedback in intelligent tutoring systems},\n year = {2009}\n}\n'}","[{'authorId': '31942647', 'name': 'J. Robison'}, {'authorId': '2779835', 'name': 'Scott W. McQuiggan'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
528,2c5f2eb1cffd043b4bd16befe1600aaf5dfddcd1,Lowering the development time of multimodal interactive application: the real-life experience of the XVR project,"In this paper we present XVR, an integrated development environment for the rapid development of Virtual Reality applications. Using a modular architecture and a VR-oriented scripting language, XVR contents can be embedded on a variety of container applications. This makes it suitable to write contents ranging from web-oriented presentations to more complex VR installations involving advanced devices, such as real-time trackers, haptic interfaces, sensorized gloves and stereoscopic devices, including HMDs. Some case studies are also presented to illustrate the development processes related to XVR and its features.",2005.0,15.0,95.0,False,,{'pages': '270-273'},"{'bibtex': '@Inproceedings{Carrozzino2005LoweringTD,\n author = {M. Carrozzino and F. Tecchia and Sandro Bacinelli and Carlo Cappelletti and M. Bergamasco},\n pages = {270-273},\n title = {Lowering the development time of multimodal interactive application: the real-life experience of the XVR project},\n year = {2005}\n}\n'}","[{'authorId': '2203390', 'name': 'M. Carrozzino'}, {'authorId': '3089335', 'name': 'F. Tecchia'}, {'authorId': '1838426', 'name': 'Sandro Bacinelli'}, {'authorId': '2060665191', 'name': 'Carlo Cappelletti'}, {'authorId': '7723077', 'name': 'M. Bergamasco'}]"
529,2c93c8da5dfe5c50119949881f90ac5a0a4f39fe,Advanced local motion patterns for macro and micro facial expression recognition,"In this paper, we develop a new method that recognizes facial expressions, on the basis of an innovative local motion patterns feature, with three main contributions. The first one is the analysis of the face skin temporal elasticity and face deformations during expression. The second one is a unified approach for both macro and micro expression recognition. And, the third one is the step forward towards in-the-wild expression recognition, dealing with challenges such as various intensity and various expression activation patterns, illumination variation and small head pose variations. Our method outperforms state-of-the-art methods for micro expression recognition and positions itself among top-rank state-of-the-art methods for macro expression recognition.",2018.0,51.0,10.0,False,,"{'volume': 'abs/1805.01951', 'name': 'ArXiv'}","{'bibtex': '@Article{Allaert2018AdvancedLM,\n author = {B. Allaert and Ioan Marius Bilasco and C. Djeraba},\n journal = {ArXiv},\n title = {Advanced local motion patterns for macro and micro facial expression recognition},\n volume = {abs/1805.01951},\n year = {2018}\n}\n'}","[{'authorId': '40125014', 'name': 'B. Allaert'}, {'authorId': '3036685', 'name': 'Ioan Marius Bilasco'}, {'authorId': '1705776', 'name': 'C. Djeraba'}]"
530,2c9b70521a0d3a5ee4c23983e8a8fde40aa65f7c,Strategies for Effective Digital Games Development and Implementation,"Digital technologies have increased the pace of knowledge creation, sharing, and the way in which learning is being undertaken. This chapter considers how Serious Games (SGs) as a digital technology endeavours to support effective lifelong learning. Three fundamental characteristics of the SG ecosystem, namely, game mechanics, interoperability, and assessment, are considered here as strategic elements that impact upon how SGs are to support learning, how they affect the learning environment, and ultimately, the SG development process. A prospective deconstruction of SGs into its pedagogical elements and its game mechanic nodes is presented to make aware the interoperability modus from which topical (domain) frameworks or architectures can be structured and assessed. To this end, the chapter explores the conceptual underpinnings through a case study on the eAdventure platform and argues that the key elements form the foundation for strategic development and implementation of SGs.",2013.0,46.0,38.0,False,,"{'volume': '', 'pages': '168-198', 'name': ''}","{'bibtex': '@Inproceedings{Lim2013StrategiesFE,\n author = {T. Lim and S. Louchart and N. Suttie and J. Ritchie and R. Aylett and Ioana A. Stanescu and I. Roceanu and I. Martínez-Ortiz and P. Moreno-Ger},\n pages = {168-198},\n title = {Strategies for Effective Digital Games Development and Implementation},\n year = {2013}\n}\n'}","[{'authorId': '145841951', 'name': 'T. Lim'}, {'authorId': '2910576', 'name': 'S. Louchart'}, {'authorId': '3181393', 'name': 'N. Suttie'}, {'authorId': '50361260', 'name': 'J. Ritchie'}, {'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '40621355', 'name': 'Ioana A. Stanescu'}, {'authorId': '49989999', 'name': 'I. Roceanu'}, {'authorId': '1398833087', 'name': 'I. Martínez-Ortiz'}, {'authorId': '1389962953', 'name': 'P. Moreno-Ger'}]"
531,2ca16b47c88c895f1bf60b9faf59943762c33fcf,An Architecture for Autism: Built Environment Performance in Accordance to the Autism ASPECTSS™ Design Index,,2015.0,0.0,26.0,False,,"{'volume': '8', 'pages': '479-500', 'name': 'Design Principles and Practices: An International Journal'}","{'bibtex': '@Article{Mostafa2015AnAF,\n author = {Magda Mostafa},\n journal = {Design Principles and Practices: An International Journal},\n pages = {479-500},\n title = {An Architecture for Autism: Built Environment Performance in Accordance to the Autism ASPECTSS™ Design Index},\n volume = {8},\n year = {2015}\n}\n'}","[{'authorId': '114123187', 'name': 'Magda Mostafa'}]"
532,2cc18c34e3e6375ac0472d0f79f789aec3986b68,The Illusion of Agency: The Influence of the Agency of an Artificial Agent on Its Persuasive Power,,2012.0,21.0,23.0,True,"{'url': 'https://research.tue.nl/files/3525603/600490186523923.pdf', 'status': None}",{'pages': '90-99'},"{'bibtex': '@Inproceedings{Midden2012TheIO,\n author = {C. Midden and Jaap Ham},\n pages = {90-99},\n title = {The Illusion of Agency: The Influence of the Agency of an Artificial Agent on Its Persuasive Power},\n year = {2012}\n}\n'}","[{'authorId': '3026039', 'name': 'C. Midden'}, {'authorId': '145960497', 'name': 'Jaap Ham'}]"
533,2cd052ffde128ead5a220a67a8d23345c93be314,"Virtual reality platform for Self-Attachment therapy, assisted by a virtual agent with emotion recognition capabilities","Mental disorders have been a serious and growing problem for people around the planet in recent years and efficient ways of treatment are yet to be developed. Self-Attachment is a recently introduced psychotherapeutic method in which the patient creates a compassionate and affectional bond with their childhood-self using their childhood photos. The underlying theory and the promising results of the Self-Attachment therapy, in combination with its self-administrable nature, motivate further research in technologies that can enhance the procedure of the therapy. Virtual reality is a technology that has experienced rapid evolution over the last years, yet its ability to replace existing psychotherapeutic techniques remains fairly unexplored. The aim of this thesis is to create a user-friendly and highly interactive virtual reality platform that delivers the Self-Attachment therapy in an efficient way by creating an avatar of the patient’s childhood-self based on a 2D childhood photo. For the fulfillment of this goal, the implemented platform has been equipped with the latest features of the head-mounted Oculus Quest device and interactable components. In addition, the virtual environment features a virtual agent who acts as an assistant and is able to predict the emotional state of the user. The aforementioned achievements have led to the creation of a complete virtual platform, capable of autonomously delivering the Self-Attachment therapy in a personalised experience for the user. During an impact evaluation trial, a version of the platform was tested by seven healthy individuals and the results were promising. The high levels of immersiveness of the platform and its ability to attract and maintain the user’s engagement played a crucial role in obtaining positive feedback from the participants. Furthermore, the platform was successful in triggering participants’ emotions, who in the end preferred the virtual experience over the original therapy which is based on the use of their childhood photo. Consequently, we believe that this project is the beginning of the creation of a tool that will be able to autonomously and effectively treat people with mental disorders in the near future.",2020.0,50.0,1.0,False,,,"{'bibtex': '@Inproceedings{Edalat2020VirtualRP,\n author = {A. Edalat},\n title = {Virtual reality platform for Self-Attachment therapy, assisted by a virtual agent with emotion recognition capabilities},\n year = {2020}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}]"
534,2d08dbfb26d35399c7c9f68b6faa46f63488d499,A Rapid Evidence Assessment of Immersive Virtual Reality as an Adjunct Therapy in Acute Pain Management in Clinical Practice,"Objectives:Immersive virtual reality (IVR) therapy has been explored as an adjunct therapy for the management of acute pain among children and adults for several conditions. Therapeutic approaches have traditionally involved medication and physiotherapy but such approaches are limited over time by their cost and side effects. This review seeks to critically evaluate the evidence for and against IVR as an adjunctive therapy for acute clinical pain applications. Methods:A rapid evidence assessment (REA) strategy was used. CINAHL, Medline, Web of Science, IEEE Xplore Digital Library, and the Cochrane Library databases were screened in from December 2012 to March 2013 to identify studies exploring IVR therapies as an intervention to assist in the management of pain. Main outcome measures were for acute pain and functional impairment. Results:Seventeen research studies were included in total including 5 RCTs, 6 randomized crossover studies, 2 case series studies, and 4 single-patient case studies. This included a total of 337 patients. Of these studies only 4 had a low risk of bias. There was strong overall evidence for immediate and short-term pain reduction, whereas moderate evidence was found for short-term effects on physical function. Little evidence exists for longer-term benefits. IVR was not associated with any serious adverse events. Discussion:This review found moderate evidence for the reduction of pain and functional impairment after IVR in patients with acute pain. Further high-quality studies are required for the conclusive judgment of its effectiveness in acute pain, to establish potential benefits for chronic pain, and for safety.",2014.0,77.0,143.0,False,,"{'volume': '30', 'pages': '1089–1098', 'name': 'The Clinical Journal of Pain'}","{'bibtex': '@Article{Garrett2014ARE,\n author = {Bernie Garrett and T. Taverner and Wendy Masinde and D. Gromala and Chris D. Shaw and Michael Negraeff},\n journal = {The Clinical Journal of Pain},\n pages = {1089–1098},\n title = {A Rapid Evidence Assessment of Immersive Virtual Reality as an Adjunct Therapy in Acute Pain Management in Clinical Practice},\n volume = {30},\n year = {2014}\n}\n'}","[{'authorId': '34214879', 'name': 'Bernie Garrett'}, {'authorId': '3237686', 'name': 'T. Taverner'}, {'authorId': '15921526', 'name': 'Wendy Masinde'}, {'authorId': '1744767', 'name': 'D. Gromala'}, {'authorId': '145600106', 'name': 'Chris D. Shaw'}, {'authorId': '12200854', 'name': 'Michael Negraeff'}]"
535,2d1d04f26ca23018eab0b6e5d79c860b82aff118,Third Edition,,2011.0,71.0,413.0,False,,,"{'bibtex': '@Inproceedings{Rinehart2011ThirdE,\n author = {W. Rinehart and D. Sloan and C. Hurd},\n title = {Third Edition},\n year = {2011}\n}\n'}","[{'authorId': '134872107', 'name': 'W. Rinehart'}, {'authorId': '87987866', 'name': 'D. Sloan'}, {'authorId': '87371574', 'name': 'C. Hurd'}]"
536,2d2c0b2ca556f27f9adcecf636f7a2eb8f7f2a49,EDUBOT-A Chatbot For Education in Covid-19 Pandemic and VQAbot Comparison,"A chatbot is software that is programmed and designed to simulate conversation with human users through Artificial Intelligence. During this pandemic, where students are confined to their homes with limited guidance from teachers, this chatbot provides a human-like interface that can solve academic queries of students, thus encouraging students to learn in an interesting manner. This paper demonstrates and presents the design and development of Student Chatbot software integrated with a user website that handles students' queries through defined intents. The paper covers the chatbot system with Recurrent Neural Network (RNN) for dealing language part, Convolutional Neural Network (CNN) to deal with the image part, Dialogflow, illustrating with precision the intent and entity representation and keyword matching techniques used by introducing an artificial brain into “Web-Based Bot”. The aim to have a balanced user interface that is easy to access and customized to all target users. Also two Visual Question Answering chatbots ie visualdialog.cloudcv and CloudCV are compared to find which performs better. It was found that chatbot serves accurate for education.",2021.0,17.0,4.0,False,,"{'pages': '1707-1714', 'name': '2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)'}","{'bibtex': '@Article{Sophia2021EDUBOTACF,\n author = {J. Sophia and T. Jacob},\n journal = {2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)},\n pages = {1707-1714},\n title = {EDUBOT-A Chatbot For Education in Covid-19 Pandemic and VQAbot Comparison},\n year = {2021}\n}\n'}","[{'authorId': '2127998124', 'name': 'J. Sophia'}, {'authorId': '40636037', 'name': 'T. Jacob'}]"
537,2d5673caa9e6af3a7b82a43f19ee920992db07ad,Computing Machinery and Intelligence,"I propose to consider the question, “Can machines think?”♣ This should begin with definitions of the meaning of the terms “machine” and “think”. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words “machine” and “think” are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, “Can machines think?” is to be sought in a statistical survey such as a Gallup poll.",1950.0,14.0,9668.0,False,,"{'volume': 'LIX', 'pages': '433-460', 'name': 'Mind'}","{'bibtex': '@Article{Turing1950ComputingMA,\n author = {A. Turing},\n journal = {Mind},\n pages = {433-460},\n title = {Computing Machinery and Intelligence},\n volume = {LIX},\n year = {1950}\n}\n'}","[{'authorId': '2262347', 'name': 'A. Turing'}]"
538,2d7a3dd3ea386de50e13704c37b3c2a106ad571a,Towards internet of things modeling: a gateway approach,,2016.0,60.0,25.0,True,"{'url': 'https://casmodeling.springeropen.com/track/pdf/10.1186/s40294-016-0038-3', 'status': None}","{'volume': '4', 'pages': '1-11', 'name': 'Complex Adaptive Systems Modeling'}","{'bibtex': '@Article{Altamimi2016TowardsIO,\n author = {A. B. Altamimi and R. Ramadan},\n journal = {Complex Adaptive Systems Modeling},\n pages = {1-11},\n title = {Towards internet of things modeling: a gateway approach},\n volume = {4},\n year = {2016}\n}\n'}","[{'authorId': '3253521', 'name': 'A. B. Altamimi'}, {'authorId': '8970271', 'name': 'R. Ramadan'}]"
539,2d88e7e9c6cf3cc48f3d34c6f6b893799695bc43,Designing nonverbal communication for pedagogical agents: When less is more,,2009.0,60.0,148.0,False,,"{'volume': '25', 'pages': '450-457', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Baylor2009DesigningNC,\n author = {A. L. Baylor and Soyoung Kim},\n journal = {Comput. Hum. Behav.},\n pages = {450-457},\n title = {Designing nonverbal communication for pedagogical agents: When less is more},\n volume = {25},\n year = {2009}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '2144259493', 'name': 'Soyoung Kim'}]"
541,2d99dcb48f4f5f9cae977a9e7da9ecdc17b9b0c1,Real-time speech-driven lip synchronization,"Speech-driven lip synchronization, an important part of facial animation, is to animate a face model to render lip movements that are synchronized with the acoustic speech signal. It has many applications in human-computer interaction. In this paper, we present a framework that systematically addresses multimodal database collection and processing and real-time speech-driven lip synchronization using collaborative filtering which is a data-driven approach used by many online retailers to recommend products. Mel-frequency cepstral coefficients (MFCCs) with their delta and acceleration coefficients and Facial Animation Parameters (FAPs) supported by MPEG-4 for the visual representation of speech are utilized as acoustic features and animation parameters respectively. The proposed system is speaker independent and real-time capable. The subjective experiments show that the proposed approach generates a natural facial animation.",2010.0,18.0,6.0,False,,"{'pages': '378-382', 'name': '2010 4th International Universal Communication Symposium'}","{'bibtex': '@Article{Mu2010RealtimeSL,\n author = {Kaihui Mu and J. Tao and Jianfeng Che and Minghao Yang},\n journal = {2010 4th International Universal Communication Symposium},\n pages = {378-382},\n title = {Real-time speech-driven lip synchronization},\n year = {2010}\n}\n'}","[{'authorId': '3295988', 'name': 'Kaihui Mu'}, {'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '2061534506', 'name': 'Jianfeng Che'}, {'authorId': '2740129', 'name': 'Minghao Yang'}]"
542,2ddfcc851a12ed34d8f0ad270c4b8286393796f4,Social anxiety predicts avoidance behaviour in virtual encounters,"Avoidant behaviour is critical in social anxiety and social phobia, being a major factor in the maintenance of anxiety. However, almost all previous studies of social avoidance were restricted to using self-reports for the study of intentional aspects of avoidance. In contrast, the current study used immersive virtual reality technology to measure interpersonal distance as an index of avoidance, an unintentional behavioural indicator. In a virtual supermarket, twenty-three female participants differing in social anxiety approached computer-generated persons (avatars) under the pretext of a cover story. During the task, different aspects of approach and avoidance were measured. The results confirmed the hypotheses: The more anxious participants were, the more slowly they approached the avatars, and the larger the distance they kept from the avatars. This indicates that even sub-phobic social anxiety is related to unintentional avoidance behaviour in social situations.",2010.0,25.0,67.0,False,,"{'volume': '24', 'pages': '1269 - 1276', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Rinck2010SocialAP,\n author = {M. Rinck and T. Rörtgen and Wolf-Gero Lange and R. Dotsch and D. Wigboldus and E. Becker},\n journal = {Cognition and Emotion},\n pages = {1269 - 1276},\n title = {Social anxiety predicts avoidance behaviour in virtual encounters},\n volume = {24},\n year = {2010}\n}\n'}","[{'authorId': '2505736', 'name': 'M. Rinck'}, {'authorId': '113703375', 'name': 'T. Rörtgen'}, {'authorId': '46641514', 'name': 'Wolf-Gero Lange'}, {'authorId': '2365875', 'name': 'R. Dotsch'}, {'authorId': '39854264', 'name': 'D. Wigboldus'}, {'authorId': '3107071', 'name': 'E. Becker'}]"
543,2e15c4feab6122750ea53583325ca450d9a70d0d,Report of the technical investigation of The Station nightclub fire :: appendices,"A fire occurred on the night of Feb. 20, 2003, in The Station nightclub at 211 Cowesett Avenue, West Warwick, Rhode Island. A band that was on the platform that night, during its performance, used pyrotechnics that ignited polyurethane foam insulation lining the walls and ceiling of the platform. The fire spread quickly along the walls and ceiling area over the dance floor. Smoke was visible in the exit doorways in a little more than one minute, and flames were observed breaking through a portion of the roof in less than five minutes. Egress from the nightclub, which was not equipped with sprinklers, was hampered by crowding at the main entrance to the building. One hundred people lost their lives in the fire. On Feb. 27, 2003, under the authority of the National Construction Safety Team (NCST) Act, the National Institute of Standards and Technology (NIST) established a National Construction Safety Team to determine the likely technical cause or causes of the building failure that led to the high number of casualties in that fire. This report documents the procedures, findings, and issues that were raised by the investigation. Volume I contains the main report and Volume II contains appendix material. The investigation concluded that strict adherence to 2003 model codes available at the time of the fire would go a long way to preventing similar tragedies in the future. Changes to the codes subsequent to the fire made them stronger. By making some additional changes – and state and local agencies adopting and enforcing them – we can strengthen occupant safety even further. Ten recommendations to improve model building and fire codes, standards and practices (as they existed in February 2003) resulted from the investigation, including (i) urging state and local jurisdictions to (a) adopt and update building and fire codes covering nightclubs based on one of the model codes and (b) enforce those codes aggressively; (ii) strengthening the requirements for the installation of automatic fire sprinklers; (iii) increasing the factor of safety on the time for occupants to egress; (iv) tightening the restriction on the use of flexible polyurethane foam -and other materials that ignite as easily and propagate flames as rapidly as non-fire retarded foam -as an interior finish product; (v) further limiting the use of pyrotechnics; and (vi) conducting research in specific areas to underpin the recommended changes.",2005.0,1.0,46.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Grosshandler2005ReportOT,\n author = {W. Grosshandler and N. Bryner and Daniel Madrzykowski and K. Kuntz},\n title = {Report of the technical investigation of The Station nightclub fire :: appendices},\n year = {2005}\n}\n'}","[{'authorId': '89869714', 'name': 'W. Grosshandler'}, {'authorId': '8871732', 'name': 'N. Bryner'}, {'authorId': '50853958', 'name': 'Daniel Madrzykowski'}, {'authorId': '97424509', 'name': 'K. Kuntz'}]"
544,2e36998bb64688e3484c2d6f8431b86f04a1332e,From Greta's mind to her face: modelling the dynamics of affective states in a conversational embodied agent,,2003.0,91.0,312.0,True,"{'url': 'http://www.di.uniba.it/intint/people/papers/ijhcs-affect.pdf', 'status': None}","{'volume': '59', 'pages': '81-118', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': ""@Article{Rosis2003FromGM,\n author = {F. D. Rosis and C. Pelachaud and I. Poggi and V. Carofiglio and B. D. Carolis},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {81-118},\n title = {From Greta's mind to her face: modelling the dynamics of affective states in a conversational embodied agent},\n volume = {59},\n year = {2003}\n}\n""}","[{'authorId': '1807752', 'name': 'F. D. Rosis'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1802126', 'name': 'I. Poggi'}, {'authorId': '1694255', 'name': 'V. Carofiglio'}, {'authorId': '1739256', 'name': 'B. D. Carolis'}]"
550,2e377bdd4104d2869d1cc53e0a7f6acb36a53d8e,EMOTION AND FILM THEORY,,2003.0,39.0,21.0,False,,"{'volume': '26', 'pages': '169-187', 'name': ''}","{'bibtex': '@Inproceedings{Wiley2003EMOTIONAF,\n author = {Norbert Wiley},\n pages = {169-187},\n title = {EMOTION AND FILM THEORY},\n volume = {26},\n year = {2003}\n}\n'}","[{'authorId': '112853075', 'name': 'Norbert Wiley'}]"
551,2e43a55fbdafac189615945fa17feaf6610b7339,"Eye Tracking Methodology - Theory and Practice, Third Edition",,2003.0,0.0,344.0,True,,{'pages': '1-366'},"{'bibtex': '@Inproceedings{Duchowski2003EyeTM,\n author = {A. Duchowski},\n pages = {1-366},\n title = {Eye Tracking Methodology - Theory and Practice, Third Edition},\n year = {2003}\n}\n'}","[{'authorId': '2245673', 'name': 'A. Duchowski'}]"
552,2e4ca3d95ffb83870661dd66deee143e782f0706,Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale,"Automatic evaluation of language generation systems is a well-studied problem in Natural Language Processing. While novel metrics are proposed every year, a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation, despite their known limitations. This is partly due to ease of use, and partly because researchers expect to see them and know how to interpret them. In this paper, we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets, language pairs and tasks. Our experiments show that metrics (i) usually prefer system outputs to human-authored texts, (ii) can be insensitive to correct translations of rare words, (iii) can yield surprisingly high scores when given a single sentence as system output for the entire test set.",2020.0,27.0,24.0,True,"{'url': 'https://www.aclweb.org/anthology/2020.coling-main.210.pdf', 'status': None}","{'volume': 'abs/2010.13588', 'name': 'ArXiv'}","{'bibtex': '@Article{Caglayan2020CuriousCO,\n author = {Ozan Caglayan and P. Madhyastha and Lucia Specia},\n journal = {ArXiv},\n title = {Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale},\n volume = {abs/2010.13588},\n year = {2020}\n}\n'}","[{'authorId': '10791325', 'name': 'Ozan Caglayan'}, {'authorId': '3238408', 'name': 'P. Madhyastha'}, {'authorId': '1702974', 'name': 'Lucia Specia'}]"
553,2e4f8e46898aa5229d079487a009ec88ed70294d,Simulating Social Emotion Regulation in Virtual Reality: Effect of Virtual Social Support Following Ostracism in a Cyberball Game,"Virtual reality (VR) is a valuable research tool offering advantages in terms of high experimenter control and standardization in the simulation of vivid personal and social experiences. It has been used for assessments and training in social cognition with the use of virtual agents instead of face-to-face interactions – but its potential for the study of social emotion regulation has, perhaps surprisingly, largely remained untapped. The present study evaluates a novel immersive VR scenario designed to study the efficacy of social support by a virtual agent using a modified version of Cyberball, an established paradigm to induce the feeling of ostracism. Participants embodied a new pupil in a virtual school environment and played Cyberball, after which they either did or did not receive emotional support. Self-reports and psychophysiological markers demonstrated that the negative impact of social exclusion in Cyberball was successfully replicated, while participants also reported a significant improvement in emotional state after being supported by the virtual agent. These results indicate the potential of the developed scenario for research on social emotion regulation in immersive VR. Future studies could aim to test the efficacy of social support for people with difficulties in self-regulation, for example individuals with high social anxiety, with a view to developing training programs in VR.",2023.0,0.0,1.0,True,,"{'name': 'Int. J. Emerg. Technol. Learn.', 'pages': '4-27', 'volume': '18'}","{'bibtex': '@Article{Stallmann2023SimulatingSE,\n author = {Lina Stallmann and Michel Tran and D. Rudrauf and Daniel Dukes and Andrea C. Samson},\n booktitle = {International Journal of Emerging Technologies in Learning (iJET)},\n journal = {Int. J. Emerg. Technol. Learn.},\n pages = {4-27},\n title = {Simulating Social Emotion Regulation in Virtual Reality: Effect of Virtual Social Support Following Ostracism in a Cyberball Game},\n volume = {18},\n year = {2023}\n}\n'}","[{'authorId': '2124332447', 'name': 'Lina Stallmann'}, {'authorId': '2054039824', 'name': 'Michel Tran'}, {'authorId': '3090887', 'name': 'D. Rudrauf'}, {'authorId': '39779139', 'name': 'Daniel Dukes'}, {'authorId': '38707445', 'name': 'Andrea C. Samson'}]"
554,2e571bffc52137980f4c5b4385466435ea5c42d3,Multimodal Backchannels for Embodied Conversational Agents,,2010.0,17.0,53.0,False,,{'pages': '194-200'},"{'bibtex': '@Inproceedings{Bevacqua2010MultimodalBF,\n author = {Elisabetta Bevacqua and Sathish Pammi and S. Hyniewska and M. Schröder and C. Pelachaud},\n pages = {194-200},\n title = {Multimodal Backchannels for Embodied Conversational Agents},\n year = {2010}\n}\n'}","[{'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '2345401', 'name': 'Sathish Pammi'}, {'authorId': '1783043', 'name': 'S. Hyniewska'}, {'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
555,2e971101aa2db715c0436a002dba2997ec7d7f41,Students' Responses to a Humanlike Approach to Elicit Emotion in an Educational Virtual World,,2018.0,13.0,1.0,False,,{'pages': '291-295'},"{'bibtex': ""@Article{Ranjbartabar2018StudentsRT,\n author = {Hedieh Ranjbartabar and Deborah Richards and Anupam Makhija and M. Jacobson},\n booktitle = {International Conference on Artificial Intelligence in Education},\n pages = {291-295},\n title = {Students' Responses to a Humanlike Approach to Elicit Emotion in an Educational Virtual World},\n year = {2018}\n}\n""}","[{'authorId': '2788668', 'name': 'Hedieh Ranjbartabar'}, {'authorId': '144037536', 'name': 'Deborah Richards'}, {'authorId': '50825468', 'name': 'Anupam Makhija'}, {'authorId': '2299671', 'name': 'M. Jacobson'}]"
556,2e9d221c206e9503ceb452302d68d10e293f2a10,Long Short-Term Memory,"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.",1997.0,47.0,70615.0,False,,"{'volume': '9', 'pages': '1735-1780', 'name': 'Neural Computation'}","{'bibtex': '@Article{Hochreiter1997LongSM,\n author = {S. Hochreiter and J. Schmidhuber},\n journal = {Neural Computation},\n pages = {1735-1780},\n title = {Long Short-Term Memory},\n volume = {9},\n year = {1997}\n}\n'}","[{'authorId': '3308557', 'name': 'S. Hochreiter'}, {'authorId': '145341374', 'name': 'J. Schmidhuber'}]"
557,2ea93609216babae7f3a323089234e1305309037,Do emotional stimuli interfere with response inhibition? Evidence from the stop signal paradigm,"Participants performed a stop signal task in which an emotional picture preceded a neutral stimulus. They were asked to respond on the basis of the identity of the neutral stimulus unless an auditory tone was presented, in which case participants should try to withhold their response. In Experiment 1, we used positive, neutral and negative pictures. Results demonstrated that the presentation of an emotional stimulus prolonged both response and stopping latencies regardless of the valence of the emotional stimulus. This suggested that the degree of arousal could modulate the interference effect. In Experiment 2, high- and low-arousing pictures with a positive or negative valence were used. In line with the arousal hypothesis, high-arousal pictures interfered more with responding and stopping than low-arousing pictures whereas the valence of the pictures had little or no effect. These findings support the hypothesis that emotional stimuli interrupt ongoing cognitively controlled activities because they attract attention away from these ongoing activities.",2007.0,27.0,268.0,False,,"{'volume': '21', 'pages': '391 - 403', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Verbruggen2007DoES,\n author = {F. Verbruggen and J. de Houwer},\n journal = {Cognition and Emotion},\n pages = {391 - 403},\n title = {Do emotional stimuli interfere with response inhibition? Evidence from the stop signal paradigm},\n volume = {21},\n year = {2007}\n}\n'}","[{'authorId': '2157435', 'name': 'F. Verbruggen'}, {'authorId': '3602422', 'name': 'J. de Houwer'}]"
558,2ebbced3dd7d5806463079fa9080b420b3ed8520,Sentiment Analysis of Bangladesh-specific COVID-19 Tweets using Deep Neural Network,"Nowadays, social media became a tracker of the COVID-19 disease which reflects the status of the COVID-19 outbreak in the world. Although it is important to know the impact of COVID- 19 on the sentiment of mass people for the government and the policymakers in order to address peoples’ needs and take emergent decisions during such crisis time, not many studies have been conducted regarding this issue. Moreover, very few studies were conducted on sentiment analysis during the COVID-19 pandemic in the context of Bangladesh. The purpose of this study is to estimate the impact of the COVID-19 outbreak on the sentiment of the Bangladeshi people through a machine learning approach. To achieve this goal, COVID-19 tweets were collected over a specific period and then build a deep learning classifier, having an average area under the curve (AUC) of 0.76. The study analyzes the spread and estimates various public emotions during the outbreak. And reveals that a significant number (55%) of people had negative sentiment regarding COVID-19, whereas, 38% and 7% of people had positive and neutral sentiment respectively. This study also found that people’s involvement with social media increases as the number of active COVID-19 cases increases. Moreover, this study identified people’s sentiment towards some important concerns regarding the COVID-19 pandemic.",2021.0,0.0,5.0,False,,"{'pages': '1-6', 'name': '2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS)'}","{'bibtex': '@Article{Islam2021SentimentAO,\n author = {M. Islam and N. Khan and Ayon Roy and Md. Mahbubar Rahman and Saddam Hossain Mukta and A. K. M. Najmul Islam},\n journal = {2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS)},\n pages = {1-6},\n title = {Sentiment Analysis of Bangladesh-specific COVID-19 Tweets using Deep Neural Network},\n year = {2021}\n}\n'}","[{'authorId': '9256301', 'name': 'M. Islam'}, {'authorId': '2045331161', 'name': 'N. Khan'}, {'authorId': '49274455', 'name': 'Ayon Roy'}, {'authorId': '2116363360', 'name': 'Md. Mahbubar Rahman'}, {'authorId': '103171103', 'name': 'Saddam Hossain Mukta'}, {'authorId': '1478810924', 'name': 'A. K. M. Najmul Islam'}]"
559,2eda53312d39fabad8b6816a563c483ed85d37b1,Some Signals and Rules for Taking Speaking Turns in Conversations,"Studied the turn-taking mechanism, whereby participants manage the smooth and appropriate exchange of speaking turns in face-to-face interaction in 2 videotapes showing a therapist-patient interview and a discussion between 2 therapists. 3 basic signals were noted: (a) turn-yielding signals by the s",1972.0,19.0,1225.0,False,,"{'volume': '23', 'pages': '283-292', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Duncan1972SomeSA,\n author = {Starkey Duncan},\n journal = {Journal of Personality and Social Psychology},\n pages = {283-292},\n title = {Some Signals and Rules for Taking Speaking Turns in Conversations},\n volume = {23},\n year = {1972}\n}\n'}","[{'authorId': '48949057', 'name': 'Starkey Duncan'}]"
560,2eda7ede68dac52e32065c72fbdd6ae67da36e10,FUNDAMENTALS OF EEG MEASUREMENT,"Electroencephalographic measurements are commonly used in medical and research areas. This review article presents an introduction into EEG measurement. Its purpose is to help with orientation in EEG field and with building basic knowledge for performing EEG recordings. The article is divided into two parts. In the first part, background of the subject, a brief historical overview, and some EEG related research areas are given. The second part explains EEG recording. Modern medicine applies variety of imaging techniques of the human body. The group of electrobiological measurements comprises items as electrocardiography (ECG, heart), electromyography (EMG, muscular contractions), electroencephalography (EEG, brain), magnetoencephalography (MEG, brain), electrogastrography (EGG, stomach), electrooptigraphy (EOG, eye dipole field). Imaging techniques based on different physical principles include computer tomography (CT), magnetic resonance imaging (MRI), functional MRI (fMRI), positron emission tomography (PET), and single photon emission computed tomography (SPECT). Electroencephalography is a medical imaging technique that reads scalp electrical activity generated by brain structures. The electroencephalogram (EEG) is defined as electrical activity of an alternating type recorded from the scalp surface after being picked up by metal electrodes and conductive media (1). The EEG measured directly from the cortical surface is called electrocortiogram while when using depth probes it is called electrogram. In this article, we will refer only to EEG measured from the head surface. Thus electroencephalographic reading is a completely non-invasive procedure that can be applied repeatedly to patients, normal adults, and children with virtually no risk or limitation. When brain cells (neurons) are activated, local current flows are produced. EEG measures mostly the currents that flow during synaptic excitations of the dendrites of many pyramidal neurons in the cerebral cortex. Differences of electrical potentials are caused by summed postsynaptic graded potentials from pyramidal cells that create electrical dipoles between soma (body of neuron) and apical dendrites (neural branches). Brain electrical current consists mostly of Na+, K+, Ca++, and Cl- ions that are pumped through channels in neuron membranes in the direction governed by membrane potential (2). The detailed microscopic picture is more sophisticated, including different types of synapses involving variety of neurotransmitters. Only large populations of active neurons can generate electrical activity recordable on the head surface. Between electrode and neuronal layers current penetrates through skin, skull and several other layers. Weak electrical signals detected by the scalp electrodes are massively amplified, and then displayed on paper or stored to computer memory (3). Due to capability to reflect both the normal and abnormal electrical activity of the brain, EEG has been found to be a very powerful tool in the field of neurology and clinical neurophysiology. The human brain electric activity starts around the 17-23 week of prenatal development. It is assumed that at birth the full number of neural cells is already developed, roughly 10 11 neurons (4). This makes an average density of 10 4 neurons per cubic mm. Neurons are mutually connected into neural nets through synapses. Adults have about 500 trillion (5.10 14 ) synapses. The number of synapses per one neuron with age increases, however the number of neurons with age decreases, thus the total number of synapses decreases with age too. From the anatomical point of view, the brain can be divided into three sections: cerebrum, cerebellum, and brain stem. The cerebrum consists of left and right hemisphere with highly convoluted surface layer called cerebral cortex. The cortex is a",2002.0,17.0,1561.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Teplan2002FUNDAMENTALSOE,\n author = {M. Teplan},\n title = {FUNDAMENTALS OF EEG MEASUREMENT},\n year = {2002}\n}\n'}","[{'authorId': '1860856', 'name': 'M. Teplan'}]"
561,2f0ee4567e99f0e417550892ff864f3632415c7d,Evaluating the Effect of Gesture and Language on Personality Perception in Conversational Agents,,2010.0,40.0,130.0,True,"{'url': 'http://www.cs.ucdavis.edu/%7Eneff/papers/extraversion_final_PRE_PRINT.pdf', 'status': None}",{'pages': '222-235'},"{'bibtex': '@Inproceedings{Neff2010EvaluatingTE,\n author = {Michael Neff and Yingying Wang and Rob Abbott and M. Walker},\n pages = {222-235},\n title = {Evaluating the Effect of Gesture and Language on Personality Perception in Conversational Agents},\n year = {2010}\n}\n'}","[{'authorId': '143687087', 'name': 'Michael Neff'}, {'authorId': '145215255', 'name': 'Yingying Wang'}, {'authorId': '39764052', 'name': 'Rob Abbott'}, {'authorId': '2234088162', 'name': 'M. Walker'}]"
562,2f23b87170a860f984d38ec96e09e1bfd20e3a67,Augmented Reality in Educational Inclusion. A Systematic Review on the Last Decade,"The use of Augmented Reality (AR) to achieve educational inclusion has been not deeply explored. This systematic review describes the current state of using AR as an educational technology that takes into consideration the needs of all students including those with a disability. It is done through the analysis of factors, such as the advantages of AR, its limitations, uses, challenges, its scope in the educational field, the attended population and the positive or negative effects of its use in learning scenarios that involve students with diverse educational needs. A total of 50 studies between 2008 and 2018 were analyzed through searching in three interdisciplinary databases: Scopus, Web of Science, and Springer link. For this, the methodological stages considered were planning the review, search, analysis of literature and results report. After analyzing the results, it was possible to demonstrate that the use of AR for inclusive education in the field of sciences is where more studies have been conducted. In regard to the population with disabilities, among the most representative advantages reported were the motivation, interaction and generating interest on the part of the student. At the same time, an important methodological limitation identified was the size of the sample; some investigations were done with two or three subjects, some studies Single Subject Designs were found. In terms of the population attended, the studies generally included students with different impairments (hearing, visual, motor or cognitive), minorities (ethnic, vulnerable), leaving aside other groups excluded as exceptional talents and immigrants, which could be explored in the future. Despite different problems to be addressed, few frameworks to the diversity attention in education were reported, and there was no model and methodology in inclusive education considered in the studies. Finally, from this review we have identified open issues that could give rise to new research in the subject of using AR to favor the creation of inclusive learning scenarios.",2019.0,94.0,88.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.01835/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Quintero2019AugmentedRI,\n author = {Jairo Quintero and S. Baldiris and R. Rubira and Jhoni Cerón and Gloria Vélez},\n journal = {Frontiers in Psychology},\n title = {Augmented Reality in Educational Inclusion. A Systematic Review on the Last Decade},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '2057637451', 'name': 'Jairo Quintero'}, {'authorId': '1728461', 'name': 'S. Baldiris'}, {'authorId': '10377566', 'name': 'R. Rubira'}, {'authorId': '152740360', 'name': 'Jhoni Cerón'}, {'authorId': '120193213', 'name': 'Gloria Vélez'}]"
563,2f3563bf21116a2332451532d486cd195fda316f,Measures of Individual Differences in Temperament,"Reliability and validity data are presented for three orthogonal measures of temperament: trait-pleasure, trait-arousal, and trait-dominance. The KR-20 reliability coefficients for the three scales were .91, .60, and .84, respectively. Intercorrelations among the three scales were insignificant and low. Thus, the expectation that these three measures could be used as a parsimonious base for the description of temperament was confirmed. The trait-pleasure scale was correlated positively with measures of social desirability, achieving tendency, extroversion, and affiliative tendency, and was correlated negatively with measures of trait-anxiety, neuroticism, and aggression. The trait-arousal scale was not related to the social desirability scale, and was correlated positively with measures of trait-anxiety, neuroticism, and aggression. The trait-dominance scale was also free of social desirability bias. It exhibited positive correlations with measures of dominance-submissiveness, autonomy, extroversion, achieving tendency, and aggression, and negative correlations with measures of trait-anxiety and neuroticism.",1978.0,22.0,72.0,False,,"{'volume': '38', 'pages': '1105 - 1117', 'name': 'Educational and Psychological Measurement'}","{'bibtex': '@Article{Mehrabian1978MeasuresOI,\n author = {A. Mehrabian},\n journal = {Educational and Psychological Measurement},\n pages = {1105 - 1117},\n title = {Measures of Individual Differences in Temperament},\n volume = {38},\n year = {1978}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}]"
564,2f36a05985fa13ff2e555215a8049a4212eb5a34,Guidelines for Designing Computational Models of Emotions,"Rapid growth in computational modeling of emotion and cognitive-affective architectures occurred over the past 15 years. Emotion models and architectures are built to elucidate the mechanisms of emotions and enhance believability and effectiveness of synthetic agents and robots. Despite the many emotion models developed to date, a lack of consistency and clarity regarding what exactly it means to 'model emotions' persists. There are no systematic guidelines for development of computational models of emotions. This paper deconstructs the often vague term 'emotion modeling' by suggesting the view of emotion models in terms of two fundamental categories of processes: emotion generation and emotion effects. Computational tasks necessary to implement these processes are also identified. The paper addresses how computational building blocks provide a basis for the development of more systematic guidelines for affective model development. The paper concludes with a description of an affective requirements analysis and design process for developing affective computational models in agent architectures.",2011.0,92.0,133.0,False,,"{'volume': '2', 'pages': '26-79', 'name': 'Int. J. Synth. Emot.'}","{'bibtex': '@Article{Hudlicka2011GuidelinesFD,\n author = {E. Hudlicka},\n journal = {Int. J. Synth. Emot.},\n pages = {26-79},\n title = {Guidelines for Designing Computational Models of Emotions},\n volume = {2},\n year = {2011}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
566,2f40843c695a75917c766e3a0b9efd183f4cf890,BDI agents in social simulations: a survey,"Abstract Modelling and simulation have long been dominated by equation-based approaches, until the recent advent of agent-based approaches. To curb the resulting complexity of models, Axelrod promoted the KISS principle: ‘Keep It Simple, Stupid’. But the community is divided and a new principle appeared: KIDS, ‘Keep It Descriptive, Stupid’. Richer models were thus developed for a variety of phenomena, while agent cognition still tends to be modelled with simple reactive particle-like agents. This is not always appropriate, in particular in the social sciences trying to account for the complexity of human behaviour. One solution is to model humans as belief, desire and intention (BDI) agents, an expressive paradigm using concepts from folk psychology, making it easier for modellers and users to understand the simulation. This paper provides a methodological guide to the use of BDI agents in social simulations, and an overview of existing methodologies and tools for using them.",2016.0,190.0,98.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-01484960/file/adam_17127.pdf', 'status': None}","{'volume': '31', 'pages': '207 - 238', 'name': 'The Knowledge Engineering Review'}","{'bibtex': '@Article{Adam2016BDIAI,\n author = {C. Adam and B. Gaudou},\n journal = {The Knowledge Engineering Review},\n pages = {207 - 238},\n title = {BDI agents in social simulations: a survey},\n volume = {31},\n year = {2016}\n}\n'}","[{'authorId': '2236335', 'name': 'C. Adam'}, {'authorId': '1735938', 'name': 'B. Gaudou'}]"
567,2f53c93c83c322137cbf1ebd8adbfc3121a97caf,"Telerobotics, Automation, and Human Supervisory Control","Theory and models of supervisory control - frameworks and fragments supervisory control of anthropomorphic teleoperators for space, undersea, and other applications supervisory control in transportation, process, and other automated systems social implications of telerobotics, automation, and supervisory control.",2003.0,0.0,1729.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sheridan2003TeleroboticsAA,\n author = {T. Sheridan},\n title = {Telerobotics, Automation, and Human Supervisory Control},\n year = {2003}\n}\n'}","[{'authorId': '1712194', 'name': 'T. Sheridan'}]"
568,2f614c29d03090dd26f91d06573f5df8bd83ae1d,An introduction to the five-factor model and its applications.,"The five-factor model of personality is a hierarchical organization of personality traits in terms of five basic dimensions: Extraversion, Agreeableness, Conscientiousness, Neuroticism, and Openness to Experience. Research using both natural language adjectives and theoretically based personality questionnaires supports the comprehensiveness of the model and its applicability across observers and cultures. This article summarizes the history of the model and its supporting evidence; discusses conceptions of the nature of the factors; and outlines an agenda for theorizing about the origins and operation of the factors. We argue that the model should prove useful both for individual assessment and for the elucidation of a number of topics of interest to personality psychologists.",1992.0,141.0,6129.0,True,"{'url': 'http://psych.colorado.edu/~carey/courses/psyc5112/readings/psnbig5_mccrae03.pdf', 'status': None}","{'volume': '60 2', 'pages': '\n          175-215\n        ', 'name': 'Journal of personality'}","{'bibtex': '@Article{McCrae1992AnIT,\n author = {R. McCrae and O. John},\n journal = {Journal of personality},\n pages = {\n          175-215\n        },\n title = {An introduction to the five-factor model and its applications.},\n volume = {60 2},\n year = {1992}\n}\n'}","[{'authorId': '6206591', 'name': 'R. McCrae'}, {'authorId': '2254103', 'name': 'O. John'}]"
571,2f72169bc5f6d8ddad8c8463d139233fcee17468,What Novels Can Do That Films Can't (And Vice Versa),"The study of narrative has become so popular that the French have honored it with a term-la narratologie. Given the escalating and sophisticated literature on the subject, its English counterpart, ""narratology,"" may not be as risible as it sounds. Modern narratology combines two powerful intellectual trends: the Anglo-American inheritance of Henry James, Percy Lubbock, E. M. Forster, and Wayne Booth; and the mingling of Russian formalist (Viktor Shklovsky, Boris Eichenbaum, Roman Jakobson, and Vladimir Propp) with French structuralist approaches (Claude Levi-Strauss, Roland Barthes, Gerard Genette, and Tzvetan Todorov). It's not accidental that narratology has developed during a period in which linguistics and cinema theory have also flourished. Linguistics, of course, is one basis for the field now called semiotics-the study of all meaning systems, not only natural language. Another basis is the work of the philosopher Charles S. Peirce and his continuator, Charles W. Morris. These trees have borne elegant fruit: we read fascinating semiotic analyses of facial communication, body language, fashion, the circus, architecture, and gastronomy. The most vigorous, if controversial, branch of cinema studies, the work of Christian Metz, is also semiotically based. One of the most important observations to come out of narratology is that narrative itself is a deep structure quite independent of its medium. In other words, narrative is basically a kind of text organization, and that organization, that schema, needs to be actualized: in written words, as in stories and novels; in spoken words combined with the movements of actors imitating characters against sets which imitate",1980.0,0.0,235.0,False,,"{'volume': '7', 'pages': '121 - 140', 'name': 'Critical Inquiry'}","{'bibtex': ""@Article{Chatman1980WhatNC,\n author = {S. Chatman},\n journal = {Critical Inquiry},\n pages = {121 - 140},\n title = {What Novels Can Do That Films Can't (And Vice Versa)},\n volume = {7},\n year = {1980}\n}\n""}","[{'authorId': '103558925', 'name': 'S. Chatman'}]"
572,2fc6f1201b291dfe7276699f5753dc42cc6175aa,Children's recognition of emotions from vocal cues.,"Emotional cues contain important information about the intentions and feelings of others. Despite a wealth of research into children's understanding of facial signals of emotions, little research has investigated the developmental trajectory of interpreting affective cues in the voice. In this study, 48 children ranging between 5 and 10 years were tested using forced-choice tasks with non-verbal vocalizations and emotionally inflected speech expressing different positive, neutral and negative states. Children as young as 5 years were proficient in interpreting a range of emotional cues from vocal signals. Consistent with previous work, performance was found to improve with age. Furthermore, the two tasks, examining recognition of non-verbal vocalizations and emotionally inflected speech, respectively, were sensitive to individual differences, with high correspondence of performance across the tasks. From this demonstration of children's ability to recognize emotions from vocal stimuli, we also conclude that this auditory emotion recognition task is suitable for a wide age range of children, providing a novel, empirical way to investigate children's affect recognition skills.",2013.0,66.0,98.0,True,"{'url': 'https://pure.uva.nl/ws/files/1373801/109943_SauterEtAl2012BJDP.pdf', 'status': None}","{'volume': '31 Pt 1', 'pages': '\n          97-113\n        ', 'name': 'The British journal of developmental psychology'}","{'bibtex': ""@Article{Sauter2013ChildrensRO,\n author = {D. Sauter and Charlotte Panattoni and F. Happé},\n journal = {The British journal of developmental psychology},\n pages = {\n          97-113\n        },\n title = {Children's recognition of emotions from vocal cues.},\n volume = {31 Pt 1},\n year = {2013}\n}\n""}","[{'authorId': '2091778', 'name': 'D. Sauter'}, {'authorId': '49248922', 'name': 'Charlotte Panattoni'}, {'authorId': '4263634', 'name': 'F. Happé'}]"
573,2fcb530b7dcd8f6b3b94b9cd4a97b5afcdcd5b2a,Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection,"Emotions are time varying affective phenomena that are elicited as a result of stimuli. Videos and movies in particular are made to elicit emotions in their audiences. Detecting the viewers' emotions instantaneously can be used to find the emotional traces of videos. In this paper, we present our approach in instantaneously detecting the emotions of video viewers' emotions from electroencephalogram (EEG) signals and facial expressions. A set of emotion inducing videos were shown to participants while their facial expressions and physiological responses were recorded. The expressed valence (negative to positive emotions) in the videos of participants' faces were annotated by five annotators. The stimuli videos were also continuously annotated on valence and arousal dimensions. Long-short-term-memory recurrent neural networks (LSTM-RNN) and continuous conditional random fields (CCRF) were utilized in detecting emotions automatically and continuously. We found the results from facial expressions to be superior to the results from EEG signals. We analyzed the effect of the contamination of facial muscle activities on EEG signals and found that most of the emotionally valuable content in EEG features are as a result of this contamination. However, our statistical analysis showed that EEG signals still carry complementary information in presence of facial expressions.",2016.0,51.0,391.0,True,,"{'volume': '7', 'pages': '17-28', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Soleymani2016AnalysisOE,\n author = {M. Soleymani and Sadjad Asghari-Esfeden and Y. Fu and M. Pantic},\n journal = {IEEE Transactions on Affective Computing},\n pages = {17-28},\n title = {Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection},\n volume = {7},\n year = {2016}\n}\n'}","[{'authorId': '152714397', 'name': 'M. Soleymani'}, {'authorId': '1398447065', 'name': 'Sadjad Asghari-Esfeden'}, {'authorId': '46956675', 'name': 'Y. Fu'}, {'authorId': '145387780', 'name': 'M. Pantic'}]"
574,2fcb759731e2d72d742b17c5e7fdf96650791674,Building a Character Animation System,,2011.0,12.0,109.0,True,"{'url': 'http://www.arishapiro.com/Building_Animation_Shapiro.pdf', 'status': None}",{'pages': '98-109'},"{'bibtex': '@Inproceedings{Shapiro2011BuildingAC,\n author = {Ari Shapiro},\n pages = {98-109},\n title = {Building a Character Animation System},\n year = {2011}\n}\n'}","[{'authorId': '145109163', 'name': 'Ari Shapiro'}]"
575,2fee316f2f9acba12bbd7d19721ec1546c4539b5,Gamifying learning experiences: Practical implications and outcomes,,2013.0,34.0,1460.0,False,,"{'volume': '63', 'pages': '380-392', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Domínguez2013GamifyingLE,\n author = {A. Domínguez and Joseba Saenz-de-Navarrete and Luis de Marcos and Luis Fernández Sanz and Carmen Pagés-Arévalo and José-Javier Martínez},\n journal = {Comput. Educ.},\n pages = {380-392},\n title = {Gamifying learning experiences: Practical implications and outcomes},\n volume = {63},\n year = {2013}\n}\n'}","[{'authorId': '152921932', 'name': 'A. Domínguez'}, {'authorId': '1406535051', 'name': 'Joseba Saenz-de-Navarrete'}, {'authorId': '1807504', 'name': 'Luis de Marcos'}, {'authorId': '2057625402', 'name': 'Luis Fernández Sanz'}, {'authorId': '1398180044', 'name': 'Carmen Pagés-Arévalo'}, {'authorId': '2109798228', 'name': 'José-Javier Martínez'}]"
576,30009a385847c5af26c103adc8d10b56d9159713,Introduction to self-attachment and its neural basis,"We introduce the notion of self-attachment which, based on an interdisciplinary set of concepts, proposes a new psychotherapeutic technique. The underlying ideas include findings and paradigms in developmental psychology and neuroscience, neuroplasticity and long term term potentiation, fMRI studies on human bond making and religious experience, and experiments in energy based artificial neural networks. The proposed self-attachment therapeutic technique is distinguished by its intervention to create an internal and passionate affectional bond within the individual between the “adult self”, representing the logical and cognitive faculty, and the “inner child”, representing the unregulated and undeveloped emotional circuits. The aim is to create more optimal circuits for emotional regulation. The proposed self-attachment protocols internally emulate within the individual the interactions of a good enough primary care-giver and child in order to moderate the child's arousal level, minimise its negative affects and maximize its positive affects. These interactions are assumed, in developmental neuroscience and in developmental psychology, to be the basis of secure attachment of children with their parents, which leads to an optimal regulation of neurotransmitters, hormones, and the emotional dynamics of the individual. We report on several case studies of this technique in recent years. Finally, we propose a simple mathematical model to capture the impact of self-attachment protocols using the notion of strong patterns in energy based neural networks and employ a recently developed mathematical model to examine the impact of self-attachment using emotional and cognitive neural pathways for decision making.",2015.0,71.0,19.0,True,"{'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/23809/2/self-attachment.pdf', 'status': None}","{'pages': '1-8', 'name': '2015 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Edalat2015IntroductionTS,\n author = {A. Edalat},\n journal = {2015 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {Introduction to self-attachment and its neural basis},\n year = {2015}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}]"
579,30066fd55802d295974e28bd1d763af37762fc2f,Investigating the influence of embodiment on facial mimicry in HRI using computer vision-based measures,"Mimicry plays an important role in social interaction. In human communication, it is used to establish rapport and bonding both with other humans, as well as robots and virtual characters. However, little is known about the underlying factors that elicit mimicry in humans when interacting with a robot. In this work, we study the influence of embodiment on participants' ability to mimic a social character. Participants were asked to intentionally mimic the laughing behavior of the Furhat mixed embodied robotic head and a 2D virtual version of the same character. To explore the effect of embodiment, we present two novel approaches to automatically assess people's ability to mimic based solely on videos of their facial expressions. In contrast to participants' self-assessment, the analysis of video recordings suggests a better ability to mimic when people interact with the 2D embodiment.",2017.0,32.0,3.0,False,,"{'pages': '579-586', 'name': '2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)'}","{'bibtex': '@Article{Paetzel2017InvestigatingTI,\n author = {Maike Paetzel and G. Varni and Isabelle Hupont Torres and M. Chetouani and Christopher E. Peters and Ginevra Castellano},\n journal = {2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {579-586},\n title = {Investigating the influence of embodiment on facial mimicry in HRI using computer vision-based measures},\n year = {2017}\n}\n'}","[{'authorId': '2710492', 'name': 'Maike Paetzel'}, {'authorId': '1958033', 'name': 'G. Varni'}, {'authorId': '32595768', 'name': 'Isabelle Hupont Torres'}, {'authorId': '1680828', 'name': 'M. Chetouani'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
580,30322f795de22fc6af6ae169549608f7cf816f44,Processing of unattended emotional visual scenes.,"Prime pictures of emotional scenes appeared in parafoveal vision, followed by probe pictures either congruent or incongruent in affective valence. Participants responded whether the probe was pleasant or unpleasant (or whether it portrayed people or animals). Shorter latencies for congruent than for incongruent prime-probe pairs revealed affective priming. This occurred even when visual attention was focused on a concurrent verbal task and when foveal gaze-contingent masking prevented overt attention to the primes but only if these had been preexposed and appeared in the left visual field. The preexposure and laterality patterns were different for affective priming and semantic category priming. Affective priming was independent of the nature of the task (i.e., affective or category judgment), whereas semantic priming was not. The authors conclude that affective processing occurs without overt attention--although it is dependent on resources available for covert attention--and that prior experience of the stimulus is required and right-hemisphere dominance is involved.",2007.0,76.0,99.0,False,,"{'volume': '136 3', 'pages': '\n          347-69\n        ', 'name': 'Journal of experimental psychology. General'}","{'bibtex': '@Article{Calvo2007ProcessingOU,\n author = {M. Calvo and L. Nummenmaa},\n journal = {Journal of experimental psychology. General},\n pages = {\n          347-69\n        },\n title = {Processing of unattended emotional visual scenes.},\n volume = {136 3},\n year = {2007}\n}\n'}","[{'authorId': '144866673', 'name': 'M. Calvo'}, {'authorId': '2036051', 'name': 'L. Nummenmaa'}]"
581,305a0ff88a70b49f745e95bd5ef004a33f5afc4a,Basic Emotions,"determining not only that they pertain to emotion, but to which emotion . . . Appraisal is not always automatic. Sometimes the evaluation of what is happening is slow, deliberate and conscious. With such a more extended appraisal there may be some autonomic arousal, but perhaps not of a kind which is differentiated. The person could be said to be aroused or alerted, but no specific emotion is operative. Cognition plays the important role in determining what will transpire. During such extended appraisal the evaluation may match to the selective filters of the automatic appraiser . . . . It need not be, however; the experience may be diffuse rather than specific to one emotion” (pp. 58—59).",2004.0,52.0,1950.0,False,,,"{'bibtex': '@Inproceedings{Dalgleish2004BasicE,\n author = {T. Dalgleish},\n title = {Basic Emotions},\n year = {2004}\n}\n'}","[{'authorId': '2193978', 'name': 'T. Dalgleish'}]"
583,30756b1e2932c367b6f252ae5dba151bf9ca8952,The use of a virtual reality training system to improve technical skill in the maintenance of live-line power distribution networks,"ABSTRACT The application of virtual reality (VR) technologies is beneficial to the training related to industrial processes. Mainly because the technologies allow training complex threatening tasks within a safe environment. The interactive three-dimensional (3D) representation of a real world seems to be a more effective learning medium than other traditional tools. This paper presents the development and implementation of a training environment based on VR, applied to the maintenance of medium-tension overhead live-lines in power distribution networks. The architecture of the virtual environment includes three main components: the virtual warehouse of equipment, materials and tools; the interactive 3D environments; and a course management system. The system consists of 43 maintenance maneuvers, including the application of different techniques and equipment. It has three operation modes: learning, practice, and evaluation, which can be accessed according to the trainee’s level of knowledge. The virtual environment is currently used to support training of thousands of power line operators with excellent results. The aim of the system is to improve the technical skills of operators and minimize safety risks while operating power distribution networks. The system has allowed a substantial reduction of the accident rates during live-line maintenance.",2019.0,58.0,21.0,False,,"{'volume': '29', 'pages': '527 - 544', 'name': 'Interactive Learning Environments'}","{'bibtex': '@Article{Pérez-Ramírez2019TheUO,\n author = {Miguel Pérez-Ramírez and G. Arroyo-Figueroa and A. Ayala},\n journal = {Interactive Learning Environments},\n pages = {527 - 544},\n title = {The use of a virtual reality training system to improve technical skill in the maintenance of live-line power distribution networks},\n volume = {29},\n year = {2019}\n}\n'}","[{'authorId': '1401994903', 'name': 'Miguel Pérez-Ramírez'}, {'authorId': '1403074131', 'name': 'G. Arroyo-Figueroa'}, {'authorId': '145193569', 'name': 'A. Ayala'}]"
584,30c2cb79b0f09febec610276834cdd3cf2eebde9,Introducing human-computer interaction: A didactic experience,"Experts on human-computer interaction (HCI) are required to establish communication media for a broad variety of users in consequence of the expanding services offered to the market and the changing technology landscapes. Software developers need suitable criteria to handle computer interfaces because of the diversity within the `digital population' and it seems natural that educators should answer the professional questions posed by software designers. In this paper we report on the experience of a vocational course on object-oriented design, which - among other topics - provides professional criteria to students who are required to plan a large assortment of computer interfaces from panels to object lists, from animated images to social web pages. In the first stage, lessons on HCI illustrate the psychological portraits of computer users. Second, the lessons deduce practical guidelines from those profiles. Finally the students learn the technical contents regarding HCI design. The concise psychological and social criteria which guide the students to prepare the visual interfaces constitute the innovative contribution of the present work at the didactic level. The initial lessons on HCI go beyond mere technical training and it may be said that they improve the professional culture of students. The feedback from participants appeared very positive.",2016.0,21.0,3.0,False,,"{'pages': '992-996', 'name': '2016 IEEE Global Engineering Education Conference (EDUCON)'}","{'bibtex': '@Article{Rocchi2016IntroducingHI,\n author = {P. Rocchi},\n journal = {2016 IEEE Global Engineering Education Conference (EDUCON)},\n pages = {992-996},\n title = {Introducing human-computer interaction: A didactic experience},\n year = {2016}\n}\n'}","[{'authorId': '34088340', 'name': 'P. Rocchi'}]"
585,30ef8f7cc73fac8c678fc8e8925f316f78079b15,Development of a virtual agent based social tutor for children with autism spectrum disorders,"Virtual agents have been investigated as an educational tool for use with children on the autistic spectrum with positive results being gained for language skills with the use of autonomous agents and social skills with human-controlled agents. This project combines these ideas to investigate the utility of autonomous agents for teaching social skills. The virtual agent used in this project, known as the Thinking Head, has an ability to realistically portray facial expressions that lends it to this task. Two prototype modules were developed for this agent platform, one teaching basic conversation skills and the other dealing with bullying. In a pre-test-post-test evaluation, a group of children with autism who were exposed to the training modules obtained significantly higher post-test scores on their knowledge of these two topics. In addition, responses to a post-training survey indicated that participants found the virtual tutor enjoyable and useful.",2010.0,20.0,53.0,True,"{'url': 'https://dspace.flinders.edu.au/xmlui/bitstream/2328/25739/1/Milne%20Development.pdf', 'status': None}","{'pages': '1-9', 'name': 'The 2010 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Milne2010DevelopmentOA,\n author = {Marissa Milne and M. Luerssen and T. Lewis and Richard Leibbrandt and D. Powers},\n journal = {The 2010 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-9},\n title = {Development of a virtual agent based social tutor for children with autism spectrum disorders},\n year = {2010}\n}\n'}","[{'authorId': '26530439', 'name': 'Marissa Milne'}, {'authorId': '1776457', 'name': 'M. Luerssen'}, {'authorId': '145111765', 'name': 'T. Lewis'}, {'authorId': '2323617', 'name': 'Richard Leibbrandt'}, {'authorId': '144871539', 'name': 'D. Powers'}]"
586,30ff7845c8b0de24f8e494b815f3041feeb508d4,3D Constrained Local Model for rigid and non-rigid facial tracking,"We present 3D Constrained Local Model (CLM-Z) for robust facial feature tracking under varying pose. Our approach integrates both depth and intensity information in a common framework. We show the benefit of our CLM-Z method in both accuracy and convergence rates over regular CLM formulation through experiments on publicly available datasets. Additionally, we demonstrate a way to combine a rigid head pose tracker with CLM-Z that benefits rigid head tracking. We show better performance than the current state-of-the-art approaches in head pose tracking with our extension of the generalised adaptive view-based appearance model (GAVAM).",2012.0,33.0,315.0,False,,"{'pages': '2610-2617', 'name': '2012 IEEE Conference on Computer Vision and Pattern Recognition'}","{'bibtex': '@Article{Baltrušaitis20123DCL,\n author = {T. Baltrušaitis and P. Robinson and Louis-Philippe Morency},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {2610-2617},\n title = {3D Constrained Local Model for rigid and non-rigid facial tracking},\n year = {2012}\n}\n'}","[{'authorId': '1756344', 'name': 'T. Baltrušaitis'}, {'authorId': '2149814967', 'name': 'P. Robinson'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
587,30ffee716e80cebab7f169b3a4fd8ce307417b7e,Addressing the COVID-19 Pandemic in Populations With Serious Mental Illness.,"The coronavirus disease 2019 (COVID-19) pandemic will present an unprecedented stressor to patients and health care systems across the globe. Because there is currently no vaccine or treatment for the underlying infection, current health efforts are focused on providing prevention and screening, maintaining continuity of treatment for other chronic conditions, and ensuring access to appropriately intensive services for those with the most severe symptoms.1 Disasters disproportionately affect poor and vulnerable populations, and patients with serious mental illness may be among the hardest hit. High rates of smoking in this population may raise the risk of infection and confer a worse prognosis among those who develop the illness.2 Residential instability and homelessness can raise the risk of infection and make it harder to identify, follow up, and treat those who are infected.3 Individuals with serious mental illnesses who are employed may have challenges taking time off from work and may lack sufficient insurance coverage to cover testing or treatment. Small social networks may limit opportunities to obtain support from friends and family members should individuals with serious mental illness become ill. Taken together, these factors may lead to elevated infection rates and worse prognoses in this population. What strategies are available to mitigate the outcome of this epidemic among patients with serious mental illness? Federal preparedness policies developed in the wake of complex disasters have increasingly embraced the notion of whole community preparedness, which supports building and supporting structures at multiple levels to prepare and respond, particularly for vulnerable populations.4 Within the public mental health care system, this includes engagement with mental health service users, clinicians, and federal and state policies.",2020.0,5.0,371.0,False,,{'name': 'JAMA psychiatry'},"{'bibtex': '@Article{Druss2020AddressingTC,\n author = {B. Druss},\n journal = {JAMA psychiatry},\n title = {Addressing the COVID-19 Pandemic in Populations With Serious Mental Illness.},\n year = {2020}\n}\n'}","[{'authorId': '5265093', 'name': 'B. Druss'}]"
589,3108f96f80d129036f53684344f4058257b37c4b,DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset,"We develop a high-quality multi-turn dialog dataset, DailyDialog, which is intriguing in several aspects. The language is human-written and less noisy. The dialogues in the dataset reflect our daily communication way and cover various topics about our daily life. We also manually label the developed dataset with communication intention and emotion information. Then, we evaluate existing approaches on DailyDialog dataset and hope it benefit the research field of dialog systems. The dataset is available on http://yanran.li/dailydialog",2017.0,32.0,953.0,False,,"{'volume': 'abs/1710.03957', 'name': 'ArXiv'}","{'bibtex': '@Article{Li2017DailyDialogAM,\n author = {Yanran Li and Hui Su and Xiaoyu Shen and Wenjie Li and Ziqiang Cao and Shuzi Niu},\n journal = {ArXiv},\n title = {DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},\n volume = {abs/1710.03957},\n year = {2017}\n}\n'}","[{'authorId': '3305402', 'name': 'Yanran Li'}, {'authorId': '2087042666', 'name': 'Hui Su'}, {'authorId': '2562211', 'name': 'Xiaoyu Shen'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '2314396', 'name': 'Ziqiang Cao'}, {'authorId': '2944201', 'name': 'Shuzi Niu'}]"
591,31099f28cae1655003d1a97dcbaf52c3796933e7,Neuropsychological aspects of facial asymmetry during emotional expression: A review of the normal adult literature,,1997.0,130.0,149.0,False,,"{'volume': '7', 'pages': '41-60', 'name': 'Neuropsychology Review'}","{'bibtex': '@Article{Borod1997NeuropsychologicalAO,\n author = {J. Borod and C. S. Haywood and E. Koff},\n journal = {Neuropsychology Review},\n pages = {41-60},\n title = {Neuropsychological aspects of facial asymmetry during emotional expression: A review of the normal adult literature},\n volume = {7},\n year = {1997}\n}\n'}","[{'authorId': '3149424', 'name': 'J. Borod'}, {'authorId': '48742934', 'name': 'C. S. Haywood'}, {'authorId': '5126201', 'name': 'E. Koff'}]"
592,31295108ff1159f5a6ef4ab0eff56d1346af351d,"Opinion TRENDS in Cognitive Sciences Vol.10 No.10 The empathic brain: how, when and why?",,,0.0,1497.0,False,,,"{'bibtex': '@Misc{None,\n title = {Opinion TRENDS in Cognitive Sciences Vol.10 No.10 The empathic brain: how, when and why?}\n}\n'}",[]
593,314b9ab8907b6cfadde09cf9b791dcd949fd8bae,Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders,,2006.0,22.0,1613.0,True,"{'url': 'https://europepmc.org/articles/pmc3713227?pdf=render', 'status': None}","{'volume': '9', 'pages': '28-30', 'name': 'Nature Neuroscience'}","{'bibtex': '@Article{Dapretto2006UnderstandingEI,\n author = {M. Dapretto and M. S. Davies and Jennifer H. Pfeifer and A. Scott and M. Sigman and S. Bookheimer and M. Iacoboni},\n journal = {Nature Neuroscience},\n pages = {28-30},\n title = {Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders},\n volume = {9},\n year = {2006}\n}\n'}","[{'authorId': '2662420', 'name': 'M. Dapretto'}, {'authorId': '153563259', 'name': 'M. S. Davies'}, {'authorId': '2668019', 'name': 'Jennifer H. Pfeifer'}, {'authorId': '40126709', 'name': 'A. Scott'}, {'authorId': '152510948', 'name': 'M. Sigman'}, {'authorId': '144156653', 'name': 'S. Bookheimer'}, {'authorId': '1770382', 'name': 'M. Iacoboni'}]"
594,3159dc207966290c624d3868cf878a83ff8fb53e,Your presence soothes me: a neural process model of aversive emotion regulation via social buffering,"Abstract The reduction of aversive emotions by a conspecific’s presence—called social buffering—is a universal phenomenon in the mammalian world and a powerful form of human social emotion regulation. Animal and human studies on neural pathways underlying social buffering typically examined physiological reactions or regional brain activations. However, direct links between emotional and social stimuli, distinct neural processes and behavioural outcomes are still missing. Using data of 27 female participants, the current study delineated a large-scale process model of social buffering’s neural underpinnings, connecting changes in neural activity to emotional behaviour by means of voxel-wise multilevel mediation analysis. Our results confirmed that three processes underlie human social buffering: (i) social support-related reduction of activity in the orbitofrontal cortex, ventromedial and dorsolateral prefrontal cortices, anterior and mid-cingulate; (ii) downregulation of aversive emotion-induced brain activity in the superficial cortex-like amygdala and mediodorsal thalamus; and (iii) downregulation of reported aversive feelings. Results of the current study provide evidence for a distinct neural process model of aversive emotion regulation in humans by social buffering.",2020.0,57.0,8.0,True,"{'url': 'https://academic.oup.com/scan/article-pdf/15/5/561/33450991/nsaa068.pdf', 'status': None}","{'volume': '15', 'pages': '561 - 570', 'name': 'Social Cognitive and Affective Neuroscience'}","{'bibtex': '@Article{Bratec2020YourPS,\n author = {Satja Mulej Bratec and Teresa Bertram and G. Starke and F. Brandl and Xiyao Xie and C. Sorg},\n journal = {Social Cognitive and Affective Neuroscience},\n pages = {561 - 570},\n title = {Your presence soothes me: a neural process model of aversive emotion regulation via social buffering},\n volume = {15},\n year = {2020}\n}\n'}","[{'authorId': '7775987', 'name': 'Satja Mulej Bratec'}, {'authorId': '2067212278', 'name': 'Teresa Bertram'}, {'authorId': '1751526633', 'name': 'G. Starke'}, {'authorId': '39741194', 'name': 'F. Brandl'}, {'authorId': '2141704', 'name': 'Xiyao Xie'}, {'authorId': '14505378', 'name': 'C. Sorg'}]"
595,315a63fb7fc3d56feb4d9e2d32fc631dc62d909d,"Prevalence, neurobiology, and treatments for apathy in prodromal dementia","ABSTRACT Background: Apathy, characterized by diminished motivation, is a highly prevalent neuropsychiatric symptom in dementia. However, there is a substantial knowledge gap with regard to prevalence rates, neurobiological underpinnings, and effective treatments for apathy in pre-dementia states, including mild cognitive impairment (MCI) and mild behavioral impairment (MBI). Methods: We conducted a comprehensive literature search using MEDLINE, Embase, and PsycINFO databases to identify available research on apathy in prodromal dementia. Results: Apathy has consistently been detected in individuals with MCI with varying prevalence rates, and only recently has literature discussed the prevalence of apathy in MBI. Few pharmacological treatments have been utilized for apathy, with galantamine and risperidone showing mild reductions in apathetic behaviors. Non-pharmacological interventions in prodromal dementia are beginning to be explored and show promise, but few studies have replicated those results. Discussion: More comprehensive guidelines for diagnosing apathy and further research investigating neurobiological mechanisms of apathy in MCI and MBI are required in order to effectively treat apathetic patients in prodromal dementia.",2017.0,64.0,40.0,False,,"{'volume': '30', 'pages': '177 - 184', 'name': 'International Psychogeriatrics'}","{'bibtex': '@Article{Sherman2017PrevalenceNA,\n author = {Chelsea Sherman and Celina S. Liu and N. Herrmann and K. Lanctôt},\n journal = {International Psychogeriatrics},\n pages = {177 - 184},\n title = {Prevalence, neurobiology, and treatments for apathy in prodromal dementia},\n volume = {30},\n year = {2017}\n}\n'}","[{'authorId': '22853228', 'name': 'Chelsea Sherman'}, {'authorId': '2107890195', 'name': 'Celina S. Liu'}, {'authorId': '144528209', 'name': 'N. Herrmann'}, {'authorId': '4797664', 'name': 'K. Lanctôt'}]"
596,31677bcb8a8b3e17373008cc906eb7f07b4d3c3d,Action as language in a shared visual space,"A shared visual workspace allows multiple people to see similar views of objects and environments. Prior empirical literature demonstrates that visual information helps collaborators understand the current state of their task and enables them to communicate and ground their conversations efficiently. We present an empirical study that demonstrates how action replaces explicit verbal instruction in a shared visual workspace. Pairs performed a referential communication task with and without a shared visual space. A detailed sequential analysis of the communicative content reveals that pairs with a shared workspace were less likely to explicitly verify their actions with speech. Rather, they relied on visual information to provide the necessary communicative and coordinative cues.",2004.0,40.0,152.0,False,,{'name': 'Proceedings of the 2004 ACM conference on Computer supported cooperative work'},"{'bibtex': '@Article{Gergle2004ActionAL,\n author = {Darren Gergle and R. Kraut and Susan R. Fussell},\n journal = {Proceedings of the 2004 ACM conference on Computer supported cooperative work},\n title = {Action as language in a shared visual space},\n year = {2004}\n}\n'}","[{'authorId': '2497393', 'name': 'Darren Gergle'}, {'authorId': '1702853', 'name': 'R. Kraut'}, {'authorId': '1692772', 'name': 'Susan R. Fussell'}]"
597,317d38b9bf4c5aa2e204f43194a85d901e8ce191,Architecture of a Framework for Generic Assisting Conversational Agents,,2006.0,26.0,43.0,False,,{'pages': '145-156'},"{'bibtex': '@Inproceedings{Sansonnet2006ArchitectureOA,\n author = {J. Sansonnet and D. Leray and Jean-Claude Martin},\n pages = {145-156},\n title = {Architecture of a Framework for Generic Assisting Conversational Agents},\n year = {2006}\n}\n'}","[{'authorId': '1708171', 'name': 'J. Sansonnet'}, {'authorId': '144869828', 'name': 'D. Leray'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}]"
598,31b144791f19e5bef94f73e86c70e415acd22ce4,Emotion and Adaptation,,1993.0,0.0,5509.0,False,,"{'volume': '150', 'name': 'American Journal of Psychiatry'}","{'bibtex': '@Article{Cicchetti1993EmotionAA,\n author = {D. Cicchetti},\n journal = {American Journal of Psychiatry},\n title = {Emotion and Adaptation},\n volume = {150},\n year = {1993}\n}\n'}","[{'authorId': '50075430', 'name': 'D. Cicchetti'}]"
600,31b2fbf8a1e78adc6713abe54035bb2f132118f1,The Proteus Effect: The Effect of Transformed Self-Representation on Behavior,"Virtual environments, such as online games and web-based chat rooms, increasingly allow us to alter our digital self-representations dramatically and easily. But as we change our self-representations, do our self-representations change our behavior in turn? In 2 experimental studies, we explore the hypothesis that an individual’s behavior conforms to their digital self-representation independent of how others perceive them—a process we term the Proteus Effect. In the first study, participants assigned to more attractive avatars in immersive virtual environments were more intimate with confederates in a self-disclosure and interpersonal distance task than participants assigned to less attractive avatars. In our second study, participants assigned taller avatars behaved more confidently in a negotiation task than participants assigned shorter avatars. We discuss the implications of the Proteus Effect with regards to social interactions in online environments.",2007.0,52.0,1443.0,True,"{'url': 'http://vhil.stanford.edu/pubs/2007/yee-proteus-effect.pdf', 'status': None}","{'volume': '33', 'pages': '271-290', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Yee2007ThePE,\n author = {N. Yee and J. Bailenson},\n journal = {Human Communication Research},\n pages = {271-290},\n title = {The Proteus Effect: The Effect of Transformed Self-Representation on Behavior},\n volume = {33},\n year = {2007}\n}\n'}","[{'authorId': '38811484', 'name': 'N. Yee'}, {'authorId': '1737161', 'name': 'J. Bailenson'}]"
601,31b3f2048fc05c652456ce1a189888dcd04d0397,Analysis and Prediction of Student Emotions While Doing Programming Exercises,,2019.0,19.0,18.0,False,,{'pages': '24-33'},"{'bibtex': '@Inproceedings{Tiam-Lee2019AnalysisAP,\n author = {Thomas James Z. Tiam-Lee and Kaoru Sumi},\n pages = {24-33},\n title = {Analysis and Prediction of Student Emotions While Doing Programming Exercises},\n year = {2019}\n}\n'}","[{'authorId': '1405359966', 'name': 'Thomas James Z. Tiam-Lee'}, {'authorId': '145441214', 'name': 'Kaoru Sumi'}]"
602,31b71374346cf3414a7ca11e2d36158a1b67f52c,"Modeling coping behavior in virtual humans: don't worry, be happy","This article builds on insights into how humans cope with emotion to guide the design of virtual humans. Although coping is increasingly viewed in the psychological literature as having a central role in human adaptive behavior, it has been largely ignored in computational models of emotion. In this paper, we show how psychological research on the interplay between human emotion, cognition and coping behavior can serve as a central organizing principle for the behavior of human-like autonomous agents. We present a detailed domain-independent model of coping based on this framework that significantly extends our previous work. We argue that this perspective provides novel insights into realizing adaptive behavior.",2003.0,30.0,166.0,False,,{'pages': '313-320'},"{'bibtex': ""@Inproceedings{Marsella2003ModelingCB,\n author = {S. Marsella and J. Gratch},\n pages = {313-320},\n title = {Modeling coping behavior in virtual humans: don't worry, be happy},\n year = {2003}\n}\n""}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
603,31e3a593195fb8d1b7c146353b77e27035dbb3fb,Catch Me If You Can — Exploring Lying Agents in Social Settings,"Embodied conversational agents become more and more realistic concerning their conversational and their nonverbal behaviors. But if the information conveyed nonverbally exhibits clues that are not consistent with the verbal part of an agent’s action, how will the user react to such a discrepancy? Masking ones real emotions with a smile is a naturally occuring example of such a discrepancy. But such masks are often deﬁcient and thus subtle clues of lying and deceiving manifest themselves in facial expressions. The questions is how users will react to these clues if they are conveyed by an agent. Will they render an application unattractive or on the contrary more human-like? In this paper, we examine such facial clues to deception and present the results of two empirical studies: i.) lies in monologues by a talking head presenting movies, ii.) lies in an interactive game of dice.",2004.0,31.0,88.0,False,,,"{'bibtex': '@Inproceedings{Rehm2004CatchMI,\n author = {M. Rehm and Elisabeth Andr´e},\n title = {Catch Me If You Can — Exploring Lying Agents in Social Settings},\n year = {2004}\n}\n'}","[{'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '2262115677', 'name': 'Elisabeth Andr´e'}]"
604,32067ec2c992e92007f3b6817d45d66852e42d52,VR content creation and exploration with deep learning: A survey,,2020.0,174.0,51.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s41095-020-0162-z.pdf', 'status': None}","{'volume': '6', 'pages': '3-28', 'name': 'Computational Visual Media'}","{'bibtex': '@Article{Wang2020VRCC,\n author = {Miao Wang and Xu-Quan Lyu and Yijun Li and Fang-Lue Zhang},\n journal = {Computational Visual Media},\n pages = {3-28},\n title = {VR content creation and exploration with deep learning: A survey},\n volume = {6},\n year = {2020}\n}\n'}","[{'authorId': '40641980', 'name': 'Miao Wang'}, {'authorId': '1585598418', 'name': 'Xu-Quan Lyu'}, {'authorId': '2110512037', 'name': 'Yijun Li'}, {'authorId': '3326435', 'name': 'Fang-Lue Zhang'}]"
605,322ac47267c4e056298d8acfc88dc18a95114a26,VOX system: a semantic embodied conversational agent exploiting linked data,,2014.0,54.0,16.0,False,,"{'volume': '75', 'pages': '381-404', 'name': 'Multimedia Tools and Applications'}","{'bibtex': '@Article{Serón2014VOXSA,\n author = {F. Serón and Carlos Bobed},\n journal = {Multimedia Tools and Applications},\n pages = {381-404},\n title = {VOX system: a semantic embodied conversational agent exploiting linked data},\n volume = {75},\n year = {2014}\n}\n'}","[{'authorId': '2123508', 'name': 'F. Serón'}, {'authorId': '3019186', 'name': 'Carlos Bobed'}]"
606,324199805cc345460714dd33b11e5bc5abcc0c70,"AIMER: Appraisal Interpersonal Model of Emotion Regulation, Affective Virtual Students to Support Teachers Training","Elementary school classrooms are emotionally stressful environments, for both students and teachers. Successful teachers use strategies that regulate students' emotions and behaviors while also controlling their own emotions (stress, nervousness). To prepare teachers for the challenges of teaching, teacher training should include emotional and behavioral management strategies. Virtual Training Environments (VTEs) are effective at providing experiences and increasing learning in many domains. Creating VTEs for teachers can improve student learning and teacher retention. We introduce our current research aimed at integrating emotionally-intelligent virtual students within a 3D classroom training system. In our simulation, virtual students' emotional states will be determined from an appraisal process of actions taken by the teacher trainee in the virtual classroom. Virtual students will then display the appropriate non-verbal behaviors and react to the teacher accordingly. We present the first steps required to implement our proposed architecture which are based on appraisal theory of emotions and emotion regulation theory.",2019.0,37.0,2.0,False,,{'name': 'Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Delamarre2019AIMERAI,\n author = {A. Delamarre and Cédric Buche and C. Lisetti},\n journal = {Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents},\n title = {AIMER: Appraisal Interpersonal Model of Emotion Regulation, Affective Virtual Students to Support Teachers Training},\n year = {2019}\n}\n'}","[{'authorId': '17849026', 'name': 'A. Delamarre'}, {'authorId': '1753287', 'name': 'Cédric Buche'}, {'authorId': '1779199', 'name': 'C. Lisetti'}]"
607,326a37c760c665dec07420f5eb6dca681f012db1,Detecting user engagement with a robot companion using task and social interaction-based features,"Affect sensitivity is of the utmost importance for a robot companion to be able to display socially intelligent behaviour, a key requirement for sustaining long-term interactions with humans. This paper explores a naturalistic scenario in which children play chess with the iCat, a robot companion. A person-independent, Bayesian approach to detect the user's engagement with the iCat robot is presented. Our framework models both causes and effects of engagement: features related to the user's non-verbal behaviour, the task and the companion's affective reactions are identified to predict the children's level of engagement. An experiment was carried out to train and validate our model. Results show that our approach based on multimodal integration of task and social interaction-based features outperforms those based solely on non-verbal behaviour or contextual information (94.79 % vs. 93.75 % and 78.13 %).",2009.0,21.0,173.0,False,,{'pages': '119-126'},"{'bibtex': '@Inproceedings{Castellano2009DetectingUE,\n author = {Ginevra Castellano and André Pereira and Iolanda Leite and Ana Paiva and P. McOwan},\n pages = {119-126},\n title = {Detecting user engagement with a robot companion using task and social interaction-based features},\n year = {2009}\n}\n'}","[{'authorId': '39540970', 'name': 'Ginevra Castellano'}, {'authorId': '11845717', 'name': 'André Pereira'}, {'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '2803283', 'name': 'P. McOwan'}]"
608,32ba17ac7b02627b7f0d07213b7e0a00822206c1,The Architectural Basis of Affective States and Processes,"Much discussion of emotions and related topics is riddled with confusion because different authors use the key expressions with different meanings. Some confuse the concept of ""emotion"" with the more general concept of ""affect"", which covers other things besides emotions, including moods, attitudes, desires, preferences, intentions, dislikes, etc. Moreover researchers have different goals: some are concerned with understanding natural phenomena, while others are more concerned with producing useful artifacts, e.g. synthetic entertainment agents, sympathetic machine interfaces, and the like. We address this confusion by showing how ""architecture-based"" concepts can extend and refine our pre-theoretical concepts in ways that make them more useful both for expressing scientific questions and theories, and for specifying engineering objectives. An implication is that different information-processing architectures support different classes of emotions, different classes of consciousness, different varieties of perception, and so on. We start with high level concepts applicable to a wide variety of types of natural and artificial systems, including very simple organisms, namely concepts such as ""need"", ""function"", ""information-user"", ""affect"", ""information-processing architecture"". For more complex architectures, we offer the CogAff schema as a generic framework which distinguishes types of components that may be in a architecture, operating concurrently with different functional roles. We also sketch H-Cogaff, a richly-featured special case of CogAff, conjectured as a type of architecture that can explain or replicate human mental phenomena. We show how the concepts that are definable in terms of such architectures can clarify and enrich research on human emotions. If successful for the purposes of science and philosophy the architecture is also likely to be useful for engineering purposes, though many engineering goals can be achieved using shallow concepts and shallow theories, e.g., producing ""believable"" agents for computer entertainments. The more human-like robot emotions will emerge, as they do in humans, from the interactions of many mechanisms serving different purposes, not from a particular, dedicated ""emotion mechanism"".",2005.0,67.0,123.0,True,"{'url': 'http://www.cs.bham.ac.uk/research/cogaff/sloman-chrisley-scheutz-emotions.pdf', 'status': None}",{'pages': '203-244'},"{'bibtex': '@Inproceedings{Sloman2005TheAB,\n author = {A. Sloman and Ron Chrisley and Matthias Scheutz},\n pages = {203-244},\n title = {The Architectural Basis of Affective States and Processes},\n year = {2005}\n}\n'}","[{'authorId': '145788442', 'name': 'A. Sloman'}, {'authorId': '1693259', 'name': 'Ron Chrisley'}, {'authorId': '1793014', 'name': 'Matthias Scheutz'}]"
609,32fba2469859478811e979ad20345ed2737efdab,Learning motion rules from real data: Neural network for crowd simulation,,2018.0,34.0,23.0,False,,"{'volume': '310', 'pages': '125-134', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Wei2018LearningMR,\n author = {Xiang Wei and W. Lu and Lili Zhu and Weiwei Xing},\n journal = {Neurocomputing},\n pages = {125-134},\n title = {Learning motion rules from real data: Neural network for crowd simulation},\n volume = {310},\n year = {2018}\n}\n'}","[{'authorId': '50652909', 'name': 'Xiang Wei'}, {'authorId': '143844117', 'name': 'W. Lu'}, {'authorId': '2112271512', 'name': 'Lili Zhu'}, {'authorId': '145767614', 'name': 'Weiwei Xing'}]"
610,33161ce8d17a405354d20c7d0c552abc6cf189f7,CiF-CK: An architecture for social NPCS in commercial games,"We present and describe CiF-CK — a social agent architecture that models reasoning about persistent social interactions to improve narrative engagement and play experience for human interactors. The architecture is inspired by McCoy et al's Comme il-Faut (CiF) architecture that represented rich social interactions between agents that included emotions, social and relationship contexts, and longer term mood. The key contribution of this work is in adapting the richness of social interactions from CiF to a first-person interaction experience and a released distribution of its implementation on the Skyrim game engine. The released modification has been successful in the player community for the popular game.",2017.0,35.0,19.0,True,"{'url': 'http://dspace.ou.nl/bitstream/1820/9663/1/2017-GuimSantosJhala_CIG2017.pdf', 'status': None}","{'pages': '126-133', 'name': '2017 IEEE Conference on Computational Intelligence and Games (CIG)'}","{'bibtex': '@Article{Guimarães2017CiFCKAA,\n author = {Manuel Guimarães and Pedro Santos and A. Jhala},\n journal = {2017 IEEE Conference on Computational Intelligence and Games (CIG)},\n pages = {126-133},\n title = {CiF-CK: An architecture for social NPCS in commercial games},\n year = {2017}\n}\n'}","[{'authorId': '28004507', 'name': 'Manuel Guimarães'}, {'authorId': '2068679306', 'name': 'Pedro Santos'}, {'authorId': '1763814', 'name': 'A. Jhala'}]"
611,336e291572583c58c0209c3dd7d374ee0927dcad,Rapport in conflict resolution: Accounting for how face-to-face contact fosters mutual cooperation in mixed-motive conflicts.,"We propose that face-to-face contact fosters the development of rapport and thereby helps negotiators coordinate on mutually beneficial settlements in mixed-motive conflicts. Specifically, we investigate whether, in a cooperative climate, negotiators' visual access to each other's nonverbal behavior fosters a dyadic state of rapport that facilitates mutual cooperation. Experiment 1 manipulated whether negotiators stood face-to-face or side-by-side (unable to see each other) in a simulated strike negotiation. Face-to-face dyads were more likely to coordinate on a settlement early in the strike, resulting in higher joint gains. An alternative interpretation in terms of an anticipatory effect of face-to-face contact was not supported. Experiment 2 manipulated whether previously unacquainted negotiators conversed face-to-face or by telephone before separating to play a conflict game with the structure of a Prisoner's Dilemma game. Face-to-face dyads were more likely to coordinate on high joint gain outcomes. The facilitatory effect of face-to-face contact was statistically mediated by a measure of dyadic rapport. Results did not support alternative interpretations based on individual-level positive affect or expectations about opponents. We conclude with a discussion of the role of affective and dyad-level processes in social psychological models of conflict resolution.",2000.0,71.0,420.0,False,,"{'volume': '36', 'pages': '26-50', 'name': 'Journal of Experimental Social Psychology'}","{'bibtex': '@Article{Drolet2000RapportIC,\n author = {A. Drolet and M. Morris},\n journal = {Journal of Experimental Social Psychology},\n pages = {26-50},\n title = {Rapport in conflict resolution: Accounting for how face-to-face contact fosters mutual cooperation in mixed-motive conflicts.},\n volume = {36},\n year = {2000}\n}\n'}","[{'authorId': '48718478', 'name': 'A. Drolet'}, {'authorId': '145440944', 'name': 'M. Morris'}]"
612,336ef90827eeb209540070fa0f6ce15ad6c300a5,Decoupling facial expressions and head motions in complex emotions,"Perception of emotion through facial expressions and head motion is of interest to both psychology and affective computing researchers. However, very little is known about the importance of each modality individually, as they are often treated together rather than separately. We present a study which isolates the effect of head motion from facial expression in the perception of complex emotions in videos. We demonstrate that head motions carry emotional information that is complementary rather than redundant to the emotion content in facial expressions. Finally, we show that emotional expressivity in head motion is not limited to nods and shakes and that additional gestures (such as head tilts, raises and general amount of motion) could be beneficial to automated recognition systems.",2015.0,36.0,42.0,False,,"{'pages': '274-280', 'name': '2015 International Conference on Affective Computing and Intelligent Interaction (ACII)'}","{'bibtex': '@Article{Adams2015DecouplingFE,\n author = {Andra Adams and M. Mahmoud and T. Baltrušaitis and P. Robinson},\n journal = {2015 International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {274-280},\n title = {Decoupling facial expressions and head motions in complex emotions},\n year = {2015}\n}\n'}","[{'authorId': '31639770', 'name': 'Andra Adams'}, {'authorId': '97930679', 'name': 'M. Mahmoud'}, {'authorId': '1756344', 'name': 'T. Baltrušaitis'}, {'authorId': '2149814967', 'name': 'P. Robinson'}]"
613,337c5b072f0bc8b30e03276f02e3fc81e3c0ff2d,Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates,,2001.0,9.0,3691.0,False,,"{'volume': '55', 'pages': '271-280', 'name': 'Mathematics and Computers in Simulation'}","{'bibtex': '@Article{Soboĺ2001GlobalSI,\n author = {I. M. Soboĺ},\n journal = {Mathematics and Computers in Simulation},\n pages = {271-280},\n title = {Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates},\n volume = {55},\n year = {2001}\n}\n'}","[{'authorId': '1388551183', 'name': 'I. M. Soboĺ'}]"
614,33a8acdcf7685129d3cf62c3dbc04daed98beabc,Controllable Emotion Transfer For End-to-End Speech Synthesis,"Emotion embedding space learned from references is a straight-forward approach for emotion transfer in encoder-decoder structured emotional text to speech (TTS) systems. However, the transferred emotion in the synthetic speech is not accurate and expressive enough with emotion category confusions. Moreover, it is hard to select an appropriate reference to deliver desired emotion strength. To solve these problems, we propose a novel approach based on Tacotron. First, we plug two emotion classifiers – one after the reference encoder, one after the decoder output – to enhance the emotion-discriminative ability of the emotion embedding and the predicted mel-spectrum. Second, we adopt style loss to measure the difference between the generated and reference mel-spectrum. The emotion strength in the synthetic speech can be controlled by adjusting the value of the emotion embedding as the emotion embedding can be viewed as the feature map of the mel-spectrum. Experiments on emotion transfer and strength control have shown that the synthetic speech of the proposed method is more accurate and expressive with less emotion category confusions and the control of emotion strength is more salient to listeners.",2020.0,35.0,56.0,True,"{'url': 'https://arxiv.org/pdf/2011.08679', 'status': None}","{'pages': '1-5', 'name': '2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)'}","{'bibtex': '@Article{Li2020ControllableET,\n author = {Tao Li and Shan Yang and Liumeng Xue and Lei Xie},\n journal = {2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)},\n pages = {1-5},\n title = {Controllable Emotion Transfer For End-to-End Speech Synthesis},\n year = {2020}\n}\n'}","[{'authorId': '50289773', 'name': 'Tao Li'}, {'authorId': '50591589', 'name': 'Shan Yang'}, {'authorId': '46426991', 'name': 'Liumeng Xue'}, {'authorId': '144206962', 'name': 'Lei Xie'}]"
615,33b0036074b2493794cfbefdc589a869574620eb,"Goals, Representations, and Strategies in a Concept Attainment Task: the EPAM Model",,1997.0,16.0,27.0,False,,"{'volume': '37', 'pages': '265-290', 'name': 'Psychology of Learning and Motivation'}","{'bibtex': '@Article{Gobet1997GoalsRA,\n author = {F. Gobet and H. Richman and J. Staszewski and H. Simon},\n journal = {Psychology of Learning and Motivation},\n pages = {265-290},\n title = {Goals, Representations, and Strategies in a Concept Attainment Task: the EPAM Model},\n volume = {37},\n year = {1997}\n}\n'}","[{'authorId': '9005262', 'name': 'F. Gobet'}, {'authorId': '152148629', 'name': 'H. Richman'}, {'authorId': '32422330', 'name': 'J. Staszewski'}, {'authorId': '2259532335', 'name': 'H. Simon'}]"
616,340921f48de9ac42de4cc5dc3329e8c872fbb1d6,Oculus,,2021.0,0.0,50.0,False,,{'name': 'Encyclopedic Dictionary of Archaeology'},"{'bibtex': '@Article{None,\n journal = {Encyclopedic Dictionary of Archaeology},\n title = {Oculus},\n year = {2021}\n}\n'}",[]
617,3421020c64a04af023669b26cc4cba2b615ea501,There's always hope: Enhancing agent believability through expectation-based emotions,"To endow virtual agents with more realistic affective behavior, the notion of expectation-based emotions plays an important role: emotional states of agents should not only be triggered by present stimuli, but also by anticipation on future stimuli, and evaluation of past stimuli in the context of these anticipations. Within this study, an extension of the belief-desire-intention (BDI) model with expectation-based emotions is proposed. The model has been implemented in the modeling language LEADSTO. In addition, a game application has been developed, in which a user can play a dice game against an agent that is equipped with the emotion-based model. An empirical evaluation indicates that the model significantly enhances the agent's believability, in particular concerning its involvement in the situation.",2009.0,28.0,23.0,False,,"{'pages': '1-8', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': ""@Article{Bosse2009TheresAH,\n author = {T. Bosse and E. Zwanenburg},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-8},\n title = {There's always hope: Enhancing agent believability through expectation-based emotions},\n year = {2009}\n}\n""}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '2984887', 'name': 'E. Zwanenburg'}]"
618,342e20a754969961e5f2ce8ac232bd26e41439a1,Universal facial expressions of emotion.,,1970.0,0.0,436.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1970UniversalFE,\n author = {P. Ekman},\n title = {Universal facial expressions of emotion.},\n year = {1970}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
619,344b00021c1ff66cb0efdd2648dd735976e7d582,"Would You Trust a (Faulty) Robot? Effects of Error, Task Type and Personality on Human-Robot Cooperation and Trust","How do mistakes made by a robot affect its trustworthiness and acceptance in human-robot collaboration? We investigate how the perception of erroneous robot behavior may influence human interaction choices and the willingness to cooperate with the robot by following a number of itsunusual requests. For this purpose, we conducted an experiment in which participants interacted with a home companion robot in one of two experimental conditions: (1) the correct modeor (2) the faulty mode. Our findings reveal that, while significantly affecting subjective perceptions of the robot and assessments of its reliability and trustworthiness, the robot’s performance does not seem to substantially influence participants’ decisions to (not) comply with its requests. However, our results further suggest that the nature of the task requested by the robot, e.g. whether its effects are revocable as opposed to irrevocable, has a significant impact on participants’ willingness to follow its instructions.",2015.0,23.0,465.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/2696454.2696497', 'status': None}","{'pages': '1-8', 'name': '2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Salem2015WouldYT,\n author = {Maha Salem and G. Lakatos and F. Amirabdollahian and K. Dautenhahn},\n journal = {2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {1-8},\n title = {Would You Trust a (Faulty) Robot? Effects of Error, Task Type and Personality on Human-Robot Cooperation and Trust},\n year = {2015}\n}\n'}","[{'authorId': '144426526', 'name': 'Maha Salem'}, {'authorId': '32464892', 'name': 'G. Lakatos'}, {'authorId': '3029288', 'name': 'F. Amirabdollahian'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}]"
620,345c6a26bc65c877aebcc640a1e8a42e974eee96,Modeling Brief Alcohol Intervention Dialogue with MDPs for Delivery by ECAs,,2013.0,44.0,11.0,False,,{'pages': '92-105'},"{'bibtex': '@Inproceedings{Yasavur2013ModelingBA,\n author = {Ugan Yasavur and C. Lisetti and N. Rishe},\n pages = {92-105},\n title = {Modeling Brief Alcohol Intervention Dialogue with MDPs for Delivery by ECAs},\n year = {2013}\n}\n'}","[{'authorId': '2671668', 'name': 'Ugan Yasavur'}, {'authorId': '1779199', 'name': 'C. Lisetti'}, {'authorId': '1719172', 'name': 'N. Rishe'}]"
621,34b9a8f0715ff16a5118209530634fd4e83ee5b9,Multimedia in Learning,,2001.0,0.0,3382.0,False,,"{'volume': '', 'pages': '63-70', 'name': ''}","{'bibtex': '@Inproceedings{Bork2001MultimediaIL,\n author = {A. Bork and S. Gunnarsdottir},\n pages = {63-70},\n title = {Multimedia in Learning},\n year = {2001}\n}\n'}","[{'authorId': '145028923', 'name': 'A. Bork'}, {'authorId': '2372781', 'name': 'S. Gunnarsdottir'}]"
622,34be3feaa59ddf191563381793a7a235f33a295e,"Gesture's role in speaking, learning, and creating language.","When speakers talk, they gesture. The goal of this review is to investigate the contribution that these gestures make to how we communicate and think. Gesture can play a role in communication and thought at many timespans. We explore, in turn, gesture's contribution to how language is produced and understood in the moment; its contribution to how we learn language and other cognitive skills; and its contribution to how language is created over generations, over childhood, and on the spot. We find that the gestures speakers produce when they talk are integral to communication and can be harnessed in a number of ways. (a) Gesture reflects speakers' thoughts, often their unspoken thoughts, and thus can serve as a window onto cognition. Encouraging speakers to gesture can thus provide another route for teachers, clinicians, interviewers, etc., to better understand their communication partners. (b) Gesture can change speakers' thoughts. Encouraging gesture thus has the potential to change how students, patients, witnesses, etc., think about a problem and, as a result, alter the course of learning, therapy, or an interchange. (c) Gesture provides building blocks that can be used to construct a language. By watching how children and adults who do not already have a language put those blocks together, we can observe the process of language creation. Our hands are with us at all times and thus provide researchers and learners with an ever-present tool for understanding how we talk and think.",2013.0,149.0,331.0,True,"{'url': 'https://europepmc.org/articles/pmc3642279?pdf=render', 'status': None}","{'volume': '64', 'pages': '\n          257-83\n        ', 'name': 'Annual review of psychology'}","{'bibtex': ""@Article{Goldin‐Meadow2013GesturesRI,\n author = {S. Goldin‐Meadow and M. Alibali},\n journal = {Annual review of psychology},\n pages = {\n          257-83\n        },\n title = {Gesture's role in speaking, learning, and creating language.},\n volume = {64},\n year = {2013}\n}\n""}","[{'authorId': '115377287', 'name': 'S. Goldin‐Meadow'}, {'authorId': '3177547', 'name': 'M. Alibali'}]"
623,34c1d8ce112bf496f3433bfecb431d7720e426b8,Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility,,2005.0,78.0,125.0,False,,"{'volume': '62', 'pages': '281-306', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Cowell2005ManipulationON,\n author = {A. Cowell and K. Stanney},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {281-306},\n title = {Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility},\n volume = {62},\n year = {2005}\n}\n'}","[{'authorId': '7234960', 'name': 'A. Cowell'}, {'authorId': '1701555', 'name': 'K. Stanney'}]"
624,34e2cb7a4fef0651fb5c0a120c8e70ebab9f0749,It's only a computer: Virtual humans increase willingness to disclose,,2014.0,28.0,526.0,False,,"{'volume': '37', 'pages': '94-100', 'name': 'Comput. Hum. Behav.'}","{'bibtex': ""@Article{Lucas2014ItsOA,\n author = {Gale M. Lucas and J. Gratch and Aisha King and Louis-Philippe Morency},\n journal = {Comput. Hum. Behav.},\n pages = {94-100},\n title = {It's only a computer: Virtual humans increase willingness to disclose},\n volume = {37},\n year = {2014}\n}\n""}","[{'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '32722492', 'name': 'Aisha King'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
626,34fbe38622194cae32166f926e65ac082c921706,Expression of Emotions in Dance: Relation between Arm Movement Characteristics and Emotion,"This study was designed to investigate the relations between emotional expression and the movement characteristics. For this purpose, we used kinematic data related to three factors of the movement characteristics: Speed, Force, and Directness. In Exp. 1, we examined how the dancers expressed emotions when they used a certain body action and body part, and how they altered the movement characteristics. In Exp. 1, 10 female dancers were instructed to express three emotions, joy, sadness, and anger, by altering arm-movement characteristics. Analysis of variance indicated that the three exhibited emotional expressions had different movement characteristics. Discriminant analysis indicated that kinematic data for evaluation of movement characteristics are useful for discrimination of the three emotional expressions in dance. In Exp. 2, we investigated how naive observers perceived the type of emotion from the arm-movement characteristics. Analysis of variance showed that 22 observers accurately perceived each emotion distinguished from other emotions. Multiple regression analysis showed that specific movement characteristics influenced the perception of particular emotion.",2003.0,19.0,132.0,False,,"{'volume': '97', 'pages': '697 - 708', 'name': 'Perceptual and Motor Skills'}","{'bibtex': '@Article{Sawada2003ExpressionOE,\n author = {Misako Sawada and K. Suda and Motonobu Ishii},\n journal = {Perceptual and Motor Skills},\n pages = {697 - 708},\n title = {Expression of Emotions in Dance: Relation between Arm Movement Characteristics and Emotion},\n volume = {97},\n year = {2003}\n}\n'}","[{'authorId': '3487152', 'name': 'Misako Sawada'}, {'authorId': '92882753', 'name': 'K. Suda'}, {'authorId': '3473156', 'name': 'Motonobu Ishii'}]"
627,351bef53713f108450d78b958aebaab4d1e8bf7b,Empathizing with virtual agents: the effect of personification and general empathic tendencies,"For interactions to be natural, virtual agents should understand humans’ emotions, and humans should have emotional reactions towards them. In human-to-human interaction, this is achieved through empathic processes between individuals. So, improving empathic responses towards virtual agents represents a crucial step in improving human-virtual agent interactions. This study aims to identify whether the presence of a personification story and individual differences in the ability to empathize predict the empathic response towards a virtual agent. Furthermore, it investigates the effect of previous experience with virtual agents and gender on empathy towards the virtual agent. In an experiment, participants witnessed a virtual reality scene in which a virtual agent experienced sadness. Half of the participants were previously presented with a personification story about the virtual agent, and all completed a self-report questionnaire about empathy and a post-experiment survey about their empathic response towards the virtual agent. Results showed that individual differences in empathy significantly predict the ability to empathize with the virtual agent: people who are naturally predisposed to feel more empathy towards others tend to be more empathic towards the virtual agent. The personification story, previous experience and participants’ gender did not affect the empathic response. Implications and future direction for the design of virtual agents are discussed.",2022.0,61.0,2.0,False,,"{'name': '2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)', 'pages': '73-81'}","{'bibtex': '@Article{Kroes2022EmpathizingWV,\n author = {Kim Kroes and Isabella Saccardi and J. Masthoff},\n booktitle = {International Conference on Artificial Intelligence and Virtual Reality},\n journal = {2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},\n pages = {73-81},\n title = {Empathizing with virtual agents: the effect of personification and general empathic tendencies},\n year = {2022}\n}\n'}","[{'authorId': '2203809572', 'name': 'Kim Kroes'}, {'authorId': '2166475518', 'name': 'Isabella Saccardi'}, {'authorId': '145428594', 'name': 'J. Masthoff'}]"
628,3531a94f5d8728745916cadb7d9de0a801b2e596,Expression of Behaviors in Assistant Agents as Influences on Rational Execution of Plans,,2010.0,13.0,5.0,False,,{'pages': '413-419'},"{'bibtex': '@Inproceedings{Sansonnet2010ExpressionOB,\n author = {J. Sansonnet and François Bouchet},\n pages = {413-419},\n title = {Expression of Behaviors in Assistant Agents as Influences on Rational Execution of Plans},\n year = {2010}\n}\n'}","[{'authorId': '1708171', 'name': 'J. Sansonnet'}, {'authorId': '40845119', 'name': 'François Bouchet'}]"
629,3548b6ac3f044cc226681ab98df0253fddda7367,Can AI artifacts influence human cognition? The effects of artificial autonomy in intelligent personal assistants,,2021.0,92.0,108.0,False,,"{'volume': '56', 'pages': '102250', 'name': 'Int. J. Inf. Manag.'}","{'bibtex': '@Article{Hu2021CanAA,\n author = {Qian Hu and Yao-bin Lu and Zhao Pan and Y. Gong and Zhiling Yang},\n journal = {Int. J. Inf. Manag.},\n pages = {102250},\n title = {Can AI artifacts influence human cognition? The effects of artificial autonomy in intelligent personal assistants},\n volume = {56},\n year = {2021}\n}\n'}","[{'authorId': '1991013052', 'name': 'Qian Hu'}, {'authorId': '144038070', 'name': 'Yao-bin Lu'}, {'authorId': '2069543203', 'name': 'Zhao Pan'}, {'authorId': '40653187', 'name': 'Y. Gong'}, {'authorId': '2109513074', 'name': 'Zhiling Yang'}]"
630,355226f590fca31add067e8a1020edf27f3b4e2f,Bridging the Mechanical and the Human Mind: Spontaneous Mimicry of a Physically Present Android,"The spontaneous mimicry of others' emotional facial expressions constitutes a rudimentary form of empathy and facilitates social understanding. Here, we show that human participants spontaneously match facial expressions of an android physically present in the room with them. This mimicry occurs even though these participants find the android unsettling and are fully aware that it lacks intentionality. Interestingly, a video of that same android elicits weaker mimicry reactions, occurring only in participants who find the android “humanlike.” These findings suggest that spontaneous mimicry depends on the salience of humanlike features highlighted by face-to-face contact, emphasizing the role of presence in human-robot interaction. Further, the findings suggest that mimicry of androids can dissociate from knowledge of artificiality and experienced emotional unease. These findings have implications for theoretical debates about the mechanisms of imitation. They also inform creation of future robots that effectively build rapport and engagement with their human users.",2014.0,50.0,41.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0099934&type=printable', 'status': None}","{'volume': '9', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Hofree2014BridgingTM,\n author = {Galit Hofree and P. Ruvolo and M. Bartlett and P. Winkielman},\n journal = {PLoS ONE},\n title = {Bridging the Mechanical and the Human Mind: Spontaneous Mimicry of a Physically Present Android},\n volume = {9},\n year = {2014}\n}\n'}","[{'authorId': '3092566', 'name': 'Galit Hofree'}, {'authorId': '12114845', 'name': 'P. Ruvolo'}, {'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '3122131', 'name': 'P. Winkielman'}]"
631,3586d02338c87f8a7da08aed18625745fd1b3c46,"Animated conversation: rule-based generation of facial expression, gesture & spoken intonation for multiple conversational agents","We describe an implemented system which automatically generates and animates conversations between multiple human-like agents with appropriate and synchronized speech, intonation, facial expressions, and hand gestures. Conversation is created by a dialogue planner that produces the text as well as the intonation of the utterances. The speaker/listener relationship, the text, and the intonation in turn drive facial expressions, lip motions, eye gaze, head motion, and arm gestures generators. Coordinated arm, wrist, and hand motions are invoked to create semantically meaningful gestures. Throughout we will use examples from an actual synthesized, fully animated conversation.",1994.0,45.0,781.0,False,,{'name': 'Proceedings of the 21st annual conference on Computer graphics and interactive techniques'},"{'bibtex': '@Article{Cassell1994AnimatedCR,\n author = {Justine Cassell and C. Pelachaud and N. Badler and Mark Steedman and Brett Achorn and Tripp Becket and Brett Douville and Scott Prevost and Matthew Stone},\n journal = {Proceedings of the 21st annual conference on Computer graphics and interactive techniques},\n title = {Animated conversation: rule-based generation of facial expression, gesture & spoken intonation for multiple conversational agents},\n year = {1994}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1699200', 'name': 'N. Badler'}, {'authorId': '145332819', 'name': 'Mark Steedman'}, {'authorId': '1792667', 'name': 'Brett Achorn'}, {'authorId': '2955637', 'name': 'Tripp Becket'}, {'authorId': '3024972', 'name': 'Brett Douville'}, {'authorId': '35219353', 'name': 'Scott Prevost'}, {'authorId': '144884556', 'name': 'Matthew Stone'}]"
633,3586f7fe60a3c1330e4b2587b5c270281e21caab,Harassment in Social VR: Implications for Design,"We interviewed VR users $(\mathrm{n}=25)$ about their experiences with harassment, abuse, and discomfort in social YR. We find that users' definitions of ‘online harassment’ are subjective and highly personal, making it difficult to govern social spaces at the platform or application level. We also find that embodiment and presence make harassment feel more intense. Finally, we find that shared norms for appropriate behavior in social VR are still emergent, and that users distinguish between newcomers who unknowingly violate expectations for appropriateness and those users who aim to cause intentional harm.",2019.0,4.0,25.0,False,,"{'pages': '854-855', 'name': '2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)'}","{'bibtex': '@Article{Blackwell2019HarassmentIS,\n author = {Lindsay Blackwell and N. Ellison and Natasha Elliott-Deflo and Raz Schwartz},\n journal = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},\n pages = {854-855},\n title = {Harassment in Social VR: Implications for Design},\n year = {2019}\n}\n'}","[{'authorId': '35019836', 'name': 'Lindsay Blackwell'}, {'authorId': '1791021', 'name': 'N. Ellison'}, {'authorId': '1404331724', 'name': 'Natasha Elliott-Deflo'}, {'authorId': '1716015', 'name': 'Raz Schwartz'}]"
634,358f092645d60e74a0d917c147a33076037cf23e,"Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being.","Human beings can be proactive and engaged or, alternatively, passive and alienated, largely as a function of the social conditions in which they develop and function. Accordingly, research guided by self-determination theory has focused on the social-contextual conditions that facilitate versus forestall the natural processes of self-motivation and healthy psychological development. Specifically, factors have been examined that enhance versus undermine intrinsic motivation, self-regulation, and well-being. The findings have led to the postulate of three innate psychological needs--competence, autonomy, and relatedness--which when satisfied yield enhanced self-motivation and mental health and when thwarted lead to diminished motivation and well-being. Also considered is the significance of these psychological needs and processes within domains such as health care, education, work, sport, religion, and psychotherapy.",2000.0,183.0,31244.0,False,,"{'volume': '55 1', 'pages': '\n          68-78\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Ryan2000SelfdeterminationTA,\n author = {R. Ryan and E. Deci},\n journal = {The American psychologist},\n pages = {\n          68-78\n        },\n title = {Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being.},\n volume = {55 1},\n year = {2000}\n}\n'}","[{'authorId': '4064306', 'name': 'R. Ryan'}, {'authorId': '2740774', 'name': 'E. Deci'}]"
635,3598dadb1e5d38009a15d4422b6163f1277635ea,Information and Communication Technologies to Support Early Screening of Autism Spectrum Disorder: A Systematic Review,"The aim of this systematic review is to identify recent digital technologies used to detect early signs of autism spectrum disorder (ASD) in preschool children (i.e., up to six years of age). A systematic literature search was performed for English language articles and conference papers indexed in Pubmed, PsycInfo, ERIC, CINAHL, WoS, IEEE, and ACM digital libraries up until January 2020. A follow-up search was conducted to cover the literature published until December 2020 for the usefulness and interest in this area of research during the Covid-19 emergency. In total, 2427 articles were initially retrieved from databases search. Additional 481 articles were retrieved from follow-up search. Finally, 28 articles met the inclusion criteria and were included in the review. The studies included involved four main interface modalities: Natural User Interface (e.g., eye trackers), PC or mobile, Wearable, and Robotics. Most of the papers included (n = 20) involved the use of Level 1 screening tools. Notwithstanding the variability of the solutions identified, psychometric information points to considering available technologies as promising supports in clinical practice to detect early sign of ASD in young children. Further research is needed to understand the acceptability and increase use rates of technology-based screenings in clinical settings.",2021.0,67.0,6.0,True,"{'url': 'https://www.mdpi.com/2227-9067/8/2/93/pdf?version=1612412366', 'status': None}","{'volume': '8', 'name': 'Children'}","{'bibtex': '@Article{Desideri2021InformationAC,\n author = {L. Desideri and Patricia Pérez-Fuster and Gerardo Herrera},\n journal = {Children},\n title = {Information and Communication Technologies to Support Early Screening of Autism Spectrum Disorder: A Systematic Review},\n volume = {8},\n year = {2021}\n}\n'}","[{'authorId': '2806701', 'name': 'L. Desideri'}, {'authorId': '1399053598', 'name': 'Patricia Pérez-Fuster'}, {'authorId': '146803518', 'name': 'Gerardo Herrera'}]"
636,35aa24b141a401fefbd5f5c4fa307dc6f7c6f772,Interpersonal Distance in Immersive Virtual Environments,"Digital immersive virtual environment technology (IVET) enables behavioral scientists to conduct ecologically realistic experiments with near-perfect experimental control. The authors employed IVET to study the interpersonal distance maintained between participants and virtual humans. In Study 1, participants traversed a three-dimensional virtual room in which a virtual human stood. In Study 2, a virtual human approached participants. In both studies, participant gender, virtual human gender, virtual human gaze behavior, and whether virtual humans were allegedly controlled by humans (i.e., avatars) or computers (i.e., agents) were varied. Results indicated that participants maintained greater distance from virtual humans when approaching their fronts compared to their backs. In addition, participants gave more personal space to virtual agents who engaged them in mutual gaze. Moreover, when virtual humans invaded their personal space, participants moved farthest from virtual human agents. The advantages and disadvantages of IVET for the study of human behavior are discussed.",2003.0,38.0,699.0,False,,"{'volume': '29', 'pages': '819 - 833', 'name': 'Personality and Social Psychology Bulletin'}","{'bibtex': '@Article{Bailenson2003InterpersonalDI,\n author = {J. Bailenson and J. Blascovich and A. Beall and J. Loomis},\n journal = {Personality and Social Psychology Bulletin},\n pages = {819 - 833},\n title = {Interpersonal Distance in Immersive Virtual Environments},\n volume = {29},\n year = {2003}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2386187', 'name': 'J. Loomis'}]"
637,35e725620d2b9d1cd273463d1d1694918f0983c8,Differences in facial expressions of four universal emotions,,2004.0,25.0,236.0,False,,"{'volume': '128', 'pages': '235-244', 'name': 'Psychiatry Research'}","{'bibtex': '@Article{Kohler2004DifferencesIF,\n author = {C. Kohler and Travis Turner and N. Stolar and W. Bilker and C. Brensinger and R. Gur and R. Gur},\n journal = {Psychiatry Research},\n pages = {235-244},\n title = {Differences in facial expressions of four universal emotions},\n volume = {128},\n year = {2004}\n}\n'}","[{'authorId': '31936404', 'name': 'C. Kohler'}, {'authorId': '2114803325', 'name': 'Travis Turner'}, {'authorId': '2827839', 'name': 'N. Stolar'}, {'authorId': '3038423', 'name': 'W. Bilker'}, {'authorId': '2777419', 'name': 'C. Brensinger'}, {'authorId': '2406788', 'name': 'R. Gur'}, {'authorId': '144762538', 'name': 'R. Gur'}]"
638,366151c9363395783ab5fdb20814689c248b2575,Modeling emotional contagion based on experimental evidence for moderating factors,"is a lot of evidence for the phenomenon describing the spread of emotion from one person to another, called emotional contagion. Although there is a large body of research on this topic, research containing evidence for factors that moderate the process of emotional contagion, is limited and inconclusive. Furthermore most of these studies are done in a dyadic lab-setting and consequently little is known about emotional contagion in groups. This paper presents, for the first time, a dynamic computational model of contagion in groups of agents based on factors that moderate contagion. These factors are strictly based on experimental evidence in the psychological literature. In this paper we first present our review of the psychological literature. We then present our computational model as well as a pilot study investigating several group contagion cases showing the flexibility and potential of this strategy.",2012.0,39.0,18.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Coenen2012ModelingEC,\n author = {R. Coenen and J. Broekens},\n title = {Modeling emotional contagion based on experimental evidence for moderating factors},\n year = {2012}\n}\n'}","[{'authorId': '2059510738', 'name': 'R. Coenen'}, {'authorId': '1735303', 'name': 'J. Broekens'}]"
639,36670493aa690e49e7ade1747a419079395ab4bc,Emotion and decision making.,"A revolution in the science of emotion has emerged in recent decades, with the potential to create a paradigm shift in decision theories. The research reveals that emotions constitute potent, pervasive, predictable, sometimes harmful and sometimes beneficial drivers of decision making. Across different domains, important regularities appear in the mechanisms through which emotions influence judgments and choices. We organize and analyze what has been learned from the past 35 years of work on emotion and decision making. In so doing, we propose the emotion-imbued choice model, which accounts for inputs from traditional rational choice theory and from newer emotion research, synthesizing scientific models.",2015.0,235.0,1698.0,True,"{'url': 'https://escholarship.org/content/qt8552m415/qt8552m415.pdf?t=oqvnfr', 'status': None}","{'volume': '66', 'pages': '\n          799-823\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Lerner2015EmotionAD,\n author = {J. Lerner and Ye Li and Piercarlo Valdesolo and K. Kassam},\n journal = {Annual review of psychology},\n pages = {\n          799-823\n        },\n title = {Emotion and decision making.},\n volume = {66},\n year = {2015}\n}\n'}","[{'authorId': '5209814', 'name': 'J. Lerner'}, {'authorId': '2110764517', 'name': 'Ye Li'}, {'authorId': '49421872', 'name': 'Piercarlo Valdesolo'}, {'authorId': '7014924', 'name': 'K. Kassam'}]"
640,3699beeb1114b5212d1ed406a0080e68cdda47fa,Embodied Conversational Agents: Representation and Intelligence in User Interfaces,"How do we decide how to represent an intelligent system in its interface, and how do we decide how the interface represents information about the world and about its own workings to a user? This article addresses these questions by examining the interaction between representation and intelligence in user interfaces. The rubric representation covers at least three topics in this context: (1) how a computational system is represented in its user interface, (2) how the interface conveys its representations of information and the world to human users, and (3) how the system's internal representation affects the human user's interaction with the system. I argue that each of these kinds of representation (of the system, information and the world, the interaction) is key to how users make the kind of attributions of intelligence that facilitate their interactions with intelligent systems. In this vein, it makes sense to represent a systmem as a human in those cases where social collaborative behavior is key and for the system to represent its knowledge to humans in multiple ways on multiple modalities. I demonstrate these claims by discussing issues of representation and intelligence in an embodied conversational agent -- an interface in which the system is represented as a person, information is conveyed to human users by multiple modalities such as voice and hand gestures, and the internal representation is modality independent and both propositional and nonpropositional.",2001.0,34.0,299.0,False,,"{'volume': '22', 'pages': '67-84', 'name': 'AI Mag.'}","{'bibtex': '@Article{Cassell2001EmbodiedCA,\n author = {Justine Cassell},\n journal = {AI Mag.},\n pages = {67-84},\n title = {Embodied Conversational Agents: Representation and Intelligence in User Interfaces},\n volume = {22},\n year = {2001}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}]"
641,36a8de88bddab9218e5208da6889dfb7088df217,Towards a Socially Adaptive Virtual Agent,,2015.0,40.0,24.0,False,,{'pages': '3-16'},"{'bibtex': '@Article{Youssef2015TowardsAS,\n author = {Atef Ben Youssef and Mathieu Chollet and H. Jones and N. Sabouret and C. Pelachaud and M. Ochs},\n booktitle = {International Conference on Intelligent Virtual Agents},\n pages = {3-16},\n title = {Towards a Socially Adaptive Virtual Agent},\n year = {2015}\n}\n'}","[{'authorId': '49603388', 'name': 'Atef Ben Youssef'}, {'authorId': '40325099', 'name': 'Mathieu Chollet'}, {'authorId': '31600786', 'name': 'H. Jones'}, {'authorId': '1731432', 'name': 'N. Sabouret'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1724289', 'name': 'M. Ochs'}]"
642,36b84360b64a53c057b3fb59b646fd9c8b7a05ab,Regulation,"In the quarter-century that Social & Legal Studies has been published, regulation has emerged as a new, and for many exciting, interdisciplinary field. The concept itself requires a wider view of normativity than the narrow positivist one of law as command. It is certainly protean, ranging over many fundamental questions about the changing nature of the public sphere of politics and the state, and its interactions with the ‘private’ sphere of economic activity and social relations, as well as the mediation of these interactions, especially through law. This survey aims to outline and evaluate some of the main contours of the field as it has developed in this recent period, focusing on the regulation of economic activity. Regulation is seen as having emerged with the withdrawal by governments from direct provision of many economic and social services, to be replaced by corporatist bureaucracies and quasi-public agencies managing the complex public–private interactions of financialized capitalism. The arguments for ‘smart’ regulation have, in an era fixated on neo-liberalism, generally legitimized delegation of responsibility to big business. Its advocates, having been drawn into policy fields, have perhaps too often lost their critical edge, and allowed it to become instrumentalized, reflecting the technicist character of its practice.",2017.0,0.0,561.0,True,"{'url': 'https://eprints.lancs.ac.uk/id/eprint/87269/1/Regulation_final_submitted.pdf', 'status': None}","{'volume': '26', 'pages': '676 - 699', 'name': 'Social & Legal Studies'}","{'bibtex': '@Article{Picciotto2017Regulation,\n author = {S. Picciotto},\n journal = {Social & Legal Studies},\n pages = {676 - 699},\n title = {Regulation},\n volume = {26},\n year = {2017}\n}\n'}","[{'authorId': '35720444', 'name': 'S. Picciotto'}]"
643,36bd16db07dac7d23ea84c7712f94f7858427a5e,Configural information in facial expression perception.,"Composite facial expressions were prepared by aligning the top half of one expression (e.g., anger) with the bottom half of another (e.g., happiness). Experiment 1 shows that participants are slower to identify the expression in either half of these composite images relative to a ""noncomposite"" control condition in which the 2 halves are misaligned. This parallels the composite effect for facial identity (A. W. Young, D. Hellawell, & D. C. Hay, 1987), and like its identity counterpart, the effect is disrupted by inverting the stimuli (Experiment 2). Experiment 3 shows that no composite effect is found when the top and bottom sections contain different models' faces posing the same expression; this serves to exclude many nonconfigural interpretations of the composite effect (e.g., that composites are more ""attention-grabbing"" than noncomposites). Finally, Experiment 4 demonstrates that the composite effects for identity and expression operate independently of one another.",2000.0,64.0,637.0,False,,"{'volume': '26 2', 'pages': '\n          527-51\n        ', 'name': 'Journal of experimental psychology. Human perception and performance'}","{'bibtex': '@Article{Calder2000ConfiguralII,\n author = {A. Calder and A. Young and Jill Keane and M. P. Dean},\n journal = {Journal of experimental psychology. Human perception and performance},\n pages = {\n          527-51\n        },\n title = {Configural information in facial expression perception.},\n volume = {26 2},\n year = {2000}\n}\n'}","[{'authorId': '2825775', 'name': 'A. Calder'}, {'authorId': '2423497', 'name': 'A. Young'}, {'authorId': '40020056', 'name': 'Jill Keane'}, {'authorId': '2052648474', 'name': 'M. P. Dean'}]"
644,36c2e086bf91d0293e6c760ea0c99e60757749de,"Animated Agents for Procedural Training in Virtual Reality: Perception, Cognition, and Motor Control","This paper describes Steve , an animated agent that helps students learn to perform physical , procedural tasks . The student and Steve cohabit a three - dimensional , simulated mock - up of the student's work environment . Steve can demonstrate how to perform tasks and can also monitor students while they practice tasks , providing assistance when needed . This paper describes Steve's architecture in detail , including perception , cognition , and motor control . The perception module monitors the state of the virtual world , maintains a coherent representation of it , and provides this information to the cognition and motor control modules . The cognition module interprets its perceptual input , chooses appropriate goals , constructs and executes plans to achieve those goals , and sends out motor commands . The motor control module implements these motor commands , controlling Steve's voice , locomotion , gaze , and gestures , allowing Steve to manipulate objects in the virtual world .",1999.0,52.0,564.0,False,,"{'volume': '13', 'pages': '343-382', 'name': 'Appl. Artif. Intell.'}","{'bibtex': '@Article{Rickel1999AnimatedAF,\n author = {J. Rickel and W. Lewis Johnson},\n journal = {Appl. Artif. Intell.},\n pages = {343-382},\n title = {Animated Agents for Procedural Training in Virtual Reality: Perception, Cognition, and Motor Control},\n volume = {13},\n year = {1999}\n}\n'}","[{'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '2247993128', 'name': 'W. Lewis Johnson'}]"
645,36e3a68e57ee0de629ebcd536b95b0b8128987c8,Building Autonomous Sensitive Artificial Listeners,"This paper describes a substantial effort to build a real-time interactive multimodal dialogue system with a focus on emotional and nonverbal interaction capabilities. The work is motivated by the aim to provide technology with competences in perceiving and producing the emotional and nonverbal behaviors required to sustain a conversational dialogue. We present the Sensitive Artificial Listener (SAL) scenario as a setting which seems particularly suited for the study of emotional and nonverbal behavior since it requires only very limited verbal understanding on the part of the machine. This scenario allows us to concentrate on nonverbal capabilities without having to address at the same time the challenges of spoken language understanding, task modeling, etc. We first report on three prototype versions of the SAL scenario in which the behavior of the Sensitive Artificial Listener characters was determined by a human operator. These prototypes served the purpose of verifying the effectiveness of the SAL scenario and allowed us to collect data required for building system components for analyzing and synthesizing the respective behaviors. We then describe the fully autonomous integrated real-time system we created, which combines incremental analysis of user behavior, dialogue management, and synthesis of speaker and listener behavior of a SAL character displayed as a virtual agent. We discuss principles that should underlie the evaluation of SAL-type systems. Since the system is designed for modularity and reuse and since it is publicly available, the SAL system has potential as a joint research tool in the affective computing research community.",2012.0,143.0,204.0,True,"{'url': 'https://ris.utwente.nl/ws/files/6867478/buildingsal.pdf', 'status': None}","{'volume': '3', 'pages': '165-183', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Schröder2012BuildingAS,\n author = {M. Schröder and Elisabetta Bevacqua and R. Cowie and F. Eyben and H. Gunes and D. Heylen and M. Maat and G. McKeown and Sathish Pammi and M. Pantic and C. Pelachaud and Björn Schuller and E. D. Sevin and M. Valstar and M. Wöllmer},\n journal = {IEEE Transactions on Affective Computing},\n pages = {165-183},\n title = {Building Autonomous Sensitive Artificial Listeners},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '145635430', 'name': 'R. Cowie'}, {'authorId': '1751126', 'name': 'F. Eyben'}, {'authorId': '1781916', 'name': 'H. Gunes'}, {'authorId': '1678537', 'name': 'D. Heylen'}, {'authorId': '2975858', 'name': 'M. Maat'}, {'authorId': '2228246', 'name': 'G. McKeown'}, {'authorId': '2345401', 'name': 'Sathish Pammi'}, {'authorId': '145387780', 'name': 'M. Pantic'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '145411696', 'name': 'Björn Schuller'}, {'authorId': '1761859', 'name': 'E. D. Sevin'}, {'authorId': '1795528', 'name': 'M. Valstar'}, {'authorId': '2103575', 'name': 'M. Wöllmer'}]"
646,36f01c8daeb55f06e1b84f785aa84049e07911c7,Relationship between vocalizations and head nods as listener responses.,"An earlier study showed that listeners in conversations insert brief responses (""mm-hmm,"" ""I see,"" and the like) almost exclusively at the ends of rhythmical units in the talker's speech (Dittmann & Llewellyn, 1967). In this study these vocal responses were compared with a visible one, the head nod, and it was found that the 2 occurred together more often than chance would predict. Content analysis showed that these co-occurrences usually serve an interpersonal function: the wish of the listener to speak or the wish of the talker for feedback. When they did occur together, nods were found to precede the vocal response slightly. Apparently the listener must hold a vocal response politely until the speaker has finished a unit, but may nod before then.",1968.0,6.0,175.0,False,,"{'volume': '9 1', 'pages': '\n          79-84\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Dittmann1968RelationshipBV,\n author = {A. Dittmann and L. Llewellyn},\n journal = {Journal of personality and social psychology},\n pages = {\n          79-84\n        },\n title = {Relationship between vocalizations and head nods as listener responses.},\n volume = {9 1},\n year = {1968}\n}\n'}","[{'authorId': '3956276', 'name': 'A. Dittmann'}, {'authorId': '2335983', 'name': 'L. Llewellyn'}]"
647,3710c1fd770aebc06d3dc9b1392ead94caf54bc2,The effect of experience on system usability scale ratings,"Longitudinal studies have to do with testing over time and thus take into consideration previous user experience with a product or product versions. However, it is difficult to conduct these types of studies. Therefore the literature is sparse on examples of the explicit effect of user experience on user satisfaction metrics in industry-standard survey instruments. During a development experience in 2009, we used a cross-sectional method to look at the effects of user profiles on ratings for commercial products that use one such instrument, the System Usability Scale or SUS. 
 
Recent research has reported finding that differences in user ratings could be based on the extent of a user's prior experience with the computer system, a Web site being visited or a desktop application like Microsoft's Office suite being used. Compared to off-the-shelf office products or personal Web applications, we were curious if we would find the same experience effect for domain specialists using geosciences products in the course of their daily professional job roles. In fact, from data collected with 262 end users across different geographic locations testing two related oilfield product releases, one Web-based and one desktop-based, we found results that were quite close to early assessment studies: Users having a more extensive experience with a product tended to provide higher, more favorable, SUS scores over users with either no or limited experience with a product---and by as much as 15-16%, regardless of the domain product type. This and other observations found during our product testing have led us to offer some practical how-to's to our internal product analysts responsible for managing product test cycles, administering instruments like the SUS to users, and reporting results to development teams.",2012.0,24.0,176.0,False,,"{'volume': '7', 'pages': '56-67', 'name': 'Journal of Usability Studies archive'}","{'bibtex': '@Article{McLellan2012TheEO,\n author = {S. McLellan and Andrew Muddimer and S. Peres},\n journal = {Journal of Usability Studies archive},\n pages = {56-67},\n title = {The effect of experience on system usability scale ratings},\n volume = {7},\n year = {2012}\n}\n'}","[{'authorId': '144062875', 'name': 'S. McLellan'}, {'authorId': '2889238', 'name': 'Andrew Muddimer'}, {'authorId': '145212300', 'name': 'S. Peres'}]"
648,373ba28a9790dc9df676548b21e2123bfe5d15b4,"How Is Believability of a Virtual Agent Related to Warmth, Competence, Personification, and Embodiment?","The term “believability” is often used to describe expectations concerning virtual agents. In this paper, we analyze which factors influence the believability of the agent acting as the software assistant. We consider several factors such as embodiment, communicative behavior, and emotional capabilities. We conduct a perceptive study where we analyze the role of plausible and/or appropriate emotional displays in relation to believability. We also investigate how people judge the believability of the agent, and whether it provokes social reactions of humans toward it. Finally, we evaluate the respective impact of embodiment and emotion over believability judgments. The results of our study show that (a) appropriate emotions lead to higher perceived believability, (b) the notion of believability is closely correlated with the two major socio-cognitive variables, namely competence and warmth, and (c) considering an agent as believable can be different from having a human-like attitude toward it. Finally, a primacy of emotion behavior over embodiment while judging believability is also hypothesized from free responses given by the participants of this experiment.",2011.0,44.0,71.0,False,,"{'name': 'PRESENCE: Teleoperators and Virtual Environments', 'pages': '431-448', 'volume': '20'}","{'bibtex': '@Article{Demeure2011HowIB,\n author = {Virginie Demeure and Radoslaw Niewiadomski and C. Pelachaud},\n booktitle = {PRESENCE: Teleoperators and Virtual Environments},\n journal = {PRESENCE: Teleoperators and Virtual Environments},\n pages = {431-448},\n title = {How Is Believability of a Virtual Agent Related to Warmth, Competence, Personification, and Embodiment?},\n volume = {20},\n year = {2011}\n}\n'}","[{'authorId': '2539387', 'name': 'Virginie Demeure'}, {'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
649,374e3971853950b5bf98b8f2602caf6d188147a5,Real and Illusory Interactions Enhance Presence in Virtual Environments,"It has long been argued that the possibility to interact in and with a virtual environment (VE) enhances the sense of presence. On the basis of a three-component model of presence, we specify this hypothesis and argue that the mental representation of possible actions should especially enhance spatial presence, and to a lesser extent the involvement and realness of a VE. We support this hypothesis in three studies. A correlative study showed that self-reported interaction possibilities correlated significantly with spatial presence, but not with the other two factors. A first experimental study showed that possible self-movement significantly increased spatial presence and realness. A second experimental study showed that even the illusion of interaction, with no actual interaction taking place, significantly increased spatial presence.",2002.0,24.0,226.0,False,,"{'volume': '11', 'pages': '425-434', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Regenbrecht2002RealAI,\n author = {H. Regenbrecht and Thomas W. Schubert},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {425-434},\n title = {Real and Illusory Interactions Enhance Presence in Virtual Environments},\n volume = {11},\n year = {2002}\n}\n'}","[{'authorId': '1745309', 'name': 'H. Regenbrecht'}, {'authorId': '2151364', 'name': 'Thomas W. Schubert'}]"
650,375243fc58bf2319894703111e52b6d8ad2ec111,"Comparisons among the Holden Psychological Screening Inventory (HPSI), the Brief Symptom Inventory (BSI), and the Balanced Inventory of Desirable Responding (BIDR)","Issues of reliability, item latent structure, and faking on the Holden Psychological Screening Inventory (HPSI), the Brief Symptom Inventory (BSI), and the Balanced Inventory of Desirable Responding (BIDR) were examined with a sample of 300 university undergraduates. Reliability analyses indicated that scales from all inventories had acceptable internal consistency. Confirmatory item principal component analyses supported the structures and scoring keys of the HPSI and the BIDR, but not the BSI. Although all inventories were susceptible to faking, validity indices of the HPSI and the BIDR could correctly classify over two-thirds of test respondents as either responding honestly or as faking.",2000.0,21.0,48.0,False,,"{'volume': '7', 'pages': '163 - 175', 'name': 'Assessment'}","{'bibtex': '@Article{Holden2000ComparisonsAT,\n author = {R. Holden and Katherine B. Starzyk and L. McLeod and Melanie J. Edwards},\n journal = {Assessment},\n pages = {163 - 175},\n title = {Comparisons among the Holden Psychological Screening Inventory (HPSI), the Brief Symptom Inventory (BSI), and the Balanced Inventory of Desirable Responding (BIDR)},\n volume = {7},\n year = {2000}\n}\n'}","[{'authorId': '40252192', 'name': 'R. Holden'}, {'authorId': '38956355', 'name': 'Katherine B. Starzyk'}, {'authorId': '114697267', 'name': 'L. McLeod'}, {'authorId': '153196106', 'name': 'Melanie J. Edwards'}]"
651,375e201aa93dcff804959e70c0ae7a2d44593ae6,Designing empathic computers: the effect of multimodal empathic feedback using animated agent,"Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. Early research has shown some promising results when adopting strategies of how we comfort others, but many questions on how to build such systems remain unanswered. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content. Findings and implications for the design of empathic computer systems are discussed and directions for future research are suggested.",2009.0,16.0,52.0,False,,{'pages': '7'},"{'bibtex': '@Inproceedings{Nguyen2009DesigningEC,\n author = {Hien Nguyen and J. Masthoff},\n pages = {7},\n title = {Designing empathic computers: the effect of multimodal empathic feedback using animated agent},\n year = {2009}\n}\n'}","[{'authorId': '2110579362', 'name': 'Hien Nguyen'}, {'authorId': '145428594', 'name': 'J. Masthoff'}]"
652,376973681a3e717736625bd4e680515b909cf339,Do We Really Need to Collect Millions of Faces for Effective Face Recognition?,,2016.0,50.0,352.0,True,"{'url': 'https://arxiv.org/pdf/1603.07057', 'status': None}","{'volume': 'abs/1603.07057', 'name': 'ArXiv'}","{'bibtex': '@Article{Masi2016DoWR,\n author = {I. Masi and A. Tran and Tal Hassner and J. Leksut and G. Medioni},\n journal = {ArXiv},\n title = {Do We Really Need to Collect Millions of Faces for Effective Face Recognition?},\n volume = {abs/1603.07057},\n year = {2016}\n}\n'}","[{'authorId': '11269472', 'name': 'I. Masi'}, {'authorId': '2077431021', 'name': 'A. Tran'}, {'authorId': '1756099', 'name': 'Tal Hassner'}, {'authorId': '2955822', 'name': 'J. Leksut'}, {'authorId': '3463966', 'name': 'G. Medioni'}]"
653,376cf14b5bf4d0e636233d4344757e5e44cda285,Affective computing: challenges,,2003.0,18.0,828.0,False,,"{'volume': '59', 'pages': '55-64', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Picard2003AffectiveCC,\n author = {Rosalind W. Picard},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {55-64},\n title = {Affective computing: challenges},\n volume = {59},\n year = {2003}\n}\n'}","[{'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
654,3773ab6b9ccfd164d190e8b7a9088f0e0658193f,Designing an Intelligent Virtual Agent for Social Communication in Autism,"
 
 This paper describes the Intelligent Engine (IE) of ECHOES, a serious game built for helping young children with Autism Spectrum Conditions acquire social communication skills. ECHOES IE's main component is an autonomous virtual agent that acts as a credible social partner for children with autism by engaging them in interactive learning activities. The other IE components are a user model, a drama manager and a social communication engine. We discuss how AI technology allows us to satisfy the requirements for the design of the agent and the learning activities that we identified through consultations with children and carers and a review of best practices for autism intervention. We present experimental results pertaining to the agent's effectiveness, which show encouraging improvements for a number of children.
 
",2013.0,23.0,17.0,True,"{'url': 'https://ojs.aaai.org/index.php/AIIDE/article/download/12688/12536', 'status': None}",{'name': 'Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment'},"{'bibtex': '@Article{Bernardini2013DesigningAI,\n author = {S. Bernardini and K. Porayska-Pomsta and H. Sampath},\n journal = {Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},\n title = {Designing an Intelligent Virtual Agent for Social Communication in Autism},\n year = {2013}\n}\n'}","[{'authorId': '2282728', 'name': 'S. Bernardini'}, {'authorId': '1400276226', 'name': 'K. Porayska-Pomsta'}, {'authorId': '153885101', 'name': 'H. Sampath'}]"
655,378b2c02001320b2056602c1f8532ae9f15daa4d,"Interest, Learning, and the Psychological Processes That Mediate Their Relationship.","Although influences of interest on learning are well documented, mediating processes have not been clarified. The authors investigated how individual and situational interest factors contribute to topic interest and text learning. Traditional self-report measures were combined with novel interactive computerized methods of recording cognitive and affective reactions to science and popular culture texts, monitoring their development in real time. Australian and Canadian students read 4 expository texts. Both individual interest variables and specific text titles influenced topic interest. Examination of processes predictive of text learning indicated that topic interest was related to affective response, affect to persistence, and persistence to learning. Combining self-rating scales with dynamic measures of student activities provided new insight into how interest influences learning.",2002.0,68.0,1076.0,False,,"{'volume': '94', 'pages': '545-561', 'name': 'Journal of Educational Psychology'}","{'bibtex': '@Article{Ainley2002InterestLA,\n author = {M. Ainley and S. Hidi and Dagmar Berndorff},\n journal = {Journal of Educational Psychology},\n pages = {545-561},\n title = {Interest, Learning, and the Psychological Processes That Mediate Their Relationship.},\n volume = {94},\n year = {2002}\n}\n'}","[{'authorId': '2925700', 'name': 'M. Ainley'}, {'authorId': '2387795', 'name': 'S. Hidi'}, {'authorId': '71445698', 'name': 'Dagmar Berndorff'}]"
656,379d84eb2a3fb4994d23ffeec18feedae18d0e11,An architecture for more realistic conversational systems,"In this paper, we describe an architecture for conversational systems that enables human-like performance along several important dimensions. First, interpretation is incremental, multi-level, and involves both general and task- and domain-specific knowledge. Second, generation is also incremental, proceeds in parallel with interpretation, and accounts for phenomena such as turn-taking, grounding and interruptions. Finally, the overall behavior of the system in the task at hand is determined by the (incremental) results of interpretation, the persistent goals and obligations of the system, and exogenous events of which it becomes aware. As a practical matter, the architecture supports a separation of responsibilities that enhances portability to new tasks and domains.",2001.0,19.0,323.0,True,"{'url': 'https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.6761&rep=rep1&type=pdf', 'status': None}",{'pages': '1-8'},"{'bibtex': '@Inproceedings{Allen2001AnAF,\n author = {James F. Allen and G. Ferguson and Amanda Stent},\n pages = {1-8},\n title = {An architecture for more realistic conversational systems},\n year = {2001}\n}\n'}","[{'authorId': '145844737', 'name': 'James F. Allen'}, {'authorId': '144436424', 'name': 'G. Ferguson'}, {'authorId': '1690152', 'name': 'Amanda Stent'}]"
657,37accf85881b6abfec95dc241d58a1e5f0fb3c26,Cortical correlations in wavelet domain for estimation of emotional dysfunctions,,2018.0,84.0,26.0,False,,"{'volume': '30', 'pages': '1085-1094', 'name': 'Neural Computing and Applications'}","{'bibtex': '@Article{Aydın2018CorticalCI,\n author = {S. Aydın and Serdar Demirtas and S. Yetkin},\n journal = {Neural Computing and Applications},\n pages = {1085-1094},\n title = {Cortical correlations in wavelet domain for estimation of emotional dysfunctions},\n volume = {30},\n year = {2018}\n}\n'}","[{'authorId': '35098633', 'name': 'S. Aydın'}, {'authorId': '3368304', 'name': 'Serdar Demirtas'}, {'authorId': '2066393', 'name': 'S. Yetkin'}]"
658,37bdb0c35d00d3af6201b6f5f56e751ff09e601a,Automation Failures on Tasks Easily Performed by Operators Undermine Trust in Automated Aids,"Objective: We tested the hypothesis that automation errors on tasks easily performed by humans undermine trust in automation. Background: Research has revealed that the reliability of imperfect automation is frequently misperceived. We examined the manner in which the easiness and type of imperfect automation errors affect trust and dependence. Method: Participants performed a target detection task utilizing an automated aid. In Study 1, the aid missed targets either on easy trials (easy miss group) or on difficult trials (difficult miss group). In Study 2, we manipulated both easiness and type of error (miss vs. false alarm). The aid erred on either difficult trials alone (difficult errors group) or on difficult and easy trials (easy miss group; easy false alarm group). Results: In both experiments, easy errors led to participants mistrusting and disagreeing more with the aid on difficult trials, as compared with those using aids that generated only difficult errors. This resulted in a downward shift in decision criterion for the former, leading to poorer overall performance. Misses and false alarms led to similar effects. Conclusion: Automation errors on tasks that appear “easy” to the operator severely degrade trust and reliance. Application: Potential applications include the implementation of system design solutions that circumvent the negative effects of easy automation errors.",2006.0,44.0,231.0,False,,"{'volume': '48', 'pages': '241 - 256', 'name': 'Human Factors: The Journal of Human Factors and Ergonomics Society'}","{'bibtex': '@Article{Madhavan2006AutomationFO,\n author = {P. Madhavan and D. Wiegmann and Frank C. Lacson},\n journal = {Human Factors: The Journal of Human Factors and Ergonomics Society},\n pages = {241 - 256},\n title = {Automation Failures on Tasks Easily Performed by Operators Undermine Trust in Automated Aids},\n volume = {48},\n year = {2006}\n}\n'}","[{'authorId': '2820508', 'name': 'P. Madhavan'}, {'authorId': '2732870', 'name': 'D. Wiegmann'}, {'authorId': '2823736', 'name': 'Frank C. Lacson'}]"
659,37c02744688401c6624d2de49ba22b9d6506caaf,Attention and performance.,"Recent progress in the study of attention and performance is discussed, focusing on the nature of attentional control and the effects of practice. Generally speaking, the effects of mental set are proving more pervasive than was previously suspected, whereas automaticity is proving less robust. Stimulus attributes (e.g. onsets, transients) thought to have a ""wired-in"" ability to capture attention automatically have been shown to capture attention only as a consequence of voluntarily adopted task sets. Recent research suggests that practice does not have as dramatic effects as is commonly believed. While it may turn out that some mental operations are automatized in the strongest sense, this may be uncommon. Recent work on task switching is also described; optimal engagement in a task set is proving to be intimately tied to learning operations triggered by the actual performance of a new task, not merely the anticipation of such performance.",2001.0,84.0,637.0,False,,"{'volume': '52', 'pages': '\n          629-51\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Pashler2001AttentionAP,\n author = {H. Pashler and J. C. Johnston and E. Ruthruff},\n journal = {Annual review of psychology},\n pages = {\n          629-51\n        },\n title = {Attention and performance.},\n volume = {52},\n year = {2001}\n}\n'}","[{'authorId': '2310380', 'name': 'H. Pashler'}, {'authorId': '143607120', 'name': 'J. C. Johnston'}, {'authorId': '2159745', 'name': 'E. Ruthruff'}]"
660,37d116d50af56473b58c0c79a7ea6276cb142680,Authoring Game-based Interactive Narrative using Social Games and Comme il,"Comme il Faut is an artificial intelligence system and authoring strategy for creating game-based interactive stories about relationships and social interactions between characters. Using the abstraction of the social game, Comme il Faut creates experiences where specific dramatic interactions between characters arise from play. This paper describes the process of authoring for Comme il Faut. Specifically, we will describe the authoring and design considerations for Comme il Faut's inaugural game, The Prom. We discuss how we extracted and encoded an exaggerated social logic from pre-existing media experiences to create its intended story space, developed an idiosyncratic local culture for its story world, defined a set of character histories and personalities to be revealed through play, and authored the specific lines of dialogue and motivating social situations that give the audience experience of The Prom its particular character. Together, these produce an experience with much greater fictional specificity than in open-ended simulation games and many more options for what happens (and how things happen) than in traditional game stories.",2010.0,7.0,56.0,False,,,"{'bibtex': '@Inproceedings{Mccoy2010AuthoringGI,\n author = {Joshua Mccoy and Mike Treanor and B. Samuel and B. Tearse and Michael Mateas},\n title = {Authoring Game-based Interactive Narrative using Social Games and Comme il},\n year = {2010}\n}\n'}","[{'authorId': '38523727', 'name': 'Joshua Mccoy'}, {'authorId': '2952013', 'name': 'Mike Treanor'}, {'authorId': '144253835', 'name': 'B. Samuel'}, {'authorId': '2663075', 'name': 'B. Tearse'}, {'authorId': '114402462', 'name': 'Michael Mateas'}]"
661,37f2ba71dd16f26971e78ea824e3e36bece9ba3c,Modeling Norm Dynamics in Multiagent Systems,,2018.0,0.0,5.0,False,,"{'volume': '5', 'pages': '491-564', 'name': 'FLAP'}","{'bibtex': '@Article{Frantz2018ModelingND,\n author = {Christopher K. Frantz and G. Pigozzi},\n journal = {FLAP},\n pages = {491-564},\n title = {Modeling Norm Dynamics in Multiagent Systems},\n volume = {5},\n year = {2018}\n}\n'}","[{'authorId': '13474685', 'name': 'Christopher K. Frantz'}, {'authorId': '2251921', 'name': 'G. Pigozzi'}]"
662,37fde06dacf825ac8b33d340eb27bfbf65893146,Deep Facial Expression Recognition: A Survey,"With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and the recent success of deep learning techniques in various fields, deep neural networks have increasingly been leveraged to learn discriminative representations for automatic FER. Recent deep FER systems generally focus on two important issues: overfitting caused by a lack of sufficient training data and expression-unrelated variations, such as illumination, head pose, and identity bias. In this survey, we provide a comprehensive review of deep FER, including datasets and algorithms that provide insights into these intrinsic problems. First, we introduce the available datasets that are widely used in the literature and provide accepted data selection and evaluation principles for these datasets. We then describe the standard pipeline of a deep FER system with the related background knowledge and suggestions for applicable implementations for each stage. For the state-of-the-art in deep FER, we introduce existing novel deep neural networks and related training strategies that are designed for FER based on both static images and dynamic image sequences and discuss their advantages and limitations. Competitive performances and experimental comparisons on widely used benchmarks are also summarized. We then extend our survey to additional related issues and application scenarios. Finally, we review the remaining challenges and corresponding opportunities in this field as well as future directions for the design of robust deep FER systems.",2018.0,327.0,904.0,True,"{'url': 'https://arxiv.org/pdf/1804.08348', 'status': None}","{'volume': '13', 'pages': '1195-1215', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Li2018DeepFE,\n author = {Shan Li and Weihong Deng},\n journal = {IEEE Transactions on Affective Computing},\n pages = {1195-1215},\n title = {Deep Facial Expression Recognition: A Survey},\n volume = {13},\n year = {2018}\n}\n'}","[{'authorId': '2144502570', 'name': 'Shan Li'}, {'authorId': '1774956', 'name': 'Weihong Deng'}]"
663,38313dd4fbe9108e602cc70b76e35fd425cea5a2,Route planning for intelligent autonomous land vehicles using hierarchical terrain representation,"In this paper, an intelligent navigation system for autonomous land vehicles (ALV) using hierarchical terrain representation has been developed which can successfully negotiate an obstacle and threat-laden terrain, even if nothing is known beforehand about the terrain. The ALV stores new information in its memory as it travels, has the ability to backtrack out of unexpected dead ends, and performs spontaneous decision-making in the field based on local sensor readings. The optimal global route of the ALV journey is obtained using dynamic programming, and decision-making is accomplished via a production rule-based system. Execution examples demonstrate the power of the prototype system to solving navigation problems. This establishes the feasibility of constructing a valid ALV by combining search techniques with artificial intelligence tools such as production rule-based systems.",1987.0,6.0,22.0,False,,"{'volume': '4', 'pages': '1947-1952', 'name': 'Proceedings. 1987 IEEE International Conference on Robotics and Automation'}","{'bibtex': '@Article{Metea1987RoutePF,\n author = {Nark B. Metea and J. Tsai},\n journal = {Proceedings. 1987 IEEE International Conference on Robotics and Automation},\n pages = {1947-1952},\n title = {Route planning for intelligent autonomous land vehicles using hierarchical terrain representation},\n volume = {4},\n year = {1987}\n}\n'}","[{'authorId': '3453694', 'name': 'Nark B. Metea'}, {'authorId': '145118476', 'name': 'J. Tsai'}]"
664,3839a6a41e863151e380e3aa80fdbe594231a8dc,A methodology for building believable social agents,,1997.0,14.0,44.0,True,,{'pages': '114-121'},"{'bibtex': '@Inproceedings{Reilly1997AMF,\n author = {W. Scott Neal Reilly},\n pages = {114-121},\n title = {A methodology for building believable social agents},\n year = {1997}\n}\n'}","[{'authorId': '2239842555', 'name': 'W. Scott Neal Reilly'}]"
665,3840ecff1e0a35359be3409612df7f12b251aad8,Apathy is associated with lower inferior temporal cortical thickness in mild cognitive impairment and normal elderly individuals.,"Apathy is a common neuropsychiatric symptom in Alzheimer's disease dementia and amnestic mild cognitive impairment and is associated with cortical atrophy in Alzheimer's disease dementia. This study investigated possible correlations between apathy and cortical atrophy in 47 individuals with mild cognitive impairment and 19 clinically normal elderly. Backward elimination multivariate linear regression was used to evaluate the cross-sectional relationship between scores on the Apathy Evaluation Scale and thickness of several cortical regions and covariates. Lower inferior temporal cortical thickness was predictive of greater apathy. Greater anterior cingulate cortical thickness was also predictive of greater apathy, suggesting an underlying reactive process.",2015.0,41.0,53.0,True,"{'url': 'https://europepmc.org/articles/pmc4342844?pdf=render', 'status': None}","{'volume': '27 1', 'pages': '\n          e22-7\n        ', 'name': 'The Journal of neuropsychiatry and clinical neurosciences'}","{'bibtex': '@Article{Guercio2015ApathyIA,\n author = {B. Guercio and Nancy J. Donovan and Andrew M. Ward and A. Schultz and Natacha Lorius and R. Amariglio and D. Rentz and Keith A. Johnson and R. Sperling and G. Marshall},\n journal = {The Journal of neuropsychiatry and clinical neurosciences},\n pages = {\n          e22-7\n        },\n title = {Apathy is associated with lower inferior temporal cortical thickness in mild cognitive impairment and normal elderly individuals.},\n volume = {27 1},\n year = {2015}\n}\n'}","[{'authorId': '6855495', 'name': 'B. Guercio'}, {'authorId': '4181598', 'name': 'Nancy J. Donovan'}, {'authorId': '1946495146', 'name': 'Andrew M. Ward'}, {'authorId': '2442664', 'name': 'A. Schultz'}, {'authorId': '4001133', 'name': 'Natacha Lorius'}, {'authorId': '5217438', 'name': 'R. Amariglio'}, {'authorId': '2147040', 'name': 'D. Rentz'}, {'authorId': '32207254', 'name': 'Keith A. Johnson'}, {'authorId': '2289371', 'name': 'R. Sperling'}, {'authorId': '4205480', 'name': 'G. Marshall'}]"
666,3874d7aca02099fea52344a4ac42b8b1a5cdf5dd,Virtual Agents and 3D Virtual Worlds for Preserving and Simulating Cultures,,2009.0,18.0,31.0,False,,{'pages': '257-271'},"{'bibtex': '@Inproceedings{Bogdanovych2009VirtualAA,\n author = {A. Bogdanovych and J. A. Rodríguez and S. Simoff and A. Cohen},\n pages = {257-271},\n title = {Virtual Agents and 3D Virtual Worlds for Preserving and Simulating Cultures},\n year = {2009}\n}\n'}","[{'authorId': '2876469', 'name': 'A. Bogdanovych'}, {'authorId': '2116899991', 'name': 'J. A. Rodríguez'}, {'authorId': '2638499', 'name': 'S. Simoff'}, {'authorId': '2112929107', 'name': 'A. Cohen'}]"
667,38a9f63f23f33084ddeb08006fb118fe751480fe,ALMA: a layered model of affect,"In this paper we introduce ALMA - A Layered Model of Affect. It integrates three major affective characteristics: emotions, moods and personality that cover short, medium, and long term affect. The use of this model consists of two phases: In the preparation phase appraisal rules and personality profiles for characters must be specified with the help of AffectML - our XML based affect modeling language. In the runtime phase, the specified appraisal rules are used to compute real-time emotions and moods as results of a subjective appraisal of relevant input. The computed affective characteristics are represented in AffectML and can be processed by sub-sequent modules that control the cognitive processes and physical behavior of embodied conversational characters. ALMA is part of the VirtualHuman project which develops interactive virtual characters that serve as dialog partners with human-like conversational skills. ALMA provides our virtual humans with a personality profile and with real-time emotions and moods. These are used by the multimodal behavior generation module to enrich the lifelike and believable qualities.",2005.0,31.0,466.0,False,,{'pages': '29-36'},"{'bibtex': '@Inproceedings{Gebhard2005ALMAAL,\n author = {Patrick Gebhard},\n pages = {29-36},\n title = {ALMA: a layered model of affect},\n year = {2005}\n}\n'}","[{'authorId': '48785659', 'name': 'Patrick Gebhard'}]"
672,38bb261f5c0f7d5d150e7b306deec46544729908,Appraisal Theories of Emotion: State of the Art and Future Development,,2013.0,71.0,934.0,True,"{'url': 'https://biblio.ugent.be/publication/2958617/file/6776022.pdf', 'status': None}","{'volume': '5', 'pages': '119 - 124', 'name': 'Emotion Review'}","{'bibtex': '@Article{Moors2013AppraisalTO,\n author = {A. Moors and P. Ellsworth and K. Scherer and N. Frijda},\n journal = {Emotion Review},\n pages = {119 - 124},\n title = {Appraisal Theories of Emotion: State of the Art and Future Development},\n volume = {5},\n year = {2013}\n}\n'}","[{'authorId': '2064945', 'name': 'A. Moors'}, {'authorId': '4367292', 'name': 'P. Ellsworth'}, {'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '49584958', 'name': 'N. Frijda'}]"
673,38c465d415ca2b3f5225f36230347c8ebbd89768,Thespian: Modeling Socially Normative Behavior in a Decision-Theoretic Framework,,2006.0,26.0,57.0,False,,{'pages': '369-382'},"{'bibtex': '@Inproceedings{Si2006ThespianMS,\n author = {Mei Si and S. Marsella and D. Pynadath},\n pages = {369-382},\n title = {Thespian: Modeling Socially Normative Behavior in a Decision-Theoretic Framework},\n year = {2006}\n}\n'}","[{'authorId': '33432486', 'name': 'Mei Si'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '1748597', 'name': 'D. Pynadath'}]"
674,38f89c38060099d0f17279326cbd172f341ac62d,How to turn difficulties into opportunities: drawing from diversity to promote social cohesion,"Racism in Europe is an ongoing reality that shapes many people’s everyday lives. Diversity is often perceived as a barrier to social cohesion or educational success. These discourses are very often translated into measures that tend to assimilate or segregate those with a migrant or minority background. In this article, drawing from the results of the INCLUD‐ED project, it is argued that through the implementation of successful actions diversity can be turned into an opportunity to enhance learning and social cohesion.",2011.0,32.0,32.0,False,,"{'volume': '21', 'pages': '49 - 62', 'name': 'International Studies in Sociology of Education'}","{'bibtex': '@Article{Alexiu2011HowTT,\n author = {Teodor Mircea Alexiu and Teresa Sordé},\n journal = {International Studies in Sociology of Education},\n pages = {49 - 62},\n title = {How to turn difficulties into opportunities: drawing from diversity to promote social cohesion},\n volume = {21},\n year = {2011}\n}\n'}","[{'authorId': '81812330', 'name': 'Teodor Mircea Alexiu'}, {'authorId': '8277445', 'name': 'Teresa Sordé'}]"
675,3906485099c38d66ca4190e89fb308b08ad03bde,Gandalf: an embodied humanoid capable of real-time multimodal dialogue with people,"Gandalf is a fully autonomous, humanoid agent that perceives a user's multimodal actsNspeech, prosody, manual gesture, body language, gazeNand generates appropriate multimodal responses to these in real-time (speech, gaze, facial & manual gesture & head movement). Gandalf has knowledge about the solar system and can travel to and tell users about the planets and moons with speech and gesture. Gandalf demonstrates a coherent framework for psychosoical dialogue skills which enables the production of concurrent reactive and reflective behaviors and planning of communicative acts, with response cycles analogous to those found in human face-to-face dialogue, from 1/6th of a second and up. Gandalf has been tested in interaction with humans and shown to be capable of supporting and sustaining multimodal, situated, real-time dialogue. Content Areas: Interaction between people and agents, face-to-face communication, action selection and planning, real-time performance, synthetic agents.",1997.0,7.0,97.0,True,,{'pages': '536-537'},"{'bibtex': '@Inproceedings{Thórisson1997GandalfAE,\n author = {K. Thórisson},\n pages = {536-537},\n title = {Gandalf: an embodied humanoid capable of real-time multimodal dialogue with people},\n year = {1997}\n}\n'}","[{'authorId': '1727838', 'name': 'K. Thórisson'}]"
676,390e28272229ce2f17f4a3357e53c080a3f73c44,Enhancing daily living skills in four adults with autism spectrum disorder through an embodied digital technology-mediated intervention,,2019.0,51.0,27.0,False,,{'name': 'Research in Autism Spectrum Disorders'},"{'bibtex': '@Article{Pérez-Fuster2019EnhancingDL,\n author = {Patricia Pérez-Fuster and Javier Sevilla and Gerardo Herrera},\n journal = {Research in Autism Spectrum Disorders},\n title = {Enhancing daily living skills in four adults with autism spectrum disorder through an embodied digital technology-mediated intervention},\n year = {2019}\n}\n'}","[{'authorId': '1399053598', 'name': 'Patricia Pérez-Fuster'}, {'authorId': '143732702', 'name': 'Javier Sevilla'}, {'authorId': '146803518', 'name': 'Gerardo Herrera'}]"
677,3921f459a9ee26827963abc4abf013b4cc9cbd32,Crowds by Example,"We present an example‐based crowd simulation technique. Most crowd simulation techniques assume that the behavior exhibited by each person in the crowd can be defined by a restricted set of rules. This assumption limits the behavioral complexity of the simulated agents. By learning from real‐world examples, our autonomous agents display complex natural behaviors that are often missing in crowd simulations. Examples are created from tracked video segments of real pedestrian crowds. During a simulation, autonomous agents search for examples that closely match the situation that they are facing. Trajectories taken by real people in similar situations, are copied to the simulated agents, resulting in seemingly natural behaviors.",2007.0,33.0,894.0,False,,"{'volume': '26', 'name': 'Computer Graphics Forum'}","{'bibtex': '@Article{Lerner2007CrowdsBE,\n author = {Alon Lerner and Y. Chrysanthou and Dani Lischinski},\n journal = {Computer Graphics Forum},\n title = {Crowds by Example},\n volume = {26},\n year = {2007}\n}\n'}","[{'authorId': '39149037', 'name': 'Alon Lerner'}, {'authorId': '1706408', 'name': 'Y. Chrysanthou'}, {'authorId': '1684384', 'name': 'Dani Lischinski'}]"
678,3922d7f8862f89248c2a09533e8ccd130b35d1ed,The Persistence of First Impressions: The Effect of Repeated Interactions on the Perception of a Social Robot,"Numerous studies in social psychology have shown that familiarization across repeated interactions improves people’s perception of the other. If and how these findings relate to human-robot interaction (HRI) is not well understood, even though such knowledge is crucial when pursuing long-term interactions. In our work, we investigate the persistence of first impressions by asking 49 participants to play a geography game with a robot. We measure how their perception of the robot changes over three sessions with three to ten days of zero exposure in between. Our results show that different perceptual dimensions stabilize within different time frames, with the robot’s competence being the fastest to stabilize and perceived threat the most fluctuating over time. We also found evidence that perceptual differences between robots with varying levels of humanlikeness persist across repeated interactions. This study has important implications for HRI design as it sheds new light on the influence of robots’ embodiment and interaction abilities. Moreover, it also impacts HRI theory as it presents novel findings contributing to research on the uncanny valley and robot perception in general. CCS CONCEPTS •Human-centered computing → Empirical studies in HCI; Natural language interfaces; •Computer systems organization →Robotics; •Computing methodologies →Intelligent agents. ACM Reference Format: Maike Paetzel, Giulia Perugia, and Ginevra Castellano. 2020. The Persistence of First Impressions: The Effect of Repeated Interactions on the Perception of a Social Robot. In Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (HRI ’20), March 23–26, 2020, Cambridge, United Kingdom. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ 3319502.3374786",2020.0,61.0,55.0,False,,"{'pages': '73-82', 'name': '2020 15th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Paetzel2020ThePO,\n author = {Maike Paetzel and G. Perugia and Ginevra Castellano},\n journal = {2020 15th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {73-82},\n title = {The Persistence of First Impressions: The Effect of Repeated Interactions on the Perception of a Social Robot},\n year = {2020}\n}\n'}","[{'authorId': '2710492', 'name': 'Maike Paetzel'}, {'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
679,392446af8e704efcc2b795309275b3006a21ee5e,Effects of emotional content on working memory capacity,"ABSTRACT Emotional events tend to be remembered better than neutral events, but emotional states and stimuli may also interfere with cognitive processes that underlie memory performance. The current study investigated the effects of emotional content on working memory capacity (WMC), which involves both short term storage and executive attention control. We tested competing hypotheses in a preregistered experiment (N = 297). The emotional enhancement hypothesis predicts that emotional stimuli attract attention and additional processing resources relative to neutral stimuli, thereby making it easier to encode and store emotional information in WMC. The emotional impairment hypothesis, by contrast, predicts that emotional stimuli interfere with attention control and the active maintenance of information in working memory. Participants completed a common measure of WMC (the operation span task; Turner, M. L., & Engle, R. W. [1989]. Is working memory capacity task dependent? Journal of Memory and Language, 28, 127–154) that included either emotional or neutral words. Results revealed that WMC was reduced for emotional words relative to neutral words, consistent with the emotional impairment hypothesis.",2019.0,33.0,22.0,False,,"{'volume': '33', 'pages': '370 - 377', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Garrison2019EffectsOE,\n author = {Katie E Garrison and B. Schmeichel},\n journal = {Cognition and Emotion},\n pages = {370 - 377},\n title = {Effects of emotional content on working memory capacity},\n volume = {33},\n year = {2019}\n}\n'}","[{'authorId': '19194781', 'name': 'Katie E Garrison'}, {'authorId': '4555303', 'name': 'B. Schmeichel'}]"
680,39271ddb2c8a40e5d4d8430d7e24b1498ef4f944,Multiple meanings of behavior: Construing actions in terms of competence or morality.,"Multiplicity of behavior features gives rise to its different interpretations (in addition to behavior vagueness and ambiguity typically studied in social cognition research). Particularly, identical actions are construable both in moral and competence-related categories due to distinct behavioral features underlying each of these interpretations. It was hypothesized that the two construals are alternatively used by the perceiver. Because of perspective-dependent differences in accessibility and applicability of competence and moral categories, it was hypothesized that actors interpret their own behavior in competence terms, whereas observers interpret it in moral categories, and that within the actor perspective, competence construal is used to a higher degree by male than female perceivers, but the opposite is true for moral construal",1994.0,34.0,302.0,False,,"{'volume': '67', 'pages': '222-232', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Wojciszke1994MultipleMO,\n author = {B. Wojciszke},\n journal = {Journal of Personality and Social Psychology},\n pages = {222-232},\n title = {Multiple meanings of behavior: Construing actions in terms of competence or morality.},\n volume = {67},\n year = {1994}\n}\n'}","[{'authorId': '2585858', 'name': 'B. Wojciszke'}]"
681,392917176507d775d840e9532f1beadd0b74cf27,The Design Experience,,2016.0,0.0,11.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cooper2016TheDE,\n author = {R. Cooper and M. Press},\n title = {The Design Experience},\n year = {2016}\n}\n'}","[{'authorId': '144931305', 'name': 'R. Cooper'}, {'authorId': '144380860', 'name': 'M. Press'}]"
682,39447676a45d3ddb31bf19ab0c9885ed24a2d57d,The design of motivational agents and avatars,,2011.0,52.0,162.0,False,,"{'volume': '59', 'pages': '291-300', 'name': 'Educational Technology Research and Development'}","{'bibtex': '@Article{Baylor2011TheDO,\n author = {A. L. Baylor},\n journal = {Educational Technology Research and Development},\n pages = {291-300},\n title = {The design of motivational agents and avatars},\n volume = {59},\n year = {2011}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}]"
684,394a647e390ab215cb5a30e861f80d3295a5a9bb,Major depression: behavioral markers of depression and recovery.,"The concepts of psychosocial and psychomotor inhibition characteristic of major depression are based primarily on clinical observations. It is possible to describe and define these two types of inhibition by means of a systematic, quantitative ethological (behavioral) approach, which singles out precise and significant behavior markers. This investigation focuses on the behavioral features of psychosocial and psychomotor inhibition in 11 hospitalized depressed subjects and their changes during clinical recovery. The hypothesis that major depression is characterized by a significant reduction of social interaction is tested (psycho-intellectual inhibition is not addressed). Results show significant behavioral differences between depressed and recovered subjects with depression being characterized by a significant reduction of social interaction, whereas self occupation and body mobility are reduced to a lesser degree. Behavior markers for depression include nonspecific gaze, withdrawal, no mouth movements, no eye region movements, and social inactivity. Behavior markers for recovery include socially interested, social smile, verbal social initiative, speech, nod, raised eyebrows, wrinkled eyebrows, social laughter, gesticulation, drum one's fingers, point, and help. Findings point to tendencies toward two types of major depression and two types of recovery. A companion paper (Schelde, this journal) addresses theoretical issues.",1998.0,0.0,34.0,False,,"{'volume': '186 3', 'pages': '\n          133-40\n        ', 'name': 'The Journal of nervous and mental disease'}","{'bibtex': '@Article{Schelde1998MajorDB,\n author = {J. Schelde},\n journal = {The Journal of nervous and mental disease},\n pages = {\n          133-40\n        },\n title = {Major depression: behavioral markers of depression and recovery.},\n volume = {186 3},\n year = {1998}\n}\n'}","[{'authorId': '5450623', 'name': 'J. Schelde'}]"
685,396a7df3c1c55d95255c505dc9ccaffe0e3257e3,Laterlized facial muscle response to positive and negative emotional stimuli.,"Facial electromyography (EMG) was recorded from left and right zygomatic and corrugator muscle regions in response to reflective questions and during voluntary facial expressions. Both muscle regions showed consistent responses to five emotions (happiness, excitement, neutral, sadness, and fear) evoked in the involuntary condition (i.e. reflective questions) and four emotional facial expressions (happiness, excitement, sadness, and fear) self-generated in the voluntary condition. Lateralized responses were found for the zygomatic muscle in the involuntary condition: positive emotion questions elicited relatively greater right muscle activity than left muscle activity, while negative emotion questions elicited relatively greater left muscle activity than right muscle activity. Lateralized responses were found for the corrugator muscle in the voluntary condition, but were not significantly related to type of emotional expression. Sex differences indicating greater lateralization for females were found in some of the measures. The results are consistent with the hypothesized specialization of the left and right cerebral hemispheres for the mediation of positive and negative emotions, respectively.",1979.0,29.0,204.0,False,,"{'volume': '16 6', 'pages': '\n          561-71\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Schwartz1979LaterlizedFM,\n author = {Gary E. Schwartz and G. Ahern and Serena-lynn Brown},\n journal = {Psychophysiology},\n pages = {\n          561-71\n        },\n title = {Laterlized facial muscle response to positive and negative emotional stimuli.},\n volume = {16 6},\n year = {1979}\n}\n'}","[{'authorId': '2172995181', 'name': 'Gary E. Schwartz'}, {'authorId': '2073749', 'name': 'G. Ahern'}, {'authorId': '115455129', 'name': 'Serena-lynn Brown'}]"
686,3974ebb9db25ae9e4644d7ceb5831e3376190d0a,Multimodal expressive embodied conversational agents,"In this paper we present our work toward the creation of a multimodal expressive Embodied Conversational Agent (ECA). Our agent, called Greta, exhibits nonverbal behaviors synchronized with speech. We are using the taxonomy of communicative functions developed by Isabella Poggi [22] to specify the behavior of the agent. Based on this taxonomy a representation language, Affective Presentation Markup Language, APML has been defined to drive the animation of the agent [4]. Lately, we have been working on creating no longer a generic agent but an agent with individual characteristics. We have been concentrated on the behavior specification for an individual agent. In particular we have defined a set of parameters to change the expressivity of the agent's behaviors. Six parameters have been defined and implemented to encode gesture and face expressivity. We have performed perceptual studies of our expressivity model.",2005.0,29.0,137.0,False,,{'name': 'Proceedings of the 13th annual ACM international conference on Multimedia'},"{'bibtex': '@Article{Pelachaud2005MultimodalEE,\n author = {C. Pelachaud},\n journal = {Proceedings of the 13th annual ACM international conference on Multimedia},\n title = {Multimodal expressive embodied conversational agents},\n year = {2005}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}]"
687,3985df5d3be8c96e7e6ea83ab20cada776a54915,Surround-screen projection-based virtual reality: the design and implementation of the CAVE,"This paper describes the CAVE (CAVE Automatic Virtual Environment) virtual reality/scientific visualization system in detail and demonstrates that projection technology applied to virtual-reality goals achieves a system that matches the quality of workstation screens in terms of resolution, color, and flicker-free stereo. In addition, this format helps reduce the effect of common tracking and system latency errors. The off-axis perspective projection techniques we use are shown to be simple and straightforward. Our techniques for doing multi-screen stereo vision are enumerated, and design barriers, past and current, are described. Advantages and disadvantages of the projection paradigm are discussed, with an analysis of the effect of tracking noise and delay on the user. Successive refinement, a necessary tool for scientific visualization, is developed in the virtual reality context. The use of the CAVE as a one-to-many presentation device at SIGGRAPH '92 and Supercomputing '92 for computational science data is also mentioned.",1993.0,16.0,2874.0,False,,{'name': 'Proceedings of the 20th annual conference on Computer graphics and interactive techniques'},"{'bibtex': '@Article{Cruz-Neira1993SurroundscreenPV,\n author = {C. Cruz-Neira and D. Sandin and T. DeFanti},\n journal = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques},\n title = {Surround-screen projection-based virtual reality: the design and implementation of the CAVE},\n year = {1993}\n}\n'}","[{'authorId': '1398664231', 'name': 'C. Cruz-Neira'}, {'authorId': '145464769', 'name': 'D. Sandin'}, {'authorId': '2029117', 'name': 'T. DeFanti'}]"
688,399da68d3b97218b6c80262df7963baa89dcc71b,SRILM - an extensible language modeling toolkit,"SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools.",2002.0,37.0,5128.0,False,,{'pages': '901-904'},"{'bibtex': '@Inproceedings{Stolcke2002SRILMA,\n author = {A. Stolcke},\n pages = {901-904},\n title = {SRILM - an extensible language modeling toolkit},\n year = {2002}\n}\n'}","[{'authorId': '1762744', 'name': 'A. Stolcke'}]"
689,39ddd2b1b678fadfa0e84c94ba319425c93ab97e,Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship,"Interfaces that talk and listen are populating computers, cars, call centers, and even home appliances and toys, but voice interfaces invariably frustrate rather than help. In Wired for Speech, Clifford Nass and Scott Brave reveal how interactive voice technologies can readily and effectively tap into the automatic responses all speech -- whether from human or machine -- evokes. Wired for Speech demonstrates that people are ""voice-activated"": we respond to voice technologies as we respond to actual people and behave as we would in any social situation. By leveraging this powerful finding, voice interfaces can truly emerge as the next frontier for efficient, user-friendly technology.Wired for Speech presents new theories and experiments and applies them to critical issues concerning how people interact with technology-based voices. It considers how people respond to a female voice in e-commerce (does stereotyping matter?), how a car's voice can promote safer driving (are ""happy"" cars better cars?), whether synthetic voices have personality and emotion (is sounding like a person always good?), whether an automated call center should apologize when it cannot understand a spoken request (""To Err is Interface; To Blame, Complex""), and much more. Nass and Brave's deep understanding of both social science and design, drawn from ten years of research at Nass's Stanford laboratory, produces results that often challenge conventional wisdom and common design practices. These insights will help designers and marketers build better interfaces, scientists construct better theories, and everyone gain better understandings of the future of the machines that speak with us.",2005.0,0.0,228.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Nass2005WiredFS,\n author = {C. Nass and Scott Brave},\n title = {Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship},\n year = {2005}\n}\n'}","[{'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '2739604', 'name': 'Scott Brave'}]"
690,39f4b885274e2577cbba78f46f13e7dccd55df4b,Using gamification to motivate children to complete empirical studies in lab environments,"In this paper, we describe the challenges we encountered and solutions we developed while collecting mobile touch and gesture interaction data in laboratory conditions from children ages 5 to 7 years old. We identify several challenges of conducting empirical studies with young children, including study length, motivation, and environment. We then propose and validate techniques for designing study protocols for this age group, focusing on the use of gamification components to better engage children in laboratory studies. The use of gamification increased our study task completion rates from 73% to 97%. This research contributes a better understanding of how to design study protocols for young children when lab studies are needed or preferred. Research with younger age groups alongside older children, adults, and special populations can lead to more sound guidelines for universal usability of mobile applications.",2013.0,20.0,98.0,False,,{'name': 'Proceedings of the 12th International Conference on Interaction Design and Children'},"{'bibtex': '@Article{Brewer2013UsingGT,\n author = {Robin N. Brewer and Lisa Anthony and Quincy Brown and Germaine Irwin and Jaye Nias and B. Tate},\n journal = {Proceedings of the 12th International Conference on Interaction Design and Children},\n title = {Using gamification to motivate children to complete empirical studies in lab environments},\n year = {2013}\n}\n'}","[{'authorId': '145664318', 'name': 'Robin N. Brewer'}, {'authorId': '145757861', 'name': 'Lisa Anthony'}, {'authorId': '145693580', 'name': 'Quincy Brown'}, {'authorId': '29905953', 'name': 'Germaine Irwin'}, {'authorId': '3009026', 'name': 'Jaye Nias'}, {'authorId': '39590030', 'name': 'B. Tate'}]"
691,39fc78bc0ee863a18a202efd684bc8c12ba65501,Features Importance Analysis for Emotional Speech Classification,,2005.0,13.0,48.0,False,,{'pages': '449-457'},"{'bibtex': '@Inproceedings{Tao2005FeaturesIA,\n author = {J. Tao and Yongguo Kang},\n pages = {449-457},\n title = {Features Importance Analysis for Emotional Speech Classification},\n year = {2005}\n}\n'}","[{'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '1729563', 'name': 'Yongguo Kang'}]"
692,3a1a2cff2b70fb84a7ca7d97f8adcc5855851795,The Kaldi Speech Recognition Toolkit,"We describe the design of Kaldi, a free, open-source toolkit for speech recognition research. Kaldi provides a speech recognition system based on finite-state automata (using the freely available OpenFst), together with detailed documentation and a comprehensive set of scripts for building complete recognition systems. Kaldi is written is C++, and the core library supports modeling of arbitrary phonetic-context sizes, acoustic modeling with subspace Gaussian mixture models (SGMM) as well as standard Gaussian mixture models, together with all commonly used linear and affine transforms. Kaldi is released under the Apache License v2.0, which is highly nonrestrictive, making it suitable for a wide community of users.",2011.0,26.0,5947.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Povey2011TheKS,\n author = {Daniel Povey and Arnab Ghoshal and Gilles Boulianne and L. Burget and O. Glembek and N. Goel and M. Hannemann and P. Motlícek and Y. Qian and Petr Schwarz and J. Silovský and G. Stemmer and Karel Veselý},\n title = {The Kaldi Speech Recognition Toolkit},\n year = {2011}\n}\n'}","[{'authorId': '1792214', 'name': 'Daniel Povey'}, {'authorId': '2268620', 'name': 'Arnab Ghoshal'}, {'authorId': '2541218', 'name': 'Gilles Boulianne'}, {'authorId': '1816892', 'name': 'L. Burget'}, {'authorId': '3075141', 'name': 'O. Glembek'}, {'authorId': '46356878', 'name': 'N. Goel'}, {'authorId': '2592983', 'name': 'M. Hannemann'}, {'authorId': '2745667', 'name': 'P. Motlícek'}, {'authorId': '2480051', 'name': 'Y. Qian'}, {'authorId': '35455336', 'name': 'Petr Schwarz'}, {'authorId': '3330139', 'name': 'J. Silovský'}, {'authorId': '1708033', 'name': 'G. Stemmer'}, {'authorId': '2459598', 'name': 'Karel Veselý'}]"
694,3a46c26d15fd3ad9e4ec3a70bfeb3f22f7af9ccd,Positive affect and decision making.,,1993.0,0.0,1439.0,False,,"{'volume': '', 'pages': '261-277', 'name': ''}","{'bibtex': '@Inproceedings{Isen1993PositiveAA,\n author = {Alice M. Isen},\n pages = {261-277},\n title = {Positive affect and decision making.},\n year = {1993}\n}\n'}","[{'authorId': '3865216', 'name': 'Alice M. Isen'}]"
695,3a60678ad2b862fa7c27b11f04c93c010cc6c430,A Multimodal Database for Affect Recognition and Implicit Tagging,"MAHNOB-HCI is a multimodal database recorded in response to affective stimuli with the goal of emotion recognition and implicit tagging research. A multimodal setup was arranged for synchronized recording of face videos, audio signals, eye gaze data, and peripheral/central nervous system physiological signals. Twenty-seven participants from both genders and different cultural backgrounds participated in two experiments. In the first experiment, they watched 20 emotional videos and self-reported their felt emotions using arousal, valence, dominance, and predictability as well as emotional keywords. In the second experiment, short videos and images were shown once without any tag and then with correct or incorrect tags. Agreement or disagreement with the displayed tags was assessed by the participants. The recorded videos and bodily responses were segmented and stored in a database. The database is made available to the academic community via a web-based system. The collected data were analyzed and single modality and modality fusion results for both emotion recognition and implicit tagging experiments are reported. These results show the potential uses of the recorded modalities and the significance of the emotion elicitation protocol.",2012.0,48.0,1112.0,True,"{'url': 'http://ibug.doc.ic.ac.uk/media/uploads/documents/taffcsi-2010-11-0112-2.pdf', 'status': None}","{'volume': '3', 'pages': '42-55', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Soleymani2012AMD,\n author = {M. Soleymani and J. Lichtenauer and T. Pun and M. Pantic},\n journal = {IEEE Transactions on Affective Computing},\n pages = {42-55},\n title = {A Multimodal Database for Affect Recognition and Implicit Tagging},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '152714397', 'name': 'M. Soleymani'}, {'authorId': '2796371', 'name': 'J. Lichtenauer'}, {'authorId': '1809085', 'name': 'T. Pun'}, {'authorId': '145387780', 'name': 'M. Pantic'}]"
696,3a7895b17db0cda7bbf86bcda52c46a3e03b6ded,DialogueRNN: An Attentive RNN for Emotion Detection in Conversations,"Emotion detection in conversations is a necessary step for a number of applications, including opinion mining over chat history, social media threads, debates, argumentation mining, understanding consumer feedback in live conversations, and so on. Currently systems do not treat the parties in the conversation individually by adapting to the speaker of each utterance. In this paper, we describe a new method based on recurrent neural networks that keeps track of the individual party states throughout the conversation and uses this information for emotion classification. Our model outperforms the state-of-the-art by a significant margin on two different datasets.",2018.0,26.0,461.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/4657/4535', 'status': None}",{'pages': '6818-6825'},"{'bibtex': '@Inproceedings{Majumder2018DialogueRNNAA,\n author = {Navonil Majumder and Soujanya Poria and Devamanyu Hazarika and Rada Mihalcea and Alexander Gelbukh and E. Cambria},\n pages = {6818-6825},\n title = {DialogueRNN: An Attentive RNN for Emotion Detection in Conversations},\n year = {2018}\n}\n'}","[{'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}, {'authorId': '1747784', 'name': 'Alexander Gelbukh'}, {'authorId': '49943757', 'name': 'E. Cambria'}]"
697,3a8ca154126cfbdfa6ab1787a0264c8739cfea4f,Consensus-Based Human-Agent Interaction Model for Emotion Regulation in ASD,,2019.0,7.0,2.0,False,,{'pages': '295-301'},"{'bibtex': '@Article{Park2019ConsensusBasedHI,\n author = {C. Park and Hifza Javed and M. Jeon},\n booktitle = {Interacción},\n pages = {295-301},\n title = {Consensus-Based Human-Agent Interaction Model for Emotion Regulation in ASD},\n year = {2019}\n}\n'}","[{'authorId': '1695172', 'name': 'C. Park'}, {'authorId': '2079306', 'name': 'Hifza Javed'}, {'authorId': '2572836', 'name': 'M. Jeon'}]"
698,3aa4404958b5cb69bf4e4c93fda6cff1648d4ffb,Recognition Profile of Emotions in Natural and Virtual Faces,"Background Computer-generated virtual faces become increasingly realistic including the simulation of emotional expressions. These faces can be used as well-controlled, realistic and dynamic stimuli in emotion research. However, the validity of virtual facial expressions in comparison to natural emotion displays still needs to be shown for the different emotions and different age groups. Methodology/Principal Findings Thirty-two healthy volunteers between the age of 20 and 60 rated pictures of natural human faces and faces of virtual characters (avatars) with respect to the expressed emotions: happiness, sadness, anger, fear, disgust, and neutral. Results indicate that virtual emotions were recognized comparable to natural ones. Recognition differences in virtual and natural faces depended on specific emotions: whereas disgust was difficult to convey with the current avatar technology, virtual sadness and fear achieved better recognition results than natural faces. Furthermore, emotion recognition rates decreased for virtual but not natural faces in participants over the age of 40. This specific age effect suggests that media exposure has an influence on emotion recognition. Conclusions/Significance Virtual and natural facial displays of emotion may be equally effective. Improved technology (e.g. better modelling of the naso-labial area) may lead to even better results as compared to trained actors. Due to the ease with which virtual human faces can be animated and manipulated, validated artificial emotional expressions will be of major relevance in future research and therapeutic applications.",2008.0,46.0,109.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0003628&type=printable', 'status': None}","{'volume': '3', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Dyck2008RecognitionPO,\n author = {M. Dyck and Maren Winbeck and Susanne Leiberg and Yuhan Chen and R. C. Gur and K. Mathiak},\n journal = {PLoS ONE},\n title = {Recognition Profile of Emotions in Natural and Virtual Faces},\n volume = {3},\n year = {2008}\n}\n'}","[{'authorId': '3108830', 'name': 'M. Dyck'}, {'authorId': '3660635', 'name': 'Maren Winbeck'}, {'authorId': '2178712', 'name': 'Susanne Leiberg'}, {'authorId': '2115868005', 'name': 'Yuhan Chen'}, {'authorId': '40217273', 'name': 'R. C. Gur'}, {'authorId': '2448724', 'name': 'K. Mathiak'}]"
701,3ab6b1dfe63c9527bd74cdd8283426811d517740,Anxiety Increases the Feeling of Presence in Virtual Reality,"Given previous studies indicating a significant correlation between anxiety and presence, the purpose of this investigation was to explore the direction of the causal relationship between them. The sample consisted of 31 adults suffering from snake phobia. The study featured a randomized within-between design with two conditions and three counterbalanced immersions: (a) a baseline control immersion (BASELINE), (b) an immersion in a threatening and anxiety-inducing environment (ANX), and (c) an immersion in a nonthreatening environment that should not induce anxiety (NOANX). In the NOANX environment, participants were immersed for 5 min in a virtual Egyptian desert. They were told that the environment was safe and contained no snakes. The ANX immersion was identical, except that participants were led to believe that a multitude of hidden and dangerous snakes were lurking in the environment. A period of distraction (reading a text on relaxation) separated the ANX and NOANX immersions. Experimenters recorded presence and anxiety in the middle of and after each VR immersion. These brief measures of presence supported our hypothesis and were significantly higher in the anxious immersion than in the baseline or the nonanxious immersion. This finding was not corroborated by the presence questionnaire, where scores varied significantly in the opposite direction. The results from the brief one-item measures of presence support the significant contribution of emotions felt during the immersion on the subjective feeling of presence. The mixed results with the presence questionnaire are discussed, along with psychological factors potentially involved in presence.",2008.0,69.0,159.0,False,,"{'volume': '17', 'pages': '376-391', 'name': 'PRESENCE: Teleoperators and Virtual Environments'}","{'bibtex': '@Article{Bouchard2008AnxietyIT,\n author = {S. Bouchard and J. St-Jacques and Geneviève Robillard and P. Renaud},\n journal = {PRESENCE: Teleoperators and Virtual Environments},\n pages = {376-391},\n title = {Anxiety Increases the Feeling of Presence in Virtual Reality},\n volume = {17},\n year = {2008}\n}\n'}","[{'authorId': '144981172', 'name': 'S. Bouchard'}, {'authorId': '1403100009', 'name': 'J. St-Jacques'}, {'authorId': '35912970', 'name': 'Geneviève Robillard'}, {'authorId': '39993457', 'name': 'P. Renaud'}]"
702,3aca0ab1638e6d05b4811d54ff547794678d3fb4,A Computational Study of Expressive Facial Dynamics in Children with Autism,"Several studies have established that facial expressions of children with autism are often perceived as atypical, awkward or less engaging by typical adult observers. Despite this clear deficit in the quality of facial expression production, very little is understood about its underlying mechanisms and characteristics. This paper takes a computational approach to studying details of facial expressions of children with high functioning autism (HFA). The objective is to uncover those characteristics of facial expressions, notably distinct from those in typically developing children, and which are otherwise difficult to detect by visual inspection. We use motion capture data obtained from subjects with HFA and typically developing subjects while they produced various facial expressions. This data is analyzed to investigate how the overall and local facial dynamics of children with HFA differ from their typically developing peers. Our major observations include reduced complexity in the dynamic facial behavior of the HFA group arising primarily from the eye region.",2018.0,35.0,53.0,True,,"{'volume': '9', 'pages': '14-20', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Guha2018ACS,\n author = {T. Guha and Zhaojun Yang and R. Grossman and Shrikanth S. Narayanan},\n journal = {IEEE Transactions on Affective Computing},\n pages = {14-20},\n title = {A Computational Study of Expressive Facial Dynamics in Children with Autism},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '1720741', 'name': 'T. Guha'}, {'authorId': '3161887', 'name': 'Zhaojun Yang'}, {'authorId': '35711564', 'name': 'R. Grossman'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
703,3ad11696a552d86f3903efc593968e2492cc6b22,Intrinsic and extrinsic motivators of attachment under active inference,"This paper addresses the formation of infant attachment types within the context of active inference: a holistic account of action, perception and learning in the brain. We show how the organised forms of attachment (secure, avoidant and ambivalent) might arise in (Bayesian) infants. Specifically, we show that these distinct forms of attachment emerge from a minimisation of free energy—over interoceptive states relating to internal stress levels—when seeking proximity to caregivers who have a varying impact on these interoceptive states. In line with empirical findings in disrupted patterns of affective communication, we then demonstrate how exteroceptive cues (in the form of caregiver-mediated AMBIANCE affective communication errors, ACE) can result in disorganised forms of attachment in infants of caregivers who consistently increase stress when the infant seeks proximity, but can have an organising (towards ambivalence) effect in infants of inconsistent caregivers. In particular, we differentiate disorganised attachment from avoidance in terms of the high epistemic value of proximity seeking behaviours (resulting from the caregiver’s misleading exteroceptive cues) that preclude the emergence of coherent and organised behavioural policies. Our work, the first to formulate infant attachment in terms of active inference, makes a new testable prediction with regards to the types of affective communication errors that engender ambivalent attachment.",2018.0,124.0,10.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0193955&type=printable', 'status': None}","{'volume': '13', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Cittern2018IntrinsicAE,\n author = {David Cittern and T. Nolte and Karl J. Friston and A. Edalat},\n journal = {PLoS ONE},\n title = {Intrinsic and extrinsic motivators of attachment under active inference},\n volume = {13},\n year = {2018}\n}\n'}","[{'authorId': '2585368', 'name': 'David Cittern'}, {'authorId': '38852400', 'name': 'T. Nolte'}, {'authorId': '1737497', 'name': 'Karl J. Friston'}, {'authorId': '1694989', 'name': 'A. Edalat'}]"
704,3ad8e10d867e7338195545780556fe695b85eccb,Science Perspectives on Psychological,"Dual-process and dual-system theories in both cognitive and social psychology have been subjected to a number of recently published criticisms. However, they have been attacked as a category, incorrectly assuming there is a generic version that applies to all. We identify and respond to 5 main lines of argument made by such critics. We agree that some of these arguments have force against some of the theories in the literature but believe them to be overstated. We argue that the dual-processing distinction is supported by much recent evidence in cognitive science. Our preferred theoretical approach is one in which rapid autonomous processes (Type 1) are assumed to yield default responses unless intervened on by distinctive higher order reasoning processes (Type 2). What defines the difference is that Type 2 processing supports hypothetical thinking and load heavily on working memory.",,124.0,2585.0,False,,,"{'bibtex': '@Misc{None,\n title = {Science Perspectives on Psychological}\n}\n'}",[]
705,3b197ec2caae32f8a14b88ce981c61027cfe5218,ANALYSIS OF GAMIFICATION OF EDUCATION,"In the last decade, there has been considerable literature on gamification of education. Based on the resulting experience, the educational community indicate consensus on necessity of “gamification” of education to improve the quality of education. The study presented here is motivated by this necessity and aim to review literature related to the use of gamification of education. “Gamification” is about motivation and engagement. Making learning fun does not require huge investments in technology. Instead, focusing on the ways that entertainment technology engages us can result in methods that we can transfer to any learning situation. Many educators have attempted, with varying degrees of success, to effectively operate game elements to increase student motivation and achievement in the classroom. There have been many obstacles in their courses as the intellectual challenges of mastering the content of the course. To overcome these obstacles, students are expected to engage in critical thinking and push themselves to consider new ideas. In order to overcome these obstacles, a large collection of proven techniques such as abstraction, decomposition, iteration and recursion which has called computational thinking will be integrated to gamification of education.",2017.0,7.0,126.0,False,,,"{'bibtex': '@Inproceedings{Avsar2017ANALYSISOG,\n author = {Emel Koc Avsar},\n title = {ANALYSIS OF GAMIFICATION OF EDUCATION},\n year = {2017}\n}\n'}","[{'authorId': '2082630368', 'name': 'Emel Koc Avsar'}]"
706,3b1a88437b4be845ff1a3145eca3fe0f8691c37b,Recognition of facial emotional expressions from moving and static displays by individuals with mental retardation.,"Moving and static videotaped and photographic displays of posed emotional expressions were presented to 12 adults with mental retardation and 12 without mental retardation to investigate the role of movement in the recognition of facial expressions of emotion. Participants chose the corresponding emotion portrayed by the displays from among six written and pictorial labels of the emotions. Results indicated that individuals with mental retardation were significantly poorer at identifying anger, fear, disgust, and surprise. Both groups performed significantly better on the moving as opposed to the static videotaped displays of the emotions sad and angry. Visual-perceptual limitations are likely contributors to the poorer performance of the group with mental retardation in recognizing moving and static facial expressions of emotion.",1999.0,0.0,142.0,False,,"{'volume': '104 3', 'pages': '\n          270-8\n        ', 'name': 'American journal of mental retardation : AJMR'}","{'bibtex': '@Article{Harwood1999RecognitionOF,\n author = {Natalie K. Harwood and Laura J. Hall and A. Shinkfield},\n journal = {American journal of mental retardation : AJMR},\n pages = {\n          270-8\n        },\n title = {Recognition of facial emotional expressions from moving and static displays by individuals with mental retardation.},\n volume = {104 3},\n year = {1999}\n}\n'}","[{'authorId': '2253730768', 'name': 'Natalie K. Harwood'}, {'authorId': '2253619625', 'name': 'Laura J. Hall'}, {'authorId': '5029045', 'name': 'A. Shinkfield'}]"
707,3b22ce4c3243a0fc2ff68d91c7e1ae085f276452,Reciprocal Velocity Obstacles for real-time multi-agent navigation,"In this paper, we propose a new concept - the ""Reciprocal Velocity Obstacle""- for real-time multi-agent navigation. We consider the case in which each agent navigates independently without explicit communication with other agents. Our formulation is an extension of the Velocity Obstacle concept [3], which was introduced for navigation among (passively) moving obstacles. Our approach takes into account the reactive behavior of the other agents by implicitly assuming that the other agents make a similar collision-avoidance reasoning. We show that this method guarantees safe and oscillation- free motions for each of the agents. We apply our concept to navigation of hundreds of agents in densely populated environments containing both static and moving obstacles, and we show that real-time and scalable performance is achieved in such challenging scenarios.",2008.0,25.0,1386.0,True,"{'url': 'http://www.cs.unc.edu/~geom/RVO/icra2008.pdf', 'status': None}","{'pages': '1928-1935', 'name': '2008 IEEE International Conference on Robotics and Automation'}","{'bibtex': '@Article{Berg2008ReciprocalVO,\n author = {J. V. D. Berg and M. Lin and Dinesh Manocha},\n journal = {2008 IEEE International Conference on Robotics and Automation},\n pages = {1928-1935},\n title = {Reciprocal Velocity Obstacles for real-time multi-agent navigation},\n year = {2008}\n}\n'}","[{'authorId': '144721873', 'name': 'J. V. D. Berg'}, {'authorId': '144247566', 'name': 'M. Lin'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
708,3b2524c884400cdbe72217c1576817babf3ce543,Using Virtual Environments for Teaching Social Understanding to 6 Adolescents with Autistic Spectrum Disorders,,2007.0,36.0,356.0,False,,"{'volume': '37', 'pages': '589-600', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Mitchell2007UsingVE,\n author = {P. Mitchell and S. Parsons and A. Leonard},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {589-600},\n title = {Using Virtual Environments for Teaching Social Understanding to 6 Adolescents with Autistic Spectrum Disorders},\n volume = {37},\n year = {2007}\n}\n'}","[{'authorId': '2087504899', 'name': 'P. Mitchell'}, {'authorId': '144674468', 'name': 'S. Parsons'}, {'authorId': '117398139', 'name': 'A. Leonard'}]"
709,3b398b1debbcd427495e6ad47b4c499dbbfdbb9a,Foundations of Game-Based Learning,"In this article we argue that to study or apply games as learning environments, multiple perspectives have to be taken into account. We first define game-based learning and gamification, and then discuss theoretical models that describe learning with games, arguing that playfulness is orthogonal to learning theory. We then review design elements of games that facilitate learning by fostering learners' cognitive, behavioral, affective, and sociocultural engagement with the subject matter. Finally, we discuss the basis of these design elements in cognitive, motivational, affective, and sociocultural foundations by reviewing key theories from education and psychology that are the most pertinent to game-based learning and by describing empirical research on learning with games that has been or should be conducted. We conclude that a combination of cognitive, motivational, affective, and sociocultural perspectives is necessary for both game design and game research to fully capture what games have to offer for learning.",2015.0,213.0,665.0,False,,"{'volume': '50', 'pages': '258 - 283', 'name': 'Educational Psychologist'}","{'bibtex': '@Article{Plass2015FoundationsOG,\n author = {J. Plass and B. Homer and C. Kinzer},\n journal = {Educational Psychologist},\n pages = {258 - 283},\n title = {Foundations of Game-Based Learning},\n volume = {50},\n year = {2015}\n}\n'}","[{'authorId': '2154049', 'name': 'J. Plass'}, {'authorId': '3161818', 'name': 'B. Homer'}, {'authorId': '2230663', 'name': 'C. Kinzer'}]"
710,3b5247ada3a14bde5c78db59f1726ab1c385a904,Mining a multimodal corpus for non-verbal behavior sequences conveying attitudes,"Interpersonal attitudes are expressed by non-verbal behaviors on a variety of different modalities. The perception of these behaviors is influenced by how they are sequenced with other behaviors from the same person and behaviors from other interactants. In this paper, we present a method for extracting and generating sequences of non-verbal signals expressing interpersonal attitudes. These sequences are used as part of a framework for non-verbal expression with Embodied Conversational Agents that considers different features of non-verbal behavior: global behavior tendencies, interpersonal reactions, sequencing of non-verbal signals, and communicative intentions. Our method uses a sequence mining technique on an annotated multimodal corpus to extract sequences characteristic of different attitudes. New sequences of non-verbal signals are generated using a probabilistic model, and evaluated using the previously mined sequences.",2014.0,32.0,15.0,False,,{'pages': '3417-3424'},"{'bibtex': '@Inproceedings{Chollet2014MiningAM,\n author = {Mathieu Chollet and M. Ochs and C. Pelachaud},\n pages = {3417-3424},\n title = {Mining a multimodal corpus for non-verbal behavior sequences conveying attitudes},\n year = {2014}\n}\n'}","[{'authorId': '40325099', 'name': 'Mathieu Chollet'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
711,3b6163ad3cb47fa7120a67f828094a0f8d4302d5,A Novel Fusion Method by Static and Moving Facial Capture,"For many years, face recognition has been one of the most important domains in pattern recognition. Nowadays, face recognition is more required to be used in video actually. So moving facial capture must be studied firstly because of performance requirement. Since classic facial capture method is not so suitable in a moving environment, in this paper, we present a novel facial capture method in a moving environment. Firstly, continuous frames are extracted from detecting videos by similar characteristics. Then, we present an algorithm to extract the moving object and restructure background. Meanwhile, with analysis of skin color in both moving and static areas, we use the classic faces capture method to catch all faces. Finally, experimental results show that this method has better robustness and accuracy.",2013.0,15.0,35.0,True,"{'url': 'https://downloads.hindawi.com/journals/mpe/2013/503924.pdf', 'status': None}","{'volume': '2013', 'pages': '1-6', 'name': 'Mathematical Problems in Engineering'}","{'bibtex': '@Article{Liu2013ANF,\n author = {Shuai Liu and Weina Fu and Wen Zhao and Jiantao Zhou and Qianzhong Li},\n journal = {Mathematical Problems in Engineering},\n pages = {1-6},\n title = {A Novel Fusion Method by Static and Moving Facial Capture},\n volume = {2013},\n year = {2013}\n}\n'}","[{'authorId': '50152289', 'name': 'Shuai Liu'}, {'authorId': '1712119', 'name': 'Weina Fu'}, {'authorId': '98902637', 'name': 'Wen Zhao'}, {'authorId': '66102996', 'name': 'Jiantao Zhou'}, {'authorId': '2143524664', 'name': 'Qianzhong Li'}]"
712,3b755990708e25de2f84eed2b8072165c5ceb94d,Designing the user interface strategies for effective human-computer interaction,"For courses in Human-Computer Interaction. The Sixth Edition of Designing the User Interface provides a comprehensive, authoritative, and up-to-date introduction to the dynamic field of human-computer interaction (HCI) and user experience (UX) design. This classic book has defined and charted the astonishing evolution of user interfaces for three decades. Students and professionals learn practical principles and guidelines needed to develop high quality interface designs that users can understand, predict, and control. The book covers theoretical foundations and design processes such as expert reviews and usability testing. By presenting current research andinnovations in human-computer interaction, the authors strive toinspire students, guide designers, and provoke researchers to seek solutions that improve the experiences of novice and expert users, while achieving universal usability. The authors also provide balanced presentations on controversial topics such as augmented and virtual reality, voice and natural language interfaces, and information visualization. Updates include current HCI design methods, new design examples, and totally revamped coverage of social media, search and voice interaction. Major revisions were made toEVERY chapter, changing almost every figure (170 new color figures) and substantially updating the references.",1998.0,0.0,6873.0,True,"{'url': 'http://www.gbv.de/dms/ilmenau/toc/588404004.PDF', 'status': None}","{'pages': 'I-XVIII, 1-652'}","{'bibtex': '@Inproceedings{Shneiderman1998DesigningTU,\n author = {B. Shneiderman and C. Plaisant},\n pages = {I-XVIII, 1-652},\n title = {Designing the user interface strategies for effective human-computer interaction},\n year = {1998}\n}\n'}","[{'authorId': '1740403', 'name': 'B. Shneiderman'}, {'authorId': '1764846', 'name': 'C. Plaisant'}]"
713,3bab44a7b62b417ff4529325af0fba83eedf9f62,Fusion of Facial Expressions and EEG for Multimodal Emotion Recognition,"This paper proposes two multimodal fusion methods between brain and peripheral signals for emotion recognition. The input signals are electroencephalogram and facial expression. The stimuli are based on a subset of movie clips that correspond to four specific areas of valance-arousal emotional space (happiness, neutral, sadness, and fear). For facial expression detection, four basic emotion states (happiness, neutral, sadness, and fear) are detected by a neural network classifier. For EEG detection, four basic emotion states and three emotion intensity levels (strong, ordinary, and weak) are detected by two support vector machines (SVM) classifiers, respectively. Emotion recognition is based on two decision-level fusion methods of both EEG and facial expression detections by using a sum rule or a production rule. Twenty healthy subjects attended two experiments. The results show that the accuracies of two multimodal fusion detections are 81.25% and 82.75%, respectively, which are both higher than that of facial expression (74.38%) or EEG detection (66.88%). The combination of facial expressions and EEG information for emotion recognition compensates for their defects as single information sources.",2017.0,34.0,82.0,True,"{'url': 'http://downloads.hindawi.com/journals/cin/2017/2107451.pdf', 'status': None}","{'volume': '2017', 'name': 'Computational Intelligence and Neuroscience'}","{'bibtex': '@Article{Huang2017FusionOF,\n author = {Yongrui Huang and Jianhao Yang and Pengkai Liao and Jiahui Pan},\n journal = {Computational Intelligence and Neuroscience},\n title = {Fusion of Facial Expressions and EEG for Multimodal Emotion Recognition},\n volume = {2017},\n year = {2017}\n}\n'}","[{'authorId': '49866167', 'name': 'Yongrui Huang'}, {'authorId': '2109746852', 'name': 'Jianhao Yang'}, {'authorId': '31804753', 'name': 'Pengkai Liao'}, {'authorId': '7588999', 'name': 'Jiahui Pan'}]"
714,3bd53f4a4918324cd8c4eb2d8012f03b01cd2d5b,Strong attractors of Hopfield neural networks to model attachment types and behavioural patterns,"We study the notion of a strong attractor of a Hopfield neural model as a pattern that has been stored multiple times in the network, and examine its properties using basic mathematical techniques as well as a variety of simulations. It is proposed that strong attractors can be used to model attachment types in developmental psychology as well as behavioural patterns in psychology and psychotherapy. We study the stability and basins of attraction of strong attractors in the presence of other simple attractors and show that they are indeed more stable with a larger basin of attraction compared with simple attractors. We also show that the perturbation of a strong attractor by random noise results in a cluster of attractors near the original strong attractor measured by the Hamming distance. We investigate the stability and basins of attraction of such clusters as the noise increases and establish that the unfolding of the strong attractor, leading to its breakup, goes through three different stages. Finally the relation between strong attractors of different multiplicity and their influence on each other are studied and we show how the impact of a strong attractor can be replaced with that of a new strong attractor. This retraining of the network is proposed as a model of how attachment types and behavioural patterns can undergo change.",2013.0,29.0,20.0,True,"{'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/11760/2/hopfield-networks-f.pdf', 'status': None}","{'pages': '1-10', 'name': 'The 2013 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Edalat2013StrongAO,\n author = {A. Edalat and Federico Mancinelli},\n journal = {The 2013 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-10},\n title = {Strong attractors of Hopfield neural networks to model attachment types and behavioural patterns},\n year = {2013}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}, {'authorId': '2894014', 'name': 'Federico Mancinelli'}]"
715,3bd7b18b165cc9bedebe6d92a092e3f2aa8c12f5,Development of Computational Models of Emotions for Autonomous Agents: A Review,,2014.0,126.0,65.0,False,,"{'volume': '6', 'pages': '351-375', 'name': 'Cognitive Computation'}","{'bibtex': '@Article{Rodríguez2014DevelopmentOC,\n author = {Luis-Felipe Rodríguez and Félix F. Ramos},\n journal = {Cognitive Computation},\n pages = {351-375},\n title = {Development of Computational Models of Emotions for Autonomous Agents: A Review},\n volume = {6},\n year = {2014}\n}\n'}","[{'authorId': '40428623', 'name': 'Luis-Felipe Rodríguez'}, {'authorId': '145956015', 'name': 'Félix F. Ramos'}]"
717,3bdfafa0fc0bc514ccc251f1a8b75e510fa6361b,"You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human–Robot Interaction","Gaze following occurs automatically in social interactions, but the degree to which gaze is followed depends on whether an agent is perceived to have a mind, making its behavior socially more relevant for the interaction. Mind perception also modulates the attitudes we have toward others, and determines the degree of empathy, prosociality, and morality invested in social interactions. Seeing mind in others is not exclusive to human agents, but mind can also be ascribed to non-human agents like robots, as long as their appearance and/or behavior allows them to be perceived as intentional beings. Previous studies have shown that human appearance and reliable behavior induce mind perception to robot agents, and positively affect attitudes and performance in human–robot interaction. What has not been investigated so far is whether different triggers of mind perception have an independent or interactive effect on attitudes and performance in human–robot interaction. We examine this question by manipulating agent appearance (human vs. robot) and behavior (reliable vs. random) within the same paradigm and examine how congruent (human/reliable vs. robot/random) versus incongruent (human/random vs. robot/reliable) combinations of these triggers affect performance (i.e., gaze following) and attitudes (i.e., agent ratings) in human–robot interaction. The results show that both appearance and behavior affect human–robot interaction but that the two triggers seem to operate in isolation, with appearance more strongly impacting attitudes, and behavior more strongly affecting performance. The implications of these findings for human–robot interaction are discussed.",2017.0,100.0,74.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01393/pdf', 'status': None}","{'volume': '8', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Abubshait2017YouLH,\n author = {A. Abubshait and E. Wiese},\n journal = {Frontiers in Psychology},\n title = {You Look Human, But Act Like a Machine: Agent Appearance and Behavior Modulate Different Aspects of Human–Robot Interaction},\n volume = {8},\n year = {2017}\n}\n'}","[{'authorId': '23148511', 'name': 'A. Abubshait'}, {'authorId': '2658383', 'name': 'E. Wiese'}]"
718,3c010ce98d2f141e7653bd8f9b2b0864936280bd,Piaget’s Theory,,1976.0,0.0,2697.0,False,,"{'volume': '', 'pages': '11-23', 'name': ''}","{'bibtex': '@Inproceedings{Piaget1976PiagetsT,\n author = {Jean Piaget},\n pages = {11-23},\n title = {Piaget’s Theory},\n year = {1976}\n}\n'}","[{'authorId': '46541880', 'name': 'Jean Piaget'}]"
719,3c063d689309cb2402cc6047674d2001d6476934,Human-Computer Interaction: Process and Principles of Human-Computer Interface Design,"This paper has summarized the conceptions of human-machine systems and human-computer interface,studied and analyzed the ways of human-computer interaction. Under these instructions, it proposed the design process and methods of human-computer interface,as well as some attentive points and the basic principles to be abided by during the design process, which gives some interface designation basis for the design of human machine systems and has certain guidance significance.The major ideas of this paper are to explain how to improve the human-machine systems, how to make machines adapt to and serve humans effectively and better,thereby brings the humans, machines and environment into a harmonious relationship.",2009.0,4.0,41.0,False,,"{'pages': '230-233', 'name': '2009 International Conference on Computer and Automation Engineering'}","{'bibtex': '@Article{Chao2009HumanComputerIP,\n author = {Gong Chao},\n journal = {2009 International Conference on Computer and Automation Engineering},\n pages = {230-233},\n title = {Human-Computer Interaction: Process and Principles of Human-Computer Interface Design},\n year = {2009}\n}\n'}","[{'authorId': '2061392387', 'name': 'Gong Chao'}]"
720,3c1acc34dfd7de6feac56c37ad0a3a0d0dae98fe,Inferring Pragmatics from Dialogue Contexts in Simulated Virtual Agent Games,,2011.0,17.0,3.0,False,,{'pages': '123-138'},"{'bibtex': '@Article{Chien2011InferringPF,\n author = {Yu-Hung Chien and V. Soo},\n booktitle = {International Workshop on Agents for Educational Games and Simulations},\n pages = {123-138},\n title = {Inferring Pragmatics from Dialogue Contexts in Simulated Virtual Agent Games},\n year = {2011}\n}\n'}","[{'authorId': '11984844', 'name': 'Yu-Hung Chien'}, {'authorId': '1700936', 'name': 'V. Soo'}]"
721,3c2360fbc612e8381ecda4f79c2c3cf52e681829,The Effects of a Pedagogical Agent's Smiling Expression on the Learner's Emotions and Motivation in a Virtual Learning Environment.,"The present study aimed to test the hypothesis that a smiling expression on the face of a talking pedagogical agent could positively affect a learner’s emotions, motivation, and learning outcomes in a virtual learning environment. Contrary to the hypothesis, results from Experiment 1 demonstrated that the pedagogical agent’s smile induced negative emotional and motivational responses in learners. Experiment 2 showed that the social meaning of a pedagogical agent’s smile might be perceived by learners as polite or fake. In addition, qualitative data provided insights into factors that may cause negative perceptions of a pedagogical agent’s smile, which in turn lead to negative affective (emotional and motivational) states in learners. Theoretical and design implications for pedagogical agents in virtual learning environment are discussed in the concluding section of the paper.",2016.0,52.0,30.0,True,"{'url': 'http://www.irrodl.org/index.php/irrodl/article/download/2350/3935', 'status': None}","{'volume': '17', 'pages': '248-266', 'name': 'The International Review of Research in Open and Distributed Learning'}","{'bibtex': ""@Article{Liew2016TheEO,\n author = {Tze Wei Liew and N. Zin and N. Sahari and Su-Mae Tan},\n journal = {The International Review of Research in Open and Distributed Learning},\n pages = {248-266},\n title = {The Effects of a Pedagogical Agent's Smiling Expression on the Learner's Emotions and Motivation in a Virtual Learning Environment.},\n volume = {17},\n year = {2016}\n}\n""}","[{'authorId': '3091348', 'name': 'Tze Wei Liew'}, {'authorId': '3211229', 'name': 'N. Zin'}, {'authorId': '49357391', 'name': 'N. Sahari'}, {'authorId': '3311426', 'name': 'Su-Mae Tan'}]"
722,3c3e423d04a5d79d5e5346f3f0c656b82646dab4,Reading skill and neural processing accuracy improvement after a 3-hour intervention in preschoolers with difficulties in reading-related skills,,2012.0,84.0,96.0,False,,"{'volume': '1448', 'pages': '42-55', 'name': 'Brain Research'}","{'bibtex': '@Article{Lovio2012ReadingSA,\n author = {Riikka Lovio and Anu Halttunen and H. Lyytinen and R. Näätänen and T. Kujala},\n journal = {Brain Research},\n pages = {42-55},\n title = {Reading skill and neural processing accuracy improvement after a 3-hour intervention in preschoolers with difficulties in reading-related skills},\n volume = {1448},\n year = {2012}\n}\n'}","[{'authorId': '6100134', 'name': 'Riikka Lovio'}, {'authorId': '2078787680', 'name': 'Anu Halttunen'}, {'authorId': '39518098', 'name': 'H. Lyytinen'}, {'authorId': '2868442', 'name': 'R. Näätänen'}, {'authorId': '1887682', 'name': 'T. Kujala'}]"
723,3c5864d0d40434dd2e3e9dcb60df3c5dbf593a85,Multi-Agent Foraging: state-of-the-art and research challenges,,2017.0,79.0,40.0,True,"{'url': 'https://casmodeling.springeropen.com/track/pdf/10.1186/s40294-016-0041-8', 'status': None}","{'volume': '5', 'pages': '1-24', 'name': 'Complex Adaptive Systems Modeling'}","{'bibtex': '@Article{Zedadra2017MultiAgentFS,\n author = {Ouarda Zedadra and Nicolas Jouandeau and Hamid Seridi and G. Fortino},\n journal = {Complex Adaptive Systems Modeling},\n pages = {1-24},\n title = {Multi-Agent Foraging: state-of-the-art and research challenges},\n volume = {5},\n year = {2017}\n}\n'}","[{'authorId': '1873244', 'name': 'Ouarda Zedadra'}, {'authorId': '2882109', 'name': 'Nicolas Jouandeau'}, {'authorId': '2305167', 'name': 'Hamid Seridi'}, {'authorId': '1691577', 'name': 'G. Fortino'}]"
724,3c62e25f7f6a035ef59eefd7ff13ca42c59a716f,A Framework for Immersive Virtual Environments (FIVE): Speculations on the Role of Presence in Virtual Environments,"This paper reviews the concepts of immersion and presence in virtual environments (VEs). We propose that the degree of immersion can be objectively assessed as the characteristics of a technology, and has dimensions such as the extent to which a display system can deliver an inclusive, extensive, surrounding, and vivid illusion of virtual environment to a participant. Other dimensions of immersion are concerned with the extent of body matching, and the extent to which there is a self-contained plot in which the participant can act and in which there is an autonomous response. Presence is a state of consciousness that may be concomitant with immersion, and is related to a sense of being in a place. Presence governs aspects of autonomie responses and higher-level behaviors of a participant in a VE. The paper considers single and multiparticipant shared environments, and draws on the experience of ComputerSupported Cooperative Working (CSCW) research as a guide to understanding presence in shared environments. The paper finally outlines the aims of the FIVE Working Group, and the 1995 FIVE Conference in London, UK.",1997.0,48.0,1962.0,False,,"{'volume': '6', 'pages': '603-616', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Slater1997AFF,\n author = {M. Slater and S. Wilbur},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {603-616},\n title = {A Framework for Immersive Virtual Environments (FIVE): Speculations on the Role of Presence in Virtual Environments},\n volume = {6},\n year = {1997}\n}\n'}","[{'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '36707580', 'name': 'S. Wilbur'}]"
725,3c7cf782e4094a7d66d8ad5da80a8083a8e72307,"Outcomes for Implementation Research: Conceptual Distinctions, Measurement Challenges, and Research Agenda",,2010.0,73.0,3975.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10488-010-0319-7.pdf', 'status': None}","{'volume': '38', 'pages': '65 - 76', 'name': 'Administration and Policy in Mental Health'}","{'bibtex': '@Article{Proctor2010OutcomesFI,\n author = {E. Proctor and Hiie Silmere and R. Raghavan and P. Hovmand and G. Aarons and Alicia C. Bunger and R. Griffey and Melissa A. Hensley},\n journal = {Administration and Policy in Mental Health},\n pages = {65 - 76},\n title = {Outcomes for Implementation Research: Conceptual Distinctions, Measurement Challenges, and Research Agenda},\n volume = {38},\n year = {2010}\n}\n'}","[{'authorId': '144714949', 'name': 'E. Proctor'}, {'authorId': '6428578', 'name': 'Hiie Silmere'}, {'authorId': '35464599', 'name': 'R. Raghavan'}, {'authorId': '2132087', 'name': 'P. Hovmand'}, {'authorId': '145349578', 'name': 'G. Aarons'}, {'authorId': '144046643', 'name': 'Alicia C. Bunger'}, {'authorId': '19206773', 'name': 'R. Griffey'}, {'authorId': '1485300590', 'name': 'Melissa A. Hensley'}]"
726,3c900f9f5c9e259f4a91a29412ffad303e9bc3c8,"How cognitive, social, and emotional profiles impact humor appreciation: sense of humor in autism spectrum disorder and Williams syndrome","Abstract Humor is a complex and multi-faceted phenomenon composed of a variety of cognitive, social, and emotional processes. This paper will discuss humor appreciation in individuals with autism spectrum disorder (ASD) and individuals with Williams syndrome (WS), a rare genetic disorder mainly characterized by intellectual disabilities, high social approach tendencies and high positive emotions. Drawing on research on the comprehension and appreciation of humor in individuals with ASD, this paper aims to better understand how the particular cognitive, social, and emotional profile of individuals with WS might affect their appreciation of humor and how such research could ultimately lead to a greater understanding of the nature of humor.",2021.0,51.0,5.0,True,"{'url': 'https://www.degruyter.com/document/doi/10.1515/humor-2021-0038/pdf', 'status': None}","{'volume': '35', 'pages': '113 - 133', 'name': 'HUMOR'}","{'bibtex': '@Article{Treichel2021HowCS,\n author = {Noémie Treichel and Daniel Dukes and K. Barisnikov and Andrea C. Samson},\n journal = {HUMOR},\n pages = {113 - 133},\n title = {How cognitive, social, and emotional profiles impact humor appreciation: sense of humor in autism spectrum disorder and Williams syndrome},\n volume = {35},\n year = {2021}\n}\n'}","[{'authorId': '2124359121', 'name': 'Noémie Treichel'}, {'authorId': '39779139', 'name': 'Daniel Dukes'}, {'authorId': '4021172', 'name': 'K. Barisnikov'}, {'authorId': '38707445', 'name': 'Andrea C. Samson'}]"
727,3cab85489dada987db53f391690bbaf0284b9563,Social Skills Development in Children with Autism Spectrum Disorders: A Review of the Intervention Research,,2007.0,67.0,879.0,False,,"{'volume': '37', 'pages': '1858-1868', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{White2007SocialSD,\n author = {Susan Williams White and Kathleen Keonig and L. Scahill},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {1858-1868},\n title = {Social Skills Development in Children with Autism Spectrum Disorders: A Review of the Intervention Research},\n volume = {37},\n year = {2007}\n}\n'}","[{'authorId': '8181364', 'name': 'Susan Williams White'}, {'authorId': '4171300', 'name': 'Kathleen Keonig'}, {'authorId': '144260517', 'name': 'L. Scahill'}]"
728,3cbe855bfad50102061b4c5bde1e0dc41df5cf15,Why do I like you when you behave like me? Neural mechanisms mediating positive consequences of observing someone being imitated,"Social psychological and developmental research revealed that imitation serves a fundamental social function. It has been shown that human beings have the tendency to automatically mirror the behavior of others—the so-called chameleon effect. Furthermore, it has been demonstrated that being imitated leads to positive feelings toward the imitator. But why do we feel more positive about someone who imitates us? In the current fMRI study we aimed at exploring the neural correlates of the positive consequences of being imitated by means of an observation paradigm. Our results indicate that being imitated compared to not being imitated activates brain areas that have been associated with emotion and reward processing, namely medial orbitofrontal cortex/ventromedial prefrontal cortex (mOFC/vmPFC, GLM whole-brain contrast). Moreover mOFC/vmPFC shows higher effective connectivity with striatum and mid-posterior insula during being imitated compared to not being imitated.",2010.0,58.0,74.0,True,"{'url': 'https://biblio.ugent.be/publication/1084894/file/6744531', 'status': None}","{'volume': '5', 'pages': '384 - 392', 'name': 'Social Neuroscience'}","{'bibtex': '@Article{Kühn2010WhyDI,\n author = {S. Kühn and Barbara C. N. Müller and Rick B. van Baaren and A. Wietzker and A. Dijksterhuis and M. Brass},\n journal = {Social Neuroscience},\n pages = {384 - 392},\n title = {Why do I like you when you behave like me? Neural mechanisms mediating positive consequences of observing someone being imitated},\n volume = {5},\n year = {2010}\n}\n'}","[{'authorId': '1895071', 'name': 'S. Kühn'}, {'authorId': '40517064', 'name': 'Barbara C. N. Müller'}, {'authorId': '113458595', 'name': 'Rick B. van Baaren'}, {'authorId': '6198748', 'name': 'A. Wietzker'}, {'authorId': '4730036', 'name': 'A. Dijksterhuis'}, {'authorId': '2425526', 'name': 'M. Brass'}]"
729,3cc7e9d49d07b24fd50962f3100e2acc7a157b3e,Unmasking The Face,,1975.0,0.0,2005.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1975UnmaskingTF,\n author = {P. Ekman},\n title = {Unmasking The Face},\n year = {1975}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
730,3cd1df050819bdc4aca0d0d3fad793ddde0a65c6,"Deep learning analysis of mobile physiological, environmental and location sensor data for emotion detection",,2019.0,48.0,188.0,True,,"{'volume': '49', 'pages': '46-56', 'name': 'Inf. Fusion'}","{'bibtex': '@Article{Kanjo2019DeepLA,\n author = {E. Kanjo and Eman M. G. Younis and C. Ang},\n journal = {Inf. Fusion},\n pages = {46-56},\n title = {Deep learning analysis of mobile physiological, environmental and location sensor data for emotion detection},\n volume = {49},\n year = {2019}\n}\n'}","[{'authorId': '2034060', 'name': 'E. Kanjo'}, {'authorId': '3232402', 'name': 'Eman M. G. Younis'}, {'authorId': '2499731', 'name': 'C. Ang'}]"
731,3d0bcd30f4e569dde73522d574c2a1adda90c451,THE DEVELOPMENT OF MARKERS FOR THE BIG-FIVE FACTOR STRUCTURE,"To satisfy the need in personality research for factorially univocal measures of each of the 5 domains that subsume most English-language terms for personality-traits, new sets of Big-Five factor markers were investigated. In studies of adjective-anchored bipolar rating scales, a transparent format was found to produce factor markers that were more univocal than the same scales administered in the traditional format. Nonetheless, even the transparent bipolar scales proved less robust as factor markers than did parallel sets of adjectives administered in unipolar format. A set of 100 unipolar terms proved to be highly robust across quite diverse samples of self and peer descriptions. These new markers were compared with previously developed ones based on far larger sets of trait adjectives, as well as with the scales from the NEO and Hogan personality inventories.",1992.0,64.0,5052.0,False,,"{'volume': '4', 'pages': '26-42', 'name': 'Psychological Assessment'}","{'bibtex': '@Article{Goldberg1992THEDO,\n author = {L. R. Goldberg},\n journal = {Psychological Assessment},\n pages = {26-42},\n title = {THE DEVELOPMENT OF MARKERS FOR THE BIG-FIVE FACTOR STRUCTURE},\n volume = {4},\n year = {1992}\n}\n'}","[{'authorId': '30316209', 'name': 'L. R. Goldberg'}]"
732,3d0debd877ba219ff85e3597fd21a54cea955ded,The Effects of Empathy on Self-Esteem and Subjective Well-Being,"Previous studies have investigated the effect of empathy on relations. However, there have been few studies that found the effect of empathy on subjective well-being. This study aimed to investigate relations between empathy and subjective well-being. It was hypothesized that empathy had effects on subjective well-being in the mediation of self-esteem. Heo, J.H. and Lee, C.J. (2010) investigated the psychometric properties of EQ. However they did not do confirmatory analysis. So confirmatory analysis needs to be done in this study. Data was collected from 421 College student (male 192, female 225), and analyzed by SEM and path analysis. Results revealed that 3 factors model of EQ was proper, and EQ had effects on subjective well-being in the mediation of self-esteem. This suggested that empathy be a very important factor in our culture, and fulfillment of cultural task enhance self-esteem, which improve subjectve well-being. And cultural features should be considered in the study of empathy.",2010.0,0.0,2.0,False,,"{'volume': '29', 'pages': '332-338', 'name': 'The Journal of the Acoustical Society of Korea'}","{'bibtex': '@Article{Heo2010TheEO,\n author = {Jae-hong Heo and Chan-Jong Lee},\n journal = {The Journal of the Acoustical Society of Korea},\n pages = {332-338},\n title = {The Effects of Empathy on Self-Esteem and Subjective Well-Being},\n volume = {29},\n year = {2010}\n}\n'}","[{'authorId': '93868035', 'name': 'Jae-hong Heo'}, {'authorId': '67043433', 'name': 'Chan-Jong Lee'}]"
733,3d2185dcd4ac42e6ef5a389545963e289102f8ab,Do you speak to a human or a virtual agent? automatic analysis of user’s social cues during mediated communication,"While several research works have shown that virtual agents are able to generate natural and social behaviors from users, few of them have compared these social reactions to those expressed dur- ing a human-human mediated communication. In this paper, we propose to explore the social cues expressed by a user during a mediated communication either with an embodied conversational agent or with another human. For this purpose, we have exploited a machine learning method to identify the facial and head social cues characteristics in each interaction type and to construct a model to automatically determine if the user is interacting with a virtual agent or another human. e results show that, in fact, the users do not express the same facial and head movements during a communication with a virtual agent or another user. Based on these results, we propose to use such a machine learning model to automatically measure the social capability of a virtual agent to generate a social behavior in the user comparable to a human- human interaction. e resulting model can detect automatically if the user is communicating with a virtual or real interlocutor, looking only at the user’s face and head during one second.",2017.0,35.0,8.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-01793356/file/ArticleICMIOchsetal-2017Final.pdf', 'status': None}",{'name': 'Proceedings of the 19th ACM International Conference on Multimodal Interaction'},"{'bibtex': '@Article{Ochs2017DoYS,\n author = {M. Ochs and Nathan Libermann and Axel Boidin and T. Chaminade},\n journal = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},\n title = {Do you speak to a human or a virtual agent? automatic analysis of user’s social cues during mediated communication},\n year = {2017}\n}\n'}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '2104943740', 'name': 'Nathan Libermann'}, {'authorId': '2078341555', 'name': 'Axel Boidin'}, {'authorId': '1728769', 'name': 'T. Chaminade'}]"
734,3d319b724ab3c6ddce66d58652fde0218a65d410,Gaze-based Screening of Autistic Traits for Adolescents and Young Adults using Prosaic Videos,"Autism Spectrum Disorder (ASD) is a universal and often lifelong neuro-developmental disorder. Individuals with ASD often present comorbidities such as epilepsy, depression, and anxiety. In the United States, in 2014, 1 out of 68 people was affected by autism, but worldwide, the number of affected people drops to 1 in 160. This disparity is primarily due to underdiagnosis and unreported cases in resource-constrained environments. Wiggins et al. 1 found that, in the US, children of color are under-identified with ASD. Missing a diagnosis is not without consequences; approximately 26% of adults with ASD are under-employed, and are under-enrolled in higher education. Unfortunately, ASD diagnosis is not straightforward and involves a subjective assessment of the patient's behavior. Because such assessments can be noisy and even non-existent in low-resource environments, many cases go unidentified. Many such cases remain undiagnosed even when the patient reaches adolescence or adulthood. There is a need for an objective, low-cost, and ubiquitous approach to diagnose ASD. Autism is often characterized by symptoms such as limited interpersonal and social communication skills, and difficulty in face recognition and emotion interpretation. When watching video media, these symptoms can manifest as reduced eye fixation, resulting in characteristic gaze behaviors. Thus, we developed an approach to screen patients with ASD using their gaze behavior while they watch videos on a laptop screen. We used a dedicated eye tracker to record the participant's gaze. With data from 60 participants (35 with ASD and 25 without ASD), our algorithm demonstrates 92.5% classification accuracy after the participants watched 15 seconds of the video. We also developed a proof-of-concept regression model that estimates the severity of the condition and achieves a mean absolute error of 2.03 on the Childhood Autism Rating Scale (CARS). One of the most common approaches to identify individuals with ASD involves studying family home videos and investigating an infant's gaze and interactions with their families. However, having an expert carefully inspect hours of home video is expensive and unscalable. Our approach is more accessible and ubiquitous as we can directly sense the gaze of the user while they watch videos. Such sensing can be directly deployed on billions of smartphones around the world that are equipped with a front-facing camera. In our current exploration, we use a dedicated eye-tracker but achieving similar performance using an unmodified s martphone c amera is not far-fetched. Our results demonstrate that passively tracking a user's gaze pattern while they watch videos on a screen can enable robust identification of individuals with ASD. Past work has used specially-created visual content to detect ASD, but getting large sets of the population to watch specific videos is hard. Thus, we focus on generic content and selected four prosaic video scenes as a proof of concept. Our research team includes experienced psychologists to inform the study design and contextualize the performance of the final system. Although our gaze tracking approach cannot yet replace a clinical assessment, we believe it could be valuable for screening individuals passively, as they consume media content on computing devices (e.g., YouTube, Netflix, in-game cut scenes). We believe our efforts in estimating condition severity is also an essential first step towards building an entirely automated, in-home screening, and condition management tool. With rapid advancements in gaze tracking on consumer devices (e.g., Apple iPhone, HTC Vive), autism detection could be included on modern computing devices as a downloadable app or background feature, and potentially reduce the number of undiagnosed cases. Such a system could also track the efficacy of treatment and interventions. Additionally, ASD detection could be used to automatically adapt user interfaces, which has been shown to improve accessibility.",2020.0,41.0,4.0,False,,{'name': 'Proceedings of the 3rd ACM SIGCAS Conference on Computing and Sustainable Societies'},"{'bibtex': '@Article{Ahuja2020GazebasedSO,\n author = {Karan Ahuja and A. Bose and Mohit Jain and K. Dey and Anil Joshi and K. Achary and Blessin Varkey and Chris Harrison and Mayank Goel},\n journal = {Proceedings of the 3rd ACM SIGCAS Conference on Computing and Sustainable Societies},\n title = {Gaze-based Screening of Autistic Traits for Adolescents and Young Adults using Prosaic Videos},\n year = {2020}\n}\n'}","[{'authorId': '3451315', 'name': 'Karan Ahuja'}, {'authorId': '2069221594', 'name': 'A. Bose'}, {'authorId': '2089551047', 'name': 'Mohit Jain'}, {'authorId': '144710196', 'name': 'K. Dey'}, {'authorId': '2066730374', 'name': 'Anil Joshi'}, {'authorId': '144171754', 'name': 'K. Achary'}, {'authorId': '48619892', 'name': 'Blessin Varkey'}, {'authorId': '145078227', 'name': 'Chris Harrison'}, {'authorId': '4646339', 'name': 'Mayank Goel'}]"
735,3d52d429b4d83d096dd354e8470bf3655e8b67bc,Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good,"Developing intelligent persuasive conversational agents to change people’s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals’ demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals’ personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.",2019.0,41.0,168.0,True,"{'url': 'https://www.aclweb.org/anthology/P19-1566.pdf', 'status': None}","{'volume': 'abs/1906.06725', 'name': 'ArXiv'}","{'bibtex': '@Article{Wang2019PersuasionFG,\n author = {Xuewei Wang and Weiyan Shi and Richard Kim and Y. Oh and Sijia Yang and Jingwen Zhang and Zhou Yu},\n journal = {ArXiv},\n title = {Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good},\n volume = {abs/1906.06725},\n year = {2019}\n}\n'}","[{'authorId': '47120703', 'name': 'Xuewei Wang'}, {'authorId': '8299781', 'name': 'Weiyan Shi'}, {'authorId': '2054541342', 'name': 'Richard Kim'}, {'authorId': '2072731142', 'name': 'Y. Oh'}, {'authorId': '2108973978', 'name': 'Sijia Yang'}, {'authorId': '50561415', 'name': 'Jingwen Zhang'}, {'authorId': '1564034697', 'name': 'Zhou Yu'}]"
736,3d65c2418f0ce39b6b7228ddc9c1dc6fd19fa0ab,Mimicry and expressiveness of an ECA in human-agent interaction: familiarity breeds content!,,2016.0,46.0,25.0,True,"{'url': 'https://computationalcognitivescience.springeropen.com/track/pdf/10.1186/s40469-016-0008-2', 'status': None}","{'volume': '2', 'name': 'Computational Cognitive Science'}","{'bibtex': '@Article{Stevens2016MimicryAE,\n author = {C. Stevens and Bronwyn Pinchbeck and T. Lewis and M. Luerssen and D. Pfitzner and D. Powers and Arman Abrahamyan and Yvonne Leung and G. Gibert},\n journal = {Computational Cognitive Science},\n title = {Mimicry and expressiveness of an ECA in human-agent interaction: familiarity breeds content!},\n volume = {2},\n year = {2016}\n}\n'}","[{'authorId': '1717473', 'name': 'C. Stevens'}, {'authorId': '35318213', 'name': 'Bronwyn Pinchbeck'}, {'authorId': '145111765', 'name': 'T. Lewis'}, {'authorId': '1776457', 'name': 'M. Luerssen'}, {'authorId': '1692446', 'name': 'D. Pfitzner'}, {'authorId': '144871539', 'name': 'D. Powers'}, {'authorId': '1804967', 'name': 'Arman Abrahamyan'}, {'authorId': '31685492', 'name': 'Yvonne Leung'}, {'authorId': '2493088', 'name': 'G. Gibert'}]"
737,3d80f96f8e3e72b4a6244e615b16d783b6115973,Towards Sentiment-Aware Multi-Modal Dialogue Policy Learning,,2020.0,21.0,14.0,False,,"{'volume': '14', 'pages': '246-260', 'name': 'Cognitive Computation'}","{'bibtex': '@Article{Saha2020TowardsSM,\n author = {Tulika Saha and S. Saha and P. Bhattacharyya},\n journal = {Cognitive Computation},\n pages = {246-260},\n title = {Towards Sentiment-Aware Multi-Modal Dialogue Policy Learning},\n volume = {14},\n year = {2020}\n}\n'}","[{'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
738,3ddda3145dbb20a63c6fc36661ac3e464d0ab295,Positive and Negative Affect Schedule,,2011.0,0.0,101.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Watson2011PositiveAN,\n author = {D. Watson and L. Clark and A. Tellegen},\n title = {Positive and Negative Affect Schedule},\n year = {2011}\n}\n'}","[{'authorId': '145213999', 'name': 'D. Watson'}, {'authorId': '10034636', 'name': 'L. Clark'}, {'authorId': '116114697', 'name': 'A. Tellegen'}]"
739,3de5d40b60742e3dfa86b19e7f660962298492af,Class-Based n-gram Models of Natural Language,"We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics.",1992.0,15.0,3460.0,False,,"{'volume': '18', 'pages': '467-479', 'name': 'Comput. Linguistics'}","{'bibtex': '@Article{Brown1992ClassBasedNM,\n author = {P. Brown and V. D. Pietra and P. D. Souza and J. Lai and R. Mercer},\n journal = {Comput. Linguistics},\n pages = {467-479},\n title = {Class-Based n-gram Models of Natural Language},\n volume = {18},\n year = {1992}\n}\n'}","[{'authorId': '32538203', 'name': 'P. Brown'}, {'authorId': '39944066', 'name': 'V. D. Pietra'}, {'authorId': '144856857', 'name': 'P. D. Souza'}, {'authorId': '3853032', 'name': 'J. Lai'}, {'authorId': '2474650', 'name': 'R. Mercer'}]"
740,3deb202c71646b47d6e61699b82a5ce9e4412ec6,Affective Multimodal Control of Virtual,"In this paper we report about the use of computer generated affect to control body and mind of cognitively modeled virtual characters. We use the computational model of affect ALMA that is able to simulate three different affect types in real-time. The computation of affect is based on a novel approach of an appraisal language. Both the use of elements of the appraisal language and the simulation of different affect types has been evaluated. Affect is used to control facial expressions, facial complexions, affective animations, posture, and idle behavior on the body layer and the selection of dialogue strategies on the mind layer. To enable a fine-grained control of these aspects a Player Markup Language (PML) has been developed. The PML is player-independent and allows a sophisticated control of character actions coordinated by high-level temporal constraints. An Action Encoder module maps the output of ALMA to PML actions using affect display rules. These actions drive the real-time rendering of affect, gesture and speech parameters of virtual characters, which we call Virtual Humans.",2020.0,26.0,5.0,True,"{'url': 'https://ijvr.eu/article/download/3864/12090', 'status': None}","{'volume': '6', 'pages': '43-54', 'name': 'Int. J. Virtual Real.'}","{'bibtex': '@Article{Klesen2020AffectiveMC,\n author = {Martin Klesen and Patrick Gebhard},\n journal = {Int. J. Virtual Real.},\n pages = {43-54},\n title = {Affective Multimodal Control of Virtual},\n volume = {6},\n year = {2020}\n}\n'}","[{'authorId': '2922093', 'name': 'Martin Klesen'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}]"
741,3df8c316a6a6f1cb68b29abb86b3b09e1f1b5569,A case-control family history study of autism.,"Family history data on 99 autistic and 36 Down's syndrome probands are reported. They confirmed a raised familial loading for both autism and more broadly defined pervasive developmental disorders in siblings (2.9% and 2.9%, respectively, vs 0% in the Down's group) and also evidence for the familial aggregation of a lesser variant of autism, comprising more subtle communication/social impairments or stereotypic behaviours, but not mental retardation alone. Between 12.4 and 20.4% of the autism siblings and 1.6% and 3.2% of the Down's siblings exhibited this lesser variant, depending on the stringency of its definition. Amongst autistic probands with speech, various features of their disorder (increased number of autistic symptoms; reduced verbal and performance ability) as well as a history of obstetric complications, indexed an elevation in familial loading. No such association was seen in the probands without speech, even though familial loading for the lesser variant in this subgroup, was significantly higher than in the Down's controls. The findings suggest that the autism phenotype extends beyond autism as traditionally diagnosed; that aetiology involves several genes; that autism is genetically heterogeneous; and that obstetric abnormalities in autistic subjects may derive from abnormality in the foetus.",1994.0,29.0,1114.0,False,,"{'volume': '35 5', 'pages': '\n          877-900\n        ', 'name': 'Journal of child psychology and psychiatry, and allied disciplines'}","{'bibtex': '@Article{Bolton1994ACF,\n author = {P. Bolton and Hope Macdonald and A. Pickles and P. Rios and S. Goode and M. Crowson and A. Bailey and M. Rutter},\n journal = {Journal of child psychology and psychiatry, and allied disciplines},\n pages = {\n          877-900\n        },\n title = {A case-control family history study of autism.},\n volume = {35 5},\n year = {1994}\n}\n'}","[{'authorId': '5897982', 'name': 'P. Bolton'}, {'authorId': '33193167', 'name': 'Hope Macdonald'}, {'authorId': '2066480', 'name': 'A. Pickles'}, {'authorId': '2067807870', 'name': 'P. Rios'}, {'authorId': '34178191', 'name': 'S. Goode'}, {'authorId': '49150998', 'name': 'M. Crowson'}, {'authorId': '2356031', 'name': 'A. Bailey'}, {'authorId': '2779929', 'name': 'M. Rutter'}]"
742,3e13193efbd8466ccec27bd808a30b37fcad0156,Relational Messages Associated with Nonverbal Behaviors.,"Based on the assumptions that relational messages are multidimensional and that they are frequently communicated by nonverbal cues, this experiment manipulated five nonverbal cues -eye contact, proximity, body lean, smiling, and touch - to determine what meanings they convey along four relational message dimensions. Subjects (N= 150) observed 2 out of 40 videotaped conversational segments in which a male-female dyad presented various combinations of the nonverbal cues. High eye contact, close proximity, forward body lean, and smiling all conveyed greater intimacy, attraction, and trust. Low eye contact, a distal position, backward body lean, and the absence of smiling and touch communicated greater detachment. High eye contact, close proximity, and smiling also communicated less emotional arousal and greater composure, while high eye contact and close proximity alone conveyed greater dominance and control. Effects of combinations of cues and sex-differences are also reported.",1984.0,61.0,370.0,False,,"{'volume': '10', 'pages': '351-378', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Burgoon1984RelationalMA,\n author = {J. Burgoon and D. Buller and Jerold L. Hale and M. Turck},\n journal = {Human Communication Research},\n pages = {351-378},\n title = {Relational Messages Associated with Nonverbal Behaviors.},\n volume = {10},\n year = {1984}\n}\n'}","[{'authorId': '2896960', 'name': 'J. Burgoon'}, {'authorId': '2461312', 'name': 'D. Buller'}, {'authorId': '39973716', 'name': 'Jerold L. Hale'}, {'authorId': '39842046', 'name': 'M. Turck'}]"
743,3e15f73d154a40932ebcc7b766a81e697263bca6,Perception of Basic Emotions from Facial Expressions of Dynamic Virtual Avatars,,2015.0,24.0,7.0,False,,{'pages': '409-419'},"{'bibtex': '@Inproceedings{Faita2015PerceptionOB,\n author = {Claudia Faita and F. Vanni and C. Lorenzini and M. Carrozzino and Camilla Tanca and M. Bergamasco},\n pages = {409-419},\n title = {Perception of Basic Emotions from Facial Expressions of Dynamic Virtual Avatars},\n year = {2015}\n}\n'}","[{'authorId': '3223757', 'name': 'Claudia Faita'}, {'authorId': '13333196', 'name': 'F. Vanni'}, {'authorId': '3491266', 'name': 'C. Lorenzini'}, {'authorId': '2203390', 'name': 'M. Carrozzino'}, {'authorId': '2814090', 'name': 'Camilla Tanca'}, {'authorId': '7723077', 'name': 'M. Bergamasco'}]"
744,3e16a068b5ad2317b0dc373501ffbc1834f6c3af,"A Spontaneous Micro-expression Database: Inducement, collection and baseline","Micro-expressions are short, involuntary facial expressions which reveal hidden emotions. Micro-expressions are important for understanding humans' deceitful behavior. Psychologists have been studying them since the 1960's. Currently the attention is elevated in both academic fields and in media. However, while general facial expression recognition (FER) has been intensively studied for years in computer vision, little research has been done in automatically analyzing micro-expressions. The biggest obstacle to date has been the lack of a suitable database. In this paper we present a novel Spontaneous Micro-expression Database SMIC, which includes 164 micro-expression video clips elicited from 16 participants. Micro-expression detection and recognition performance are provided as baselines. SMIC provides sufficient source material for comprehensive testing of automatic systems for analyzing micro-expressions, which has not been possible with any previously published database.",2013.0,35.0,431.0,True,"{'url': 'http://tomas.pfister.fi/files/li2013microexpressions.pdf', 'status': None}","{'pages': '1-6', 'name': '2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)'}","{'bibtex': '@Article{Li2013ASM,\n author = {Xiaobai Li and Tomas Pfister and Xiaohua Huang and Guoying Zhao and M. Pietikäinen},\n journal = {2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},\n pages = {1-6},\n title = {A Spontaneous Micro-expression Database: Inducement, collection and baseline},\n year = {2013}\n}\n'}","[{'authorId': '1502872895', 'name': 'Xiaobai Li'}, {'authorId': '1945962', 'name': 'Tomas Pfister'}, {'authorId': '47932625', 'name': 'Xiaohua Huang'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '145962204', 'name': 'M. Pietikäinen'}]"
745,3e58205f859f6fd13623fb1dbedc3f4ade5c49c4,Affect Simulation with Primary and Secondary Emotions,,2008.0,42.0,59.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/2609667/2645598/IVA08_Becker-Asano_Wachsmuth.pdf', 'status': None}",{'pages': '15-28'},"{'bibtex': '@Inproceedings{Becker-Asano2008AffectSW,\n author = {C. Becker-Asano and I. Wachsmuth},\n pages = {15-28},\n title = {Affect Simulation with Primary and Secondary Emotions},\n year = {2008}\n}\n'}","[{'authorId': '1403827243', 'name': 'C. Becker-Asano'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
746,3e5e3ce6f1ccf669e4c75ecf3dce2baf8d9f19b2,Feeling Ambivalent: A Model of Mixed Emotions for Virtual Agents,,2006.0,15.0,12.0,False,,{'pages': '329-342'},"{'bibtex': '@Inproceedings{Lee2006FeelingAA,\n author = {B. Lee and E. C. Kao and V. Soo},\n pages = {329-342},\n title = {Feeling Ambivalent: A Model of Mixed Emotions for Virtual Agents},\n year = {2006}\n}\n'}","[{'authorId': '49132154', 'name': 'B. Lee'}, {'authorId': '15450398', 'name': 'E. C. Kao'}, {'authorId': '1700936', 'name': 'V. Soo'}]"
747,3e5f253ee65bde85c09c5b7abac4f6f582240587,ISO 9241-9 evaluation of video game controllers,"Fifteen participants completed a study comparing video game controllers for point-select tasks. We used a Fitts' law task, as per ISO 9241-9, using the Nintendo Wii Remote for infrared pointing, the Nintendo Classic Controller for analogue stick pointing, and a standard mouse as a baseline condition. The mouse had the highest throughput at 3.78 bps. Both game controllers performed poorly by comparison. The Wii Remote throughput was 31.5% lower, at 2.59 bps, and the Classic Controller 60.8% lower at 1.48 bps. Comparing just the video game controllers, the Wii Remote presents a 75% increase in throughput over the Classic Controller. Error rates for the mouse, Classic Controller, and the Wii Remote were 3.53%, 6.58%, and 10.2%, respectively. Fourteen of 15 participants expressed a preference for the Wii Remote over the Classic Controller for pointing tasks in a home entertainment environment.",2009.0,16.0,131.0,False,,{'pages': '223-230'},"{'bibtex': '@Inproceedings{Natapov2009ISO9E,\n author = {Daniel Natapov and Steven J. Castellucci and I. Mackenzie},\n pages = {223-230},\n title = {ISO 9241-9 evaluation of video game controllers},\n year = {2009}\n}\n'}","[{'authorId': '2474408', 'name': 'Daniel Natapov'}, {'authorId': '2994301', 'name': 'Steven J. Castellucci'}, {'authorId': '47315589', 'name': 'I. Mackenzie'}]"
748,3e7da5b3a59b12ff1b29a790a1c0d354de76bb4f,A Short Form of the Test of Facial Recognition for Clinical Use,"Summary To explore the possibility of developing a valid abbreviated form of the Test of Facial Recognition of Benton and Van Allen for clinical use, the test performances of 185 adult patients with established diagnoses of brain disease and 151 adult patients without history or evidence of brain disease were studied. Stepwise multiple discriminant analysis on subsamples of the brain-diseased and control patients identified discriminating items which were then subjected to cross-validation on independent subsamples. The resulting short form of the test consisted of 16 items requiring 27 responses, representing a 50 percent reduction in length. Part-whole correlation coefficients between the short and long forms of the test ranged from .884 to .940 in five different samples of patients. With use of the smoothed equipercentile method of Flanagan, a table for predicting long form scores from obtained short form scores was constructed. Guidelines for the employment of the short form in clinical evaluation wer...",1975.0,6.0,110.0,False,,"{'volume': '91', 'pages': '223-228', 'name': 'The Journal of Psychology'}","{'bibtex': '@Article{Levin1975ASF,\n author = {H. Levin and K. D. Hamsher and A. Benton},\n journal = {The Journal of Psychology},\n pages = {223-228},\n title = {A Short Form of the Test of Facial Recognition for Clinical Use},\n volume = {91},\n year = {1975}\n}\n'}","[{'authorId': '1910665', 'name': 'H. Levin'}, {'authorId': '3563344', 'name': 'K. D. Hamsher'}, {'authorId': '2203961', 'name': 'A. Benton'}]"
749,3e9ba2cf4b71d3109d7c928245ea324a74e41be4,Commitment and Effectiveness of Situated Agents,"Recent research in real-time Artificial Intelligence has focussed upon the design of situated agents and, in particular, how to achieve effective and robust behaviour with limited computational resources. A range of architectures and design principles has been proposed to solve this problem. This has led to the development of simulated worlds that can serve as testbeds in which the effectiveness of different agents can be evaluated. We report here an experimental program that aimed to investigate how commitment to goals contributes to effective behaviour and to compare the properties of different strategies for reacting to change. Our results demonstrate the feasibility of developing systems for empirical measurement of agent performance that are stable, sensitive, and capable of revealing the effect of ""high-level"" agent characteristics such as commitment.",1991.0,13.0,226.0,False,,{'pages': '82-88'},"{'bibtex': '@Inproceedings{Kinny1991CommitmentAE,\n author = {D. Kinny and M. Georgeff},\n pages = {82-88},\n title = {Commitment and Effectiveness of Situated Agents},\n year = {1991}\n}\n'}","[{'authorId': '2337543', 'name': 'D. Kinny'}, {'authorId': '1694809', 'name': 'M. Georgeff'}]"
750,3ea11e4fc90fffc4932ccaac262e8f42e68572d2,Formalisme de description des gestes de la langue des signes française pour la génération du mouvement de signeurs virtuels [French Sign Language Gesture Description Formalism for the Generation of Virtual Signer Motion],"This paper presents a model for generating French sign language gestures, which is based on both a semi-formal modelling approach, and on a specification formalism yielding to the translation of an utterance into a continuous data flow for the control of a virtual character. This approach benefits from knowledge of structural linguistics proper to sign language, and results of motion capture analysis.",2007.0,37.0,5.0,False,,"{'volume': '48', 'pages': '115-149', 'name': 'Trait. Autom. des Langues'}","{'bibtex': '@Article{Gibet2007FormalismeDD,\n author = {Sylvie Gibet and Alexis Héloir},\n journal = {Trait. Autom. des Langues},\n pages = {115-149},\n title = {Formalisme de description des gestes de la langue des signes française pour la génération du mouvement de signeurs virtuels [French Sign Language Gesture Description Formalism for the Generation of Virtual Signer Motion]},\n volume = {48},\n year = {2007}\n}\n'}","[{'authorId': '2066213664', 'name': 'Sylvie Gibet'}, {'authorId': '2064000639', 'name': 'Alexis Héloir'}]"
751,3ea76b808abc87297ad1ba45cdfdca65ba4d704c,The neuroscience of emotion regulation development: implications for education,,2016.0,60.0,82.0,True,"{'url': 'https://europepmc.org/articles/pmc5096655?pdf=render', 'status': None}","{'volume': '10', 'pages': '142-148', 'name': 'Current Opinion in Behavioral Sciences'}","{'bibtex': '@Article{Martin2016TheNO,\n author = {Rebecca E. Martin and K. Ochsner},\n journal = {Current Opinion in Behavioral Sciences},\n pages = {142-148},\n title = {The neuroscience of emotion regulation development: implications for education},\n volume = {10},\n year = {2016}\n}\n'}","[{'authorId': '7766514', 'name': 'Rebecca E. Martin'}, {'authorId': '2669604', 'name': 'K. Ochsner'}]"
752,3eb068252f341ace3b29c7b88f93cf491330a3d2,I've been here before!: location and appraisal in memory retrieval,"The objective of our current work was to create a model for agent memory retrieval of emotionally relevant episodes. We analyzed agent architectures that support memory retrieval realizing that none fulfilled all of our requirements. We designed an episodic memory retrieval model consisting of two main steps: location ecphory, in which the agent's current location is matched against stored memories associated locations; and recollective experience, in which memories that had a positive match are re-appraised. We implemented our model and used it to drive the behavior of characters in a game application. We recorded the application running and used the videos to create a non-interactive evaluation. The evaluation's results are consistent with our hypothesis that agents with memory retrieval of emotionally relevant episodes would be perceived as more believable than similar agents without it.",2011.0,30.0,18.0,False,,{'pages': '1039-1046'},"{'bibtex': ""@Inproceedings{Gomes2011IveBH,\n author = {P. Gomes and C. Martinho and Ana Paiva},\n pages = {1039-1046},\n title = {I've been here before!: location and appraisal in memory retrieval},\n year = {2011}\n}\n""}","[{'authorId': '1784861', 'name': 'P. Gomes'}, {'authorId': '145813496', 'name': 'C. Martinho'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
753,3ebdcef1c13a3f83a8d755c61815cc6c6ba0653f,Fast force-generation dynamics of human articulatory muscles.,"To explore the mechanisms of speech articulation, which is one of the most sophisticated human motor skills controlled by the central nervous system, we investigated the force-generation dynamics of the human speech articulator muscles [orbicularis oris superior (OOS) and inferior (OOI) muscles of the lips]. Short-pulse electrical stimulation (300 micros) with approximately three or four times the sensation threshold intensity of each subject induced the muscle response. The responses of these muscles were modeled as second-order dynamics with a time delay (TD), and the model parameters [natural frequency (NF), damping ratio (DR), and TD] were identified with a nonlinear least mean squares method. The OOS (NF: 6.1 Hz, DR: 0.71, TD: 14.5 ms) and OOI (NF: 6.1 Hz, DR: 0.68, TD: 15.6 ms) showed roughly similar characteristics in eight subjects. The dynamics in the tongue (generated by combined muscles) also showed similar characteristics (NF: 6.1 Hz, DR: 0.68, TD: 17.4 ms) in two subjects. The NF was higher, and the DR was lower than results measured for arm muscles (NF: 4.25 Hz, DR: 1.05, TD: 23.8 ms for triceps long head), indicating that articulatory organs adapt for more rapid movement. In contrast, slower response dynamics was estimated when muscle force data by voluntarily contraction task were used for force-generation dynamics modeling. We discuss methodological problems in estimating muscle dynamics when different kinds of muscle contraction methods are used.",2004.0,31.0,45.0,False,,"{'volume': '96 6', 'pages': '\n          2318-24; discussion 2317\n        ', 'name': 'Journal of applied physiology'}","{'bibtex': '@Article{Ito2004FastFD,\n author = {Takayuki Ito and E. Murano and H. Gomi},\n journal = {Journal of applied physiology},\n pages = {\n          2318-24; discussion 2317\n        },\n title = {Fast force-generation dynamics of human articulatory muscles.},\n volume = {96 6},\n year = {2004}\n}\n'}","[{'authorId': '145214184', 'name': 'Takayuki Ito'}, {'authorId': '2391497', 'name': 'E. Murano'}, {'authorId': '2561820', 'name': 'H. Gomi'}]"
754,3ecf1498f7f0da3146c508f3ff0f04c5e766cb42,PETEEI: a PET with evolving emotional intelligence,"The emergence of, what is now called, ‘emotional intellige nce’ has revealed yet another aspect of human intelligence. Emot ions were shown to have a major impact on many of our everyday tasks, including decision-making, planning, communication, and behavior. Researchers have recently acknowledged this major role that emotions play, and thus we see a variety of models bei ng presented on simulating emotions in agents. However, emotion is not a simple process, it is often linked with many other pr ocesses, one of which is learning. As it has long been emphasized throug h psychology literature, memory and experience help shape and build the dynamic nature of the emotional process. In this pa per, we introduce PETEEI (a PET with Evolving Emotional Intelligence). PETEEI is a general model for simulating emotions in agents, with a particular emphasis on incorporating vario us learning mechanisms so that it can produce emotions accor ding to its own experience. Furthermore, it was modeled to recogniz e and cope with the various mood and emotional changes of its owne r. We have implemented PETEEI using fuzzy logic. An evaluation involving twenty-one subjects indicated that simulating the dynamic emotional process through learning provides a significantly more believable agent.",1999.0,37.0,85.0,False,,{'pages': '9-15'},"{'bibtex': '@Inproceedings{El-Nasr1999PETEEIAP,\n author = {M. S. El-Nasr and T. Ioerger and J. Yen},\n pages = {9-15},\n title = {PETEEI: a PET with evolving emotional intelligence},\n year = {1999}\n}\n'}","[{'authorId': '1381933697', 'name': 'M. S. El-Nasr'}, {'authorId': '1681317', 'name': 'T. Ioerger'}, {'authorId': '143674364', 'name': 'J. Yen'}]"
755,3eebc19737b5add8640065c49b81af231ff09274,Lectures on the Experimental Psychology of the Thought-Processes,,1910.0,0.0,130.0,False,,,"{'bibtex': '@Inproceedings{Woodworth1910LecturesOT,\n author = {R. Woodworth},\n title = {Lectures on the Experimental Psychology of the Thought-Processes},\n year = {1910}\n}\n'}","[{'authorId': '38807438', 'name': 'R. Woodworth'}]"
756,3f24bb4bf632cb05df08039cb8b7139a273f3338,Proxemics with multiple dynamic characters in an immersive virtual environment,"An experiment was carried out to examine the impact on electrodermal activity of people when approached by groups of one or four virtual characters at varying distances. It was premised on the basis of proxemics theory that the closer the approach of the virtual characters to the participant, the greater the level of physiological arousal. Physiological arousal was measured by the number of skin conductance responses within a short time period after the approach, and the maximum change in skin conductance level 5 s after the approach. The virtual characters were each either female or a cylinder of human size, and one or four characters approached each subject a total of 12 times. Twelve male subjects were recruited for the experiment. The results suggest that the number of skin conductance responses after the approach and the change in skin conductance level increased the closer the virtual characters approached toward the participants. Moreover, these response variables were inversely correlated with the number of visits, showing a typical adaptation effect. There was some evidence to suggest that the number of characters who simultaneously approached (one or four) was positively associated with the responses. Surprisingly there was no evidence of a difference in response between the humanoid characters and cylinders on the basis of this physiological data. It is suggested that the similarity in this quantitative arousal response to virtual characters and virtual objects might mask a profound difference in qualitative response, an interpretation supported by questionnaire and interview results. Overall the experiment supported the premise that people exhibit heightened physiological arousal the closer they are approached by virtual characters.",2010.0,32.0,133.0,True,"{'url': 'https://diposit.ub.edu/dspace/bitstream/2445/54024/1/616991.pdf', 'status': None}","{'volume': '8', 'pages': '3:1-3:12', 'name': 'ACM Trans. Appl. Percept.'}","{'bibtex': '@Article{Llobera2010ProxemicsWM,\n author = {J. Llobera and B. Spanlang and G. Ruffini and M. Slater},\n journal = {ACM Trans. Appl. Percept.},\n pages = {3:1-3:12},\n title = {Proxemics with multiple dynamic characters in an immersive virtual environment},\n volume = {8},\n year = {2010}\n}\n'}","[{'authorId': '48334647', 'name': 'J. Llobera'}, {'authorId': '2891686', 'name': 'B. Spanlang'}, {'authorId': '144679534', 'name': 'G. Ruffini'}, {'authorId': '144931212', 'name': 'M. Slater'}]"
757,3f3a737d0e334ccb56271d762a444c01434aa6c8,FearNot! - An Emergent Narrative Approach to Virtual Dramas for Anti-bullying Education,,2007.0,9.0,114.0,False,,{'pages': '202-205'},"{'bibtex': '@Inproceedings{Aylett2007FearNotA,\n author = {R. Aylett and M. Vala and P. Sequeira and Ana Paiva},\n pages = {202-205},\n title = {FearNot! - An Emergent Narrative Approach to Virtual Dramas for Anti-bullying Education},\n year = {2007}\n}\n'}","[{'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '7306645', 'name': 'M. Vala'}, {'authorId': '1744526', 'name': 'P. Sequeira'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
758,3f3d8fd3d9122ba222472afbab764ee6809b600a,Choosing when to interact with learners,"In this paper, we describe a method for pedagogical agents to choose when to interact with learners in interactive learning environments. This method is based on observations of human tutors coaching students in on-line learning tasks. It takes into account the focus of attention of the learner, the learner's current task, and expected time required to perform the task. A Bayesian network model combines evidence from eye gaze and interface actions to infer learner focus of attention. The attention model is combined with a plan recognizer to detect different types of learner difficulties such as confusion and indecision which warrant intervention. We plan to incorporate this capability into a pedagogical agent able to interact with learners in socially appropriate ways.",2004.0,6.0,24.0,False,,{'pages': '307-309'},"{'bibtex': '@Inproceedings{Qu2004ChoosingWT,\n author = {Lei Qu and Ning Wang and W. Johnson},\n pages = {307-309},\n title = {Choosing when to interact with learners},\n year = {2004}\n}\n'}","[{'authorId': '2056322994', 'name': 'Lei Qu'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '145834585', 'name': 'W. Johnson'}]"
759,3f3f11fe52ebba8707fc76ecea29b20d40963f30,The developmental origins of a disposition toward empathy: Genetic and environmental contributions.,"The authors investigated the development of a disposition toward empathy and its genetic and environmental origins. Young twins' (N = 409 pairs) cognitive (hypothesis testing) and affective (empathic concern) empathy and prosocial behavior in response to simulated pain by mothers and examiners were observed at multiple time points. Children's mean level of empathy and prosociality increased from 14 to 36 months. Positive concurrent and longitudinal correlations indicated that empathy was a relatively stable disposition, generalizing across ages, across its affective and cognitive components, and across mother and examiner. Multivariate genetic analyses showed that genetic effects increased, and that shared environmental effects decreased, with age. Genetic effects contributed to both change and continuity in children's empathy, whereas shared environmental effects contributed to stability and nonshared environmental effects contributed to change. Empathy was associated with prosocial behavior, and this relationship was mainly due to environmental effects.",2008.0,67.0,487.0,False,,"{'volume': '8 6', 'pages': '\n          737-52\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Knafo2008TheDO,\n author = {A. Knafo and C. Zahn-Waxler and C. V. Van Hulle and Joann L. Robinson and S. Rhee},\n journal = {Emotion},\n pages = {\n          737-52\n        },\n title = {The developmental origins of a disposition toward empathy: Genetic and environmental contributions.},\n volume = {8 6},\n year = {2008}\n}\n'}","[{'authorId': '5128614', 'name': 'A. Knafo'}, {'authorId': '1398158374', 'name': 'C. Zahn-Waxler'}, {'authorId': '72258629', 'name': 'C. V. Van Hulle'}, {'authorId': '145084432', 'name': 'Joann L. Robinson'}, {'authorId': '7137870', 'name': 'S. Rhee'}]"
760,3f7803ced283b37a193e616c43c598e4c1720541,The emotional Stroop task and psychopathology.,"Attentional bias is a central feature of many cognitive theories of psychopathology. One of the most frequent methods of investigating such bias has been an emotional analog of the Stroop task. In this task, participants name the colors in which words are printed, and the words vary in their relevance to each theme of psychopathology. The authors review research showing that patients are often slower to name the color of a word associated with concerns relevant to their clinical condition. They address the causes and mechanisms underlying the phenomenon, focusing on J.D. Cohen, K. Dunbar, and J.L. McClelland's (1990) parallel distributed processing model.",1996.0,103.0,2444.0,False,,"{'volume': '120 1', 'pages': '\n          3-24\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{M1996TheES,\n author = {G. W I L L I A M S A N D R E W M and D. Cohen and K. Dun-Bar and J. L. Mcclelland and J. Mark and G. Williams and Brendan Bradley and T. Dalgleish and Andy Macleod and Karen Mogg and Mark G Williams and Williams},\n journal = {Psychological bulletin},\n pages = {\n          3-24\n        },\n title = {The emotional Stroop task and psychopathology.},\n volume = {120 1},\n year = {1996}\n}\n'}","[{'authorId': '2248803009', 'name': 'G. W I L L I A M S A N D R E W M'}, {'authorId': '2248872775', 'name': 'D. Cohen'}, {'authorId': '2248802661', 'name': 'K. Dun-Bar'}, {'authorId': '2248803920', 'name': 'J. L. Mcclelland'}, {'authorId': '2239436018', 'name': 'J. Mark'}, {'authorId': '2248831872', 'name': 'G. Williams'}, {'authorId': '2248806247', 'name': 'Brendan Bradley'}, {'authorId': '2193978', 'name': 'T. Dalgleish'}, {'authorId': '2248803633', 'name': 'Andy Macleod'}, {'authorId': '2248802574', 'name': 'Karen Mogg'}, {'authorId': '2249058514', 'name': 'Mark G Williams'}, {'authorId': '2248805785', 'name': 'Williams'}]"
761,3fb3e336684791fb42f5444769a5f1e5484d1522,Fostering multimedia learning of science: Exploring the role of an animated agent's image,,2007.0,25.0,165.0,False,,"{'volume': '49', 'pages': '677-690', 'name': 'Comput. Educ.'}","{'bibtex': ""@Article{Dunsworth2007FosteringML,\n author = {Qi Dunsworth and R. Atkinson},\n journal = {Comput. Educ.},\n pages = {677-690},\n title = {Fostering multimedia learning of science: Exploring the role of an animated agent's image},\n volume = {49},\n year = {2007}\n}\n""}","[{'authorId': '81486204', 'name': 'Qi Dunsworth'}, {'authorId': '1737845', 'name': 'R. Atkinson'}]"
762,3fdbf4e4980464abd2e85defcfe4ebefa4fe0a00,Cognitive Biases in Crowdsourcing,"Crowdsourcing has become a popular paradigm in data curation, annotation and evaluation for many artificial intelligence and information retrieval applications. Considerable efforts have gone into devising effective quality control mechanisms that identify or discourage cheat submissions in an attempt to improve the quality of noisy crowd judgments. Besides purposeful cheating, there is another source of noise that is often alluded to but insufficiently studied: Cognitive biases. This paper investigates the prevalence and effect size of a range of common cognitive biases on a standard relevance judgment task. Our experiments are based on three sizable publicly available document collections and note significant detrimental effects on annotation quality, system ranking and the performance of derived rankers when task design does not account for such biases.",2018.0,64.0,112.0,False,,{'name': 'Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining'},"{'bibtex': '@Article{Eickhoff2018CognitiveBI,\n author = {Carsten Eickhoff},\n journal = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},\n title = {Cognitive Biases in Crowdsourcing},\n year = {2018}\n}\n'}","[{'authorId': '1764160', 'name': 'Carsten Eickhoff'}]"
763,3ff96435f510c67b8f715def7c244d6bece0e7af,When a Talking-Face Computer Agent Is Half-Human and Half-Humanoid: Human Identity and Consistency Preference.,"Computer-generated anthropomorphic characters are a growing type of communicator that is deployed in digital communication environments. An essential theoretical question is how people identify humanlike but clearly artificial, hence humanoid, entities in comparison to natural human ones. This identity categorization inquiry was approached under the framework of consistency and tested through examining inconsistency effects from mismatching categories. Study 1 (N = 80), incorporating a self-disclosure task, tested participants’ responses to a talking-face agent, which varied in four combinations of human versus humanoid faces and voices. In line with the literature on inconsistency, the pairing of a human face with a humanoid voice or a humanoid face with a human voice led to longer processing time in making judgment of the agent and less trust than the pairing of a face and a voice from either the human or the humanoid category. Female users particularly showed negative attitudes toward inconsistently paired talking faces. Study 2 (N = 80), using a task that stressed comprehension demand, replicated the inconsistency effects on judging time and females’ negative attitudes but not for comprehension-related outcomes. Voice clarity overshadowed the consistency concern for comprehension-related responses. The overall inconsistency effects suggest that people treat humanoid entities in a different category from natural human ones.",2007.0,60.0,122.0,False,,"{'volume': '33', 'pages': '163-193', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Gong2007WhenAT,\n author = {Li Gong and C. Nass},\n journal = {Human Communication Research},\n pages = {163-193},\n title = {When a Talking-Face Computer Agent Is Half-Human and Half-Humanoid: Human Identity and Consistency Preference.},\n volume = {33},\n year = {2007}\n}\n'}","[{'authorId': '2056813456', 'name': 'Li Gong'}, {'authorId': '2029850', 'name': 'C. Nass'}]"
764,404694adbee46926ebadf2d4a02021ca75c73ce9,Comparing an On-Screen Agent with a Robotic Agent in Non-Face-to-Face Interactions,,2008.0,8.0,22.0,False,,{'pages': '498-504'},"{'bibtex': '@Inproceedings{Komatsu2008ComparingAO,\n author = {T. Komatsu and Yukari Abe},\n pages = {498-504},\n title = {Comparing an On-Screen Agent with a Robotic Agent in Non-Face-to-Face Interactions},\n year = {2008}\n}\n'}","[{'authorId': '1723194', 'name': 'T. Komatsu'}, {'authorId': '9618507', 'name': 'Yukari Abe'}]"
765,4061bca09d27481190d4b9bbc62fe6a0ad016278,The Polyvagal Theory: phylogenetic contributions to social behavior,,2003.0,51.0,669.0,False,,"{'volume': '79', 'pages': '503-513', 'name': 'Physiology & Behavior'}","{'bibtex': '@Article{Porges2003ThePT,\n author = {S. Porges},\n journal = {Physiology & Behavior},\n pages = {503-513},\n title = {The Polyvagal Theory: phylogenetic contributions to social behavior},\n volume = {79},\n year = {2003}\n}\n'}","[{'authorId': '4226466', 'name': 'S. Porges'}]"
766,40c5441aad96b366996e6af163ca9473a19bb9ad,Identification of common molecular subsequences.,,1981.0,19.0,10359.0,False,,"{'volume': '147 1', 'pages': '\n          195-7\n        ', 'name': 'Journal of molecular biology'}","{'bibtex': '@Article{Smith1981IdentificationOC,\n author = {Temple F. Smith and M. Waterman},\n journal = {Journal of molecular biology},\n pages = {\n          195-7\n        },\n title = {Identification of common molecular subsequences.},\n volume = {147 1},\n year = {1981}\n}\n'}","[{'authorId': '2109503620', 'name': 'Temple F. Smith'}, {'authorId': '2398669', 'name': 'M. Waterman'}]"
767,40da87c0fea4f05377326b98fb2ca1e962fb7355,Emotive alert: HMM-based emotion detection in voicemail messages,"Voicemail has become an integral part of our personal and professional communication. The number of messages that accumulate in our voice mailboxes necessitate new ways of prioritizing them. Currently, we are forced to actively listen to all messages in order to find out which ones are important and which ones can be attended to later on. In this paper, we describe Emotive Alert, a system that can detect some of the significant emotions in a new message and notify the account owner along various affective axes, including urgency, formality, valence (happy vs. sad) and arousal (calm vs. excited). We have used a purely acoustic, HMM-based approach for identifying the emotions, which allows application of this system to all messages independent of language.",2005.0,7.0,40.0,False,,{'name': 'Proceedings of the 10th international conference on Intelligent user interfaces'},"{'bibtex': '@Article{Inanoglu2005EmotiveAH,\n author = {Zeynep Inanoglu and R. Caneel},\n journal = {Proceedings of the 10th international conference on Intelligent user interfaces},\n title = {Emotive alert: HMM-based emotion detection in voicemail messages},\n year = {2005}\n}\n'}","[{'authorId': '2571389', 'name': 'Zeynep Inanoglu'}, {'authorId': '2020387', 'name': 'R. Caneel'}]"
768,40ec4c93b8fcf7e85385e9cf0d498411b3f31aca,Review of Semantic-Free Utterances in Social Human–Robot Interaction,"As a young and emerging field in social human–robot interaction (HRI), semantic-free utterances (SFUs) research has been receiving attention over the last decade. SFUs are an auditory interaction means for machines that allow emotion and intent expression, which are composed of vocalizations and sounds without semantic content or language dependence. Currently, SFUs are most commonly utilized in animation movies (e.g., R2-D2, WALL-E, Despicable Me), cartoons (e.g., “Teletubbies,” “Morph,” “La Linea”), and computer games (e.g., The Sims) and hold significant potential for applications in HRI. SFUs are categorized under four general types: Gibberish Speech (GS), Non-Linguistic Utterances (NLUs), Musical Utterances (MU), and Paralinguistic Utterances (PU). By introducing the concept of SFUs and bringing multiple sets of studies in social HRI that have never been analyzed jointly before, this article addresses the need for a comprehensive study of the existing literature for SFUs. It outlines the current grand challenges, open questions, and provides guidelines for future researchers considering to utilize SFU in social HRI.",2016.0,161.0,65.0,False,,"{'volume': '32', 'pages': '63 - 85', 'name': 'International Journal of Human-Computer Interaction'}","{'bibtex': '@Article{Yilmazyildiz2016ReviewOS,\n author = {S. Yilmazyildiz and Robin Read and Tony Belpaeme and W. Verhelst},\n journal = {International Journal of Human-Computer Interaction},\n pages = {63 - 85},\n title = {Review of Semantic-Free Utterances in Social Human–Robot Interaction},\n volume = {32},\n year = {2016}\n}\n'}","[{'authorId': '1914965', 'name': 'S. Yilmazyildiz'}, {'authorId': '48014697', 'name': 'Robin Read'}, {'authorId': '2301161', 'name': 'Tony Belpaeme'}, {'authorId': '1802474', 'name': 'W. Verhelst'}]"
769,417b37b3256b2ca7567f0dc2ca3c96c61f3a8376,Understanding the relationship between patient language and outcomes in internet-enabled cognitive behavioural therapy: A deep learning approach to automatic coding of session transcripts,"Abstract Objective: Understanding patient responses to psychotherapy is important in developing effective interventions. However, coding patient language is a resource-intensive exercise and difficult to perform at scale. Our aim was to develop a deep learning model to automatically identify patient utterances during text-based internet-enabled Cognitive Behavioural Therapy and to determine the association between utterances and clinical outcomes. Method: Using 340 manually annotated transcripts we trained a deep learning model to categorize patient utterances into one or more of five categories. The model was used to automatically code patient utterances from our entire data set of transcripts (∼34,000 patients), and logistic regression analyses used to determine the association between both reliable improvement and engagement, and patient responses. Results: Our model reached human-level agreement on three of the five patient categories. Regression analyses revealed that increased counter change-talk (movement away from change) was associated with lower odds of both reliable improvement and engagement, while increased change-talk (movement towards change or self-exploration) was associated with increased odds of improvement and engagement. Conclusions: Deep learning provides an effective means of automatically coding patient utterances at scale. This approach enables the development of a data-driven understanding of the relationship between therapist and patient during therapy.",2020.0,36.0,19.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/10503307.2020.1788740?needAccess=true', 'status': None}","{'volume': '31', 'pages': '300 - 312', 'name': 'Psychotherapy Research'}","{'bibtex': '@Article{Ewbank2020UnderstandingTR,\n author = {M. Ewbank and R. Cummins and V. Tablan and A. Catarino and S. Buchholz and A. Blackwell},\n journal = {Psychotherapy Research},\n pages = {300 - 312},\n title = {Understanding the relationship between patient language and outcomes in internet-enabled cognitive behavioural therapy: A deep learning approach to automatic coding of session transcripts},\n volume = {31},\n year = {2020}\n}\n'}","[{'authorId': '1984805', 'name': 'M. Ewbank'}, {'authorId': '153714664', 'name': 'R. Cummins'}, {'authorId': '2095029103', 'name': 'V. Tablan'}, {'authorId': '94314925', 'name': 'A. Catarino'}, {'authorId': '122886979', 'name': 'S. Buchholz'}, {'authorId': '7176472', 'name': 'A. Blackwell'}]"
770,4182e7d996577fffe8aada56a7439c29fe07b2c6,Consequences require antecedents: Toward a process model of emotion elicitation.,,2000.0,0.0,166.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Smith2000ConsequencesRA,\n author = {Craig A. Smith and L. D. Kirby},\n title = {Consequences require antecedents: Toward a process model of emotion elicitation.},\n year = {2000}\n}\n'}","[{'authorId': '2110202993', 'name': 'Craig A. Smith'}, {'authorId': '39504235', 'name': 'L. D. Kirby'}]"
771,42183990e3ccf449ca1ca8a8b582fce720b08013,Promoting Social and Emotional Learning With Games,"This article has two broad objectives: (a) It reviews the theoretical and practical literature on the use of games to facilitate social and emotional learning (SEL). (b) Based on this review, it argues that games are a powerful way of developing social and emotional learning in young people. In addition, we draw on our collective experience as educational psychologists to identify effective practice when using games to teach SEL. The social and emotional skills needed to play successfully with others are those needed to succeed at work and in adult life. Prosocial skills involve regulating negative emotions, taking turns and sharing, support orientations to others that are fair, just, and respectful. The natural affiliation between children, play, and the desire to have fun with others makes games an ideal vehicle for teaching SEL. Circle Time games are used to support universal programs for teaching SEL to whole classes. Therapeutic board games provide an effective intervention for young people who have been targeted for further guided practice in small group settings. Verbatim quotations from students and teachers demonstrate ways in which SEL has generalized to real-life situations. The role of facilitator is crucial to the success of this approach, both in modeling appropriate skills and making the learning connections for students. In this article, facilitation and debriefing are deconstructed and the value of collaborative, rather than competitive, aspects of games highlighted.",2009.0,84.0,214.0,False,,"{'volume': '40', 'pages': '626 - 644', 'name': 'Simulation & Gaming'}","{'bibtex': '@Article{Hromek2009PromotingSA,\n author = {R. Hromek and S. Roffey},\n journal = {Simulation & Gaming},\n pages = {626 - 644},\n title = {Promoting Social and Emotional Learning With Games},\n volume = {40},\n year = {2009}\n}\n'}","[{'authorId': '114636489', 'name': 'R. Hromek'}, {'authorId': '115064384', 'name': 'S. Roffey'}]"
772,4236663e6416423fca02d5b058302adcb78f51f3,COSMIC: COmmonSense knowledge for eMotion Identification in Conversations,"In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-theart methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, COSMIC addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at https://github.com/declare-lab/conv-emotion.",2020.0,46.0,179.0,True,"{'url': 'https://www.aclweb.org/anthology/2020.findings-emnlp.224.pdf', 'status': None}",{'pages': '2470-2481'},"{'bibtex': '@Inproceedings{Ghosal2020COSMICCK,\n author = {Deepanway Ghosal and Navonil Majumder and Alexander Gelbukh and Rada Mihalcea and Soujanya Poria},\n pages = {2470-2481},\n title = {COSMIC: COmmonSense knowledge for eMotion Identification in Conversations},\n year = {2020}\n}\n'}","[{'authorId': '32528506', 'name': 'Deepanway Ghosal'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '1747784', 'name': 'Alexander Gelbukh'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}]"
773,42420cf7a07d089a24944f802bcae71606516af2,Human Behavior Models for Virtual Agents in Repeated Decision Making under Uncertainty,"To design virtual agents that simulate humans in repeated decision making under uncertainty, we seek to quantitatively characterize the actual human behavior in these settings. We collect our data from 800 real human subjects through a large-scale randomized online experiment. We evaluate the performance of a wide range of computational models in fitting the data by both conducting a scalable search through the space of two-component models (i.e. inference + selection model) and investigating a few rules of thumb. 
 
Our results suggest that across different decision-making environment, an average human decision maker can be best described by a two-component model, which is composed of an inference model that relies heavily on more recent information (i.e. displays recency bias) and a selection model which assumes cost-proportional errors and reluctance to change in subsequent trials (i.e. displays status-quo bias). Additionally, while a large portion of individuals behave like the average decision maker, how they differ from each other is greatly influenced by the environment. These results imply the possibility of constructing agents with a single type of model that is robust against the context, and provide insights into adjusting heterogeneity among multiple agents based on the context.",2015.0,29.0,3.0,False,,{'pages': '581-589'},"{'bibtex': '@Inproceedings{Yin2015HumanBM,\n author = {Ming Yin and Yu-An Sun},\n pages = {581-589},\n title = {Human Behavior Models for Virtual Agents in Repeated Decision Making under Uncertainty},\n year = {2015}\n}\n'}","[{'authorId': '2053888438', 'name': 'Ming Yin'}, {'authorId': '2108705456', 'name': 'Yu-An Sun'}]"
774,4246caa136ede0b59b4a762f24e9907f0f0e969c,Both of Us Disgusted in My Insula The Common Neural Basis of Seeing and Feeling Disgust,,2003.0,76.0,2138.0,True,"{'url': 'http://www.cell.com/article/S0896627303006792/pdf', 'status': None}","{'volume': '40', 'pages': '655-664', 'name': 'Neuron'}","{'bibtex': '@Article{Wicker2003BothOU,\n author = {B. Wicker and C. Keysers and J. Plailly and J. Royet and V. Gallese and G. Rizzolatti},\n journal = {Neuron},\n pages = {655-664},\n title = {Both of Us Disgusted in My Insula The Common Neural Basis of Seeing and Feeling Disgust},\n volume = {40},\n year = {2003}\n}\n'}","[{'authorId': '144109100', 'name': 'B. Wicker'}, {'authorId': '46646879', 'name': 'C. Keysers'}, {'authorId': '1816716', 'name': 'J. Plailly'}, {'authorId': '2936760', 'name': 'J. Royet'}, {'authorId': '2914469', 'name': 'V. Gallese'}, {'authorId': '2460061', 'name': 'G. Rizzolatti'}]"
775,426333c1527eb9fd4d7bd0be72a5f0d7decfe2e8,The Impression of Phones and Prosody Choice in the Gibberish Speech of the Virtual Embodied Conversational Agent Kotaro,"The number of smart devices is expected to exceed 100 billion by 2050, and many will feature conversational user interfaces. Thus, methods for generating appropriate prosody for the responses of embodied conversational agents will be very important. This paper presents the results of the “Talk to Kotaro” experiment, which was conducted to better understand how people from different cultural backgrounds react when listening to prosody and phone choices for the IPA symbol-based gibberish speech of the virtual embodied conversational agent Kotaro. It also presents an analysis of the responses to a post-experiment Likert scale questionnaire and the emotions estimated from the participants’ facial expressions, which allowed one to obtain a phone embedding matrix and to conclude that there is no common cross-cultural baseline impression regarding different prosody parameters and that similarly sounding phones are not close in the embedding space. Finally, it also provides the obtained data in a fully anonymous data set.",2023.0,33.0,0.0,True,"{'url': 'https://www.mdpi.com/2076-3417/13/18/10143/pdf?version=1694412690', 'status': 'GOLD'}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Gonzalez2023TheIO,\n author = {Antonio Galiza Cerdeira Gonzalez and W. Lo and I. Mizuuchi},\n booktitle = {Applied Sciences},\n journal = {Applied Sciences},\n title = {The Impression of Phones and Prosody Choice in the Gibberish Speech of the Virtual Embodied Conversational Agent Kotaro},\n year = {2023}\n}\n'}","[{'authorId': '2186651371', 'name': 'Antonio Galiza Cerdeira Gonzalez'}, {'authorId': '30984026', 'name': 'W. Lo'}, {'authorId': '144737212', 'name': 'I. Mizuuchi'}]"
776,42692324ae66e59d9b61877055a4d122487793fe,"Virtual reality in the assessment, understanding, and treatment of mental health disorders","Mental health problems are inseparable from the environment. With virtual reality (VR), computer-generated interactive environments, individuals can repeatedly experience their problematic situations and be taught, via evidence-based psychological treatments, how to overcome difficulties. VR is moving out of specialist laboratories. Our central aim was to describe the potential of VR in mental health, including a consideration of the first 20 years of applications. A systematic review of empirical studies was conducted. In all, 285 studies were identified, with 86 concerning assessment, 45 theory development, and 154 treatment. The main disorders researched were anxiety (n = 192), schizophrenia (n = 44), substance-related disorders (n = 22) and eating disorders (n = 18). There are pioneering early studies, but the methodological quality of studies was generally low. The gaps in meaningful applications to mental health are extensive. The most established finding is that VR exposure-based treatments can reduce anxiety disorders, but there are numerous research and treatment avenues of promise. VR was found to be a much-misused term, often applied to non-interactive and non-immersive technologies. We conclude that VR has the potential to transform the assessment, understanding and treatment of mental health problems. The treatment possibilities will only be realized if – with the user experience at the heart of design – the best immersive VR technology is combined with targeted translational interventions. The capability of VR to simulate reality could greatly increase access to psychological therapies, while treatment outcomes could be enhanced by the technology's ability to create new realities. VR may merit the level of attention given to neuroimaging.",2017.0,67.0,628.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A786FC699B11F6A4BB02B6F99DC20237/S003329171700040Xa.pdf/div-class-title-virtual-reality-in-the-assessment-understanding-and-treatment-of-mental-health-disorders-div.pdf', 'status': None}","{'volume': '47', 'pages': '2393 - 2400', 'name': 'Psychological Medicine'}","{'bibtex': '@Article{Freeman2017VirtualRI,\n author = {Daniel Freeman and S. Reeve and A. Robinson and A. Ehlers and D. Clark and B. Spanlang and M. Slater},\n journal = {Psychological Medicine},\n pages = {2393 - 2400},\n title = {Virtual reality in the assessment, understanding, and treatment of mental health disorders},\n volume = {47},\n year = {2017}\n}\n'}","[{'authorId': '2136711807', 'name': 'Daniel Freeman'}, {'authorId': '29021285', 'name': 'S. Reeve'}, {'authorId': '48325879', 'name': 'A. Robinson'}, {'authorId': '145848941', 'name': 'A. Ehlers'}, {'authorId': '2117734702', 'name': 'D. Clark'}, {'authorId': '2891686', 'name': 'B. Spanlang'}, {'authorId': '144931212', 'name': 'M. Slater'}]"
778,426dc04094d1e2cd1ab84e979a2db3af669d018f,Sentiment and Sarcasm Classification With Multitask Learning,"Sentiment classification and sarcasm detection are both important natural language processing tasks. Sentiment is always coupled with sarcasm where intensive emotion is expressed. Nevertheless, most literature considers them as two separate tasks. We argue that knowledge in sarcasm detection can also be beneficial to sentiment classification and vice versa. We show that these two tasks are correlated, and present a multitask learning-based framework using a deep neural network that models this correlation to improve the performance of both tasks in a multitask learning setting. Our method outperforms the state of the art by 3–4% in the benchmark dataset.",2019.0,29.0,167.0,True,"{'url': 'https://arxiv.org/pdf/1901.08014', 'status': None}","{'volume': '34', 'pages': '38-43', 'name': 'IEEE Intelligent Systems'}","{'bibtex': '@Article{Majumder2019SentimentAS,\n author = {Navonil Majumder and Soujanya Poria and Haiyun Peng and Niyati Chhaya and E. Cambria and Alexander Gelbukh},\n journal = {IEEE Intelligent Systems},\n pages = {38-43},\n title = {Sentiment and Sarcasm Classification With Multitask Learning},\n volume = {34},\n year = {2019}\n}\n'}","[{'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '10761233', 'name': 'Haiyun Peng'}, {'authorId': '2954043', 'name': 'Niyati Chhaya'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '1747784', 'name': 'Alexander Gelbukh'}]"
779,4273ad346de23a38abde6d88754e8b8b70a29351,Emotion Regulation Patterns in Adolescents With High‐Functioning Autism Spectrum Disorder: Comparison to Typically Developing Adolescents and Association With Psychiatric Symptoms,"Autism spectrum disorder (ASD) is often associated with poor emotional control and psychopathology, such as anxiety and depression; however, little is known about the underlying mechanisms. Emotion regulation (ER) is a potential contributing factor, but there has been limited research on ER and its role in comorbid psychopathology in ASD. In this study, we compared self‐reported ER with self‐ and parent reports of psychopathology in 25 high‐functioning adolescents with ASD and 23 age‐ and Intelligence Quotient (IQ)‐matched typically developing controls. Contrary to expectations, both groups reported similar levels of adaptive, voluntary forms of ER (problem solving, acceptance, etc.). However, the ASD group reported significantly greater use of involuntary forms of ER that are typically maladaptive, including remaining focused on the stressor (e.g. rumination and emotional arousal) and shutting down (e.g. emotional numbing and being unable to think or act). Associations between ER and psychopathology were generally more robust using self‐report rather than parent report. For both groups, greater endorsement of involuntary ER strategies was associated with higher ratings of psychopathology, whereas voluntary ER strategies focused on changing or adapting to the situation were significantly associated with lower levels of psychopathology. The magnitude and direction of association between ER types and psychopathology were similar for measures of depression and anxiety. These findings can help guide the development of psychosocial treatments targeting dysfunctional ER in adolescents with ASD. Interventions focused on ER as a transdiagnostic process may be a more robust method to improve emotional control and decrease emotional distress in ASD than disorder‐specific interventions. Autism Res 2014, 7: 344–354. © 2014 International Society for Autism Research, Wiley Periodicals, Inc.",2014.0,48.0,184.0,True,"{'url': 'https://europepmc.org/articles/pmc4136477?pdf=render', 'status': None}","{'volume': '7', 'name': 'Autism Research'}","{'bibtex': '@Article{Mazefsky2014EmotionRP,\n author = {C. Mazefsky and Xenia Borue and Taylor N Day and N. Minshew},\n journal = {Autism Research},\n title = {Emotion Regulation Patterns in Adolescents With High‐Functioning Autism Spectrum Disorder: Comparison to Typically Developing Adolescents and Association With Psychiatric Symptoms},\n volume = {7},\n year = {2014}\n}\n'}","[{'authorId': '3501849', 'name': 'C. Mazefsky'}, {'authorId': '3583715', 'name': 'Xenia Borue'}, {'authorId': '145417300', 'name': 'Taylor N Day'}, {'authorId': '3701869', 'name': 'N. Minshew'}]"
780,427f1ec3a8dea8fdd6a50ac2bbb46d983de26e79,A Method for Learning Macro-Actions for Virtual Characters Using Programming by Demonstration and Reinforcement Learning,"The decision-making by agents in games is commonly based on reinforcement learning. To improve the quality of agents, it is necessary to solve the problems of the time and state space that are required for learning. Such problems can be solved by Macro-Actions, which are defined and executed by a sequence of primitive actions. In this line of research, the learning time is reduced by cutting down the number of policy decisions by agents. Macro-Actions were originally defined as combinations of the same primitive actions. Based on studies that showed the generation of Macro-Actions by learning, Macro-Actions are now thought to consist of diverse kinds of primitive actions. However an enormous amount of learning time and state space are required to generate Macro-Actions. To resolve these issues, we can apply insights from studies on the learning of tasks through Programming by Demonstration (PbD) to generate Macro- Actions that reduce the learning time and state space. In this paper, we propose a method to define and execute Macro-Actions. Macro-Actions are learned from a human subject via PbD and a policy is learned by reinforcement learning. In an experiment, the proposed method was applied to a car simulation to verify the scalability of the proposed method. Data was collected from the driving control of a human subject, and then the Macro- Actions that are required for running a car were generated. Furthermore, the policy that is necessary for driving on a track was learned. The acquisition of Macro-Actions by PbD reduced the driving time by about 16% compared to the case in which Macro-Actions were directly defined by a human subject. In addition, the learning time was also reduced by a faster convergence of the optimum policies.",2012.0,14.0,3.0,True,"{'url': 'http://society.kisti.re.kr/sv/SV_svpsbs03V.do?method=download&cn1=JAKO201229664764832', 'status': None}","{'volume': '8', 'pages': '409-420', 'name': 'J. Inf. Process. Syst.'}","{'bibtex': '@Article{Sung2012AMF,\n author = {Yunsick Sung and Kyungeun Cho},\n journal = {J. Inf. Process. Syst.},\n pages = {409-420},\n title = {A Method for Learning Macro-Actions for Virtual Characters Using Programming by Demonstration and Reinforcement Learning},\n volume = {8},\n year = {2012}\n}\n'}","[{'authorId': '38968784', 'name': 'Yunsick Sung'}, {'authorId': '2818294', 'name': 'Kyungeun Cho'}]"
781,4288cbc1fbc4f620045ca193086c1d476145dfae,Visual prosody: facial movements accompanying speech,"As we articulate speech, we usually move the head and exhibit various facial expressions. This visual aspect of speech aids understanding and helps communicating additional information, such as the speaker's mood. We analyze quantitatively head and facial movements that accompany speech and investigate how they relate to the text's prosodic structure. We recorded several hours of speech and measured the locations of the speakers' main facial features as well as their head poses. The text was evaluated with a prosody prediction tool, identifying phrase boundaries and pitch accents. Characteristic for most speakers are simple motion patterns that are repeatedly applied in synchrony with the main prosodic events. Direction and strength of head movements vary widely from one speaker to another, yet their timing is typically well synchronized with the spoken text. Understanding quantitatively the correlations between head movements and spoken text is important for synthesizing photo-realistic talking heads. Talking heads appear much more engaging when they exhibit realistic motion patterns.",2002.0,11.0,208.0,True,"{'url': 'https://era.ed.ac.uk/bitstream/1842/962/1/Graf.pdf', 'status': None}","{'pages': '396-401', 'name': 'Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition'}","{'bibtex': '@Article{Graf2002VisualPF,\n author = {H. Graf and E. Cosatto and V. Strom and Fu Jie Huang},\n journal = {Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition},\n pages = {396-401},\n title = {Visual prosody: facial movements accompanying speech},\n year = {2002}\n}\n'}","[{'authorId': '1775043', 'name': 'H. Graf'}, {'authorId': '3165487', 'name': 'E. Cosatto'}, {'authorId': '3151603', 'name': 'V. Strom'}, {'authorId': '13919023', 'name': 'Fu Jie Huang'}]"
782,428d4aa8c331bb4609126443c942463aa8a5d74b,Emotional versus neutral expressions and perceptions of social dominance and submissiveness.,"Emotional expressions influence social judgments of personality traits. The goal of the present research was to show that it is of interest to assess the impact of neutral expressions in this context. In 2 studies using different methodologies, the authors found that participants perceived men who expressed neutral and angry emotions as higher in dominance when compared with men expressing sadness or shame. Study 1 showed that this is also true for men expressing happiness. In contrast, women expressing either anger or happiness were perceived as higher in dominance than were women showing a neutral expression who were rated as less dominant. However, sadness expressions by both men and women clearly decreased the extent to which they were perceived as dominant, and a trend in this direction emerged for shame expressions by men in Study 2. Thus, neutral expressions seem to be perceived as a sign of dominance in men but not in women. The present findings extend our understanding of the way different emotional expressions affect perceived dominance and the signal function of neutral expressions-which in the past have often been ignored.",2009.0,35.0,132.0,True,"{'url': 'http://psychophysiolab.com/uhess/pubs/HSH09.pdf', 'status': None}","{'volume': '9 3', 'pages': '\n          378-84\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Hareli2009EmotionalVN,\n author = {Shlomo Hareli and Noga Shomrat and U. Hess},\n journal = {Emotion},\n pages = {\n          378-84\n        },\n title = {Emotional versus neutral expressions and perceptions of social dominance and submissiveness.},\n volume = {9 3},\n year = {2009}\n}\n'}","[{'authorId': '3141618', 'name': 'Shlomo Hareli'}, {'authorId': '48082188', 'name': 'Noga Shomrat'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
783,42b39a9906eb3bceaeb0c4e88d6071405d9daf00,Emotions Revealed: Recognizing Faces and Feelings to Improve Communication and Emotional Life,"""A tour de force. If you read this book, you'll never look at other people in quite the same way again."" Malcolm GladwellRenowned psychologist Paul Ekman explains the roots of our emotions anger, fear, disgust, sadness, and happiness and shows how they cascade across our faces, providing clear signals to those who can identify the clues. As featured in Malcolm Gladwell's bestseller ""Blink,"" Ekman's Facial Action Coding System offers intense training in recognizing feelings in spouses, children, colleagues, even strangers on the street. In ""Emotions Revealed,"" Ekman distills decades of research into a practical, mind-opening, and life-changing guide to reading the emotions of those around us. He answers such questions as: How does our body signal to others whether we are slightly sad or anguished, peeved or enraged? Can we learn to distinguish between a polite smile and the genuine thing? Can we ever truly control our emotions? Packed with unique exercises and photographs, and a new chapter on emotions and lying that encompasses security and terrorism as well as gut decisions, ""Emotions Revealed"" is an indispensable resource for navigating our emotional world.""",2003.0,18.0,1444.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman2003EmotionsRR,\n author = {P. Ekman},\n title = {Emotions Revealed: Recognizing Faces and Feelings to Improve Communication and Emotional Life},\n year = {2003}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
784,42e1b4c2b60baed1ee771a08946e2f430e0a6f15,Emotion and the Prefrontal Cortex: An Integrative Review,"The prefrontal cortex (PFC) plays a critical role in the generation and regulation of emotion. However, we lack an integrative framework for understanding how different emotion-related functions are organized across the entire expanse of the PFC, as prior reviews have generally focused on specific emotional processes (e.g., decision making) or specific anatomical regions (e.g., orbitofrontal cortex). Additionally, psychological theories and neuroscientific investigations have proceeded largely independently because of the lack of a common framework. Here, we provide a comprehensive review of functional neuroimaging, electrophysiological, lesion, and structural connectivity studies on the emotion-related functions of 8 subregions spanning the entire PFC. We introduce the appraisal-by-content model, which provides a new framework for integrating the diverse range of empirical findings. Within this framework, appraisal serves as a unifying principle for understanding the PFC’s role in emotion, while relative content-specialization serves as a differentiating principle for understanding the role of each subregion. A synthesis of data from affective, social, and cognitive neuroscience studies suggests that different PFC subregions are preferentially involved in assigning value to specific types of inputs: exteroceptive sensations, episodic memories and imagined future events, viscero-sensory signals, viscero-motor signals, actions, others’ mental states (e.g., intentions), self-related information, and ongoing emotions. We discuss the implications of this integrative framework for understanding emotion regulation, value-based decision making, emotional salience, and refining theoretical models of emotion. This framework provides a unified understanding of how emotional processes are organized across PFC subregions and generates new hypotheses about the mechanisms underlying adaptive and maladaptive emotional functioning.",2017.0,499.0,383.0,False,,"{'volume': '143', 'pages': '1033–1081', 'name': 'Psychological Bulletin'}","{'bibtex': '@Article{Dixon2017EmotionAT,\n author = {Matthew L. Dixon and Ravi Thiruchselvam and R. Todd and K. Christoff},\n journal = {Psychological Bulletin},\n pages = {1033–1081},\n title = {Emotion and the Prefrontal Cortex: An Integrative Review},\n volume = {143},\n year = {2017}\n}\n'}","[{'authorId': '4296355', 'name': 'Matthew L. Dixon'}, {'authorId': '6635627', 'name': 'Ravi Thiruchselvam'}, {'authorId': '38124822', 'name': 'R. Todd'}, {'authorId': '2788051', 'name': 'K. Christoff'}]"
785,42e416a3448c3825bd20675b8d3e527a1b98d593,Effects of mood on high elaboration attitude change: The mediating role of likelihood judgments,"Two experiments examined the processes by which positive and negative mood states produce attitude change under high elaboration conditions. We hypothesized that under high elaboration conditions, mood would influence attitudes by affecting the perceived likelihood of occurrence for consequences presented in message arguments. In Experiment I, arguments were framed positively, and positive mood led to greater perceived likelihood of the consequences and more favourable attitudes than negative mood for subjects high in need for cognition (NC). In Experiment 2, arguments were framed either positively or negatively, and a mood × frame interaction was obtained on attitude and likelihood judgments for high-NC subjects. That is, positive mood led to marginally greater perceived likelihood of positive consequences but to lower likelihood of negative consequences as compared to negative mood. As a result, positive mood tended to lead to more persuasion than negative mood when the message was framed positively, but to less persuasion when the message was framed negatively In both experiments, path analyses supported the prediction that likelihood judgments mediated the impact of mood on attitudes for high-NC individuals.",1994.0,36.0,181.0,False,,"{'volume': '24', 'pages': '25-43', 'name': 'European Journal of Social Psychology'}","{'bibtex': '@Article{Wegener1994EffectsOM,\n author = {D. Wegener and R. Petty and David J. Klein},\n journal = {European Journal of Social Psychology},\n pages = {25-43},\n title = {Effects of mood on high elaboration attitude change: The mediating role of likelihood judgments},\n volume = {24},\n year = {1994}\n}\n'}","[{'authorId': '32464299', 'name': 'D. Wegener'}, {'authorId': '32761043', 'name': 'R. Petty'}, {'authorId': '116959163', 'name': 'David J. Klein'}]"
786,433aa68fa1834093bd1e0696f8b832c33d0030a0,Analysis of the Big‐five Personality Factors in Terms of the PAD Temperament Model,"Abstract The big-five personality factors were investigated using the trait pleasure-arousability-dominance (PAD) temperament model to assess overlap, and, specifically, similarities and differences, among the five dimensions. Results showed that extraverts were primarily dominant and secondarily pleasant, Agreeableness resembled dependency with pleasant, arousable, and submissive characteristics, but involved greater pleasantness. Conscientiousness included equal degrees of pleasant and dominant qualities. Emotional stability involved almost equal degrees of pleasant and unarousable characteristics, lacking the important dominant feature in this trait. Sophistication was weighted primarily by dominant, and secondarily by arousable, characteristics. The PAD scales explained approximately 75% of the reliable variance in three of the factors (extraversion emotional stability, agreeableness) that have been identified, albeit sometimes with differing labels, in alternative general approaches to personality de...",1996.0,34.0,176.0,False,,"{'volume': '48', 'pages': '86-92', 'name': 'Australian Journal of Psychology'}","{'bibtex': '@Article{Mehrabian1996AnalysisOT,\n author = {A. Mehrabian},\n journal = {Australian Journal of Psychology},\n pages = {86-92},\n title = {Analysis of the Big‐five Personality Factors in Terms of the PAD Temperament Model},\n volume = {48},\n year = {1996}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}]"
788,434e121afd0e189853775ea31cbab0396417739c,Extinction Learning in Humans Role of the Amygdala and vmPFC,,2004.0,35.0,1699.0,True,"{'url': 'http://www.cell.com/article/S0896627304005689/pdf', 'status': None}","{'volume': '43', 'pages': '897-905', 'name': 'Neuron'}","{'bibtex': '@Article{Phelps2004ExtinctionLI,\n author = {E. Phelps and M. Delgado and Katherine I. Nearing and Joseph E LeDoux},\n journal = {Neuron},\n pages = {897-905},\n title = {Extinction Learning in Humans Role of the Amygdala and vmPFC},\n volume = {43},\n year = {2004}\n}\n'}","[{'authorId': '2471431', 'name': 'E. Phelps'}, {'authorId': '144118279', 'name': 'M. Delgado'}, {'authorId': '5021619', 'name': 'Katherine I. Nearing'}, {'authorId': '2332694', 'name': 'Joseph E LeDoux'}]"
789,4364057f7c278a6067c807bca953a7a1587520e9,Well-being among older adults on different continents,"Old age represents a new frontier. The number of older people is increasing throughout the world. This changing demography affects individuals, but also families, communities and societies. The focus of this issue is the well–being of older adults on different continents. Scientists from around the world address this issue using a wide array of research designs and methodologies to provide a broad perspective on aging. Five topics are considered: Well–Being Among Older Adults; Social Support; Functional Status, Well–Being and Successful Aging; Cross–Cultural Approaches to the Study of Aging; and Research Perspectives in Aging. This issue clearly demonstrates that scientists have much to contribute to the goal of optimizing the experience of aging and creating a society for all ages.",2002.0,0.0,40.0,False,,"{'volume': '58', 'pages': '617-626', 'name': 'Journal of Social Issues'}","{'bibtex': '@Article{Antonucci2002WellbeingAO,\n author = {T. Antonucci and Corann Okorodudu and H. Akiyama},\n journal = {Journal of Social Issues},\n pages = {617-626},\n title = {Well-being among older adults on different continents},\n volume = {58},\n year = {2002}\n}\n'}","[{'authorId': '3765960', 'name': 'T. Antonucci'}, {'authorId': '118239350', 'name': 'Corann Okorodudu'}, {'authorId': '48495017', 'name': 'H. Akiyama'}]"
790,436833fa62ebde03b0dab25fe18f0e3609cc7f95,"When the social mirror breaks: deficits in automatic, but not voluntary, mimicry of emotional facial expressions in autism.","Humans, infants and adults alike, automatically mimic a variety of behaviors. Such mimicry facilitates social functioning, including establishment of interpersonal rapport and understanding of other minds. This fundamental social process may thus be impaired in disorders such as autism characterized by socio-emotional and communicative deficits. We examined automatic and voluntary mimicry of emotional facial expression among adolescents and adults with autistic spectrum disorders (ASD) and a typical sample matched on age, gender and verbal intelligence. Participants viewed pictures of happy and angry expressions while the activity over their cheek and brow muscle region was monitored with electromyography (EMG). ASD participants did not automatically mimic facial expressions whereas the typically developing participants did. However, both groups showed evidence of successful voluntary mimicry. The data suggest that autism is associated with an impairment of a basic automatic social-emotion process. Results have implications for understanding typical and atypical social cognition.",2006.0,60.0,485.0,False,,"{'volume': '9 3', 'pages': '\n          295-302\n        ', 'name': 'Developmental science'}","{'bibtex': '@Article{McIntosh2006WhenTS,\n author = {D. McIntosh and Aimee Reichmann-Decker and P. Winkielman and J. Wilbarger},\n journal = {Developmental science},\n pages = {\n          295-302\n        },\n title = {When the social mirror breaks: deficits in automatic, but not voluntary, mimicry of emotional facial expressions in autism.},\n volume = {9 3},\n year = {2006}\n}\n'}","[{'authorId': '21464189', 'name': 'D. McIntosh'}, {'authorId': '1403429333', 'name': 'Aimee Reichmann-Decker'}, {'authorId': '3122131', 'name': 'P. Winkielman'}, {'authorId': '5795843', 'name': 'J. Wilbarger'}]"
791,436b2f2a5c299224671aee48c0bcfc66351c9ee1,Inferring Capabilities of Intelligent Agents from Their External Traits,"We investigate the usability of humanlike agent-based interfaces for interactive advice-giving systems. In an experiment with a travel advisory system, we manipulate the “humanlikeness” of the agent interface. We demonstrate that users of the more humanlike agents try to exploit capabilities that were not signaled by the system. This severely reduces the usability of systems that look human but lack humanlikehumanlike capabilities (overestimation effect). We explain this effect by showing that users of humanlike agents form anthropomorphic beliefs (a user's “mental model”) about the system: They act humanlike towards the system and try to exploit typical humanlike capabilities they believe the system possesses. Furthermore, we demonstrate that the mental model users form of an agent-based system is inherently integrated (as opposed to the compositional mental model they form of conventional interfaces): Cues provided by the system do not instill user responses in a one-to-one matter but are instead integrated into a single mental model.",2016.0,86.0,66.0,False,,"{'volume': '6', 'pages': '1 - 25', 'name': 'ACM Transactions on Interactive Intelligent Systems (TiiS)'}","{'bibtex': '@Article{Knijnenburg2016InferringCO,\n author = {Bart P. Knijnenburg and M. Willemsen},\n journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},\n pages = {1 - 25},\n title = {Inferring Capabilities of Intelligent Agents from Their External Traits},\n volume = {6},\n year = {2016}\n}\n'}","[{'authorId': '2477993', 'name': 'Bart P. Knijnenburg'}, {'authorId': '1918235', 'name': 'M. Willemsen'}]"
792,43814f683616ff3db83488f73df44b01d2e67392,Computationally modeling human emotion,Computer models of emotion inform theories of human intelligence and advance human-centric applications.,2014.0,59.0,109.0,False,,"{'volume': '57', 'pages': '56-67', 'name': 'Commun. ACM'}","{'bibtex': '@Article{Marsella2014ComputationallyMH,\n author = {S. Marsella and J. Gratch},\n journal = {Commun. ACM},\n pages = {56-67},\n title = {Computationally modeling human emotion},\n volume = {57},\n year = {2014}\n}\n'}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
793,438ebea976185003c4ff0658a4313922aaf86154,Quick Quiz: A Gamified Approach for Enhancing Learning,"Gamification has the potential to improve the quality of learning by better engaging students with learning activities. Our objective in this study is to evaluate a gamified learning activity along the dimensions of learning, engagement, and enjoyment. The activity made use of a gamified multiple choice quiz implemented as a software tool and was trialled in three undergraduate IT-related courses. A questionnaire survey was used to collect data to gauge levels of learning, engagement, and enjoyment. Results show that there was some degree of engagement and enjoyment. The majority of participants (77.63 per cent) reported that they were engaged enough to want to complete the quiz and 46.05 per cent stated they were happy while playing the quiz. In terms of learning, the overall results were positive since 60.53 per cent of students stated that it enhanced their learning effectiveness. A limitation of the work is that the results are self-reported and the activity was used over a short period of time. Thus, future work should include longer trial periods and evaluating improvements to learning using alternative approaches to self-reported data.",2013.0,23.0,158.0,False,,{'pages': '206'},"{'bibtex': '@Inproceedings{Cheong2013QuickQA,\n author = {C. Cheong and F. Cheong and J. Filippou},\n pages = {206},\n title = {Quick Quiz: A Gamified Approach for Enhancing Learning},\n year = {2013}\n}\n'}","[{'authorId': '40177042', 'name': 'C. Cheong'}, {'authorId': '118251855', 'name': 'F. Cheong'}, {'authorId': '2224782', 'name': 'J. Filippou'}]"
794,43b51cd58a9c49b3da2c936e71496e817a4c59a7,Initial speaking distance as a function of the speakers’ relationship,,1966.0,6.0,188.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758%2FBF03328362.pdf', 'status': None}","{'volume': '5', 'pages': '221-222', 'name': 'Psychonomic Science'}","{'bibtex': '@Article{Willis1966InitialSD,\n author = {F. N. Willis},\n journal = {Psychonomic Science},\n pages = {221-222},\n title = {Initial speaking distance as a function of the speakers’ relationship},\n volume = {5},\n year = {1966}\n}\n'}","[{'authorId': '40515590', 'name': 'F. N. Willis'}]"
795,43d1bd95f891fb226e7f517ee2a46eebeded103d,The Art of Agent-Oriented Modeling,"Today, when computing is pervasive and deployed over a range of devices by a multiplicity of users, we need to develop computer software to interact with both the ever-increasing complexity of the technical world and the growing fluidity of social organizations. The Art of Agent-Oriented Modeling presents a new conceptual model for developing software systems that are open, intelligent, and adaptive. It describes an approach for modeling complex systems that consist of people, devices, and software agents in a changing environment (sometimes known as distributed sociotechnical systems). The authors take an agent-oriented view, as opposed to the more common object-oriented approach. Thinking in terms of agents (which they define as the human and man-made components of a system), they argue, can change the way people think of software and the tasks it can perform. The book offers an integrated and coherent set of concepts and models, presenting the models at three levels of abstraction corresponding to a motivation layer (where the purpose, goals, and requirements of the system are described), a design layer, and an implementation layer. It compares platforms by implementing the same models in four different languages; compares methodologies by using a common example; includes extensive case studies; and offers exercises suitable for either class use or independent study. Intelligent Robotics and Autonomous Agents series",2009.0,0.0,297.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sterling2009TheAO,\n author = {L. Sterling and K. Taveter},\n title = {The Art of Agent-Oriented Modeling},\n year = {2009}\n}\n'}","[{'authorId': '145977411', 'name': 'L. Sterling'}, {'authorId': '2478538', 'name': 'K. Taveter'}]"
796,43d6dd39bef33e3298f74933aa1d1a3cb00b363a,Increasing the expressiveness of virtual agents: autonomous generation of speech and gesture for spatial description tasks,"Embodied conversational agents are required to be able to express themselves convincingly and autonomously. Based on an empirial study on spatial descriptions of landmarks in direction-giving, we present a model that allows virtual agents to automatically generate, i.e., select the content and derive the form of coordinated language and iconic gestures. Our model simulates the interplay between these two modes of expressiveness on two levels. First, two kinds of knowledge representation (propositional and imagistic) are utilized to capture the modality-specific contents and processes of content planning. Second, specific planners are integrated to carry out the formulation of concrete verbal and gestural behavior. A probabilistic approach to gesture formulation is presented that incorporates multiple contextual factors as well as idiosyncratic patterns in the mapping of visuo-spatial referent properties onto gesture morphology. Results from a prototype implementation are described.",2009.0,22.0,61.0,False,,{'pages': '361-368'},"{'bibtex': '@Inproceedings{Bergmann2009IncreasingTE,\n author = {K. Bergmann and S. Kopp},\n pages = {361-368},\n title = {Increasing the expressiveness of virtual agents: autonomous generation of speech and gesture for spatial description tasks},\n year = {2009}\n}\n'}","[{'authorId': '2025591', 'name': 'K. Bergmann'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
798,43f772b01549ab4b6b4a6359be033b9c5ce0fd0c,Interactive Crowd-Behavior Learning for Surveillance and Training,"The proposed interactive crowd-behavior learning algorithms can be used to analyze crowd videos for surveillance and training applications. The authors' formulation combines online tracking algorithms from computer vision, nonlinear pedestrian motion models from computer graphics, and machine learning techniques to automatically compute trajectory-level pedestrian behaviors for each agent in the video. These learned behaviors are used to automatically detect anomalous behaviors, perform motion segmentation, and generate realistic behaviors for virtual reality training applications.",2016.0,19.0,13.0,False,,"{'volume': '36', 'pages': '37-45', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Bera2016InteractiveCL,\n author = {Aniket Bera and Sujeong Kim and Dinesh Manocha},\n journal = {IEEE Computer Graphics and Applications},\n pages = {37-45},\n title = {Interactive Crowd-Behavior Learning for Surveillance and Training},\n volume = {36},\n year = {2016}\n}\n'}","[{'authorId': '2718563', 'name': 'Aniket Bera'}, {'authorId': '52162164', 'name': 'Sujeong Kim'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
799,43fcd0ca9ddb52ac666c9881e72b020659ebfca0,You can do that?!: Feasibility of virtual reality exposure therapy in the treatment of PTSD due to military sexual trauma.,,2019.0,52.0,74.0,True,"{'url': 'http://manuscript.elsevier.com/S0887618517304991/pdf/S0887618517304991.pdf', 'status': None}","{'volume': '61', 'pages': '\n          55-63\n        ', 'name': 'Journal of anxiety disorders'}","{'bibtex': '@Article{Loucks2019YouCD,\n author = {Laura Loucks and Carly W Yasinski and S. Norrholm and J. Maples-Keller and L. Post and Liza C Zwiebach and Devika Fiorillo and Megan Goodlin and T. Jovanović and A. Rizzo and B. Rothbaum},\n journal = {Journal of anxiety disorders},\n pages = {\n          55-63\n        },\n title = {You can do that?!: Feasibility of virtual reality exposure therapy in the treatment of PTSD due to military sexual trauma.},\n volume = {61},\n year = {2019}\n}\n'}","[{'authorId': '51068804', 'name': 'Laura Loucks'}, {'authorId': '3871408', 'name': 'Carly W Yasinski'}, {'authorId': '4786216', 'name': 'S. Norrholm'}, {'authorId': '1402540811', 'name': 'J. Maples-Keller'}, {'authorId': '5687182', 'name': 'L. Post'}, {'authorId': '7393790', 'name': 'Liza C Zwiebach'}, {'authorId': '14106480', 'name': 'Devika Fiorillo'}, {'authorId': '51068246', 'name': 'Megan Goodlin'}, {'authorId': '2770002', 'name': 'T. Jovanović'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '1831766', 'name': 'B. Rothbaum'}]"
801,440c81e2159149c33cf82b843cfd79d323c92de5,MAUI: a multimodal affective user interface,"Human intelligence is being increasingly redefined to include the all-encompassing effect of emotions upon what used to be considered 'pure reason'. With the recent progress of research in computer vision, speech/prosody recognition, and bio-feedback, real-time recognition of affect will enhance human-computer interaction considerably, as well as assist further progress in the development of new emotion theories.In this article, we describe how affect, moods and emotions closely interact with cognition and how affect and emotion are the quintessential multimodal processes in humans. We then propose an adaptive system architecture designed to sense the user's emotional and affective states via three multimodal subsystems (V, K, A): namely (1) the Visual (from facial images and videos), (2) Kinesthetic (from autonomic nervous system (ANS) signals), and (3) Auditory (from speech). The results of the system sensing are then integrated into the multimodal perceived multimodal anthropomorphic interface agent then adapts its interface by responding most appropriately to the current emotional states of its user, and provides intelligent multi-modal feedback to the user.",2002.0,51.0,123.0,False,,{'pages': '161-170'},"{'bibtex': '@Inproceedings{Lisetti2002MAUIAM,\n author = {Christine L. Lisetti and Fatma Nasoz},\n pages = {161-170},\n title = {MAUI: a multimodal affective user interface},\n year = {2002}\n}\n'}","[{'authorId': '143607713', 'name': 'Christine L. Lisetti'}, {'authorId': '2107729', 'name': 'Fatma Nasoz'}]"
802,4419303eb2f5a6f647ece642f2fa2f707761e971,Robot and virtual reality-based intervention in autism: a comprehensive review,,2021.0,80.0,10.0,False,,"{'volume': '13', 'pages': '1879 - 1891', 'name': 'International Journal of Information Technology'}","{'bibtex': '@Article{Abu-Amara2021RobotAV,\n author = {F. Abu-Amara and A. Bensefia and Heba Mohammad and Hatem Tamimi},\n journal = {International Journal of Information Technology},\n pages = {1879 - 1891},\n title = {Robot and virtual reality-based intervention in autism: a comprehensive review},\n volume = {13},\n year = {2021}\n}\n'}","[{'authorId': '1410432206', 'name': 'F. Abu-Amara'}, {'authorId': '2390354', 'name': 'A. Bensefia'}, {'authorId': '2057202670', 'name': 'Heba Mohammad'}, {'authorId': '26960052', 'name': 'Hatem Tamimi'}]"
803,443136202ddf2b5a8fc95ba8eacfa2dc1274c22d,Emotion regulation in autism spectrum disorder: evidence from parent interviews and children's daily diaries.,"BACKGROUND
Although emotion dysregulation is not a defining feature of Autism Spectrum Disorder (ASD), there is a growing consensus that emotional problems play a prominent role in this disorder.


METHODS
The present study examined a wide range of emotion regulation (ER) strategies in 32 individuals with ASD compared to 31 group-matched typically developing (TD) participants in three emotional domains (anger, anxiety, and amusement). Parents of individuals with ASD and TD individuals were interviewed about their child's emotional experience and the use and efficacy of 10 ER strategies. In addition, participants filled out daily diaries on experience and regulation in the same emotional domains.


RESULTS
Compared to TD individuals, parents reported that individuals with ASD experienced more anger and anxiety and less amusement, made less frequent use of a variety of adaptive ER strategies (e.g. problem solving, cognitive reappraisal), and made more frequent use of maladaptive strategies (e.g. repetitive behavior). Moreover, individuals with ASD were less effective at utilizing adaptive ER strategies. Self-reports showed differences in experience of amusement and in ER strategies for anger and anxiety, but not in experience of anger and anxiety.


CONCLUSIONS
This study provides evidence that individuals with ASD less frequently use adaptive - but more frequently use maladaptive - ER strategies. Implications for ASD treatments that focus on increasing the use of adaptive strategies are discussed.",2015.0,45.0,84.0,False,,"{'volume': '56 8', 'pages': '\n          903-13\n        ', 'name': 'Journal of child psychology and psychiatry, and allied disciplines'}","{'bibtex': ""@Article{Samson2015EmotionRI,\n author = {Andrea C. Samson and W. Wells and Jennifer M. Phillips and A. Hardan and J. Gross},\n journal = {Journal of child psychology and psychiatry, and allied disciplines},\n pages = {\n          903-13\n        },\n title = {Emotion regulation in autism spectrum disorder: evidence from parent interviews and children's daily diaries.},\n volume = {56 8},\n year = {2015}\n}\n""}","[{'authorId': '38707445', 'name': 'Andrea C. Samson'}, {'authorId': '33448033', 'name': 'W. Wells'}, {'authorId': '2536136', 'name': 'Jennifer M. Phillips'}, {'authorId': '6760287', 'name': 'A. Hardan'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
805,443f871d8c4b4569032337c48d4d4a34bcc33762,Examining nonverbal shame markers among post-pregnancy women with maltreatment histories,,2011.0,0.0,11.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Menke2011ExaminingNS,\n author = {Rena A. Menke},\n title = {Examining nonverbal shame markers among post-pregnancy women with maltreatment histories},\n year = {2011}\n}\n'}","[{'authorId': '32982720', 'name': 'Rena A. Menke'}]"
806,444e1be1d52cb1231051d6213a0f8f0a04a50fdd,Automatic apex frame spotting in micro-expression database,"Micro-expression usually occurs at high-stakes situations and may provide useful information in the field of behavioral psychology for better interpretion and analysis. Unfortunately, it is technically challenging to detect and recognize micro-expressions due to its brief duration and the subtle facial distortions. Apex frame, which is the instant indicating the most expressive emotional state in a video, is effective to classify the emotion in that particular frame. In this work, we present a novel method to spot the apex frame of a spontaneous micro-expression video sequence. A binary search approach is employed to locate the index of the frame in which the peak facial changes occur. Features from specific facial regions are extracted to better represent and describe the expression details. The defined facial regions are selected based on the action unit and landmark coordinates of the subject, in which case these processes are automated. We consider three distinct feature descriptors to evaluate the reliability of the proposed approach. Improvements of at least 20% are achieved when compared to the baselines.",2015.0,16.0,76.0,False,,"{'pages': '665-669', 'name': '2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)'}","{'bibtex': '@Article{Liong2015AutomaticAF,\n author = {Sze‐Teng Liong and John See and Koksheik Wong and A. Ngo and Yee-Hui Oh and R. Phan},\n journal = {2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)},\n pages = {665-669},\n title = {Automatic apex frame spotting in micro-expression database},\n year = {2015}\n}\n'}","[{'authorId': '39888137', 'name': 'Sze‐Teng Liong'}, {'authorId': '143937986', 'name': 'John See'}, {'authorId': '1713159', 'name': 'Koksheik Wong'}, {'authorId': '35256518', 'name': 'A. Ngo'}, {'authorId': '2154760', 'name': 'Yee-Hui Oh'}, {'authorId': '145016295', 'name': 'R. Phan'}]"
807,44509e21527ef0e70c7d4d0603a631ae319e2451,Toward a Theory of Empathic Arousal and Development,,1978.0,52.0,76.0,False,,"{'volume': '', 'pages': '227-256', 'name': ''}","{'bibtex': '@Inproceedings{Hoffman1978TowardAT,\n author = {M. Hoffman},\n pages = {227-256},\n title = {Toward a Theory of Empathic Arousal and Development},\n year = {1978}\n}\n'}","[{'authorId': '82128751', 'name': 'M. Hoffman'}]"
808,4463302e706e8547a549ac6a401de0cf1cf0cb20,Social relationships and health.,"The author discusses 3 variables that assess different aspects of social relationships—social support, social integration, and negative interaction. The author argues that all 3 are associated with health outcomes, that these variables each influence health through different mechanisms, and that associations between these variables and health are not spurious findings attributable to our personalities. This argument suggests a broader view of how to intervene in social networks to improve health. This includes facilitating both social integration and social support by creating and nurturing both close (strong) and peripheral (weak) ties within natural social networks and reducing opportunities for negative social interaction. Finally, the author emphasizes the necessity to understand more about who benefits most and least from socialconnectedness interventions.",2004.0,39.0,2369.0,False,,"{'volume': '59 8', 'pages': '\n          676-684\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Cohen2004SocialRA,\n author = {Sheldon Cohen},\n journal = {The American psychologist},\n pages = {\n          676-684\n        },\n title = {Social relationships and health.},\n volume = {59 8},\n year = {2004}\n}\n'}","[{'authorId': '145708972', 'name': 'Sheldon Cohen'}]"
809,446d4b669654ab35dea35cf885d10e580e9d2e48,The Consortium for the early identification of Alzheimer's disease–Quebec (CIMA-Q),,2019.0,48.0,22.0,True,,"{'volume': '11', 'pages': '787 - 796', 'name': ""Alzheimer's & Dementia : Diagnosis, Assessment & Disease Monitoring""}","{'bibtex': ""@Article{Belleville2019TheCF,\n author = {S. Belleville and A. LeBlanc and M. Kergoat and F. Calon and P. Gaudreau and Sébastien S. Hébert and C. Hudon and N. Leclerc and N. Mechawar and S. Duchesne and S. Gauthier and Pierre Sylvie Christian Frédéric Howard Louis Stephen Sim Bellec Belleville Bocti Calon Chertkow Collins Cun and Pierre Bellec and S. Belleville and C. Bocti and F. Calon and H. Chertkow and L. Collins and S. Cunnane and S. Duchesne and P. Gaudreau and S. Gauthier and Sébastien S. Hébert and Carol Hudon Marie-Jeanne-Kergoat and A. LeBlanc and N. Leclerc and N. Mechawar and Natalie Philips and J. Soucy and T. T. Dang Vu and L. Verret and J. Villalpando},\n journal = {Alzheimer's & Dementia : Diagnosis, Assessment & Disease Monitoring},\n pages = {787 - 796},\n title = {The Consortium for the early identification of Alzheimer's disease–Quebec (CIMA-Q)},\n volume = {11},\n year = {2019}\n}\n""}","[{'authorId': '145580293', 'name': 'S. Belleville'}, {'authorId': '4862602', 'name': 'A. LeBlanc'}, {'authorId': '144549746', 'name': 'M. Kergoat'}, {'authorId': '3922173', 'name': 'F. Calon'}, {'authorId': '144992181', 'name': 'P. Gaudreau'}, {'authorId': '5540255', 'name': 'Sébastien S. Hébert'}, {'authorId': '9164412', 'name': 'C. Hudon'}, {'authorId': '2090038348', 'name': 'N. Leclerc'}, {'authorId': '4984276', 'name': 'N. Mechawar'}, {'authorId': '2873793', 'name': 'S. Duchesne'}, {'authorId': '2059389436', 'name': 'S. Gauthier'}, {'authorId': None, 'name': 'Pierre Sylvie Christian Frédéric Howard Louis Stephen Sim Bellec Belleville Bocti Calon Chertkow Collins Cun'}, {'authorId': '2943011', 'name': 'Pierre Bellec'}, {'authorId': '145580293', 'name': 'S. Belleville'}, {'authorId': '47456475', 'name': 'C. Bocti'}, {'authorId': '3922173', 'name': 'F. Calon'}, {'authorId': '114187679', 'name': 'H. Chertkow'}, {'authorId': '123435565', 'name': 'L. Collins'}, {'authorId': '2193740444', 'name': 'S. Cunnane'}, {'authorId': '2873793', 'name': 'S. Duchesne'}, {'authorId': '144992181', 'name': 'P. Gaudreau'}, {'authorId': '2059389436', 'name': 'S. Gauthier'}, {'authorId': '5540255', 'name': 'Sébastien S. Hébert'}, {'authorId': '2185658429', 'name': 'Carol Hudon Marie-Jeanne-Kergoat'}, {'authorId': '4862602', 'name': 'A. LeBlanc'}, {'authorId': '2090038348', 'name': 'N. Leclerc'}, {'authorId': '4984276', 'name': 'N. Mechawar'}, {'authorId': '1392498620', 'name': 'Natalie Philips'}, {'authorId': '145318694', 'name': 'J. Soucy'}, {'authorId': '1737522062', 'name': 'T. T. Dang Vu'}, {'authorId': '39110343', 'name': 'L. Verret'}, {'authorId': '7580946', 'name': 'J. Villalpando'}]"
810,44752d423353ca5fcaf9123a9e71f98921ada266,AFFECTIVE COMPUTING,"- Some machine should interpret the emotional state of humans beings or human and adapt its behaviour to them, giving an appropriate response for the emotions. Affective computing is the study and development of systems and devices which could or can recognize, interpret, process, and simulate human affects. Affective computing is human-computer interaction where the device has the ability to detect and appropriately respond to its user's emotions and other stimuli. It is an interdisciplinary field spanning computer science, psychology, and cognitive science. A motivation is the ability to simulate empathy.",2015.0,29.0,4783.0,False,,,"{'bibtex': '@Inproceedings{Picard2015AFFECTIVEC,\n author = {Rosalind W. Picard},\n title = {AFFECTIVE COMPUTING},\n year = {2015}\n}\n'}","[{'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
813,4478d467ea7ccca581e29ec51ced90373e90e364,A machine translation system from English to American Sign Language,,2000.0,34.0,189.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/efca3f6c-3825-44bb-b140-b8392eed756c/download', 'status': None}",{'pages': '54-67'},"{'bibtex': '@Inproceedings{Zhao2000AMT,\n author = {Liwei Zhao and K. Schuler and William Schuler and Christian Vogler and N. Badler and Martha Palmer},\n pages = {54-67},\n title = {A machine translation system from English to American Sign Language},\n year = {2000}\n}\n'}","[{'authorId': '2427954', 'name': 'Liwei Zhao'}, {'authorId': '2135004', 'name': 'K. Schuler'}, {'authorId': '1747648', 'name': 'William Schuler'}, {'authorId': '2467082', 'name': 'Christian Vogler'}, {'authorId': '1699200', 'name': 'N. Badler'}, {'authorId': '145755155', 'name': 'Martha Palmer'}]"
814,44b35318ded38fba380de265aa66e0ac307d19ac,Language use of depressed and depression-vulnerable college students,"Essays written by currently-depressed, formerly-depressed, and never-depressed college students were examined for differences in language that might shed light on the cognitive operations associated with depression and depression-vulnerability. A text analysis program computed the incidence of words in predesignated categories. Consistent with Beck's cognitive model and with Pyczsinski and Greenberg's self-focus model of depression, depressed participants used more negatively valenced words and used the word, ""I"" more than did never-depressed participants. Formerly-depressed (presumably depression-vulnerable) participants did not differ from never-depressed participants on these indices of depressive processing. However, consistent with prediction, formerly-depressed participants' use of the word ""I"" increased across the essays and was significantly greater than that of never-depressed writers in the final portion of the essays.",2004.0,33.0,878.0,False,,"{'volume': '18', 'pages': '1121 - 1133', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Rude2004LanguageUO,\n author = {Stephanie Rude and Eva-Maria Gortner and James Pennebaker},\n journal = {Cognition and Emotion},\n pages = {1121 - 1133},\n title = {Language use of depressed and depression-vulnerable college students},\n volume = {18},\n year = {2004}\n}\n'}","[{'authorId': '2244916451', 'name': 'Stephanie Rude'}, {'authorId': '48294156', 'name': 'Eva-Maria Gortner'}, {'authorId': '2244916477', 'name': 'James Pennebaker'}]"
815,44f298351d262ab3a3d3f4040f90682dca0e0ec6,‘Emotiplay’: a serious game for learning about emotions in children with autism: results of a cross-cultural evaluation,,2017.0,81.0,91.0,False,,"{'volume': '26', 'pages': '979-992', 'name': 'European Child & Adolescent Psychiatry'}","{'bibtex': ""@Article{Fridenson-Hayo2017EmotiplayAS,\n author = {Shimrit Fridenson-Hayo and S. Berggren and Amandine Lassalle and Shahar Tal and Delia Pigat and N. Meir-Goren and Helen O'Reilly and S. Ben-Zur and S. Bölte and S. Baron-Cohen and O. Golan},\n journal = {European Child & Adolescent Psychiatry},\n pages = {979-992},\n title = {‘Emotiplay’: a serious game for learning about emotions in children with autism: results of a cross-cultural evaluation},\n volume = {26},\n year = {2017}\n}\n""}","[{'authorId': '1398348823', 'name': 'Shimrit Fridenson-Hayo'}, {'authorId': '40595864', 'name': 'S. Berggren'}, {'authorId': '6502953', 'name': 'Amandine Lassalle'}, {'authorId': '2391819', 'name': 'Shahar Tal'}, {'authorId': '2625704', 'name': 'Delia Pigat'}, {'authorId': '1398348866', 'name': 'N. Meir-Goren'}, {'authorId': '2085299554', 'name': ""Helen O'Reilly""}, {'authorId': '1398348812', 'name': 'S. Ben-Zur'}, {'authorId': '1804720', 'name': 'S. Bölte'}, {'authorId': '2202501491', 'name': 'S. Baron-Cohen'}, {'authorId': '2100443', 'name': 'O. Golan'}]"
816,45018ea1121bee5bb7c6e236edc687701220b2c7,Research of emotion modeling for intelligent virtual agent,"To make the intelligent virtual agent become more natural and believable, giving her emotion ability is very important. According to Basic Emotion Theory and Cognitive Evaluation Theory in Psychology, it proposes an emotion model based on Fuzzy Rules. Firstly, emotion factor is generated according to the emotion elicited rules based on Fuzzy IF-THEN rules. Then a nonlinear function restricted by personality, emotion factor and emotion state at the previous moment was used to compute emotion strength. The simulation result shows, this model can simulate the fuzzy and nonlinear characteristic of human emotion to a certain extent.",2010.0,12.0,2.0,False,,"{'name': '2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)', 'pages': '286-289', 'volume': '2'}","{'bibtex': '@Conference{Lin2010ResearchOE,\n author = {Shi Lin and Li Zhigang and Ding Aihua},\n booktitle = {International Conference on Computer and Automation Engineering},\n journal = {2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)},\n pages = {286-289},\n title = {Research of emotion modeling for intelligent virtual agent},\n volume = {2},\n year = {2010}\n}\n'}","[{'authorId': '2108833763', 'name': 'Shi Lin'}, {'authorId': '46644542', 'name': 'Li Zhigang'}, {'authorId': '31161618', 'name': 'Ding Aihua'}]"
817,451888efc54933010dafe44e3226f766336cff9e,Mixed Reality: A Survey,,2009.0,66.0,87.0,True,"{'url': 'https://www.research-collection.ethz.ch/bitstream/20.500.11850/15325/1/eth-41730-01.pdf', 'status': None}",{'pages': '47-68'},"{'bibtex': '@Inproceedings{Costanza2009MixedRA,\n author = {Enrico Costanza and A. Kunz and M. Fjeld},\n pages = {47-68},\n title = {Mixed Reality: A Survey},\n year = {2009}\n}\n'}","[{'authorId': '2780886', 'name': 'Enrico Costanza'}, {'authorId': '143717147', 'name': 'A. Kunz'}, {'authorId': '1685537', 'name': 'M. Fjeld'}]"
818,451d6f9b4be8a478cf177b228dd06f65cabbd530,Evaluation of Four Designed Virtual Agent Personalities,"Convincing conversational agents require a coherent set of behavioral responses that can be interpreted by a human observer as indicative of a personality. This paper discusses the continued development and subsequent evaluation of virtual agents based on sound psychological principles. We use Eysenck's theoretical basis to explain aspects of the characterization of our agents, and we describe an architecture where personality affects the agent's global behavior quality as well as their back-channel productions. Drawing on psychological research, we evaluate perception of our agents' personalities and credibility by human viewers (N = 187). Our results suggest that we succeeded in validating theoretically grounded indicators of personality in our virtual agents, and that it is feasible to place our characters on Eysenck's scales. A key finding is that the presence of behavioral characteristics reinforces the prescribed personality profiles that are already emerging from the still images. Our long-term goal is to enhance agents' ability to sustain realistic interaction with human users, and we discuss how this preliminary work may be further developed to include more systematic variation of Eysenck's personality scales.",2012.0,64.0,58.0,True,"{'url': 'https://pureadmin.qub.ac.uk/ws/files/1710496/Affective_Computing_IEEE_Transactions_on_DOI_10.1109T_AFFC.2010.6_2011_McRorie.pdf', 'status': None}","{'volume': '3', 'pages': '311-322', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{McRorie2012EvaluationOF,\n author = {Margaret McRorie and I. Sneddon and G. McKeown and Elisabetta Bevacqua and E. D. Sevin and C. Pelachaud},\n journal = {IEEE Transactions on Affective Computing},\n pages = {311-322},\n title = {Evaluation of Four Designed Virtual Agent Personalities},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '2314861', 'name': 'Margaret McRorie'}, {'authorId': '145688200', 'name': 'I. Sneddon'}, {'authorId': '2228246', 'name': 'G. McKeown'}, {'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '1761859', 'name': 'E. D. Sevin'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
819,4550e5fb37a6b0198be6c4f266e3e9b9aecc8a89,Adding Communicative and Affective Strategies to an Embodied Conversational Agent to Enhance Second Language Learners’ Willingness to Communicate,,2018.0,73.0,41.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2Fs40593-018-0171-6.pdf', 'status': None}","{'volume': '29', 'pages': '29-57', 'name': 'International Journal of Artificial Intelligence in Education'}","{'bibtex': '@Article{Ayedoun2018AddingCA,\n author = {Emmanuel Ayedoun and Yuki Hayashi and Kazuhisa Seta},\n journal = {International Journal of Artificial Intelligence in Education},\n pages = {29-57},\n title = {Adding Communicative and Affective Strategies to an Embodied Conversational Agent to Enhance Second Language Learners’ Willingness to Communicate},\n volume = {29},\n year = {2018}\n}\n'}","[{'authorId': '3350062', 'name': 'Emmanuel Ayedoun'}, {'authorId': '145494830', 'name': 'Yuki Hayashi'}, {'authorId': '35658486', 'name': 'Kazuhisa Seta'}]"
820,45a974e5740c6464d225746ec0700134da90310a,Theory of Mind and Empathy as Multidimensional Constructs: Neurological Foundations,"Empathy describes an individual's ability to understand and feel the other. In this article, we review recent theoretical approaches to the study of empathy. Recent evidence supports 2 possible empathy systems: an emotional system and a cognitive system. These processes are served by separate, albeit interacting, brain networks. When a cognitive empathic response is generated, the theory of mind (ToM) network (i.e., medial prefrontal cortex, superior temporal sulcus, temporal poles) and the affective ToM network (mainly involving the ventromedial prefrontal cortex) are typically involved. In contrast, the emotional empathic response is driven mainly by simulation and involves regions that mediate emotional experiences (i.e., amygdala, insula). A decreased empathic response may be due to deficits in mentalizing (cognitive ToM, affective ToM) or in simulation processing (emotional empathy), with these deficits mediated by different neural systems. It is proposed that a balanced activation of these 2 networks is required for appropriate social behavior.",2014.0,99.0,167.0,False,,"{'volume': '34', 'pages': '282–295', 'name': 'Topics in Language Disorders'}","{'bibtex': '@Article{Dvash2014TheoryOM,\n author = {Jonathan Dvash and S. Shamay-Tsoory},\n journal = {Topics in Language Disorders},\n pages = {282–295},\n title = {Theory of Mind and Empathy as Multidimensional Constructs: Neurological Foundations},\n volume = {34},\n year = {2014}\n}\n'}","[{'authorId': '5303069', 'name': 'Jonathan Dvash'}, {'authorId': '1397560295', 'name': 'S. Shamay-Tsoory'}]"
821,45c842da3c9115f38c9cd5243bb43279ae6dd6e8,Listener Responses as a Collaborative Process: The Role of Gaze,"The authors examined precisely when and how listeners insert their responses into a speaker's narrative. A collaborative theory would predict a relationship between the speaker's acts and the listener's responses, and the authors proposed that speaker gaze coordinated this collaboration. The listener typically looks more at the speaker than the reverse, but at key points while speaking the speaker seeks a response by looking at the listener, creating a brief period of mutual gaze called here a gaze window. The listener was very likely to respond with “mhm,” a nod, or other reaction during this period, after which the speaker quickly looked away and continued speaking. This model was tested with 9 dyads in which 1 person was telling a close-call story to the other. The results confirmed the model for each dyad, demonstrating both collaboration in dialogue at the microlevel and a high degree of integration and coordination of audible and visible acts, in this case, speech and gaze.",2002.0,27.0,425.0,False,,"{'volume': '52', 'pages': '566-580', 'name': 'Journal of Communication'}","{'bibtex': '@Article{Bavelas2002ListenerRA,\n author = {J. Bavelas and Linda Coates and Trudy Johnson},\n journal = {Journal of Communication},\n pages = {566-580},\n title = {Listener Responses as a Collaborative Process: The Role of Gaze},\n volume = {52},\n year = {2002}\n}\n'}","[{'authorId': '2816755', 'name': 'J. Bavelas'}, {'authorId': '143892343', 'name': 'Linda Coates'}, {'authorId': '2114152350', 'name': 'Trudy Johnson'}]"
822,45d5eb95969bd3965b3dac7c92dbba12a5e14659,Flexible String Matching Against Large Databases in Practice,,2004.0,4.0,123.0,True,"{'url': 'http://www.vldb.org/conf/2004/IND3P3.PDF', 'status': None}",{'pages': '1078-1086'},"{'bibtex': '@Inproceedings{Koudas2004FlexibleSM,\n author = {Nick Koudas and A. Marathe and D. Srivastava},\n pages = {1078-1086},\n title = {Flexible String Matching Against Large Databases in Practice},\n year = {2004}\n}\n'}","[{'authorId': '1721062', 'name': 'Nick Koudas'}, {'authorId': '2440762', 'name': 'A. Marathe'}, {'authorId': '145860176', 'name': 'D. Srivastava'}]"
823,45d7333daf44b2cf80f91b07e06ad6c70e3e9aab,Facial Action Coding,,2009.0,0.0,90.0,False,,{'pages': '400'},"{'bibtex': '@Inproceedings{Gu2009FacialAC,\n author = {Leon Gu and T. Kanade and D. Gorodnichy and Ming-Hsuan Yang and M. Tistarelli and P. Grother and Elham Tabassi and S. Shan and Xilin Chen and Wen Gao and I. Patras and I. Kakadiaris and G. Passalis and G. Toderici and Takis Perakis and T. Theoharis and Onur C. Hamsici and Aleix M. Martinez and Lior Wolf and Stan Z. Li and Dong Yi and G. Bebis and R. Chellappa and G. Aggarwal and S. K. Zhou and K. Jia and S. Gong and Sami Romdhani Jasenko Zivanov and A. Roy-Chowdhury and Yilei Xu and C. Castillo and D. Jacobs and Michael C. Bromby and M. Pantic and R. Sánchez-Reillo and Robert Mueller and S. Malassiotis and Hisao Ogata Mitsutoshi Himaga and M. Himaga and Xudong Jiang and N. Allinson and F. Alonso-Fernandez and Julian Fierrez and Jean-François Mainguet and J. Bigun and M. Hara and Jie Tian and Yangyang Zhang and Kai Cao and H. Bergman and A. Zeelenberg and D. Maltoni and R. Cappelli and W. Yau and D. Meuwly and Geppy Parziale and Ruben Vera Rodriguez and N. Evans and J. Mason and M. Pavlou and C. Champod and B. Yamashita and R. B. Kennedy and T. Hicks and R. Coquoz and Victor Minchih Lee and L. Osadciw and K. Veeramachaneni and A. Ross and N. Poh and Ajay Kumar and Karthik Nandakumar and A. Noore and Richa Singh and Mayank Vasta and J. Ortega-Garcia},\n pages = {400},\n title = {Facial Action Coding},\n year = {2009}\n}\n'}","[{'authorId': '2164904', 'name': 'Leon Gu'}, {'authorId': '1733113', 'name': 'T. Kanade'}, {'authorId': '1752832', 'name': 'D. Gorodnichy'}, {'authorId': '37144787', 'name': 'Ming-Hsuan Yang'}, {'authorId': '1725688', 'name': 'M. Tistarelli'}, {'authorId': '2136478', 'name': 'P. Grother'}, {'authorId': '2326261', 'name': 'Elham Tabassi'}, {'authorId': '145455919', 'name': 'S. Shan'}, {'authorId': '46772547', 'name': 'Xilin Chen'}, {'authorId': '37110739', 'name': 'Wen Gao'}, {'authorId': '50058816', 'name': 'I. Patras'}, {'authorId': '1389595099', 'name': 'I. Kakadiaris'}, {'authorId': '1995903', 'name': 'G. Passalis'}, {'authorId': '1805076', 'name': 'G. Toderici'}, {'authorId': '1922974', 'name': 'Takis Perakis'}, {'authorId': '1691888', 'name': 'T. Theoharis'}, {'authorId': '1872879', 'name': 'Onur C. Hamsici'}, {'authorId': '1384255355', 'name': 'Aleix M. Martinez'}, {'authorId': '48519520', 'name': 'Lior Wolf'}, {'authorId': '1390908654', 'name': 'Stan Z. Li'}, {'authorId': '1391030060', 'name': 'Dong Yi'}, {'authorId': '1808451', 'name': 'G. Bebis'}, {'authorId': '9215658', 'name': 'R. Chellappa'}, {'authorId': '145540688', 'name': 'G. Aggarwal'}, {'authorId': '2219251984', 'name': 'S. K. Zhou'}, {'authorId': '2370507', 'name': 'K. Jia'}, {'authorId': '144784813', 'name': 'S. Gong'}, {'authorId': '1394325436', 'name': 'Sami Romdhani Jasenko Zivanov'}, {'authorId': '1404727582', 'name': 'A. Roy-Chowdhury'}, {'authorId': '3044430', 'name': 'Yilei Xu'}, {'authorId': '145586343', 'name': 'C. Castillo'}, {'authorId': '34734622', 'name': 'D. Jacobs'}, {'authorId': '1763129', 'name': 'Michael C. Bromby'}, {'authorId': '145387780', 'name': 'M. Pantic'}, {'authorId': '1398678008', 'name': 'R. Sánchez-Reillo'}, {'authorId': '144228198', 'name': 'Robert Mueller'}, {'authorId': '1744180', 'name': 'S. Malassiotis'}, {'authorId': '1394325413', 'name': 'Hisao Ogata Mitsutoshi Himaga'}, {'authorId': '3142558', 'name': 'M. Himaga'}, {'authorId': '3307580', 'name': 'Xudong Jiang'}, {'authorId': '50729465', 'name': 'N. Allinson'}, {'authorId': '83074055', 'name': 'F. Alonso-Fernandez'}, {'authorId': '1701431', 'name': 'Julian Fierrez'}, {'authorId': '2320083', 'name': 'Jean-François Mainguet'}, {'authorId': '5058247', 'name': 'J. Bigun'}, {'authorId': '31803652', 'name': 'M. Hara'}, {'authorId': '145883434', 'name': 'Jie Tian'}, {'authorId': '1591117336', 'name': 'Yangyang Zhang'}, {'authorId': '39758810', 'name': 'Kai Cao'}, {'authorId': '30929649', 'name': 'H. Bergman'}, {'authorId': '2999901', 'name': 'A. Zeelenberg'}, {'authorId': '1687735', 'name': 'D. Maltoni'}, {'authorId': '34592319', 'name': 'R. Cappelli'}, {'authorId': '145492070', 'name': 'W. Yau'}, {'authorId': '3143556', 'name': 'D. Meuwly'}, {'authorId': '31523399', 'name': 'Geppy Parziale'}, {'authorId': '1382543677', 'name': 'Ruben Vera Rodriguez'}, {'authorId': '37860402', 'name': 'N. Evans'}, {'authorId': '1715733', 'name': 'J. Mason'}, {'authorId': '48296309', 'name': 'M. Pavlou'}, {'authorId': '2274216', 'name': 'C. Champod'}, {'authorId': '1394325387', 'name': 'B. Yamashita'}, {'authorId': '48336405', 'name': 'R. B. Kennedy'}, {'authorId': '152575474', 'name': 'T. Hicks'}, {'authorId': '49584132', 'name': 'R. Coquoz'}, {'authorId': '1380778493', 'name': 'Victor Minchih Lee'}, {'authorId': '2598035', 'name': 'L. Osadciw'}, {'authorId': '1803567', 'name': 'K. Veeramachaneni'}, {'authorId': '145743106', 'name': 'A. Ross'}, {'authorId': '2404207', 'name': 'N. Poh'}, {'authorId': '2109186465', 'name': 'Ajay Kumar'}, {'authorId': '34633765', 'name': 'Karthik Nandakumar'}, {'authorId': '2487227', 'name': 'A. Noore'}, {'authorId': '2041134713', 'name': 'Richa Singh'}, {'authorId': '1388376926', 'name': 'Mayank Vasta'}, {'authorId': '1397258551', 'name': 'J. Ortega-Garcia'}]"
824,45e6fbad2cbe3ee72afaed0ce1669681582a0479,"Fear, Trauma, and Posttraumatic Stress Disorder: Clinical, Neurobiological, and Cultural Perspectives",,2016.0,33.0,5.0,False,,"{'volume': '', 'pages': '303-313', 'name': ''}","{'bibtex': '@Inproceedings{Rubin2016FearTA,\n author = {Mikael Rubin and Maya Neria and Y. Neria},\n pages = {303-313},\n title = {Fear, Trauma, and Posttraumatic Stress Disorder: Clinical, Neurobiological, and Cultural Perspectives},\n year = {2016}\n}\n'}","[{'authorId': '5420662', 'name': 'Mikael Rubin'}, {'authorId': '119117443', 'name': 'Maya Neria'}, {'authorId': '4858881', 'name': 'Y. Neria'}]"
825,45e8135ee43703d395b61082b80e1b4699248b98,Immersion in Virtual Reality Can Increase Exercise Motivation and Physical Performance,,2018.0,26.0,33.0,False,,{'pages': '94-102'},"{'bibtex': '@Inproceedings{Kim2018ImmersionIV,\n author = {Gyoung Kim and F. Biocca},\n pages = {94-102},\n title = {Immersion in Virtual Reality Can Increase Exercise Motivation and Physical Performance},\n year = {2018}\n}\n'}","[{'authorId': '143628295', 'name': 'Gyoung Kim'}, {'authorId': '1726689', 'name': 'F. Biocca'}]"
826,4607cc32250a1a7f638b2d6e25e8026b32054906,GenieTutor: A Computer-Assisted Second-Language Learning System Based on Spoken Language Understanding,,2015.0,5.0,15.0,False,,{'pages': '257-262'},"{'bibtex': '@Inproceedings{Kwon2015GenieTutorAC,\n author = {Oh-Woog Kwon and Ki-Young Lee and Yoon-Hyung Roh and Jin-Xia Huang and Sung-Kwon Choi and Y. K. Kim and Hyung-Bae Jeon and Y. Oh and Yun-Kyung Lee and B. Kang and Euisok Chung and J. Park and Yun-Kyung Lee},\n pages = {257-262},\n title = {GenieTutor: A Computer-Assisted Second-Language Learning System Based on Spoken Language Understanding},\n year = {2015}\n}\n'}","[{'authorId': '40641768', 'name': 'Oh-Woog Kwon'}, {'authorId': '2152542430', 'name': 'Ki-Young Lee'}, {'authorId': '3019507', 'name': 'Yoon-Hyung Roh'}, {'authorId': '2926314', 'name': 'Jin-Xia Huang'}, {'authorId': '2621870', 'name': 'Sung-Kwon Choi'}, {'authorId': '3030175', 'name': 'Y. K. Kim'}, {'authorId': '2067116', 'name': 'Hyung-Bae Jeon'}, {'authorId': '2299444', 'name': 'Y. Oh'}, {'authorId': '2146337673', 'name': 'Yun-Kyung Lee'}, {'authorId': '2094201', 'name': 'B. Kang'}, {'authorId': '2801379', 'name': 'Euisok Chung'}, {'authorId': '1923028', 'name': 'J. Park'}, {'authorId': '2146337673', 'name': 'Yun-Kyung Lee'}]"
827,460fd4fdf1ebe60dcbf57060dc19904635869290,Sentiment Classification towards Question-Answering with Hierarchical Matching Network,"In an e-commerce environment, user-oriented question-answering (QA) text pair could carry rich sentiment information. In this study, we propose a novel task/method to address QA sentiment analysis. In particular, we create a high-quality annotated corpus with specially-designed annotation guidelines for QA-style sentiment classification. On the basis, we propose a three-stage hierarchical matching network to explore deep sentiment information in a QA text pair. First, we segment both the question and answer text into sentences and construct a number of [Q-sentence, A-sentence] units in each QA text pair. Then, by leveraging a QA bidirectional matching layer, the proposed approach can learn the matching vectors of each [Q-sentence, A-sentence] unit. Finally, we characterize the importance of the generated matching vectors via a self-matching attention layer. Experimental results, comparing with a number of state-of-the-art baselines, demonstrate the impressive effectiveness of the proposed approach for QA-style sentiment classification.",2018.0,36.0,27.0,True,"{'url': 'https://www.aclweb.org/anthology/D18-1401.pdf', 'status': None}",{'pages': '3654-3663'},"{'bibtex': '@Inproceedings{Shen2018SentimentCT,\n author = {Chenlin Shen and Changlong Sun and Jingjing Wang and Yangyang Kang and Shoushan Li and Xiaozhong Liu and Luo Si and Min Zhang and Guodong Zhou},\n pages = {3654-3663},\n title = {Sentiment Classification towards Question-Answering with Hierarchical Matching Network},\n year = {2018}\n}\n'}","[{'authorId': '50413860', 'name': 'Chenlin Shen'}, {'authorId': '2060934', 'name': 'Changlong Sun'}, {'authorId': '2109839506', 'name': 'Jingjing Wang'}, {'authorId': '38753454', 'name': 'Yangyang Kang'}, {'authorId': '2109167274', 'name': 'Shoushan Li'}, {'authorId': '1713802', 'name': 'Xiaozhong Liu'}, {'authorId': '2059080424', 'name': 'Luo Si'}, {'authorId': None, 'name': 'Min Zhang'}, {'authorId': '143740945', 'name': 'Guodong Zhou'}]"
828,4631b75b09c6289ab706e741b41c095981c5dd5f,Crowding in Context: An Examination of the Differential Responses of Men and Women to High-Density Living Environments∗,"This study examines the question of gender-equivalent outcomes of mental health and social behavior in the context of crowding stress. It tests the hypothesis that gender will influence the exhibition of stress outcomes resulting from exposure to high-density living environments, with women displaying internalized responses and men responding with externalized styles. Expanding on the types of gender-appropriate disorders examined in this area of research, I selected depression, aggression, and withdrawal as gender-specific disorders based on theory and prior research. Multilevel analyses of data from a survey of Toronto residents indicate that, while the effects of household density are conditioned by gender, support for the existence of gender-equivalent outcomes is mixed. While women living in crowded homes are more likely to be depressed, men exposed to high-density living environments do not report increased aggression. However, men report higher levels of withdrawal, and some males respond with both aggression and withdrawal.",2008.0,92.0,75.0,True,"{'url': 'https://engagedscholarship.csuohio.edu/cgi/viewcontent.cgi?article=1125&context=clsoc_crim_facpub', 'status': None}","{'volume': '49', 'pages': '254 - 268', 'name': 'Journal of Health and Social Behavior'}","{'bibtex': '@Article{Regoeczi2008CrowdingIC,\n author = {Wendy C. Regoeczi},\n journal = {Journal of Health and Social Behavior},\n pages = {254 - 268},\n title = {Crowding in Context: An Examination of the Differential Responses of Men and Women to High-Density Living Environments∗},\n volume = {49},\n year = {2008}\n}\n'}","[{'authorId': '11033590', 'name': 'Wendy C. Regoeczi'}]"
829,46443fcfc5d651b8ae96c74d55bbe9d7f56107dd,Implementation and evaluation of a satisfaction/altruism based architecture for multi-robot systems,"We have developed an agent's architecture towards the goal of building efficient, robust and safe multi-robot systems considered as cooperating distributed reactive agents. This architecture is based on satisfaction and altruism allowing the agents to amend their low-level behavior like goal seeking and collision avoidance in order to solve more complex problems. We demonstrate in particular that local conflicting and locking situations are automatically avoided or made repulsive. Computer simulations of tasks in complex environments confirm it. The designed mini-robots, the implementation of their architecture, and the communication protocol are described. The same hardware is shared between communication, collision avoidance, and task achievement. Experiments using two mobile robots and a test bed confirm the theoretical and simulation results.",2002.0,15.0,50.0,True,"{'url': 'https://hal-lirmm.ccsd.cnrs.fr/lirmm-00269416/file/D233.PDF', 'status': None}","{'volume': '1', 'pages': '1007-1012 vol.1', 'name': 'Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)'}","{'bibtex': '@Article{Lucidarme2002ImplementationAE,\n author = {P. Lucidarme and Olivier Simonin and A. Liégeois},\n journal = {Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)},\n pages = {1007-1012 vol.1},\n title = {Implementation and evaluation of a satisfaction/altruism based architecture for multi-robot systems},\n volume = {1},\n year = {2002}\n}\n'}","[{'authorId': '2472443', 'name': 'P. Lucidarme'}, {'authorId': '1807441', 'name': 'Olivier Simonin'}, {'authorId': '2904376', 'name': 'A. Liégeois'}]"
830,46465a97ab883cc72d9f601263a208afae6fb31a,Measuring personality in one minute or less: A 10-item short version of the Big Five Inventory in English and German,,2007.0,20.0,3252.0,False,,"{'volume': '41', 'pages': '203-212', 'name': 'Journal of Research in Personality'}","{'bibtex': '@Article{Rammstedt2007MeasuringPI,\n author = {Beatrice Rammstedt and O. John},\n journal = {Journal of Research in Personality},\n pages = {203-212},\n title = {Measuring personality in one minute or less: A 10-item short version of the Big Five Inventory in English and German},\n volume = {41},\n year = {2007}\n}\n'}","[{'authorId': '6408438', 'name': 'Beatrice Rammstedt'}, {'authorId': '2254103', 'name': 'O. John'}]"
831,46571652648f95aa23bc1d8f4697905db292fce3,On the Utilization of Social Animals as a Model for Social Robotics,"Social robotics is a thriving field in building artificial agents. The possibility to construct agents that can engage in meaningful social interaction with humans presents new challenges for engineers. In general, social robotics has been inspired primarily by psychologists with the aim of building human-like robots. Only a small subcategory of “companion robots” (also referred to as robotic pets) was built to mimic animals. In this opinion essay we argue that all social robots should be seen as companions and more conceptual emphasis should be put on the inter-specific interaction between humans and social robots. This view is underlined by the means of an ethological analysis and critical evaluation of present day companion robots. We suggest that human–animal interaction provides a rich source of knowledge for designing social robots that are able to interact with humans under a wide range of conditions.",2012.0,67.0,83.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00075/pdf', 'status': None}","{'volume': '3', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Miklósi2012OnTU,\n author = {Á. Miklósi and M. Gácsi},\n journal = {Frontiers in Psychology},\n title = {On the Utilization of Social Animals as a Model for Social Robotics},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '52191123', 'name': 'Á. Miklósi'}, {'authorId': '3131165', 'name': 'M. Gácsi'}]"
832,469c5d279c5e0625f730f98dc07d2d8b875a2e82,Rediscovering the social group: A self-categorization theory.,1. Introducing the Problem: Individual and Group 2. Rediscovering the Social Group 3. A Self-Categorization Theory 4. The Analysis of Social Influence 5. Social Identity 6. The Salience of Social Categories 7. Social Identity and Group Polarization 8. Crowd Behaviour as Social Action 9. Conclusion.,1989.0,0.0,9146.0,False,,"{'volume': '18', 'pages': '645', 'name': 'Contemporary Sociology'}","{'bibtex': '@Article{Turner1989RediscoveringTS,\n author = {J. Turner and M. Hogg and P. Oakes and S. Reicher and M. Wetherell},\n journal = {Contemporary Sociology},\n pages = {645},\n title = {Rediscovering the social group: A self-categorization theory.},\n volume = {18},\n year = {1989}\n}\n'}","[{'authorId': '144385080', 'name': 'J. Turner'}, {'authorId': '152475749', 'name': 'M. Hogg'}, {'authorId': '48266513', 'name': 'P. Oakes'}, {'authorId': '6078899', 'name': 'S. Reicher'}, {'authorId': '32919858', 'name': 'M. Wetherell'}]"
833,46b9670547e0efa388ebe4be945abd4269e3e061,Social Behaviors Increase in Children with Autism in the Presence of Animals Compared to Toys,"Background Previous research has demonstrated the capacity of animal presence to stimulate social interaction among humans. The purpose of this study was to examine the interactions of children with autism spectrum disorder (ASD) with an adult and their typically-developing peers in the presence of animals (two guinea pigs) compared to toys. Methods Ninety-nine children from 15 classrooms in 4 schools met the inclusion criteria and participated in groups of three (1 child with ASD and 2 typically-developing peers). Each group was video-recorded during three 10-minute, free-play sessions with toys and three 10-minute, free-play sessions with two guinea pigs. Two blinded observers coded the behavior of children with ASD and their peers. To account for the nested study design, data were analyzed using hierarchical generalized linear modeling. Results Participants with ASD demonstrated more social approach behaviors (including talking, looking at faces, and making tactile contact) and received more social approaches from their peers in the presence of animals compared to toys. They also displayed more prosocial behaviors and positive affect (i.e., smiling and laughing) as well as less self-focused behaviors and negative affect (i.e., frowning, crying, and whining) in the presence of animals compared to toys. Conclusions These results suggest that the presence of an animal can significantly increase positive social behaviors among children with ASD.",2013.0,65.0,129.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0057010&type=printable', 'status': None}","{'volume': '8', 'name': 'PLoS ONE'}","{'bibtex': '@Article{O’Haire2013SocialBI,\n author = {M. O’Haire and S. McKenzie and A. Beck and V. Slaughter},\n journal = {PLoS ONE},\n title = {Social Behaviors Increase in Children with Autism in the Presence of Animals Compared to Toys},\n volume = {8},\n year = {2013}\n}\n'}","[{'authorId': '1403112735', 'name': 'M. O’Haire'}, {'authorId': '5248094', 'name': 'S. McKenzie'}, {'authorId': '144999873', 'name': 'A. Beck'}, {'authorId': '7251004', 'name': 'V. Slaughter'}]"
834,46b9fbc467c4865985a426e79e1b1e276e13e17c,Estimating emotion regulation capabilities,"To improve the performance and wellbeing of humans in complex human-computer interaction settings, ambient (or pervasive) systems need the capability to recognize the emotions of humans, but also the ability to reason about their emotion regulation processes. To this end, this paper introduces a computational model to estimate and reason about emotion regulation. The model has been implemented and tested using the high-level modeling language LEADSTO. A first evaluation indicates that the model is successful in estimating a person's emotion regulation dynamics, and is robust to different parameter settings.",2008.0,33.0,5.0,False,,{'pages': '93'},"{'bibtex': '@Inproceedings{Bosse2008EstimatingER,\n author = {T. Bosse and F. J. Lange},\n pages = {93},\n title = {Estimating emotion regulation capabilities},\n year = {2008}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '38590917', 'name': 'F. J. Lange'}]"
835,46d01e53a0531e659048000e273ae0e194332204,A survey of trust in internet applications,"Trust is an important aspect of decision making for Internet applications and particularly influences the specification of security policy, i.e., who is authorized to perform actions as well as the techniques needed to manage and implement security to and for the applications. This survey examines the various definitions of trust in the literature and provides a working definition of trust for Internet applications. The properties of trust relationships are explained and classes of different types of trust identified in the literature are discussed with examples. Some influential examples of trust management systems are described.",2000.0,74.0,1264.0,True,"{'url': 'http://www.doc.ic.ac.uk/~mss/Papers/Trust_Survey.pdf', 'status': None}","{'volume': '3', 'pages': '2-16', 'name': 'IEEE Communications Surveys & Tutorials'}","{'bibtex': '@Article{Grandison2000ASO,\n author = {T. Grandison and M. Sloman},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {2-16},\n title = {A survey of trust in internet applications},\n volume = {3},\n year = {2000}\n}\n'}","[{'authorId': '47346594', 'name': 'T. Grandison'}, {'authorId': '1738169', 'name': 'M. Sloman'}]"
836,46d800dd01e9711deb61687334cf7bf4ec8c53ad,A Second Chance to Make a First Impression? How Appearance and Nonverbal Behavior Affect Perceived Warmth and Competence of Virtual Agents over Time,,2012.0,34.0,108.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/2522306/2534545/Bergmann_Eyssel_Kopp_IVA2012_final.pdf', 'status': None}",{'pages': '126-138'},"{'bibtex': '@Inproceedings{Bergmann2012ASC,\n author = {K. Bergmann and F. Eyssel and S. Kopp},\n pages = {126-138},\n title = {A Second Chance to Make a First Impression? How Appearance and Nonverbal Behavior Affect Perceived Warmth and Competence of Virtual Agents over Time},\n year = {2012}\n}\n'}","[{'authorId': '2025591', 'name': 'K. Bergmann'}, {'authorId': '2557354', 'name': 'F. Eyssel'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
837,46dbf46178bdc6475e5bd68cc712a066ca222f49,Evaluating an Animated Pedagogical Agent,,2000.0,13.0,64.0,True,"{'url': 'http://ir.canterbury.ac.nz/bitstream/10092/308/1/41217_SmartEgg.pdf', 'status': None}",{'pages': '73-82'},"{'bibtex': '@Inproceedings{Mitrovic2000EvaluatingAA,\n author = {A. Mitrovic and P. Suraweera},\n pages = {73-82},\n title = {Evaluating an Animated Pedagogical Agent},\n year = {2000}\n}\n'}","[{'authorId': '145951543', 'name': 'A. Mitrovic'}, {'authorId': '2659276', 'name': 'P. Suraweera'}]"
838,46dc779829fda5c130363f9ca8107f7b9bb71dd4,The Toronto Empathy Questionnaire: Scale Development and Initial Validation of a Factor-Analytic Solution to Multiple Empathy Measures,"To formulate a parsimonious tool to assess empathy, we used factor analysis on a combination of self-report measures to examine consensus and developed a brief self-report measure of this common factor. The Toronto Empathy Questionnaire (TEQ) represents empathy as a primarily emotional process. In 3 studies, the TEQ demonstrated strong convergent validity, correlating positively with behavioral measures of social decoding, self-report measures of empathy, and negatively with a measure of Autism symptomatology. Moreover, it exhibited good internal consistency and high test–retest reliability. The TEQ is a brief, reliable, and valid instrument for the assessment of empathy.",2009.0,71.0,791.0,True,"{'url': 'https://europepmc.org/articles/pmc2775495?pdf=render', 'status': None}","{'volume': '91', 'pages': '62 - 71', 'name': 'Journal of Personality Assessment'}","{'bibtex': '@Article{Spreng2009TheTE,\n author = {R. N. Spreng and Margaret C. McKinnon and Raymond A. Mar and B. Levine},\n journal = {Journal of Personality Assessment},\n pages = {62 - 71},\n title = {The Toronto Empathy Questionnaire: Scale Development and Initial Validation of a Factor-Analytic Solution to Multiple Empathy Measures},\n volume = {91},\n year = {2009}\n}\n'}","[{'authorId': '2237636209', 'name': 'R. N. Spreng'}, {'authorId': '2244215139', 'name': 'Margaret C. McKinnon'}, {'authorId': '2239270536', 'name': 'Raymond A. Mar'}, {'authorId': '145157804', 'name': 'B. Levine'}]"
839,46e3485f18ff334b4fc3c15a71ba61a6c9ea2a0e,International Journal of Advanced Robotic Systems Modelling and Simulating of Risk Behaviours in Virtual Environments Based on Multi-Agent and Fuzzy Logic Regular Paper,"Due to safety and ethical issues, traditional experimental approaches to modelling underground risk behaviours can be costly, dangerous and even impossible to realize. Based on multi-agent technology, a virtual coalmine platform for risk behaviour simulation is presented to model and simulate the human-machineenvironment related risk factors in underground coalmines. To reveal mine workers’ risk behaviours, a fuzzy emotional behaviour model is proposed to simulate underground miners’ responding behaviours to potential hazardous events based on cognitive appraisal theories and fuzzy logic techniques. The proposed emotion model can generate more believable behaviours for virtual miners according to personalized emotion states, internal motivation needs and behaviour selection thresholds. Finally, typical accident cases of underground hazard spotting and locomotive transport were implemented. The behaviour believability of virtual miners was evaluated with a user assessment method. Experimental results show that the proposed models can create more realistic and reasonable behaviours in virtual coalmine environments, which can improve miners’ risk awareness and further train miners’ emergent decision-making ability when facing unexpected underground situations.",2017.0,32.0,0.0,False,,,"{'bibtex': '@Inproceedings{Cai2017InternationalJO,\n author = {Linqin Cai and Zhuo Yang and Simon X. Yang and Hongchun Qu},\n title = {International Journal of Advanced Robotic Systems Modelling and Simulating of Risk Behaviours in Virtual Environments Based on Multi-Agent and Fuzzy Logic Regular Paper},\n year = {2017}\n}\n'}","[{'authorId': '2524401', 'name': 'Linqin Cai'}, {'authorId': '2109506237', 'name': 'Zhuo Yang'}, {'authorId': '98726631', 'name': 'Simon X. Yang'}, {'authorId': '2133747', 'name': 'Hongchun Qu'}]"
840,470c41daed60c733d422280ce1c568b4548a6f38,Multimodal emotion estimation and emotional synthesize for interaction virtual agent,"In this study, we create a 3D interactive virtual character based on multi-modal emotional recognition and rule based emotional synthesize techniques. This agent estimates users' emotional state by combining the information from the audio and facial expression with CART and boosting. For the output module of the agent, the voice is generated by TTS (Text-to-Speech)system by freely given text. The synchronous visual information of agent, including facial expression, head motion, gesture and body animation, are generated by multi-modal mapping from motion capture database. A kind of high level behavior markerup language(hBML) which contains five keywords is used to drive the animation of virtual agent for emotional expression. Experiments show that this virtual character is considered natural and realistic in multimodal interaction environments.",2012.0,41.0,0.0,False,,"{'name': '2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems', 'pages': '191-196', 'volume': '01'}","{'bibtex': '@Article{Yang2012MultimodalEE,\n author = {Minghao Yang and J. Tao and Hao Li and Kaihui Mu},\n booktitle = {2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems},\n journal = {2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems},\n pages = {191-196},\n title = {Multimodal emotion estimation and emotional synthesize for interaction virtual agent},\n volume = {01},\n year = {2012}\n}\n'}","[{'authorId': '2740129', 'name': 'Minghao Yang'}, {'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '1706574', 'name': 'Hao Li'}, {'authorId': '3295988', 'name': 'Kaihui Mu'}]"
841,470f00ab856d1c6d2b2e559b61c56cbbb2ecc0a4,Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolutional Neural Network,,2021.0,57.0,15.0,False,,"{'volume': '45', 'name': 'Journal of Medical Systems'}","{'bibtex': '@Article{Ganapathy2021EmotionRU,\n author = {Nagarajan Ganapathy and Y. R. Veeranki and Himanshu Kumar and R. Swaminathan},\n journal = {Journal of Medical Systems},\n title = {Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolutional Neural Network},\n volume = {45},\n year = {2021}\n}\n'}","[{'authorId': '51229309', 'name': 'Nagarajan Ganapathy'}, {'authorId': '70301139', 'name': 'Y. R. Veeranki'}, {'authorId': '2065156735', 'name': 'Himanshu Kumar'}, {'authorId': '152155282', 'name': 'R. Swaminathan'}]"
842,47122569f7099558c8ff5eb3d169674d9ee32b8a,Engagement vs. Deceit: Virtual Humans with Human Autobiographies,,2009.0,29.0,86.0,True,"{'url': 'http://www.ccs.neu.edu/research/rag/publications/IVA09.backstory.pdf', 'status': None}",{'pages': '6-19'},"{'bibtex': '@Inproceedings{Bickmore2009EngagementVD,\n author = {T. Bickmore and Daniel Schulman and Langxuan Yin},\n pages = {6-19},\n title = {Engagement vs. Deceit: Virtual Humans with Human Autobiographies},\n year = {2009}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '50247170', 'name': 'Daniel Schulman'}, {'authorId': '2721397', 'name': 'Langxuan Yin'}]"
843,472ba8dd4ec72b34e85e733bccebb115811fd726,Cosine Similarity Metric Learning for Face Verification,,2010.0,25.0,668.0,False,,{'pages': '709-720'},"{'bibtex': '@Inproceedings{Nguyen2010CosineSM,\n author = {Hieu V. Nguyen and L. Bai},\n pages = {709-720},\n title = {Cosine Similarity Metric Learning for Face Verification},\n year = {2010}\n}\n'}","[{'authorId': '2110579514', 'name': 'Hieu V. Nguyen'}, {'authorId': '143642695', 'name': 'L. Bai'}]"
844,473908b1e211530710969c4117f517f7c900af55,How anthropomorphism affects empathy toward robots,A long-standing question within the robotics community is about the degree of human-likeness robots ought to have when interacting with humans. We explore an unexamined aspect of this problem: how people empathize with robots along the anthropomorphic spectrum. We conducted an experiment that measured how people empathized with robots shown to be experiencing mistreatment by humans. Our results indicate that people empathize more strongly with more human-looking robots and less with mechanical-looking robots.,2009.0,8.0,243.0,True,"{'url': 'http://papers.laurelriek.org/hri09.pdf', 'status': None}","{'pages': '245-246', 'name': '2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Riek2009HowAA,\n author = {L. Riek and Tal-Chen Rabinowitch and B. Chakrabarti and P. Robinson},\n journal = {2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {245-246},\n title = {How anthropomorphism affects empathy toward robots},\n year = {2009}\n}\n'}","[{'authorId': '144786679', 'name': 'L. Riek'}, {'authorId': '2640789', 'name': 'Tal-Chen Rabinowitch'}, {'authorId': '3102450', 'name': 'B. Chakrabarti'}, {'authorId': '2149814967', 'name': 'P. Robinson'}]"
845,4751bf540930c77876dabaa2aee20c00c58eef66,Believability Through Psychosocial Behaviour: Creating Bots That Are More Engaging and Entertaining,,2012.0,80.0,12.0,False,,{'pages': '29-68'},"{'bibtex': '@Inproceedings{Bailey2012BelievabilityTP,\n author = {C. Bailey and Jiaming You and G. Acton and A. Rankin and M. Katchabaw},\n pages = {29-68},\n title = {Believability Through Psychosocial Behaviour: Creating Bots That Are More Engaging and Entertaining},\n year = {2012}\n}\n'}","[{'authorId': '123583022', 'name': 'C. Bailey'}, {'authorId': '2102392', 'name': 'Jiaming You'}, {'authorId': '2073644828', 'name': 'G. Acton'}, {'authorId': '2073890045', 'name': 'A. Rankin'}, {'authorId': '1793961', 'name': 'M. Katchabaw'}]"
846,47524f71f2e22307a6bd2e86dabd9aabe3a140bd,Relational agents : effecting change through human-computer relationships,"What kinds of social relationships can people have with computers? Are there activities that computers can engage in that actively draw people into relationships with them? What are the potential benefits to the people who participate in these human-computer relationships? To address these questions this work introduces a theory of Relational Agents, which are computational artifacts designed to build and maintain long-term, social-emotional relationships with their users. These can be purely software humanoid animated agents--as developed in this work--but they can also be non-humanoid or embodied in various physical forms, from robots, to pets, to jewelry, clothing, hand-helds, and other interactive devices. Central to the notion of relationship is that it is a persistent construct, spanning multiple interactions; thus, Relational Agents are explicitly designed to remember past history and manage future expectations in their interactions with users. Finally, relationships are fundamentally social and emotional, and detailed knowledge of human social psychology--with a particular emphasis on the role of affect--must be incorporated into these agents if they are to effectively leverage the mechanisms of human social cognition in order to build relationships in the most natural manner possible. People build relationships primarily through the use of language, and primarily within the context of face-to-face conversation. Embodied Conversational Agents--anthropomorphic computer characters that emulate the experience of face-to-face conversation--thus provide the substrate for this work, and so the relational activities provided by the theory will primarily be specific types of verbal and nonverbal conversational behaviors used by people to negotiate and maintain relationships. This work also provides an analysis of the types of applications in which having a human-computer relationship is advantageous to the human participant. In addition to applications in which the relationship is an end in itself (e.g., in entertainment systems), human-computer relationships are important in tasks in which the human is attempting to undergo some change in behavior or cognitive or emotional state. One such application is explored here: a system for assisting the user through a month-long health behavior change program in the area of exercise adoption. This application involves the research, design and implementation of relational agents as well as empirical evaluation of their ability to build relationships and effect change over a series of interactions with users. Thesis Supervisors: Rosalind W. Picard, Associate Professor of Media Arts and Sciences Justine Cassell, Associate Professor of Media Arts and Sciences",2003.0,246.0,321.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bickmore2003RelationalA,\n author = {T. Bickmore},\n title = {Relational agents : effecting change through human-computer relationships},\n year = {2003}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}]"
847,47541d04ec24662c0be438531527323d983e958e,Affective Information Processing,,2008.0,498.0,72.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Tao2008AffectiveIP,\n author = {J. Tao and T. Tan},\n title = {Affective Information Processing},\n year = {2008}\n}\n'}","[{'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '143874948', 'name': 'T. Tan'}]"
848,475a9b7b23da93c35da9aeb5e4fbfef01bef9385,EEVEE: the Empathy-Enhancing Virtual Evolving Environment,"Empathy is a multifaceted emotional and mental faculty that is often found to be affected in a great number of psychopathologies, such as schizophrenia, yet it remains very difficult to measure in an ecological context. The challenge stems partly from the complexity and fluidity of this social process, but also from its covert nature. One powerful tool to enhance experimental control over such dynamic social interactions has been the use of avatars in virtual reality (VR); information about an individual in such an interaction can be collected through the analysis of his or her neurophysiological and behavioral responses. We have developed a unique platform, the Empathy-Enhancing Virtual Evolving Environment (EEVEE), which is built around three main components: (1) different avatars capable of expressing feelings and emotions at various levels based on the Facial Action Coding System (FACS); (2) systems for measuring the physiological responses of the observer (heart and respiration rate, skin conductance, gaze and eye movements, facial expression); and (3) a multimodal interface linking the avatar's behavior to the observer's neurophysiological response. In this article, we provide a detailed description of the components of this innovative platform and validation data from the first phases of development. Our data show that healthy adults can discriminate different negative emotions, including pain, expressed by avatars at varying intensities. We also provide evidence that masking part of an avatar's face (top or bottom half) does not prevent the detection of different levels of pain. This innovative and flexible platform provides a unique tool to study and even modulate empathy in a comprehensive and ecological manner in various populations, notably individuals suffering from neurological or psychiatric disorders.",2015.0,69.0,28.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnhum.2015.00112/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Human Neuroscience'}","{'bibtex': '@Article{Jackson2015EEVEETE,\n author = {P. Jackson and P. Michon and Erik Geslin and Maxime Carignan and Danny Beaudoin},\n journal = {Frontiers in Human Neuroscience},\n title = {EEVEE: the Empathy-Enhancing Virtual Evolving Environment},\n volume = {9},\n year = {2015}\n}\n'}","[{'authorId': '6079112', 'name': 'P. Jackson'}, {'authorId': '145500372', 'name': 'P. Michon'}, {'authorId': '34861774', 'name': 'Erik Geslin'}, {'authorId': '32406041', 'name': 'Maxime Carignan'}, {'authorId': '33470496', 'name': 'Danny Beaudoin'}]"
849,476029ac9be26bf7f121a388f5c1e45d204efe52,BERT for Joint Intent Classification and Slot Filling,"Intent classification and slot filling are two essential tasks for natural language understanding. They often suffer from small-scale human-labeled training data, resulting in poor generalization capability, especially for rare words. Recently a new language representation model, BERT (Bidirectional Encoder Representations from Transformers), facilitates pre-training deep bidirectional representations on large-scale unlabeled corpora, and has created state-of-the-art models for a wide variety of natural language processing tasks after simple fine-tuning. However, there has not been much effort on exploring BERT for natural language understanding. In this work, we propose a joint intent classification and slot filling model based on BERT. Experimental results demonstrate that our proposed model achieves significant improvement on intent classification accuracy, slot filling F1, and sentence-level semantic frame accuracy on several public benchmark datasets, compared to the attention-based recurrent neural network models and slot-gated models.",2019.0,26.0,426.0,False,,"{'volume': 'abs/1902.10909', 'name': 'ArXiv'}","{'bibtex': '@Article{Chen2019BERTFJ,\n author = {Qian Chen and Zhu Zhuo and Wen Wang},\n journal = {ArXiv},\n title = {BERT for Joint Intent Classification and Slot Filling},\n volume = {abs/1902.10909},\n year = {2019}\n}\n'}","[{'authorId': '47261124', 'name': 'Qian Chen'}, {'authorId': '1500648476', 'name': 'Zhu Zhuo'}, {'authorId': '2117827836', 'name': 'Wen Wang'}]"
850,476ee56bf99d8b848815a61a77fdc79325e2d5b3,Fuzzy logic based robot path planning in unknown environment,"This paper proposes a new method, minimum risk approach, to address the local path planning to escape from local minimum during goal-oriented robot navigation in unknown environments. This approach is theoretically proved to guarantee global convergence even in the long-wall, unstructured, cluttered, maze-like, and modified environments. The approach adopts a strategy of multi-behavior coordination, in which a novel path-searching behavior is developed to recommend the regional direction with minimum risk. The paper provides a fuzzy logic framework to implement the behavior design and coordination. It is verified by the simulated and real world tests.",2005.0,12.0,83.0,False,,"{'volume': '2', 'pages': '813-818 Vol. 2', 'name': '2005 International Conference on Machine Learning and Cybernetics'}","{'bibtex': '@Article{Wang2005FuzzyLB,\n author = {M. Wang and J.N.K. Liu},\n journal = {2005 International Conference on Machine Learning and Cybernetics},\n pages = {813-818 Vol. 2},\n title = {Fuzzy logic based robot path planning in unknown environment},\n volume = {2},\n year = {2005}\n}\n'}","[{'authorId': '39872583', 'name': 'M. Wang'}, {'authorId': '2116031967', 'name': 'J.N.K. Liu'}]"
851,478d05393388f47179d55df8c791156b88697919,A User Perception--Based Approach to Create Smiling Embodied Conversational Agents,"In order to improve the social capabilities of embodied conversational agents, we propose a computational model to enable agents to automatically select and display appropriate smiling behavior during human--machine interaction. A smile may convey different communicative intentions depending on subtle characteristics of the facial expression and contextual cues. To construct such a model, as a first step, we explore the morphological and dynamic characteristics of different types of smiles (polite, amused, and embarrassed smiles) that an embodied conversational agent may display. The resulting lexicon of smiles is based on a corpus of virtual agents’ smiles directly created by users and analyzed through a machine-learning technique. Moreover, during an interaction, a smiling expression impacts on the observer’s perception of the interpersonal stance of the speaker. As a second step, we propose a probabilistic model to automatically compute the user’s potential perception of the embodied conversational agent’s social stance depending on its smiling behavior and on its physical appearance. This model, based on a corpus of users’ perceptions of smiling and nonsmiling virtual agents, enables a virtual agent to determine the appropriate smiling behavior to adopt given the interpersonal stance it wants to express. An experiment using real human--virtual agent interaction provided some validation of the proposed model.",2017.0,97.0,34.0,True,"{'url': 'https://pureadmin.qub.ac.uk/ws/files/120315954/ArticleTIIS_VersionRevised.pdf', 'status': None}","{'volume': '7', 'pages': '1 - 33', 'name': 'ACM Transactions on Interactive Intelligent Systems (TiiS)'}","{'bibtex': '@Article{Ochs2017AUP,\n author = {M. Ochs and C. Pelachaud and G. McKeown},\n journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},\n pages = {1 - 33},\n title = {A User Perception--Based Approach to Create Smiling Embodied Conversational Agents},\n volume = {7},\n year = {2017}\n}\n'}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2228246', 'name': 'G. McKeown'}]"
852,479106770ee21a67247396f558828ac557024abf,Virtual Reality and Simulation in Neurosurgical Training.,,2017.0,57.0,195.0,False,,"{'volume': '106', 'pages': '\n          1015-1029\n        ', 'name': 'World neurosurgery'}","{'bibtex': '@Article{Bernardo2017VirtualRA,\n author = {A. Bernardo},\n journal = {World neurosurgery},\n pages = {\n          1015-1029\n        },\n title = {Virtual Reality and Simulation in Neurosurgical Training.},\n volume = {106},\n year = {2017}\n}\n'}","[{'authorId': '144116292', 'name': 'A. Bernardo'}]"
853,47c161963d8252293fe9ed43da2e1070824c2e2e,Comparing and Evaluating Real Time Character Engines for Virtual Environments,"As animated characters increasingly become vital parts of virtual environments, then the engines that drive these characters increasingly become vital parts of virtual environment software. This paper gives an overview of the state of the art in character engines, and proposes a taxonomy of the features that are commonly found in them. This taxonomy can be used as a tool for comparison and evaluation of different engines. In order to demonstrate this we use it to compare three engines. The first is Cal3D, the most commonly used open source engine. We also introduce two engines created by the authors, Piavca and HALCA. The paper ends with a brief discussion of some other popular engines.",2010.0,64.0,72.0,True,"{'url': 'https://research.gold.ac.uk/3282/1/PiavcaPresence.pdf', 'status': None}","{'volume': '19', 'pages': '95-117', 'name': 'PRESENCE: Teleoperators and Virtual Environments'}","{'bibtex': '@Article{Gillies2010ComparingAE,\n author = {M. Gillies and B. Spanlang},\n journal = {PRESENCE: Teleoperators and Virtual Environments},\n pages = {95-117},\n title = {Comparing and Evaluating Real Time Character Engines for Virtual Environments},\n volume = {19},\n year = {2010}\n}\n'}","[{'authorId': '2589934', 'name': 'M. Gillies'}, {'authorId': '2891686', 'name': 'B. Spanlang'}]"
854,47c9cf8832287837493ad2074f460f8940adaf89,Avatars in Clinical Psychology: A Framework for the Clinical Use of Virtual Humans,"Early applications of virtual reality (VR) technology in psychological assessment, treatment, and research have yielded promising results. In particular, an increasing number of studies analyze the unique features of the experience made by patients during their exposure to virtual environments. However, the majority of these studies explore how patients navigate in the virtual spaces and interact with virtual objects. Only a few of them investigate the features of inhabited virtual environments, where real people and autonomous virtual humans are able to interact and to cooperate. In particular, there is a lack of discussion of the role that such autonomous virtual humans could have in VR-aided psychotherapy. The main goal of this paper is to identify a framework for future research in this area. Three levels of analysis are identified. The purpose of the first two levels is the identification of the key ""physical"" features (e.g., appearance, structure) and ""internal"" characteristics (e.g., behavior, degree of autonomy, perceptual capabilities) needed by an effective simulation. The third level is concerned with the evaluation of the interaction characteristics required for a successful relationship between the patient and the virtual human.",2003.0,34.0,55.0,False,,"{'volume': '6 2', 'pages': '\n          117-25\n        ', 'name': 'Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society'}","{'bibtex': '@Article{Gaggioli2003AvatarsIC,\n author = {A. Gaggioli and F. Mantovani and G. Castelnuovo and B. Wiederhold and G. Riva},\n journal = {Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},\n pages = {\n          117-25\n        },\n title = {Avatars in Clinical Psychology: A Framework for the Clinical Use of Virtual Humans},\n volume = {6 2},\n year = {2003}\n}\n'}","[{'authorId': '1700503', 'name': 'A. Gaggioli'}, {'authorId': '2274674', 'name': 'F. Mantovani'}, {'authorId': '3331953', 'name': 'G. Castelnuovo'}, {'authorId': '1686405', 'name': 'B. Wiederhold'}, {'authorId': '144059813', 'name': 'G. Riva'}]"
856,47fc921add1421ff8adb730df7aa9e7f865bfdeb,Toward Practical Smile Detection,"Machine learning approaches have produced some of the highest reported performances for facial expression recognition. However, to date, nearly all automatic facial expression recognition research has focused on optimizing performance on a few databases that were collected under controlled lighting conditions on a relatively small number of subjects. This paper explores whether current machine learning methods can be used to develop an expression recognition system that operates reliably in more realistic conditions. We explore the necessary characteristics of the training data set, image registration, feature representation, and machine learning algorithms. A new database, GENKI, is presented which contains pictures, photographed by the subjects themselves, from thousands of different people in many different real-world imaging conditions. Results suggest that human-level expression recognition accuracy in real-life illumination conditions is achievable with machine learning technology. However, the data sets currently used in the automatic expression recognition literature to evaluate progress may be overly constrained and could potentially lead research into locally optimal algorithmic solutions.",2009.0,43.0,325.0,False,,"{'volume': '31', 'pages': '2106-2111', 'name': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'}","{'bibtex': '@Article{Whitehill2009TowardPS,\n author = {J. Whitehill and G. Littlewort and Ian R. Fasel and M. Bartlett and J. Movellan},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {2106-2111},\n title = {Toward Practical Smile Detection},\n volume = {31},\n year = {2009}\n}\n'}","[{'authorId': '143973061', 'name': 'J. Whitehill'}, {'authorId': '2724380', 'name': 'G. Littlewort'}, {'authorId': '2039025', 'name': 'Ian R. Fasel'}, {'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '1741200', 'name': 'J. Movellan'}]"
857,480aab717bd4551bedb25949080888b6731bce90,How familiar characters influence children's judgments about information and products.,,2014.0,30.0,26.0,False,,"{'volume': '128', 'pages': '\n          1-20\n        ', 'name': 'Journal of experimental child psychology'}","{'bibtex': ""@Article{Danovitch2014HowFC,\n author = {Judith H. Danovitch and Candice M. Mills},\n journal = {Journal of experimental child psychology},\n pages = {\n          1-20\n        },\n title = {How familiar characters influence children's judgments about information and products.},\n volume = {128},\n year = {2014}\n}\n""}","[{'authorId': '3196314', 'name': 'Judith H. Danovitch'}, {'authorId': '7560415', 'name': 'Candice M. Mills'}]"
858,48596a00247b68200568ac511f2fa78773947a68,Activity Theory: Implications for Human-computer Interaction the Need for a Theory of Human-computer Interaction Basic Principles of Activity Theory,"Recently interest has grown in applying activity theory, the leading theoretical approach in Russian psychology, to issues of human-computer interaction. This chapter analyzes why experts in the field are looking for an alternative to the currently dominant cognitive approach. The basic principles of activity theory are presented and their implications for human-computer interaction are discussed. The chapter concludes with an outline of the potential impact of activity theory on studies and design of computer use in real-life settings. It is generally accepted that the lack of an adequate theory of human-computer interaction (HCI) is one of the most important reasons that progress in the field of HCI is relatively modest, compared with the rate of technological development. People coming to the field of HCI from different disciplines—psychology, computer science, graphics design, and others—have serious problems in coordinating and combining their efforts. For example, typical HCI curricula for undergraduate and graduate students present a mixture of knowledge from various disciplines rather than an integrated perspective. Traditional conceptual approaches cannot provide an appropriate basis for addressing many important aspects of HCI, including computer-supported cooperative work (CSCW) and cross-cultural aspects of computer use. Consequently the impact of HCI studies on current design practice is limited, with user interface design being based mainly on intuition and expensive trial and error. The form of a suitable HCI theory has been subjected to much debate recently (Carroll, Kellogg, and Rosson 1991). A major trend in the debate has been the growing dissatisfaction with the dominant cognitive approach (Bannon 1991; Wood 1992; Monk et al. 1993). In contrast to the general agreement that current attempts to apply cognitive psychology to HCI are not very successful, there is little agreement on the most promising theoretical alternatives. Proposals vary from an enrichment of the traditional cognitive scheme (Barnard 1991) to a radical shift in paradigms, for example, from scientific experimental studies to ethnographic methodology (see Monk et al. 1993). In this period of theoretical uncertainty there has been a growing interest in activity theory, greatly stimulated by Bødker's works (1989, 1991). She was the first Western researcher who presented the basic ideas and potential benefits of activity theory to the HCI community. Recently, a number of papers discussing the activity theory approach to HCI have appeared in major international journals and The aim of the present chapter is to summarize current work in activity theory and its implications for …",,31.0,426.0,False,,,"{'bibtex': '@Misc{None,\n author = {V. Kaptelinin},\n title = {Activity Theory: Implications for Human-computer Interaction the Need for a Theory of Human-computer Interaction Basic Principles of Activity Theory}\n}\n'}","[{'authorId': '1751148', 'name': 'V. Kaptelinin'}]"
859,48669a13c5c30da39eb439c03e4e4c7d7ab5576e,The emotion probe. Studies of motivation and attention.,"Emotions are action dispositions--states of vigilant readiness that vary widely in reported affect, physiology, and behavior. They are driven, however, by only 2 opponent motivational systems, appetitive and aversive--subcortical circuits that mediate reactions to primary reinforcers. Using a large emotional picture library, reliable affective psychophysiologies are shown, defined by the judged valence (appetitive/pleasant or aversive/unpleasant) and arousal of picture percepts. Picture-evoked affects also modulate responses to independently presented startle probe stimuli. In other words, they potentiate startle reflexes during unpleasant pictures and inhibit them during pleasant pictures, and both effects are augmented by high picture arousal. Implications are elucidated for research in basic emotions, psychopathology, and theories of orienting and defense. Conclusions highlight both the approach's constraints and promising paths for future study.",1995.0,76.0,2654.0,False,,"{'volume': '50 5', 'pages': '\n          372-85\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Lang1995TheEP,\n author = {P. Lang},\n journal = {The American psychologist},\n pages = {\n          372-85\n        },\n title = {The emotion probe. Studies of motivation and attention.},\n volume = {50 5},\n year = {1995}\n}\n'}","[{'authorId': '143853826', 'name': 'P. Lang'}]"
861,486e9427d75044e05a2421c147154b099a478402,It’s not just what we touch but also how we touch it,,2014.0,0.0,7.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bianchi-Berthouze2014ItsNJ,\n author = {N. Bianchi-Berthouze and A. T. Jimenez},\n title = {It’s not just what we touch but also how we touch it},\n year = {2014}\n}\n'}","[{'authorId': '1398541310', 'name': 'N. Bianchi-Berthouze'}, {'authorId': '143840883', 'name': 'A. T. Jimenez'}]"
862,4880434b8efc9a73db45b47b89f04df533420b51,Facial Expressions of Emotions for Virtual Characters,"The virtual character’s expressions of emotions may significantly enhance human-machine interaction. To give the capability to virtual characters to display emotions, the latter should be endowed with a repertoire of facial expressions that convey emotional meanings in conversational settings. In this chapter, we explore research works highlighting different methodologies both to identify the morphological and dynamic characteristics of emotional facial expressions and to measure the effects of the emotional expressions on the user’s perception during human-machine interaction.",2015.0,59.0,19.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ochs2015FacialEO,\n author = {M. Ochs and Radoslaw Niewiadomski and C. Pelachaud},\n title = {Facial Expressions of Emotions for Virtual Characters},\n year = {2015}\n}\n'}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
864,48930c5afaeca22751c59ee5f16c92d473985a65,Creating an Agent-Based Framework for Don’t Starve Together,"Today’s video games are striving to maintain high levels of fidelity. The realistic graphical representation of virtual worlds is only betrayed by the lack of believability that ingame characters present. To maintain the immersion created by exquisite graphics, characters must be able to create the illusion of life, which requires them to possess basic human traits like social awareness, reactivity, and active goal pursuit. Some game genres, like role playing games, have seen this problem being addressed by using agency based characters. However, survival games have not been subject to the same attention. In this work, we address this issue by proposing a framework that allows developers to create characters based on agency models for survival games. By making use of FAtiMA Toolkit, a fully fledged model for agency, and Don’t Starve Together, a popular survival game, we’ve implemented and published such a framework with an example character, Walter. Walter has been run and tested against a behaviour tree based agent.",2018.0,51.0,2.0,False,,,"{'bibtex': '@Inproceedings{Almeida2018CreatingAA,\n author = {Fábio Vieira de Almeida and R. Prada and C. Martinho},\n title = {Creating an Agent-Based Framework for Don’t Starve Together},\n year = {2018}\n}\n'}","[{'authorId': '2053384133', 'name': 'Fábio Vieira de Almeida'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145813496', 'name': 'C. Martinho'}]"
865,48af5a77e5c4d32d90fe0601170552673530a125,PERFORM,"A major goal of research on virtual humans is the animation of expressive characters that display distinct psychological attributes. Body motion is an effective way of portraying different personalities and differentiating characters. The purpose and contribution of this work is to describe a formal, broadly applicable, procedural, and empirically grounded association between personality and body motion and apply this association to modify a given virtual human body animation that can be represented by these formal concepts. Because the body movement of virtual characters may involve different choices of parameter sets depending on the context, situation, or application, formulating a link from personality to body motion requires an intermediate step to assist generalization. For this intermediate step, we refer to Laban Movement Analysis, which is a movement analysis technique for systematically describing and evaluating human motion. We have developed an expressive human motion generation system with the help of movement experts and conducted a user study to explore how the psychologically validated OCEAN personality factors were perceived in motions with various Laban parameters. We have then applied our findings to procedurally animate expressive characters with personality, and validated the generalizability of our approach across different models and animations via another perception study.",2016.0,0.0,59.0,False,,"{'volume': '36', 'pages': '1 - 16', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Durupinar2016PERFORM,\n author = {Funda Durupinar and Mubbasir Kapadia and Susan Deutsch and Michael Neff and N. Badler},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 16},\n title = {PERFORM},\n volume = {36},\n year = {2016}\n}\n'}","[{'authorId': '2643744', 'name': 'Funda Durupinar'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '2047954359', 'name': 'Susan Deutsch'}, {'authorId': '143687087', 'name': 'Michael Neff'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
866,48cafa65a23cfa30fa30adcb60786b22e6a34b7a,Psychology and Non-Photorealistic Rendering: The Beginning of a Beautiful Relationship,,2003.0,33.0,40.0,False,,{'pages': '277-286'},"{'bibtex': '@Inproceedings{Halper2003PsychologyAN,\n author = {Nick Halper and M. Mellin and C. Herrmann and V. Linneweber and T. Strothotte},\n pages = {277-286},\n title = {Psychology and Non-Photorealistic Rendering: The Beginning of a Beautiful Relationship},\n year = {2003}\n}\n'}","[{'authorId': '1950943', 'name': 'Nick Halper'}, {'authorId': '48930261', 'name': 'M. Mellin'}, {'authorId': '1765445', 'name': 'C. Herrmann'}, {'authorId': '103357331', 'name': 'V. Linneweber'}, {'authorId': '1697367', 'name': 'T. Strothotte'}]"
867,48e71c7d49d8d95ffde8363be7be0ff7c30dca8d,Context in Emotion Perception,"We review recent work demonstrating consistent context effects during emotion perception. Visual scenes, voices, bodies, other faces, cultural orientation, and even words shape how emotion is perceived in a face, calling into question the still-common assumption that the emotional state of a person is written on and can be read from the face like words on a page. Incorporating context during emotion perception appears to be routine, efficient, and, to some degree, automatic. This evidence challenges the standard view of emotion perception represented in psychology texts, in the cognitive neuroscience literature, and in the popular media and points to a necessary change in the basic paradigm used in the scientific study of emotion perception.",2011.0,27.0,683.0,False,,"{'volume': '20', 'pages': '286 - 290', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Barrett2011ContextIE,\n author = {L. F. Barrett and B. Mesquita and M. Gendron},\n journal = {Current Directions in Psychological Science},\n pages = {286 - 290},\n title = {Context in Emotion Perception},\n volume = {20},\n year = {2011}\n}\n'}","[{'authorId': '1731779', 'name': 'L. F. Barrett'}, {'authorId': '5935785', 'name': 'B. Mesquita'}, {'authorId': '144556585', 'name': 'M. Gendron'}]"
869,491d3e5621cc866465cbec7b3c8776eedd330deb,Integrating Biosignals into Information Systems: A NeuroIS Tool for Improving Emotion Regulation,"Traders and investors are aware that emotional processes can have material consequences on their financial decision performance. However, typical learning approaches for debiasing fail to overcome emotionally driven financial dispositions, mostly because of subjects' limited capacity for self-monitoring. Our research aims at improving decision makers' performance by (1) boosting their awareness to their emotional state and (2) improving their skills for effective emotion regulation. To that end, we designed and implemented a serious game-based NeuroIS tool that continuously displays the player's individual emotional state, via biofeedback, and adapts the difficulty of the decision environment to this emotional state. The design artifact was then evaluated in two laboratory experiments. Taken together, our study demonstrates how information systems design science research can contribute to improving financial decision making by integrating physiological data into information technology artifacts. Moreover, we provide specific design guidelines for how biofeedback can be integrated into information systems.",2013.0,83.0,114.0,False,,"{'volume': '30', 'pages': '247 - 278', 'name': 'Journal of Management Information Systems'}","{'bibtex': '@Article{Astor2013IntegratingBI,\n author = {Philipp J. Astor and M. Adam and Petar Jerčić and Kristina Schaaff and Christof Weinhardt},\n journal = {Journal of Management Information Systems},\n pages = {247 - 278},\n title = {Integrating Biosignals into Information Systems: A NeuroIS Tool for Improving Emotion Regulation},\n volume = {30},\n year = {2013}\n}\n'}","[{'authorId': '2112197', 'name': 'Philipp J. Astor'}, {'authorId': '24235135', 'name': 'M. Adam'}, {'authorId': '2164864', 'name': 'Petar Jerčić'}, {'authorId': '2340442', 'name': 'Kristina Schaaff'}, {'authorId': '1733795', 'name': 'Christof Weinhardt'}]"
870,491e2c09243dab781cd616c2b60aecc9e018e6e5,Crowd Behavior Simulation With Emotional Contagion in Unexpected Multihazard Situations,"Numerous research efforts have been conducted to simulate the crowd movements, while relatively few of them are specifically focused on multihazard situations. In this paper, we propose a novel crowd simulation method by modeling the generation and contagion of panic emotion under multihazard circumstances. In order to depict the effect from hazards and other agents to crowd movement, we first classify hazards into different types (transient and persistent, concurrent and nonconcurrent, and static and dynamic) based on their inherent characteristics. Second, we introduce the concept of perilous field for each hazard and further transform the critical level of the field to its invoked-panic emotion. After that, we propose an emotional contagion model to simulate the evolving process of panic emotion caused by multiple hazards. Finally, we introduce an emotional reciprocal velocity obstacles (RVOs) model to simulate the crowd behaviors by augmenting the traditional RVO model with emotional contagion, which for the first time combines the emotional impact and local avoidance together. Our experimental results demonstrate that the overall approach is robust, can better generate realistic crowds and the panic emotion dynamics in a crowd. Furthermore, it is recommended that our method can be applied to various complex multihazard environments.",2018.0,57.0,88.0,True,"{'url': 'https://arxiv.org/pdf/1801.10000', 'status': None}","{'volume': '51', 'pages': '1567-1581', 'name': 'IEEE Transactions on Systems, Man, and Cybernetics: Systems'}","{'bibtex': '@Article{Xu2018CrowdBS,\n author = {Mingliang Xu and Xiaozhen Xie and Pei Lv and Jiangwei Niu and Hua Wang and Chaochao Li and Ruijie Zhu and Z. Deng and Bing Zhou},\n journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},\n pages = {1567-1581},\n title = {Crowd Behavior Simulation With Emotional Contagion in Unexpected Multihazard Situations},\n volume = {51},\n year = {2018}\n}\n'}","[{'authorId': '2285442', 'name': 'Mingliang Xu'}, {'authorId': '2016679', 'name': 'Xiaozhen Xie'}, {'authorId': '144470801', 'name': 'Pei Lv'}, {'authorId': '35667840', 'name': 'Jiangwei Niu'}, {'authorId': '2113254290', 'name': 'Hua Wang'}, {'authorId': '7431398', 'name': 'Chaochao Li'}, {'authorId': '2070270237', 'name': 'Ruijie Zhu'}, {'authorId': '145140508', 'name': 'Z. Deng'}, {'authorId': '2118869098', 'name': 'Bing Zhou'}]"
871,4921d2f5eaace341f8597db48803b0a34daad347,Episodic memory system of affective agent with emotion for long-term human-robot interaction,"In long-term human robot interaction, memory of experience is important. This paper suggests episodic memory system for an affective robot which contains emotion. Storage, retention and retrieval of episodic memory are modeled with psychological bases. This modeled memory system will be implemented to pet-like virtual agent with reactive emotion generation model[2].",2013.0,8.0,4.0,False,,"{'name': '2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)', 'pages': '720-722'}","{'bibtex': '@Article{Kim2013EpisodicMS,\n author = {Hansoul Kim and Jeong-Yean Yang and D. Kwon},\n booktitle = {International Conference on Ubiquitous Robots and Ambient Intelligence},\n journal = {2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)},\n pages = {720-722},\n title = {Episodic memory system of affective agent with emotion for long-term human-robot interaction},\n year = {2013}\n}\n'}","[{'authorId': '51226875', 'name': 'Hansoul Kim'}, {'authorId': '47988042', 'name': 'Jeong-Yean Yang'}, {'authorId': '145079887', 'name': 'D. Kwon'}]"
872,494ea49753b90fc8eac4daf0a2e7197c128af197,The SERA Ecosystem: Socially Expressive Robotics Architecture for Autonomous Human-Robot Interaction,"Based on the development of several different HRI scenarios using different robots, we have been establishing the SERA ecosystem. SERA is composed of both a model and tools for integrating an AI agent with a robotic embodiment, in human-robot interaction scenarios. We present the model, and several of the reusable tools that were developed, namely Thalamus, Skene and Nutty Tracks. Finally we exemplify how such tools and model have been used and integrated in five different HRI scenarios using the NAO, Keepon and EMYS robots.",2016.0,15.0,29.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ribeiro2016TheSE,\n author = {T. Ribeiro and André Pereira and E. D. Tullio and Ana Paiva},\n title = {The SERA Ecosystem: Socially Expressive Robotics Architecture for Autonomous Human-Robot Interaction},\n year = {2016}\n}\n'}","[{'authorId': '145856842', 'name': 'T. Ribeiro'}, {'authorId': '11845717', 'name': 'André Pereira'}, {'authorId': '3188237', 'name': 'E. D. Tullio'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
873,495ba0d8366ffe131abfea5f6c62bbe8632fedaa,Facial micro-expression recognition based on accordion spatio-temporal representation and random forests,,2021.0,58.0,5.0,False,,"{'volume': '79', 'pages': '103183', 'name': 'J. Vis. Commun. Image Represent.'}","{'bibtex': '@Article{Guermazi2021FacialMR,\n author = {Radhouane Guermazi and Taoufik Ben Abdallah and Mohamed Hammami},\n journal = {J. Vis. Commun. Image Represent.},\n pages = {103183},\n title = {Facial micro-expression recognition based on accordion spatio-temporal representation and random forests},\n volume = {79},\n year = {2021}\n}\n'}","[{'authorId': '3359353', 'name': 'Radhouane Guermazi'}, {'authorId': '17319524', 'name': 'Taoufik Ben Abdallah'}, {'authorId': '153185504', 'name': 'Mohamed Hammami'}]"
874,49820a5500b7e6fbb8d77d642c6360857da09cef,The Influence of Conversational Agents on Socially Desirable Responding,"Conversational agents (CAs) are becoming an increasingly common component in many information systems. The ubiquity of CAs in cell phones, entertainment systems, and messaging applications has led to a growing need to understand how design choices made when developing CAs influence user interactions. In this study, we explore the use case of CAs that gather potentially sensitive information from people—for example, in a medical interview. Using a laboratory experiment, we examine the influence of CA responsiveness and embodiment on the answers people give in response to sensitive and non-sensitive questions. The results show that for sensitive questions, the responsiveness of the CA increased the social desirability of the responses given by participants.",2018.0,47.0,30.0,True,"{'url': 'http://scholarspace.manoa.hawaii.edu/bitstream/10125/49925/1/paper0038.pdf', 'status': None}",{'pages': '1-10'},"{'bibtex': '@Inproceedings{Schuetzler2018TheIO,\n author = {Ryan M. Schuetzler and J. Giboney and G. M. Grimes and J. Nunamaker},\n pages = {1-10},\n title = {The Influence of Conversational Agents on Socially Desirable Responding},\n year = {2018}\n}\n'}","[{'authorId': '50818348', 'name': 'Ryan M. Schuetzler'}, {'authorId': '2436820', 'name': 'J. Giboney'}, {'authorId': '145026915', 'name': 'G. M. Grimes'}, {'authorId': '1752841', 'name': 'J. Nunamaker'}]"
875,49d07082a104a22bd66b3ae5133175ee2e49e82b,Better game characters by design : a psychological approach,"* About the Author* Foreword by Tim Schafer* Preface* About the DVD*I First Impressions* What Is Covered and Why* Who Will Find Part I Most Useful* Overview of Key Concepts* Take-Aways from Part I*1 Social Surface*1.1 What Is Covered and Why*1.2 The Psychological Principles*1.3 Design Pointers*1.4 Interview: Gonzalo Frasca*1.5 Summary and What Is Next*1.6 Exercises*1.7 Further Reading*2 Practical Questions - Dominance, Friendliness, and Personality*2.1 What Is Covered and Why*2.2 The Psychological Principles*2.3 Design Pointers*2.4 Summary and What Is Next*2.5 Exercises*2.6 Further Reading*II Focus on the Player* What Is Covered and Why* Who Will Find Part II Most Useful* Overview of Key Concepts* Take-Aways from Part II*3 Culture*3.1 What Is Covered and Why*3.2 The Psychological Principles*3.3 Design Pointers*3.4 Interview: Ryoichi Hasegawa and Roppyaku Tsurumi of Sony*3.5 Interview: Lewis Johnson*3.6 Summary and What Is Next*3.7 Exercises*3.8 Further Reading*4 Gender*4.1 What Is Covered and Why*4.2 The Psychological Principles*4.3 Design Pointers*4.4 Interviews with Gamers - Personal Perspectives*4.5 Summary and What Is Next*4.6 Exercises*4.7 Further Reading*III Using a Character's Social Equipment* What Is Covered and Why* Who Will Find Part III Most Useful* Overview of Key Concepts* Take-Aways from Part III*5 The Face*5.1 What Is Covered and Why*5.2 The Psychological Principles*5.3 Design Pointers*5.4 Summary and What Is Next*5.5 Exercises*5.6 Further Reading*6 The Body*6.1 What Is Covered and Why*6.2 The Psychological Principles*6.3 Design Pointers*6.4 Interview: Chuck Clanton*6.5 Summary and What Is Next*6.6 Exercise*6.7 Further Reading*7 The Voice*7.1 What Is Covered and Why*7.2 The Psychological Principles*7.3 Design Pointers*7.4 Further Directions - Emotion Detection*7.5 Interview: MIT Media Lab's Zeynep Inanoglu and Ron Caneel*7.6 Summary and What Is Next*7.7 Exercise*7.8 Further Reading*7.9 Answers to Exercises*IV Characters in Action* What Is Covered and Why* Who Will Find Part IV Most Useful* Overview of Key Concepts* Take-Aways from Part IV*8 Player-Characters*8.1 What Is Covered and Why*8.2 The Psychological Principles*8.3 Design Pointers*8.4 Interview: Marc Laidlaw*8.5 Summary and What Is Next*8.6 Exercises*8.7 Further Reading*8.8 Acknowledgments*9 Nonplayer-Characters*9.1 What Is Covered and Why*9.2 The Psychological Principles*9.3 Dimensions of Social Roles and NPCs*9.4 Common Social Roles in Games*9.5 Design Guidelines*9.6 Summary and What Is Next*9.7 Exercises*9.8 Further Reading*V Putting It All Together* What Is Covered and Why* Who Will Find Part V Most Useful* Overview of Key Concepts* Take-Aways from Part V*10 Process*10.1 What Is Covered and Why*10.2 Arguments for Bringing a Social-Psychological Approach to Game Development*10.3 The Development Time Line*10.4 Building in the Social-Psychological Approach*10.5 Interview: Tim Schafer*10.6 Summary and What Is Next*10.7 Further Reading*11 Evaluation*11.1 What Is Covered and Why*11.2 The Psychological Principles*11.3 Current Evaluation Practice in Game Design: Market Research and Play Testing*11.4 Taking Design to the Next Level with Preproduction Evaluation*11.5 A Note on Postproduction Evaluation*11.6 Evaluation Checklist*11.7 Games Usability Perspectives*11.8 Interview: Randy Pagulayan*11.9 Interview: Nicole Lazzaro*11.10 Affective Sensing: An Evaluation Method for the Future?*11.11 Summary*11.12 Exercises*11.13 Further Reading * Appendix* Index",2006.0,0.0,68.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Isbister2006BetterGC,\n author = {K. Isbister},\n title = {Better game characters by design : a psychological approach},\n year = {2006}\n}\n'}","[{'authorId': '1740889', 'name': 'K. Isbister'}]"
876,49decc507915ae123621a6213277990c2e0b8e13,Review of micro-expression spotting and recognition in video sequences,,2021.0,83.0,15.0,True,,"{'volume': '3', 'pages': '1-17', 'name': 'Virtual Real. Intell. Hardw.'}","{'bibtex': '@Article{Pan2021ReviewOM,\n author = {Hang Pan and Lun Xie and Zhiliang Wang and B. Liu and Minghao Yang and J. Tao},\n journal = {Virtual Real. Intell. Hardw.},\n pages = {1-17},\n title = {Review of micro-expression spotting and recognition in video sequences},\n volume = {3},\n year = {2021}\n}\n'}","[{'authorId': '46326993', 'name': 'Hang Pan'}, {'authorId': '143971861', 'name': 'Lun Xie'}, {'authorId': '2108080548', 'name': 'Zhiliang Wang'}, {'authorId': '48265485', 'name': 'B. Liu'}, {'authorId': '2740129', 'name': 'Minghao Yang'}, {'authorId': '37670752', 'name': 'J. Tao'}]"
877,49f9ba2a1699e105ec651b480f91c59af73d7e8f,On signalling that it's your turn to speak☆,,1974.0,16.0,198.0,False,,"{'volume': '10', 'pages': '234-247', 'name': 'Journal of Experimental Social Psychology'}","{'bibtex': ""@Article{Duncan1974OnST,\n author = {Starkey Duncan and G. Niederehe},\n journal = {Journal of Experimental Social Psychology},\n pages = {234-247},\n title = {On signalling that it's your turn to speak☆},\n volume = {10},\n year = {1974}\n}\n""}","[{'authorId': '48949057', 'name': 'Starkey Duncan'}, {'authorId': '5255944', 'name': 'G. Niederehe'}]"
878,49fc6a156e6c0c7f00ab4309f133adb99f1c3530,Emotion elicitation using films,"Abstract Researchers interested in emotion have long struggled with the problem of how to elicit emotional responses in the laboratory. In this article, we summarise five years of work to develop a set of films that reliably elicit each of eight emotional states (amusement, anger, contentment, disgust, fear, neutral, sadness, and surprise). After evaluating over 250 films, we showed selected film clips to an ethnically diverse sample of 494 English-speaking subjects. We then chose the two best films for each of the eight target emotions based on the intensity and discreteness of subjects' responses to each film. We found that our set of 16 films successfully elicited amusement, anger, contentment. disgust, sadness, surprise, a relatively neutral state, and, to a lesser extent, fear. We compare this set of films with another set recently described by Philippot (1993), and indicate that detailed instructions for creating our set of film stimuli will be provided on request.",1995.0,78.0,2481.0,False,,"{'volume': '9', 'pages': '87-108', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Gross1995EmotionEU,\n author = {J. Gross and R. Levenson},\n journal = {Cognition & Emotion},\n pages = {87-108},\n title = {Emotion elicitation using films},\n volume = {9},\n year = {1995}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}, {'authorId': '2001910', 'name': 'R. Levenson'}]"
880,4a3207d19b45552332b084d0dc39ce5134c6f82e,Analysis of eye gaze pattern of infants at risk of autism spectrum disorder using Markov models,"This paper presents the possibility of using pattern recognition algorithms of infant gaze patterns at six months of age among children at high risk for an autism spectrum disorder (ASD). ASDs, which must be diagnosed by 3 years of age, are characterized by communication and interaction impairments which frequently involve disturbances of visual attention and gaze patterning. We used video cameras to record the face-to-face interactions of 32 infant subjects with their parents. The video was manually coded to determine the eye gaze pattern of infants by marking where the infant was looking in each frame (either at their parent's face or away from their parent's face). In order to identify infants ASD diagnosis at three years, we analyzed infant eye gaze patterns at six months. Variable-order Markov Models (VMM) were used to create models for typically developing comparison children as well as children with an ASD. The models correctly classified infants who did and did not develop an ASD diagnosis with an accuracy rate of 93.75 percent. Employing an assessment tool at a very young age offers the hope of early intervention, potentially mitigating the effects of the disorder throughout the rest of the child's life.",2011.0,16.0,19.0,False,,"{'pages': '282-287', 'name': '2011 IEEE Workshop on Applications of Computer Vision (WACV)'}","{'bibtex': '@Article{Alie2011AnalysisOE,\n author = {David Alie and M. Mahoor and W. Mattson and Daniel R. Anderson and D. Messinger},\n journal = {2011 IEEE Workshop on Applications of Computer Vision (WACV)},\n pages = {282-287},\n title = {Analysis of eye gaze pattern of infants at risk of autism spectrum disorder using Markov models},\n year = {2011}\n}\n'}","[{'authorId': '1849265', 'name': 'David Alie'}, {'authorId': '145531712', 'name': 'M. Mahoor'}, {'authorId': '144009444', 'name': 'W. Mattson'}, {'authorId': '47965400', 'name': 'Daniel R. Anderson'}, {'authorId': '1874236', 'name': 'D. Messinger'}]"
881,4a393ea8f6d50cabf24e017e59a88a8f7845ccd7,Simulation of the Emotion Dynamics in a Group of Agents in an Evacuation Situation,,2010.0,28.0,47.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-00692147/file/PRACSYS-2010_Le_et_al.pdf', 'status': None}",{'pages': '604-619'},"{'bibtex': '@Inproceedings{Minh2010SimulationOT,\n author = {L. V. Minh and C. Adam and Richard Canal and B. Gaudou and Hô Tuòng Vinh and P. Taillandier},\n pages = {604-619},\n title = {Simulation of the Emotion Dynamics in a Group of Agents in an Evacuation Situation},\n year = {2010}\n}\n'}","[{'authorId': '2145238780', 'name': 'L. V. Minh'}, {'authorId': '2236335', 'name': 'C. Adam'}, {'authorId': '2281462', 'name': 'Richard Canal'}, {'authorId': '1735938', 'name': 'B. Gaudou'}, {'authorId': '2186675', 'name': 'Hô Tuòng Vinh'}, {'authorId': '1788938', 'name': 'P. Taillandier'}]"
882,4a4a799a39af5ae7372e722d5fcc8489939ca5a2,AVATAR ”autism: Virtual agents to augment relationships in children”,"The purpose of this article is to propose the use of semipersonalized Virtual Agents as a therapeutic support for children with Autistic Spectrum Disorder. The contribution of this work is in the raised hybrid model that combines artificial intelligence and human intelligence. We review the main technologies used in the diagnosis and treatment of autism. Then we focus on the use of Virtual Agents as a means of interaction. Finally, the AVATAR Project is presented as an integral solution to improve the social skills of children with autism.",2017.0,27.0,6.0,False,,"{'pages': '1-4', 'name': '2017 IEEE XXIV International Conference on Electronics, Electrical Engineering and Computing (INTERCON)'}","{'bibtex': '@Article{Guerrero-Vásquez2017AVATARV,\n author = {L. F. Guerrero-Vásquez and J. Bravo-Torres and M. López-Nores},\n journal = {2017 IEEE XXIV International Conference on Electronics, Electrical Engineering and Computing (INTERCON)},\n pages = {1-4},\n title = {AVATAR ”autism: Virtual agents to augment relationships in children”},\n year = {2017}\n}\n'}","[{'authorId': '1384430360', 'name': 'L. F. Guerrero-Vásquez'}, {'authorId': '1398154358', 'name': 'J. Bravo-Torres'}, {'authorId': '1403802069', 'name': 'M. López-Nores'}]"
883,4a4dc23d9e6a37c443e04d928c0ef29740b6e158,"Handbook of Attachment: Theory, Research, and Clinical Applications",,2001.0,0.0,1122.0,False,,"{'volume': '63', 'pages': '588', 'name': 'Journal of Marriage and Family'}","{'bibtex': '@Article{Bell2001HandbookOA,\n author = {K. L. Bell},\n journal = {Journal of Marriage and Family},\n pages = {588},\n title = {Handbook of Attachment: Theory, Research, and Clinical Applications},\n volume = {63},\n year = {2001}\n}\n'}","[{'authorId': '46412398', 'name': 'K. L. Bell'}]"
884,4a554da55fd9ff76c99e25d2ce937b225dc1100c,A survey of named entity recognition and classification,"This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.",2007.0,84.0,2617.0,False,,"{'volume': '30', 'pages': '3-26', 'name': 'Lingvisticae Investigationes'}","{'bibtex': '@Article{Nadeau2007ASO,\n author = {David Nadeau and S. Sekine},\n journal = {Lingvisticae Investigationes},\n pages = {3-26},\n title = {A survey of named entity recognition and classification},\n volume = {30},\n year = {2007}\n}\n'}","[{'authorId': '40421028', 'name': 'David Nadeau'}, {'authorId': '1714612', 'name': 'S. Sekine'}]"
885,4a56cb6c5cb7c60caf5e585d27a8e5f2c7a689ee,"Underground Coal Mine Disasters 1900 - 2010: Events, Responses, and a Look to the Future","This paper captures almost 110 years of history of underground coal mine disasters in the United States. The deadly disasters of the first ten years of the twentieth century led to the U.S. Congress founding the U.S. Bureau of Mines (USBM) in 1910. The authors examine the changing trends in mine disasters including the frequency of fatalities, causal types, the responses to those disasters and most importantly, the growing body of research on human behavior in mine emergencies. Emphasis is on the future - integrating the research on human behavior in disasters into the mining industry. This research includes the integration of the judgment decision- making process, communication, leadership in escape, expectations training, incident command center issues including fatigue, shifts and leadership, plus issues concerning the introduction of refuge chambers into U.S. mines. The authors suggest that a key factor in meeting the goal of increasing successful mine escape and rescue while decreasing fatalities and injuries lies in the field of social-psychological research and human behavior interventions.",2010.0,19.0,29.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Brnich2010UndergroundCM,\n author = {M. Brnich and Kathleen M. Kowalski-Trakofker},\n title = {Underground Coal Mine Disasters 1900 - 2010: Events, Responses, and a Look to the Future},\n year = {2010}\n}\n'}","[{'authorId': '13530702', 'name': 'M. Brnich'}, {'authorId': '1448466172', 'name': 'Kathleen M. Kowalski-Trakofker'}]"
887,4a5f0c5c7d1b404cbb3a717e5581d86ff29025de,Reinforcement Learning: A Tutorial Survey and Recent Advances,"In the last few years, reinforcement learning (RL), also called adaptive (or approximate) dynamic programming, has emerged as a powerful tool for solving complex sequential decision-making problems in control theory. Although seminal research in this area was performed in the artificial intelligence (AI) community, more recently it has attracted the attention of optimization theorists because of several noteworthy success stories from operations management. It is on large-scale and complex problems of dynamic optimization, in particular the Markov decision problem (MDP) and its variants, that the power of RL becomes more obvious. It has been known for many years that on large-scale MDPs, the curse of dimensionality and the curse of modeling render classical dynamic programming (DP) ineffective. The excitement in RL stems from its direct attack on these curses, which allows it to solve problems that were considered intractable via classical DP in the past. The success of RL is due to its strong mathematical roots in the principles of DP, Monte Carlo simulation, function approximation, and AI. Topics treated in some detail in this survey are temporal differences, Q-learning, semi-MDPs, and stochastic games. Several recent advances in RL, e.g., policy gradients and hierarchical RL, are covered along with references. Pointers to numerous examples of applications are provided. This overview is aimed at uncovering the mathematical roots of this science so that readers gain a clear understanding of the core concepts and are able to use them in their own research. The survey points to more than 100 references from the literature.",2009.0,140.0,294.0,True,"{'url': 'http://web.mst.edu/~gosavia/joc.pdf', 'status': None}","{'volume': '21', 'pages': '178-192', 'name': 'INFORMS J. Comput.'}","{'bibtex': '@Article{Gosavi2009ReinforcementLA,\n author = {A. Gosavi},\n journal = {INFORMS J. Comput.},\n pages = {178-192},\n title = {Reinforcement Learning: A Tutorial Survey and Recent Advances},\n volume = {21},\n year = {2009}\n}\n'}","[{'authorId': '2536655', 'name': 'A. Gosavi'}]"
888,4a62a517a45897be4291dc75d825c5ab2ae7e1da,Fun and fair: influencing turn-taking in a multi-party game with a virtual agent,"Language-based interfaces for children hold great promise in education, therapy, and entertainment. An important subset of these interfaces includes those with a virtual agent that mediates the interaction. When participants are groups of children, the agent will need to exert a certain amount of turn-taking control to ensure that all group members participate and benefit from the experience, but must do so without being so overtly directive as to undermine the children's enjoyment of and engagement in the task. We present a hierarchy of nonverbal and verbal behaviors that a virtual agent can employ flexibly when passing the conversational turn. When used effectively, these behaviors can equalize participation, and potentially decrease the amount of overlapping speech among participants, improving automatic speech recognition in turn. We evaluated the behaviors by having children play a language-based game twice, once with a flexible host and once with an inflexible host that did not have access to the behaviors. Post-game opinion cards revealed no difference between the conditions with respect to fun or likability of the host, despite the flexible agent eliciting more evenly distributed play.",2013.0,13.0,17.0,False,,{'name': 'Proceedings of the 12th International Conference on Interaction Design and Children'},"{'bibtex': '@Article{Andrist2013FunAF,\n author = {Sean Andrist and Iolanda Leite and J. Lehman},\n journal = {Proceedings of the 12th International Conference on Interaction Design and Children},\n title = {Fun and fair: influencing turn-taking in a multi-party game with a virtual agent},\n year = {2013}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '2142730', 'name': 'J. Lehman'}]"
890,4a6e6ac6103002030da08b723be0cca025686d37,Usability and acceptability of technology for community-dwelling older adults with mild cognitive impairment and dementia: a systematic literature review,"Background The objective of this review was to obtain an overview of the technologies that have been explored with older adults with mild cognitive impairment and dementia (MCI/D), current knowledge on the usability and acceptability of such technologies, and how people with MCI/D and their family carers (FCs) were involved in these studies. Materials and methods Primary studies published between 2007 and 2017 that explored the use of technologies for community-dwelling people with MCI/D were identified through five databases: MEDLINE, PsycINFO, Embase, AMED, and CINAHL. Twenty-nine out of 359 papers met the criteria for eligibility. We used the Mixed Methods Appraisal Tool for quality assessment. Results A wide range of technologies was presented in the 29 studies, sorted into four domains: 1) safe walking indoors and outdoors; 2) safe living; 3) independent living; and 4) entertainment and social communication. The current state of knowledge regarding usability and acceptability reveals that even if researchers are aware of these concepts and intend to measure usability and acceptability, they seem difficult to assess. Terms such as “user friendliness” and “acceptance” were used frequently. User participation in the 29 studies was high. Persons with MCI/D, FCs, and staff/other older adults were involved in focus groups, workshops, and interviews as part of the preimplementation process. Conclusion Research regarding technologies to support people with MCI/D seems optimistic, and a wide range of technologies has been evaluated in homes with people with MCI/D and their FCs. A major finding was the importance of including people with MCI/D and their FCs in research, in order to learn about required design features to enhance usability and acceptability. Surprisingly, very few studies reported on the consequences of technology use with regard to quality of life, occupational performance, or human dignity.",2018.0,70.0,124.0,True,"{'url': 'https://www.dovepress.com/getfile.php?fileID=41905', 'status': None}","{'volume': '13', 'pages': '863 - 886', 'name': 'Clinical Interventions in Aging'}","{'bibtex': '@Article{Holthe2018UsabilityAA,\n author = {Torhild Holthe and Liv Halvorsrud and D. Karterud and Kari-Anne Hoel and A. Lund},\n journal = {Clinical Interventions in Aging},\n pages = {863 - 886},\n title = {Usability and acceptability of technology for community-dwelling older adults with mild cognitive impairment and dementia: a systematic literature review},\n volume = {13},\n year = {2018}\n}\n'}","[{'authorId': '8298739', 'name': 'Torhild Holthe'}, {'authorId': '4262176', 'name': 'Liv Halvorsrud'}, {'authorId': '14561772', 'name': 'D. Karterud'}, {'authorId': '2051567307', 'name': 'Kari-Anne Hoel'}, {'authorId': '144388483', 'name': 'A. Lund'}]"
891,4a76e941dbac0585cd355cd6e6af00b6164461ac,Affect and Emotion,,2013.0,39.0,147.0,False,,"{'volume': '', 'pages': '452-464', 'name': ''}","{'bibtex': '@Inproceedings{Anderson2013AffectAE,\n author = {B. Anderson},\n pages = {452-464},\n title = {Affect and Emotion},\n year = {2013}\n}\n'}","[{'authorId': '145514522', 'name': 'B. Anderson'}]"
892,4a7b8fb8cb69f53c6c2ac3ae518a974773240b94,A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data,,2005.0,43.0,3847.0,False,,"{'volume': '25', 'pages': '1325-1335', 'name': 'NeuroImage'}","{'bibtex': '@Article{Eickhoff2005ANS,\n author = {S. Eickhoff and K. Stephan and H. Mohlberg and C. Grefkes and G. Fink and K. Amunts and K. Zilles},\n journal = {NeuroImage},\n pages = {1325-1335},\n title = {A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data},\n volume = {25},\n year = {2005}\n}\n'}","[{'authorId': '1717616', 'name': 'S. Eickhoff'}, {'authorId': '1715046', 'name': 'K. Stephan'}, {'authorId': '2766350', 'name': 'H. Mohlberg'}, {'authorId': '1824186', 'name': 'C. Grefkes'}, {'authorId': '38644159', 'name': 'G. Fink'}, {'authorId': '1751796', 'name': 'K. Amunts'}, {'authorId': '144897358', 'name': 'K. Zilles'}]"
893,4a808df6a798b41de27c4e584000d45fc444d507,Traveller–Intercultural training with intelligent agents for young adults,"In this paper we describe Traveller, an intercultural training tool for young adults. Traveller is based on an original theoretical framework which focuses on key concepts of intercultural training. By progressing through a creative story, users are able to engage via a novel interaction paradigm with intelligent virtual characters that incorporate different simulated cultures which can 
lead to misunderstandings and sometimes conflicts. Through the use of an innovative evaluation approach, users will gain a greater understanding of the behavioural differences between these characters, and thereby learn to become more effective at dealing with misunderstandings due to differences in culture.",2013.0,24.0,12.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Degens2013TravellerInterculturalTW,\n author = {D. M. Degens and G. Hofstede and S. Mascarenhas and André Silva and Ana Paiva and Felix Kistler and E. André and A. Świderska and Eva G. Krumhuber and Arvid Kappas and Colette Hume and L. Hall and R. Aylett},\n title = {Traveller–Intercultural training with intelligent agents for young adults},\n year = {2013}\n}\n'}","[{'authorId': '70181201', 'name': 'D. M. Degens'}, {'authorId': '2584600', 'name': 'G. Hofstede'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '2493926', 'name': 'André Silva'}, {'authorId': '145136630', 'name': 'Ana Paiva'}, {'authorId': '2844803', 'name': 'Felix Kistler'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '3114113', 'name': 'A. Świderska'}, {'authorId': '50755536', 'name': 'Eva G. Krumhuber'}, {'authorId': '1742554', 'name': 'Arvid Kappas'}, {'authorId': '48159628', 'name': 'Colette Hume'}, {'authorId': '144160845', 'name': 'L. Hall'}, {'authorId': '1732377', 'name': 'R. Aylett'}]"
894,4aa9b1c9078b596c5daaf4d51e729c16163d5dac,Emotion and personal space: Neural correlates of approach‐avoidance tendencies to different facial expressions as a function of coldhearted psychopathic traits,"In social interactions, humans are expected to regulate interpersonal distance in response to the emotion displayed by others. Yet, the neural mechanisms implicated in approach‐avoidance tendencies to distinct emotional expressions have not been fully described. Here, we investigated the neural systems implicated in regulating the distance to different emotions, and how they vary as a function of empathy. Twenty‐three healthy participants assessed for psychopathic traits underwent fMRI scanning while they viewed approaching and withdrawing angry, fearful, happy, sad and neutral faces. Participants were also asked to set the distance to those faces on a computer screen, and to adjust the physical distance from the experimenter outside the scanner. Participants kept the greatest distances from angry faces, and shortest from happy expressions. This was accompanied by increased activation in the dorsomedial prefrontal and orbitofrontal cortices, inferior frontal gyrus, and temporoparietal junction for angry and happy expressions relative to the other emotions. Irrespective of emotion, longer distances were kept from approaching faces, which was associated with increased activation in the amygdala and insula, as well as parietal and prefrontal regions. Amygdala activation was positively correlated with greater preferred distances to angry, fearful and sad expressions. Moreover, participants scoring higher on coldhearted psychopathic traits (lower empathy) showed reduced amygdala activation to sad expressions. These findings elucidate the neural mechanisms underlying social approach‐avoidance, and how they are related to variations in empathy. Hum Brain Mapp 38:1492–1506, 2017. © 2016 Wiley Periodicals, Inc.",2017.0,88.0,27.0,True,"{'url': 'https://europepmc.org/articles/pmc6866784?pdf=render', 'status': None}","{'volume': '38', 'name': 'Human Brain Mapping'}","{'bibtex': '@Article{Vieira2017EmotionAP,\n author = {Joana B. Vieira and T. Tavares and A. Marsh and D. Mitchell},\n journal = {Human Brain Mapping},\n title = {Emotion and personal space: Neural correlates of approach‐avoidance tendencies to different facial expressions as a function of coldhearted psychopathic traits},\n volume = {38},\n year = {2017}\n}\n'}","[{'authorId': '80682861', 'name': 'Joana B. Vieira'}, {'authorId': '3500182', 'name': 'T. Tavares'}, {'authorId': '22358598', 'name': 'A. Marsh'}, {'authorId': '2928107', 'name': 'D. Mitchell'}]"
895,4abedd09e2410921a4174883b89dc8d020e7f929,Fuzzy Rules for Events Perception and Emotions in an Agent Architecture,"In complex simulations, multi-agents systems allow to model virtual humans with an explicit cognitive process representation. However, this cognitive process is hard to model and is therefore generally simplified in an application-dependant way. In order to improve the realism of individual and collective behavior of these agents, we propose to integrate the perception of events and the computation of agents emotions in a fuzzy framework. The modeling of the perception and its effect on emotions through fuzzy rules enables the agents to consider properly the virtual environment. We show how different kinds of fuzzy rules can help in the calculus of emotions. Computation of emotions is based on the evaluation of events’ occurrence. Once the events are perceived by the agents, our method uses the desirability of these events to compute emotions relevant to crisis situations. We illustrate this model with a traffic simulation example.",2011.0,32.0,6.0,True,,{'pages': '657-664'},"{'bibtex': '@Inproceedings{Jones2011FuzzyRF,\n author = {H. Jones and Julien Saunier and D. Lourdeaux},\n pages = {657-664},\n title = {Fuzzy Rules for Events Perception and Emotions in an Agent Architecture},\n year = {2011}\n}\n'}","[{'authorId': '31600786', 'name': 'H. Jones'}, {'authorId': '1708997', 'name': 'Julien Saunier'}, {'authorId': '1790872', 'name': 'D. Lourdeaux'}]"
896,4ac16699f2562446ed77b0b15cce8fc021de5df6,Chronometric explorations of mind,,1978.0,0.0,2185.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Posner1978ChronometricEO,\n author = {M. Posner},\n title = {Chronometric explorations of mind},\n year = {1978}\n}\n'}","[{'authorId': '2262729', 'name': 'M. Posner'}]"
897,4ac4404957de150ae9d18d8bddbc8df1b23415ad,Nonparametric discriminant analysis and nearest neighbor classification,,2003.0,17.0,120.0,False,,"{'volume': '24', 'pages': '2743-2749', 'name': 'Pattern Recognit. Lett.'}","{'bibtex': '@Article{Bressan2003NonparametricDA,\n author = {M. Bressan and Jordi Vitrià},\n journal = {Pattern Recognit. Lett.},\n pages = {2743-2749},\n title = {Nonparametric discriminant analysis and nearest neighbor classification},\n volume = {24},\n year = {2003}\n}\n'}","[{'authorId': '3454299', 'name': 'M. Bressan'}, {'authorId': '1793079', 'name': 'Jordi Vitrià'}]"
898,4ad6f75115b02de4f1bc674322ab9f1ead4e70d7,Multitask Learning for Complaint Identification and Sentiment Analysis,,2021.0,58.0,19.0,False,,"{'volume': '14', 'pages': '212-227', 'name': 'Cognitive Computation'}","{'bibtex': '@Article{Singh2021MultitaskLF,\n author = {A. Singh and S. Saha and Mohammed Hasanuzzaman and K. Dey},\n journal = {Cognitive Computation},\n pages = {212-227},\n title = {Multitask Learning for Complaint Identification and Sentiment Analysis},\n volume = {14},\n year = {2021}\n}\n'}","[{'authorId': '1561332263', 'name': 'A. Singh'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '144231505', 'name': 'Mohammed Hasanuzzaman'}, {'authorId': '144710196', 'name': 'K. Dey'}]"
899,4aede0d0759ca6c6eef53ffa357cbc326af60814,Effects of Virtual Human Animation on Emotion Contagion in Simulated Inter-Personal Experiences,"We empirically examined the impact of virtual human animation on the emotional responses of participants in a medical virtual reality system for education in the signs and symptoms of patient deterioration. Participants were presented with one of two virtual human conditions in a between-subjects experiment, static (non-animated) and dynamic (animated). Our objective measures included the use of psycho-physical Electro Dermal Activity (EDA) sensors, and subjective measures inspired by social psychology research included the Differential Emotions Survey (DES IV) and Positive and Negative Affect Survey (PANAS). We analyzed the quantitative and qualitative measures associated with participants' emotional state at four distinct time-steps in the simulated interpersonal experience as the virtual patient's medical condition deteriorated. Results suggest that participants in the dynamic condition with animations exhibited a higher sense of co-presence and greater emotional response as compared to participants in the static condition, corresponding to the deterioration in the medical condition of the virtual patient. Negative affect of participants in the dynamic condition increased at a higher rate than for participants in the static condition. The virtual human animations elicited a stronger response in negative emotions such as anguish, fear, and anger as the virtual patient's medical condition worsened.",2014.0,29.0,48.0,False,,"{'volume': '20', 'pages': '626-635', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Wu2014EffectsOV,\n author = {Yanxiang Wu and Sabarish V. Babu and R. Armstrong and Jeffrey W. Bertrand and Jun Luo and Tania Roy and S. Daily and Lauren Cairco and L. Hodges and Tracy Fasolino},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {626-635},\n title = {Effects of Virtual Human Animation on Emotion Contagion in Simulated Inter-Personal Experiences},\n volume = {20},\n year = {2014}\n}\n'}","[{'authorId': '2134149709', 'name': 'Yanxiang Wu'}, {'authorId': '144403504', 'name': 'Sabarish V. Babu'}, {'authorId': '143923500', 'name': 'R. Armstrong'}, {'authorId': '33296377', 'name': 'Jeffrey W. Bertrand'}, {'authorId': '2116813593', 'name': 'Jun Luo'}, {'authorId': '144455263', 'name': 'Tania Roy'}, {'authorId': '1959041', 'name': 'S. Daily'}, {'authorId': '2725134', 'name': 'Lauren Cairco'}, {'authorId': '1710833', 'name': 'L. Hodges'}, {'authorId': '3043236', 'name': 'Tracy Fasolino'}]"
900,4afd3665d73fcd852cf9176e44d6131dcdf89868,User interface design,,1990.0,12.0,705.0,False,,"{'pages': 'I-XXIII, 1-470'}","{'bibtex': '@Inproceedings{Thimbleby1990UserID,\n author = {H. Thimbleby},\n pages = {I-XXIII, 1-470},\n title = {User interface design},\n year = {1990}\n}\n'}","[{'authorId': '1779970', 'name': 'H. Thimbleby'}]"
901,4b149a326e38b9237077d794a0d5f5b4865efacf,"AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild","Automated affective computing in the wild setting is a challenging problem in computer vision. Existing annotated databases of facial expressions in the wild are small and mostly cover discrete emotions (aka the categorical model). There are very limited annotated facial databases for affective computing in the continuous dimensional model (e.g., valence and arousal). To meet this need, we collected, annotated, and prepared for public distribution a new database of facial emotions in the wild (called AffectNet). AffectNet contains more than 1,000,000 facial images from the Internet by querying three major search engines using 1,250 emotion related keywords in six different languages. About half of the retrieved images were manually annotated for the presence of seven discrete facial expressions and the intensity of valence and arousal. AffectNet is by far the largest database of facial expression, valence, and arousal in the wild enabling research in automated facial expression recognition in two different emotion models. Two baseline deep neural networks are used to classify images in the categorical model and predict the intensity of valence and arousal. Various evaluation metrics show that our deep neural network baselines can perform better than conventional machine learning methods and off-the-shelf facial expression recognition systems.",2017.0,72.0,1114.0,True,"{'url': 'https://arxiv.org/pdf/1708.03985', 'status': None}","{'volume': '10', 'pages': '18-31', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Mollahosseini2017AffectNetAD,\n author = {A. Mollahosseini and Behzad Hasani and M. Mahoor},\n journal = {IEEE Transactions on Affective Computing},\n pages = {18-31},\n title = {AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild},\n volume = {10},\n year = {2017}\n}\n'}","[{'authorId': '2314025', 'name': 'A. Mollahosseini'}, {'authorId': '9706655', 'name': 'Behzad Hasani'}, {'authorId': '145531712', 'name': 'M. Mahoor'}]"
902,4b2126d5f0584788b67514b3e509e1acb1ef92a8,Real-time speech-driven face animation with expressions using neural networks,"A real-time speech-driven synthetic talking face provides an effective multimodal communication interface in distributed collaboration environments. Nonverbal gestures such as facial expressions are important to human communication and should be considered by speech-driven face animation systems. In this paper, we present a framework that systematically addresses facial deformation modeling, automatic facial motion analysis, and real-time speech-driven face animation with expression using neural networks. Based on this framework, we learn a quantitative visual representation of the facial deformations, called the motion units (MUs). A facial deformation can be approximated by a linear combination of the MUs weighted by MU parameters (MUPs). We develop an MU-based facial motion tracking algorithm which is used to collect an audio-visual training database. Then, we construct a real-time audio-to-MUP mapping by training a set of neural networks using the collected audio-visual training database. The quantitative evaluation of the mapping shows the effectiveness of the proposed approach. Using the proposed method, we develop the functionality of real-time speech-driven face animation with expressions for the iFACE system. Experimental results show that the synthetic expressive talking face of the iFACE system is comparable with a real face in terms of the effectiveness of their influences on bimodal human emotion perception.",2002.0,57.0,107.0,True,"{'url': 'http://www.cs.brandeis.edu/~hong/Research/e_paper/IEEE_TNN2002/ieee_tnn_2002.pdf', 'status': None}","{'volume': '13 4', 'pages': '\n          916-27\n        ', 'name': 'IEEE transactions on neural networks'}","{'bibtex': '@Article{Hong2002RealtimeSF,\n author = {P. Hong and Zhen Wen and Thomas S. Huang},\n journal = {IEEE transactions on neural networks},\n pages = {\n          916-27\n        },\n title = {Real-time speech-driven face animation with expressions using neural networks},\n volume = {13 4},\n year = {2002}\n}\n'}","[{'authorId': '8824068', 'name': 'P. Hong'}, {'authorId': '2067930817', 'name': 'Zhen Wen'}, {'authorId': '153652752', 'name': 'Thomas S. Huang'}]"
903,4b5e889135b0f52d02089be7e3251fa397b83829,Fuzzy sets,,1996.0,0.0,34895.0,False,,"{'volume': '', 'pages': '394', 'name': ''}","{'bibtex': '@Inproceedings{Zadeh1996FuzzyS,\n author = {L. Zadeh},\n pages = {394},\n title = {Fuzzy sets},\n year = {1996}\n}\n'}","[{'authorId': '145718274', 'name': 'L. Zadeh'}]"
904,4b693046e4db3f8e68812c42a8601545b0104000,ALTRIRAS: A Computer Game for Training Children with Autism Spectrum Disorder in the Recognition of Basic Emotions,"This paper presents a computer game developed to assist children with Autism Spectrum Disorder (ASD) to recognize facial expressions associated with the four basic emotions: joy, sadness, anger, and surprise. This game named ALTRIRAS is a role-playing game (RPG), a kind of game pointed out by the literature as the most suitable for these children for being more social than competitive. It has recreational settings built with 2D graphic interface to keep the children’s attention and an access control and a register mechanism to allow the monitoring of the child’s progress. The data collection of the functional, nonfunctional, psychological, and educational requirements, as well as the evaluation of its consistency and usability, was made by a multidisciplinary team consisting of five experts in each of the following expertises: pedagogy, psychology, psychopedagogy, and game development. The effectiveness test of the game was performed by 10 children with ASD and 28 children with neurotypical development, which were separated into control and experimental groups, respectively. All experts and children with neurotypical development answered the System Usability Scale (SUS) questionnaire after playing the game. The results were positive, between experts and volunteers regarding their acceptance. However, the time of exposure to the game in children with ASD should be increased to effective assistance in the recognition of facial expressions.",2019.0,49.0,25.0,True,"{'url': 'https://downloads.hindawi.com/journals/ijcgt/2019/4384896.pdf', 'status': None}","{'volume': '2019', 'pages': '4384896:1-4384896:16', 'name': 'Int. J. Comput. Games Technol.'}","{'bibtex': '@Article{Almeida2019ALTRIRASAC,\n author = {L. M. Almeida and Diego Pereira da Silva and D. P. Theodório and W. W. Silva and S. C. M. Rodrigues and T. A. Scardovelli and A. P. Silva and M. Bissaco},\n journal = {Int. J. Comput. Games Technol.},\n pages = {4384896:1-4384896:16},\n title = {ALTRIRAS: A Computer Game for Training Children with Autism Spectrum Disorder in the Recognition of Basic Emotions},\n volume = {2019},\n year = {2019}\n}\n'}","[{'authorId': '145001031', 'name': 'L. M. Almeida'}, {'authorId': '2115857218', 'name': 'Diego Pereira da Silva'}, {'authorId': '123022073', 'name': 'D. P. Theodório'}, {'authorId': '120274659', 'name': 'W. W. Silva'}, {'authorId': '38721234', 'name': 'S. C. M. Rodrigues'}, {'authorId': '3120200', 'name': 'T. A. Scardovelli'}, {'authorId': '92281342', 'name': 'A. P. Silva'}, {'authorId': '2083197', 'name': 'M. Bissaco'}]"
905,4b80501bc072c12e4e51cb8db0b626c4974e6ca0,Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport,"Nonconscious behavioral mimicry occurs when a person unwittingly imitates the behaviors of another person. This mimicry has been attributed to a direct link between perceiving a behavior and performing that same behavior. The current experiments explored whether having a goal to affiliate augments the tendency to mimic the behaviors of interaction partners. Experiment 1 demonstrated that having an affiliation goal increases nonconscious mimicry, and Experiment 2 further supported this proposition by demonstrating that people who have unsuccessfully attempted to affiliate in an interaction subsequently exhibit more mimicry than those who have not experienced such a failure. Results suggest that behavioral mimicry may be part of a person's repertoire of behaviors, used nonconsciously, when there is a desire to create rapport.",2003.0,25.0,1202.0,False,,"{'volume': '14', 'pages': '334 - 339', 'name': 'Psychological Science'}","{'bibtex': '@Article{Lakin2003UsingNB,\n author = {Jessica L. Lakin and T. Chartrand},\n journal = {Psychological Science},\n pages = {334 - 339},\n title = {Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport},\n volume = {14},\n year = {2003}\n}\n'}","[{'authorId': '5622454', 'name': 'Jessica L. Lakin'}, {'authorId': '6026289', 'name': 'T. Chartrand'}]"
906,4b8771d931aa26d9565fdaa24ae17fa73ea46ae4,Games and Learning Alliance,,2013.0,72.0,13.0,True,"{'url': 'https://research.ou.nl/files/939666/Acquiring%2021st%20Century%20Skills_4CID_2014_GALA-.pdf', 'status': None}",{'volume': '8605'},"{'bibtex': '@Inproceedings{Gloria2013GamesAL,\n author = {A. D. Gloria},\n title = {Games and Learning Alliance},\n volume = {8605},\n year = {2013}\n}\n'}","[{'authorId': '1696279', 'name': 'A. D. Gloria'}]"
907,4b90006f2ba4c0e1a9be1a6a6eb19f921a0748ba,"An Interdependent Model of Personality, Motivation, Emotion, and Mood for Intelligent Virtual Agents","Building intelligent agents that can believably interact with humans is a difficult yet important task in a host of applications, including therapy, education, and entertainment. We submit that in order to enhance believability, the agent's affective state should be accurately modeled and should realistically influence the agent's behavior. We propose a computational model of affect which incorporates an empirically-based interplay between its various affective components - personality, motivation, emotion, and mood. Further, our model captures a number of salient mechanisms that are observable in humans and that influence the agent's behavior. We are therefore hopeful that our model will facilitate more engaging and meaningful human-agent interactions. We evaluate our model and illustrate its efficacy, as well as the importance of the different components in the model and their interplay.",2019.0,37.0,17.0,True,"{'url': 'https://zenodo.org/record/2672901/files/supplemental_material.pdf', 'status': 'GREEN'}",{'name': 'Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Shvo2019AnIM,\n author = {Maayan Shvo and Jakob Buhmann and Mubbasir Kapadia},\n booktitle = {International Conference on Intelligent Virtual Agents},\n journal = {Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents},\n title = {An Interdependent Model of Personality, Motivation, Emotion, and Mood for Intelligent Virtual Agents},\n year = {2019}\n}\n'}","[{'authorId': '40959392', 'name': 'Maayan Shvo'}, {'authorId': '51147349', 'name': 'Jakob Buhmann'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
909,4b9452bb4265ccf8e196c45fac3ccf141524d2f9,IDEAS4Games: Building Expressive Virtual Characters for Computer Games,,2008.0,35.0,43.0,False,,{'pages': '426-440'},"{'bibtex': '@Inproceedings{Gebhard2008IDEAS4GamesBE,\n author = {Patrick Gebhard and M. Schröder and Marcela Charfuelan and C. Endres and Michael Kipp and Sathish Pammi and M. Rumpler and O. Türk},\n pages = {426-440},\n title = {IDEAS4Games: Building Expressive Virtual Characters for Computer Games},\n year = {2008}\n}\n'}","[{'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '2191162', 'name': 'Marcela Charfuelan'}, {'authorId': '93808977', 'name': 'C. Endres'}, {'authorId': '145616714', 'name': 'Michael Kipp'}, {'authorId': '2345401', 'name': 'Sathish Pammi'}, {'authorId': '46682269', 'name': 'M. Rumpler'}, {'authorId': '2057037', 'name': 'O. Türk'}]"
910,4bd36617c310a2eaddc5ad95826da34d1e175760,Experiences of Game-Based Learning and Reviewing History of the Experience Using Player's Emotions,"In this paper, we discuss whether the history of a learning experience, containing action and emotion information, is useful for review of the experience in game-based learning using virtual space. We developed a game-based story generation system that automatically generates scripts in real time by using a player's emotions and actions. The system has two functions: a game-based experiential learning environment and automatic story generation. The system provides the player with a virtual world and a virtual tool operated by using a hand controller and a display. The system recognizes the player's real-time emotions through facial expressions, and it outputs reactions based on these emotions and actions via a knowledge-based system when the player operates the tool. Then, it outputs scripts based on the emotions and the history of actions. We evaluated the system by conducting experiments with university students as subjects. As a result, subjects found the stories generated by this system interesting because they were based on the player's experience in the game and used the player's behavioral history and emotions. If we consider this as a record of the learning experience, the learning history is an impressive record accompanied by emotions. Thus, historical information that records the actions and emotions of the learner in real time is considered effective because it allows the learner to recall his or her own experiences after the game experience. The results suggest that the historical information, including the learner's real-time actions and emotions, is helpful for review in learning. There is a possibility that experiential learning through games using virtual spaces, such as the one used in this study, will become widespread in the future. In such cases, it will be necessary to examine the learning effects of using historical information with emotions. Therefore, we believe that the results and discussions in this study will be useful for experiential learning using virtual spaces.",2022.0,26.0,1.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frai.2022.874106/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Artificial Intelligence'}","{'bibtex': ""@Article{Sumi2022ExperiencesOG,\n author = {Kaoru Sumi and Shusuke Sato},\n journal = {Frontiers in Artificial Intelligence},\n title = {Experiences of Game-Based Learning and Reviewing History of the Experience Using Player's Emotions},\n volume = {5},\n year = {2022}\n}\n""}","[{'authorId': '145441214', 'name': 'Kaoru Sumi'}, {'authorId': '152639869', 'name': 'Shusuke Sato'}]"
911,4bf061f85d1495448f83b5e3bb6ec7e30bfe818d,The persona effect: affective impact of animated pedagogical agents,"Animated pedagogical agents that inhabit interactive learning environments can exhibit strikingly lifelike behaviors. In addition to providing problem-solving advice in response to students’ activities in the learning environment, these agents may also be able to play a powerful motivational role. To design the most effective agent-based learning environment software, it is essential to understand how students perceive an animated pedagogical agent with regard to affective dimensions such as encouragement, utility, credibility, and clarity. This paper describes a study of the affective impact of animated pedagogical agents on students’ learning experiences. One hundred middle school students interacted with animated pedagogical agents to assess their perception of agents’ affective characteristics. The study revealed the persona eflecr, which is that the presence of a lifelike character in an interactive learning environment~ven one that is not expressive— can have a strong positive effect on student’s perception of their learning experience. The study also demonstrates the interesting effect of multiple types of explanatory behaviors on both affective perception and learning performance.",1997.0,23.0,956.0,False,,{'name': 'Proceedings of the ACM SIGCHI Conference on Human factors in computing systems'},"{'bibtex': '@Article{Lester1997ThePE,\n author = {James C. Lester and S. Converse and Susan H. Kahler and S. T. Barlow and Brian A. Stone and Ravinder S. Bhogal},\n journal = {Proceedings of the ACM SIGCHI Conference on Human factors in computing systems},\n title = {The persona effect: affective impact of animated pedagogical agents},\n year = {1997}\n}\n'}","[{'authorId': '2249310517', 'name': 'James C. Lester'}, {'authorId': '3047047', 'name': 'S. Converse'}, {'authorId': '2249314519', 'name': 'Susan H. Kahler'}, {'authorId': '2249325955', 'name': 'S. T. Barlow'}, {'authorId': '143980642', 'name': 'Brian A. Stone'}, {'authorId': '2687019', 'name': 'Ravinder S. Bhogal'}]"
913,4c1f0185446e631f760a6a435a98c915554f9dcb,Pictures of Facial Affect,,1976.0,0.0,4421.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1976PicturesOF,\n author = {P. Ekman},\n title = {Pictures of Facial Affect},\n year = {1976}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
914,4c22319e4ba5c74e81408f4757a810fed85a983b,"Valence-Arousal Model based Emotion Recognition using EEG, peripheral physiological signals and Facial Expression","Emotion recognition plays a particularly important role in the field of artificial intelligence. However, the emotional recognition of electroencephalogram (EEG) in the past was only a unimodal or a bimodal based on EEG. This paper aims to use deep learning to perform emotional recognition based on the multimodal with valence-arousal dimension of EEG, peripheral physiological signals, and facial expressions. The experiment uses the complete data of 18 experimenters in the Database for Emotion Analysis Using Physiological Signals (DEAP) to classify the EEG, peripheral physiological signals and facial expression video in unimodal and multimodal fusion. The experiment demonstrates that Multimodal fusion's accuracy is excelled that in unimodal and bimodal fusion. The multimodal compensates for the defects of unimodal and bimodal information sources.",2020.0,30.0,7.0,False,,{'name': 'Proceedings of the 4th International Conference on Machine Learning and Soft Computing'},"{'bibtex': '@Article{Zhu2020ValenceArousalMB,\n author = {Qi Zhu and G. Lu and Jingjie Yan},\n journal = {Proceedings of the 4th International Conference on Machine Learning and Soft Computing},\n title = {Valence-Arousal Model based Emotion Recognition using EEG, peripheral physiological signals and Facial Expression},\n year = {2020}\n}\n'}","[{'authorId': '144400492', 'name': 'Qi Zhu'}, {'authorId': '33351491', 'name': 'G. Lu'}, {'authorId': '2840913', 'name': 'Jingjie Yan'}]"
915,4c35ee9ae51c4cf00dc3183d462e43b6f0685f86,Digital Chameleons,"Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.",2005.0,29.0,327.0,False,,"{'volume': '16', 'pages': '814 - 819', 'name': 'Psychological Science'}","{'bibtex': '@Article{Bailenson2005DigitalC,\n author = {J. Bailenson and N. Yee},\n journal = {Psychological Science},\n pages = {814 - 819},\n title = {Digital Chameleons},\n volume = {16},\n year = {2005}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '38811484', 'name': 'N. Yee'}]"
916,4c3ca19de3a47f4fec7428c437fca9a198e453ab,Augmented Reality Applications for Education: Five Directions for Future Research,,2017.0,23.0,27.0,False,,{'pages': '402-414'},"{'bibtex': '@Inproceedings{Garzón2017AugmentedRA,\n author = {Juan Garzón and J. Pavón and S. Baldiris},\n pages = {402-414},\n title = {Augmented Reality Applications for Education: Five Directions for Future Research},\n year = {2017}\n}\n'}","[{'authorId': '145500740', 'name': 'Juan Garzón'}, {'authorId': '145879358', 'name': 'J. Pavón'}, {'authorId': '1728461', 'name': 'S. Baldiris'}]"
917,4c790c71219f6be248a3d426347bf7c4e3a0a6c4,"The Montreal Cognitive Assessment, MoCA: A Brief Screening Tool For Mild Cognitive Impairment","Objectives: To develop a 10‐minute cognitive screening tool (Montreal Cognitive Assessment, MoCA) to assist first‐line physicians in detection of mild cognitive impairment (MCI), a clinical state that often progresses to dementia.",2005.0,23.0,16369.0,False,,"{'volume': '53', 'name': 'Journal of the American Geriatrics Society'}","{'bibtex': '@Article{Nasreddine2005TheMC,\n author = {Z. Nasreddine and N. Phillips and Valérie Bédirian and S. Charbonneau and V. Whitehead and Isabelle Collin and J. Cummings and H. Chertkow},\n journal = {Journal of the American Geriatrics Society},\n title = {The Montreal Cognitive Assessment, MoCA: A Brief Screening Tool For Mild Cognitive Impairment},\n volume = {53},\n year = {2005}\n}\n'}","[{'authorId': '4789895', 'name': 'Z. Nasreddine'}, {'authorId': '2227151', 'name': 'N. Phillips'}, {'authorId': '49488473', 'name': 'Valérie Bédirian'}, {'authorId': '46626405', 'name': 'S. Charbonneau'}, {'authorId': '51356427', 'name': 'V. Whitehead'}, {'authorId': '2073409937', 'name': 'Isabelle Collin'}, {'authorId': '2084085', 'name': 'J. Cummings'}, {'authorId': '114187679', 'name': 'H. Chertkow'}]"
918,4c940c7726ddd513e95d808442a77396d71e9f07,Universal dimensions of social cognition: warmth and competence,,2007.0,69.0,3246.0,False,,"{'volume': '11', 'pages': '77-83', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Fiske2007UniversalDO,\n author = {S. Fiske and Amy J. C. Cuddy and P. Glick},\n journal = {Trends in Cognitive Sciences},\n pages = {77-83},\n title = {Universal dimensions of social cognition: warmth and competence},\n volume = {11},\n year = {2007}\n}\n'}","[{'authorId': '1885803', 'name': 'S. Fiske'}, {'authorId': '3513501', 'name': 'Amy J. C. Cuddy'}, {'authorId': '48151160', 'name': 'P. Glick'}]"
919,4c97102fe8d31dc506af642ae0902251b1406a59,Tuple centres for the coordination of Internet agents,"The paper presents the TUCSON coordination model for Internet applications based on network-aware (possibly mobile) agents. The model is based on the notion of tuple centre, an enhanced tuple space whose behaviour can be extended according to the application needs. Everv node of a TUCSON environment provides its local communication space, made up of a multiplicity of independently-programmable tuple centres. This makes it possible to embed global system properties into the space of components’ interaction, thus enabling flexible cooperation over space and time between agents, and permitting to easily face many issues critical to Internet applications, such as heterogeneity and dynamicity of the execution environments.",1999.0,36.0,78.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/298151.298231', 'status': None}",{'pages': '183-190'},"{'bibtex': '@Inproceedings{Omicini1999TupleCF,\n author = {Andrea Omicini and F. Zambonelli},\n pages = {183-190},\n title = {Tuple centres for the coordination of Internet agents},\n year = {1999}\n}\n'}","[{'authorId': '3119182', 'name': 'Andrea Omicini'}, {'authorId': '1684412', 'name': 'F. Zambonelli'}]"
920,4ca718817b5ae1f97db940b490ec1e68131254d8,Mobile Robot Motion Control from Demonstration and Corrective Feedback,,2010.0,123.0,34.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Mobile_Robot_Motion_Control_from_Demonstration_and_Corrective_Feedback/6555563/1/files/12037793.pdf', 'status': None}",{'pages': '431-450'},"{'bibtex': '@Inproceedings{Argall2010MobileRM,\n author = {B. Argall and Brett Browning and M. Veloso},\n pages = {431-450},\n title = {Mobile Robot Motion Control from Demonstration and Corrective Feedback},\n year = {2010}\n}\n'}","[{'authorId': '1836885', 'name': 'B. Argall'}, {'authorId': '1699032', 'name': 'Brett Browning'}, {'authorId': '1956361', 'name': 'M. Veloso'}]"
921,4ca84d9ab54ac8efabc6c52e320292852a16adee,Behavioral appropriateness and situational constraint as dimensions of social behavior.,"In the first of two studies, 52 subjects were required to judge the appropriateness of IS behaviors in each of IS situations in a behavior-situation matrix. Differences among behaviors, situations, and their interaction contributed substantial proportions of the total variance in judgments. The concepts of behavioral appropriateness and situational constraint were offered to account for the differences obtained among behaviors and situations, respectively. A second study using a new sample of 42 subjects and different methods of measurement provided initial construct validity evidence for the concepts. Implications of these results for the construction of situational response hierarchies, the development of behavior and situation taxonomies, and causal attribution were discussed.",1974.0,31.0,208.0,False,,"{'volume': '30', 'pages': '579-586', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Price1974BehavioralAA,\n author = {R. Price and D. L. Bouffard},\n journal = {Journal of Personality and Social Psychology},\n pages = {579-586},\n title = {Behavioral appropriateness and situational constraint as dimensions of social behavior.},\n volume = {30},\n year = {1974}\n}\n'}","[{'authorId': '143809316', 'name': 'R. Price'}, {'authorId': '113907614', 'name': 'D. L. Bouffard'}]"
922,4ca85470edf8a5499921ac35209887e013b64a9b,Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game,,2005.0,39.0,172.0,False,,"{'volume': '62', 'pages': '231-245', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Prendinger2005UsingHP,\n author = {H. Prendinger and Junichiro Mori and M. Ishizuka},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {231-245},\n title = {Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game},\n volume = {62},\n year = {2005}\n}\n'}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '40645851', 'name': 'Junichiro Mori'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
924,4cb462b2d7a161908556bf09eadebebf9aae8122,Evaluating Affective Feedback of the 3D Agent Max in a Competitive Cards Game,,2005.0,19.0,71.0,True,"{'url': 'http://www.miv.t.u-tokyo.ac.jp/papers/christian_helmut_ACII_05.pdf', 'status': None}",{'pages': '466-473'},"{'bibtex': '@Inproceedings{Becker2005EvaluatingAF,\n author = {Christian Becker and H. Prendinger and M. Ishizuka and I. Wachsmuth},\n pages = {466-473},\n title = {Evaluating Affective Feedback of the 3D Agent Max in a Competitive Cards Game},\n year = {2005}\n}\n'}","[{'authorId': '2068695177', 'name': 'Christian Becker'}, {'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
926,4cc7d53edbf76313a65f32b4cb0347d528868d98,Emotion Regulation,,,59.0,926.0,False,,,"{'bibtex': '@Misc{None,\n author = {C. Mazefsky and S. White},\n title = {Emotion Regulation}\n}\n'}","[{'authorId': '3501849', 'name': 'C. Mazefsky'}, {'authorId': '2197231', 'name': 'S. White'}]"
929,4cc8c4b33d4af568b2fbe5fd42766b9b4b1d1f18,Emotion-oriented requirements engineering,,2017.0,0.0,14.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Curumsing2017EmotionorientedRE,\n author = {M. Curumsing},\n title = {Emotion-oriented requirements engineering},\n year = {2017}\n}\n'}","[{'authorId': '3292250', 'name': 'M. Curumsing'}]"
930,4ccb7d15e4262ec25383a5266e22a72a76deec94,Language Learning Enhanced by Massive Multiple Online Role-Playing Games (MMORPGs) and the Underlying Behavioral and Neural Mechanisms,"Massive Multiple Online Role-Playing Games (MMORPGs) have increased in popularity among children, juveniles, and adults since MMORPGs’ appearance in this digital age. MMORPGs can be applied to enhancing language learning, which is drawing researchers’ attention from different fields and many studies have validated MMORPGs’ positive effect on language learning. However, there are few studies on the underlying behavioral or neural mechanism of such effect. This paper reviews the educational application of the MMORPGs based on relevant macroscopic and microscopic studies, showing that gamers’ overall language proficiency or some specific language skills can be enhanced by real-time online interaction with peers and game narratives or instructions embedded in the MMORPGs. Mechanisms underlying the educational assistant role of MMORPGs in second language learning are discussed from both behavioral and neural perspectives. We suggest that attentional bias makes gamers/learners allocate more cognitive resources toward task-related stimuli in a controlled or an automatic way. Moreover, with a moderating role played by activation of reward circuit, playing the MMORPGs may strengthen or increase functional connectivity from seed regions such as left anterior insular/frontal operculum (AI/FO) and visual word form area to other language-related brain areas.",2017.0,89.0,24.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnhum.2017.00095/pdf', 'status': None}","{'volume': '11', 'name': 'Frontiers in Human Neuroscience'}","{'bibtex': '@Article{Zhang2017LanguageLE,\n author = {Yongjun Zhang and Hongwen Song and Xiaoming Liu and D. Tang and Yue-e Chen and Xiaochu Zhang},\n journal = {Frontiers in Human Neuroscience},\n title = {Language Learning Enhanced by Massive Multiple Online Role-Playing Games (MMORPGs) and the Underlying Behavioral and Neural Mechanisms},\n volume = {11},\n year = {2017}\n}\n'}","[{'authorId': '2108259783', 'name': 'Yongjun Zhang'}, {'authorId': '3856135', 'name': 'Hongwen Song'}, {'authorId': '2108960012', 'name': 'Xiaoming Liu'}, {'authorId': '32497575', 'name': 'D. Tang'}, {'authorId': '49068778', 'name': 'Yue-e Chen'}, {'authorId': '8442660', 'name': 'Xiaochu Zhang'}]"
931,4cfd967688cb5efe7489ef9ecff51630d55db528,GRETA. A BELIEVABLE EMBODIED CONVERSATIONAL AGENT,,2005.0,53.0,150.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-03342893/file/IVA_GALA_2021%281%29.pdf', 'status': None}","{'volume': '27', 'pages': '3-25', 'name': ''}","{'bibtex': '@Inproceedings{Poggi2005GRETAAB,\n author = {I. Poggi and C. Pelachaud and F. D. Rosis and V. Carofiglio and B. D. Carolis},\n pages = {3-25},\n title = {GRETA. A BELIEVABLE EMBODIED CONVERSATIONAL AGENT},\n volume = {27},\n year = {2005}\n}\n'}","[{'authorId': '1802126', 'name': 'I. Poggi'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1807752', 'name': 'F. D. Rosis'}, {'authorId': '1694255', 'name': 'V. Carofiglio'}, {'authorId': '1739256', 'name': 'B. D. Carolis'}]"
934,4d193b61afb62301652f8fb41fafaa2a85898062,"Achieving rapport with turn-by-turn, user-responsive emotional coloring",,2011.0,53.0,98.0,True,"{'url': 'http://www.cs.utep.edu/nigel/papers/specom-jaime.pdf', 'status': None}","{'volume': '53', 'pages': '1137-1148', 'name': 'Speech Commun.'}","{'bibtex': '@Article{Acosta2011AchievingRW,\n author = {Jaime C. Acosta and Nigel G. Ward},\n journal = {Speech Commun.},\n pages = {1137-1148},\n title = {Achieving rapport with turn-by-turn, user-responsive emotional coloring},\n volume = {53},\n year = {2011}\n}\n'}","[{'authorId': '2061081005', 'name': 'Jaime C. Acosta'}, {'authorId': '32987878', 'name': 'Nigel G. Ward'}]"
935,4d1c5ed6d0255f3f6e520f4eef786ce578685bc9,Fully Embodied Conversational Avatars: Making Communicative Behaviors Autonomous,,1999.0,30.0,138.0,False,,"{'volume': '2', 'pages': '45-64', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Cassell1999FullyEC,\n author = {Justine Cassell and H. Vilhjálmsson},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {45-64},\n title = {Fully Embodied Conversational Avatars: Making Communicative Behaviors Autonomous},\n volume = {2},\n year = {1999}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}]"
936,4d357ffc1cf60d3f34b5345899619882791474bb,Deep Reinforcement Learning for General Video Game AI,"The General Video Game AI (GVGAI) competition and its associated software framework provides a way of benchmarking AI algorithms on a large number of games written in a domain-specific description language. While the competition has seen plenty of interest, it has so far focused on online planning, providing a forward model that allows the use of algorithms such as Monte Carlo Tree Search. In this paper, we describe how we interface GVGAI to the OpenAI Gym environment, a widely used way of connecting agents to reinforcement learning problems. Using this interface, we characterize how widely used implementations of several deep reinforcement learning algorithms fare on a number of GVGAI games. We further analyze the results to provide a first indication of the relative difficulty of these games relative to each other, and relative to those in the Arcade Learning Environment under similar conditions.",2018.0,24.0,102.0,True,"{'url': 'https://arxiv.org/pdf/1806.02448', 'status': None}","{'pages': '1-8', 'name': '2018 IEEE Conference on Computational Intelligence and Games (CIG)'}","{'bibtex': '@Article{Torrado2018DeepRL,\n author = {R. Torrado and Philip Bontrager and J. Togelius and Jialin Liu and Diego Pérez-Liébana},\n journal = {2018 IEEE Conference on Computational Intelligence and Games (CIG)},\n pages = {1-8},\n title = {Deep Reinforcement Learning for General Video Game AI},\n year = {2018}\n}\n'}","[{'authorId': '15099359', 'name': 'R. Torrado'}, {'authorId': '14171685', 'name': 'Philip Bontrager'}, {'authorId': '1810053', 'name': 'J. Togelius'}, {'authorId': '46701122', 'name': 'Jialin Liu'}, {'authorId': '1389741275', 'name': 'Diego Pérez-Liébana'}]"
937,4d3bca2565bba38799c41bf8cdf995a072123e6e,"Gaze cueing of attention: visual attention, social cognition, and individual differences.","During social interactions, people's eyes convey a wealth of information about their direction of attention and their emotional and mental states. This review aims to provide a comprehensive overview of past and current research into the perception of gaze behavior and its effect on the observer. This encompasses the perception of gaze direction and its influence on perception of the other person, as well as gaze-following behavior such as joint attention, in infant, adult, and clinical populations. Particular focus is given to the gaze-cueing paradigm that has been used to investigate the mechanisms of joint attention. The contribution of this paradigm has been significant and will likely continue to advance knowledge across diverse fields within psychology and neuroscience.",2007.0,367.0,1211.0,True,"{'url': 'https://europepmc.org/articles/pmc1950440?pdf=render', 'status': None}","{'volume': '133 4', 'pages': '\n          694-724\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Frischen2007GazeCO,\n author = {A. Frischen and A. Bayliss and S. Tipper},\n journal = {Psychological bulletin},\n pages = {\n          694-724\n        },\n title = {Gaze cueing of attention: visual attention, social cognition, and individual differences.},\n volume = {133 4},\n year = {2007}\n}\n'}","[{'authorId': '47039010', 'name': 'A. Frischen'}, {'authorId': '40471972', 'name': 'A. Bayliss'}, {'authorId': '6674999', 'name': 'S. Tipper'}]"
938,4d49dc7078e9a69eddfbd9f81e13fbc97db3827f,Does the Directivity of a Virtual Agent's Speech Influence the Perceived Social Presence?,"When interacting and communicating with virtual agents in immersive environments, the agents’ behavior should be believable and authentic. Thereby, one important aspect is a convincing auralization of their speech. In this work-in-progress paper a study design to evaluate the effect of adding directivity to speech sound source on the perceived social presence of a virtual agent is presented. Therefore, we describe the study design and discuss first results of a prestudy as well as consequential improvements of the design.",2018.0,11.0,6.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Wendt2018DoesTD,\n author = {J. Wendt and Tom Vierjahn and T. Kuhlen and Andrea Bonsch and J. Stienen and B. Weyers and M. Vorländer},\n title = {Does the Directivity of a Virtual Agent's Speech Influence the Perceived Social Presence?},\n year = {2018}\n}\n""}","[{'authorId': '39812907', 'name': 'J. Wendt'}, {'authorId': '2824434', 'name': 'Tom Vierjahn'}, {'authorId': '144483066', 'name': 'T. Kuhlen'}, {'authorId': '1753088713', 'name': 'Andrea Bonsch'}, {'authorId': '52111617', 'name': 'J. Stienen'}, {'authorId': '2638784', 'name': 'B. Weyers'}, {'authorId': '2979397', 'name': 'M. Vorländer'}]"
939,4d83f1a79d10f683515396d45553e10b07f3ecf1,Virtual Reality Exposure Therapy for Social Phobia: A Pilot Study in Evoking Fear in a Virtual World,"Social phobia is one of the most commonly occurring anxiety disorders. Standard treatment or training involves gradually exposing patients to social situations they fear. These exposures are however difficult to control for a therapist. An alternative therefore might be to use virtual reality exposure. This paper reports on the design of four social scenarios (a bus stop, a train station, a clothing shop, and a reception desk of a restaurant) implemented in virtual reality. Results of a pilot evaluation with none phobic patients suggest that these worlds might be able to evoke anxiety, and manipulating the verbal and behavioural responses of the human avatars might give therapists the ability to control the level of fear evoking elements in these worlds.",2008.0,16.0,23.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Brinkman2008VirtualRE,\n author = {Willem-Paul Brinkman and C. van der Mast and Daniel De Vliegher},\n title = {Virtual Reality Exposure Therapy for Social Phobia: A Pilot Study in Evoking Fear in a Virtual World},\n year = {2008}\n}\n'}","[{'authorId': '145495942', 'name': 'Willem-Paul Brinkman'}, {'authorId': '2052500457', 'name': 'C. van der Mast'}, {'authorId': '2252116170', 'name': 'Daniel De Vliegher'}]"
940,4db1ab1b3b826c926ab617c32ab3d4cfc6f908e0,Sharing Solutions: Persistence and Grounding in Multimodal Collaborative Problem Solving,"This article reports on an exploratory study of the relationship between grounding and problem solving in multimodal computer-mediated collaboration. This article examines two different media, a shared whiteboard and a MOO environment that includes a text chat facility. A study was done on how the acknowledgment rate (how often partners give feedback of having perceived, understood, and accepted partner's contributions) varies according to the media and the content of interactions. It was expected that the whiteboard would serve to draw schemata that disambiguate chat utterances. Instead, results show that the whiteboard is primarily used to represent the state of problem solving and the chat is used for grounding information created on the whiteboard. These results are interpreted in terms of persistence: More persistent information is exchanged through the more persistent medium. The whiteboard was used as a shared memory rather than a grounding tool.",2006.0,23.0,252.0,True,"{'url': 'https://telearn.archives-ouvertes.fr/hal-00190698/file/Dillenbourg-Pierre-2006a.pdf', 'status': None}","{'volume': '15', 'pages': '121 - 151', 'name': 'Journal of the Learning Sciences'}","{'bibtex': '@Article{Dillenbourg2006SharingSP,\n author = {P. Dillenbourg and D. Traum},\n journal = {Journal of the Learning Sciences},\n pages = {121 - 151},\n title = {Sharing Solutions: Persistence and Grounding in Multimodal Collaborative Problem Solving},\n volume = {15},\n year = {2006}\n}\n'}","[{'authorId': '1799133', 'name': 'P. Dillenbourg'}, {'authorId': '144518646', 'name': 'D. Traum'}]"
941,4dd5d605ff615e9be0362eb29d39029a62d4c134,Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in Temperament,,1996.0,62.0,1279.0,False,,"{'volume': '14', 'pages': '261-292', 'name': 'Current Psychology'}","{'bibtex': '@Article{Mehrabian1996PleasurearousaldominanceAG,\n author = {A. Mehrabian},\n journal = {Current Psychology},\n pages = {261-292},\n title = {Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in Temperament},\n volume = {14},\n year = {1996}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}]"
948,4dd720be505c9557c182684b2d5026ee49dbcca3,Pedagogical Agents that Interact with Learners,"In this paper, we describe a method for pedagogical agents to choose when to interact with learners in interactive learning environments. This method is based on observations of human tutors coaching students in on-line learning tasks. It takes into account the focus of attention of the learner, the learner’s current task, and expected time required to perform the task. A Bayesian network model combines evidence from eye gaze and interface actions to infer learner focus of attention. The attention model is combined with a plan recognizer to detect learner difficulties which warrant intervention. This capability is part of a pedagogical agent able to interact with learners in socially appropriate ways.",2004.0,24.0,12.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Qu2004PedagogicalAT,\n author = {Lei Qu and Ning Wang and M. Rey},\n title = {Pedagogical Agents that Interact with Learners},\n year = {2004}\n}\n'}","[{'authorId': '2056322994', 'name': 'Lei Qu'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '144995564', 'name': 'M. Rey'}]"
949,4ddf4d220e9b0366328b401f3ed83b4fa9db6a5f,Kansei Engineering: A New Consumer-Oriented Technology for Product Development,,2003.0,0.0,41.0,False,,"{'volume': '', 'pages': '25-1-25-14', 'name': ''}","{'bibtex': '@Inproceedings{Nagamachi2003KanseiEA,\n author = {M. Nagamachi},\n pages = {25-1-25-14},\n title = {Kansei Engineering: A New Consumer-Oriented Technology for Product Development},\n year = {2003}\n}\n'}","[{'authorId': '2662596', 'name': 'M. Nagamachi'}]"
950,4df2f94782cd9c96214094977a639968727e8e72,EMA: A process model of appraisal dynamics,,2009.0,63.0,446.0,False,,"{'volume': '10', 'pages': '70-90', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Marsella2009EMAAP,\n author = {S. Marsella and J. Gratch},\n journal = {Cognitive Systems Research},\n pages = {70-90},\n title = {EMA: A process model of appraisal dynamics},\n volume = {10},\n year = {2009}\n}\n'}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
957,4e01a9a52a396967b580ca1c58dc8f38108b08ba,Understanding intelligent agents: analysis and synthesis,"Current views of intelligent agent technologies are reviewed with respect to (a) their general cognitive capabilities and (b) the classic Belief-Desire-Intention (BDI) model. A benchmark agent model is developed as a basis for analyzing and comparing agent systems. PROforma is an agent technology that has grown out of work in modeling medical expertise and the benchmark is used to carry out a case study analysis of this technology, looking at it from three contrasting points of view: logic programming, object-oriented programming and agent-oriented programming. These viewpoints yield different insights into the strengths and weaknesses of PROforma and lead to a clarification and consolidation of the benchmark agent features. The consolidated model offers a useful framework for analysis and comparison of other agent systems in medicine or other domains.",2003.0,45.0,69.0,False,,"{'volume': '16', 'pages': '139-152', 'name': 'AI Commun.'}","{'bibtex': '@Article{Fox2003UnderstandingIA,\n author = {J. Fox and Martin Beveridge and D. Glasspool},\n journal = {AI Commun.},\n pages = {139-152},\n title = {Understanding intelligent agents: analysis and synthesis},\n volume = {16},\n year = {2003}\n}\n'}","[{'authorId': '1690329', 'name': 'J. Fox'}, {'authorId': '29555543', 'name': 'Martin Beveridge'}, {'authorId': '1806431', 'name': 'D. Glasspool'}]"
958,4e3763f6b07efbb3f15cc128be4356599d653f9f,The science of interpersonal touch: An overview,,2010.0,217.0,690.0,False,,"{'volume': '34', 'pages': '246-259', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Gallace2010TheSO,\n author = {A. Gallace and C. Spence},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {246-259},\n title = {The science of interpersonal touch: An overview},\n volume = {34},\n year = {2010}\n}\n'}","[{'authorId': '2508045', 'name': 'A. Gallace'}, {'authorId': '144248893', 'name': 'C. Spence'}]"
959,4e3fbf9d06210b556b27b6ae720266113dac4092,Measuring friendship quality in late adolescents and young adults: McGill Friendship Questionnaires.,"Two studies established the psychometric properties of two friendship questionnaires; one taps respondents' feelings for a friend and satisfaction with the friendship, the other, respondents' assessments of the degree to which a friend fulfills six friendship functions (stimulating companionship, help, intimacy, reliable alliance, self-validation, and emotional security). Factor analysis confirmed the subscale structure of each questionnaire. The subscales showed high internal consistency, distinguished best from casual friends, and did not covary with social desirability. They did covary with the duration of being a best friend and with a self-esteem subscale regarding close friends, but not with other self-esteem measures. Women reported higher positive feelings for their friend than did men, and evaluated the friend higher on friendship functions. Finally, positive feelings and satisfaction covaried with each friendship function subscale. The research here concerns the development and validation of two multi-scale friendship questionnaires-one concerning a respondent's feelings for a friend and friendship, the other concerning the respondent's assessment of the degree to which the friend fulfills six friendship functions. The studies grew out of work on friendship quality in children and young adolescents (Aboud & Mendelson, 1996; Mendelson, Aboud, & Lanthier, 1994). The goal here was to design measures, based on a similar model of friendship, suitable for late adolescents and young adults. Friendships, like other relationships, vary in quality. Although it is difficult to judge friendship quality in behavioral terms, length of the relationship and reciprocated versus nonreciprocated nominations are gross criterion measures of friendship quality. Furthermore, individuals can specify types of friendships, distinguishing, for example, between best friends, good friends, casual friends, and acquaintances (i.e., nonfriends); and such distinctions are also gross criterion measures of quality. Gender also provides a criterion for validating friendship measures, because there is ample evidence that gender differences do exist, with women's friendships characterized by better overall quality, closeness, enjoyment, intimacy, and nurturance (e.g., Bell, 1991; Jones, 1991; Sapadin, 1988; Wright & Scanlon, 1991). Thus, any friendship measure should be sensitive enough to differentiate women's and men's friendships. At the most general level, relationships can be assessed as positive or negative. In these terms, friendship scales have been developed to assess attachment to the friend and conflict.2 Attachment refers to the special 1This paper was completed in 1997; we subsequently published a brief version (Mendelson & Aboud, 1999). Part of the research was presented as a poster (Measuring Friendship Quality in Late Adolescents and Young Adults) at the American Psychological Association, Toronto, ON, August, 1996. We heartily thank the following: Jocelyne Andrews, Sophie Beugnot, Lisa Seidel, and Tsafrir Vanounou collected data reported here as part of their undergraduate theses. Rhonda Amsel offered excellent statistical advice. Finally, Barry Corenblum, Richard Koestner, and Debbie Moskowitz constructively criticized a draft of the manuscript. The research was supported by grants from the Social Sciences and Humanities Research Council of Canada and from the Social Sciences Research Grants Subcommittee of the Faculty of Graduate Studies and Research, McGill University. Send correspondence to Morton J. Mendelson (morton.mendelson@mcgill.ca). 2Conflict, which might be considered the opposite of attachment, can certainly be an important aspect of any relationship. Indeed, friends often have conflicts, but may nonetheless be able to resolve them equitably and without bad feelings (Hartup, Laursen, Stewart & Eastenson, 1988). Thus, numerous friendship measures have subscales related to conflict or conflict resolution (Bukowski et al., 1994; Furman & Adler, 1982; Furman McGill Friendship Questionnaires 2 feelings that individuals have for a friend. Mutual liking has often been used as a criterion to identify a friend, but a separate subscale may be used to assess liking in greater depth (cf. Bukowski, Hoza, & Boivin, 1994; Sharabany, 1974; Wright, 1991). One of the measures reported here, taps positive feelings for the friend and satisfaction with the friendship, which will be viewed as criterion measures of undifferentiated friendship quality. Although the two measures are conceptually distinct, they should covary highly because they are both assumed to reflect overall friendship quality. However, an important assumption guiding research on friendship is that it is possible to assess specific qualities of friendships. Consideration of the theoretical foundations of various scales suggested that a framework based on friendship functions (Furman & Buhrmester, 1985; Parker & Asher, 1989)--rather than specific behaviors (Bukowski, et al. 1994; Sharabany, Gershoni, & Hofman, 1981) or motives (Wright, 1991)-is preferable for a number of reasons: It provides a broader scope, yields a better ideal for a mature relationship, and makes it possible to develop analogous, if not identical, measures for different developmental stages. Within a functional approach, a friend is seen as a source of certain social, emotional and instrumental resources that a person seeks (Asher & Parker, 1989; Weiss, 1974). In a review of existing measures (Aboud & Mendelson, 1992), we sought to define friendship functions that were theoretically distinct, that distinguished between friends and nonfriends, and that were associated with affection/satisfaction. We identified six relevant functions (stimulating companionship, help, intimacy, reliable alliance, self-validation and, emotional security). It is assumed that individual friends fulfill some, if not all, of these functions, so measures of the different functions should covary. Nonetheless, the following definitions describe what are clearly six conceptually distinguishable functions of friendship: Stimulating Companionship refers to doing things together that arouse enjoyment, amusement, and excitement. This quality seems to be an important expectation of friends at all ages. Some measures have focused mainly on doing things together (Buhrmester, 1990; Bukowski et al., 1994; Parker & Asher, 1989; Sharabany, 1974), but it seems important to stress the fun and excitement in common activities (Jones, 1991; Wright, 1991). Help refers to providing guidance, assistance, information, advice, and other forms of tangible aid necessary to meet needs or goals. Thus, it need not be reciprocal (Jones, 1991). Help has been assessed in specific subscales (Bukowski et al., 1994; Parker & Asher, 1989; Wright, 1991) and it has also been combined with support (Bukowski et al., 1994; Sharabany, 1974). However, the instrumental aspect of support tapped by help is distinguishable from other aspects of support tapped by Emotional Security and Self-Validation. Intimacy refers to sensitivity to the other's needs and states, providing an accepting context in which personal thoughts and feelings can be openly and honestly expressed, and openly and honestly disclosing personal information about oneself. A number of researchers have Intimacy subscales (e.g., Buhrmester & Furman, 1987), although Mannarino (1976) and Buhrmester (1990) assess it as a composite along with companionship. Sharabany's (1974) Sensitivity and Knowing subscale stresses the importance of knowing without any explicit disclosure. Wright (1991) does not include such a subscale except as it pertains to selfaffirmation or the expression of true feelings. Reliable Alliance refers to being able to count on the continuing availability and loyalty of the friend. This was an important dimension underlying Selman's (1980) distinction between a fair-weather friend who would end the relationship if conflict or strains arose and a more durable friend. It is assessed in a specific Conflict and Betrayal subscale (Parker & Asher, 1989) and in a Trust and Loyalty subscale (Sharabany, 1974). Bukowski and colleagues' (1994) Reliable Alliance subscale concerns self-disclosure, which is referred to here & Buhrmester, 1985; Parker and Asher, 1989; Wright, 1991). However, these constructs are not theoretically analogous to the six friendship functions considered here. Therefore, we are currently developing separate instruments to tap negative feelings for a friend and the incidence of conflict and conflict resolution in a friendship. McGill Friendship Questionnaires 3 as Intimacy; but they combine it with a Transcending Problems subscale that is closer to the definition of Reliable Alliance. Self-Validation refers to perceiving the other as reassuring, agreeing, encouraging, listening, and otherwise helping to maintain one's self-image as a competent and worthwhile person. This is often achieved through social comparison and consensual validation of one's attributes and beliefs. Similar items have been referred to as Attachment (Sharabany, 1974), as Ego Support and Self-Affirmation (Wright, 1991), and as Reflected Appraisal (Bukowski et al., 1994), although that was combined with an Affective Bond subscale as part of Closeness. Emotional Security refers to the comfort and confidence provided by the friend in novel or threatening situations. Although the emotional support provided by a friend is considered to be important, only Wright (1991) includes items in a Security subscale to assess perception of the friend as safe and unthreatening because he or she does not betray one's trust or draw attention to one's weaknesses. Besides assessing the respondent's feelings for the friend and satisfaction with the friendship, it seems important to choose between assessing the functions that the friend is perceived to fulfill and the functions that the respondent reportedly fulfills. Most,",1999.0,11.0,275.0,False,,"{'volume': '31', 'pages': '130-132', 'name': 'Canadian Journal of Behavioural Science'}","{'bibtex': '@Article{Mendelson1999MeasuringFQ,\n author = {M. Mendelson and F. Aboud},\n journal = {Canadian Journal of Behavioural Science},\n pages = {130-132},\n title = {Measuring friendship quality in late adolescents and young adults: McGill Friendship Questionnaires.},\n volume = {31},\n year = {1999}\n}\n'}","[{'authorId': '34212255', 'name': 'M. Mendelson'}, {'authorId': '5913573', 'name': 'F. Aboud'}]"
960,4e45f66270407862c8fcd8c1bd5507e09a840b70,"Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances","Emotion is intrinsic to humans and consequently, emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data on platforms such as Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential applications in health-care systems (as a tool for psychological analysis), education (understanding student frustration), and more. In Addition, ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user’s emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However, it is a difficult problem to solve because of several research challenges. In this paper, we discuss these challenges and shed light on recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC.",2019.0,48.0,231.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08764449.pdf', 'status': None}","{'volume': '7', 'pages': '100943-100953', 'name': 'IEEE Access'}","{'bibtex': '@Article{Poria2019EmotionRI,\n author = {Soujanya Poria and Navonil Majumder and Rada Mihalcea and E. Hovy},\n journal = {IEEE Access},\n pages = {100943-100953},\n title = {Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances},\n volume = {7},\n year = {2019}\n}\n'}","[{'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}, {'authorId': '144547315', 'name': 'E. Hovy'}]"
961,4e547c5e3b6fa9b8861e0801ea354b4150d330cd,"The Many Meanings/Aspects of Emotion: Definitions, Functions, Activation, and Regulation","Many psychological scientists and behavioral neuroscientists affirm that “emotion” influences thinking, decision-making, actions, social relationships, well-being, and physical and mental health. Yet there is no consensus on a definition of the word “emotion,” and the present data suggest that it cannot be defined as a unitary concept. Theorists and researchers attribute quite different yet heuristic meanings to “emotion.” They show considerable agreement about emotion activation, functions, and regulation. The central goal of this article is to alert researchers, students, and other consumers of “emotion” research to the multiple meanings or aspects that distinguished scientists attribute to ”emotion,” increase appreciation of its interesting and challenging complexity, and sharpen perspectives on “emotion” and the associated body of literature that is of critical significance to science and society.",2010.0,32.0,458.0,False,,"{'volume': '2', 'pages': '363 - 370', 'name': 'Emotion Review'}","{'bibtex': '@Article{Izard2010TheMM,\n author = {C. Izard},\n journal = {Emotion Review},\n pages = {363 - 370},\n title = {The Many Meanings/Aspects of Emotion: Definitions, Functions, Activation, and Regulation},\n volume = {2},\n year = {2010}\n}\n'}","[{'authorId': '38430881', 'name': 'C. Izard'}]"
962,4e57c5a19ede727045a5d6664ca1be9b8d298e95,The Face of the Chameleon: The Experience of Facial Mimicry for the Mimicker and the Mimickee,"ABSTRACT This research addressed three questions concerning facial mimicry: (a) Does the relationship between mimicry and liking characterize all facial expressions, or is it limited to specific expressions? (b) Is the relationship between facial mimicry and liking symmetrical for the mimicker and the mimickee? (c) Does conscious mimicry have consequences for emotion recognition? A paradigm is introduced in which participants interact over a computer setup with a confederate whose prerecorded facial displays of emotion are synchronized with participants’ behavior to create the illusion of social interaction. In Experiment 1, the confederate did or did not mimic participants’ facial displays of various subsets of basic emotions. Mimicry promoted greater liking for the confederate regardless of which emotions were mimicked. Experiment 2 reversed these roles: participants were instructed to mimic or not to mimic the confederate’s facial displays. Mimicry did not affect liking for the confederate but it did impair emotion recognition.",2015.0,72.0,33.0,True,"{'url': 'https://europepmc.org/articles/pmc4642179?pdf=render', 'status': None}","{'volume': '155', 'pages': '590 - 604', 'name': 'The Journal of Social Psychology'}","{'bibtex': '@Article{Kulesza2015TheFO,\n author = {Wojciech Kulesza and A. Cislak and Robin R. Vallacher and Andrzej Nowak and Martyna Czekiel and S. Bedyńska},\n journal = {The Journal of Social Psychology},\n pages = {590 - 604},\n title = {The Face of the Chameleon: The Experience of Facial Mimicry for the Mimicker and the Mimickee},\n volume = {155},\n year = {2015}\n}\n'}","[{'authorId': '145213848', 'name': 'Wojciech Kulesza'}, {'authorId': '15744706', 'name': 'A. Cislak'}, {'authorId': '3038804', 'name': 'Robin R. Vallacher'}, {'authorId': '49683665', 'name': 'Andrzej Nowak'}, {'authorId': '5195231', 'name': 'Martyna Czekiel'}, {'authorId': '6410603', 'name': 'S. Bedyńska'}]"
964,4e6ac44ad26ae8767bbe73e40d768b8d02382560,How the Timing and Magnitude of Robot Errors Influence Peoples' Trust of Robots in an Emergency Scenario,,2017.0,33.0,48.0,False,,{'pages': '42-52'},"{'bibtex': ""@Inproceedings{Rossi2017HowTT,\n author = {Alessandra Rossi and K. Dautenhahn and K. Koay and M. Walters},\n pages = {42-52},\n title = {How the Timing and Magnitude of Robot Errors Influence Peoples' Trust of Robots in an Emergency Scenario},\n year = {2017}\n}\n""}","[{'authorId': '48369504', 'name': 'Alessandra Rossi'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '1749179', 'name': 'K. Koay'}, {'authorId': '1847981', 'name': 'M. Walters'}]"
965,4f0abe8b1a974885996e8938d9a395c2353894e3,Postural Mirroring and Intergroup Relations,"The present study examined the effects of four types of intergroup orientation on interpersonal postural mirroring both within and between groups. One hundred and four female subjects were assigned to quartets, each made up of two dyads in one of four conditions: (1) Control; (2) coacting; (3) cooperating; and (4) competing. As predicted, results showed greater intergroup relative to intragroup mirroring for cooperating dyads than for competing dyads. Unexpectedly, subjects in the coacting condition showed a significantly higher level of intergroup mirroring than any other condition. Both results are interpreted as evidence that postural mirroring is an obvious yet unobtrusive indicator of openness to interpersonal involvement.",1985.0,8.0,96.0,False,,"{'volume': '11', 'pages': '207 - 217', 'name': 'Personality and Social Psychology Bulletin'}","{'bibtex': '@Article{LaFrance1985PosturalMA,\n author = {M. LaFrance},\n journal = {Personality and Social Psychology Bulletin},\n pages = {207 - 217},\n title = {Postural Mirroring and Intergroup Relations},\n volume = {11},\n year = {1985}\n}\n'}","[{'authorId': '37544705', 'name': 'M. LaFrance'}]"
966,4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e,End-To-End Memory Networks,"We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network [23] but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch [2] to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering [22] and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.",2015.0,26.0,2352.0,False,,{'pages': '2440-2448'},"{'bibtex': '@Inproceedings{Sukhbaatar2015EndToEndMN,\n author = {Sainbayar Sukhbaatar and Arthur Szlam and J. Weston and R. Fergus},\n pages = {2440-2448},\n title = {End-To-End Memory Networks},\n year = {2015}\n}\n'}","[{'authorId': '2265067', 'name': 'Sainbayar Sukhbaatar'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '145183709', 'name': 'J. Weston'}, {'authorId': '2276554', 'name': 'R. Fergus'}]"
967,4f1450fc7a37a5c09abc2b23bff3aee31f25d2a3,Effectiveness of Immersive Virtual Reality-based Communication for Construction Projects,,2019.0,48.0,31.0,True,,"{'volume': '23', 'pages': '4972 - 4983', 'name': 'KSCE Journal of Civil Engineering'}","{'bibtex': '@Article{Abbas2019EffectivenessOI,\n author = {Ali Abbas and M. Choi and Joonoh Seo and S. Cha and Heng Li},\n journal = {KSCE Journal of Civil Engineering},\n pages = {4972 - 4983},\n title = {Effectiveness of Immersive Virtual Reality-based Communication for Construction Projects},\n volume = {23},\n year = {2019}\n}\n'}","[{'authorId': '115055132', 'name': 'Ali Abbas'}, {'authorId': '122228036', 'name': 'M. Choi'}, {'authorId': '3039883', 'name': 'Joonoh Seo'}, {'authorId': '38821821', 'name': 'S. Cha'}, {'authorId': '49404672', 'name': 'Heng Li'}]"
968,4f59f676086cfc45cea8ba9a6239a16d3a652b6c,Emotion and sociable humanoid robots,,2003.0,77.0,1172.0,False,,"{'volume': '59', 'pages': '119-155', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Breazeal2003EmotionAS,\n author = {C. Breazeal},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {119-155},\n title = {Emotion and sociable humanoid robots},\n volume = {59},\n year = {2003}\n}\n'}","[{'authorId': '1711777', 'name': 'C. Breazeal'}]"
969,4f731ca60b8dae526f53bdf215a43c5cdb1c3e13,Cómo mejorar la adherencia al tratamiento,,2006.0,0.0,8.0,False,,"{'volume': '', 'pages': '39', 'name': ''}","{'bibtex': '@Inproceedings{Momblona2006CómoML,\n author = {J. M. S. Momblona},\n pages = {39},\n title = {Cómo mejorar la adherencia al tratamiento},\n year = {2006}\n}\n'}","[{'authorId': '66817402', 'name': 'J. M. S. Momblona'}]"
970,4f7bf03bfe27341a16ea605597d31a5925e31ef4,Emotional interaction model for a service robot,"This paper presents the emotional interaction model that receives classified inputs from user's response and decides what emotional response the robot should generate. Cognitive emotion modeling requires profound understanding about human's cognitive processes and ideas on how to implement each constitutional components of the model into the robot. The proposed model is composed of two layers: reactive and deliberative layers. Reactive layer is in charge of immediate emotional response of the robot. It works with pre-defined rules which relate input to its corresponding emotional expressions. This layer enables immediate display of the robot's emotional state to the user so that lifelike characteristics of the robot can be achieved. The deliberative layer is in charge of the appraisal-based emotion expression and carries out the function of ""action-coloring,"" which adds flavor to the actions being taken. Emotional interaction scenarios which are considered to be possible with the proposed emotion model are also introduced.",2005.0,14.0,25.0,False,,"{'pages': '672-678', 'name': 'ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.'}","{'bibtex': '@Article{Kim2005EmotionalIM,\n author = {Hyoung-Rock Kim and Kang-Woo Lee and D. Kwon},\n journal = {ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.},\n pages = {672-678},\n title = {Emotional interaction model for a service robot},\n year = {2005}\n}\n'}","[{'authorId': '2031350', 'name': 'Hyoung-Rock Kim'}, {'authorId': '2118245627', 'name': 'Kang-Woo Lee'}, {'authorId': '145079887', 'name': 'D. Kwon'}]"
971,4f81f418fe3efbf5ff956d5248288a8c7d188ebd,The Effectiveness of Social Stories among Children and Adolescents with Autism Spectrum Disorders: Meta-Analysis.,,2016.0,0.0,17.0,False,,"{'volume': '5', 'pages': '51-60', 'name': ''}","{'bibtex': '@Inproceedings{Saad2016TheEO,\n author = {Mourad Ali Eissa Saad},\n pages = {51-60},\n title = {The Effectiveness of Social Stories among Children and Adolescents with Autism Spectrum Disorders: Meta-Analysis.},\n volume = {5},\n year = {2016}\n}\n'}","[{'authorId': '119400961', 'name': 'Mourad Ali Eissa Saad'}]"
972,4f8291709f45d0408ba8816b6e650d40ba46a62a,"Language, Cognition, and the Brain: Insights From Sign Language Research","Contents: Preface. Introduction. The Structure of American Sign Language: Linguistic Universals and Modality Effects. The Confluence of Language and Space. Psycholinguistic Studies of Sign Perception, Online Processing, and Production. Sign Language Acquisition. The Critical Period Hypothesis and the Effects of Late Language Acquisition. Memory for Sign Language: Implications for the Structure of Working Memory. The Impact of Sign Language Use on Visuospatial Cognition. Sign Language and the Brain. Appendices: Handshapes in American Sign Language. Linguistic Distinctions Among Communication Forms in Nicaragua.",2001.0,0.0,608.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Emmorey2001LanguageCA,\n author = {K. Emmorey},\n title = {Language, Cognition, and the Brain: Insights From Sign Language Research},\n year = {2001}\n}\n'}","[{'authorId': '2094807072', 'name': 'K. Emmorey'}]"
973,4f95af1f0d23c58f9316dbebaf5651c1d0bf85c6,Speech-based Gesture Generation for Robots and Embodied Agents: A Scoping Review,"Humans use gestures as a means of non-verbal communication. Often accompanying speech, these gestures have several purposes but in general, aim to convey an intended message to the receiver. Researchers have tried to develop systems to allow embodied agents to be better communicators when interacting with humans via using gestures. In this article, we present a scoping literature review of the methods and the metrics used to generate and evaluate co-speech gestures. After collecting a set of papers using a term search on the Scopus database, we analysed the content of these papers based on methodology (i.e., model, the dataset used), evaluation measures (i.e., objective and subjective) and limitations. The results indicate that data-driven approaches are used more frequently. In terms of evaluation measures, we found a trend of combining objective and subjective metrics, while no standards exist for either. This literature review provides an overview of the research in the area and, more specifically insights the trends and the challenges to be met in building a system to automatically generate gestures for embodied agents.",2021.0,44.0,14.0,False,,{'name': 'Proceedings of the 9th International Conference on Human-Agent Interaction'},"{'bibtex': '@Article{Liu2021SpeechbasedGG,\n author = {Yu Liu and Gelareh Mohammadi and Yang Song and W. Johal},\n journal = {Proceedings of the 9th International Conference on Human-Agent Interaction},\n title = {Speech-based Gesture Generation for Robots and Embodied Agents: A Scoping Review},\n year = {2021}\n}\n'}","[{'authorId': '2155143593', 'name': 'Yu Liu'}, {'authorId': '4911295', 'name': 'Gelareh Mohammadi'}, {'authorId': '2157994950', 'name': 'Yang Song'}, {'authorId': '2963096', 'name': 'W. Johal'}]"
974,4f9dd3ba172b13f35152fd68477b9f57809e5789,The influence of individuals on situations: Implications for understanding the links between personality and social behavior.,"In an analysis of the nature and origins of predictability in social behavior, two propositions are considered: (1) There exist categories of individuals whose social behavior is readily predictable from measures of personal attributes such as attitudes, traits, and dispositions as well as categories of individuals whose social behavior is readily predictable from situational and interpersonal specifications of behavioral appropriateness; (2) underlying these differences in predictability are systematic choices to enter and to spend time in social settings and interpersonal contexts that promote and facilitate one or other of these characteristic behavioral orientations. The implications of these propositions for the study of personality and social behavior are considered in the specific case of the psychological construct of self-monitoring and in the general case of understanding the reciprocal influences of individuals and their social worlds.",1983.0,55.0,137.0,False,,"{'volume': '51 3', 'pages': '\n          497-516\n        ', 'name': 'Journal of personality'}","{'bibtex': '@Article{Snyder1983TheIO,\n author = {M. Snyder},\n journal = {Journal of personality},\n pages = {\n          497-516\n        },\n title = {The influence of individuals on situations: Implications for understanding the links between personality and social behavior.},\n volume = {51 3},\n year = {1983}\n}\n'}","[{'authorId': '143958550', 'name': 'M. Snyder'}]"
975,4fa175b43ea640957ab04e379d87a8d3aca600bb,Investigating the process of emotion recognition in immersive and non-immersive virtual technological setups,"This paper investigates the use of Immersive Virtual Environment (IVE) to evaluate the process of emotion recognition from faces (ERF). ERF has been mostly probed by using still photographs resembling universal expressions. However, this approach does not reflect the vividness of faces. Virtual Reality (VR) makes use of animated agents, trying to overcome this issue by reproducing the inherent dynamic of facial expressions, but outside a natural environment. We suggest that a setup using IVE technology simulating a real scene in combination with virtual agents (VAs) displaying dynamic facial expressions should improve the study of ERF. To support our claim we carried out an experiment in which two groups of subjects had to recognize VAs facial expression of universal and basic emotions in IVE and No-IVE condition. The goal was to evaluate the impact of the immersion in VE for ERF investigation. Results showed that the level of immersion in IVE does not interfere with the recognition task and a high level of accuracy in facial recognition suggests that IVE can be used to investigate the process of ERF.",2016.0,32.0,4.0,False,,{'name': 'Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology'},"{'bibtex': '@Article{Faita2016InvestigatingTP,\n author = {Claudia Faita and F. Vanni and Camilla Tanca and E. Ruffaldi and M. Carrozzino and M. Bergamasco},\n booktitle = {Virtual Reality Software and Technology},\n journal = {Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology},\n title = {Investigating the process of emotion recognition in immersive and non-immersive virtual technological setups},\n year = {2016}\n}\n'}","[{'authorId': '3223757', 'name': 'Claudia Faita'}, {'authorId': '13333196', 'name': 'F. Vanni'}, {'authorId': '2814090', 'name': 'Camilla Tanca'}, {'authorId': '1854191', 'name': 'E. Ruffaldi'}, {'authorId': '2203390', 'name': 'M. Carrozzino'}, {'authorId': '7723077', 'name': 'M. Bergamasco'}]"
976,4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563,Recipes for Safety in Open-domain Chatbots,"Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior and unwanted biases. We investigate a variety of methods to mitigate these issues in the context of open-domain generative dialogue models. We introduce a new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time. We conduct experiments comparing these methods and find our new techniques are (i) safer than existing models as measured by automatic and human evaluations while (ii) maintaining usability metrics such as engagingness relative to the state of the art. We then discuss the limitations of this work by analyzing failure cases of our models.",2020.0,75.0,163.0,False,,"{'volume': 'abs/2010.07079', 'name': 'ArXiv'}","{'bibtex': '@Article{Xu2020RecipesFS,\n author = {Jing Xu and Da Ju and Margaret Li and Y-Lan Boureau and J. Weston and Emily Dinan},\n journal = {ArXiv},\n title = {Recipes for Safety in Open-domain Chatbots},\n volume = {abs/2010.07079},\n year = {2020}\n}\n'}","[{'authorId': '2155954521', 'name': 'Jing Xu'}, {'authorId': '3092435', 'name': 'Da Ju'}, {'authorId': '6649233', 'name': 'Margaret Li'}, {'authorId': '90841478', 'name': 'Y-Lan Boureau'}, {'authorId': '145183709', 'name': 'J. Weston'}, {'authorId': '31461304', 'name': 'Emily Dinan'}]"
977,4fdc075d1cc14d64c11c3c860e86a082b761f4a0,A Survey of Augmented Reality,"This paper surveys the field of augmented reality (AR), in which 3D virtual objects are integrated into a 3D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment, and military applications that have been explored. This paper describes the characteristics of augmented reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective augmented reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using augmented reality.",1997.0,156.0,8698.0,True,"{'url': 'http://www.cs.unc.edu/~azuma/ARpresence.pdf', 'status': None}","{'volume': '6', 'pages': '355-385', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Azuma1997ASO,\n author = {Ronald T. Azuma},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {355-385},\n title = {A Survey of Augmented Reality},\n volume = {6},\n year = {1997}\n}\n'}","[{'authorId': '34679537', 'name': 'Ronald T. Azuma'}]"
978,4fdc24cbc96e50e059b758ce0180219f6a9cb226,VirtualHuman: dialogic and affective interaction with virtual characters,"Natural multimodal interaction with realistic virtual characters provides rich opportunities for entertainment and education. In this paper we present the current VIRTUALHUMAN demonstrator system. It provides a knowledge-based framework to create interactive applications in a multi-user, multi-agent setting. The behavior of the virtual humans and objects in the 3D environment is controlled by interacting affective conversational dialogue engines. An elaborate model of affective behavior adds natural emotional reactions and presence of the virtual humans. Actions are defined in a XML-based markup language that supports the incremental specification of synchronized multimodal output. The system was successfully demonstrated during CeBIT 2006.",2006.0,28.0,32.0,False,,{'pages': '51-58'},"{'bibtex': '@Inproceedings{Reithinger2006VirtualHumanDA,\n author = {Norbert Reithinger and Patrick Gebhard and Markus Löckelt and A. Ndiaye and Norbert Pfleger and Martin Klesen},\n pages = {51-58},\n title = {VirtualHuman: dialogic and affective interaction with virtual characters},\n year = {2006}\n}\n'}","[{'authorId': '1731353', 'name': 'Norbert Reithinger'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '1700512', 'name': 'Markus Löckelt'}, {'authorId': '2706336', 'name': 'A. Ndiaye'}, {'authorId': '1705387', 'name': 'Norbert Pfleger'}, {'authorId': '2922093', 'name': 'Martin Klesen'}]"
979,500d6e335c8490234511a74b3165fac606fc543d,Affective Interactions Using Virtual Reality: The Link between Presence and Emotions,"Many studies showed the ability of movies and imagery techniques to elicit emotions. Nevertheless, it is less clear how to manipulate the content of interactive media to induce specific emotional responses. In particular, this is true for the emerging medium virtual reality (VR), whose main feature is the ability to induce a feeling of ""presence"" in the computer-generated world experienced by the user. The main goal of this study was to analyze the possible use of VR as an affective medium. Within this general goal, the study also analyzed the relationship between presence and emotions. The results confirmed the efficacy of VR as affective medium: the interaction with ""anxious"" and ""relaxing"" virtual environments produced anxiety and relaxation. The data also showed a circular interaction between presence and emotions: on one side, the feeling of presence was greater in the ""emotional"" environments; on the other side, the emotional state was influenced by the level of presence. The significance of these results for the assessment of affective interaction is discussed.",2007.0,45.0,817.0,False,,"{'volume': '10 1', 'pages': '\n          45-56\n        ', 'name': 'Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society'}","{'bibtex': '@Article{Riva2007AffectiveIU,\n author = {G. Riva and F. Mantovani and Claret S. Capideville and A. Preziosa and F. Morganti and D. Villani and A. Gaggioli and C. Botella and M. A. Raya},\n journal = {Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},\n pages = {\n          45-56\n        },\n title = {Affective Interactions Using Virtual Reality: The Link between Presence and Emotions},\n volume = {10 1},\n year = {2007}\n}\n'}","[{'authorId': '144059813', 'name': 'G. Riva'}, {'authorId': '2274674', 'name': 'F. Mantovani'}, {'authorId': '2208482', 'name': 'Claret S. Capideville'}, {'authorId': '3234117', 'name': 'A. Preziosa'}, {'authorId': '1745080', 'name': 'F. Morganti'}, {'authorId': '103238720', 'name': 'D. Villani'}, {'authorId': '1700503', 'name': 'A. Gaggioli'}, {'authorId': '145945543', 'name': 'C. Botella'}, {'authorId': '7604530', 'name': 'M. A. Raya'}]"
980,50135b37e5be956a317a39589178cf54b724f00d,Crowd Simulation,,2019.0,40.0,119.0,False,,,"{'bibtex': '@Inproceedings{Thalmann2019CrowdS,\n author = {D. Thalmann},\n title = {Crowd Simulation},\n year = {2019}\n}\n'}","[{'authorId': '2223622395', 'name': 'D. Thalmann'}]"
981,50236de1791a009dc77d7266c412469a22437b4b,"Micro-expression recognition: an updated review of current trends, challenges and solutions",,2018.0,123.0,56.0,False,,"{'volume': '36', 'pages': '445-468', 'name': 'The Visual Computer'}","{'bibtex': '@Article{Goh2018MicroexpressionRA,\n author = {Kam Meng Goh and Chee How Ng and Li Li Lim and U. U. Sheikh},\n journal = {The Visual Computer},\n pages = {445-468},\n title = {Micro-expression recognition: an updated review of current trends, challenges and solutions},\n volume = {36},\n year = {2018}\n}\n'}","[{'authorId': '49939827', 'name': 'Kam Meng Goh'}, {'authorId': '2064846826', 'name': 'Chee How Ng'}, {'authorId': '97650523', 'name': 'Li Li Lim'}, {'authorId': '2412102', 'name': 'U. U. Sheikh'}]"
982,504eff078bd0a2b9c4bcf58730daa5a42845f5dd,The influence of social dependencies on decision-making: initial investigations with a new game,"This paper describes a new multi-player computer game, Colored Trails (CT), which may be played by people, computers and heterogeneous groups. CT was designed to enable investigation of properties of decision-making strategies in multi-agent situations of varying complexity. The paper presents the results of an initial series of experiments of CT games in which agentsý choices affected not only their own outcomes but also the outcomes of other agents. It compares the behavior of people with that of computer agents deploying a variety of decision-making strategies. The results align with behavioral economics studies in showing that people cooperate when they play and that factors of social dependency influence their levels of cooperation. Preliminary results indicate that people design agents to play strategies closer to game-theory predictions, yielding lower utility. Additional experiments show that such agents perform worse than agents designed to make choices that resemble human cooperative behavior. The paper describes challenges raised by these results for designers of agents, especially agents that need to operate in heterogeneous groups that include people.",2004.0,16.0,138.0,False,,"{'pages': '782-789', 'name': 'Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.'}","{'bibtex': '@Article{Grosz2004TheIO,\n author = {B. Grosz and Sarit Kraus and Shavit Talman and B. Stossel and Moti Havlin},\n journal = {Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.},\n pages = {782-789},\n title = {The influence of social dependencies on decision-making: initial investigations with a new game},\n year = {2004}\n}\n'}","[{'authorId': '1692242', 'name': 'B. Grosz'}, {'authorId': '1691597', 'name': 'Sarit Kraus'}, {'authorId': '2939375', 'name': 'Shavit Talman'}, {'authorId': '40446340', 'name': 'B. Stossel'}, {'authorId': '2425853', 'name': 'Moti Havlin'}]"
983,50981e47da7a9d1eb620b96db6bf820485eaa31f,Human behaviors modeling in multi-agent virtual environment,,2017.0,34.0,15.0,False,,"{'name': 'Multimedia Tools and Applications', 'pages': '5851-5871', 'volume': '76'}","{'bibtex': '@Article{Cai2017HumanBM,\n author = {Linqin Cai and Binbin Liu and Jimin Yu and Jianrong Zhang},\n booktitle = {Multimedia tools and applications},\n journal = {Multimedia Tools and Applications},\n pages = {5851-5871},\n title = {Human behaviors modeling in multi-agent virtual environment},\n volume = {76},\n year = {2017}\n}\n'}","[{'authorId': '2524401', 'name': 'Linqin Cai'}, {'authorId': '2109444810', 'name': 'Binbin Liu'}, {'authorId': '2115987564', 'name': 'Jimin Yu'}, {'authorId': '2108128657', 'name': 'Jianrong Zhang'}]"
984,50aa2fb1a359d2ad618ccbdee943d6f90742a2b5,Universals and cultural differences in facial expressions of emotion.,,1972.0,0.0,2593.0,False,,"{'volume': '1971', 'pages': '207-282', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1972UniversalsAC,\n author = {P. Ekman},\n pages = {207-282},\n title = {Universals and cultural differences in facial expressions of emotion.},\n volume = {1971},\n year = {1972}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
985,50beb573d318383ff348630dc2e2d7335e06d0e4,The Impact of Technology on People with Autism Spectrum Disorder: A Systematic Literature Review,"People with autism spectrum disorder (ASD) tend to enjoy themselves and be engaged when interacting with computers, as these interactions occur in a safe and trustworthy environment. In this paper, we present a systematic literature review on the state of the research on the use of technology to teach people with ASD. We reviewed 94 studies that show how the use of technology in educational contexts helps people with ASD develop several skills, how these approaches consider aspects of user experience, usability and accessibility, and how game elements are used to enrich learning environments. This systematic literature review shows that the development and evaluation of systems and applications for users with ASD is very promising. The use of technological advancements such as virtual agents, artificial intelligence, virtual reality, and augmented reality undoubtedly provides a comfortable environment that promotes constant learning for people with ASD.",2019.0,110.0,101.0,True,"{'url': 'https://www.mdpi.com/1424-8220/19/20/4485/pdf?version=1571367192', 'status': None}","{'volume': '19', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Valencia2019TheIO,\n author = {K. Valencia and Cristian Rusu and Daniela Quiñones and Eric Jamet},\n journal = {Sensors (Basel, Switzerland)},\n title = {The Impact of Technology on People with Autism Spectrum Disorder: A Systematic Literature Review},\n volume = {19},\n year = {2019}\n}\n'}","[{'authorId': '97803089', 'name': 'K. Valencia'}, {'authorId': '145064035', 'name': 'Cristian Rusu'}, {'authorId': '40049831', 'name': 'Daniela Quiñones'}, {'authorId': '35123248', 'name': 'Eric Jamet'}]"
986,50dbf733e1bf8bb210a9c4ddd1d687dade014182,Empirical Evaluation of the Interplay of Emotion and Visual Attention in Human-Virtual Human Interaction,"We examined the effect of rendering style and the interplay between attention and emotion in users during interaction with a virtual patient in a medical training simulator. The virtual simulation was rendered representing a sample from the photo-realistic to the non-photorealistic continuum, namely Near-Realistic, Cartoon or Pencil-Shader. In a mixed design study, we collected 45 participants’ emotional responses and gaze behavior using surveys and an eye tracker while interacting with a virtual patient who was medically deteriorating over time. We used a cross-lagged panel analysis of attention and emotion to understand their reciprocal relationship over time. We also performed a mediation analysis to compare the extent to which the virtual agent’s appearance and his affective behavior impacted users’ emotional and attentional responses. Results showed the interplay between participants’ visual attention and emotion over time and also showed that attention was a stronger variable than emotion during the interaction with the virtual human.",2019.0,44.0,5.0,False,,{'name': 'ACM Symposium on Applied Perception 2019'},"{'bibtex': '@Article{Volonte2019EmpiricalEO,\n author = {Matias Volonte and Reza Ghaiumy Anaraky and Bart P. Knijnenburg and A. Duchowski and Sabarish V. Babu},\n booktitle = {ACM Symposium on Applied Perception},\n journal = {ACM Symposium on Applied Perception 2019},\n title = {Empirical Evaluation of the Interplay of Emotion and Visual Attention in Human-Virtual Human Interaction},\n year = {2019}\n}\n'}","[{'authorId': '51250937', 'name': 'Matias Volonte'}, {'authorId': '121111647', 'name': 'Reza Ghaiumy Anaraky'}, {'authorId': '2477993', 'name': 'Bart P. Knijnenburg'}, {'authorId': '2245673', 'name': 'A. Duchowski'}, {'authorId': '144403504', 'name': 'Sabarish V. Babu'}]"
987,50fbcfc18723ccebb0c4e1a6e931a341929d4ac8,I Know What I Did Last Summer: Autobiographic Memory in Synthetic Characters,,2007.0,19.0,42.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/36158/36158.pdf', 'status': None}",{'pages': '606-617'},"{'bibtex': '@Inproceedings{Dias2007IKW,\n author = {João Dias and W. C. Ho and Thurid Vogt and Nathalie Beeckman and Ana Paiva and E. André},\n pages = {606-617},\n title = {I Know What I Did Last Summer: Autobiographic Memory in Synthetic Characters},\n year = {2007}\n}\n'}","[{'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '34654263', 'name': 'W. C. Ho'}, {'authorId': '30169286', 'name': 'Thurid Vogt'}, {'authorId': '2620317', 'name': 'Nathalie Beeckman'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '1742930', 'name': 'E. André'}]"
988,51045c5de3f17d4fb4baa9458b10077e9d520d06,Subtle Executive Impairment in Children with Autism and Children with ADHD,,2005.0,59.0,370.0,False,,"{'volume': '35', 'pages': '279-293', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Goldberg2005SubtleEI,\n author = {M. C. Goldberg and M. C. Goldberg and S. Mostofsky and S. Mostofsky and L. Cutting and L. Cutting and E. Mahone and E. Mahone and B. Astor and M. Denckla and M. Denckla and Rebecca Landa and R. Landa},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {279-293},\n title = {Subtle Executive Impairment in Children with Autism and Children with ADHD},\n volume = {35},\n year = {2005}\n}\n'}","[{'authorId': '39824100', 'name': 'M. C. Goldberg'}, {'authorId': '39824100', 'name': 'M. C. Goldberg'}, {'authorId': '7517252', 'name': 'S. Mostofsky'}, {'authorId': '7517252', 'name': 'S. Mostofsky'}, {'authorId': '2576395', 'name': 'L. Cutting'}, {'authorId': '2576395', 'name': 'L. Cutting'}, {'authorId': '144783784', 'name': 'E. Mahone'}, {'authorId': '144783784', 'name': 'E. Mahone'}, {'authorId': '4519538', 'name': 'B. Astor'}, {'authorId': '3485134', 'name': 'M. Denckla'}, {'authorId': '3485134', 'name': 'M. Denckla'}, {'authorId': '2074773491', 'name': 'Rebecca Landa'}, {'authorId': '3231968', 'name': 'R. Landa'}]"
989,5119728e8265f9f0abde47b9f72176cdb7a15c60,The Impact of System Feedback on Learners' Affective and Physiological States,,2010.0,34.0,62.0,False,,{'pages': '264-273'},"{'bibtex': ""@Inproceedings{Pour2010TheIO,\n author = {Payam Aghaei Pour and M. Hussain and Omar Alzoubi and S. D’Mello and R. Calvo},\n pages = {264-273},\n title = {The Impact of System Feedback on Learners' Affective and Physiological States},\n year = {2010}\n}\n""}","[{'authorId': '2229578500', 'name': 'Payam Aghaei Pour'}, {'authorId': '145460472', 'name': 'M. Hussain'}, {'authorId': '1780551', 'name': 'Omar Alzoubi'}, {'authorId': '1383996606', 'name': 'S. D’Mello'}, {'authorId': '144792845', 'name': 'R. Calvo'}]"
990,5132b0463e8d2d7c6e2d775b839bab6282495bae,"Body Cues, Not Facial Expressions, Discriminate Between Intense Positive and Negative Emotions","Joy or Pain? Face recognition and processing are so completely central to human social interactions that these functions are supported by specialized regions in the brain. One of the fundamental aspects being processed is emotion, particularly whether the emotion being expressed is positive or negative. Nevertheless, neuroimaging studies have documented that perceiving opposite emotions often activates the same or overlapping regions. Aviezer et al. (p. 1225) report that the recognition of positive versus negative emotions actually relies on information communicated by the body—the extent to which perceivers identified joy versus grief in composite figures was driven by whether the body came from a joyous (versus grievous) image rather than the face. The body reveals what the face conceals. The distinction between positive and negative emotions is fundamental in emotion models. Intriguingly, neurobiological work suggests shared mechanisms across positive and negative emotions. We tested whether similar overlap occurs in real-life facial expressions. During peak intensities of emotion, positive and negative situations were successfully discriminated from isolated bodies but not faces. Nevertheless, viewers perceived illusory positivity or negativity in the nondiagnostic faces when seen with bodies. To reveal the underlying mechanisms, we created compounds of intense negative faces combined with positive bodies, and vice versa. Perceived affect and mimicry of the faces shifted systematically as a function of their contextual body emotion. These findings challenge standard models of emotion expression and highlight the role of the body in expressing and perceiving emotions.",2012.0,34.0,626.0,False,,"{'volume': '338', 'pages': '1225 - 1229', 'name': 'Science'}","{'bibtex': '@Article{Aviezer2012BodyCN,\n author = {Hillel Aviezer and Y. Trope and A. Todorov},\n journal = {Science},\n pages = {1225 - 1229},\n title = {Body Cues, Not Facial Expressions, Discriminate Between Intense Positive and Negative Emotions},\n volume = {338},\n year = {2012}\n}\n'}","[{'authorId': '4387567', 'name': 'Hillel Aviezer'}, {'authorId': '5169679', 'name': 'Y. Trope'}, {'authorId': '145441940', 'name': 'A. Todorov'}]"
992,51367e79650b15d6f80b51098b7608dc29ea846c,When facial expressions dominate emotion perception in groups of virtual characters,"Virtual characters play a central role in populating virtual worlds, whether they act as conduits for human expressions as avatars or are automatically controlled by a machine as agents. In modern game-related scenarios, it is economical to assemble virtual characters from varying sources of appearances and motions. However, doing so may have unintended consequences with respect to how people perceive their expressions. This paper presents an initial study investigating the impact of facial expressions and full body motions from varying sources on the perception of intense positive and negative emotional expressions in small groups of virtual characters. 21 participants views a small group of three virtual characters engaged in intense animated behaviours as their face and body motions were varied between positive, neutral and negative valence expressions. While emotion perception was based on both the bodies and the faces of the characters, we found a strong impact of the valence of facial expressions on the perception of emotions in the group. We discuss these findings in relation to the combination of manually created and automatically defined motion sources, highlighting implications for the animation of virtual characters.",2017.0,11.0,4.0,True,"{'url': 'https://research.edgehill.ac.uk/files/20108173/08056588.pdf', 'status': 'GREEN'}","{'name': '2017 9th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)', 'pages': '157-160'}","{'bibtex': '@Article{Palmberg2017WhenFE,\n author = {Robin C. O. Palmberg and Christopher E. Peters and A. Qureshi},\n booktitle = {International Conference on Games and Virtual Worlds for Serious Applications},\n journal = {2017 9th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)},\n pages = {157-160},\n title = {When facial expressions dominate emotion perception in groups of virtual characters},\n year = {2017}\n}\n'}","[{'authorId': '46340448', 'name': 'Robin C. O. Palmberg'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '10649439', 'name': 'A. Qureshi'}]"
993,513b211c568add795b38f9092a11aa19c582c7f1,Reading What the Mind Thinks From How the Eye Sees,"Human eyes convey a remarkable variety of complex social and emotional information. However, it is unknown which physical eye features convey mental states and how that came about. In the current experiments, we tested the hypothesis that the receiver’s perception of mental states is grounded in expressive eye appearance that serves an optical function for the sender. Specifically, opposing features of eye widening versus eye narrowing that regulate sensitivity versus discrimination not only conveyed their associated basic emotions (e.g., fear vs. disgust, respectively) but also conveyed opposing clusters of complex mental states that communicate sensitivity versus discrimination (e.g., awe vs. suspicion). This sensitivity-discrimination dimension accounted for the majority of variance in perceived mental states (61.7%). Further, these eye features remained diagnostic of these complex mental states even in the context of competing information from the lower face. These results demonstrate that how humans read complex mental states may be derived from a basic optical principle of how people see.",2017.0,42.0,54.0,False,,"{'volume': '28', 'pages': '494 - 503', 'name': 'Psychological Science'}","{'bibtex': '@Article{Lee2017ReadingWT,\n author = {D. H. Lee and A. Anderson},\n journal = {Psychological Science},\n pages = {494 - 503},\n title = {Reading What the Mind Thinks From How the Eye Sees},\n volume = {28},\n year = {2017}\n}\n'}","[{'authorId': '143876403', 'name': 'D. H. Lee'}, {'authorId': '5040426', 'name': 'A. Anderson'}]"
994,51d1b5c2e56711add0cd453e8191ba42c8165ef1,Towards an Architecture Model for Emotion Recognition in Interactive Systems: Application to a Ballet Dance Show,"In the context of the very dynamic and challenging domain of affective computing, we adopt a software engineering point of view on emotion recognition in interactive systems. Our goal is threefold: first, developing an architecture model for emotion recognition. This architecture model emphasizes multimodality and reusability. Second, developing a prototype based on this architecture model. For this prototype we focus on gesturebased emotion recognition. And third, using this prototype for augmenting a ballet dance show.",2009.0,26.0,8.0,True,"{'url': 'http://hal.univ-grenoble-alpes.fr/docs/00/95/33/07/PDF/WINVR2009.pdf', 'status': None}","{'volume': '', 'pages': '19-24', 'name': ''}","{'bibtex': '@Inproceedings{Clay2009TowardsAA,\n author = {Alexis Clay and N. Couture and L. Nigay},\n pages = {19-24},\n title = {Towards an Architecture Model for Emotion Recognition in Interactive Systems: Application to a Ballet Dance Show},\n year = {2009}\n}\n'}","[{'authorId': '7237380', 'name': 'Alexis Clay'}, {'authorId': '2742240', 'name': 'N. Couture'}, {'authorId': '1807947', 'name': 'L. Nigay'}]"
995,5201f214fe8d473e9853b94e4fe58eccbb37721b,The psychology of sex differences,,1978.0,0.0,2311.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lips1978ThePO,\n author = {H. Lips and N. Colwill},\n title = {The psychology of sex differences},\n year = {1978}\n}\n'}","[{'authorId': '103190827', 'name': 'H. Lips'}, {'authorId': '15569598', 'name': 'N. Colwill'}]"
996,520737ed72f1880747f4a4f0cae535b2be17239d,Preliminary Reaction Analysis of Audience with Bio-Emotion Estimation Method,"This study is to propose an analytical technique and evaluation measures effective for investigations of emotion estimation by using biological information. For conducting investigations to analyze atmosphere and emotions by corresponding biological information with a Russell's circumplex model, any of analytical techniques or evaluation measures are not established and therefore are used with uncertain effectiveness. In this study, we propose a novel technique using vector decomposition, while a reported study proposed a technique using the ratio of distances analysis, for emotion estimation on the basis of 8 emotion classifications by using 2 different types of biological information including an electroencephalogram and pulse rate, in which a point of emotion is classified on a circumplex model corresponding to a two-dimensional coordinate. Also, to validate the effectiveness, we analyzed audience's emotions responded to a show initially motivating us to investigate. We demonstrated that the evaluation measures could be more effective by validating the evaluation.",2018.0,11.0,6.0,False,,"{'volume': '02', 'pages': '601-605', 'name': '2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)'}","{'bibtex': '@Article{Sugaya2018PreliminaryRA,\n author = {Midori Sugaya and Takuya Hiramatsu and Reiji Yoshida and F. Chen},\n journal = {2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)},\n pages = {601-605},\n title = {Preliminary Reaction Analysis of Audience with Bio-Emotion Estimation Method},\n volume = {02},\n year = {2018}\n}\n'}","[{'authorId': '145094033', 'name': 'Midori Sugaya'}, {'authorId': '2071056968', 'name': 'Takuya Hiramatsu'}, {'authorId': '46784763', 'name': 'Reiji Yoshida'}, {'authorId': '144180429', 'name': 'F. Chen'}]"
997,52085e555bdc5ecb35d650a1536685265b808808,The Influence of Avatars on Online Consumer Shopping Behavior,"An impediment to Web-based retail sales is the impersonal nature of Web-based shopping. A solution to this problem is to use an avatar to deliver product information. An avatar is a graphic representation that can be animated by means of computer technology. Study 1 shows that using an avatar sales agent leads to more satisfaction with the retailer, a more positive attitude toward the product, and a greater purchase intention. Study 2 shows that an attractive avatar is a more effective sales agent at moderate levels of product involvement, but an expert avatar is a more effective sales agent at high levels of product involvement.",2006.0,76.0,636.0,True,"{'url': 'http://warrington.ufl.edu/departments/mkt/docs/janiszewski/avatarjm.pdf', 'status': None}","{'volume': '70', 'pages': '19 - 36', 'name': 'Journal of Marketing'}","{'bibtex': '@Article{Holzwarth2006TheIO,\n author = {M. Holzwarth and Chris Janiszewski and Marcus Neumann},\n journal = {Journal of Marketing},\n pages = {19 - 36},\n title = {The Influence of Avatars on Online Consumer Shopping Behavior},\n volume = {70},\n year = {2006}\n}\n'}","[{'authorId': '4143591', 'name': 'M. Holzwarth'}, {'authorId': '4931836', 'name': 'Chris Janiszewski'}, {'authorId': '2060376572', 'name': 'Marcus Neumann'}]"
998,521cd68e96579db8cf5dadbbc51ca3a78f790c71,Emotional Belief-Desire-Intention Agent Model: Previous Work And Proposed Architecture,"Research in affective computing shows that agents cannot be truly intelligent, nor believable or realistic without emotions. In this paper, we present a model of emotional agents that is based on a BDI architecture. We show how we can integrate emotions, resources and personality features into an artificial intelligent agent so as to obtain a human-like behavior of this agent. We place our work in the general context of existing research in emotional agents, with emphasis on BDI emotional models.",2013.0,17.0,28.0,True,,"{'volume': '2', 'name': 'International Journal of Advanced Research in Artificial Intelligence'}","{'bibtex': '@Article{Puica2013EmotionalBA,\n author = {M. Puica and A. Florea},\n journal = {International Journal of Advanced Research in Artificial Intelligence},\n title = {Emotional Belief-Desire-Intention Agent Model: Previous Work And Proposed Architecture},\n volume = {2},\n year = {2013}\n}\n'}","[{'authorId': '144168605', 'name': 'M. Puica'}, {'authorId': '1732513', 'name': 'A. Florea'}]"
999,5240d55c6fc07ae3c685b4170ea1476f6ce76f5f,Please Scroll down for Article Cognition & Emotion Assessing the Effectiveness of a Large Database of Emotion-eliciting Films: a New Tool for Emotion Researchers,"'Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers', This article may be used for research, teaching and private study purposes. Any substantial or systematic reproduction, redistribution , reselling , loan or sub-licensing, systematic supply or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material.",,58.0,771.0,False,,,"{'bibtex': '@Misc{None,\n author = {A. Schaefer and F. Nils and X. Sanchez and P. Philippot},\n title = {Please Scroll down for Article Cognition & Emotion Assessing the Effectiveness of a Large Database of Emotion-eliciting Films: a New Tool for Emotion Researchers}\n}\n'}","[{'authorId': '2204817', 'name': 'A. Schaefer'}, {'authorId': '2083760609', 'name': 'F. Nils'}, {'authorId': '48979019', 'name': 'X. Sanchez'}, {'authorId': '4443997', 'name': 'P. Philippot'}]"
1000,52464b7c13d33375996971c829d942a615f8e094,Empirical Validation in Agent-based Models: Introduction to the Special Issue,,2007.0,27.0,77.0,True,"{'url': 'https://www.iris.sssup.it/bitstream/11382/5363/1/COMPECO_2007_Intro.pdf', 'status': None}","{'volume': '30', 'pages': '189-194', 'name': 'Computational Economics'}","{'bibtex': '@Article{Fagiolo2007EmpiricalVI,\n author = {G. Fagiolo and C. Birchenhall and P. Windrum},\n journal = {Computational Economics},\n pages = {189-194},\n title = {Empirical Validation in Agent-based Models: Introduction to the Special Issue},\n volume = {30},\n year = {2007}\n}\n'}","[{'authorId': '1931731', 'name': 'G. Fagiolo'}, {'authorId': '1782759', 'name': 'C. Birchenhall'}, {'authorId': '1766251', 'name': 'P. Windrum'}]"
1001,526486a9f0662ce95b9e269833197d9b0b5056bb,2D statistical models of facial expressions for realistic 3D avatar animation,We address the issue of modelling facial expressions for realistic 3D avatar animation. We introduce a hierarchical decomposition of a human face into different components and model them according to their intrinsic functionalities. The parametrisation of the expressions is achieved in a two-level framework. First level accounts for the low level component facial actions and is represented by hierarchical latent variable models. The second level models the final expressions as a combination of subcomponent information extracted from the lower level using combinatorial logic. Finally we produce continuous animation curves that are used to animate 3D avatar in a morph-based fashion. Our approach is entirely based on 2D information extracted from the input source.,2005.0,19.0,42.0,True,"{'url': 'http://www.dcs.qmul.ac.uk/~sgg/papers/ZalewskiGongCVPR05.pdf', 'status': None}","{'volume': '2', 'pages': '217-222 vol. 2', 'name': ""2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)""}","{'bibtex': ""@Article{Zalewski20052DSM,\n author = {Lukasz Zalewski and S. Gong},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},\n pages = {217-222 vol. 2},\n title = {2D statistical models of facial expressions for realistic 3D avatar animation},\n volume = {2},\n year = {2005}\n}\n""}","[{'authorId': '34780294', 'name': 'Lukasz Zalewski'}, {'authorId': '144784813', 'name': 'S. Gong'}]"
1002,52a71e0dd7a299e370ad548bcb82a0813ca3f6da,A survey on virtual environment applications to fear of public speaking.,"BACKGROUND
Social Anxiety Disorder (SAD) is one of the most prevalent anxiety disorders in Europe and comprises the fear of public speaking as its typical sub-type. Cognitive-Behavioural Therapy (CBT) is the intervention of choice for SAD, and it includes exposure to anxiety-provoking stimuli to induce systematic desensitization and reduce anxiety. Similarly, exposure therapy per se has been used and found effective, although it is not as specific as CBT for the treatment of SAD. Interestingly, exposure to anxiety-provoking situations can be achieved in Virtual Environments (VEs) through the simulation of social situations allowing individuals with public speaking anxiety to live and develop real exposure-like reactions. The Virtual Reality Exposure Therapy (VRET) is the treatment of anxiety disorders based on such VEs.


AIM
This article aims to provide an overview of the scientific literature related to the applications of Virtual Reality to the treatment of fear of public speaking.


MATERIALS AND METHODS
We conducted the literature review on PubMed and Google Scholar for studies including the fear-of-public-speaking VEs.


RESULTS AND CONCLUSIONS
Reviewed studies addressed two main aspects: the design parameters of the VEs for adequate reactions to synthetic social stimuli, and the efficacy of VEs for fear of public speaking treatment. VEs resulted effective for triggering as-if-real reactions in relation to public speaking. VE-based exposures reduced public speaking anxiety measurements, decreased scores and maintained them at 3 month follow-up. Studies comparing VRET to pharmacological therapy are lacking, and there are few randomized controlled trials that compare VRET to CBT, especially on fear of public speaking treatment.",2013.0,29.0,29.0,False,,"{'volume': '17 12', 'pages': '\n          1561-8\n        ', 'name': 'European review for medical and pharmacological sciences'}","{'bibtex': '@Article{Vanni2013ASO,\n author = {F. Vanni and C. Conversano and A. Del Debbio and P. Landi and M. Carlini and C. Fanciullacci and M. Bergamasco and A. di Fiorino and L. Dell’Osso},\n journal = {European review for medical and pharmacological sciences},\n pages = {\n          1561-8\n        },\n title = {A survey on virtual environment applications to fear of public speaking.},\n volume = {17 12},\n year = {2013}\n}\n'}","[{'authorId': '13333196', 'name': 'F. Vanni'}, {'authorId': '3323335', 'name': 'C. Conversano'}, {'authorId': '117154993', 'name': 'A. Del Debbio'}, {'authorId': '32148749', 'name': 'P. Landi'}, {'authorId': '34145571', 'name': 'M. Carlini'}, {'authorId': '6571538', 'name': 'C. Fanciullacci'}, {'authorId': '2098874402', 'name': 'M. Bergamasco'}, {'authorId': '6857000', 'name': 'A. di Fiorino'}, {'authorId': '134293567', 'name': 'L. Dell’Osso'}]"
1003,52d7eb0fbc3522434c13cc247549f74bb9609c5d,WIDER FACE: A Face Detection Benchmark,"Face detection is one of the most studied topics in the computer vision community. Much of the progresses have been made by the availability of face detection benchmark datasets. We show that there is a gap between current face detection performance and the real world requirements. To facilitate future face detection research, we introduce the WIDER FACE dataset1, which is 10 times larger than existing datasets. The dataset contains rich annotations, including occlusions, poses, event categories, and face bounding boxes. Faces in the proposed dataset are extremely challenging due to large variations in scale, pose and occlusion, as shown in Fig. 1. Furthermore, we show that WIDER FACE dataset is an effective training source for face detection. We benchmark several representative detection systems, providing an overview of state-of-the-art performance and propose a solution to deal with large scale variation. Finally, we discuss common failure cases that worth to be further investigated.",2015.0,40.0,1320.0,True,"{'url': 'http://arxiv.org/pdf/1511.06523', 'status': None}","{'pages': '5525-5533', 'name': '2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)'}","{'bibtex': '@Article{Yang2015WIDERFA,\n author = {Shuo Yang and Ping Luo and Chen Change Loy and Xiaoou Tang},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5525-5533},\n title = {WIDER FACE: A Face Detection Benchmark},\n year = {2015}\n}\n'}","[{'authorId': '92887925', 'name': 'Shuo Yang'}, {'authorId': '47571885', 'name': 'Ping Luo'}, {'authorId': '1717179', 'name': 'Chen Change Loy'}, {'authorId': '50295995', 'name': 'Xiaoou Tang'}]"
1004,52dfba1732dbc7644ff50c85bdfa144309cf916c,E-Learning Systems in Virtual Environment,"E-learning is one of the emerging needs of the information age. Therefore a lot of potential is seen in distance learning development. Virtual environment interface to E-learning systems have recently appeared on the Internet. Using virtual reality environment, the applications appear to be promising to E-learning tasks more nature and interactive. Also using this technology, it is possible to get a sense of three dimensional environments and level of user immersion. Extensible 3D (X3D) is the most common tool for building 3D viewing and browsing of E-learning systems. In this paper the benefits of virtual reality environment using X3D in E-learning applications are demonstrated. Those will be shown via implementing two Web enabled virtual environment E-learning systems. The first one is an on-line virtual chemistry lab system. This application gives the student the ability to perform all experiments in a certain crucial. The second application is an on-line English language education system. This application gives the students the ability to learn the language audile and visual via on line interactive system. X3D is used as the main implementation tool which give the systems users the full visualization and interactivity of all learning steps.",2008.0,18.0,41.0,False,,"{'pages': '71-76', 'name': '2008 ITI 6th International Conference on Information & Communications Technology'}","{'bibtex': '@Article{Abdul-Kader2008ELearningSI,\n author = {H. Abdul-Kader},\n journal = {2008 ITI 6th International Conference on Information & Communications Technology},\n pages = {71-76},\n title = {E-Learning Systems in Virtual Environment},\n year = {2008}\n}\n'}","[{'authorId': '150119659', 'name': 'H. Abdul-Kader'}]"
1005,52e916a509beb9dd1300eb9a36dd8aab5bd2d09a,"Bakhtin’s Theory of the Literary Chronotope: Reflections, Applications, Perspectives",,2014.0,0.0,66.0,False,,"{'volume': '19', 'pages': '266 - 267', 'name': 'The European Legacy'}","{'bibtex': '@Article{Cusack2014BakhtinsTO,\n author = {Andrew Cusack},\n journal = {The European Legacy},\n pages = {266 - 267},\n title = {Bakhtin’s Theory of the Literary Chronotope: Reflections, Applications, Perspectives},\n volume = {19},\n year = {2014}\n}\n'}","[{'authorId': '1749206707', 'name': 'Andrew Cusack'}]"
1006,5300fe7b113721377ae10e68da9cc8b59936f44e,Cerebral Cortex doi:10.1093/cercor/bhq064 A Role for REM Sleep in Recalibrating the Sensitivity of the Human Brain to Specific Emotions,,2010.0,0.0,237.0,False,,,"{'bibtex': '@Inproceedings{None,\n title = {Cerebral Cortex doi:10.1093/cercor/bhq064 A Role for REM Sleep in Recalibrating the Sensitivity of the Human Brain to Specific Emotions},\n year = {2010}\n}\n'}",[]
1007,53020f0473fd052c8e1307907410da878c256756,THE ACQUISITION OF LEXICAL AND GRAMMATICAL ASPECT,"THE ACQUISITION OF LEXICAL AND GRAMMATICAL ASPECT. Ping Li and Yasuhiro Shirai. Berlin: Mouton de Gruyter, 2000. Pp. v + 261. $106.00 cloth. This book covers everything related to aspect in the field of language acquisition; I was amazed by how the authors managed to do this in such a clear manner in only 261 pages. The book discusses numerous topics related to the acquisition of aspect: from tense to grammatical to lexical aspect, from nativist to functionalist approaches, from a connectionist model to Universal Grammar, and from first language (L1) to second language (L2). It also covers relevant previous research in the acquisition of tense and aspect in Chinese, English, and Japanese. Although the aim of the book is not an extensive survey of the research done on aspect in all possible languages, given the importance of the work done on aspect in Slavic languages, one might have expected to see more discussion of this area.",2004.0,37.0,508.0,False,,"{'volume': '26', 'pages': '469 - 470', 'name': 'Studies in Second Language Acquisition'}","{'bibtex': '@Article{Seidlhofer2004THEAO,\n author = {Barbara Seidlhofer},\n journal = {Studies in Second Language Acquisition},\n pages = {469 - 470},\n title = {THE ACQUISITION OF LEXICAL AND GRAMMATICAL ASPECT},\n volume = {26},\n year = {2004}\n}\n'}","[{'authorId': '2264303363', 'name': 'Barbara Seidlhofer'}]"
1008,5317e548dfbb35fdbecd14779bd85822efc75d75,"Explicit and Implicit Feedback, Modified Output, and SLA: Does Explicit and Implicit Feedback Promote Learning and Learner–Learner Interactions?","Research on interactional feedback has typically focused on feedback learners receive from native speakers (i.e., NS-learner contexts). However, for many second language (L2) learners, the majority of their opportunities to engage in interaction occur with other learners (i.e., learner-learner contexts). The literature has suggested that feedback in learner-learner interaction contexts differs from that found in NS-learner contexts in the quantity of feedback moves (e.g., Mackey, Oliver, & Leeman, 2003), types of feedback used (Pica, Lincoln-Porter, Paninos, & Linnell, 1996), and narrowness of linguistic foci (Toth, 2008). The current study examines how learners provide each other with two types of input-providing feedback, recasts (implicit feedback), and explicit corrections (explicit feedback), in order to investigate how different types of feedback and responses to feedback promote learning of English past tense and locatives. Findings suggest a limited evidence for a relationship between implicit feedback, modified output, and L2 learning, and evidence for a negative effect of explicit corrections from peers. These findings indicate that the role of feedback and modified output in learning may be different in learner-learner interactions than has been found in NS-learner interactions. [ABSTRACT FROM AUTHOR]",2011.0,49.0,94.0,False,,"{'volume': '95', 'pages': '42-63', 'name': 'The Modern Language Journal'}","{'bibtex': '@Article{Adams2011ExplicitAI,\n author = {R. Adams and Ana-Maria Nuevo and T. Egi},\n journal = {The Modern Language Journal},\n pages = {42-63},\n title = {Explicit and Implicit Feedback, Modified Output, and SLA: Does Explicit and Implicit Feedback Promote Learning and Learner–Learner Interactions?},\n volume = {95},\n year = {2011}\n}\n'}","[{'authorId': '48460302', 'name': 'R. Adams'}, {'authorId': '1409367152', 'name': 'Ana-Maria Nuevo'}, {'authorId': '92221073', 'name': 'T. Egi'}]"
1009,532ca98132aa867d3429a57e0e223527ca606b21,Environment as a first class abstraction in multiagent systems,,2007.0,100.0,465.0,True,"{'url': 'https://lirias.kuleuven.be/bitstream/123456789/124216/1/2007JAAMAS.pdf', 'status': None}","{'volume': '14', 'pages': '5-30', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Weyns2007EnvironmentAA,\n author = {Danny Weyns and Andrea Omicini and J. Odell},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {5-30},\n title = {Environment as a first class abstraction in multiagent systems},\n volume = {14},\n year = {2007}\n}\n'}","[{'authorId': '1680103', 'name': 'Danny Weyns'}, {'authorId': '3119182', 'name': 'Andrea Omicini'}, {'authorId': '144687425', 'name': 'J. Odell'}]"
1010,5331fc3019f9400f7aba4d2719671d20157e9bd6,Detecting digital chameleons,,2008.0,54.0,73.0,True,"{'url': 'http://www.stanford.edu/~bailenso/papers/DDC.pdf', 'status': None}","{'volume': '24', 'pages': '66-87', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Bailenson2008DetectingDC,\n author = {J. Bailenson and N. Yee and Kayur Patel and A. Beall},\n journal = {Comput. Hum. Behav.},\n pages = {66-87},\n title = {Detecting digital chameleons},\n volume = {24},\n year = {2008}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '38811484', 'name': 'N. Yee'}, {'authorId': '39699737', 'name': 'Kayur Patel'}, {'authorId': '40458739', 'name': 'A. Beall'}]"
1011,5363ae6d0b2b708542a5e526c30dcd1df8d8fd2e,Repeated Measures Correlation,"Repeated measures correlation (rmcorr) is a statistical technique for determining the common within-individual association for paired measures assessed on two or more occasions for multiple individuals. Simple regression/correlation is often applied to non-independent observations or aggregated data; this may produce biased, specious results due to violation of independence and/or differing patterns between-participants versus within-participants. Unlike simple regression/correlation, rmcorr does not violate the assumption of independence of observations. Also, rmcorr tends to have much greater statistical power because neither averaging nor aggregation is necessary for an intra-individual research question. Rmcorr estimates the common regression slope, the association shared among individuals. To make rmcorr accessible, we provide background information for its assumptions and equations, visualization, power, and tradeoffs with rmcorr compared to multilevel modeling. We introduce the R package (rmcorr) and demonstrate its use for inferential statistics and visualization with two example datasets. The examples are used to illustrate research questions at different levels of analysis, intra-individual, and inter-individual. Rmcorr is well-suited for research questions regarding the common linear association in paired repeated measures data. All results are fully reproducible.",2017.0,56.0,1148.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00456/pdf', 'status': None}","{'volume': '8', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Bakdash2017RepeatedMC,\n author = {J. Bakdash and L. Marusich},\n journal = {Frontiers in Psychology},\n title = {Repeated Measures Correlation},\n volume = {8},\n year = {2017}\n}\n'}","[{'authorId': '2046924', 'name': 'J. Bakdash'}, {'authorId': '2933461', 'name': 'L. Marusich'}]"
1012,536b6852f110559b899639f13f4d17b10e20fe0c,Examining the Influence of Emotional Expressions in Online Consumer Reviews on Perceived Helpfulness,,2020.0,60.0,46.0,False,,"{'volume': '57', 'pages': '102266', 'name': 'Inf. Process. Manag.'}","{'bibtex': '@Article{Chen2020ExaminingTI,\n author = {Mei-Ju Chen and C. Farn},\n journal = {Inf. Process. Manag.},\n pages = {102266},\n title = {Examining the Influence of Emotional Expressions in Online Consumer Reviews on Perceived Helpfulness},\n volume = {57},\n year = {2020}\n}\n'}","[{'authorId': '2000386602', 'name': 'Mei-Ju Chen'}, {'authorId': '2956666', 'name': 'C. Farn'}]"
1013,5386be85c00ed356dd149489309686ddd68f307b,"Chapter 7. Task complexity, modified output, and L2 development in learner–learner interaction","This chapter examines the effects of task complexity [± reasoning demands] on modified output and the relationship between output modifications and L2 development. Seventy-nine adult English as a Second Language learners were divided into two groups: (1) low reasoning demands; and (2) high reasoning demands; and engaged in two sets of tasks which targeted English past tense and locative prepositions. While learners modified their output using a variety of modification moves, learners who completed high complexity tasks produced more self-repair than those who completed the low complexity ones. Self-repair was related to learning locatives for the high complexity group only as measured by delayed grammaticality judgment and oral post-tests. Pushed output, as well as the total amount of modified output, was related to learning past tense for the low complexity group only as measured by delayed grammaticality judgment post-tests. These findings are discussed in light of the Cognition Hypothesis and show an intricate pattern among level of task complexity, type of target structure, type of modified output, and learning.",2011.0,0.0,15.0,False,,"{'volume': '', 'pages': '175-202', 'name': ''}","{'bibtex': '@Inproceedings{Nuevo2011Chapter7T,\n author = {Ana-Maria Nuevo and R. Adams and Lauren Ross-Feldman},\n pages = {175-202},\n title = {Chapter 7. Task complexity, modified output, and L2 development in learner–learner interaction},\n year = {2011}\n}\n'}","[{'authorId': '1409367152', 'name': 'Ana-Maria Nuevo'}, {'authorId': '48460302', 'name': 'R. Adams'}, {'authorId': '1410826438', 'name': 'Lauren Ross-Feldman'}]"
1014,538f7c7fe733e80741e8588934feb1837b31587a,Virtual reality in autism: state of the art,"Autism spectrum disorders are characterized by core deficits with regard to three domains, i.e. social interaction, communication and repetitive or stereotypic behaviour. It is crucial to develop intervention strategies helping individuals with autism, their caregivers and educators in daily life. For this purpose, virtual reality (VR), i.e. a simulation of the real world based on computer graphics, can be useful as it allows instructors and therapists to offer a safe, repeatable and diversifiable environment during learning. This mini review examines studies that have investigated the use of VR in autism.",2011.0,26.0,198.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/87139C7A486EDCC5A62ECEC2FFDB3F19/S2045796011000448a.pdf/div-class-title-virtual-reality-in-autism-state-of-the-art-div.pdf', 'status': None}","{'volume': '20', 'pages': '235 - 238', 'name': 'Epidemiology and Psychiatric Sciences'}","{'bibtex': '@Article{Bellani2011VirtualRI,\n author = {M. Bellani and L. Fornasari and L. Chittaro and P. Brambilla},\n journal = {Epidemiology and Psychiatric Sciences},\n pages = {235 - 238},\n title = {Virtual reality in autism: state of the art},\n volume = {20},\n year = {2011}\n}\n'}","[{'authorId': '2069094', 'name': 'M. Bellani'}, {'authorId': '20890019', 'name': 'L. Fornasari'}, {'authorId': '1692716', 'name': 'L. Chittaro'}, {'authorId': '3110755', 'name': 'P. Brambilla'}]"
1015,53955e4364878c40d64ff17d9b617525331d3460,The embodiment of sexualized virtual selves: The Proteus effect and experiences of self-objectification via avatars,,2013.0,83.0,212.0,False,,"{'volume': '29', 'pages': '930-938', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Fox2013TheEO,\n author = {Jesse Fox and J. Bailenson and Liz Tricase},\n journal = {Comput. Hum. Behav.},\n pages = {930-938},\n title = {The embodiment of sexualized virtual selves: The Proteus effect and experiences of self-objectification via avatars},\n volume = {29},\n year = {2013}\n}\n'}","[{'authorId': '143619505', 'name': 'Jesse Fox'}, {'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '1399011038', 'name': 'Liz Tricase'}]"
1016,53b2df376be86fb82e47d9492f2f053c40af2094,Storytelling in the Higher Education Classroom: Why It Matters,"Abstract Life stories, while a powerful method in social sciences and humanities scholarship, are still not widely accepted and used in the higher education classroom. This commentary encourages college and university professors, particularly those of minority backgrounds, to feel at ease in using storytelling as a classroom pedagogical tool. Stories can illustrate the complexity of current pressing issues such as immigration, identity development, and injustice, among many others. They open up possibilities for student engagement in interpretative and relational learning, and opportunities to examine the narratives that are widely told.",2020.0,14.0,2.0,False,,"{'volume': '68', 'pages': '187 - 188', 'name': 'College Teaching'}","{'bibtex': '@Article{Astiz2020StorytellingIT,\n author = {M. F. Astiz},\n journal = {College Teaching},\n pages = {187 - 188},\n title = {Storytelling in the Higher Education Classroom: Why It Matters},\n volume = {68},\n year = {2020}\n}\n'}","[{'authorId': '48433678', 'name': 'M. F. Astiz'}]"
1017,53c27bdbd7d6c13684e2a1e20a4b13c1a1afd283,Separation: Anxiety and Anger (Attachment and Loss--Volume II),,1974.0,0.0,170.0,False,,"{'volume': '23', 'pages': '428', 'name': 'The Family Coordinator'}","{'bibtex': '@Article{Greenspan1974SeparationAA,\n author = {B. Greenspan and J. Bowlby},\n journal = {The Family Coordinator},\n pages = {428},\n title = {Separation: Anxiety and Anger (Attachment and Loss--Volume II)},\n volume = {23},\n year = {1974}\n}\n'}","[{'authorId': '31450532', 'name': 'B. Greenspan'}, {'authorId': '114946010', 'name': 'J. Bowlby'}]"
1018,53c36c1e5f8639457ffe6db25515e2f8ad25f61e,EmotionMeter: A Multimodal Framework for Recognizing Human Emotions,"In this paper, we present a multimodal emotion recognition framework called EmotionMeter that combines brain waves and eye movements. To increase the feasibility and wearability of EmotionMeter in real-world applications, we design a six-electrode placement above the ears to collect electroencephalography (EEG) signals. We combine EEG and eye movements for integrating the internal cognitive states and external subconscious behaviors of users to improve the recognition accuracy of EmotionMeter. The experimental results demonstrate that modality fusion with multimodal deep neural networks can significantly enhance the performance compared with a single modality, and the best mean accuracy of 85.11% is achieved for four emotions (happy, sad, fear, and neutral). We explore the complementary characteristics of EEG and eye movements for their representational capacities and identify that EEG has the advantage of classifying happy emotion, whereas eye movements outperform EEG in recognizing fear emotion. To investigate the stability of EmotionMeter over time, each subject performs the experiments three times on different days. EmotionMeter obtains a mean recognition accuracy of 72.39% across sessions with the six-electrode EEG and eye movement features. These experimental results demonstrate the effectiveness of EmotionMeter within and between sessions.",2019.0,78.0,444.0,False,,"{'volume': '49', 'pages': '1110-1122', 'name': 'IEEE Transactions on Cybernetics'}","{'bibtex': '@Article{Zheng2019EmotionMeterAM,\n author = {Wei-Long Zheng and Wei Liu and Yifei Lu and Bao-Liang Lu and A. Cichocki},\n journal = {IEEE Transactions on Cybernetics},\n pages = {1110-1122},\n title = {EmotionMeter: A Multimodal Framework for Recognizing Human Emotions},\n volume = {49},\n year = {2019}\n}\n'}","[{'authorId': '3108302', 'name': 'Wei-Long Zheng'}, {'authorId': '2157221046', 'name': 'Wei Liu'}, {'authorId': '2141538523', 'name': 'Yifei Lu'}, {'authorId': '1715839', 'name': 'Bao-Liang Lu'}, {'authorId': '145683892', 'name': 'A. Cichocki'}]"
1019,53ca6eb4330cfd2cbda76febef3e82864d2250f1,Emotional Contagion,"Theorists have proposed that men and women and those in various occupational groups should differ in their susceptibility to primitive emotional contagion. Study 1 was designed to explore the extent to which gender and occupation affected respondents’ self-reports of emotional contagion, as measured by the Emotional Contagion (EC) scale. As predicted, women in a variety of occupations secured higher total EC scores than did men. Study 2 was designed to determine the extent to which gender affected self-reports of emotional contagion (again as measured by the EC scale) and actual responsiveness to others’ emotions. As predicted, women received higher EC scores, reported sharing the targets’ emotions to a greater extent, and were rated by judges as displaying more emotional contagion than did men.",1995.0,23.0,1598.0,False,,"{'volume': '19', 'pages': '355 - 371', 'name': 'Psychology of Women Quarterly'}","{'bibtex': '@Article{Doherty1995EmotionalC,\n author = {William Doherty and Lisa Orirnoto},\n journal = {Psychology of Women Quarterly},\n pages = {355 - 371},\n title = {Emotional Contagion},\n volume = {19},\n year = {1995}\n}\n'}","[{'authorId': '2071426439', 'name': 'William Doherty'}, {'authorId': '2260244028', 'name': 'Lisa Orirnoto'}]"
1021,53cc69a06da9442580d94bc574e04a0fee4ff663,Movements and voices affect perceived sex of virtual conversers,"In this paper, we investigate the ability of humans to determine the sex of conversing characters, based on audio and visual cues. We used a corpus of motions and sounds captured from three male and three female actors conversing about a range of topics. In our Unisensory Experiments, visual and auditory stimuli were presented separately to participants who rated how male or female they found them to be. In our Multisensory Experiments, audio and visual information were integrated to determine how they interacted. We found that audio was much easier to classify than motion, and that audio affected but did not saturate ratings when motion and audio were integrated. Finally, even when informative appearance cues were present, this did not help to disambiguate incongruent motion and audio.",2010.0,17.0,8.0,False,,{'pages': '125-128'},"{'bibtex': ""@Inproceedings{Mcdonnell2010MovementsAV,\n author = {R. Mcdonnell and C. O'Sullivan},\n pages = {125-128},\n title = {Movements and voices affect perceived sex of virtual conversers},\n year = {2010}\n}\n""}","[{'authorId': '145795454', 'name': 'R. Mcdonnell'}, {'authorId': '1404017833', 'name': ""C. O'Sullivan""}]"
1022,53e61ce334dcf8f9252e2b9a8f7112fd10d19bd2,Topography of social touching depends on emotional bonds between humans,"Significance Touch is a powerful tool for communicating positive emotions. However, it has remained unknown to what extent social touch would maintain and establish social bonds. We asked a total of 1,368 people from five countries to reveal, using an Internet-based topographical self-reporting tool, those parts of their body that they would allow relatives, friends, and strangers to touch. These body regions formed relationship-specific maps in which the total area was directly related to the strength of the emotional bond between the participant and the touching person. Cultural influences were minor. We suggest that these relation-specific bodily patterns of social touch constitute an important mechanism supporting the maintenance of human social bonds. Nonhuman primates use social touch for maintenance and reinforcement of social structures, yet the role of social touch in human bonding in different reproductive, affiliative, and kinship-based relationships remains unresolved. Here we reveal quantified, relationship-specific maps of bodily regions where social touch is allowed in a large cross-cultural dataset (N = 1,368 from Finland, France, Italy, Russia, and the United Kingdom). Participants were shown front and back silhouettes of human bodies with a word denoting one member of their social network. They were asked to color, on separate trials, the bodily regions where each individual in their social network would be allowed to touch them. Across all tested cultures, the total bodily area where touching was allowed was linearly dependent (mean r2 = 0.54) on the emotional bond with the toucher, but independent of when that person was last encountered. Close acquaintances and family members were touched for more reasons than less familiar individuals. The bodily area others are allowed to touch thus represented, in a parametric fashion, the strength of the relationship-specific emotional bond. We propose that the spatial patterns of human social touch reflect an important mechanism supporting the maintenance of social bonds.",2015.0,42.0,265.0,True,"{'url': 'https://www.pnas.org/content/pnas/112/45/13811.full.pdf', 'status': None}","{'volume': '112', 'pages': '13811 - 13816', 'name': 'Proceedings of the National Academy of Sciences'}","{'bibtex': '@Article{Suvilehto2015TopographyOS,\n author = {Juulia T. Suvilehto and E. Glerean and Robin I. M. Dunbar and R. Hari and L. Nummenmaa},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {13811 - 13816},\n title = {Topography of social touching depends on emotional bonds between humans},\n volume = {112},\n year = {2015}\n}\n'}","[{'authorId': '4687082', 'name': 'Juulia T. Suvilehto'}, {'authorId': '2825466', 'name': 'E. Glerean'}, {'authorId': '144610599', 'name': 'Robin I. M. Dunbar'}, {'authorId': '143873866', 'name': 'R. Hari'}, {'authorId': '2036051', 'name': 'L. Nummenmaa'}]"
1023,53e66b6934516a9859573f4866f81f04bce977ae,Control of goal-directed and stimulus-driven attention in the brain,,2002.0,129.0,11076.0,True,"{'url': 'https://www.research.unipd.it/bitstream/11577/3439853/1/nrn755.pdf', 'status': None}","{'volume': '3', 'pages': '201-215', 'name': 'Nature Reviews Neuroscience'}","{'bibtex': '@Article{Corbetta2002ControlOG,\n author = {M. Corbetta and G. Shulman},\n journal = {Nature Reviews Neuroscience},\n pages = {201-215},\n title = {Control of goal-directed and stimulus-driven attention in the brain},\n volume = {3},\n year = {2002}\n}\n'}","[{'authorId': '1723344', 'name': 'M. Corbetta'}, {'authorId': '39269549', 'name': 'G. Shulman'}]"
1024,53f5d8a344348c3deb2bc8de7d36c012bf72c91d,Power implications of touch in male—Female relationships,,1978.0,6.0,52.0,False,,"{'volume': '4', 'pages': '103-110', 'name': 'Sex Roles'}","{'bibtex': '@Article{Summerhayes1978PowerIO,\n author = {Diana L. Summerhayes and Robert W. Suchner},\n journal = {Sex Roles},\n pages = {103-110},\n title = {Power implications of touch in male—Female relationships},\n volume = {4},\n year = {1978}\n}\n'}","[{'authorId': '115664158', 'name': 'Diana L. Summerhayes'}, {'authorId': '117302284', 'name': 'Robert W. Suchner'}]"
1025,53ff0f5d9f2ecf1654cafb2ec204521489ca808b,Modeling Cognition–Emotion Interactions in Symbolic Agent Architectures: Examples of Research and Applied Models,,2018.0,24.0,4.0,False,,"{'name': 'Intelligent Systems, Control and Automation: Science and Engineering'}","{'bibtex': '@Article{Hudlicka2018ModelingCI,\n author = {E. Hudlicka},\n booktitle = {Intelligent Systems, Control and Automation: Science and Engineering},\n journal = {Intelligent Systems, Control and Automation: Science and Engineering},\n title = {Modeling Cognition–Emotion Interactions in Symbolic Agent Architectures: Examples of Research and Applied Models},\n year = {2018}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
1026,5437c4dc3ce6e571817481cdd6cb8d2c7afb785e,Beliefs about the Minds of Others Influence How We Process Sensory Information,"Attending where others gaze is one of the most fundamental mechanisms of social cognition. The present study is the first to examine the impact of the attribution of mind to others on gaze-guided attentional orienting and its ERP correlates. Using a paradigm in which attention was guided to a location by the gaze of a centrally presented face, we manipulated participants' beliefs about the gazer: gaze behavior was believed to result either from operations of a mind or from a machine. In Experiment 1, beliefs were manipulated by cue identity (human or robot), while in Experiment 2, cue identity (robot) remained identical across conditions and beliefs were manipulated solely via instruction, which was irrelevant to the task. ERP results and behavior showed that participants' attention was guided by gaze only when gaze was believed to be controlled by a human. Specifically, the P1 was more enhanced for validly, relative to invalidly, cued targets only when participants believed the gaze behavior was the result of a mind, rather than of a machine. This shows that sensory gain control can be influenced by higher-order (task-irrelevant) beliefs about the observed scene. We propose a new interdisciplinary model of social attention, which integrates ideas from cognitive and social neuroscience, as well as philosophy in order to provide a framework for understanding a crucial aspect of how humans' beliefs about the observed scene influence sensory processing.",2014.0,53.0,128.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0094339&type=printable', 'status': None}","{'volume': '9', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Wykowska2014BeliefsAT,\n author = {A. Wykowska and E. Wiese and A. Prosser and H. Müller},\n journal = {PLoS ONE},\n title = {Beliefs about the Minds of Others Influence How We Process Sensory Information},\n volume = {9},\n year = {2014}\n}\n'}","[{'authorId': '2351204', 'name': 'A. Wykowska'}, {'authorId': '2658383', 'name': 'E. Wiese'}, {'authorId': '2079343109', 'name': 'A. Prosser'}, {'authorId': '2093435673', 'name': 'H. Müller'}]"
1027,54413f5265f7b6e8dc19858549e7d4d96f1a7eb1,Development of a Virtual Classroom for High School Teacher Training,,2016.0,5.0,5.0,False,,{'pages': '489-493'},"{'bibtex': '@Inproceedings{Huang2016DevelopmentOA,\n author = {Hung-Hsuan Huang and Y. Ida and Kohei Yamaguchi and K. Kawagoe},\n pages = {489-493},\n title = {Development of a Virtual Classroom for High School Teacher Training},\n year = {2016}\n}\n'}","[{'authorId': '1684753', 'name': 'Hung-Hsuan Huang'}, {'authorId': '50166441', 'name': 'Y. Ida'}, {'authorId': '2116781460', 'name': 'Kohei Yamaguchi'}, {'authorId': '2865341', 'name': 'K. Kawagoe'}]"
1028,545ce673b236ec4413a64df42204ab9c79ed6e15,"Machine Audition: Principles, Algorithms and Systems","Machine audition is the study of algorithms and systems for the automatic analysis and understanding of sound by machine. It has recently attracted increasing interest within several research communities, such as signal processing, machine learning, auditory modeling, perception and cognition, psychology, pattern recognition, and artificial intelligence. However, the developments made so far are fragmented within these disciplines, lacking connections and incurring potentially overlapping research activities in this subject area. Machine Audition: Principles, Algorithms and Systems contains advances in algorithmic developments, theoretical frameworks, and experimental research findings. This book is useful for professionals who want an improved understanding about how to design algorithms for performing automatic analysis of audio signals, construct a computing system for understanding sound, and learn how to build advanced human-computer interactive systems.",2010.0,296.0,190.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Wang2010MachineAP,\n author = {Wenwu Wang},\n title = {Machine Audition: Principles, Algorithms and Systems},\n year = {2010}\n}\n'}","[{'authorId': '2134821831', 'name': 'Wenwu Wang'}]"
1029,548c2fae5e76d5f99f8432a4f9a2990a4237de00,The process of emotional experience: A self-perception theory.,,1992.0,0.0,109.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Laird1992ThePO,\n author = {J. Laird and C. Bresler},\n title = {The process of emotional experience: A self-perception theory.},\n year = {1992}\n}\n'}","[{'authorId': '36136195', 'name': 'J. Laird'}, {'authorId': '118401445', 'name': 'C. Bresler'}]"
1030,548c49ba181be28c69e8a46831b89a350c0c30e8,"Which do you feel comfortable, interview by a real doctor or by a virtual doctor? A comparative study of responses to inquiries with various psychological intensities, for the development of the Hyper Hospital","The ""Hyper Hospital"" is a novel medical care system which will be constructed on an electronic information network. The human interface of the Hyper Hospital based on the modern virtual reality technology is expected to maximally enhance patients' ability of healing illness by computer-supported online visual consultations. In order to investigate the effects and features of online visual consultations in the Hyper Hospital, we conducted an experiment to clarify the influence of electronic interviews on the talking behavior of interviewees in the similar context to real doctor-patient interactions. Four types of distant-confrontation interviews were presented to voluntary subjects and their verbal and nonverbal responses were analyzed from the human ethological viewpoints. In the media-mediated interviews both the latency and the duration of interviewees' utterances in answering questions increased compared with those of live face to face interviews. These results suggest that the interviewee became more verbose or talkative in the mediated interviews, but his psychological tension was generally augmented.<<ETX>>",1993.0,6.0,9.0,False,,"{'pages': '370-374', 'name': 'Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication'}","{'bibtex': '@Article{Yoshida1993WhichDY,\n author = {A. Yoshida and Y. Hagita and K. Yamazaki and T. Yamaguchi},\n journal = {Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication},\n pages = {370-374},\n title = {Which do you feel comfortable, interview by a real doctor or by a virtual doctor? A comparative study of responses to inquiries with various psychological intensities, for the development of the Hyper Hospital},\n year = {1993}\n}\n'}","[{'authorId': '2972995', 'name': 'A. Yoshida'}, {'authorId': '70298295', 'name': 'Y. Hagita'}, {'authorId': '32420943', 'name': 'K. Yamazaki'}, {'authorId': '2107215814', 'name': 'T. Yamaguchi'}]"
1031,54a5fc0cdf5d252f53a05e3ec07477a4774c41f5,Empathy framework for embodied conversational agents,,2020.0,49.0,33.0,False,,"{'volume': '59', 'pages': '123-132', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Yalçın2020EmpathyFF,\n author = {Ö. Yalçın},\n journal = {Cognitive Systems Research},\n pages = {123-132},\n title = {Empathy framework for embodied conversational agents},\n volume = {59},\n year = {2020}\n}\n'}","[{'authorId': '80264274', 'name': 'Ö. Yalçın'}]"
1033,54c6a3cff54ec889609d05aa46d0229ec11ccdee,Why Psychologists Should by Default Use Welch's t-test Instead of Student's t-test with Unequal Group Sizes,"When comparing two independent groups, psychology researchers commonly use Student’s t -tests. Assumptions of normality and homogeneity of variance underlie this test. More often than not, when these conditions are not met, Student’s t -test can be severely biased and lead to invalid statistical inferences. Moreover, we argue that the assumption of equal variances will seldom hold in psychological research, and choosing between Student’s t -test and Welch’s t -test based on the outcomes of a test of the equality of variances often fails to provide an appropriate answer. We show that the Welch’s t -test provides a better control of Type 1 error rates when the assumption of homogeneity of variance is not met, and it loses little robustness compared to Student’s t -test when the assumptions are met. We argue that Welch’s t -test should be used as a default strategy.",2017.0,45.0,466.0,True,"{'url': 'http://www.rips-irsp.com/articles/10.5334/irsp.82/galley/42/download/', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Delacre2017WhyPS,\n author = {Marie Delacre and D. Lakens and C. Leys},\n title = {Why Psychologists Should by Default Use Welch's t-test Instead of Student's t-test with Unequal Group Sizes},\n year = {2017}\n}\n""}","[{'authorId': '144856357', 'name': 'Marie Delacre'}, {'authorId': '87792747', 'name': 'D. Lakens'}, {'authorId': '40296894', 'name': 'C. Leys'}]"
1034,54cc1f2e86d1913521b466cef19d72ed02b6c800,Argonaute—a database for gene regulation by mammalian microRNAs,,2005.0,55.0,50220.0,True,"{'url': 'https://academic.oup.com/nar/article-pdf/34/suppl_1/D115/3925296/gkj093.pdf', 'status': None}","{'volume': '34', 'pages': 'D115 - D118', 'name': 'Nucleic Acids Research'}","{'bibtex': '@Article{Shahi2005ArgonauteaDF,\n author = {Priyanka Shahi and Serguei Loukianiouk and Andreas Bohne-Lang and M. Kenzelmann and Stefan Küffer and S. Maertens and Roland Eils and Hermann-Josef Gröne and Norbert Gretz and Benedikt Brors},\n journal = {Nucleic Acids Research},\n pages = {D115 - D118},\n title = {Argonaute—a database for gene regulation by mammalian microRNAs},\n volume = {34},\n year = {2005}\n}\n'}","[{'authorId': '2258460322', 'name': 'Priyanka Shahi'}, {'authorId': '51951956', 'name': 'Serguei Loukianiouk'}, {'authorId': '2258458990', 'name': 'Andreas Bohne-Lang'}, {'authorId': '34263049', 'name': 'M. Kenzelmann'}, {'authorId': '2258458988', 'name': 'Stefan Küffer'}, {'authorId': '2258459103', 'name': 'S. Maertens'}, {'authorId': '2257284464', 'name': 'Roland Eils'}, {'authorId': '2244235521', 'name': 'Hermann-Josef Gröne'}, {'authorId': '2244740436', 'name': 'Norbert Gretz'}, {'authorId': '2254975286', 'name': 'Benedikt Brors'}]"
1036,54dc19cc9375b20159f5e5e3e571616246b2c029,Modeling Task-Based vs. Affect-based Feedback Behavior in Pedagogical Agents: An Inductive Approach,"Affect has been the subject of increasing attention in cognitive accounts of learning. Many intelligent tutoring systems now seek to adapt pedagogy to student affective and motivational processes in an effort to increase the effectiveness of tutorial interaction and improve learning outcomes. However, the majority of research on tutorial feedback has focused on pedagogical content, often at the expense of the affective component of the learning process. It is unclear under which circumstances it is more appropriate to focus directly on student affect and when support is best offered through task-related feedback. This paper proposes an inductive framework for modeling task-based and affect-based feedback to inform the behavior of pedagogical agents within a narrative-centered learning environment.",2009.0,28.0,33.0,False,,{'pages': '25-32'},"{'bibtex': '@Inproceedings{Robison2009ModelingTV,\n author = {J. Robison and Scott W. McQuiggan and James C. Lester},\n pages = {25-32},\n title = {Modeling Task-Based vs. Affect-based Feedback Behavior in Pedagogical Agents: An Inductive Approach},\n year = {2009}\n}\n'}","[{'authorId': '31942647', 'name': 'J. Robison'}, {'authorId': '2779835', 'name': 'Scott W. McQuiggan'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
1037,5508b7d4ae2a375b6a8d448b90205a417a70f40c,Effect of Teacher's Gaze on Children's Story Recall,"Two studies utilize a repeated-measures design to compare the story-recall performances of 46 primary-school children who were administered stories in the presence and absence of teacher's gaze. Analysis indicates a significant positive relationship between gaze and recall, especially among boys. These findings are discussed in terms of the literature on the effects of eye contact and teacher's expectancies.",1980.0,19.0,61.0,False,,"{'volume': '50', 'pages': '35 - 42', 'name': 'Perceptual and Motor Skills'}","{'bibtex': ""@Article{Otteson1980EffectOT,\n author = {J. P. Otteson and C. Otteson},\n journal = {Perceptual and Motor Skills},\n pages = {35 - 42},\n title = {Effect of Teacher's Gaze on Children's Story Recall},\n volume = {50},\n year = {1980}\n}\n""}","[{'authorId': '5118019', 'name': 'J. P. Otteson'}, {'authorId': '115568743', 'name': 'C. Otteson'}]"
1038,55216d13302c27514e987ca657e30bd3e5fcc841,Machinery for Artificial Emotions,"We present a preliminary definition and theory of artificial emotion viewed as a sequential process comprising the appraisal of the agent global state, the generation of an emotion-signal, and an emotion-response. This theory distinguishes cognitive from affective appraisal on an architecture-grounded basis. Affective appraisal is performed by the affective component of the architecture; cognitive appraisal is performed by its cognitive component. A scheme for emotion classification with seven dimensions is presented. Among them, we emphasize the roles played by emotions and the way these roles are fulfilled. It is shown how emotions are generated, represented, and used in the Salt & Pepper architecture for autonomous agents (Botelho, 1997). Salt & Pepper is a specific architecture comprising an affective engine, a cognitive and behavioral engine, and an interruption manager. Most properties of the cognitive and behavioral engine rely upon a hybrid associative, schema-based long-term memory. In Salt & Pep...",2001.0,40.0,36.0,False,,"{'volume': '32', 'pages': '465-506', 'name': 'Cybern. Syst.'}","{'bibtex': '@Article{Botelho2001MachineryFA,\n author = {L. Botelho and H. Coelho},\n journal = {Cybern. Syst.},\n pages = {465-506},\n title = {Machinery for Artificial Emotions},\n volume = {32},\n year = {2001}\n}\n'}","[{'authorId': '2509141', 'name': 'L. Botelho'}, {'authorId': '144739158', 'name': 'H. Coelho'}]"
1039,554f93785da4640eb9583a92218253b0dc0de56f,Realizing Multimodal Behavior - Closing the Gap between Behavior Planning and Embodied Agent Presentation,,2010.0,11.0,30.0,False,,{'pages': '57-63'},"{'bibtex': '@Inproceedings{Kipp2010RealizingMB,\n author = {Michael Kipp and A. Héloir and M. Schröder and Patrick Gebhard},\n pages = {57-63},\n title = {Realizing Multimodal Behavior - Closing the Gap between Behavior Planning and Embodied Agent Presentation},\n year = {2010}\n}\n'}","[{'authorId': '145616714', 'name': 'Michael Kipp'}, {'authorId': '2812935', 'name': 'A. Héloir'}, {'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}]"
1040,557837599c2199a35457a5ab02e696f98ef03522,Amygdala activation at 3T in response to human and avatar facial expressions of emotions,,2007.0,51.0,139.0,False,,"{'volume': '161', 'pages': '126-133', 'name': 'Journal of Neuroscience Methods'}","{'bibtex': '@Article{Moser2007AmygdalaAA,\n author = {E. Moser and B. Derntl and S. Robinson and B. Fink and R. Gur and K. Grammer},\n journal = {Journal of Neuroscience Methods},\n pages = {126-133},\n title = {Amygdala activation at 3T in response to human and avatar facial expressions of emotions},\n volume = {161},\n year = {2007}\n}\n'}","[{'authorId': '145056721', 'name': 'E. Moser'}, {'authorId': '2643854', 'name': 'B. Derntl'}, {'authorId': '145455683', 'name': 'S. Robinson'}, {'authorId': '4166802', 'name': 'B. Fink'}, {'authorId': '144762538', 'name': 'R. Gur'}, {'authorId': '1850299', 'name': 'K. Grammer'}]"
1041,557b0d6b7ae7f9d046bd8914b354628cd1c9c20b,Two Sides of Appraisal: Implementing Appraisal and Its Consequences within a Cognitive Architecture,"Appraisal processes provide an affective assessment of an agent’s current situation, in light of its needs and goals. This paper describes a computational model of the appraisal process, implemented within the broader context of a cognitive agent architecture. A particular focus here is on modeling the interacting influences of states and traits on perception and cognition, including their effects on the appraisal process itself. These effects are modeled by manipulating a series of architecture parameters, such as the speed and processing capacity of the individual modules. The paper presents results of an evaluation experiment modeling the behavior of three types of agents: ‘normal’, ‘anxious’, and ‘aggressive’. The appraisal model generated different affective appraisals of the same set of external circumstances for the different agent types, resulting in distinct emotions, and eventually leading to observable differences in behavior. The paper concludes with a brief discussion of some of the issues encountered during the appraisal model development.",2004.0,27.0,27.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hudlicka2004TwoSO,\n author = {E. Hudlicka},\n title = {Two Sides of Appraisal: Implementing Appraisal and Its Consequences within a Cognitive Architecture},\n year = {2004}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
1042,55c6ef565aa51e37eea2c536f104b962af54aa1c,Animated wrinkle maps,An efficient method for rendering animated wrinkles on a human face is presented. This method allows an animator to independently blend multiple wrinkle maps across multiple regions of a textured mesh such as the female character shown in Figure 1. This method is both efficient in terms of computation as well as storage costs and is easily implemented in a real-time application using modern programmable graphics processors.,2007.0,2.0,39.0,False,,{'name': 'ACM SIGGRAPH 2007 courses'},"{'bibtex': '@Article{Oat2007AnimatedWM,\n author = {Christopher Oat},\n journal = {ACM SIGGRAPH 2007 courses},\n title = {Animated wrinkle maps},\n year = {2007}\n}\n'}","[{'authorId': '2355579', 'name': 'Christopher Oat'}]"
1043,55dfc09b17523d85c74c0206e604c837a3049698,Using real life incidents for realistic virtual crowds with data-driven emotion contagion ✩,"We propose a data-driven approach for tuning, validating and optimizing crowd simulations by learning parameters from real-life videos. We discuss the common traits of incidents and their video footages suitable for the learning step. We then demonstrate the learning process in three real-life incidents: a bombing attack, a panic situation on the subway and a Black Friday rush. We reanimate the incidents using an existing emotion contagion and crowd simulation framework and optimize the parameters that characterize agent behavior with respect to the data extracted from the video footages of the incidents. © 2018 Elsevier Ltd. All rights reserved.",2018.0,0.0,6.0,False,,,"{'bibtex': '@Inproceedings{Eren2018UsingRL,\n author = {A. Eren and ğur Güdükbay and Funda Durupinar},\n title = {Using real life incidents for realistic virtual crowds with data-driven emotion contagion ✩},\n year = {2018}\n}\n'}","[{'authorId': '2059121007', 'name': 'A. Eren'}, {'authorId': '2084226639', 'name': 'ğur Güdükbay'}, {'authorId': '2643744', 'name': 'Funda Durupinar'}]"
1044,55eb7ec9b9740f6c69d6e62062a24bfa091bbb0c,CAS(ME)2: A Database of Spontaneous Macro-expressions and Micro-expressions,,2016.0,36.0,25.0,False,,{'pages': '48-59'},"{'bibtex': '@Inproceedings{Qu2016CASME2AD,\n author = {Fangbing Qu and Sujing Wang and Wen-Jing Yan and Xiaolan Fu},\n pages = {48-59},\n title = {CAS(ME)2: A Database of Spontaneous Macro-expressions and Micro-expressions},\n year = {2016}\n}\n'}","[{'authorId': '34495371', 'name': 'Fangbing Qu'}, {'authorId': '2116429451', 'name': 'Sujing Wang'}, {'authorId': '9185305', 'name': 'Wen-Jing Yan'}, {'authorId': '144054357', 'name': 'Xiaolan Fu'}]"
1045,55f1773c1c806054dba0aa3de1b19e1621f6255e,Effects of Virtual Agent Gender on User Performance and Preference in a VR Training Program,,2019.0,27.0,4.0,False,,{'name': 'Lecture Notes in Networks and Systems'},"{'bibtex': '@Article{Shang2019EffectsOV,\n author = {Xiumin Shang and Marcelo Kallmann and A. Arif},\n journal = {Lecture Notes in Networks and Systems},\n title = {Effects of Virtual Agent Gender on User Performance and Preference in a VR Training Program},\n year = {2019}\n}\n'}","[{'authorId': '51499868', 'name': 'Xiumin Shang'}, {'authorId': '1682684', 'name': 'Marcelo Kallmann'}, {'authorId': '145888782', 'name': 'A. Arif'}]"
1046,55f9ef36c9b82fb8254cffb5d81453ec8283e5d1,A closer look at preschoolers' freely produced labels for facial expressions.,"Children's performance on free labeling of prototypical facial expressions of basic emotions is modest and improves only gradually. In 3 data sets (N = 80, ages 4 or 5 years; N = 160, ages 2 to 5 years; N = 80, ages 3 to 4 years), errors remained even when method factors (poor stimuli, unavailability of an appropriate label, or the difficulty of a production task) were controlled. Children's use of emotion labels increased with age in a systematic order: Happy, angry, and sad emerged early and in that order, were more accessible, and were applied broadly (overgeneralized) but systematically. Scared, surprised, and disgusted emerged later and often in that order, were less accessible, and were applied narrowly.",2003.0,52.0,391.0,False,,"{'volume': '39 1', 'pages': '\n          114-28\n        ', 'name': 'Developmental psychology'}","{'bibtex': ""@Article{Widen2003ACL,\n author = {Sherri C Widen and J. Russell},\n journal = {Developmental psychology},\n pages = {\n          114-28\n        },\n title = {A closer look at preschoolers' freely produced labels for facial expressions.},\n volume = {39 1},\n year = {2003}\n}\n""}","[{'authorId': '3947094', 'name': 'Sherri C Widen'}, {'authorId': '46367714', 'name': 'J. Russell'}]"
1047,5609bcf08a4d6f552e5401608a9762cb09e3bbe7,Teaching negotiation 1,,2016.0,0.0,1.0,False,,"{'volume': '', 'pages': '38-39', 'name': 'English teaching professional'}","{'bibtex': '@Article{Tedone2016TeachingN1,\n author = {David Tedone},\n journal = {English teaching professional},\n pages = {38-39},\n title = {Teaching negotiation 1},\n year = {2016}\n}\n'}","[{'authorId': '89318602', 'name': 'David Tedone'}]"
1048,562151dbc19ea6850ad2f35d981ffb93dc7788c8,Facial expression recognition using emotion avatar image,"Existing facial expression recognition techniques analyze the spatial and temporal information for every single frame in a human emotion video. On the contrary, we create the Emotion Avatar Image (EAI) as a single good representation for each video or image sequence for emotion recognition. In this paper, we adopt the recently introduced SIFT flow algorithm to register every frame with respect to an Avatar reference face model. Then, an iterative algorithm is used not only to super-resolve the EAI representation for each video and the Avatar reference, but also to improve the recognition performance. Subsequently, we extract the features from EAIs using both Local Binary Pattern (LBP) and Local Phase Quantization (LPQ). Then the results from both texture descriptors are tested on the Facial Expression Recognition and Analysis Challenge (FERA2011) data, GEMEP-FERA dataset. To evaluate this simple yet powerful idea, we train our algorithm only using the given 155 videos of training data from GEMEP-FERA dataset. The result shows that our algorithm eliminates the person-specific information for emotion and performs well on unseen data.",2011.0,19.0,99.0,False,,"{'pages': '866-871', 'name': 'Face and Gesture 2011'}","{'bibtex': '@Article{Yang2011FacialER,\n author = {Songfan Yang and B. Bhanu},\n journal = {Face and Gesture 2011},\n pages = {866-871},\n title = {Facial expression recognition using emotion avatar image},\n year = {2011}\n}\n'}","[{'authorId': '1803478', 'name': 'Songfan Yang'}, {'authorId': '144452270', 'name': 'B. Bhanu'}]"
1049,562b3a980bbe291390ac1bc7ec81ca6be9d06be5,Autonomic nervous system activity in emotion: A review,,2010.0,335.0,2304.0,False,,"{'volume': '84', 'pages': '394-421', 'name': 'Biological Psychology'}","{'bibtex': '@Article{Kreibig2010AutonomicNS,\n author = {Sylvia D. Kreibig},\n journal = {Biological Psychology},\n pages = {394-421},\n title = {Autonomic nervous system activity in emotion: A review},\n volume = {84},\n year = {2010}\n}\n'}","[{'authorId': '3279362', 'name': 'Sylvia D. Kreibig'}]"
1050,563e3f5ead81b9491c7622695611a44b8fa9870d,"Affective e-Learning: Using ""Emotional"" Data to Improve Learning in Pervasive Learning Environment","Using emotion detection technologies from biophysical signals, this study explored how emotion evolves during learning process and how emotion feedback could be used to improve learning experiences. This article also described a cutting-edge pervasive e-Learning platform used in a Shanghai online college and proposed an affective e-Learning model, which combined learners’ emotions with the Shanghai e-Learning platform. The study was guided by Russell’s circumplex model of affect and Kort’s learning spiral model. The results about emotion recognition from physiological signals achieved a best-case accuracy (86.3%) for four types of learning emotions. And results from emotion revolution study showed that engagement and confusion were the most important and frequently occurred emotions in learning, which is consistent with the findings from AutoTutor project. No evidence from this study validated Kort’s learning spiral model. An experimental prototype of the affective e-Learning model was built to help improve students’ learning experience by customizing learning material delivery based on students’ emotional state. Experiments indicated the superiority of emotion aware over non-emotion-aware with a performance increase of 91%.",2009.0,79.0,438.0,False,,"{'volume': '12', 'pages': '176-189', 'name': 'J. Educ. Technol. Soc.'}","{'bibtex': '@Article{Shen2009AffectiveEU,\n author = {Liping Shen and Minjuan Wang and R. Shen},\n journal = {J. Educ. Technol. Soc.},\n pages = {176-189},\n title = {Affective e-Learning: Using ""Emotional"" Data to Improve Learning in Pervasive Learning Environment},\n volume = {12},\n year = {2009}\n}\n'}","[{'authorId': '2026339', 'name': 'Liping Shen'}, {'authorId': '66986544', 'name': 'Minjuan Wang'}, {'authorId': '2613907', 'name': 'R. Shen'}]"
1051,563e821bb5ea825efb56b77484f5287f08cf3753,"Convolutional networks for images, speech, and time series",,1998.0,18.0,5102.0,False,,"{'volume': '', 'pages': '255-258', 'name': ''}","{'bibtex': '@Inproceedings{LeCun1998ConvolutionalNF,\n author = {Yann LeCun and Yoshua Bengio},\n pages = {255-258},\n title = {Convolutional networks for images, speech, and time series},\n year = {1998}\n}\n'}","[{'authorId': '1688882', 'name': 'Yann LeCun'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]"
1052,5651a95e52669118b27463083755cb2437d8d8da,A multi-layer artificial intelligence and sensing based affective conversational embodied agent,"Building natural and conversational virtual humans is a task of formidable complexity. We believe that, especially when building agents that affectively interact with biological humans in real-time, a cognitive science-based, multilayered sensing and artificial intelligence (AI) systems approach is needed. For this demo, we show a working version (through human interaction with it) our modular system of natural, conversation 3D virtual human using AI or sensing layers. These including sensing the human user via facial emotion recognition, voice stress, semantic meaning of the words, eye gaze, heart rate, and galvanic skin response. These inputs are combined with AI sensing and recognition of the environment using deep learning natural language captioning or dense captioning. These are all processed by our AI avatar system allowing for an affective and empathetic conversation using an NLP topic-based dialogue capable of using facial expressions, gestures, breath, eye gaze and voice language-based two-way back and forth conversations with a sensed human. Our lab has been building these systems in stages over the years.",2019.0,3.0,6.0,False,,"{'pages': '91-92', 'name': '2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)'}","{'bibtex': '@Article{DiPaola2019AMA,\n author = {S. DiPaola and Ö. Yalçın},\n journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)},\n pages = {91-92},\n title = {A multi-layer artificial intelligence and sensing based affective conversational embodied agent},\n year = {2019}\n}\n'}","[{'authorId': '1700040', 'name': 'S. DiPaola'}, {'authorId': '80264274', 'name': 'Ö. Yalçın'}]"
1053,565d85a75332607440e2cf8d67ab20650b8f83da,An Emotion Model of 3D Virtual Characters in Intelligent Virtual Environment,,2005.0,14.0,45.0,True,"{'url': 'http://pdf.aminer.org/000/018/687/an_emotion_model_of_d_virtual_characters_in_intelligent_virtual.pdf', 'status': None}",{'pages': '629-636'},"{'bibtex': '@Inproceedings{Liu2005AnEM,\n author = {Z. Liu and Zhigeng Pan},\n pages = {629-636},\n title = {An Emotion Model of 3D Virtual Characters in Intelligent Virtual Environment},\n year = {2005}\n}\n'}","[{'authorId': '46270580', 'name': 'Z. Liu'}, {'authorId': '145086315', 'name': 'Zhigeng Pan'}]"
1055,565ec5cd68f81e5d3d1a9306335795622d1425e4,Building Virtual Reality Environments for Distance Education on the Web: A Case Study in Medical Education,"The paper presents an investigation into the role of virtual reality and web technologies in the field of distance education. Within this frame, special emphasis is given on the building of web-based virtual learning environments so as to successfully fulfill their educational objectives. In particular, basic pedagogical methods are studied, focusing mainly on the efficient preparation, approach and presentation of learning content, and specific designing rules are presented considering the hypermedia, virtual and educational nature of this kind of applications. The paper also aims to highlight the educational benefits arising from the use of virtual reality technology in medicine and study the emerging area of web-based medical simulations. Finally, an innovative virtual reality environment for distance education in medicine is demonstrated. The proposed environment reproduces conditions of the real learning process and enhances learning through a real-time interactive simulator. Keywords—Distance education, medicine, virtual reality, web.",2007.0,28.0,36.0,False,,"{'volume': '1', 'pages': '645-653', 'name': 'World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering'}","{'bibtex': '@Article{Dimitropoulos2007BuildingVR,\n author = {K. Dimitropoulos and A. Manitsaris and I. Mavridis},\n journal = {World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering},\n pages = {645-653},\n title = {Building Virtual Reality Environments for Distance Education on the Web: A Case Study in Medical Education},\n volume = {1},\n year = {2007}\n}\n'}","[{'authorId': '2296506', 'name': 'K. Dimitropoulos'}, {'authorId': '144028942', 'name': 'A. Manitsaris'}, {'authorId': '143612830', 'name': 'I. Mavridis'}]"
1056,567219290b6a01b55c63221f700245c9f8f529ee,The CUBE-G approach – Coaching culture-specific nonverbal behavior by virtual agents,"Embodied conversational agents have been proven to be powerful tools for engaging users in interactions and thus are suitable for training scenarios that rely on a role-playing metaphor. In the CUBE-G project we propose an approach for culture-adaptive behavior generation of such agents, which can be employed in edutainment applications for increasing cultural awareness and for learning some of the appropriate behavior routines. In this paper we present the methodological approach of a standardized collection of multimodal behavioral corpora for different cultures to inform a parametrized model of cultural behavior",2007.0,20.0,48.0,False,,,"{'bibtex': '@Inproceedings{Rehm2007TheCA,\n author = {M. Rehm and E. André and Nikolaus Bee and Birgit Lugrin and M. Wissner},\n title = {The CUBE-G approach – Coaching culture-specific nonverbal behavior by virtual agents},\n year = {2007}\n}\n'}","[{'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '1790555', 'name': 'Nikolaus Bee'}, {'authorId': '2158172', 'name': 'Birgit Lugrin'}, {'authorId': '2754538', 'name': 'M. Wissner'}]"
1057,56a179f61072d0b1d554b5d9f2add15009f6c938,Crowd macro state detection using entropy model,,2015.0,27.0,14.0,False,,"{'volume': '431', 'pages': '84-93', 'name': 'Physica A-statistical Mechanics and Its Applications'}","{'bibtex': '@Article{Zhao2015CrowdMS,\n author = {Ying Zhao and Mengqi Yuan and G. Su and Tao Chen},\n journal = {Physica A-statistical Mechanics and Its Applications},\n pages = {84-93},\n title = {Crowd macro state detection using entropy model},\n volume = {431},\n year = {2015}\n}\n'}","[{'authorId': '2118976734', 'name': 'Ying Zhao'}, {'authorId': '2055429479', 'name': 'Mengqi Yuan'}, {'authorId': '2881973', 'name': 'G. Su'}, {'authorId': '2118211827', 'name': 'Tao Chen'}]"
1058,56c63c2ee7480cccae09b76f590f7f057a58b9e8,Combining Facial and Postural Expressions of Emotions in a Virtual Character,,2009.0,40.0,66.0,False,,{'pages': '287-300'},"{'bibtex': '@Inproceedings{Clavel2009CombiningFA,\n author = {C. Clavel and Justine Plessier and Jean-Claude Martin and Laurent Ach and Benoît Morel},\n pages = {287-300},\n title = {Combining Facial and Postural Expressions of Emotions in a Virtual Character},\n year = {2009}\n}\n'}","[{'authorId': '1724799', 'name': 'C. Clavel'}, {'authorId': '2094801535', 'name': 'Justine Plessier'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '2305305', 'name': 'Laurent Ach'}, {'authorId': '32214926', 'name': 'Benoît Morel'}]"
1061,56cb6e507c4bac27315aa9560ded4b112fdc052b,School readiness. Integrating cognition and emotion in a neurobiological conceptualization of children's functioning at school entry.,"The author examines the construct of emotionality, developmental relations between cognition and emotion, and neural plasticity and frontal cortical functioning and proposes a developmental neurobiological model of children's school readiness. Direct links are proposed among emotionality, use-dependent synaptic stabilization related to the prefrontal cortex, the development of executive function abilities, and academic and social competence in school settings. The author considers research on the efficacy of preschool compensatory education in promoting school readiness and recommends that programs expand to include curricula directly addressing social and emotional competence. Research should focus on the ontogeny of self-regulation and successful adaptation to the socially defined role of student, the development of prevention research programs to reflect this orientation, and interdisciplinary collaborations that integrate scientific methods and questions in the pursuit of comprehensive knowledge of human developmental processes.",2002.0,177.0,1749.0,False,,"{'volume': '57 2', 'pages': '\n          111-27\n        ', 'name': 'The American psychologist'}","{'bibtex': ""@Article{Blair2002SchoolRI,\n author = {Clancy Blair},\n journal = {The American psychologist},\n pages = {\n          111-27\n        },\n title = {School readiness. Integrating cognition and emotion in a neurobiological conceptualization of children's functioning at school entry.},\n volume = {57 2},\n year = {2002}\n}\n""}","[{'authorId': '2250430912', 'name': 'Clancy Blair'}]"
1062,56cb8cd0cb348ab4da14e19918396a236235e08e,The Effects of an Embodied Conversational Agent's Nonverbal Behavior on User's Evaluation and Behavioral Mimicry,,2007.0,57.0,57.0,False,,{'pages': '238-251'},"{'bibtex': ""@Inproceedings{Krämer2007TheEO,\n author = {N. Krämer and N. Simons and S. Kopp},\n pages = {238-251},\n title = {The Effects of an Embodied Conversational Agent's Nonverbal Behavior on User's Evaluation and Behavioral Mimicry},\n year = {2007}\n}\n""}","[{'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '34434164', 'name': 'N. Simons'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
1063,56ccf17dced2d3bb73f66a18afa20caf5a429c21,Machines and Mindlessness: Social Responses to Computers,"Following Langer (1992), this article reviews a series of experimental studiesthat demonstrate that individuals mindlessly apply social rules and expecta-tions to computers. The first set of studies illustrates how individuals overusehuman social categories, applying gender stereotypes to computers and ethnicallyidentifying with computer agents. The second set demonstrates that people exhibitoverlearned social behaviors such as politeness and reciprocity toward comput-ers.Inthethirdsetofstudies,prematurecognitivecommitmentsaredemonstrated:Aspecialisttelevisionsetisperceivedasprovidingbettercontentthanageneralisttelevision set. A final series of studies demonstrates the depth of social responseswith respect to computer “personality.” Alternative explanations for these find -ings, such as anthropomorphism and intentional social responses, cannot explainthe results. We conclude with an agenda for future research.Computer users approach the personal computer in many different ways.Experienced word processors move smoothly from keyboard to mouse to menu,mixing prose and commands to the computer automatically; the distinctionbetween the hand and the tool blurs (Heidegger, 1977; Winograd & Flores, 1987).Novices cautiously strike each key, fearing that one false move will initiate anuncontrollable series of unwanted events. Game players view computers as",2000.0,64.0,2359.0,False,,"{'volume': '56', 'pages': '81-103', 'name': 'Journal of Social Issues'}","{'bibtex': '@Article{Nass2000MachinesAM,\n author = {C. Nass and Youngme Moon},\n journal = {Journal of Social Issues},\n pages = {81-103},\n title = {Machines and Mindlessness: Social Responses to Computers},\n volume = {56},\n year = {2000}\n}\n'}","[{'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '33875827', 'name': 'Youngme Moon'}]"
1065,56db2ac44324d0649bbe643ee070d7ba5724f243,How social is social responses to computers? The function of the degree of anthropomorphism in computer representations,,2008.0,29.0,239.0,False,,"{'volume': '24', 'pages': '1494-1509', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Gong2008HowSI,\n author = {Li Gong},\n journal = {Comput. Hum. Behav.},\n pages = {1494-1509},\n title = {How social is social responses to computers? The function of the degree of anthropomorphism in computer representations},\n volume = {24},\n year = {2008}\n}\n'}","[{'authorId': '2056813503', 'name': 'Li Gong'}]"
1066,56e3df3a807605151e18991e4298e4a8b00aee67,As Seen by the Other … : Perspectives on the Self in the Memories and Emotional Perceptions of Easterners and Westerners,"The experiment reported investigated the phenomenological consequences of Easterners' and Westerners' perspectives on the self. Two findings are consistent with the notion that Asians are more likely than Westerners to experience the self from the perspective of the generalized other First, Eastern participants were more likely than Western participants to have third-person (as opposed to first-person) memories when they thought about situations in which they would be at the center of a scene. Second, Easterners and Westerners engaged in different sorts of projections when they read the emotional expressions of other people. Westerners were more biased than Easterners toward egocentric projection of their own emotions onto others, whereas Easterners were more biased than Westerners toward relational projection, in which they projected onto others the emotions that the generalized other would feel in relation to the participant. Implications for how phenomenological experiences could reinforce different Eastern and Western ideologies about the self and the group are discussed.",2002.0,24.0,218.0,False,,"{'volume': '13', 'pages': '55 - 59', 'name': 'Psychological Science'}","{'bibtex': '@Article{Cohen2002AsSB,\n author = {D. Cohen and A. Gunz},\n journal = {Psychological Science},\n pages = {55 - 59},\n title = {As Seen by the Other … : Perspectives on the Self in the Memories and Emotional Perceptions of Easterners and Westerners},\n volume = {13},\n year = {2002}\n}\n'}","[{'authorId': '40634589', 'name': 'D. Cohen'}, {'authorId': '13321799', 'name': 'A. Gunz'}]"
1067,570d4a53b703af132f3b69e0f685c6feff0ebbc4,A method of emotion contagion for crowd evacuation,,2017.0,24.0,59.0,False,,"{'volume': '483', 'pages': '250-258', 'name': 'Physica A-statistical Mechanics and Its Applications'}","{'bibtex': '@Article{Cao2017AMO,\n author = {M. Cao and Guijuan Zhang and Mengsi Wang and Dianjie Lu and Hong Liu},\n journal = {Physica A-statistical Mechanics and Its Applications},\n pages = {250-258},\n title = {A method of emotion contagion for crowd evacuation},\n volume = {483},\n year = {2017}\n}\n'}","[{'authorId': '4840308', 'name': 'M. Cao'}, {'authorId': '3172102', 'name': 'Guijuan Zhang'}, {'authorId': '2145361200', 'name': 'Mengsi Wang'}, {'authorId': '7382513', 'name': 'Dianjie Lu'}, {'authorId': '2118902760', 'name': 'Hong Liu'}]"
1068,570e196c99881312322f7e11264580a51ab6c133,A Blueprint for Affective Computing: A Sourcebook and Manual,"'Affective computing' is a branch of computing concerned with the theory and construction of machines which can detect, respond to, and simulate human emotional states. It is an interdisciplinary field spanning the computer sciences, psychology, and cognitive science. Affective computing is a rapidly developing field within industry and science. There is now a great drive to make technologies such as robotic systems, avatars in service-related human computer interaction, e-learning, game characters, or companion devices more marketable by endowing the 'soulless' robots or agents with the ability to recognize and adjust to the user's feelings as well as to be able to communicate appropriate emotional signals.A Blueprint for Affective Computing: A sourcebook and manual is the very first attempt to ground affective computing within the disciplines of psychology, affective neuroscience, and philosophy. This book illustrates the contributions of each of these disciplines to the development of the ever-growing field of affective computing. In addition, it demonstrates practical examples of cross-fertilization between disciplines in order to highlight the need for integration of computer science, engineering and the affective sciences. Focusing on a topic at the frontiers of human computer interaction research, this book will be of great interest to students and researchers in psychology, neuroscience, computational neuroscience, computer science, and artificial intelligence.",2010.0,0.0,194.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Scherer2010ABF,\n author = {K. Scherer and T. Bänziger and E. Roesch},\n title = {A Blueprint for Affective Computing: A Sourcebook and Manual},\n year = {2010}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '2162242', 'name': 'T. Bänziger'}, {'authorId': '2489004', 'name': 'E. Roesch'}]"
1069,571dbe47ec20c98dc39d92ec22c3e6b3d3d3eed5,The Comforting Touch: Tactile Intimacy and Talk in Managing Children’s Distress,"ABSTRACT The present study examines young children’s distress management in situ, focusing on situations of crying and caregivers’ embodied—haptic—soothing responses in preschools in Sweden. The adults’ responses to crying involve embraces, stroking, and patting. Haptic soothing is managed by calibrating the bodily proximity and postural orientations between the participants, including haptic—embracing or face-to-face—formations that are coordinated with particular forms of talk. Haptic formations configure specific affordances for embodied participation by actualizing the availability of tactile, aural, and visual modalities. The interactional organization of soothing in an embracing formation involves: an initiation/invitation and response, submergence of two bodies into a close haptic contact, and coordinated withdrawal from haptic contact. The embracing formation temporarily suspends the requirements for the distressed person to act like a responsive listener and speaker. The caregiver uses the face-to-face formation to reestablish conditions for the child’s interactional co-presence. Data are in Swedish and English translation.",2017.0,44.0,73.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/08351813.2017.1301293?needAccess=true', 'status': None}","{'volume': '50', 'pages': '109 - 127', 'name': 'Research on Language and Social Interaction'}","{'bibtex': '@Article{Cekaite2017TheCT,\n author = {Asta Cekaite and Malva Kvist Holm},\n journal = {Research on Language and Social Interaction},\n pages = {109 - 127},\n title = {The Comforting Touch: Tactile Intimacy and Talk in Managing Children’s Distress},\n volume = {50},\n year = {2017}\n}\n'}","[{'authorId': '3115357', 'name': 'Asta Cekaite'}, {'authorId': '1751740277', 'name': 'Malva Kvist Holm'}]"
1070,57415c8c567d2ba3d92eaef6b5b974277d010094,The Process Model of Group-Based Emotion,"Scholars interested in emotion regulation have documented the different goals and strategies individuals have for regulating their emotions. However, little attention has been paid to the regulation of group-based emotions, which are based on individuals’ self-categorization as a group member and occur in response to situations perceived as relevant for that group. We propose a model for examining group-based emotion regulation that integrates intergroup emotions theory and the process model of emotion regulation. This synergy expands intergroup emotion theory by facilitating further investigation of different goals (i.e., hedonic or instrumental) and strategies (e.g., situation selection and modification strategies) used to regulate group-based emotions. It also expands emotion regulation research by emphasizing the role of self-categorization (e.g., as an individual or a group member) in the emotional process. Finally, we discuss the promise of this theoretical synergy and suggest several directions for future research on group-based emotion regulation.",2016.0,220.0,140.0,True,"{'url': 'https://pure.rug.nl/ws/files/240727357/1088868315581263.pdf', 'status': None}","{'volume': '20', 'pages': '118 - 141', 'name': 'Personality and Social Psychology Review'}","{'bibtex': '@Article{Goldenberg2016ThePM,\n author = {Amit Goldenberg and E. Halperin and Martijn van Zomeren and J. Gross},\n journal = {Personality and Social Psychology Review},\n pages = {118 - 141},\n title = {The Process Model of Group-Based Emotion},\n volume = {20},\n year = {2016}\n}\n'}","[{'authorId': '40484649', 'name': 'Amit Goldenberg'}, {'authorId': '1722823', 'name': 'E. Halperin'}, {'authorId': '82305608', 'name': 'Martijn van Zomeren'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
1071,5749b3590147259baeff87f91d250bf07938c60e,Towards a Better Understanding of Context and Context-Awareness,,1999.0,28.0,5189.0,True,"{'url': 'http://www.cc.gatech.edu/fce/contexttoolkit/chiws/Dey.pdf', 'status': None}",{'pages': '304-307'},"{'bibtex': '@Inproceedings{Abowd1999TowardsAB,\n author = {G. Abowd and A. Dey and P. Brown and N. Davies and Mark T. Smith and Pete Steggles},\n pages = {304-307},\n title = {Towards a Better Understanding of Context and Context-Awareness},\n year = {1999}\n}\n'}","[{'authorId': '9267108', 'name': 'G. Abowd'}, {'authorId': '144021446', 'name': 'A. Dey'}, {'authorId': '144580566', 'name': 'P. Brown'}, {'authorId': '144396244', 'name': 'N. Davies'}, {'authorId': '2118906157', 'name': 'Mark T. Smith'}, {'authorId': '1771459', 'name': 'Pete Steggles'}]"
1072,57624d99699f71f213b3a8d2f1905a56ac60f1c7,Eye movements as indices for the utility of life-like interface agents: A pilot study,,2007.0,48.0,29.0,False,,"{'volume': '19', 'pages': '281-292', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Prendinger2007EyeMA,\n author = {H. Prendinger and Chunling Ma and M. Ishizuka},\n journal = {Interact. Comput.},\n pages = {281-292},\n title = {Eye movements as indices for the utility of life-like interface agents: A pilot study},\n volume = {19},\n year = {2007}\n}\n'}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '2112486362', 'name': 'Chunling Ma'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
1074,577b5f1f3787837d1d4641e0f373a6c1e7414e60,Dreaming Your Fear Away: A Computational Model for Fear Extinction Learning during Dreaming,,2011.0,33.0,11.0,True,"{'url': 'http://www.few.vu.nl/%7Ewai/Papers/ICONIP11dreams.pdf', 'status': None}",{'pages': '197-209'},"{'bibtex': '@Inproceedings{Treur2011DreamingYF,\n author = {Jan Treur},\n pages = {197-209},\n title = {Dreaming Your Fear Away: A Computational Model for Fear Extinction Learning during Dreaming},\n year = {2011}\n}\n'}","[{'authorId': '1726343', 'name': 'Jan Treur'}]"
1075,57d5d5689beab6ffe835ce9418905867a0fa498a,Negotiating the Multiple Realities of Technology in Literacy Research and Instruction,The authors consider the relation between research and practice as it applies to digital technologies. They do so within the multiple realities of different theoretical and methodological perspectives.,1999.0,38.0,194.0,False,,"{'volume': '34', 'pages': '478-492', 'name': 'Reading Research Quarterly'}","{'bibtex': '@Article{Labbo1999NegotiatingTM,\n author = {L. Labbo and D. Reinking},\n journal = {Reading Research Quarterly},\n pages = {478-492},\n title = {Negotiating the Multiple Realities of Technology in Literacy Research and Instruction},\n volume = {34},\n year = {1999}\n}\n'}","[{'authorId': '52641148', 'name': 'L. Labbo'}, {'authorId': '66295841', 'name': 'D. Reinking'}]"
1076,57ea5a83a1b91d8eaf4fe9e08ca5efbf6a3e90e4,An affective model of interplay between emotions and learning: reengineering educational pedagogy-building a learning companion,"There is an interplay, between emotions and learning, but this interaction is far more complex than previous theories have articulated. The article proffers a novel model by which to: 1). regard the interplay of emotions upon learning for, 2). the larger practical aim of crafting computer-based models that will recognize a learner's affective state and respond appropriately to it, so that learning will proceed at an optimal pace.",2001.0,19.0,794.0,False,,"{'pages': '43-46', 'name': 'Proceedings IEEE International Conference on Advanced Learning Technologies'}","{'bibtex': '@Article{Kort2001AnAM,\n author = {B. Kort and R. Reilly and Rosalind W. Picard},\n journal = {Proceedings IEEE International Conference on Advanced Learning Technologies},\n pages = {43-46},\n title = {An affective model of interplay between emotions and learning: reengineering educational pedagogy-building a learning companion},\n year = {2001}\n}\n'}","[{'authorId': '1808703', 'name': 'B. Kort'}, {'authorId': '48825373', 'name': 'R. Reilly'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
1077,581018e542acb848bafa7983a226e68255e69ad2,The Nature of Rapport and Its Nonverbal Correlates,The purpose of this article is to offer a conceptualization of rapport that has utility for identifying the nonverbal correlates associated with rapport. We describe the nature of rapport in terms ...,1990.0,41.0,855.0,False,,"{'volume': '1', 'pages': '285-293', 'name': 'Psychological Inquiry'}","{'bibtex': '@Article{Tickle-Degnen1990TheNO,\n author = {L. Tickle-Degnen and R. Rosenthal},\n journal = {Psychological Inquiry},\n pages = {285-293},\n title = {The Nature of Rapport and Its Nonverbal Correlates},\n volume = {1},\n year = {1990}\n}\n'}","[{'authorId': '1399872060', 'name': 'L. Tickle-Degnen'}, {'authorId': '1998366', 'name': 'R. Rosenthal'}]"
1081,581204981569a4baa3690797c549ee51fa52f4dc,School-based prevention programs for depression and anxiety in adolescence: a systematic review.,"School-based interventions are considered a promising effort to prevent the occurrence of mental disorders in adolescents. This systematic review focuses on school-based prevention interventions on depression and anxiety disorders utilizing an RCT design, starting from the year 2000. Based on an online search (PubMed, Scirus, OVID, ISI) and bibliographic findings in the eligible articles, 28 studies providing information were reviewed. The search process ended on 2 May 2011. The majority of interventions turn out to be effective, both for depression (65%) and anxiety (73%). However, the obtained overall mean effect sizes calculated from the most utilized questionnaires can be considered rather small (CDI: -0.12; RCMAS: -0.29). The majority of the reviewed school-based interventions shows effectiveness in reducing or preventing mental disorders in adolescents. However, effect size computation revealed only small-scale effectiveness. Future studies have to consider the impact of program implementation variations.",2014.0,50.0,146.0,True,"{'url': 'https://academic.oup.com/heapro/article-pdf/29/3/427/2280099/dat001.pdf', 'status': None}","{'volume': '29 3', 'pages': '\n          427-41\n        ', 'name': 'Health promotion international'}","{'bibtex': '@Article{Corrieri2014SchoolbasedPP,\n author = {S. Corrieri and D. Heider and I. Conrad and A. Blume and H. König and S. Riedel-Heller},\n journal = {Health promotion international},\n pages = {\n          427-41\n        },\n title = {School-based prevention programs for depression and anxiety in adolescence: a systematic review.},\n volume = {29 3},\n year = {2014}\n}\n'}","[{'authorId': '6870166', 'name': 'S. Corrieri'}, {'authorId': '31538125', 'name': 'D. Heider'}, {'authorId': '2064785350', 'name': 'I. Conrad'}, {'authorId': '49379596', 'name': 'A. Blume'}, {'authorId': '144069012', 'name': 'H. König'}, {'authorId': '1381759898', 'name': 'S. Riedel-Heller'}]"
1082,581d3ebdb2eae794f1203d7fb927476f43925132,Empathy Modulates the Rewarding Effect of Mimicry,,2016.0,49.0,15.0,True,"{'url': 'https://www.nature.com/articles/srep27751.pdf', 'status': None}","{'volume': '6', 'name': 'Scientific Reports'}","{'bibtex': '@Article{Neufeld2016EmpathyMT,\n author = {J. Neufeld and B. Chakrabarti},\n journal = {Scientific Reports},\n title = {Empathy Modulates the Rewarding Effect of Mimicry},\n volume = {6},\n year = {2016}\n}\n'}","[{'authorId': '50377075', 'name': 'J. Neufeld'}, {'authorId': '3102450', 'name': 'B. Chakrabarti'}]"
1083,5845b1f067bd37205271b6f03fc1570c244f4eeb,Nonverbal Teacher-student Communication in the Foreign Language Classroom,"Nonverbal communication refers to a form of communication without using the words to repress oneself. Nonverbal communication is so basic that the teachers tend to take it for granted and always ignore it in the English classroom teaching. For attaining the goal of teaching, and improving teaching quality and efficiency in the foreign language classroom, the improvement of teaching method is a very important factor. Briefly introducing the definition and types of nonverbal communication, this paper discusses the functions and principles of using nonverbal communication in English teaching classroom and it explains some ways of using the nonverbal behaviors to improve the foreign language teaching. Therefore, the significance of nonverbal communication should be fully acknowledged by both teacher and students.",2014.0,12.0,18.0,True,,"{'volume': '4', 'pages': '2627-2632', 'name': 'Theory and Practice in Language Studies'}","{'bibtex': '@Article{Pan2014NonverbalTC,\n author = {Qi Pan},\n journal = {Theory and Practice in Language Studies},\n pages = {2627-2632},\n title = {Nonverbal Teacher-student Communication in the Foreign Language Classroom},\n volume = {4},\n year = {2014}\n}\n'}","[{'authorId': '46758080', 'name': 'Qi Pan'}]"
1084,585639b260d8278208bb577ffc6bf2ef0ffa0312,The PHQ-9,"AbstractOBJECTIVE: While considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. Therefore, we examined the validity of a brief, new measure of depression severity.
 MEASUREMENTS: The Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-9 is the depression module, which scores each of the 9 DSM-IV criteria as “0” (not at all) to “3” (nearly every day). The PHQ-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. Construct validity was assessed using the 20-item Short-Form General Health Survey, self-reported sick days and clinic visits, and symptom-related difficulty. Criterion validity was assessed against an independent structured mental health professional (MHP) interview in a sample of 580 patients.
 RESULTS: As PHQ-9 depression severity increased, there was a substantial decrease in functional status on all 6 SF-20 subscales. Also, symptom-related difficulty, sick days, and health care utilization increased. Using the MHP reinterview as the criterion standard, a PHQ-9 score ≥10 had a sensitivity of 88% and a specificity of 88% for major depression. PHQ-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. Results were similar in the primary care and obstetrics-gynecology samples.
 CONCLUSION: In addition to making criteria-based diagnoses of depressive disorders, the PHQ-9 is also a reliable and valid measure of depression severity. These characteristics plus its brevity make the PHQ-9 a useful clinical and research tool.",2001.0,27.0,19377.0,True,,"{'volume': '16', 'pages': '606-613', 'name': 'Journal of General Internal Medicine'}","{'bibtex': '@Article{Kroenke2001TheP,\n author = {K. Kroenke and R. Spitzer and Janet B W Williams},\n journal = {Journal of General Internal Medicine},\n pages = {606-613},\n title = {The PHQ-9},\n volume = {16},\n year = {2001}\n}\n'}","[{'authorId': '3737608', 'name': 'K. Kroenke'}, {'authorId': '2069763', 'name': 'R. Spitzer'}, {'authorId': '2111787096', 'name': 'Janet B W Williams'}]"
1085,586078656d5bee43e0cb7c57e3ececfb067cc451,ExpressGesture: Expressive gesture generation from speech through database matching,"Co‐speech gestures are a vital ingredient in making virtual agents more human‐like and engaging. Automatically generated gestures based on speech‐input often lack realistic and defined gesture form. We present a database‐driven approach guaranteeing defined gesture form. We built a large corpus of over 23,000 motion‐captured co‐speech gestures and select individual gestures based on expressive gesture characteristics that can be estimated from speech audio. The expressive parameters are gesture velocity and acceleration, gesture size, arm swivel, and finger extension. Individual, parameter‐matched gestures are then combined into animated sequences. We evaluate our gesture generation system in two perceptual studies. The first study compares our method to the ground truth gestures as well as mismatched gestures. The second study compares our method to five current generative machine learning models. Our method outperformed mismatched gesture selection in the first study and showed competitive performance in the second.",2021.0,34.0,30.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cav.2016', 'status': None}","{'volume': '32', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Ferstl2021ExpressGestureEG,\n author = {Ylva Ferstl and Michael Neff and R. Mcdonnell},\n journal = {Computer Animation and Virtual Worlds},\n title = {ExpressGesture: Expressive gesture generation from speech through database matching},\n volume = {32},\n year = {2021}\n}\n'}","[{'authorId': '3430725', 'name': 'Ylva Ferstl'}, {'authorId': '143687087', 'name': 'Michael Neff'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
1086,5871ba1359b95641dcadb6df23f52661acc4176f,EASEL: Easy Automatic Segmentation Event Labeler,"Video annotation is a vital part of research examining gestural and multimodal interaction as well as computer vision, machine learning, and interface design. However, annotation is a difficult, time-consuming task that requires high cognitive effort. Existing tools for labeling and annotation still require users to manually label most of the data, limiting the tools helpfulness. In this paper, we present the Easy Automatic Segmentation Event Labeler (EASEL), a tool supporting gesture analysis. EASEL streamlines the annotation process by introducing assisted annotation, using automatic gesture segmentation and recognition to automatically annotate gestures. To evaluate the efficacy of assisted annotation, we conducted a user study with 24 participants and found that assisted annotation decreased the time needed to annotate videos with no difference in accuracy compared with manual annotation. The results of our study demonstrate the benefit of adding computational intelligence to video and audio annotation tasks.",2018.0,18.0,8.0,False,,{'name': '23rd International Conference on Intelligent User Interfaces'},"{'bibtex': '@Article{Wang2018EASELEA,\n author = {Isaac Wang and P. Narayana and Jesse Smith and B. Draper and J. Beveridge and J. Ruiz},\n journal = {23rd International Conference on Intelligent User Interfaces},\n title = {EASEL: Easy Automatic Segmentation Event Labeler},\n year = {2018}\n}\n'}","[{'authorId': '10693895', 'name': 'Isaac Wang'}, {'authorId': '145382418', 'name': 'P. Narayana'}, {'authorId': '2109847325', 'name': 'Jesse Smith'}, {'authorId': '1694404', 'name': 'B. Draper'}, {'authorId': '143905691', 'name': 'J. Beveridge'}, {'authorId': '151062472', 'name': 'J. Ruiz'}]"
1087,58751dabf6812284610e1123b3c10db852497a43,Computational Study of Primitive Emotional Contagion in Dyadic Interactions,"Interpersonal human-human interaction is a dynamical exchange and coordination of social signals, feelings and emotions usually performed through and across multiple modalities such as facial expressions, gestures, and language. Developing machines able to engage humans in rich and natural interpersonal interactions requires capturing such dynamics. This paper addresses primitive emotional contagion during dyadic interactions in which roles are prefixed. Primitive emotional contagion was defined as the tendency people have to automatically mimic and synchronize their multimodal behavior during interactions and, consequently, to emotionally converge. To capture emotional contagion, a cross-recurrence based methodology that explicitly integrates short and long-term temporal dynamics through the analysis of both facial expressions and sentiment was developed. This approach is employed to assess emotional contagion at unimodal, multimodal and cross-modal levels and is evaluated on the Solid SAL-SEMAINE corpus. Interestingly, the approach is able to show the importance of the adoption of cross-modal strategies for addressing emotional contagion.",2020.0,77.0,16.0,False,,"{'volume': '11', 'pages': '258-271', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Varni2020ComputationalSO,\n author = {G. Varni and I. Hupont and C. Clavel and M. Chetouani},\n journal = {IEEE Transactions on Affective Computing},\n pages = {258-271},\n title = {Computational Study of Primitive Emotional Contagion in Dyadic Interactions},\n volume = {11},\n year = {2020}\n}\n'}","[{'authorId': '1958033', 'name': 'G. Varni'}, {'authorId': '2321433', 'name': 'I. Hupont'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '1680828', 'name': 'M. Chetouani'}]"
1088,58997d2d1f94c6a28e266b858f0f76e3b16a3374,Towards Multimodal Human-Like Characteristics and Expressive Visual Prosody in Virtual Agents,"One of the key challenges in designing Embodied Conversational Agents (ECA) is to produce human-like gestural and visual prosody expressivity. Another major challenge is to maintain the interlocutor's attention by adapting the agent's behavior to the interlocutor's multimodal behavior. This paper outlines my PhD research plan that aims to develop convincing expressive and natural behavior in ECAs and to explore and model the mechanisms that govern human-agent multimodal interaction. Additionally, I describe in this paper my first PhD milestone which focuses on developing an end-to-end LSTM Neural Network model for upper-face gestures generation. The main task consists of building a model that can produce expressive and coherent upper-face gestures while considering multiple modalities: speech audio, text, and action units.",2020.0,42.0,11.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-03115575/file/ICMI.pdf', 'status': None}",{'name': 'Proceedings of the 2020 International Conference on Multimodal Interaction'},"{'bibtex': '@Article{Fares2020TowardsMH,\n author = {Mireille Fares},\n journal = {Proceedings of the 2020 International Conference on Multimodal Interaction},\n title = {Towards Multimodal Human-Like Characteristics and Expressive Visual Prosody in Virtual Agents},\n year = {2020}\n}\n'}","[{'authorId': '48265085', 'name': 'Mireille Fares'}]"
1089,5899f3076301a1d40f23ff24391bd12cbeb82d79,Simulation Models for Virtual Reality Applications,"The paper describes some simulation models used to implement virtual reality applications, addressing the presentation of the architecture of VR systems, VR applications in different fields, including medicine, an introduction to simulation techniques and a set of mathematical models for creating virtual scenes. The material represents a significant development of the presentation given at the workshop VRRM 2007: Virtual Reality in Rehabilitation Medicine, with details on mathematical aspects.",2008.0,26.0,4.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Albeanu2008SimulationMF,\n author = {G. Albeanu},\n title = {Simulation Models for Virtual Reality Applications},\n year = {2008}\n}\n'}","[{'authorId': '9337392', 'name': 'G. Albeanu'}]"
1090,58b32f05f840dd941bcaa04945c236326bdbabe4,The Effects of Agent Nonverbal Communication on Procedural and Attitudinal Learning Outcomes,,2008.0,25.0,30.0,False,,{'pages': '208-214'},"{'bibtex': '@Inproceedings{Baylor2008TheEO,\n author = {A. L. Baylor and Soyoung Kim},\n pages = {208-214},\n title = {The Effects of Agent Nonverbal Communication on Procedural and Attitudinal Learning Outcomes},\n year = {2008}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '2144259493', 'name': 'Soyoung Kim'}]"
1091,58f72b53d576c6e4a42b4d8812e5542ffa2c03cc,DBpedia - A crystallization point for the Web of Data,,2009.0,28.0,2399.0,False,,"{'volume': '7', 'pages': '154-165', 'name': 'J. Web Semant.'}","{'bibtex': '@Article{Bizer2009DBpediaA,\n author = {Christian Bizer and Jens Lehmann and Georgi Kobilarov and S. Auer and Christian Becker and Richard Cyganiak and Sebastian Hellmann},\n journal = {J. Web Semant.},\n pages = {154-165},\n title = {DBpedia - A crystallization point for the Web of Data},\n volume = {7},\n year = {2009}\n}\n'}","[{'authorId': '1729154', 'name': 'Christian Bizer'}, {'authorId': '144568027', 'name': 'Jens Lehmann'}, {'authorId': '2051816', 'name': 'Georgi Kobilarov'}, {'authorId': '145044578', 'name': 'S. Auer'}, {'authorId': '2068696031', 'name': 'Christian Becker'}, {'authorId': '1702661', 'name': 'Richard Cyganiak'}, {'authorId': '2024066', 'name': 'Sebastian Hellmann'}]"
1092,5940ee7d6bbf85bdb9c65777219ffef8477a09a0,Closing the gender gap in STEM with friendly male instructors? On the effects of rapport behavior and gender of a virtual agent in an instructional interaction,,2016.0,96.0,72.0,False,,"{'volume': '99', 'pages': '1-13', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Krämer2016ClosingTG,\n author = {N. Krämer and Bilge Karacora and Gale M. Lucas and Morteza Dehghani and Gina Rüther and J. Gratch},\n journal = {Comput. Educ.},\n pages = {1-13},\n title = {Closing the gender gap in STEM with friendly male instructors? On the effects of rapport behavior and gender of a virtual agent in an instructional interaction},\n volume = {99},\n year = {2016}\n}\n'}","[{'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '3364569', 'name': 'Bilge Karacora'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '145707560', 'name': 'Morteza Dehghani'}, {'authorId': '50714008', 'name': 'Gina Rüther'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
1093,5948fffabf53f4eec8333322c791d21c6d6280b4,Can computers feel? Theory and design of an emotional system,"Abstract Emotions can be regarded as the manifestations of a system that realises multiple concerns and operates in an uncertain environment. Taking the concern realisation function as a starting point, it is argued that the major phenomena of emotion follow from considerations of what properties a subsystem implementing that function should have. The major phenomena are: the existence of the feelings of pleasure and pain, the importance of cognitive or appraisal variables, the presence of innate, pre-programmed behaviours as well as of complex constructed plans for achieving emotion goals, and the occurrence of behavioural interruption, disturbance and impulse-like priority of emotional goals. The system properties underlying these phenomena are facilities for relevance detection of events with regard to the multiple concerns, availability of relevance signals that can be recognised by the action system, and facilities for control precedence, or flexible goal priority ordering and shift. A computer progr...",1987.0,6.0,162.0,False,,"{'volume': '1', 'pages': '235-257', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Frijda1987CanCF,\n author = {N. Frijda and Jaap Swagerman},\n journal = {Cognition & Emotion},\n pages = {235-257},\n title = {Can computers feel? Theory and design of an emotional system},\n volume = {1},\n year = {1987}\n}\n'}","[{'authorId': '49584958', 'name': 'N. Frijda'}, {'authorId': '116727475', 'name': 'Jaap Swagerman'}]"
1094,5973adbdd599054cec8889c13f4fe6b6c6d5b27d,From Habits to Standards: Towards Systematic Design of Emotion Models and Affective Architectures,,2014.0,35.0,20.0,False,,{'pages': '3-23'},"{'bibtex': '@Inproceedings{Hudlicka2014FromHT,\n author = {E. Hudlicka},\n pages = {3-23},\n title = {From Habits to Standards: Towards Systematic Design of Emotion Models and Affective Architectures},\n year = {2014}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
1095,5998232f2dd056b19c30d20c61bf63c381f9c859,Emotion expression in body action and posture.,"Emotion communication research strongly focuses on the face and voice as expressive modalities, leaving the rest of the body relatively understudied. Contrary to the early assumption that body movement only indicates emotional intensity, recent studies have shown that body movement and posture also conveys emotion specific information. However, a deeper understanding of the underlying mechanisms is hampered by a lack of production studies informed by a theoretical framework. In this research we adopted the Body Action and Posture (BAP) coding system to examine the types and patterns of body movement that are employed by 10 professional actors to portray a set of 12 emotions. We investigated to what extent these expression patterns support explicit or implicit predictions from basic emotion theory, bidimensional theory, and componential appraisal theory. The overall results showed partial support for the different theoretical approaches. They revealed that several patterns of body movement systematically occur in portrayals of specific emotions, allowing emotion differentiation. Although a few emotions were prototypically expressed by one particular pattern, most emotions were variably expressed by multiple patterns, many of which can be explained as reflecting functional components of emotion such as modes of appraisal and action readiness. It is concluded that further work in this largely underdeveloped area should be guided by an appropriate theoretical framework to allow a more systematic design of experiments and clear hypothesis testing.",2012.0,89.0,374.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:97844/ATTACHMENT01', 'status': None}","{'volume': '12 5', 'pages': '\n          1085-101\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Dael2012EmotionEI,\n author = {N. Dael and M. Mortillaro and K. Scherer},\n journal = {Emotion},\n pages = {\n          1085-101\n        },\n title = {Emotion expression in body action and posture.},\n volume = {12 5},\n year = {2012}\n}\n'}","[{'authorId': '47658592', 'name': 'N. Dael'}, {'authorId': '37837552', 'name': 'M. Mortillaro'}, {'authorId': '2462740', 'name': 'K. Scherer'}]"
1096,59a2918e95e633c0bf269b25a810629a9d8c8bf7,Road collisions avoidance using vehicular cyber-physical systems: a taxonomy and review,,2016.0,176.0,25.0,True,,"{'volume': '4', 'pages': '1-34', 'name': 'Complex Adaptive Systems Modeling'}","{'bibtex': '@Article{Riaz2016RoadCA,\n author = {F. Riaz and M. Niazi},\n journal = {Complex Adaptive Systems Modeling},\n pages = {1-34},\n title = {Road collisions avoidance using vehicular cyber-physical systems: a taxonomy and review},\n volume = {4},\n year = {2016}\n}\n'}","[{'authorId': '40611071', 'name': 'F. Riaz'}, {'authorId': '1795560', 'name': 'M. Niazi'}]"
1097,59a4916eee47bb2c84d4ebe303cc6ef7a6314ac0,A Virtual Therapist That Responds Empathically to Your Answers,,2008.0,13.0,30.0,False,,{'pages': '417-425'},"{'bibtex': '@Inproceedings{Pontier2008AVT,\n author = {M. Pontier and G. F. Siddiqui},\n pages = {417-425},\n title = {A Virtual Therapist That Responds Empathically to Your Answers},\n year = {2008}\n}\n'}","[{'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}]"
1098,59b0d670f75d3761a03e7298f8215ede2777cdc4,EVA: Generating Emotional Behavior of Virtual Agents using Expressive Features of Gait and Gaze,"We present a novel, real-time algorithm, EVA, for generating virtual agents with various perceived emotions. Our approach is based on using Expressive Features of gaze and gait to convey emotions corresponding to happy, sad, angry, or neutral. We precompute a data-driven mapping between gaits and their perceived emotions. EVA uses this gait emotion association at runtime to generate appropriate walking styles in terms of gaits and gaze. Using the EVA algorithm, we can simulate gaits and gazing behaviors of hundreds of virtual agents in real-time with known emotional characteristics. We have evaluated the benefits in different multi-agent VR simulation environments. Our studies suggest that the use of expressive features corresponding to gait and gaze can considerably increase the sense of presence in scenarios with multiple virtual agents.",2019.0,68.0,29.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3343036.3343129', 'status': None}",{'name': 'ACM Symposium on Applied Perception 2019'},"{'bibtex': '@Article{Randhavane2019EVAGE,\n author = {Tanmay Randhavane and Aniket Bera and Kyra Kapsaskis and R. Sheth and Kurt Gray and Dinesh Manocha},\n journal = {ACM Symposium on Applied Perception 2019},\n title = {EVA: Generating Emotional Behavior of Virtual Agents using Expressive Features of Gait and Gaze},\n year = {2019}\n}\n'}","[{'authorId': '3352747', 'name': 'Tanmay Randhavane'}, {'authorId': '2718563', 'name': 'Aniket Bera'}, {'authorId': '80905955', 'name': 'Kyra Kapsaskis'}, {'authorId': '2065900892', 'name': 'R. Sheth'}, {'authorId': '144470585', 'name': 'Kurt Gray'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
1099,59c031abdc731e1fa6d7df300089b8c61a0ca1db,The hidden dimension: an anthropologist examines man's use of space in public and private,,1969.0,0.0,405.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Hall1969TheHD,\n author = {E. Hall},\n title = {The hidden dimension: an anthropologist examines man's use of space in public and private},\n year = {1969}\n}\n""}","[{'authorId': '1422357475', 'name': 'E. Hall'}]"
1100,59c83d0e1473691e47493d966a205c0d2321b0cf,Sex differences in empathy and related behaviors.,"According to the prevailing cultural stereotype as well as various psychological theories, empathy (the vicarious affective response to another person's feelings) is more prevalent in females than in males. A review of the research indicates that females do indeed appear to be more empathic than mal",1977.0,63.0,752.0,False,,"{'volume': '84 4', 'pages': '\n          712-22\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Hoffman1977SexDI,\n author = {M. Hoffman},\n journal = {Psychological bulletin},\n pages = {\n          712-22\n        },\n title = {Sex differences in empathy and related behaviors.},\n volume = {84 4},\n year = {1977}\n}\n'}","[{'authorId': '82128751', 'name': 'M. Hoffman'}]"
1101,59e1748506640a3ef8f69c0fe2f22bbe8db8c7ca,A Comprehensive Guideline for Bengali Sentiment Annotation,"Sentiment Analysis (SA) is a Natural Language Processing (NLP) and an Information Extraction (IE) task that primarily aims to obtain the writer’s feelings expressed in positive or negative by analyzing a large number of documents. SA is also widely studied in the fields of data mining, web mining, text mining, and information retrieval. The fundamental task in sentiment analysis is to classify the polarity of a given content as Positive, Negative, or Neutral. Although extensive research has been conducted in this area of computational linguistics, most of the research work has been carried out in the context of English language. However, Bengali sentiment expression has varying degree of sentiment labels, which can be plausibly distinct from English language. Therefore, sentiment assessment of Bengali language is undeniably important to be developed and executed properly. In sentiment analysis, the prediction potential of an automatic modeling is completely dependent on the quality of dataset annotation. Bengali sentiment annotation is a challenging task due to diversified structures (syntax) of the language and its different degrees of innate sentiments (i.e., weakly and strongly positive/negative sentiments). Thus, in this article, we propose a novel and precise guideline for the researchers, linguistic experts, and referees to annotate Bengali sentences immaculately with a view to building effective datasets for automatic sentiment prediction efficiently.",2021.0,73.0,8.0,False,,"{'volume': '21', 'pages': '1 - 19', 'name': 'Transactions on Asian and Low-Resource Language Information Processing'}","{'bibtex': '@Article{Mukta2021ACG,\n author = {Md. Saddam Hossain Mukta and Md. Adnanul Islam and Faisal Ahamed Khan and Afjal Hossain and Shuvanon Razik and Shazzad Hossain and J. Mahmud},\n journal = {Transactions on Asian and Low-Resource Language Information Processing},\n pages = {1 - 19},\n title = {A Comprehensive Guideline for Bengali Sentiment Annotation},\n volume = {21},\n year = {2021}\n}\n'}","[{'authorId': '1806836', 'name': 'Md. Saddam Hossain Mukta'}, {'authorId': '7484275', 'name': 'Md. Adnanul Islam'}, {'authorId': '2086745422', 'name': 'Faisal Ahamed Khan'}, {'authorId': '152223089', 'name': 'Afjal Hossain'}, {'authorId': '49985445', 'name': 'Shuvanon Razik'}, {'authorId': '47867440', 'name': 'Shazzad Hossain'}, {'authorId': '145359935', 'name': 'J. Mahmud'}]"
1102,5a0126fe377e0da0af24dffa312a44c227a599bc,Virtual Agents in Conflict,,2012.0,13.0,12.0,False,,{'pages': '105-111'},"{'bibtex': '@Inproceedings{Campos2012VirtualAI,\n author = {Henrique Campos and Joana Campos and C. Martinho and Ana Paiva},\n pages = {105-111},\n title = {Virtual Agents in Conflict},\n year = {2012}\n}\n'}","[{'authorId': '144005447', 'name': 'Henrique Campos'}, {'authorId': '2066804320', 'name': 'Joana Campos'}, {'authorId': '145813496', 'name': 'C. Martinho'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1103,5a2892f91addeea2f4600d28b23e684be32f5b2c,DEAP: A Database for Emotion Analysis ;Using Physiological Signals,"We present a multimodal data set for the analysis of human affective states. The electroencephalogram (EEG) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the EEG signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of EEG, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.",2012.0,60.0,2921.0,True,"{'url': 'https://ris.utwente.nl/ws/files/6474169/DEAP.pdf', 'status': None}","{'volume': '3', 'pages': '18-31', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Koelstra2012DEAPAD,\n author = {Sander Koelstra and C. Mühl and M. Soleymani and Jong-Seok Lee and A. Yazdani and T. Ebrahimi and T. Pun and A. Nijholt and I. Patras},\n journal = {IEEE Transactions on Affective Computing},\n pages = {18-31},\n title = {DEAP: A Database for Emotion Analysis ;Using Physiological Signals},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '2079441', 'name': 'Sander Koelstra'}, {'authorId': '1753164', 'name': 'C. Mühl'}, {'authorId': '152714397', 'name': 'M. Soleymani'}, {'authorId': '48173549', 'name': 'Jong-Seok Lee'}, {'authorId': '40131608', 'name': 'A. Yazdani'}, {'authorId': '1681498', 'name': 'T. Ebrahimi'}, {'authorId': '1809085', 'name': 'T. Pun'}, {'authorId': '144483472', 'name': 'A. Nijholt'}, {'authorId': '50058816', 'name': 'I. Patras'}]"
1104,5a6e961426816d44953d7db02c75b51cbe7491df,Designing a non-verbal language for expressive avatars,"Collaborative Virtual Environments (CVEs) were designed as an expansion of the text-based chat room, rather than a novel application, exploiting the possibilities of online three dimensional graphical space. This initial design direction is observable at the interface level. We put forward the case that to achieve an efficient CVE system, one will have to design and implement a multi modal User Interface based on expressive Avatars as a representation of the different participants, also as an embodiment of software agents. We emphasise the expressiveness of the avatar as a crucial improvement to the efficiency of their communication capabilities, and we describe a vocabulary of expressions to be implemented. We put forward the case that to be more efficient, particularly during a dialogue, an avatar is required to play a role in the communication using non-verbal channels such as body postures, facial expressions and hand gestures. We also suggest conversation circles to facilitate the gathering of participants in a discussion. These circles will address navigation difficulties in CVEs and encourage social exchanges.",2000.0,15.0,72.0,False,,{'pages': '93-101'},"{'bibtex': '@Inproceedings{Salem2000DesigningAN,\n author = {Benjamin Salem and N. Earle},\n pages = {93-101},\n title = {Designing a non-verbal language for expressive avatars},\n year = {2000}\n}\n'}","[{'authorId': '145909342', 'name': 'Benjamin Salem'}, {'authorId': '3461880', 'name': 'N. Earle'}]"
1105,5a7bbddf0d76cf3f0f575f2e2306456efba9dea4,Thinking of the future and past: the roles of the frontal pole and the medial temporal lobes,,2003.0,46.0,595.0,False,,"{'volume': '19', 'pages': '1369-1380', 'name': 'NeuroImage'}","{'bibtex': '@Article{Okuda2003ThinkingOT,\n author = {J. Okuda and T. Fujii and H. Ohtake and T. Tsukiura and K. Tanji and Kyoko Suzuki and R. Kawashima and H. Fukuda and M. Itoh and A. Yamadori},\n journal = {NeuroImage},\n pages = {1369-1380},\n title = {Thinking of the future and past: the roles of the frontal pole and the medial temporal lobes},\n volume = {19},\n year = {2003}\n}\n'}","[{'authorId': '47427643', 'name': 'J. Okuda'}, {'authorId': '15381401', 'name': 'T. Fujii'}, {'authorId': '32867660', 'name': 'H. Ohtake'}, {'authorId': '3111494', 'name': 'T. Tsukiura'}, {'authorId': '2754748', 'name': 'K. Tanji'}, {'authorId': '2109096190', 'name': 'Kyoko Suzuki'}, {'authorId': '144820330', 'name': 'R. Kawashima'}, {'authorId': '144596379', 'name': 'H. Fukuda'}, {'authorId': '46751096', 'name': 'M. Itoh'}, {'authorId': '3549564', 'name': 'A. Yamadori'}]"
1106,5a7e59f69e9d1cdb10c46a366fe9d97855a1350c,Real-time 3D morphable shape model fitting to monocular in-the-wild videos,"Reconstructing 3D face shape from a single 2D photograph as well as from video is an inherently ill-posed problem with many ambiguities. One way to solve some of the ambiguities is using a 3D face model to aid the task. 3D Morphable Face Models (3DMMs) are amongst the state of the art methods for 3D face reconstruction, or so called 3D model fitting. However, current existing methods have severe limitations, and most of them have not been trialled on in-the-wild data. Current analysis-by-synthesis methods form complex non-linear optimisation processes, and optimisers often get stuck in local optima. Further, most existing methods are slow, requiring in the order of minutes to process one photograph. 
This thesis presents an algorithm to reconstruct 3D face shape from a single image as well as from sets of images or video frames in real-time. We introduce a solution for linear fitting of a PCA shape identity model and expression blendshapes to 2D facial landmarks. To improve the accuracy of the shape, a fast face contour fitting algorithm is introduced. These different components of the algorithm are run in iteration, resulting in a fast, linear shape-to-landmarks fitting algorithm. The algorithm, specifically designed to fit to landmarks obtained from in-the-wild images, by tackling imaging conditions that occur in in-the-wild images like facial expressions and the mismatch of 2D–3D contour correspondences, achieves the shape reconstruction accuracy of much more complex, nonlinear state of the art methods, while being multiple orders of magnitudes faster. 
 Second, we address the problem of fitting to sets of multiple images of the same person, as well as monocular video sequences. We extend the proposed shape-tolandmarks fitting to multiple frames by using the knowledge that all images are from the same identity. To recover facial texture, the approach uses texture from the original images, instead of employing the often-used PCA albedo model of a 3DMM. We employ an algorithm that merges texture from multiple frames in real-time based on a weighting of each triangle of the reconstructed shape mesh. 
 Last, we make the proposed real-time 3D morphable face model fitting algorithm available as open-source software. In contrast to ubiquitous available 2D-based face models and code, there is a general lack of software for 3D morphable face model fitting, hindering a widespread adoption. The library thus constitutes a significant contribution to the community.",2017.0,0.0,5.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Huber2017Realtime3M,\n author = {P. Huber},\n title = {Real-time 3D morphable shape model fitting to monocular in-the-wild videos},\n year = {2017}\n}\n'}","[{'authorId': '39976184', 'name': 'P. Huber'}]"
1107,5a842a3c66e77706d842b3a06ac3b13685171498,"Attachment in Adulthood: Structure, Dynamics, and Change","The attachment behavioral system: basic concepts and principles -- A model of attachment-system functioning and dynamics in adulthood -- Normative attachment processes -- Measurement of attachment-related constructs in adulthood -- Individual differences in attachment-system functioning: development, stability, and change -- Attachment-related mental representations of self and others -- Attachment processes and emotion regulation -- Attachment orientations, behavioral self-regulation, and personal growth -- An attachment perspective on interpersonal regulation -- Attachment processes and couple functioning -- Relations between the attachment and caregiving systems -- Attachment and sex -- Attachment bases of psychopathology -- Implications of attachment theory and research for counseling and psychotherapy -- Applications of attachment theory and research in group and organizational settings -- Reflections on attachment security.",2007.0,0.0,3560.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mikulincer2007AttachmentIA,\n author = {M. Mikulincer and P. Shaver},\n title = {Attachment in Adulthood: Structure, Dynamics, and Change},\n year = {2007}\n}\n'}","[{'authorId': '4021295', 'name': 'M. Mikulincer'}, {'authorId': '4509891', 'name': 'P. Shaver'}]"
1108,5a9cac54de14e58697d0315fe3c01f3dbe69c186,Grounding in communication,"GROUNDING It takes two people working together to play a duet, shake hands, play chess, waltz, teach, or make love. To succeed, the two of them have to coordinate both the content and process of what they are doing. Alan and Barbara, on the piano, must come to play the same Mozart duet. This is coordination of content. They must also synchronize their entrances and exits, coordinate how loudly to play forte and pianissimo, and otherwise adjust to each other's tempo and dynamics. This is coordination of process. They cannot even begin to coordinate on content without assuming a vast amount of shared information or common ground-that is, mutual knowledge, mutual beliefs, and mutual assumptions And to coordinate on process, they need to update their common ground moment by moment. All collective actions are built on common ground and its accumulation. We thank many colleagues for discussion of the issues we take up here.",1991.0,42.0,4402.0,True,"{'url': 'http://www.math.caltech.edu/SimonPapers/41.pdf', 'status': None}",{'pages': '127-149'},"{'bibtex': '@Inproceedings{Clark1991GroundingIC,\n author = {H. H. Clark and S. Brennan},\n pages = {127-149},\n title = {Grounding in communication},\n year = {1991}\n}\n'}","[{'authorId': '29224904', 'name': 'H. H. Clark'}, {'authorId': '71463834', 'name': 'S. Brennan'}]"
1109,5aae5913137cfb296db85c082c349af251e1152f,Modeling Human-Like Decision Making for Virtual Agents in Time-Critical Situations,"Generating human-like behaviors for virtual agents has become increasingly important in many applications, such as crowd simulation, virtual training, digital entertainment, and safety planning. One of challenging issues in behavior modeling is how virtual agents make decisions given some time-critical and uncertain situations. In this paper, we present HumDPM, a decision process model for virtual agents, which incorporates two important factors of human decision making in time-critical situations: experience and emotion. In HumDPM, rather than relying on deliberate rational analysis, an agent makes its decisions by matching past experience cases to the current situation. We propose the detailed representation of experience case and investigate the mechanisms of situation assessment, experience matching and experience execution. To incorporate emotion into HumDPM, we introduce an emotion appraisal process in situation assessment for emotion elicitation. In HumDPM, the decision making process of an agent may be affected by its emotional states when: 1) deciding whether it is necessary to do a re-match of experience cases, 2) determining the situational context, and 3) selecting experience cases. We illustrate the effectiveness of HumDPM in crowd simulation. A case study for emergency evacuation in a subway station scenario is conducted, which shows how a varied crowd composition leads to different evacuation behaviors, due to the retrieval of different experiences and the variation of agents' emotional states.",2010.0,14.0,17.0,False,,"{'pages': '360-367', 'name': '2010 International Conference on Cyberworlds'}","{'bibtex': '@Article{Luo2010ModelingHD,\n author = {Linbo Luo and Suiping Zhou and Wentong Cai and M. Lees and M. Low},\n journal = {2010 International Conference on Cyberworlds},\n pages = {360-367},\n title = {Modeling Human-Like Decision Making for Virtual Agents in Time-Critical Situations},\n year = {2010}\n}\n'}","[{'authorId': '49571827', 'name': 'Linbo Luo'}, {'authorId': '145038982', 'name': 'Suiping Zhou'}, {'authorId': '1688786', 'name': 'Wentong Cai'}, {'authorId': '143737543', 'name': 'M. Lees'}, {'authorId': '1696470', 'name': 'M. Low'}]"
1110,5aebb3964e3cdc9a4e9d630f28941a2eeec22c22,Physiology-based Recognition of Facial Micro-expressions using EEG and Identification of the Relevant Sensors by Emotion,"In this paper, we present a novel work about predicting the facial expressions from physiological signals of the brain. The main contributions of this paper are twofold. a) Investigation of the predictability of facial micro-expressions from EEG. b) Identification of the relevant features to the prediction. To reach our objectives, an experiment was conducted and we have proceeded in three steps: i) We recorded facial expressions and the corresponding EEG signals of participant while he/she is looking at pictures stimuli from the IAPS (International Affective Picture System). ii) We fed machine learning algorithms with timedomain and frequency-domain features of one second EEG signals with also the corresponding facial expression data as ground truth in the training phase. iii) Using the trained classifiers, we predict facial emotional reactions without the need to a camera. Our method leads us to very promising results since we have reached high accuracy. It also provides an additional important result by locating which electrodes can be used to characterize specific emotion. This system will be particularly useful to evaluate emotional reactions in virtual reality environments where the user is wearing VR headset that hides the face and makes the traditional webcam facial expression detectors obsolete.",2016.0,23.0,15.0,False,,{'pages': '130-137'},"{'bibtex': '@Inproceedings{Benlamine2016PhysiologybasedRO,\n author = {Mohamed S. Benlamine and Maher Chaouachi and C. Frasson and A. Dufresne},\n pages = {130-137},\n title = {Physiology-based Recognition of Facial Micro-expressions using EEG and Identification of the Relevant Sensors by Emotion},\n year = {2016}\n}\n'}","[{'authorId': '3455946', 'name': 'Mohamed S. Benlamine'}, {'authorId': '50149519', 'name': 'Maher Chaouachi'}, {'authorId': '1788058', 'name': 'C. Frasson'}, {'authorId': '34862420', 'name': 'A. Dufresne'}]"
1111,5af5095704d56f3611471a397692926dbc0a2642,A meta-analytic review of emotion recognition and aging: Implications for neuropsychological models of aging,,2008.0,210.0,772.0,False,,"{'volume': '32', 'pages': '863-881', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Ruffman2008AMR,\n author = {T. Ruffman and J. Henry and Vicki Livingstone and L. Phillips},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {863-881},\n title = {A meta-analytic review of emotion recognition and aging: Implications for neuropsychological models of aging},\n volume = {32},\n year = {2008}\n}\n'}","[{'authorId': '3890791', 'name': 'T. Ruffman'}, {'authorId': '2149900272', 'name': 'J. Henry'}, {'authorId': '2089621685', 'name': 'Vicki Livingstone'}, {'authorId': '1994871', 'name': 'L. Phillips'}]"
1114,5b07c4016a6547e1211a172fe5ea95db5d463b16,A Treatise of Human Nature: Being an Attempt to introduce the experimental Method of Reasoning into Moral Subjects,"ion, Etc. Part II Of the Ideas of Space and Time, Part III Of Knowledge and Probability Part IV Of the Sceptical and Other Systems of",1972.0,0.0,10444.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hume1972ATO,\n author = {David Hume},\n title = {A Treatise of Human Nature: Being an Attempt to introduce the experimental Method of Reasoning into Moral Subjects},\n year = {1972}\n}\n'}","[{'authorId': '152806633', 'name': 'David Hume'}]"
1116,5b25edaf99383629ddda15e5fb5975ab3489205b,Screen Time Tantrums: How Families Manage Screen Media Experiences for Toddlers and Preschoolers,"Prior work shows that setting limits on young children's screen time is conducive to healthy development but can be a challenge for families. We investigate children's (age 1 - 5) transitions to and from screen-based activities to understand the boundaries families have set and their experiences living within them. We report on interviews with 27 parents and a diary study with a separate 28 families examining these transitions. These families turn on screens primarily to facilitate parents' independent activities. Parents feel this is appropriate but self-audit and express hesitation, as they feel they are benefiting from an activity that can be detrimental to their child's well-being. We found that families turn off screens when parents are ready to give their child their full attention and technology presents a natural stopping point. Transitioning away from screens is often painful, and predictive factors determine the pain of a transition. Technology-mediated transitions are significantly more successful than parent-mediated transitions, suggesting that the design community has the power to make this experience better for parents and children by creating technologies that facilitate boundary-setting and respect families' self-defined limits.",2016.0,57.0,101.0,False,,{'name': 'Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Hiniker2016ScreenTT,\n author = {Alexis Hiniker and Hye-Ji Suh and Sabina Cao and J. Kientz},\n journal = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},\n title = {Screen Time Tantrums: How Families Manage Screen Media Experiences for Toddlers and Preschoolers},\n year = {2016}\n}\n'}","[{'authorId': '2749233', 'name': 'Alexis Hiniker'}, {'authorId': '83550719', 'name': 'Hye-Ji Suh'}, {'authorId': '3396372', 'name': 'Sabina Cao'}, {'authorId': '1738606', 'name': 'J. Kientz'}]"
1117,5b4e26bcb588ad71a4d34cb4c026797c53eb57c8,Quand et Comment Toucher un Humain ? Un Modèle de Décision pour un Agent Touchant,"Le toucher est un sens dont on connait de mieux en mieux l’importance dans le developpement social et le bien-etre general de l’etre humain, de son enfance a son âge le plus avance. C’est un sens dont on sait qu’il participe activement a la facilitation de l’etablissement des relations sociales et il constitue un canal extremement puissant en terme de communication emotionnelle. Les agents conversationnels animes (ACA) se voient quant a eux munis de plus en plus de capacites sociales et emotionnelles. Ils peuvent creer de l’entente (rapport) avec des humains en exprimant leurs pensees et leurs emotions a travers des modalites aussi bien verbales que non-verbales. Le toucher semble donc constituer une modalite tout a fait pertinente pour les ACA, qui en sont encore tres peu munis. Munir des ACA de capacites de toucher social pose un certain nombre de defis qui commencent seulement a etre etudies. La forme d’un ACA peut etre extremement differente d’une implementation a une autre, et la facon dont on peut les munir d’un sens du toucher en est grandement influencee. Comment elaborer une boucle interactive complete dans laquelle un agent conversationnel anime peut a la fois etre touche par un humain, interpreter ce toucher, choisir comment toucher l’humain en retour, et realiser ce toucher sur l’humain ? En particulier, comment modeliser l’interaction sociale basee sur le toucher ? Quels touchers sont acceptables dans quels situations ? Comment toucher un humain de maniere credible et coherente ? Les travaux presentes ici proposent un modele de decision adapte a un agent conversationnel anime touchant, capable d’utiliser le toucher social et affectif pour interagir avec un etre humain dans une boucle interactive complete, dans un contexte d’environnement immersif.",2020.0,44.0,1.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Boucaud2020QuandEC,\n author = {Fabien Boucaud and Indira Thouvenin and C. Pelachaud},\n title = {Quand et Comment Toucher un Humain ? Un Modèle de Décision pour un Agent Touchant},\n year = {2020}\n}\n'}","[{'authorId': '2083420831', 'name': 'Fabien Boucaud'}, {'authorId': '2065183900', 'name': 'Indira Thouvenin'}, {'authorId': '2065027297', 'name': 'C. Pelachaud'}]"
1118,5b79ff699b21d2c9122e876bb93ff7dd0f5d7993,EMA: A computational model of appraisal dynamics,"A computational model of emotion must explain both the rapid dynamics of some emotional reactions as well as the slower responses that follow deliberation. This is often addressed by positing multiple appraisal processes such as fast pattern directed vs. slower deliberative appraisals. In our view, this confuses appraisal with inference. Rather, we argue for a single and automatic appraisal process that operates over a person’s interpretation of their relationship to the environment. Dynamics arise from perceptual and inferential processes operating on this interpretation (including deliberative and reactive processes). We illustrate this perspective through the computational modeling of a naturalistic emotional situation.",2006.0,13.0,68.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Marsella2006EMAAC,\n author = {S. Marsella and J. Gratch},\n title = {EMA: A computational model of appraisal dynamics},\n year = {2006}\n}\n'}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
1119,5b97856b564eb552777deca1bb794d4f91e18f46,Making faces: Creating three-dimensional parameterized models of facial expression,,2001.0,17.0,71.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03195356.pdf', 'status': None}","{'volume': '33', 'pages': '115-123', 'name': 'Behavior Research Methods, Instruments, & Computers'}","{'bibtex': '@Article{Spencer-Smith2001MakingFC,\n author = {Jesse Spencer-Smith and Heather A. Wild and Åse Innes-Ker and J. Townsend and Christy Duffy and Chad R. Edwards and Kristina Ervin and Nicole Merritt and Jae Won Pair},\n journal = {Behavior Research Methods, Instruments, & Computers},\n pages = {115-123},\n title = {Making faces: Creating three-dimensional parameterized models of facial expression},\n volume = {33},\n year = {2001}\n}\n'}","[{'authorId': '1405594772', 'name': 'Jesse Spencer-Smith'}, {'authorId': '39512862', 'name': 'Heather A. Wild'}, {'authorId': '1402996412', 'name': 'Åse Innes-Ker'}, {'authorId': '1923072', 'name': 'J. Townsend'}, {'authorId': '1409054566', 'name': 'Christy Duffy'}, {'authorId': '39544460', 'name': 'Chad R. Edwards'}, {'authorId': '1409092922', 'name': 'Kristina Ervin'}, {'authorId': '23601231', 'name': 'Nicole Merritt'}, {'authorId': '2240740205', 'name': 'Jae Won Pair'}]"
1121,5bb63acee23a630fa242f193d5b9abfb6ffcd9ec,Hospital Buddy: A Persistent Emotional Support Companion Agent for Hospital Patients,,2012.0,1.0,22.0,False,,{'pages': '492-495'},"{'bibtex': '@Inproceedings{Bickmore2012HospitalBA,\n author = {T. Bickmore and Laila Bukhari and L. Vardoulakis and M. Paasche-Orlow and Christopher Shanahan},\n pages = {492-495},\n title = {Hospital Buddy: A Persistent Emotional Support Companion Agent for Hospital Patients},\n year = {2012}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '1405505392', 'name': 'Laila Bukhari'}, {'authorId': '1787101', 'name': 'L. Vardoulakis'}, {'authorId': '1397166245', 'name': 'M. Paasche-Orlow'}, {'authorId': '2072882045', 'name': 'Christopher Shanahan'}]"
1122,5bcbcf866fccb34e052507c951d6012525523d09,An Alternative to Null-Hypothesis Significance Tests,"The statistic P rep estimates the probability of replicating an effect. It captures traditional publication criteria for signal-to-noise ratio, while avoiding parametric inference and the resulting Bayesian dilemma. In concert with effect size and replication intervals, P rep provides all of the information now used in evaluating research, while avoiding many of the pitfalls of traditional statistical inference.",2005.0,47.0,460.0,True,"{'url': 'https://europepmc.org/articles/pmc1473027?pdf=render', 'status': None}","{'volume': '16', 'pages': '345 - 353', 'name': 'Psychological Science'}","{'bibtex': '@Article{Killeen2005AnAT,\n author = {Peter R. Killeen},\n journal = {Psychological Science},\n pages = {345 - 353},\n title = {An Alternative to Null-Hypothesis Significance Tests},\n volume = {16},\n year = {2005}\n}\n'}","[{'authorId': '2241098672', 'name': 'Peter R. Killeen'}]"
1123,5c3e820b70ddb0d2232e7c40e37e580149e15409,A Brief Version of the Fear of Negative Evaluation Scale,"Although the Fear of Negative Evaluation (FNE) Scale has widespread applicability to many areas of research in personality and social psychology, its utility is sometimes limited by its length. This article presents a brief, 12-item version of the FNE that correlates very highly (f96) with the original scale and that demonstrates psychometric properties that are nearly identical to those of the full-length scale.",1983.0,5.0,1930.0,False,,"{'volume': '9', 'pages': '371 - 375', 'name': 'Personality and Social Psychology Bulletin'}","{'bibtex': '@Article{Leary1983ABV,\n author = {M. Leary},\n journal = {Personality and Social Psychology Bulletin},\n pages = {371 - 375},\n title = {A Brief Version of the Fear of Negative Evaluation Scale},\n volume = {9},\n year = {1983}\n}\n'}","[{'authorId': '35163278', 'name': 'M. Leary'}]"
1124,5c4824f17261cd1be5ee212a390897a65754c466,Evaluating the persona effect of an interface agent in a tutoring system,"This paper describes the evaluation of the persona effect of a speech-driven anthropomorphic agent that has been embodied in the interface of an intelligent tutoring system (ITS). This agent is responsible for guiding the student in the environment and communicating the system's feedback messages. The agent was evaluated in terms of the effect that it could have on students' learning, behaviour and experience. The participants in the experiment were divided into two groups: half of them worked with a version of the ITS which embodied the agent and the rest worked with an agent-less version. The results from this study confirm the hypothesis that a pedagogical agent incorporated in an ITS can enhance students' learning experience. On the other hand, the hypothesis that the presence of the agent improves short-term learning effects was rejected.",2002.0,8.0,145.0,False,,"{'volume': '18', 'pages': '253-261', 'name': 'J. Comput. Assist. Learn.'}","{'bibtex': '@Article{Moundridou2002EvaluatingTP,\n author = {Maria Moundridou and M. Virvou},\n journal = {J. Comput. Assist. Learn.},\n pages = {253-261},\n title = {Evaluating the persona effect of an interface agent in a tutoring system},\n volume = {18},\n year = {2002}\n}\n'}","[{'authorId': '1781216', 'name': 'Maria Moundridou'}, {'authorId': '1694669', 'name': 'M. Virvou'}]"
1125,5c4a849694ba1ea569573ab7beb7c73460ae91ad,"Artificial fishes: physics, locomotion, perception, behavior","This paper proposes a framework for animation that can achieve the intricacy of motion evident in certain natural ecosystems with minimal input from the animator. The realistic appearance, movement, and behavior of individual animals, as well as the patterns of behavior evident in groups of animals fall within the scope of the framework. Our approach to emulating this level of natural complexity is to model each animal holistically as an autonomous agent situated in its physical world. To demonstrate the approach, we develop a physics-based, virtual marine world. The world is inhabited by artificial fishes that can swim hydrodynamically in simulated water through the motor control of internal muscles that motivates fins. Their repertoire of behaviors relies on their perception of the dynamic environment. As in nature, the detailed motions of artificial fishes in their virtual habitat are not entirely predictable because they are not scripted.",1994.0,28.0,835.0,False,,{'name': 'Proceedings of the 21st annual conference on Computer graphics and interactive techniques'},"{'bibtex': '@Article{Tu1994ArtificialFP,\n author = {Xiaoyuan Tu and Demetri Terzopoulos},\n journal = {Proceedings of the 21st annual conference on Computer graphics and interactive techniques},\n title = {Artificial fishes: physics, locomotion, perception, behavior},\n year = {1994}\n}\n'}","[{'authorId': '40509745', 'name': 'Xiaoyuan Tu'}, {'authorId': '1750924', 'name': 'Demetri Terzopoulos'}]"
1126,5c58c4691063b7776344ba95fb433bf16d1082e8,The relationship between social media use and sleep quality among undergraduate students,"ABSTRACT Insufficient sleep is a growing health problem among university students, especially for freshmen during their first quarter/semester of college. Little research has studied how social media technologies impact sleep quality among college students. This study aims to determine the relationship between social media use and sleep quality among freshman undergraduates during their first quarter in college. Specifically, we explored whether variations in Twitter use across the time of day and day of the week would be associated with self-reported sleep quality. We conducted a study of freshman Twitter-using students (N = 197) over their first quarter of college, between October and December of 2015. We collected students’ tweets, labeled the content of the tweets according to different emotional states, and gave theme weekly surveys on sleep quality. Tweeting more frequently on weekday late nights was associated with lower sleep quality (β = −0.937, SE = 0.352); tweeting more frequently on weekday evenings was associated with better quality sleep (β = 0.189, SE = 0.097). Tweets during the weekday that were labeled related to the emotion of fear were associated with lower sleep quality (β = −0.302, SE = 0.131). Results suggest that social media use is associated with sleep quality among students. Results provided can be used to inform future interventions to improve sleep quality among college students.",2018.0,27.0,67.0,True,"{'url': 'https://europepmc.org/articles/pmc5881928?pdf=render', 'status': None}","{'volume': '21', 'pages': '163 - 173', 'name': 'Information, Communication & Society'}","{'bibtex': '@Article{Garett2018TheRB,\n author = {Renee Garett and Sam Liu and S. Young},\n journal = {Information, Communication & Society},\n pages = {163 - 173},\n title = {The relationship between social media use and sleep quality among undergraduate students},\n volume = {21},\n year = {2018}\n}\n'}","[{'authorId': '16067817', 'name': 'Renee Garett'}, {'authorId': '1988814420', 'name': 'Sam Liu'}, {'authorId': '2476529', 'name': 'S. Young'}]"
1127,5c71a5bd507cf727ce838e76b6a0f877652187cf,Face the noise: embodied responses to nonverbal vocalizations of discrete emotions.,"Extensive prior research has shown that the perception of an emotional facial expression automatically elicits a corresponding facial expression in the observer. Theories of embodied emotion, however, suggest that such reactions might also occur across expressive channels, because simulation is based on integrated motoric and affective representations of that emotion. In the present studies, we examined this idea by focusing on facial and experiential reactions to nonverbal emotion vocalizations. In Studies 1 and 2, we showed that both hearing and reproducing vocalizations of anger, disgust, happiness, and sadness resulted in specific facial behaviors, as well as congruent self-reported emotions (Study 2). In Studies 3 and 4, we showed that the inhibition of congruent facial actions impaired listeners' processing of emotion vocalizations (Study 3), as well as their experiences of a concordant subjective state (Study 4). Results support the idea that cross-channel simulations of others' states serve facilitative functions similar to more strict imitations of observed expressive behavior, suggesting flexibility in the motoric and affective systems involved in emotion processing and interpersonal emotion transfer. We discuss implications for embodiment research and the social consequences of expressing and matching emotions across nonverbal channels.",2012.0,101.0,123.0,False,,"{'volume': '102 4', 'pages': '\n          796-814\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Hawk2012FaceTN,\n author = {Skyler T. Hawk and A. Fischer and Gerben A. van Kleef},\n journal = {Journal of personality and social psychology},\n pages = {\n          796-814\n        },\n title = {Face the noise: embodied responses to nonverbal vocalizations of discrete emotions.},\n volume = {102 4},\n year = {2012}\n}\n'}","[{'authorId': '2390460', 'name': 'Skyler T. Hawk'}, {'authorId': '7444483', 'name': 'A. Fischer'}, {'authorId': '5980688', 'name': 'Gerben A. van Kleef'}]"
1128,5c8258a374b68af2f762f00d50cf7e9929f93431,Visual Scanning of Faces in Autism,,2002.0,73.0,1177.0,False,,"{'volume': '32', 'pages': '249-261', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Pelphrey2002VisualSO,\n author = {K. Pelphrey and N. Sasson and J. Reznick and Gregory Paul and B. Goldman and J. Piven},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {249-261},\n title = {Visual Scanning of Faces in Autism},\n volume = {32},\n year = {2002}\n}\n'}","[{'authorId': '9765768', 'name': 'K. Pelphrey'}, {'authorId': '4378420', 'name': 'N. Sasson'}, {'authorId': '2196228955', 'name': 'J. Reznick'}, {'authorId': '2057125948', 'name': 'Gregory Paul'}, {'authorId': '144387696', 'name': 'B. Goldman'}, {'authorId': '2718912', 'name': 'J. Piven'}]"
1129,5c8c37ef0e1d750343ab4499129c2709c06dc77b,Mother-infant synchrony.,Synchrony is an essential component of the interaction between a mother and her infant and is characterized by adaptive and reciprocal behaviors that promote a mutually rewarding interaction. It is an antecedent for the emergence of self-regulatory function in infants and influences current and future interactions. Understanding the dynamics of the mother-infant dyad and identifying synchronous patterns are important for promoting a healthy relationship. Approaches to measurement and challenges to model development are described.,2009.0,44.0,75.0,False,,"{'volume': '38 4', 'pages': '\n          470-7\n        ', 'name': 'Journal of obstetric, gynecologic, and neonatal nursing : JOGNN'}","{'bibtex': '@Article{Reyna2009MotherinfantS,\n author = {B. Reyna and R. Pickler},\n journal = {Journal of obstetric, gynecologic, and neonatal nursing : JOGNN},\n pages = {\n          470-7\n        },\n title = {Mother-infant synchrony.},\n volume = {38 4},\n year = {2009}\n}\n'}","[{'authorId': '5737370', 'name': 'B. Reyna'}, {'authorId': '5296721', 'name': 'R. Pickler'}]"
1130,5c96ad3a16efb7399632f2c37cd4a768a067d332,"The Development of Empathy : How , When , and Why",,2010.0,84.0,132.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{McDonald2010TheDO,\n author = {N. McDonald and D. Messinger},\n title = {The Development of Empathy : How , When , and Why},\n year = {2010}\n}\n'}","[{'authorId': '49100327', 'name': 'N. McDonald'}, {'authorId': '1874236', 'name': 'D. Messinger'}]"
1131,5ca1a4c07ff76c42c0e02df6dba13a58fa1bd95e,Emotion and motion: age-related differences in recognizing virtual agent facial expressions,,2011.0,35.0,0.0,False,,"{'name': '', 'volume': ''}","{'bibtex': '@Inproceedings{Smarr2011EmotionAM,\n author = {Cory-Ann Smarr},\n title = {Emotion and motion: age-related differences in recognizing virtual agent facial expressions},\n year = {2011}\n}\n'}","[{'authorId': '1963261', 'name': 'Cory-Ann Smarr'}]"
1132,5cceb70a11e9a09ecc03a8488d0bb7e3b8dc09a4,Eye-tracking Analysis for Product Recommendation Virtual Agent with Markov Chain Model,"PRVAs, product recommendation virtual agents, are agents that are designed for virtual clerks in online shopping. Prendinger et al. investigated the effect of virtual clerks by eye tracking analysis (Prendinger, Ma, & Ishizuka, 2007). In their experiment, participants were introduced real estate properties by text, speech, and an animated agent. They showed that the agent’s use of deictic gestures had the effect of attracting a participant’s gaze. Terada et al. studied what appearance was the most suitable for PRVAs (Terada, Jing, & Yamada, 2015). They showed that one of the most effective appearances were dog, robot, and young woman. In this paper, we investigated the effect of PRVA’s emotion transition to user’s gaze by eye tracking analysis. A Markov chain model is widely used for constructing a model of eye tracking transition. Liechty et al. showed local and global covert visual attention by adapting a Bayesian hidden Markov model (Liechty, Pieters, & Wedel, 2003). He et al. suggested investigating hidden user behaviors that occur when a user is using a search site by using a partially observable Markov model with duration (POMD) (He & Wang, 2011). This model is derived from the hidden Markov model (HMM). The difference was that POMD contained a partially observable event. He et al. suggested that only seeing without clicking links was the hidden user behavior. In this paper, our goal was to improve the PRVA design methodology by analyzing user eye-tracking data. We focused on transition-based analysis. In prior research on human-agent interaction, eye-tracking data were mainly analyzed on the basis of fixation durations. This is the most important method in this paper.",2016.0,6.0,0.0,False,,,"{'bibtex': '@Inproceedings{Ritter2016EyetrackingAF,\n author = {F. Ritter},\n title = {Eye-tracking Analysis for Product Recommendation Virtual Agent with Markov Chain Model},\n year = {2016}\n}\n'}","[{'authorId': '1701118', 'name': 'F. Ritter'}]"
1133,5cd5c8bbfdf02c48105f2d515627d447e31a2bdb,Emotion Recognition from Bengali Speech using RNN Modulation-based Categorization,"Emotion recognition is one of the most challenging tasks in the field of speech recognition and processing. Besides, it is deemed a significant branch of Human-Computer Interaction (HCI). Although there exist several techniques related to speech emotion recognition (SER), in this study, machine learning approaches for feature extraction is used. To be precise, the Mel-frequency Cepstrum Coefficient (MFCC) and Modulation Spectral (MS) is implemented to extract the relevant features from Bengali speech. Our study focuses on recognizing several states of emotion such as joy, sadness, anger, surprise, fear, and disgust from Bengali speech by exploring an emotion recognition model. Besides, in this study, a novel Bengali speech dataset is developed and used since no proper study, specifically for Bengali, on this topic is available in the literature yet. In this study, the recurrent neural network (RNN) technology is used to categorize the human voice (speech) into six particular states of emotion. Finally, our study shows that while the RNN classifier model achieves 47.66% accuracy with our Bengali speech dataset, achieved 51.33% accuracy when the dataset is first categorized using the RNN modulation technique.",2020.0,33.0,14.0,False,,"{'pages': '1131-1136', 'name': '2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)'}","{'bibtex': '@Article{Hasan2020EmotionRF,\n author = {H. Hasan and Md. Adnanul Islam},\n journal = {2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)},\n pages = {1131-1136},\n title = {Emotion Recognition from Bengali Speech using RNN Modulation-based Categorization},\n year = {2020}\n}\n'}","[{'authorId': '2065954783', 'name': 'H. Hasan'}, {'authorId': '7484275', 'name': 'Md. Adnanul Islam'}]"
1134,5cf0d213f3253cd46673d955209f8463db73cc51,IEMOCAP: interactive emotional dyadic motion capture database,,2008.0,66.0,2419.0,False,,"{'volume': '42', 'pages': '335-359', 'name': 'Language Resources and Evaluation'}","{'bibtex': '@Article{Busso2008IEMOCAPIE,\n author = {C. Busso and M. Bulut and Chi-Chun Lee and Ebrahim (Abe) Kazemzadeh and E. Provost and Samuel Kim and Jeannette N. Chang and Sungbok Lee and Shrikanth S. Narayanan},\n journal = {Language Resources and Evaluation},\n pages = {335-359},\n title = {IEMOCAP: interactive emotional dyadic motion capture database},\n volume = {42},\n year = {2008}\n}\n'}","[{'authorId': '2106794', 'name': 'C. Busso'}, {'authorId': '38816202', 'name': 'M. Bulut'}, {'authorId': '2467369', 'name': 'Chi-Chun Lee'}, {'authorId': '1764265', 'name': 'Ebrahim (Abe) Kazemzadeh'}, {'authorId': '2523983', 'name': 'E. Provost'}, {'authorId': '2110026741', 'name': 'Samuel Kim'}, {'authorId': '2522842', 'name': 'Jeannette N. Chang'}, {'authorId': '2108057415', 'name': 'Sungbok Lee'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
1138,5d2a8502542f10aa6d132827467096b389a98ba4,Improving LEO Robot Conversational Ability via Deep Learning Algorithms for Children with Autism,"The core symptom of children with autism is social difficulties. According to the research, one of the main psychological factors supposed to underlie in these difficulties is the lack or low levels of joint attention with the interaction partners. The use of robots in autism spectrum disorder (ASD) interventions has received a lot of attention in the last years. Robots can achieve high levels of effectiveness in interacting with children with autism. This paper presents robots that play several important roles and benefits in the interaction of children with autism. In the absence of dialogue corpus, we collected and integrated conversation data for children with autism. We present to use a neural network to build a robot dialogue system that generates answers freely without restrictions, and design robot movements to attract attention from children with autism. Most importantly, the robot will interact smoothly with autistic children without human intervention.",2018.0,0.0,10.0,False,,"{'pages': '416-420', 'name': '2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)'}","{'bibtex': '@Article{She2018ImprovingLR,\n author = {Tianhao She and Xin Kang and S. Nishide and F. Ren},\n journal = {2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)},\n pages = {416-420},\n title = {Improving LEO Robot Conversational Ability via Deep Learning Algorithms for Children with Autism},\n year = {2018}\n}\n'}","[{'authorId': '153326943', 'name': 'Tianhao She'}, {'authorId': '144018134', 'name': 'Xin Kang'}, {'authorId': '1792084', 'name': 'S. Nishide'}, {'authorId': '145366409', 'name': 'F. Ren'}]"
1139,5d33e0307ede66b5b9392ec5c6bd2cd4a8b0aa0f,Emotion Elicitation: A Comparison of Pictures and Films,"Pictures and film clips are widely used and accepted stimuli to elicit emotions. Based on theoretical arguments it is often assumed that the emotional effects of films exceed those of pictures, but to date this assumption has not been investigated directly. The aim of the present study was to compare pictures and films in terms of their capacity to induce emotions verified by means of explicit measures. Stimuli were (a) single pictures presented for 6 s, (b) a set of three consecutive pictures with emotionally congruent contents presented for 2 s each, (c) short film clips with a duration of 6 s. A total of 144 participants rated their emotion and arousal states following stimulus presentation. Repeated-measures ANOVAs revealed that the film clips and 3-picture version were as effective as the classical 1-picture method to elicit positive emotions, however, modulation toward positive valence was little. Modulation toward negative valence was more effective in general. Film clips were less effective than pictorial stimuli in producing the corresponding emotion states (all p < 0.001) and were less arousing (all p ≤ 0.02). Possible reasons for these unexpected results are discussed.",2016.0,47.0,133.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00180/pdf', 'status': None}","{'volume': '7', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Uhrig2016EmotionEA,\n author = {Meike Uhrig and Nadine Trautmann and U. Baumgärtner and R. Treede and Florian Henrich and W. Hiller and Susanne Marschall},\n journal = {Frontiers in Psychology},\n title = {Emotion Elicitation: A Comparison of Pictures and Films},\n volume = {7},\n year = {2016}\n}\n'}","[{'authorId': '40328283', 'name': 'Meike Uhrig'}, {'authorId': '119306072', 'name': 'Nadine Trautmann'}, {'authorId': '3356397', 'name': 'U. Baumgärtner'}, {'authorId': '2831905', 'name': 'R. Treede'}, {'authorId': '152235969', 'name': 'Florian Henrich'}, {'authorId': '145907682', 'name': 'W. Hiller'}, {'authorId': '2096280886', 'name': 'Susanne Marschall'}]"
1140,5d447ebed18b14b45cfbe31ff6673b6fbe4d7f58,Modeling the Semiotic Structure of Game Characters,"When game studies has tackled the player-character, it has tended to do so by means of an oppositon to the notion of the avatar, with the result that the ontological and semiotic nature of the character in itself has not been given due attention. This paper draws on understandings of character from the fields of narratology and literary theory to highlight the double-layered ontology of character as both a possible individual and as a semiotic construction. Uri Margolin’s narratological model of character signification is used as the basis for developing a semiotic-structural model of the player-character that addresses its specific medialities and formal nature – a task which is performed through illustrative close examinations of the player-characters in The Last of Us (Naughty Dog 2013) and Gone Home (The Fullbright Company 2013).",2014.0,40.0,12.0,False,,"{'volume': '8', 'name': ''}","{'bibtex': '@Inproceedings{Vella2014ModelingTS,\n author = {Daniel Vella},\n title = {Modeling the Semiotic Structure of Game Characters},\n volume = {8},\n year = {2014}\n}\n'}","[{'authorId': '20777014', 'name': 'Daniel Vella'}]"
1141,5d459e987b400e9a39bf18fd97543c6bf129c772,Effects of social support from various sources on depression in elderly persons.,"Although global measures of social support demonstrate significant effects on psychological and physical well-being, the differential significance of various support sources is largely unknown. The present study examines differences in the effects of functional expressive support by source on depressive symptoms. This approach is contrasted with network interaction studies of elderly persons, which do not measure functional support but do suggest that friends are distinctly significant. Spouse, friends, and adult children were found to rank in descending order of importance; relatives show no effect. Low support may have stronger effects than unavailability of sources. Effects of supports and stressors are not conditioned by age, sex, or widowhood. Implications of findings and further research needs are discussed.",1990.0,49.0,266.0,False,,"{'volume': '31 2', 'pages': '\n          148-61\n        ', 'name': 'Journal of health and social behavior'}","{'bibtex': '@Article{Dean1990EffectsOS,\n author = {A. Dean and B. Kolody and P. Wood},\n journal = {Journal of health and social behavior},\n pages = {\n          148-61\n        },\n title = {Effects of social support from various sources on depression in elderly persons.},\n volume = {31 2},\n year = {1990}\n}\n'}","[{'authorId': '74778617', 'name': 'A. Dean'}, {'authorId': '5691548', 'name': 'B. Kolody'}, {'authorId': '153329127', 'name': 'P. Wood'}]"
1142,5d48c799d3c481610c9492f2113f3ddaaf1ce755,"Effectiveness of psychoeducation for relapse, symptoms, knowledge, adherence and functioning in psychotic disorders: A meta-analysis",,2007.0,57.0,273.0,False,,"{'volume': '96', 'pages': '232-245', 'name': 'Schizophrenia Research'}","{'bibtex': '@Article{Lincoln2007EffectivenessOP,\n author = {T. Lincoln and K. Wilhelm and Yvonne Nestoriuc},\n journal = {Schizophrenia Research},\n pages = {232-245},\n title = {Effectiveness of psychoeducation for relapse, symptoms, knowledge, adherence and functioning in psychotic disorders: A meta-analysis},\n volume = {96},\n year = {2007}\n}\n'}","[{'authorId': '2209910498', 'name': 'T. Lincoln'}, {'authorId': '144451496', 'name': 'K. Wilhelm'}, {'authorId': '2210650239', 'name': 'Yvonne Nestoriuc'}]"
1143,5d4d53231b8f5ca35928b7b1dee45838e7257ec4,Unconscious Facial Reactions to Emotional Facial Expressions,"Studies reveal that when people are exposed to emotional facial expressions, they spontaneously react with distinct facial electromyographic (EMG) reactions in emotion-relevant facial muscles. These reactions reflect, in part, a tendency to mimic the facial stimuli. We investigated whether corresponding facial reactions can be elicited when people are unconsciously exposed to happy and angry facial expressions. Through use of the backward-masking technique, the subjects were prevented from consciously perceiving 30-ms exposures of happy, neutral, and angry target faces, which immediately were followed and masked by neutral faces. Despite the fact that exposure to happy and angry faces was unconscious, the subjects reacted with distinct facial muscle reactions that corresponded to the happy and angry stimulus faces. Our results show that both positive and negative emotional reactions can be unconsciously evoked, and particularly that important aspects of emotional face-to-face communication can occur on an unconscious level.",2000.0,32.0,1614.0,True,"{'url': 'http://www.communicationcache.com/uploads/1/0/8/8/10887248/unconscious_facial_reactions_to_emotional_facial_expressions.pdf', 'status': None}","{'volume': '11', 'pages': '86 - 89', 'name': 'Psychological Science'}","{'bibtex': '@Article{Dimberg2000UnconsciousFR,\n author = {U. Dimberg and M. Thunberg and Kurt Elmehed},\n journal = {Psychological Science},\n pages = {86 - 89},\n title = {Unconscious Facial Reactions to Emotional Facial Expressions},\n volume = {11},\n year = {2000}\n}\n'}","[{'authorId': '4583182', 'name': 'U. Dimberg'}, {'authorId': '3924673', 'name': 'M. Thunberg'}, {'authorId': '114829343', 'name': 'Kurt Elmehed'}]"
1144,5d67168e92f571dcc5a738ebd59570d047f14cce,Evaluation of a Virtual Agent in Guiding Users from the Non-Clinical Population in Self-Attachment Intervention,"To address the issue of mental health, therapy chatbots have been developed in recent years to deliver methods such as Cognitive Behavioural Therapy. Self-Attachment is an alternative form of therapy intended to assist individuals so they can regulate their emotional state through developing and maintaining a bond with their childhood self. In this project, we create a chatbot to suggest Self-Attachment protocols based on a user’s emotion and description of recent events leading to that emotion. The chatbot will assist in the scaling of the delivery of Self-Attachment protocols. We utilise a rule-based model within this chatbot to determine which suggestions should be presented to users and ensure that dialogue presented to users is safe and fully controllable to avoid the possibility of harming the user through potentially harmful dialogue being presented by the model. We discuss a trial of the chatbot we performed with 9 participants from the non-clinical population with prior knowledge of Self-Attachment protocols, which shows the chatbot can provide suitable suggestions for Self-Attachment protocols. The chatbot is evaluated by 3 clinicians who had not previously practised Self-Attachment protocols. We also discuss a survey produced during this project, where users were asked to rewrite prompts to be more empathetic. We discuss how it has contributed to the formation of a dataset that can be utilised to enhance the chatbot’s responses to be more empathetic and engaging.",2021.0,48.0,2.0,False,,,"{'bibtex': '@Inproceedings{None,\n title = {Evaluation of a Virtual Agent in Guiding Users from the Non-Clinical Population in Self-Attachment Intervention},\n year = {2021}\n}\n'}",[]
1145,5d6feb9213ea2b713458e316620507e1f6bcc8dd,Storm Effects,,,0.0,2.0,True,"{'url': 'https://zenodo.org/records/1429245/files/article.pdf', 'status': None}","{'volume': '22', 'pages': '290-291', 'name': 'Nature'}","{'bibtex': '@Misc{None,\n author = {J. R. Capron},\n journal = {Nature},\n pages = {290-291},\n title = {Storm Effects},\n volume = {22}\n}\n'}","[{'authorId': '153760921', 'name': 'J. R. Capron'}]"
1146,5db058de2e3637febb07b759a08d4e6cac0f1955,Internet paradox. A social technology that reduces social involvement and psychological well-being?,"The Internet could change the lives of average citizens as much as did the telephone in the early part of the 20th century and television in the 1950s and 1960s. Researchers and social critics are debating whether the Internet is improving or harming participation in community life and social relationships. This research examined the social and psychological impact of the Internet on 169 people in 73 households during their first 1 to 2 years on-line. We used longitudinal data to examine the effects of the Internet on social involvement and psychological well-being. In this sample, the Internet was used extensively for communication. Nonetheless, greater use of the Internet was associated with declines in participants' communication with family members in the household, declines in the size of their social circle, and increases in their depression and loneliness. These findings have implications for research, for public policy and for the design of technology.",1998.0,65.0,4243.0,False,,"{'volume': '53 9', 'pages': '\n          1017-31\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Kraut1998InternetPA,\n author = {Robert E. Kraut and Michael Patterson and Vicki Lundmark and S. Kiesler and Tridas Mukophadhyay and W. Scherlis},\n journal = {The American psychologist},\n pages = {\n          1017-31\n        },\n title = {Internet paradox. A social technology that reduces social involvement and psychological well-being?},\n volume = {53 9},\n year = {1998}\n}\n'}","[{'authorId': '2131324879', 'name': 'Robert E. Kraut'}, {'authorId': '144203498', 'name': 'Michael Patterson'}, {'authorId': '2737785', 'name': 'Vicki Lundmark'}, {'authorId': '47198673', 'name': 'S. Kiesler'}, {'authorId': '2223821382', 'name': 'Tridas Mukophadhyay'}, {'authorId': '1799909', 'name': 'W. Scherlis'}]"
1147,5db96ca077a2e595a4e368e6ba037f053c5c4dbc,Effects of Repetition Learning on Associative Recognition Over Time: Role of the Hippocampus and Prefrontal Cortex,"When stimuli are learned by repetition, they are remembered better and retained for a longer time. However, current findings are lacking as to whether the medial temporal lobe (MTL) and cortical regions are involved in the learning effect when subjects retrieve associative memory, and whether their activations differentially change over time due to learning experience. To address these issues, we designed an fMRI experiment in which face-scene pairs were learned once (L1) or six times (L6). Subjects learned the pairs at four retention intervals, 30-min, 1-day, 1-week and 1-month, after which they finished an associative recognition task in the scanner. The results showed that compared to learning once, learning six times led to stronger activation in the hippocampus, but weaker activation in the perirhinal cortex (PRC) as well as anterior ventrolateral prefrontal cortex (vLPFC). In addition, the hippocampal activation was positively correlated with that of the parahippocampal place area (PPA) and negatively correlated with that of the vLPFC when the L6 group was compared to the L1 group. The hippocampal activation decreased over time after L1 but remained stable after L6. These results clarified how the hippocampus and cortical regions interacted to support associative memory after different learning experiences.",2018.0,88.0,35.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnhum.2018.00277/pdf', 'status': None}","{'volume': '12', 'name': 'Frontiers in Human Neuroscience'}","{'bibtex': '@Article{Zhan2018EffectsOR,\n author = {Lexia Zhan and Dingrong Guo and Gang Chen and Jiongjiong Yang},\n journal = {Frontiers in Human Neuroscience},\n title = {Effects of Repetition Learning on Associative Recognition Over Time: Role of the Hippocampus and Prefrontal Cortex},\n volume = {12},\n year = {2018}\n}\n'}","[{'authorId': '1760914', 'name': 'Lexia Zhan'}, {'authorId': '51055208', 'name': 'Dingrong Guo'}, {'authorId': '143793345', 'name': 'Gang Chen'}, {'authorId': '2109811156', 'name': 'Jiongjiong Yang'}]"
1148,5dd298037cba0067e9a6eab5da886ac1ec926a00,Communication of individual emotions by spontaneous facial expressions,"Examined whether spontaneous facial expressions provide observers with sufficient information to distinguish accurately which of 7 affective states (6 emotional and 1 neutral) is being experienced by another person. Six undergraduate senders' facial expressions were covertly videotaped as they watched emotionally loaded slides. After each slide, senders nominated the emotions term that best described their affective reaction and also rated the pleasantness and strength of that reaction. Similar nominations of emotion terms and ratings were later made by 53 undergraduate receivers who viewed the senders' videotaped facial expression. The central measure of communication accuracy was the match between senders' and receivers' emotion nominations. Overall accuracy was significantly greater than chance, although it was not impressive in absolute terms. Only happy, angry, and disgusted expressions were recognized at above-chance rates, whereas surprised expressions were recognized at rates that were significantly worse than chance. Female Ss were significantly better senders than were male Ss. Although neither sex was found to be better at receiving facial expressions, female Ss were better receivers of female senders' expressions than of male senders' expressions. Female senders' neutral and surprised expressions were more accurately recognized than were those of male senders. The only sex difference found for decoding emotions was a tendency for male Ss to be more accurate at recognizing anger. (25 ref)",1986.0,22.0,181.0,False,,"{'volume': '50', 'pages': '737-743', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Wagner1986CommunicationOI,\n author = {H. Wagner and C. J. MacDonald and A. Manstead},\n journal = {Journal of Personality and Social Psychology},\n pages = {737-743},\n title = {Communication of individual emotions by spontaneous facial expressions},\n volume = {50},\n year = {1986}\n}\n'}","[{'authorId': '144257022', 'name': 'H. Wagner'}, {'authorId': '152422249', 'name': 'C. J. MacDonald'}, {'authorId': '92736978', 'name': 'A. Manstead'}]"
1149,5ddedbab07c3c9282b01b9f81c6026707f4533d6,Current Emotion Research in Psychophysiology: The Neurobiology of Evaluative Bivalence,"Evaluative processes have their roots in early evolutionary history, as survival is dependent on an organism’s ability to identify and respond appropriately to positive, rewarding or otherwise salubrious stimuli as well as to negative, noxious, or injurious stimuli. Consequently, evaluative processes are ubiquitous in the animal kingdom and are represented at multiple levels of the nervous system, including the lowest levels of the neuraxis. While evolution has sculpted higher level evaluative systems into complex and sophisticated information-processing networks, they do not come to replace, but rather to interact with more primitive lower level representations. Indeed, there are basic features of the underlying neuroarchitectural plan for evaluative processes that are common across levels of organization—including that of evaluative bivalence.",2011.0,74.0,52.0,False,,"{'volume': '3', 'pages': '349 - 359', 'name': 'Emotion Review'}","{'bibtex': '@Article{Norman2011CurrentER,\n author = {G. Norman and Catherine J. Norris and J. Gollan and Tiffany A Ito and L. Hawkley and Jeff T. Larsen and J. Cacioppo and G. Berntson},\n journal = {Emotion Review},\n pages = {349 - 359},\n title = {Current Emotion Research in Psychophysiology: The Neurobiology of Evaluative Bivalence},\n volume = {3},\n year = {2011}\n}\n'}","[{'authorId': '144657814', 'name': 'G. Norman'}, {'authorId': '40543729', 'name': 'Catherine J. Norris'}, {'authorId': '32987057', 'name': 'J. Gollan'}, {'authorId': '7853035', 'name': 'Tiffany A Ito'}, {'authorId': '4883465', 'name': 'L. Hawkley'}, {'authorId': '2184118', 'name': 'Jeff T. Larsen'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}, {'authorId': '3636458', 'name': 'G. Berntson'}]"
1150,5e237ef31e4a5d5a486ecbc86490ed9b43ebe48d,An evaluation of the frontal lobe theory of cognitive aging,"In the 1990s, it was argued that age-related changes in the frontal lobes predict cognitive changes in older adults. However, evidence for this hypothesis from behavioural and neuroimaging studies were equivocal at best. This chapter reviews the following four issues. First, there is little strong evidence to support the conclusion that executive control is differentially affected by age in comparison with other cognitive functions. Second, there are differences in the pattern of deficits seen following focal frontal lobe damage and those accompanying the ageing process. Third, the effects of age on social and emotional functioning have been largely ignored, despite considerable evidence linking such functions to the frontal lobes of the brain. Fourth, functional neuroimaging data do not support a straightforward version of the frontal-lobe theory of ageing.",2012.0,0.0,17.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Phillips2012AnEO,\n author = {L. Phillips and J. Henry},\n title = {An evaluation of the frontal lobe theory of cognitive aging},\n year = {2012}\n}\n'}","[{'authorId': '1994871', 'name': 'L. Phillips'}, {'authorId': '2149900272', 'name': 'J. Henry'}]"
1151,5e3a3095fa66db8d09b9f6be0356cf20ed9a4576,Expressions,": This text presents a discussion on the impacts of the precarization of the teaching work taking as a starting point the regulation of the working day of teachers of basic education. The objective is to reflect on how precarious work affects the organization of working day through the intensification of teaching work. It develops from bibliographical discussion based on historical-dialectical materialism and uses the analysis of the national legislation that involves the theme. Based on the regulation of working hours in the state of Paraná, it is discussed how the fragility of this career regulation affects teachers. In the context of the bureaucratic and managerialist State, the instability of the organization of the working day results in the intensification and precarization of the work.",2021.0,209.0,2650.0,False,,{'name': 'Cross-Cultural Pragmatics'},"{'bibtex': '@Article{d’ailleurs2021Expressions,\n author = {Je suis d’ailleurs and Je suis d’ailleurs},\n journal = {Cross-Cultural Pragmatics},\n title = {Expressions},\n year = {2021}\n}\n'}","[{'authorId': '2267255640', 'name': 'Je suis d’ailleurs'}, {'authorId': '2267255640', 'name': 'Je suis d’ailleurs'}]"
1152,5e42c2a75705e82061cdcd6888e0121e0eadd448,Relational agents: a model and implementation of building user trust,"Building trust with users is crucial in a wide range of applications, such as financial transactions, and some minimal degree of trust is required in all applications to even initiate and maintain an interaction with a user. Humans use a variety of relational conversational strategies, including small talk, to establish trusting relationships with each other. We argue that such strategies can also be used by interface agents, and that embodied conversational agents are ideally suited for this task given the myriad cues available to them for signaling trustworthiness. We describe a model of social dialogue, an implementation in an embodied conversation agent, and an experiment in which social dialogue was demonstrated to have an effect on trust, for users with a disposition to be extroverts.",2001.0,35.0,458.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Bickmore2001RelationalAA,\n author = {T. Bickmore and Justine Cassell},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Relational agents: a model and implementation of building user trust},\n year = {2001}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
1153,5e42e01d04454aae6cbda0ad4bcf1228d00c5749,Insights Into the Factors Influencing Student Motivation in Augmented Reality Learning Experiences in Vocational Education and Training,"Research on Augmented Reality (AR) in education has demonstrated that AR applications designed with diverse components boost student motivation in educational settings. However, most of the research conducted to date, does not define exactly what those components are and how these components positively affect student motivation. This study, therefore, attempts to identify some of the components that positively affect student motivation in mobile AR learning experiences to contribute to the design and development of motivational AR learning experiences for the Vocational Education and Training (VET) level of education. To identify these components, a research model constructed from the literature was empirically validated with data obtained from two sources: 35 students from four VET institutes interacting with an AR application for learning for a period of 20 days, and a self-report measure obtained from the Instructional Materials Motivation Survey (IMMS). We found that the following variables: use of scaffolding, real-time feedback, degree of success, time on-task and learning outcomes are positively correlated with the four dimensions of the ARCS model of motivation: Attention, Relevance, Confidence, and Satisfaction. Implications of these results are also described.",2018.0,58.0,44.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01486/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Bacca2018InsightsIT,\n author = {J. Bacca and S. Baldiris and R. Fabregat and Kinshuk},\n journal = {Frontiers in Psychology},\n title = {Insights Into the Factors Influencing Student Motivation in Augmented Reality Learning Experiences in Vocational Education and Training},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '8696488', 'name': 'J. Bacca'}, {'authorId': '1728461', 'name': 'S. Baldiris'}, {'authorId': '1694654', 'name': 'R. Fabregat'}, {'authorId': '7910112', 'name': 'Kinshuk'}]"
1154,5e4bca08443acdd9343e5edf448fd0d9e959588c,Human agency beliefs influence behaviour during virtual social interactions,"In recent years, with the emergence of relatively inexpensive and accessible virtual reality technologies, it is now possible to deliver compelling and realistic simulations of human-to-human interaction. Neuroimaging studies have shown that, when participants believe they are interacting via a virtual interface with another human agent, they show different patterns of brain activity compared to when they know that their virtual partner is computer-controlled. The suggestion is that users adopt an “intentional stance” by attributing mental states to their virtual partner. However, it remains unclear how beliefs in the agency of a virtual partner influence participants’ behaviour and subjective experience of the interaction. We investigated this issue in the context of a cooperative “joint attention” game in which participants interacted via an eye tracker with a virtual onscreen partner, directing each other’s eye gaze to different screen locations. Half of the participants were correctly informed that their partner was controlled by a computer algorithm (“Computer” condition). The other half were misled into believing that the virtual character was controlled by a second participant in another room (“Human” condition). Those in the “Human” condition were slower to make eye contact with their partner and more likely to try and guide their partner before they had established mutual eye contact than participants in the “Computer” condition. They also responded more rapidly when their partner was guiding them, although the same effect was also found for a control condition in which they responded to an arrow cue. Results confirm the influence of human agency beliefs on behaviour in this virtual social interaction context. They further suggest that researchers and developers attempting to simulate social interactions should consider the impact of agency beliefs on user experience in other social contexts, and their effect on the achievement of the application’s goals.",2017.0,24.0,25.0,True,,"{'volume': '5', 'name': 'PeerJ'}","{'bibtex': '@Article{Caruana2017HumanAB,\n author = {N. Caruana and Dean Spirou and Jon Brock},\n journal = {PeerJ},\n title = {Human agency beliefs influence behaviour during virtual social interactions},\n volume = {5},\n year = {2017}\n}\n'}","[{'authorId': '2135703', 'name': 'N. Caruana'}, {'authorId': '25623194', 'name': 'Dean Spirou'}, {'authorId': '48687598', 'name': 'Jon Brock'}]"
1155,5e8191d25f12804c928329cd4f53418ce7e4e22a,A Comparison between the Effect of Cooperative Learning Teaching Method and Lecture Teaching Method on Students' Learning and Satisfaction Level.,"The aim of the present research is to investigate a comparison between the effect of cooperative learning teaching method and lecture teaching method on students’ learning and satisfaction level. The research population consisted of all the fourth grade elementary school students of educational district 4 in Shiraz. The statistical population included 120 students (60 female and 60 male) of fifth grade elementary school that were selected randomly. The research method was semi-experimental and the research tools included a 40-item exam aimed at evaluating the students’ learning level and also a questionnaire aimed at measuring student’s satisfaction level that included 25 items. Validity was calculated by asking 14 educational science professors and 12 members of the board of education to examine the content of the items. The reliability of the test was confirmed through retesting (r=.88). For data analysis, t-test and variance analysis were used by utilizing SPSS software. The results showed that the cooperative learning teaching method has a higher effect on students learning than the lecture teaching method. Also the results showed that the cooperative learning method results in higher satisfaction in students that the lecture teaching method. Female students had higher satisfaction and learning levels in cooperative learning teaching method than male students did.",2015.0,22.0,29.0,True,"{'url': 'https://www.ccsenet.org/journal/index.php/ies/article/download/52587/28111', 'status': None}","{'volume': '8', 'pages': '107-112', 'name': 'International Education Studies'}","{'bibtex': ""@Article{Mohammadjani2015ACB,\n author = {Farzad Mohammadjani and F. Tonkaboni},\n journal = {International Education Studies},\n pages = {107-112},\n title = {A Comparison between the Effect of Cooperative Learning Teaching Method and Lecture Teaching Method on Students' Learning and Satisfaction Level.},\n volume = {8},\n year = {2015}\n}\n""}","[{'authorId': '113635625', 'name': 'Farzad Mohammadjani'}, {'authorId': '84262259', 'name': 'F. Tonkaboni'}]"
1156,5ea770c8e016072963b8a7497d4e3e1e26f83db5,Biometrics and Kansei Engineering,,2012.0,39.0,25.0,True,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Saeed2012BiometricsAK,\n author = {K. Saeed and T. Nagashima},\n title = {Biometrics and Kansei Engineering},\n year = {2012}\n}\n'}","[{'authorId': '145623773', 'name': 'K. Saeed'}, {'authorId': '3163017', 'name': 'T. Nagashima'}]"
1157,5f13bbb89d8d1919b9d5c34e4f864c9267918130,The Rickel Gaze Model: A Window on the Mind of a Virtual Human,,2007.0,18.0,86.0,False,,{'pages': '296-303'},"{'bibtex': '@Inproceedings{Lee2007TheRG,\n author = {Jina Lee and S. Marsella and D. Traum and J. Gratch and Brent Lance},\n pages = {296-303},\n title = {The Rickel Gaze Model: A Window on the Mind of a Virtual Human},\n year = {2007}\n}\n'}","[{'authorId': '9174234', 'name': 'Jina Lee'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '145417478', 'name': 'Brent Lance'}]"
1158,5f3feb987dc1f2108e4e19f7df897edcc6f5d334,Analyzing first impressions of warmth and competence from observable nonverbal cues in expert-novice interactions,"In this paper we present an analysis from a corpus of dyadic expert-novice knowledge sharing interactions. The analysis aims at investigating the relationship between observed non-verbal cues and first impressions formation of warmth and competence. We first obtained both discrete and continuous annotations of our data. Discrete descriptors include non-verbal cues such as type of gestures, arms rest poses, head movements and smiles. Continuous descriptors concern annotators' judgments of the expert's warmth and competence during the observed interaction with the novice. Then we computed Odds Ratios between those descriptors. Results highlight the role of smiling in warmth and competence impressions. Smiling is associated with increased levels of warmth and decreasing competence. It also affects the impact of others non-verbal cues (e.g. self-adaptors gestures) on warmth and competence. Moreover, our findings provide interesting insights about the role of rest poses, that are associated with decreased levels of warmth and competence impressions.",2017.0,46.0,19.0,False,,{'name': 'Proceedings of the 19th ACM International Conference on Multimodal Interaction'},"{'bibtex': '@Article{Biancardi2017AnalyzingFI,\n author = {Béatrice Biancardi and Angelo Cafaro and C. Pelachaud},\n journal = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},\n title = {Analyzing first impressions of warmth and competence from observable nonverbal cues in expert-novice interactions},\n year = {2017}\n}\n'}","[{'authorId': '23567239', 'name': 'Béatrice Biancardi'}, {'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1159,5f418d7bae3bd01e97ef2635a9b953bc17c53770,Fostering deep understanding in geography by inducing and managing confusion: an online learning approach,"Confusion is an emotion that is likely to occur when learning complex concepts. While this emotion is often seen as undesirable because of its potential to induce frustration and boredom, recent research has highlighted the vital role confusion can play in student learning. The learning of topics in geography such as tropical cyclone causes and processes can be particularly difficult because it requires the reconstruction of intuitive mental models that are often robust and resistant to change. This paper presents the design framework for an online module designed to enhance university students’ depth of knowledge of tropical cyclones. In particular, the intervention aims manage the level of confusion during learning. We hypothesise that in this way learners can engage with the cognitively demanding ideas in this topic and they are less likely to experience emotions such as frustration and boredom, which would be detrimental to the development of deep understanding.",2015.0,16.0,18.0,False,,"{'volume': '', 'pages': '374-378', 'name': ''}","{'bibtex': '@Inproceedings{Arguel2015FosteringDU,\n author = {A. Arguel and Rod Lane},\n pages = {374-378},\n title = {Fostering deep understanding in geography by inducing and managing confusion: an online learning approach},\n year = {2015}\n}\n'}","[{'authorId': '2896194', 'name': 'A. Arguel'}, {'authorId': '144295642', 'name': 'Rod Lane'}]"
1160,5f512b9fe24a9121bb175908b423c1fa5464cc8b,Gender differences in empathy: The role of the right hemisphere,,2008.0,51.0,346.0,False,,"{'volume': '67', 'pages': '162-167', 'name': 'Brain and Cognition'}","{'bibtex': '@Article{Rueckert2008GenderDI,\n author = {L. Rueckert and Nicolette Naybar},\n journal = {Brain and Cognition},\n pages = {162-167},\n title = {Gender differences in empathy: The role of the right hemisphere},\n volume = {67},\n year = {2008}\n}\n'}","[{'authorId': '8767469', 'name': 'L. Rueckert'}, {'authorId': '4466990', 'name': 'Nicolette Naybar'}]"
1161,5fbfca240af7702b81ef58f90e3ede22647e4b5e,On: Attachment theory and psychoanalysis.,,2007.0,0.0,444.0,False,,"{'volume': '88 Pt 1', 'pages': '\n          240-1; author reply 241-2\n        ', 'name': 'The International journal of psycho-analysis'}","{'bibtex': '@Article{Szajnberg2007OnAT,\n author = {N. Szajnberg},\n journal = {The International journal of psycho-analysis},\n pages = {\n          240-1; author reply 241-2\n        },\n title = {On: Attachment theory and psychoanalysis.},\n volume = {88 Pt 1},\n year = {2007}\n}\n'}","[{'authorId': '3897865', 'name': 'N. Szajnberg'}]"
1163,5fe003333d41dbf56f60a7c3c6c28a198e503ccd,Annotation of Emotion Carriers in Personal Narratives,"We are interested in the problem of understanding personal narratives (PN) - spoken or written - recollections of facts, events, and thoughts. For PNs, we define emotion carriers as the speech or text segments that best explain the emotional state of the narrator. Such segments may span from single to multiple words, containing for example verb or noun phrases. Advanced automatic understanding of PNs requires not only the prediction of the narrator’s emotional state but also to identify which events (e.g. the loss of a relative or the visit of grandpa) or people (e.g. the old group of high school mates) carry the emotion manifested during the personal recollection. This work proposes and evaluates an annotation model for identifying emotion carriers in spoken personal narratives. Compared to other text genres such as news and microblogs, spoken PNs are particularly challenging because a narrative is usually unstructured, involving multiple sub-events and characters as well as thoughts and associated emotions perceived by the narrator. In this work, we experiment with annotating emotion carriers in speech transcriptions from the Ulm State-of-Mind in Speech (USoMS) corpus, a dataset of PNs in German. We believe this resource could be used for experiments in the automatic extraction of emotion carriers from PN, a task that could provide further advancements in narrative understanding.",2020.0,43.0,9.0,False,,{'pages': '1517-1525'},"{'bibtex': '@Inproceedings{Tammewar2020AnnotationOE,\n author = {Aniruddha Tammewar and Alessandra Cervone and Eva-Maria Messner and G. Riccardi},\n pages = {1517-1525},\n title = {Annotation of Emotion Carriers in Personal Narratives},\n year = {2020}\n}\n'}","[{'authorId': '39823859', 'name': 'Aniruddha Tammewar'}, {'authorId': '32015706', 'name': 'Alessandra Cervone'}, {'authorId': '117656327', 'name': 'Eva-Maria Messner'}, {'authorId': '1719162', 'name': 'G. Riccardi'}]"
1164,5ff9c37f98d551f71b1dca709dc07e913622b64c,From Discourse Plans to Believable Behavior Generation,"Developing an embodied conversational agent that is able to exhibit a human-like behavior while communicating with other virtual or human agents requires enriching a typical NLG architecture. The purpose of this paper is to describe our efforts in this direction and to illustrate our approach to the generation of an Agent that shows a personality, a social intelligence and is able to react emotionally to events occurring in the environment, consistently with her goals and with the context in which the conversation takes place.",2002.0,11.0,33.0,False,,{'pages': '65-72'},"{'bibtex': '@Inproceedings{Carolis2002FromDP,\n author = {B. D. Carolis and V. Carofiglio and C. Pelachaud},\n pages = {65-72},\n title = {From Discourse Plans to Believable Behavior Generation},\n year = {2002}\n}\n'}","[{'authorId': '1739256', 'name': 'B. D. Carolis'}, {'authorId': '1694255', 'name': 'V. Carofiglio'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1165,601273c37a9670f00234f7e7092bb673e7c0b25c,A multidimensional approach to the structure of personality impressions.,,1968.0,18.0,911.0,False,,"{'volume': '9 4', 'pages': '\n          283-94\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Rosenberg1968AMA,\n author = {S. Rosenberg and C. Nelson and P. S. Vivekananthan},\n journal = {Journal of personality and social psychology},\n pages = {\n          283-94\n        },\n title = {A multidimensional approach to the structure of personality impressions.},\n volume = {9 4},\n year = {1968}\n}\n'}","[{'authorId': '144837978', 'name': 'S. Rosenberg'}, {'authorId': '41176052', 'name': 'C. Nelson'}, {'authorId': '17038348', 'name': 'P. S. Vivekananthan'}]"
1166,6036a2f5537297a384ac5ff611d3e4996fca2483,Sequential patterns for text categorization,"Text categorization is a well-known task based essentially on statistical approaches using neural networks, Support Vector Machines and other machine learning algorithms. Texts are generally considered as bags of words without any order. Although these approaches have proven to be efficient, they do not provide users with comprehensive and reusable rules about their data. Such rules are, however, very important for users to describe trends in the data they have to analyze. In this framework, an association-rule based approach has been proposed by Bing Liu (CBA). We propose, in this paper, to extend this approach by using sequential patterns in the SPaC method (Sequential Patterns for Classification) for text categorization. Taking order into account allows us to represent the succession of words through a document without complex and time-consuming representations and treatments such as those performed in natural language and grammatical methods. The original method we propose here consists in mining sequential patterns in order to build a classifier. We experimentally show that our proposal is relevant, and that it is very interesting compared to other methods. In particular, our method outperforms CBA and provides better results than SVM on some corpus.",2006.0,43.0,60.0,True,"{'url': 'https://hal-lirmm.ccsd.cnrs.fr/lirmm-00135010/file/ida245.PDF', 'status': None}","{'volume': '10', 'pages': '199-214', 'name': 'Intell. Data Anal.'}","{'bibtex': '@Article{Jaillet2006SequentialPF,\n author = {Simon Jaillet and Anne Laurent and M. Teisseire},\n journal = {Intell. Data Anal.},\n pages = {199-214},\n title = {Sequential patterns for text categorization},\n volume = {10},\n year = {2006}\n}\n'}","[{'authorId': '2476469', 'name': 'Simon Jaillet'}, {'authorId': '145472032', 'name': 'Anne Laurent'}, {'authorId': '1683304', 'name': 'M. Teisseire'}]"
1167,604a907a45015e365d8daac9de9a11d6b35be30d,An Overview of Serious Games,"Serious games are growing rapidly as a gaming industry as well as a field of academic research. There are many surveys in the field of digital serious games; however, most surveys are specific to a particular area such as education or health. So far, there has been little work done to survey digital serious games in general, which is the main goal of this paper. Hence, we discuss relevant work on serious games in different application areas including education, well-being, advertisement, cultural heritage, interpersonal communication, and health care. We also propose a taxonomy for digital serious games, and we suggest a classification of reviewed serious games applications from the literature against the defined taxonomy. Finally, the paper provides guidelines, drawn from the literature, for the design and development of successful serious games, as well as discussing research perspectives in this domain.",2014.0,92.0,345.0,True,"{'url': 'https://downloads.hindawi.com/journals/ijcgt/2014/358152.pdf', 'status': None}","{'volume': '2014', 'pages': '358152:1-358152:15', 'name': 'Int. J. Comput. Games Technol.'}","{'bibtex': '@Article{Laamarti2014AnOO,\n author = {Fedwa Laamarti and M. Eid and Abdulmotaleb El Saddik},\n journal = {Int. J. Comput. Games Technol.},\n pages = {358152:1-358152:15},\n title = {An Overview of Serious Games},\n volume = {2014},\n year = {2014}\n}\n'}","[{'authorId': '2477333', 'name': 'Fedwa Laamarti'}, {'authorId': '36728550', 'name': 'M. Eid'}, {'authorId': '30889568', 'name': 'Abdulmotaleb El Saddik'}]"
1168,6074571145b3a1f68dae28ddc489b7e398d96306,Beyond pleasure and pain: Facial expression ambiguity in adults and children during intense situations.,"According to psychological models as well as common intuition, intense positive and negative situations evoke highly distinct emotional expressions. Nevertheless, recent work has shown that when judging isolated faces, the affective valence of winning and losing professional tennis players is hard to differentiate. However, expressions produced by professional athletes during publicly broadcasted sports events may be strategically controlled. To shed light on this matter we examined if ordinary people's spontaneous facial expressions evoked during highly intense situations are diagnostic for the situational valence. In Experiment 1 we compared reactions with highly intense positive situations (surprise soldier reunions) versus highly intense negative situations (terror attacks). In Experiment 2, we turned to children and compared facial reactions with highly positive situations (e.g., a child receiving a surprise trip to Disneyland) versus highly negative situations (e.g., a child discovering her parents ate up all her Halloween candy). The results demonstrate that facial expressions of both adults and children are often not diagnostic for the valence of the situation. These findings demonstrate the ambiguity of extreme facial expressions and highlight the importance of context in everyday emotion perception. (PsycINFO Database Record",2016.0,50.0,37.0,False,,"{'volume': '16 6', 'pages': '\n          807-14\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Wenzler2016BeyondPA,\n author = {S. Wenzler and Sarah Levine and R. van Dick and V. Oertel-Knöchel and Hillel Aviezer},\n journal = {Emotion},\n pages = {\n          807-14\n        },\n title = {Beyond pleasure and pain: Facial expression ambiguity in adults and children during intense situations.},\n volume = {16 6},\n year = {2016}\n}\n'}","[{'authorId': '4688263', 'name': 'S. Wenzler'}, {'authorId': '2070544493', 'name': 'Sarah Levine'}, {'authorId': '48250810', 'name': 'R. van Dick'}, {'authorId': '1398506844', 'name': 'V. Oertel-Knöchel'}, {'authorId': '4387567', 'name': 'Hillel Aviezer'}]"
1169,607e0837c80d4380cd4ba9c3083e69aa3254a563,Relative contributions of face and body configurations: Perceiving emotional state and motion intention,"This study addressed the relative reliance on face and body configurations for different types of emotion-related judgements: emotional state and motion intention. Participants viewed images of people with either emotionally congruent (both angry or fearful) or incongruent (angry/fearful; fearful/angry) faces and bodies. Congruent conditions provided baseline responses. Incongruent conditions revealed relative reliance on face and body information for different judgements. Body configurations influenced motion-intention judgements more than facial configurations: incongruent pairs with angry bodies were more frequently perceived as moving forward than those with fearful bodies; pairs with fearful bodies were more frequently perceived as moving away. In contrast, faces influenced emotional-state judgements more, but bodies moderated ratings of face emotion. Thus, both face and body configurations influence emotion perception, but the type of evaluation required influences their relative contributions. These findings highlight the importance of considering both the face and body as important sources of emotion information.",2012.0,26.0,22.0,False,,"{'volume': '26', 'pages': '690 - 698', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{App2012RelativeCO,\n author = {B. App and C. Reed and D. McIntosh},\n journal = {Cognition and Emotion},\n pages = {690 - 698},\n title = {Relative contributions of face and body configurations: Perceiving emotional state and motion intention},\n volume = {26},\n year = {2012}\n}\n'}","[{'authorId': '145972787', 'name': 'B. App'}, {'authorId': '145182723', 'name': 'C. Reed'}, {'authorId': '21464189', 'name': 'D. McIntosh'}]"
1170,6085213f948cb197d5da626cc7d3b92210552d7d,An Architecture to Develop Multimodal Educative Applications with Chatbots,"Animated characters are beginning to be used as pedagogical tools, as they have the power to capture students' attention and foster their motivation for discovery and learning. However, in order for them to be widely employed and accepted as a learning resource, they must be easy to use and friendly. In this paper we present an architecture that facilitates building interactive pedagogical chatbots that can interact with students in natural language. Our proposal provides a modular and scalable framework to develop such systems efficiently. Additionally, we present Geranium, a system that helps children to appreciate and protect their environment with an interactive chatbot developed following our scheme.",2013.0,80.0,28.0,True,,"{'volume': '10', 'name': 'International Journal of Advanced Robotic Systems'}","{'bibtex': '@Article{Griol2013AnAT,\n author = {D. Griol and Z. Callejas},\n journal = {International Journal of Advanced Robotic Systems},\n title = {An Architecture to Develop Multimodal Educative Applications with Chatbots},\n volume = {10},\n year = {2013}\n}\n'}","[{'authorId': '1804281', 'name': 'D. Griol'}, {'authorId': '67297965', 'name': 'Z. Callejas'}]"
1171,6086c5ba570918a8c3b3d4623690860e784aca6d,Corpus-based generation of head and eyebrow motion for an embodied conversational agent,,2007.0,32.0,56.0,False,,"{'volume': '41', 'pages': '305-323', 'name': 'Language Resources and Evaluation'}","{'bibtex': '@Article{Foster2007CorpusbasedGO,\n author = {M. Foster and J. Oberlander},\n journal = {Language Resources and Evaluation},\n pages = {305-323},\n title = {Corpus-based generation of head and eyebrow motion for an embodied conversational agent},\n volume = {41},\n year = {2007}\n}\n'}","[{'authorId': '34923062', 'name': 'M. Foster'}, {'authorId': '3263707', 'name': 'J. Oberlander'}]"
1172,6089cd4d2264d23b4f5580cd00af29a85ef3659b,A Note on the Validity of Self-Reports of Absenteeism,"The general unavailability of and difficulty associated with obtaining records-based data on absenteeism suggests the potential value of self-report data for those conducting research on absenteeism. This should not be recommended, however, until the validity of these self-report measures is assessed. In this paper, we compare records-based and self-report measures of absenteeism for the same employees for the same period of time. We find that although the univariate descriptive data for the two measures are similar, the correlation between the two is .299. Although this is in the expected direction, its magnitude is small enough for us to question the validity of self- report measures of absenteeism. Several suggestions are offered for additional study of this.",1987.0,12.0,22.0,False,,"{'volume': '40', 'pages': '117 - 123', 'name': 'Human Relations'}","{'bibtex': '@Article{Mueller1987ANO,\n author = {C. Mueller and D. Wakefield and J. L. Price and J. Curry and J. McCloskey},\n journal = {Human Relations},\n pages = {117 - 123},\n title = {A Note on the Validity of Self-Reports of Absenteeism},\n volume = {40},\n year = {1987}\n}\n'}","[{'authorId': '39706207', 'name': 'C. Mueller'}, {'authorId': '31898312', 'name': 'D. Wakefield'}, {'authorId': '47051477', 'name': 'J. L. Price'}, {'authorId': '2054074831', 'name': 'J. Curry'}, {'authorId': '2980638', 'name': 'J. McCloskey'}]"
1173,6097d5bd62277def74e8582b425d223b65056ee7,Machine learning techniques for autonomous agents in military simulations — Multum in parvo,"In military simulations, software agents are used to represent individuals, weapon platforms or aggregates thereof. Modeling the behavioral capabilities and limitations of such agents may be time-consuming, requiring extensive interaction with subject matter experts and complicated scripts, but nevertheless resulting in rigid, predictable performance. Autonomous agents that learn desired behaviors themselves using Machine Learning (ML) techniques can overcome these shortcomings. However, such techniques are not yet widely used and perhaps underappreciated. In this context, the latin expression ""multum in parvo"" (""much in little"") denotes that ML agents are able to yield a large variety of behavior, despite their compactness in terms of code and usage of physical memory. This paper attempts to provide some background on applicable Machine Learning solutions and their potential military application. The paper is based on the work of the NATO Research Task Group IST-121 Machine Learning Techniques for Autonomous Computer Generated Entities.",2017.0,28.0,11.0,False,,"{'pages': '3445-3450', 'name': '2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)'}","{'bibtex': '@Article{Roessingh2017MachineLT,\n author = {J. Roessingh and A. Toubman and J. V. Oijen and G. Poppinga and R. A. Løvlid and Ming Hou and L. Luotsinen},\n journal = {2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},\n pages = {3445-3450},\n title = {Machine learning techniques for autonomous agents in military simulations — Multum in parvo},\n year = {2017}\n}\n'}","[{'authorId': '2398535', 'name': 'J. Roessingh'}, {'authorId': '3075138', 'name': 'A. Toubman'}, {'authorId': '1758865', 'name': 'J. V. Oijen'}, {'authorId': '14767528', 'name': 'G. Poppinga'}, {'authorId': '87359978', 'name': 'R. A. Løvlid'}, {'authorId': '2144273323', 'name': 'Ming Hou'}, {'authorId': '2200611', 'name': 'L. Luotsinen'}]"
1174,60a06f72e8b4c6b3cd732682dfa7da5899a3f1ff,Expression of emotion in voice and music.,,1995.0,94.0,439.0,True,"{'url': 'https://access.archive-ouverte.unige.ch/access/metadata/1698d139-3996-43a3-981b-75ba147f7d17/download', 'status': None}","{'volume': '9 3', 'pages': '\n          235-48\n        ', 'name': 'Journal of voice : official journal of the Voice Foundation'}","{'bibtex': '@Article{Scherer1995ExpressionOE,\n author = {K. Scherer},\n journal = {Journal of voice : official journal of the Voice Foundation},\n pages = {\n          235-48\n        },\n title = {Expression of emotion in voice and music.},\n volume = {9 3},\n year = {1995}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}]"
1175,60d57df50f55a7b5d3ca15807896bced82e9d1f0,The Effects of Backchannels on Fluency in L2 Oral Task Production.,,2008.0,60.0,25.0,False,,"{'volume': '36', 'pages': '279-294', 'name': 'System'}","{'bibtex': '@Article{Wolf2008TheEO,\n author = {James P. Wolf},\n journal = {System},\n pages = {279-294},\n title = {The Effects of Backchannels on Fluency in L2 Oral Task Production.},\n volume = {36},\n year = {2008}\n}\n'}","[{'authorId': '153544611', 'name': 'James P. Wolf'}]"
1176,60ed31580e9884f1a42c1666939ca9c13e9ec9d9,Design of a Product Recommendation Virtual Agent That Induces User’s Trust Operating User’s Trust,"The PRVAs, product recommendation virtual agent, are the agents that take part in the clerks on the onlineshopping. For their aims, it is very important for the PRVAs to be trusted by users. However, trustworthy the PRVA design was not be studied yet. In this paper, we suggest the user’s trust transition model that is consisted by two parameters. One parameter is user’s emotion, and the other is agent’s knowledge. We suggested the transition operators that transited these two parameters by executing when the PRVAs recommend. Emotion transition operators are agent’s smile and gestures. Knowledge transition operators is long product recommendation text. We carried on three experiments to estimate these model and transition operators. In experiment 1, we executed no transition operators. In experiment 2, we executed emotion transition operators and added knowledge transition operators in the latter half. In experiment 3, we executed knowledge transition operators in the first half and added emotion transition operators in the latter half. As a results, it is discovered that transition operators and a transition model are effective. In experiment 1, there are no transition in the participants’ trust state. In experiment 2, the participants’ knowledge perceived and trust for agent transited after executing knowledge transition operators. In experiment 3, the participants’ emotion transited after executing positive emotion operators, however, trust didn’t transited. From these result, we concluded that trust is based on each of the user’s emotion and the agent’s knowledge.",2017.0,16.0,0.0,True,,"{'name': 'Transactions of The Japanese Society for Artificial Intelligence', 'volume': '32'}","{'bibtex': '@Article{Matsui2017DesignOA,\n author = {T. Matsui and S. Yamada},\n journal = {Transactions of The Japanese Society for Artificial Intelligence},\n title = {Design of a Product Recommendation Virtual Agent That Induces User’s Trust Operating User’s Trust},\n volume = {32},\n year = {2017}\n}\n'}","[{'authorId': '49201495', 'name': 'T. Matsui'}, {'authorId': '1679243', 'name': 'S. Yamada'}]"
1177,617fdf0d840684f6919bad6ced330f67b25732e9,The effect of clinician-patient alliance and communication on treatment adherence in mental health care: a systematic review,,2012.0,65.0,214.0,True,"{'url': 'https://bmcpsychiatry.biomedcentral.com/counter/pdf/10.1186/1471-244X-12-87', 'status': None}","{'volume': '12', 'pages': '87 - 87', 'name': 'BMC Psychiatry'}","{'bibtex': '@Article{Thompson2012TheEO,\n author = {Laura Thompson and R. McCabe},\n journal = {BMC Psychiatry},\n pages = {87 - 87},\n title = {The effect of clinician-patient alliance and communication on treatment adherence in mental health care: a systematic review},\n volume = {12},\n year = {2012}\n}\n'}","[{'authorId': '145038679', 'name': 'Laura Thompson'}, {'authorId': '152765543', 'name': 'R. McCabe'}]"
1178,61957cd718d52659f7f2ae379cbe02ded3a8db05,Conversational Gaze Aversion for Virtual Agents,,2013.0,22.0,48.0,False,,{'pages': '249-262'},"{'bibtex': '@Inproceedings{Andrist2013ConversationalGA,\n author = {Sean Andrist and Bilge Mutlu and Michael Gleicher},\n pages = {249-262},\n title = {Conversational Gaze Aversion for Virtual Agents},\n year = {2013}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}]"
1179,619bb8cac2c93e127ecb0331cb2fa994d10589ec,Therapist vibe: children's expressions of their emotions through storytelling with a chatbot,"Storytelling can develop children's emotional intelligence when they are asked to freely talk about their emotions. While parents are responsible for teaching emotional intelligence, studies in using affective technologies to help people become aware of their emotions have also been explored. In this paper, we investigate the opportunity of this technology in enabling children to recognize and express their emotions. We describe a chatbot that leverages storytelling strategies to listen to children as they share emotional events they experienced, then guides them through reflective discipline to devise the next course of action. We report the types of emotions children choose to share with the chatbot, the kinds of support that the chatbot provided, the challenges during the conversation and children's perception of the chatbot. From our findings, we suggest design considerations for a conversation flow that anchors on storytelling to support child-agent interaction.",2020.0,49.0,27.0,False,,{'name': 'Proceedings of the Interaction Design and Children Conference'},"{'bibtex': ""@Article{Santos2020TherapistVC,\n author = {Kyle-Althea Santos and Ethel Ong and Ron R. Resurreccion},\n journal = {Proceedings of the Interaction Design and Children Conference},\n title = {Therapist vibe: children's expressions of their emotions through storytelling with a chatbot},\n year = {2020}\n}\n""}","[{'authorId': '1750919955', 'name': 'Kyle-Althea Santos'}, {'authorId': '8045848', 'name': 'Ethel Ong'}, {'authorId': '116323144', 'name': 'Ron R. Resurreccion'}]"
1180,61ba3584885142e46673943142a4f2280ac14387,Towards Designing Cooperative and Social Conversational Agents for Customer Service,"The idea of interacting with computers through natural language dates back to the 1960s, but recent technological advances have led to a renewed interest in conversational agents such as chatbots or digital assistants. In the customer service context, conversational agents promise to create a fast, convenient, and cost-effective channel for communicating with customers. Although numerous agents have been implemented in the past, most of them could not meet the expectations and disappeared. In this paper, we present our design science research project on how to design cooperative and social conversational agents to increase service quality in customer service. We discuss several issues that hinder the success of current conversational agents in customer service. Drawing on the cooperative principle of conversation and social response theory, we propose preliminary meta-requirements and design principles for cooperative and social conversational agents. Next, we will develop a prototype based on these design principles.",2017.0,79.0,221.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gnewuch2017TowardsDC,\n author = {Ulrich Gnewuch and Stefan Morana and A. Maedche},\n title = {Towards Designing Cooperative and Social Conversational Agents for Customer Service},\n year = {2017}\n}\n'}","[{'authorId': '7807550', 'name': 'Ulrich Gnewuch'}, {'authorId': '3339327', 'name': 'Stefan Morana'}, {'authorId': '1806905', 'name': 'A. Maedche'}]"
1181,6231ae1aeba3768f4b6f33941736fa53eec204ba,Toward a New Generation of Cross-Cultural Research,"In this article, we describe how cross-cultural research methodologies have evolved, with each phase of research addressing limitations of a previous one. We describe briefly the three previous phases and argue for embarking on a fourth phase that empirically establishes linkages between the active cultural ingredients hypothesized to cause between-country differences and the observed differences themselves. We discuss theoretical considerations and possible empirical methods to establish such linkages, and urge researchers to seriously consider incorporating these kinds of linkage studies in their programs of research.",2006.0,152.0,381.0,False,,"{'volume': '1', 'pages': '234 - 250', 'name': 'Perspectives on Psychological Science'}","{'bibtex': '@Article{Matsumoto2006TowardAN,\n author = {D. Matsumoto and S. Yoo},\n journal = {Perspectives on Psychological Science},\n pages = {234 - 250},\n title = {Toward a New Generation of Cross-Cultural Research},\n volume = {1},\n year = {2006}\n}\n'}","[{'authorId': '145413880', 'name': 'D. Matsumoto'}, {'authorId': '50313734', 'name': 'S. Yoo'}]"
1182,624328b4d6ee529019b0654bca6ca65abde60218,Directorial Control in a Decision-Theoretic Framework for Interactive Narrative,,2009.0,26.0,30.0,False,,{'pages': '221-233'},"{'bibtex': '@Inproceedings{Si2009DirectorialCI,\n author = {Mei Si and S. Marsella and D. Pynadath},\n pages = {221-233},\n title = {Directorial Control in a Decision-Theoretic Framework for Interactive Narrative},\n year = {2009}\n}\n'}","[{'authorId': '33432486', 'name': 'Mei Si'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '1748597', 'name': 'D. Pynadath'}]"
1183,6258156445ec81e556a199ddc02c2c98f6553175,The Use of Virtual Reality Technology in the Treatment of Anxiety and Other Psychiatric Disorders,"Learning objectives After participating in this activity, learners should be better able to: • Evaluate the literature regarding the effectiveness of incorporating virtual reality (VR) in the treatment of psychiatric disorders • Assess the use of exposure-based intervention for anxiety disorders Abstract Virtual reality (VR) allows users to experience a sense of presence in a computer-generated, three-dimensional environment. Sensory information is delivered through a head-mounted display and specialized interface devices. These devices track head movements so that the movements and images change in a natural way with head motion, allowing for a sense of immersion. VR, which allows for controlled delivery of sensory stimulation via the therapist, is a convenient and cost-effective treatment. This review focuses on the available literature regarding the effectiveness of incorporating VR within the treatment of various psychiatric disorders, with particular attention to exposure-based intervention for anxiety disorders. A systematic literature search was conducted in order to identify studies implementing VR-based treatment for anxiety or other psychiatric disorders. This article reviews the history of the development of VR-based technology and its use within psychiatric treatment, the empirical evidence for VR-based treatment, and the benefits for using VR for psychiatric research and treatment. It also presents recommendations for how to incorporate VR into psychiatric care and discusses future directions for VR-based treatment and clinical research.",2017.0,105.0,378.0,True,"{'url': 'https://europepmc.org/articles/pmc5421394?pdf=render', 'status': None}","{'volume': '25', 'pages': '103–113', 'name': 'Harvard Review of Psychiatry'}","{'bibtex': '@Article{Maples-Keller2017TheUO,\n author = {J. Maples-Keller and B. Bunnell and Sae-Jin Kim and B. Rothbaum},\n journal = {Harvard Review of Psychiatry},\n pages = {103–113},\n title = {The Use of Virtual Reality Technology in the Treatment of Anxiety and Other Psychiatric Disorders},\n volume = {25},\n year = {2017}\n}\n'}","[{'authorId': '1402540811', 'name': 'J. Maples-Keller'}, {'authorId': '38746727', 'name': 'B. Bunnell'}, {'authorId': '48388374', 'name': 'Sae-Jin Kim'}, {'authorId': '1831766', 'name': 'B. Rothbaum'}]"
1184,6264b14afa74004b3df433b3fc4818f20a2ea53f,Improving Adherence and Clinical Outcomes in Self-Guided Internet Treatment for Anxiety and Depression: Randomised Controlled Trial,"Background Depression and anxiety are common, disabling and chronic. Self-guided internet-delivered treatments are popular, but few people complete them. New strategies are required to realise their potential. Aims To evaluate the effect of automated emails on the effectiveness, safety, and acceptability of a new automated transdiagnostic self-guided internet-delivered treatment, the Wellbeing Course, for people with depression and anxiety. Method A randomised controlled trial was conducted through the website: www.ecentreclinic.org. Two hundred and fifty seven people with elevated symptoms were randomly allocated to the 8 week course either with or without automated emails, or to a waitlist control group. Primary outcome measures were the Patient Health Questionnaire 9-Item (PHQ-9) and the Generalized Anxiety Disorder 7-Item (GAD-7). Results Participants in the treatment groups had lower PHQ-9 and GAD-7 scores at post-treatment than controls. Automated emails increased rates of course completion (58% vs. 35%), and improved outcomes in a subsample with elevated symptoms. Conclusions The new self-guided course was beneficial, and automated emails facilitated outcomes. Further attention to strategies that facilitate adherence, learning, and safety will help realise the potential of self-guided interventions. Trial Registration Australian and New Zealand Clinical Trials Registry ACTRN12610001058066",2013.0,47.0,321.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0062873&type=printable', 'status': None}","{'volume': '8', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Titov2013ImprovingAA,\n author = {N. Titov and B. Dear and L. Johnston and Carolyn N. Lorian and Judy B Zou and Bethany M. Wootton and J. Spence and P. McEvoy and R. Rapee},\n journal = {PLoS ONE},\n title = {Improving Adherence and Clinical Outcomes in Self-Guided Internet Treatment for Anxiety and Depression: Randomised Controlled Trial},\n volume = {8},\n year = {2013}\n}\n'}","[{'authorId': '145079825', 'name': 'N. Titov'}, {'authorId': '5324295', 'name': 'B. Dear'}, {'authorId': '34979734', 'name': 'L. Johnston'}, {'authorId': '6221031', 'name': 'Carolyn N. Lorian'}, {'authorId': '6926546', 'name': 'Judy B Zou'}, {'authorId': '5482416', 'name': 'Bethany M. Wootton'}, {'authorId': '48031332', 'name': 'J. Spence'}, {'authorId': '3183309', 'name': 'P. McEvoy'}, {'authorId': '2915388', 'name': 'R. Rapee'}]"
1185,626bff3ed49434d09b03495dbd687ed74ca831db,Augmented reality as multimedia: the case for situated vocabulary learning,,2016.0,74.0,164.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1186%2Fs41039-016-0028-2.pdf', 'status': None}","{'volume': '11', 'name': 'Research and Practice in Technology Enhanced Learning'}","{'bibtex': '@Article{Santos2016AugmentedRA,\n author = {M. Santos and Arno in Wolde Lübke and Takafumi Taketomi and Goshiro Yamamoto and M. Rodrigo and C. Sandor and H. Kato},\n journal = {Research and Practice in Technology Enhanced Learning},\n title = {Augmented reality as multimedia: the case for situated vocabulary learning},\n volume = {11},\n year = {2016}\n}\n'}","[{'authorId': '2209528801', 'name': 'M. Santos'}, {'authorId': '2407518', 'name': 'Arno in Wolde Lübke'}, {'authorId': '35619125', 'name': 'Takafumi Taketomi'}, {'authorId': '4907124', 'name': 'Goshiro Yamamoto'}, {'authorId': '34880158', 'name': 'M. Rodrigo'}, {'authorId': '1806543', 'name': 'C. Sandor'}, {'authorId': '2262728792', 'name': 'H. Kato'}]"
1186,6278918bed5c1ee956546476d1e8a5d193430738,Review on Stimuli Presentation for Affect Analysis Based on EEG,"This work presents a comprehensive review on stimuli presentation, which is an important stage of any emotion elicitation experiment in affect analysis. Due to lack of standard guidelines, the researchers employ their self-devised methods which are not always sufficiently informative — making this area very inconsistent and ambiguous. In addition, an ample study about this stage including how to select, design and present the stimuli has not been reported properly earlier. In this purpose, an inclusive study has been conducted aiming to summarize various aspects of stimuli presentation including type of stimuli, available database, presentation tools, subjective measures, ethical issues and so on. Certainly, among several methods of emotion recognition (e.g., facial expression, speech, gesture and physiological signal), the EEG based emotion recognition works have been considered here due to availability of sufficient number of works, reliability and well-established technology. In total, 137 peer reviewed articles have been studied and the results show that about 83% of emotion elicitations have been performed by employing visual stimuli (mostly pictures and video). Therefore, presentation of visual stimuli has been explored with great emphasis covering laboratory setup, presentation timing, subjective issues, and ethical issues. Finally, an extensive recommendations regarding stimuli presentation has been provided which could guide to conduct the emotion elicitation experiments effectively.",2020.0,192.0,17.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09036897.pdf', 'status': None}","{'volume': '8', 'pages': '51991-52009', 'name': 'IEEE Access'}","{'bibtex': '@Article{Sarma2020ReviewOS,\n author = {Parthana Sarma and S. Barma},\n journal = {IEEE Access},\n pages = {51991-52009},\n title = {Review on Stimuli Presentation for Affect Analysis Based on EEG},\n volume = {8},\n year = {2020}\n}\n'}","[{'authorId': '1491241655', 'name': 'Parthana Sarma'}, {'authorId': '1776385', 'name': 'S. Barma'}]"
1187,6294651c71329b9379642a8b3b268c7b9ed3fe49,Media Equation Revisited: Do Users Show Polite Reactions towards an Embodied Agent?,,2009.0,14.0,77.0,False,,{'pages': '159-165'},"{'bibtex': '@Inproceedings{Hoffmann2009MediaER,\n author = {Laura Hoffmann and N. Krämer and Anh Lam-chi and S. Kopp},\n pages = {159-165},\n title = {Media Equation Revisited: Do Users Show Polite Reactions towards an Embodied Agent?},\n year = {2009}\n}\n'}","[{'authorId': '3689632', 'name': 'Laura Hoffmann'}, {'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '1422324403', 'name': 'Anh Lam-chi'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
1189,629ddee7f9b50eaed0fa6e866b134d1102d6451e,Integrating Models of Personality and Emotions into Lifelike Characters,,1999.0,31.0,251.0,True,"{'url': 'http://www.cs.bham.ac.uk/research/projects/cogaff/allen-thesis/Papers/Siena.pdf', 'status': None}",{'pages': '150-165'},"{'bibtex': '@Inproceedings{André1999IntegratingMO,\n author = {E. André and Martin Klesen and Patrick Gebhard and S. Allen and T. Rist},\n pages = {150-165},\n title = {Integrating Models of Personality and Emotions into Lifelike Characters},\n year = {1999}\n}\n'}","[{'authorId': '1742930', 'name': 'E. André'}, {'authorId': '2922093', 'name': 'Martin Klesen'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '152915261', 'name': 'S. Allen'}, {'authorId': '144984483', 'name': 'T. Rist'}]"
1191,62b0675332b18db814785656ac1c3fda10fd2294,A Review of Evaluation Practices of Gesture Generation in Embodied Conversational Agents,"Embodied conversational agents (ECAs) are often designed to produce nonverbal behavior to complement or enhance their verbal communication. One such form of the nonverbal behavior is co-speech gesturing, which involves movements that the agent makes with its arms and hands that are paired with verbal communication. Co-speech gestures for ECAs can be created using different generation methods, divided into rule-based and data-driven processes, with the latter, gaining traction because of the increasing interest from the applied machine learning community. However, reports on gesture generation methods use a variety of evaluation measures, which hinders comparison. To address this, we present a systematic review on co-speech gesture generation methods for iconic, metaphoric, deictic, and beat gestures, including reported evaluation methods. We review 22 studies that have an ECA with a human-like upper body that uses co-speech gesturing in social human-agent interaction. This includes studies that use human participants to evaluate performance. We found most studies use a within-subject design and rely on a form of subjective evaluation, but without a systematic approach. We argue that the field requires more rigorous and uniform tools for co-speech gesture evaluation, and formulate recommendations for empirical evaluation, including standardized phrases and example scenarios to help systematically test generative models across studies. Furthermore, we also propose a checklist that can be used to report relevant information for the evaluation of generative models, as well as to evaluate co-speech gesture use.",2021.0,98.0,36.0,True,"{'url': 'https://biblio.ugent.be/publication/8743014/file/8743015.pdf', 'status': None}","{'volume': '52', 'pages': '379-389', 'name': 'IEEE Transactions on Human-Machine Systems'}","{'bibtex': '@Article{Wolfert2021ARO,\n author = {Pieter Wolfert and Nicole L. Robinson and Tony Belpaeme},\n journal = {IEEE Transactions on Human-Machine Systems},\n pages = {379-389},\n title = {A Review of Evaluation Practices of Gesture Generation in Embodied Conversational Agents},\n volume = {52},\n year = {2021}\n}\n'}","[{'authorId': '88728223', 'name': 'Pieter Wolfert'}, {'authorId': '49257924', 'name': 'Nicole L. Robinson'}, {'authorId': '2301161', 'name': 'Tony Belpaeme'}]"
1192,62d28f2dbfb7f042bf5edfc640274b9e78ecb159,Perceived Emotional Intelligence in Virtual Agents,"In March 2016, several online news media reported on the inadequate emotional capabilities of interactive virtual assistants. While significant progress has been made in the general intelligence and functionality of virtual agents (VA), the emotional intelligent (EI) VA has yet been thoroughly explored. We examine user's perception of EI of virtual agents through Zara The Supergirl, a virtual agent that conducts question and answering type of conversational testing and counseling online. The results show that overall users perceive an emotion-expressing VA (EEVA) to be more EI than a non-emotion-expressing VA (NEEVA). However, simple affective expression may not be sufficient enough for EEVA to be perceived as fully EI.",2017.0,22.0,35.0,True,"{'url': 'https://repository.hkust.edu.hk/ir/bitstream/1783.1-84954/1/84954.pdf', 'status': None}",{'name': 'Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems'},"{'bibtex': '@Article{Yang2017PerceivedEI,\n author = {Yang Yang and Xiaojuan Ma and Pascale Fung},\n journal = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},\n title = {Perceived Emotional Intelligence in Virtual Agents},\n year = {2017}\n}\n'}","[{'authorId': '2152916959', 'name': 'Yang Yang'}, {'authorId': '3230330', 'name': 'Xiaojuan Ma'}, {'authorId': '1683412', 'name': 'Pascale Fung'}]"
1193,6310a969014792d394dea3b25b7155362d1c8765,Virtual faces as a tool to study emotion recognition deficits in schizophrenia,,2010.0,43.0,49.0,True,"{'url': 'https://www.zora.uzh.ch/id/eprint/39677/21/Dyck_PsychiatryRes_2010V.pdf', 'status': None}","{'volume': '179', 'pages': '247-252', 'name': 'Psychiatry Research'}","{'bibtex': '@Article{Dyck2010VirtualFA,\n author = {M. Dyck and Maren Winbeck and Susanne Leiberg and Yuhan Chen and K. Mathiak},\n journal = {Psychiatry Research},\n pages = {247-252},\n title = {Virtual faces as a tool to study emotion recognition deficits in schizophrenia},\n volume = {179},\n year = {2010}\n}\n'}","[{'authorId': '3108830', 'name': 'M. Dyck'}, {'authorId': '3660635', 'name': 'Maren Winbeck'}, {'authorId': '2178712', 'name': 'Susanne Leiberg'}, {'authorId': '2115868005', 'name': 'Yuhan Chen'}, {'authorId': '2448724', 'name': 'K. Mathiak'}]"
1194,633706c5f4b4eedac8e54b2276a15f655ee07546,iCat: an affective game buddy based on anticipatory mechanisms,"In this paper, we study the role of emotions and expressive behaviour in socially interactive characters employed in educational games. More specifically, on how we can use such emotional behaviour to help users to better understand the game state. An emotion model for these characters, which is mainly influenced by the current state of the game and is based on the emotivector anticipatory mechanism, was developed. We implemented the model in a social robot named iCat, using chess as the game scenario. The results of a preliminary evaluation suggested that the emotional behaviour embedded in the character indeed helped the users to have a better perception of the game.",2008.0,25.0,79.0,False,,{'pages': '1229-1232'},"{'bibtex': '@Inproceedings{Leite2008iCatAA,\n author = {Iolanda Leite and C. Martinho and André Pereira and Ana Paiva},\n pages = {1229-1232},\n title = {iCat: an affective game buddy based on anticipatory mechanisms},\n year = {2008}\n}\n'}","[{'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '145813496', 'name': 'C. Martinho'}, {'authorId': '11845717', 'name': 'André Pereira'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1195,63522d52d15a9d8e1b6e57148166566e90d30e50,Student motivation and engagement in maker activities under the lens of the Activity Theory: a case study in a primary school,,2023.0,46.0,4.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s40692-023-00258-y.pdf', 'status': None}","{'volume': '', 'pages': '1-19', 'name': 'Journal of Computers in Education'}","{'bibtex': '@Article{Nikou2023StudentMA,\n author = {S. Nikou},\n journal = {Journal of Computers in Education},\n pages = {1-19},\n title = {Student motivation and engagement in maker activities under the lens of the Activity Theory: a case study in a primary school},\n year = {2023}\n}\n'}","[{'authorId': '1786903', 'name': 'S. Nikou'}]"
1196,6391e61329c4923ed307bb411203dd6986a72735,Emotion-Focused Therapy: Coaching Clients to Work Through Their Feelings,"This handbook offers therapists an approach to helping clients live in harmony with head and heart. Leslie Greenberg proposes that, rather than controlling or avoiding emotions, clients can learn from their own bodily reactions and begin to act sensibly on them. Expressing emotion in ways that are appropriate to context is a highly complex skill. Offering clinical wisdom, practical guidance and case illustration, the volume presents an empirically-supported model of training clients to attain emotional wisdom.",2002.0,128.0,839.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Greenberg2002EmotionFocusedTC,\n author = {L. Greenberg},\n title = {Emotion-Focused Therapy: Coaching Clients to Work Through Their Feelings},\n year = {2002}\n}\n'}","[{'authorId': '6539543', 'name': 'L. Greenberg'}]"
1197,63e605de8d98df2c8f94182f8ccfac73ad980a51,Implementation of an evolutionary control system based on artificial emotion,"Artificial emotion is essential to robotics study.Typical implementation of artificial emotion is briefly summarized in this paper.In order to better implement emotion-learning control mechanisms,a new control architecture based on artificial emotion is proposed.It incorporates an evolution-control system based on a Genetic Algorithm with a neural and an artificial emotion control system.The neural system receives environmental information and makes decisions.The results of decision-making are fed back to the emotion-learning model.The emotion-learning model produces emotional factors(hormones)based on inner and outer conditions of the robot,and these factors is used to regulate the neural system.In the final step,the memorization and behavior module of the neural system is exported to the genetic environment.This control architecture enhances learning and adaptive capacities of robots in a dynamic environment.Simulation was made to confirm the validity of the control architecture.",2008.0,0.0,2.0,False,,"{'volume': '', 'name': 'Caai Transactions on Intelligent Systems'}","{'bibtex': '@Article{Xiong2008ImplementationOA,\n author = {X. Xiong},\n journal = {Caai Transactions on Intelligent Systems},\n title = {Implementation of an evolutionary control system based on artificial emotion},\n year = {2008}\n}\n'}","[{'authorId': '121700059', 'name': 'X. Xiong'}]"
1198,642aff2564f82828f3af379bc3adfd4f78435f35,"Aging, executive control, and attention: a review of meta-analyses",,2002.0,36.0,678.0,False,,"{'volume': '26', 'pages': '849-857', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Verhaeghen2002AgingEC,\n author = {P. Verhaeghen and J. Cerella},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {849-857},\n title = {Aging, executive control, and attention: a review of meta-analyses},\n volume = {26},\n year = {2002}\n}\n'}","[{'authorId': '3368397', 'name': 'P. Verhaeghen'}, {'authorId': '2105494', 'name': 'J. Cerella'}]"
1199,64441a238d93fc38e7a27610c66f425b9cace422,The social motivation theory of autism,,2012.0,112.0,1542.0,True,"{'url': 'https://europepmc.org/articles/pmc3329932?pdf=render', 'status': None}","{'volume': '16', 'pages': '231-239', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Chevallier2012TheSM,\n author = {C. Chevallier and G. Kohls and V. Troiani and E. Brodkin and R. Schultz},\n journal = {Trends in Cognitive Sciences},\n pages = {231-239},\n title = {The social motivation theory of autism},\n volume = {16},\n year = {2012}\n}\n'}","[{'authorId': '144629783', 'name': 'C. Chevallier'}, {'authorId': '47879364', 'name': 'G. Kohls'}, {'authorId': '2562268', 'name': 'V. Troiani'}, {'authorId': '6588720', 'name': 'E. Brodkin'}, {'authorId': '145157155', 'name': 'R. Schultz'}]"
1200,6478bfd55fb24619c38e62771e04795243b1c38f,Cross-lagged panel correlation: A test for spuriousness.,"Cross-lagged panel correlation is a method for testing spuriousness by comparing cross-lagged correlations. True experiments control for spuriousness by random assignment, but random assignment limits true experimental studies to independent variables that can be manipulated. Like any statistical method, cross-lagged analysis is based on a set of assumptions: synchronicity and stationarity. Different forms of stationarity have different consequences for both the changes in the synchronous correlations over time and the difference between cross-lags. Homogeneous stability is a necessary assumption in the identification of both the source and direction of a causal effect. Cross-lagged analysis is a low-power test. It is better adapted than either multiple regression or factor analysis for many questions in panel studies. Multiple regression must assume no errors of measurement in the independent variables and no correlated errors, while factor analysis must specify a particular factor structure. Two extended examples of cross-lagged analysis are discussed with special emphasis placed on the issue of stationarity and the estimation of reliability ratios.",1975.0,36.0,704.0,False,,"{'volume': '82', 'pages': '887-903', 'name': 'Psychological Bulletin'}","{'bibtex': '@Article{Kenny1975CrosslaggedPC,\n author = {D. Kenny},\n journal = {Psychological Bulletin},\n pages = {887-903},\n title = {Cross-lagged panel correlation: A test for spuriousness.},\n volume = {82},\n year = {1975}\n}\n'}","[{'authorId': '2060895', 'name': 'D. Kenny'}]"
1201,64878f1bf384daa26346840136b0215daf72c205,Steve: an animated pedagogical agent for procedural training in virtual environments,"Virtual reality can broaden the types of interaction between students and computer tutors. As in conventional simulation-based training, the computer can watch students practice tasks, responding to questions and offering advice. However, immersive virtual environments also allow the computer tutor to inhabit the virtual world with the student. Unlike previous, disembodied computer tutors, such a ""pedagogical agent"" can ""physically"" collaborate with students, enabling new types of interaction. To illustrate the possibilities, this paper describes Steve, a pedagogical agent for virtual environments that helps students learn procedural tasks. After providing an overview of Steve's capabilities, the paper focuses on the benefits and challenges of graphically representing Steve in the virtual environment.",1997.0,21.0,241.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/272874.272877', 'status': None}","{'volume': '8', 'pages': '16-21', 'name': 'SIGART Bull.'}","{'bibtex': '@Article{Johnson1997SteveAA,\n author = {W. Johnson and J. Rickel},\n journal = {SIGART Bull.},\n pages = {16-21},\n title = {Steve: an animated pedagogical agent for procedural training in virtual environments},\n volume = {8},\n year = {1997}\n}\n'}","[{'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '2019292', 'name': 'J. Rickel'}]"
1202,648c572b96af0acebd85e11a8a4320a9a5eb7709,An overview of Kansei engineering: a proposal of Kansei informatics toward realising safety and pleasantness of individuals in information network society,"Kansei engineering is the newly proposed engineering discipline having a novel and unique goal. While its aim has been considered, from the beginning, to construct methodology and technology capable of providing industrial products and services reflecting user's personal preference/requirement and being evaluated by satisfaction of users, its role is now growing up to consider a new leaf of more fundamental technical issues on Kansei informatics or human-computer interactions toward realising safety and pleasantness of individuals, which will be considered to be a most important fundamental problem in the coming information network society. In this paper, we try to describe an overview of Kansei engineering referring to biometrics. The contents include the background, objectives, present status, and present technical topics of Kansei engineering, where we also introduce concrete examples of developing researches. Future developments are also discussed.",2008.0,13.0,15.0,False,,"{'volume': '1', 'pages': '3-19', 'name': 'Int. J. Biom.'}","{'bibtex': '@Article{Nagashima2008AnOO,\n author = {T. Nagashima and Hidenori Tanaka and T. Uozumi},\n journal = {Int. J. Biom.},\n pages = {3-19},\n title = {An overview of Kansei engineering: a proposal of Kansei informatics toward realising safety and pleasantness of individuals in information network society},\n volume = {1},\n year = {2008}\n}\n'}","[{'authorId': '3163017', 'name': 'T. Nagashima'}, {'authorId': '2115247635', 'name': 'Hidenori Tanaka'}, {'authorId': '2679920', 'name': 'T. Uozumi'}]"
1203,64911fe0724af0029af2c6e4b25e1be67b9fc69b,Happy face advantage in recognizing facial expressions,,1995.0,27.0,203.0,False,,"{'volume': '89', 'pages': '149-163', 'name': 'Acta Psychologica'}","{'bibtex': '@Article{Kirita1995HappyFA,\n author = {Takahiro Kirita and M. Endo},\n journal = {Acta Psychologica},\n pages = {149-163},\n title = {Happy face advantage in recognizing facial expressions},\n volume = {89},\n year = {1995}\n}\n'}","[{'authorId': '70514741', 'name': 'Takahiro Kirita'}, {'authorId': '2020075997', 'name': 'M. Endo'}]"
1204,649cedc3241651d318a6caa74b5002e518bf5a2a,Driver Emotion Recognition for Intelligent Vehicles,"Driving can occupy a large portion of daily life and often can elicit negative emotional states like anger or stress, which can significantly impact road safety and long-term human health. In recent decades, the arrival of new tools to help recognize human affect has inspired increasing interest in how to develop emotion-aware systems for cars. To help researchers make needed advances in this area, this article provides a comprehensive literature survey of work addressing the problem of human emotion recognition in an automotive context. We systematically review the literature back to 2002 and identify 63 peer-review published articles on this topic. We overview each study’s methodology to measure and recognize emotions in the context of driving. Across the literature, we find a strong preference toward studying emotional states associated with high arousal and negative valence, monitoring the different states with cardiac, electrodermal activity, and speech signals, and using supervised machine learning to automatically infer the underlying human affective states. This article summarizes the existing work together with publicly available resources (e.g., datasets and tools) to help new researchers get started in this field. We also identify new research opportunities to help advance progress for improving driver emotion recognition.",2020.0,144.0,81.0,True,"{'url': 'https://dspace.mit.edu/bitstream/1721.1/146201/1/3388790.pdf', 'status': None}","{'volume': '53', 'pages': '1 - 30', 'name': 'ACM Computing Surveys (CSUR)'}","{'bibtex': '@Article{Zepf2020DriverER,\n author = {Sebastian Zepf and J. Hernández and Alexander Schmitt and W. Minker and Rosalind W. Picard},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 30},\n title = {Driver Emotion Recognition for Intelligent Vehicles},\n volume = {53},\n year = {2020}\n}\n'}","[{'authorId': '92344344', 'name': 'Sebastian Zepf'}, {'authorId': '2107841806', 'name': 'J. Hernández'}, {'authorId': '145187655', 'name': 'Alexander Schmitt'}, {'authorId': '1720942', 'name': 'W. Minker'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
1205,64d033b8939bb5f7235af10d29c8690bb19dcf98,ANGELICA : choice of output modality in an embodied agent,"The ANGELICA project addresses the problem of modality choice in information presentation by embodied, humanlike agents. The output modalities available to such agents include both language and various nonverbal signals such as pointing and gesturing. For each piece of information to be presented by the agent it must be decided whether it should be expressed using language, a nonverbal signal, or both. In the ANGELICA project a model of the different factors influencing this choice will be developed and integrated in a natural language generation system. The application domain is the presentation of route descriptions by an embodied agent in a 3D environment. Evaluation and testing form an integral part of the project. In particular, we will investigate the effect of different modality choices on the effectiveness and naturalness of the generated presentations and on the user's perception of the agent's personality.",2001.0,35.0,15.0,False,,"{'volume': '', 'pages': '89-93', 'name': ''}","{'bibtex': '@Inproceedings{Theune2001ANGELICAC,\n author = {M. Theune},\n pages = {89-93},\n title = {ANGELICA : choice of output modality in an embodied agent},\n year = {2001}\n}\n'}","[{'authorId': '1742430', 'name': 'M. Theune'}]"
1206,64fe14cb57889f95b770b088dc846671ea644769,Recognising spontaneous facial micro-expressions,"Facial micro-expressions are rapid involuntary facial expressions which reveal suppressed affect. To the best knowledge of the authors, there is no previous work that successfully recognises spontaneous facial micro-expressions. In this paper we show how a temporal interpolation model together with the first comprehensive spontaneous micro-expression corpus enable us to accurately recognise these very short expressions. We designed an induced emotion suppression experiment to collect the new corpus using a high-speed camera. The system is the first to recognise spontaneous facial micro-expressions and achieves very promising results that compare favourably with the human micro-expression detection accuracy.",2011.0,21.0,342.0,True,"{'url': 'http://tomas.pfister.fi/files/pfister11microexpressions.pdf', 'status': None}","{'pages': '1449-1456', 'name': '2011 International Conference on Computer Vision'}","{'bibtex': '@Article{Pfister2011RecognisingSF,\n author = {Tomas Pfister and Xiaobai Li and Guoying Zhao and M. Pietikäinen},\n journal = {2011 International Conference on Computer Vision},\n pages = {1449-1456},\n title = {Recognising spontaneous facial micro-expressions},\n year = {2011}\n}\n'}","[{'authorId': '1945962', 'name': 'Tomas Pfister'}, {'authorId': '1502872895', 'name': 'Xiaobai Li'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '145962204', 'name': 'M. Pietikäinen'}]"
1207,651879d699513e602ca03f2e0226556797437730,A Review of Pathfinding in Game Development,"Pathfinding is one important method in many studies or works that consists of autonomous movement, such as robot, game, transportation, and so on. Pathfinding aims to find the most efficient route for the related autonomous entity. To date, there are many algorithms regarding to the pathfinding. Especially, there are four well-known pathfinding algorithms: A*, Theta*, Dijkstra, and Breadth First Search (BFS). Due to this circumstance, this work aims to observe and review these four well-known algorithms deeper. The discussion consists of the conceptual model or framework, the formalization, and the implementation. The result shows that these algorithms have been implemented in many game so that they are promising to be used in the future game development.",2022.0,32.0,3.0,True,"{'url': 'https://journals.telkomuniversity.ac.id/cepat/article/download/4863/1828', 'status': None}","{'name': '[CEPAT] Journal of Computer Engineering: Progress, Application and Technology'}","{'bibtex': '@Article{Pardede2022ARO,\n author = {Sara Lutami Pardede and Fadel Ramli Athallah and Yahya Nur Huda and Fikri Zain},\n journal = {[CEPAT] Journal of Computer Engineering: Progress, Application and Technology},\n title = {A Review of Pathfinding in Game Development},\n year = {2022}\n}\n'}","[{'authorId': '2180940104', 'name': 'Sara Lutami Pardede'}, {'authorId': '2180940270', 'name': 'Fadel Ramli Athallah'}, {'authorId': '2180941972', 'name': 'Yahya Nur Huda'}, {'authorId': '2180940376', 'name': 'Fikri Zain'}]"
1208,6549a9d851a16f356d64ebde9ab7743d7639d67a,"Virtual human as a new diagnostic tool, a proof of concept study in the field of major depressive disorders",,2017.0,39.0,99.0,True,"{'url': 'https://www.nature.com/articles/srep42656.pdf', 'status': None}","{'volume': '7', 'name': 'Scientific Reports'}","{'bibtex': '@Article{Philip2017VirtualHA,\n author = {P. Philip and J. Micoulaud-Franchi and P. Sagaspe and E. D. Sevin and J. Olive and S. Bioulac and A. Sauteraud},\n journal = {Scientific Reports},\n title = {Virtual human as a new diagnostic tool, a proof of concept study in the field of major depressive disorders},\n volume = {7},\n year = {2017}\n}\n'}","[{'authorId': '145248978', 'name': 'P. Philip'}, {'authorId': '1398530312', 'name': 'J. Micoulaud-Franchi'}, {'authorId': '1813095', 'name': 'P. Sagaspe'}, {'authorId': '1761859', 'name': 'E. D. Sevin'}, {'authorId': '2074620344', 'name': 'J. Olive'}, {'authorId': '2759597', 'name': 'S. Bioulac'}, {'authorId': '48763838', 'name': 'A. Sauteraud'}]"
1209,6558263fccba68d31ab37cc98034d470a329e174,A National Portrait of Chronic Absenteeism in the Early Grades,"This brief is the first in a series examining the causes and consequences of chronic absenteeism during the early school years, based on analyses of data from the Early Childhood Longitudinal Study, Kinder-educational consequences of child poverty and issues of respect for diversity and social inclusion in early education.",2007.0,3.0,117.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Romero2007ANP,\n author = {Mariajosé Romero and Young-Sun Lee},\n title = {A National Portrait of Chronic Absenteeism in the Early Grades},\n year = {2007}\n}\n'}","[{'authorId': '83158220', 'name': 'Mariajosé Romero'}, {'authorId': '2145429965', 'name': 'Young-Sun Lee'}]"
1210,657112d58671b28622153a1f37f2440303a41a0b,How empathic traits affect interactions with virtual agents,"Nowadays, virtual technology with embedded virtual agents is increasingly present in everyday life. Therefore, understanding the characteristics of psychological experience in social interaction with virtual agents can be useful for theoretical and application purposes. Here, we aim to understand whether individual differences in empathy can influence social interaction with virtual agents. To this end, we designed a correlational study comparing individual propensity towards empathic traits and the ability to take the perspective of a virtual agent (VA) to understand whether and how they are associated. In an Immersive Virtual Reality (IVR) scenario, participants had to locate a glass according to the perspective of a virtual agent. They were seated behind a circular virtual table around which, in various positions closer and further away, VAs with a glass placed in front of them could appear. Participants had to decide whether the glass was to the right or left of the VA’s body midline. The results showed an association between some components of empathy and localization time: the higher the tendency to identify with a fictional character, the faster the participants were to locate the glass in all positions of the virtual agents around the table. Likewise, the higher the tendency to experience feelings of empathy, the faster they were in locating only when the VA was close to the observer. These preliminary results suggest that individual differences in empathy and the location of virtual agents help define how people experience virtual social interactions.",2021.0,39.0,1.0,False,,,"{'bibtex': '@Inproceedings{Sbordone2021HowET,\n author = {F. L. Sbordone and Renato Orti and Francesco Ruotolo and T. Iachini and G. Ruggiero},\n title = {How empathic traits affect interactions with virtual agents},\n year = {2021}\n}\n'}","[{'authorId': '1729446606', 'name': 'F. L. Sbordone'}, {'authorId': '2005416754', 'name': 'Renato Orti'}, {'authorId': '2705813', 'name': 'Francesco Ruotolo'}, {'authorId': '1902889', 'name': 'T. Iachini'}, {'authorId': '3352149', 'name': 'G. Ruggiero'}]"
1211,6581b0470b1ce3ab4329c595ff0b3aaff85eba5a,Three Systems of Insular Functional Connectivity Identified with Cluster Analysis,"Despite much research on the function of the insular cortex, few studies have investigated functional subdivisions of the insula in humans. The present study used resting-state functional connectivity magnetic resonance imaging (MRI) to parcellate the human insular lobe based on clustering of functional connectivity patterns. Connectivity maps were computed for each voxel in the insula based on resting-state functional MRI (fMRI) data and segregated using cluster analysis. We identified 3 insular subregions with distinct patterns of connectivity: a posterior region, functionally connected with primary and secondary somatomotor cortices; a dorsal anterior to middle region, connected with dorsal anterior cingulate cortex, along with other regions of a previously described control network; and a ventral anterior region, primarily connected with pregenual anterior cingulate cortex. Applying these regions to a separate task data set, we found that dorsal and ventral anterior insula responded selectively to disgusting images, while posterior insula did not. These results demonstrate that clustering of connectivity patterns can be used to subdivide cerebral cortex into anatomically and functionally meaningful subregions; the insular regions identified here should be useful in future investigations on the function of the insula.",2010.0,84.0,611.0,True,"{'url': 'https://academic.oup.com/cercor/article-pdf/21/7/1498/22787671/bhq186.pdf', 'status': None}","{'volume': '21', 'pages': '1498 - 1506', 'name': 'Cerebral Cortex (New York, NY)'}","{'bibtex': '@Article{Deen2010ThreeSO,\n author = {Ben Deen and Naomi B. Pitskel and K. Pelphrey},\n journal = {Cerebral Cortex (New York, NY)},\n pages = {1498 - 1506},\n title = {Three Systems of Insular Functional Connectivity Identified with Cluster Analysis},\n volume = {21},\n year = {2010}\n}\n'}","[{'authorId': '2305032', 'name': 'Ben Deen'}, {'authorId': '2273865', 'name': 'Naomi B. Pitskel'}, {'authorId': '9765768', 'name': 'K. Pelphrey'}]"
1212,658dac82a4f292ecd7c631c6a61408db75f05d07,The Uncanny Valley,. The uncanny valley is a phenomenon first described in 1970 by Masahiro Mori. It characterizes the correlation between the degree of human likeness of e,2019.0,13.0,1891.0,False,,{'name': 'The Animation Studies Reader'},"{'bibtex': '@Article{Bode2019TheUV,\n author = {Lisa Bode},\n journal = {The Animation Studies Reader},\n title = {The Uncanny Valley},\n year = {2019}\n}\n'}","[{'authorId': '2249341176', 'name': 'Lisa Bode'}]"
1214,659408b243cec55de8d0a3bc51b81173007aa89b,R: A language and environment for statistical computing.,"Copyright (©) 1999–2012 R Foundation for Statistical Computing. Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies. Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one. Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions, except that this permission notice may be stated in a translation approved by the R Core Team.",2014.0,0.0,318791.0,False,,"{'volume': '1', 'name': 'MSOR connections'}","{'bibtex': '@Article{Team2014RAL,\n author = {R. Team},\n journal = {MSOR connections},\n title = {R: A language and environment for statistical computing.},\n volume = {1},\n year = {2014}\n}\n'}","[{'authorId': '68986511', 'name': 'R. Team'}]"
1216,65c9b2cdf9ba8ba5696170a82fb5465ff1c3d4ea,Furhat: A Back-Projected Human-Like Robot Head for Multiparty Human-Machine Interaction,,2011.0,25.0,247.0,False,,{'pages': '114-130'},"{'bibtex': '@Inproceedings{Moubayed2011FurhatAB,\n author = {S. Moubayed and J. Beskow and Gabriel Skantze and B. Granström},\n pages = {114-130},\n title = {Furhat: A Back-Projected Human-Like Robot Head for Multiparty Human-Machine Interaction},\n year = {2011}\n}\n'}","[{'authorId': '32201536', 'name': 'S. Moubayed'}, {'authorId': '1826819', 'name': 'J. Beskow'}, {'authorId': '1711959', 'name': 'Gabriel Skantze'}, {'authorId': '144966453', 'name': 'B. Granström'}]"
1217,65d8f6e5dd70d9930076cc9b14e68d1fc61473df,Literacy in virtual worlds,"Introducing new digital literacies into classroom settings is an important and challenging task, and one that is encouraged by both policy-makers and educators. This paper draws on a case study of a 3D virtual world which aimed to engage and motivate primary school children in an immersive and literacy-rich on-line experience. Planning decisions, early experimentation and the experience of avatar interaction are explored. Using field notes, in-world interviews and observations I analyse pupil and teacher perspectives on the use of digital literacy and its relationship to conventional classroom literacy routines, and use these to trace the potential and inherently disruptive nature of such work. The paper makes the case for a wider recognition of the role of technology in literacy and suggests that teachers need time for experimentation and professional development if they are to respond appropriately to new digital literacies in the classroom.",2009.0,39.0,180.0,False,,"{'volume': '32', 'pages': '38-56', 'name': 'Journal of Research in Reading'}","{'bibtex': '@Article{Merchant2009LiteracyIV,\n author = {Guy Merchant},\n journal = {Journal of Research in Reading},\n pages = {38-56},\n title = {Literacy in virtual worlds},\n volume = {32},\n year = {2009}\n}\n'}","[{'authorId': '2487507', 'name': 'Guy Merchant'}]"
1218,660ed33f065a45527a0d3d3641cba5f54752d479,Is eye contact the key to the social brain?,"Abstract Eye contact plays a critical role in many aspects of face processing, including the processing of smiles. We propose that this is achieved by a subcortical route, which is activated by eye contact and modulates the cortical areas involve in social cognition, including the processing of facial expression. This mechanism could be impaired in individuals with autism spectrum disorders.",2010.0,663.0,491.0,True,"{'url': 'http://doc.rero.ch/record/298782/files/S0140525X10001561.pdf', 'status': None}","{'volume': '33', 'pages': '458 - 459', 'name': 'Behavioral and Brain Sciences'}","{'bibtex': '@Article{Niedenthal2010IsEC,\n author = {P. Niedenthal and M. Mermillod and M. Maringer and U. Hess},\n journal = {Behavioral and Brain Sciences},\n pages = {458 - 459},\n title = {Is eye contact the key to the social brain?},\n volume = {33},\n year = {2010}\n}\n'}","[{'authorId': '1986858', 'name': 'P. Niedenthal'}, {'authorId': '2634712', 'name': 'M. Mermillod'}, {'authorId': '40152862', 'name': 'M. Maringer'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
1220,6623524f5b3538dd15c6b618ad00c670597ffbf5,Cognitive biases in emotional disorders: Information processing and social-cognitive perspectives: Series in Affective Science,,2003.0,0.0,71.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mineka2003CognitiveBI,\n author = {S. Mineka and Eshkol Rafaeli and Iftah Yovel},\n title = {Cognitive biases in emotional disorders: Information processing and social-cognitive perspectives: Series in Affective Science},\n year = {2003}\n}\n'}","[{'authorId': '5099321', 'name': 'S. Mineka'}, {'authorId': '5860536', 'name': 'Eshkol Rafaeli'}, {'authorId': '35189498', 'name': 'Iftah Yovel'}]"
1221,663bc6fbd59fbcf97a646de81d1419eddc79b66c,The Neuroscience of Psychotherapy: Healing the Social Brain,"In contrast to this view, recent theoretical advances in brain imaging have revealed that the brain is an organ continually built and re-built by one's experience. We are now beginning to learn that many forms of psychotherapy, developed in the absence of any scientific understanding of the brain, are supported by neuroscientific findings. In fact, it could be argued that to be an effective psychotherapist these days it is essential to have some basic understanding of neuroscience. Louis Cozolino's The Neuroscience of Psychotherapy, Second Edition is the perfect place to start. In a beautifully written and accessible synthesis, Cozolino illustrates how the brain's architecture is related to the problems, passions, and aspirations of human beings. As the book so elegantly argues, all forms of psychotherapy--from psychoanalysis to behavioral interventions--are successful to the extent to which they enhance change in relevant neural circuits. Beginning with an overview of the intersecting fields of neuroscience and psychotherapy, this book delves into the brain's inner workings, from basic neuronal building blocks to complex systems of memory, language, and the organization of experience. It continues by explaining the development and organization of the healthy brain and the unhealthy brain. Common problems such as anxiety, trauma, and codependency are discussed from a scientific and clinical perspective. Throughout the book, the science behind the brain's working is applied to day-to-day experience and clinical practice. Written for psychotherapists and others interested in the relationship between brain and behavior, this book encourages us to consider the brain when attempting to understand human development, mental illness, and psychological health. Fully and thoroughly updated with the many neuroscientific developments that have happened in the eight years since the publication of the first edition, this revision to the bestselling book belongs on the shelf of all practitioners.",2017.0,0.0,58.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cozolino2017TheNO,\n author = {L. Cozolino},\n title = {The Neuroscience of Psychotherapy: Healing the Social Brain},\n year = {2017}\n}\n'}","[{'authorId': '4571106', 'name': 'L. Cozolino'}]"
1222,6666021cdc311a1f6c05b1cb067891c0a69fdf54,Just follow the suit! Trust in human-robot interactions during card game playing,"Robots are currently being developed to enter our lives and interact with us in different tasks. For humans to be able to have a positive experience of interaction with such robots, they need to trust them to some degree. In this paper, we present the development and evaluation of a social robot that was created to play a card game with humans, playing the role of a partner and opponent. This type of activity is especially important, since our target group is elderly people - a population that often suffers from social isolation. Moreover, the card game scenario can lead to the development of interesting trust dynamics during the interaction, in which the human that partners with the robot needs to trust it in order to succeed and win the game. The design of the robot's behavior and game dynamics was inspired in previous user-centered design studies in which elderly people played the same game. Our evaluation results show that the levels of trust differ according to the previous knowledge that players have of their partners. Thus, humans seem to significantly increase their trust level towards a robot they already know, whilst maintaining the same level of trust in a human that they also previously knew. Henceforth, this paper shows that trust is a multifaceted construct that develops differently for humans and robots.",2016.0,23.0,50.0,True,"{'url': 'https://repositorio.iscte-iul.pt/bitstream/10071/23089/1/conferenceobject_42281.pdf', 'status': None}","{'pages': '507-512', 'name': '2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)'}","{'bibtex': '@Article{Correia2016JustFT,\n author = {Filipa Correia and Patrícia Alves-Oliveira and Nuno Maia and T. Ribeiro and Sofia Petisca and Francisco S. Melo and A. Paiva},\n journal = {2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {507-512},\n title = {Just follow the suit! Trust in human-robot interactions during card game playing},\n year = {2016}\n}\n'}","[{'authorId': '144106225', 'name': 'Filipa Correia'}, {'authorId': '1401670338', 'name': 'Patrícia Alves-Oliveira'}, {'authorId': '2073110332', 'name': 'Nuno Maia'}, {'authorId': '145856842', 'name': 'T. Ribeiro'}, {'authorId': '143702890', 'name': 'Sofia Petisca'}, {'authorId': '145125979', 'name': 'Francisco S. Melo'}, {'authorId': '115420343', 'name': 'A. Paiva'}]"
1223,66a78ea7d0240ffb80826eebc9360270ed637826,Eye Tracking Methodology: Theory and Practice,,2003.0,52.0,2372.0,True,,"{'pages': 'I-XVII, 1-251'}","{'bibtex': '@Inproceedings{Duchowski2003EyeTM,\n author = {A. Duchowski},\n pages = {I-XVII, 1-251},\n title = {Eye Tracking Methodology: Theory and Practice},\n year = {2003}\n}\n'}","[{'authorId': '2245673', 'name': 'A. Duchowski'}]"
1224,66ac496a44e8c80784b09b0db1d210d61178af9a,Expectations of Cooperation and Competition and Their Effects on Observers' Vicarious Emotional Responses,,1989.0,53.0,376.0,False,,"{'volume': '56', 'pages': '543-554', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': ""@Article{Lanzetta1989ExpectationsOC,\n author = {J. Lanzetta and B. Englis},\n journal = {Journal of Personality and Social Psychology},\n pages = {543-554},\n title = {Expectations of Cooperation and Competition and Their Effects on Observers' Vicarious Emotional Responses},\n volume = {56},\n year = {1989}\n}\n""}","[{'authorId': '6662654', 'name': 'J. Lanzetta'}, {'authorId': '1889669', 'name': 'B. Englis'}]"
1225,66d0f80aebfb8dbc6bbe7bd89eb63a86bff2db8c,Animated Pedagogical Agents: Face-to-Face Interaction in Interactive Learning Environments,"Recent years have witnessed the birth of a new paradigm for learning environments: animated pedagogical agents. These lifelike autonomous characters cohabit learning environments with students to create rich, face-to-face learning interactions. This opens up exciting new possibilities; for example, agents can demonstrate complex tasks, employ locomotion and gesture to focus students’ attention on the most salient aspect of the task at hand, and convey emotional responses to the tutorial situation. Animated pedagogical agents offer great promise for broadening the bandwidth of tutorial communication and increasing learning environments’ ability to engage and motivate students. This article sets forth the motivations behind animated pedagogical agents, describes the key capabilities they offer, and discusses the technical issues they raise. The discussion is illustrated with descriptions of a number of animated agents that represent the current state of the art. Abstract The potential of emotional interaction between human and computer has recently interested researchers in human–computer interaction. The instructional impact of this interaction in learning environments has not been established, however. This study examined the impact of emotion and gender of a pedagogical agent as a learning companion (PAL) on social judgments, interest, self-efficacy, and learning.",2014.0,1.0,35.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Varshney2014AnimatedPA,\n author = {Aanshi Varshney},\n title = {Animated Pedagogical Agents: Face-to-Face Interaction in Interactive Learning Environments},\n year = {2014}\n}\n'}","[{'authorId': '119388304', 'name': 'Aanshi Varshney'}]"
1226,66f7c96fc118a6adfe288c2af36af058404148c6,Modeling empathy: building a link between affective and cognitive processes,,2019.0,119.0,28.0,False,,"{'volume': '53', 'pages': '2983-3006', 'name': 'Artificial Intelligence Review'}","{'bibtex': '@Article{Yalçın2019ModelingEB,\n author = {Ö. Yalçın and S. DiPaola},\n journal = {Artificial Intelligence Review},\n pages = {2983-3006},\n title = {Modeling empathy: building a link between affective and cognitive processes},\n volume = {53},\n year = {2019}\n}\n'}","[{'authorId': '80264274', 'name': 'Ö. Yalçın'}, {'authorId': '1700040', 'name': 'S. DiPaola'}]"
1227,675bb798f0cf542c0e10687c39482a8ff7e3318a,SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text,"In this paper, we present the SemEval-2019 Task 3 - EmoContext: Contextual Emotion Detection in Text. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading “Why don’t you ever text me!” we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps. A training data set of 30160 dialogues, and two evaluation data sets, Test1 and Test2, containing 2755 and 5509 dialogues respectively were released to the participants. A total of 311 teams made submissions to this task. The final leader-board was evaluated on Test2 data set, and the highest ranked submission achieved 79.59 micro-averaged F1 score. Our analysis of systems submitted to the task indicate that Bi-directional LSTM was the most common choice of neural architecture used, and most of the systems had the best performance for the Sad emotion class, and the worst for the Happy emotion class.",2019.0,46.0,201.0,True,"{'url': 'https://www.aclweb.org/anthology/S19-2005.pdf', 'status': None}",{'pages': '39-48'},"{'bibtex': '@Inproceedings{Chatterjee2019SemEval2019T3,\n author = {Ankush Chatterjee and Kedhar Nath Narahari and Meghana Joshi and Puneet Agrawal},\n pages = {39-48},\n title = {SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text},\n year = {2019}\n}\n'}","[{'authorId': '2463157', 'name': 'Ankush Chatterjee'}, {'authorId': '34749306', 'name': 'Kedhar Nath Narahari'}, {'authorId': '1651892966', 'name': 'Meghana Joshi'}, {'authorId': '2067432800', 'name': 'Puneet Agrawal'}]"
1228,675bc093e56a053e001c8bd3e2bb8d9c75b335c6,Mother-infant synchrony and the development of moral orientation in childhood and adolescence: direct and indirect mechanisms of developmental continuity.,"Links between the temporal parameters of mother-infant synchrony and moral orientation in adolescence were examined in 31 children monitored from 3 months to 13 years. At 3 and 9 months, mother's and infant's affective states during face-to-face play were microcoded and synchrony was assessed with time-series analysis. Verbal IQ, behavior problems, child self-regulated compliance, and maternal warm control discipline were examined at 2, 4, and 6 years. Moral cognition and dialogical empathy were evaluated at 6 and 13 years. Three mechanisms of continuity were proposed: continuity in small steps, continuity through a mediating variable, and direct continuity. Mother-infant synchrony across the 1st year, indexed by the lagged associations between maternal and infant affective involvement, predicted verbal IQ and behavior adaptation, which in turn predicted moral cognition. Child self-regulated compliance across the toddler and preschool years mediated the relations between the lead-lag structure of early interactions and the adolescent's dialogical skills. Direct associations were found between mother-infant synchrony and the capacity for empathy in adolescence. Participating in a synchronous exchange may sensitize infants to the emotional resonance and empathy underlying human relationships across the life span.",2007.0,99.0,178.0,False,,"{'volume': '77 4', 'pages': '\n          582-97\n        ', 'name': 'The American journal of orthopsychiatry'}","{'bibtex': '@Article{Feldman2007MotherinfantSA,\n author = {R. Feldman},\n journal = {The American journal of orthopsychiatry},\n pages = {\n          582-97\n        },\n title = {Mother-infant synchrony and the development of moral orientation in childhood and adolescence: direct and indirect mechanisms of developmental continuity.},\n volume = {77 4},\n year = {2007}\n}\n'}","[{'authorId': '144708274', 'name': 'R. Feldman'}]"
1229,67679bdaec5f6db517df1c52d66c912a7859c93d,Comparing Interpersonal Interactions with a Virtual Human to Those with a Real Human,"This paper provides key insights into the construction and evaluation of interpersonal simulators¿systems that enable interpersonal interaction with virtual humans. Using an interpersonal simulator, two studies were conducted that compare interactions with a virtual human to interactions with a similar real human. The specific interpersonal scenario employed was that of a medical interview. Medical students interacted with either a virtual human simulating appendicitis or a real human pretending to have the same symptoms. In Study I (n = 24), medical students elicited the same information from the virtual and real human, indicating that the content of the virtual and real interactions were similar. However, participants appeared less engaged and insincere with the virtual human. These behavioral differences likely stemmed from the virtual human's limited expressive behavior. Study II (n = 58) explored participant behavior using new measures. Nonverbal behavior appeared to communicate lower interest and a poorer attitude toward the virtual human. Some subjective measures of participant behavior yielded contradictory results, highlighting the need for objective, physically-based measures in future studies.",2007.0,60.0,96.0,False,,"{'volume': '13', 'pages': '443-457', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Raij2007ComparingII,\n author = {Andrew B. Raij and K. Johnsen and R. Dickerson and Benjamin C. Lok and Marc S. Cohen and M. Duerson and Rebecca R. Pauly and Amy O. Stevens and P. Wagner and D. Lind},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {443-457},\n title = {Comparing Interpersonal Interactions with a Virtual Human to Those with a Real Human},\n volume = {13},\n year = {2007}\n}\n'}","[{'authorId': '2223702744', 'name': 'Andrew B. Raij'}, {'authorId': '2664323', 'name': 'K. Johnsen'}, {'authorId': '153868524', 'name': 'R. Dickerson'}, {'authorId': '1708157', 'name': 'Benjamin C. Lok'}, {'authorId': '1400248193', 'name': 'Marc S. Cohen'}, {'authorId': '3107112', 'name': 'M. Duerson'}, {'authorId': '12139877', 'name': 'Rebecca R. Pauly'}, {'authorId': '2326383', 'name': 'Amy O. Stevens'}, {'authorId': '23806137', 'name': 'P. Wagner'}, {'authorId': '144110672', 'name': 'D. Lind'}]"
1230,6778368df92310ff447365f2145d50282334e93f,Domain Adaptation Techniques for EEG-Based Emotion Recognition: A Comparative Study on Two Public Datasets,"Affective brain–computer interface (aBCI) introduces personal affective factors to human–computer interaction. The state-of-the-art aBCI tailors its classifier to each individual user to achieve accurate emotion classification. A subject-independent classifier that is trained on pooled data from multiple subjects generally leads to inferior accuracy, due to the fact that electroencephalography patterns vary from subject to subject. Transfer learning or domain adaptation techniques have been leveraged to tackle this problem. Existing studies have reported successful applications of domain adaptation techniques on SEED dataset. However, little is known about the effectiveness of the domain adaptation techniques on other affective datasets or in a cross-dataset application. In this paper, we focus on a comparative study on several state-of-the-art domain adaptation techniques on two datasets: 1) DEAP and 2) SEED. We demonstrate that domain adaptation techniques can improve the classification accuracy on both datasets, but not so effective on DEAP as on SEED. Then, we explore the efficacy of domain adaptation in a cross-dataset setting when the data are collected under different environments using different devices and experimental protocols. Here, we propose to apply domain adaptation to reduce the intersubject variance as well as technical discrepancies between datasets, and then train a subject-independent classifier on one dataset and test on the other. Experiment results show that using domain adaptation technique in a transductive adaptation setting can improve the accuracy significantly by 7.25%–13.40% compared to the baseline accuracy where no domain adaptation technique is used.",2019.0,36.0,196.0,True,"{'url': 'https://dr.ntu.edu.sg/bitstream/10356/144553/2/Domain%20Adaptation%20Techniques%20for%20EEG%20based%20Emotion%20Recognition%20A%20Comparative%20Study%20on%20Two%20Public%20Datasets.pdf', 'status': None}","{'volume': '11', 'pages': '85-94', 'name': 'IEEE Transactions on Cognitive and Developmental Systems'}","{'bibtex': '@Article{Lan2019DomainAT,\n author = {Zirui Lan and O. Sourina and Lipo Wang and Reinhold Scherer and G. Müller-Putz},\n journal = {IEEE Transactions on Cognitive and Developmental Systems},\n pages = {85-94},\n title = {Domain Adaptation Techniques for EEG-Based Emotion Recognition: A Comparative Study on Two Public Datasets},\n volume = {11},\n year = {2019}\n}\n'}","[{'authorId': '2958855', 'name': 'Zirui Lan'}, {'authorId': '1687291', 'name': 'O. Sourina'}, {'authorId': '46659335', 'name': 'Lipo Wang'}, {'authorId': '145536330', 'name': 'Reinhold Scherer'}, {'authorId': '1397903731', 'name': 'G. Müller-Putz'}]"
1231,67ab08815dc8cb850e4464b878beeed989b10250,Optimal Symbol Set Selection: A Semiautomated Procedure,"A new model of the visual search process is developed which can improve the design of large symbol sets such as those used by nuclear power plant personnel, air traffic controllers, and battlefield troops. An experiment was conducted to determine whether the new, componential model or an already existing, discriminability model better explains visual search behavior. The results were consistent with the componential model. We show how to use the componential model to help automate selection of the optimal symbol set (i.e., the symbol set that minimizes the average time to find a target).",1992.0,19.0,31.0,False,,"{'volume': '34', 'pages': '79 - 95', 'name': 'Human Factors: The Journal of Human Factors and Ergonomics Society'}","{'bibtex': '@Article{Fisher1992OptimalSS,\n author = {D. Fisher and Nancy S. Tanner},\n journal = {Human Factors: The Journal of Human Factors and Ergonomics Society},\n pages = {79 - 95},\n title = {Optimal Symbol Set Selection: A Semiautomated Procedure},\n volume = {34},\n year = {1992}\n}\n'}","[{'authorId': '2024442', 'name': 'D. Fisher'}, {'authorId': '2060642430', 'name': 'Nancy S. Tanner'}]"
1232,6814d976154b17e41bc79f8694e2372534e50419,"G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences",,2007.0,86.0,40037.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758%2FBF03193146.pdf', 'status': None}","{'volume': '39', 'pages': '175-191', 'name': 'Behavior Research Methods'}","{'bibtex': '@Article{Faul2007GPower3A,\n author = {F. Faul and E. Erdfelder and Albert-Georg Lang and A. Buchner},\n journal = {Behavior Research Methods},\n pages = {175-191},\n title = {G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences},\n volume = {39},\n year = {2007}\n}\n'}","[{'authorId': '3442630', 'name': 'F. Faul'}, {'authorId': '3391328', 'name': 'E. Erdfelder'}, {'authorId': '123362370', 'name': 'Albert-Georg Lang'}, {'authorId': '39826407', 'name': 'A. Buchner'}]"
1233,681c4a01bcc3deb78491fae30b196afa7fe9e458,Specifying and Implementing a Persuasion Dialogue Game Using Commitments and Arguments,,2004.0,39.0,28.0,True,"{'url': 'http://users.encs.concordia.ca/~bentahar/Publications/LNAI3366(2).pdf', 'status': None}",{'pages': '130-148'},"{'bibtex': '@Inproceedings{Bentahar2004SpecifyingAI,\n author = {J. Bentahar and B. Moulin and B. Chaib-draa},\n pages = {130-148},\n title = {Specifying and Implementing a Persuasion Dialogue Game Using Commitments and Arguments},\n year = {2004}\n}\n'}","[{'authorId': '1812107', 'name': 'J. Bentahar'}, {'authorId': '1727720', 'name': 'B. Moulin'}, {'authorId': '1399443272', 'name': 'B. Chaib-draa'}]"
1234,68385c20a25aea16a54bbaad4f4230a892c010c6,Perform: perceptual approach for adding OCEAN personality to human motion using laban movement analysis,"A major goal of research on virtual humans is the animation of expressive characters that display distinct psychological attributes. Body motion is an effective way of portraying different personalities and differentiating characters. The purpose and contribution of this work is to describe a formal, broadly applicable, procedural, and empirically grounded association between personality and body motion and apply this association to modify a given virtual human body animation that can be represented by these formal concepts. Because the body movement of virtual characters may involve different choices of parameter sets depending on the context, situation, or application, formulating a link from personality to body motion requires an intermediate step to assist generalization. For this intermediate step, we refer to Laban Movement Analysis, which is a movement analysis technique for systematically describing and evaluating human motion. We have developed an expressive human motion generation system with the help of movement experts and conducted a user study to explore how the psychologically validated OCEAN personality factors were perceived in motions with various Laban parameters. We have then applied our findings to procedurally animate expressive characters with personality, and validated the generalizability of our approach across different models and animations via another perception study.",2016.0,57.0,50.0,False,,"{'volume': '36', 'name': 'ACM Trans. Graph.'}","{'bibtex': '@Article{Durupinar2016PerformPA,\n author = {Funda Durupinar and M. Kapadia and Susan Deutsch and Michael Neff and N. Badler},\n journal = {ACM Trans. Graph.},\n title = {Perform: perceptual approach for adding OCEAN personality to human motion using laban movement analysis},\n volume = {36},\n year = {2016}\n}\n'}","[{'authorId': '2643744', 'name': 'Funda Durupinar'}, {'authorId': '143980997', 'name': 'M. Kapadia'}, {'authorId': '2047954359', 'name': 'Susan Deutsch'}, {'authorId': '143687087', 'name': 'Michael Neff'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
1235,68642d447018744b30e113d476e03583d83cd82d,Emotion regulation and emotional information processing: The moderating effect of emotional awareness,,2012.0,28.0,85.0,False,,"{'volume': '52', 'pages': '433-437', 'name': 'Personality and Individual Differences'}","{'bibtex': '@Article{Szczygieł2012EmotionRA,\n author = {D. Szczygieł and J. Buczny and Róża Bazińska},\n journal = {Personality and Individual Differences},\n pages = {433-437},\n title = {Emotion regulation and emotional information processing: The moderating effect of emotional awareness},\n volume = {52},\n year = {2012}\n}\n'}","[{'authorId': '41154117', 'name': 'D. Szczygieł'}, {'authorId': '3868830', 'name': 'J. Buczny'}, {'authorId': '13512301', 'name': 'Róża Bazińska'}]"
1236,686cfc59a276e9b209aa241361c67ec37d4afe5f,A Data‐Driven Framework for Visual Crowd Analysis,"We present a novel approach for analyzing the quality of multi‐agent crowd simulation algorithms. Our approach is data‐driven, taking as input a set of user‐defined metrics and reference training data, either synthetic or from video footage of real crowds. Given a simulation, we formulate the crowd analysis problem as an anomaly detection problem and exploit state‐of‐the‐art outlier detection algorithms to address it. To that end, we introduce a new framework for the visual analysis of crowd simulations. Our framework allows us to capture potentially erroneous behaviors on a per‐agent basis either by automatically detecting outliers based on individual evaluation metrics or by accounting for multiple evaluation criteria in a principled fashion using Principle Component Analysis and the notion of Pareto Optimality. We discuss optimizations necessary to allow real‐time performance on large datasets and demonstrate the applicability of our framework through the analysis of simulations created by several widely‐used methods, including a simulation from a commercial game.",2014.0,30.0,51.0,False,,"{'volume': '33', 'name': 'Computer Graphics Forum'}","{'bibtex': '@Article{Charalambous2014ADF,\n author = {Panayiotis Charalambous and Ioannis Karamouzas and S. Guy and Y. Chrysanthou},\n journal = {Computer Graphics Forum},\n title = {A Data‐Driven Framework for Visual Crowd Analysis},\n volume = {33},\n year = {2014}\n}\n'}","[{'authorId': '39066972', 'name': 'Panayiotis Charalambous'}, {'authorId': '2478994', 'name': 'Ioannis Karamouzas'}, {'authorId': '35170565', 'name': 'S. Guy'}, {'authorId': '1706408', 'name': 'Y. Chrysanthou'}]"
1238,686e9a849db9e99a84e86652bd2d9cca228dc12e,The psychology of facial expression: What does a facial expression mean?,,1997.0,0.0,105.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Russell1997ThePO,\n author = {J. Russell and J. Fernández-Dols},\n title = {The psychology of facial expression: What does a facial expression mean?},\n year = {1997}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '1412884931', 'name': 'J. Fernández-Dols'}]"
1239,687ede32e2fea9408584a2682125a8a378ea17a0,"Virtual Agents, Learning How to Reach a Goal by Making Appropriate Compromises","This paper proposes a modification to the model-free Reinforcement learning algorithm Q-learning. It is implemented to train smart gift shopping-cart learning agents (SGSCLA). The aim of the modification is to empower the learning agent to reaching a goal by making appropriate compromises only. That is the way in which the measure models and emotional models, represented as new agent memory matrixes are introduced. This models show how the user perceives and evaluates the environment. The Shopping Center is represented by a multigraph in which the nodes represent three groups of shops. The edges illustrate the connections between the shops; the primary (major) and the secondary (minor) paths between them and the emotions, evoked in the customer under consideration by a visit to a particular shop. The user can be see the route suggested by the virtual agent and the made compromises to the goal.The emotion types chosen for the purpose of the experiment are boredom, joy and worry. The environment model allow for exploring and predicting the change in the customer’s mood as he/she moves from one shop to another.",2020.0,15.0,1.0,False,,"{'volume': '', 'name': 'Computer Science'}","{'bibtex': '@Article{Budakova2020VirtualAL,\n author = {D. Budakova and Veselka Petrova-Dimitrova and L. Dakovski},\n journal = {Computer Science},\n title = {Virtual Agents, Learning How to Reach a Goal by Making Appropriate Compromises},\n year = {2020}\n}\n'}","[{'authorId': '1799528', 'name': 'D. Budakova'}, {'authorId': '1581448954', 'name': 'Veselka Petrova-Dimitrova'}, {'authorId': '1753312', 'name': 'L. Dakovski'}]"
1240,68ae872c5e7cf31d6950d91fd902c5c42f5dee6b,Extrinsic emotion regulation.,"To date, the field of emotion regulation (ER) has largely focused on intrinsic ER (i.e., regulation of one's own emotions) and has only recently started to investigate extrinsic ER (i.e., regulation of another person's emotions). This article selectively reviews current findings in order to answer the following questions: (a) What is extrinsic ER, and how can it be distinguished from related constructs such as emotion contagion, empathy, prosocial behavior, and social support? (b) How can we best model the processes through which extrinsic ER occurs as well as individual differences in extrinsic ER ability? The answers show that although extrinsic ER has much in common with intrinsic ER, the 2 cannot be equated. Research is therefore needed on the extrinsic side of ER. (PsycINFO Database Record (c) 2020 APA, all rights reserved).",2019.0,38.0,39.0,True,"{'url': 'https://psyarxiv.com/r4e65/download', 'status': None}","{'volume': '20 1', 'pages': '\n          10-15\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Nozaki2019ExtrinsicER,\n author = {Y. Nozaki and Moïra Mikolajczak},\n journal = {Emotion},\n pages = {\n          10-15\n        },\n title = {Extrinsic emotion regulation.},\n volume = {20 1},\n year = {2019}\n}\n'}","[{'authorId': '6919876', 'name': 'Y. Nozaki'}, {'authorId': '5342207', 'name': 'Moïra Mikolajczak'}]"
1241,68b9d8fe795e71905b2f646e8a5bbb52c145369c,The IVI Lab entry to the GENEA Challenge 2022 – A Tacotron2 Based Method for Co-Speech Gesture Generation With Locality-Constraint Attention Mechanism,"This paper describes the IVI Lab entry to the GENEA Challenge 2022. We formulate the gesture generation problem as a sequence-to-sequence conversion task with text, audio, and speaker identity as inputs and the body motion as the output. We use the Tacotron2 architecture as our backbone with the locality-constraint attention mechanism that guides the decoder to learn the dependencies from the neighboring latent features. The collective evaluation released by GENEA Challenge 2022 indicates that our two entries (FSH and USK) for the full body and upper body tracks statistically outperform the audio-driven and text-driven baselines on both two subjective metrics. Remarkably, our full-body entry receives the highest speech appropriateness (60.5% matched) among all submitted entries. We also conduct an objective evaluation to compare our motion acceleration and jerk with two autoregressive baselines. The result indicates that the motion distribution of our generated gestures is much closer to the distribution of natural gestures.",2022.0,25.0,17.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3536221.3558060', 'status': None}",{'name': 'Proceedings of the 2022 International Conference on Multimodal Interaction'},"{'bibtex': '@Article{Chang2022TheIL,\n author = {Che-Jui Chang and Sen Zhang and Mubbasir Kapadia},\n journal = {Proceedings of the 2022 International Conference on Multimodal Interaction},\n title = {The IVI Lab entry to the GENEA Challenge 2022 – A Tacotron2 Based Method for Co-Speech Gesture Generation With Locality-Constraint Attention Mechanism},\n year = {2022}\n}\n'}","[{'authorId': '2152342254', 'name': 'Che-Jui Chang'}, {'authorId': '2175553614', 'name': 'Sen Zhang'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
1242,68ba4804d50c765241f377390dc021db4424d66c,Artificial Intelligence-Based Conversational Agents for Chronic Conditions: Systematic Literature Review,"Background A rising number of conversational agents or chatbots are equipped with artificial intelligence (AI) architecture. They are increasingly prevalent in health care applications such as those providing education and support to patients with chronic diseases, one of the leading causes of death in the 21st century. AI-based chatbots enable more effective and frequent interactions with such patients. Objective The goal of this systematic literature review is to review the characteristics, health care conditions, and AI architectures of AI-based conversational agents designed specifically for chronic diseases. Methods We conducted a systematic literature review using PubMed MEDLINE, EMBASE, PyscInfo, CINAHL, ACM Digital Library, ScienceDirect, and Web of Science. We applied a predefined search strategy using the terms “conversational agent,” “healthcare,” “artificial intelligence,” and their synonyms. We updated the search results using Google alerts, and screened reference lists for other relevant articles. We included primary research studies that involved the prevention, treatment, or rehabilitation of chronic diseases, involved a conversational agent, and included any kind of AI architecture. Two independent reviewers conducted screening and data extraction, and Cohen kappa was used to measure interrater agreement.A narrative approach was applied for data synthesis. Results The literature search found 2052 articles, out of which 10 papers met the inclusion criteria. The small number of identified studies together with the prevalence of quasi-experimental studies (n=7) and prevailing prototype nature of the chatbots (n=7) revealed the immaturity of the field. The reported chatbots addressed a broad variety of chronic diseases (n=6), showcasing a tendency to develop specialized conversational agents for individual chronic conditions. However, there lacks comparison of these chatbots within and between chronic diseases. In addition, the reported evaluation measures were not standardized, and the addressed health goals showed a large range. Together, these study characteristics complicated comparability and open room for future research. While natural language processing represented the most used AI technique (n=7) and the majority of conversational agents allowed for multimodal interaction (n=6), the identified studies demonstrated broad heterogeneity, lack of depth of reported AI techniques and systems, and inconsistent usage of taxonomy of the underlying AI software, further aggravating comparability and generalizability of study results. Conclusions The literature on AI-based conversational agents for chronic conditions is scarce and mostly consists of quasi-experimental studies with chatbots in prototype stage that use natural language processing and allow for multimodal user interaction. Future research could profit from evidence-based evaluation of the AI-based conversational agents and comparison thereof within and between different chronic health conditions. Besides increased comparability, the quality of chatbots developed for specific chronic conditions and their subsequent impact on the target patients could be enhanced by more structured development and standardized evaluation processes.",2020.0,80.0,84.0,True,"{'url': 'https://www.jmir.org/2020/9/e20701/PDF', 'status': None}","{'volume': '22', 'name': 'Journal of Medical Internet Research'}","{'bibtex': '@Article{Schachner2020ArtificialIC,\n author = {T. Schachner and Roman Keller and Florian v. Wangenheim},\n journal = {Journal of Medical Internet Research},\n title = {Artificial Intelligence-Based Conversational Agents for Chronic Conditions: Systematic Literature Review},\n volume = {22},\n year = {2020}\n}\n'}","[{'authorId': '113824585', 'name': 'T. Schachner'}, {'authorId': '1945060918', 'name': 'Roman Keller'}, {'authorId': '146757254', 'name': 'Florian v. Wangenheim'}]"
1243,68c6f582164c241500e644e3f3307396a1b5f51f,Mediating the expression of emotion in educational collaborative virtual environments: an experimental study,,2004.0,68.0,105.0,False,,"{'volume': '7', 'pages': '66-81', 'name': 'Virtual Reality'}","{'bibtex': '@Article{Fabri2004MediatingTE,\n author = {M. Fabri and D. Moore and D. Hobbs},\n journal = {Virtual Reality},\n pages = {66-81},\n title = {Mediating the expression of emotion in educational collaborative virtual environments: an experimental study},\n volume = {7},\n year = {2004}\n}\n'}","[{'authorId': '35033593', 'name': 'M. Fabri'}, {'authorId': '71268802', 'name': 'D. Moore'}, {'authorId': '2315561', 'name': 'D. Hobbs'}]"
1245,68cf46020b94c5e4cd155fed46a7348ed1b1b7f4,Honest Signals - How They Shape Our World,"How can you know when someone is bluffing? Paying attention? Genuinely interested? The answer, writes Sandy Pentland in Honest Signals, is that subtle patterns in how we interact with other people reveal our attitudes toward them. These unconscious social signals are not just a back channel or a complement to our conscious language; they form a separate communication network. Biologically based ""honest signaling,"" evolved from ancient primate signaling mechanisms, offers an unmatched window into our intentions, goals, and values. If we understand this ancient channel of communication, Pentland claims, we can accurately predict the outcomes of situations ranging from job interviews to first dates. Pentland, an MIT professor, has used a specially designed digital sensor worn like an ID badgea ""sociometer""to monitor and analyze the back-and-forth patterns of signaling among groups of people. He and his researchers found that this second channel of communication, revolving not around words but around social relations, profoundly influences major decisions in our liveseven though we are largely unaware of it. Pentland presents the scientific background necessary for understanding this form of communication, applies it to examples of group behavior in real organizations, and shows how by ""reading"" our social networks we can become more successful at pitching an idea, getting a job, or closing a deal. Using this ""network intelligence"" theory of social signaling, Pentland describes how we can harness the intelligence of our social network to become better managers, workers, and communicators.",2008.0,0.0,583.0,False,,"{'pages': 'I-XVII, 1-184'}","{'bibtex': '@Inproceedings{Pentland2008HonestS,\n author = {A. Pentland and T. Heibeck},\n pages = {I-XVII, 1-184},\n title = {Honest Signals - How They Shape Our World},\n year = {2008}\n}\n'}","[{'authorId': '1682773', 'name': 'A. Pentland'}, {'authorId': '3204796', 'name': 'T. Heibeck'}]"
1246,69519759a99d8bff7efc93b6503491deba492ad3,Orange tree simulation under heterogeneous environment using agent-based model ORASIM,,2012.0,83.0,8.0,False,,"{'volume': '23', 'pages': '19-35', 'name': 'Simul. Model. Pract. Theory'}","{'bibtex': '@Article{Qu2012OrangeTS,\n author = {Hongchun Qu and Youlan Wang and Linqin Cai and Ting Wang and Zhonghua Lu},\n journal = {Simul. Model. Pract. Theory},\n pages = {19-35},\n title = {Orange tree simulation under heterogeneous environment using agent-based model ORASIM},\n volume = {23},\n year = {2012}\n}\n'}","[{'authorId': '2133747', 'name': 'Hongchun Qu'}, {'authorId': '2115725295', 'name': 'Youlan Wang'}, {'authorId': '2524401', 'name': 'Linqin Cai'}, {'authorId': '2155391244', 'name': 'Ting Wang'}, {'authorId': '2110249032', 'name': 'Zhonghua Lu'}]"
1247,6998ae456640b8eac72434958e67ee5654a2fd6d,The effect of emotion on interpretation and logic in a conditional reasoning task,,2006.0,56.0,73.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03193257.pdf', 'status': None}","{'volume': '34', 'pages': '1112-1125', 'name': 'Memory & Cognition'}","{'bibtex': '@Article{Blanchette2006TheEO,\n author = {I. Blanchette},\n journal = {Memory & Cognition},\n pages = {1112-1125},\n title = {The effect of emotion on interpretation and logic in a conditional reasoning task},\n volume = {34},\n year = {2006}\n}\n'}","[{'authorId': '5691792', 'name': 'I. Blanchette'}]"
1248,69e65d9a3ca1ab6f90657463a8cf00b3b442dc4a,CUED-RNNLM — An open-source toolkit for efficient training and evaluation of recurrent neural network language models,"In recent years, recurrent neural network language models (RNNLMs) have become increasingly popular for a range of applications including speech recognition. However, the training of RNNLMs is computationally expensive, which limits the quantity of data, and size of network, that can be used. In order to fully exploit the power of RNNLMs, efficient training implementations are required. This paper introduces an open-source toolkit, the CUED-RNNLM toolkit, which supports efficient GPU-based training of RNNLMs. RNNLM training with a large number of word level output targets is supported, in contrast to existing tools which used class-based output-targets. Support fotN-best and lattice-based rescoring of both HTK and Kaldi format lattices is included. An example of building and evaluating RNNLMs with this toolkit is presented for a Kaldi based speech recognition system using the AMI corpus. All necessary resources including the source code, documentation and recipe are available online1.",2016.0,35.0,82.0,True,"{'url': 'https://www.repository.cam.ac.uk/bitstream/1810/274291/1/ICASSP16-Toolkit.pdf', 'status': None}","{'pages': '6000-6004', 'name': '2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","{'bibtex': '@Article{Chen2016CUEDRNNLMA,\n author = {Xie Chen and Xunying Liu and Y. Qian and M. Gales and P. Woodland},\n journal = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {6000-6004},\n title = {CUED-RNNLM — An open-source toolkit for efficient training and evaluation of recurrent neural network language models},\n year = {2016}\n}\n'}","[{'authorId': '2109030402', 'name': 'Xie Chen'}, {'authorId': '150344273', 'name': 'Xunying Liu'}, {'authorId': '2480051', 'name': 'Y. Qian'}, {'authorId': '1740397', 'name': 'M. Gales'}, {'authorId': '1716393', 'name': 'P. Woodland'}]"
1249,6a1c81d22308df709418311855aaba522e1f6d2e,"What do facial expressions convey: feeling states, behavioral intentions, or action requests?","Emotion theorists assume certain facial displays to convey information about the expresser's emotional state. In contrast, behavioral ecologists assume them to indicate behavioral intentions or action requests. To test these contrasting positions, over 2,000 online participants were presented with facial expressions and asked what they revealed-feeling states, behavioral intentions, or action requests. The majority of the observers chose feeling states as the message of facial expressions of disgust, fear, sadness, happiness, and surprise, supporting the emotions view. Only the anger display tended to elicit more choices of behavioral intention or action request, partially supporting the behavioral ecology view. The results support the view that facial expressions communicate emotions, with emotions being multicomponential phenomena that comprise feelings, intentions, and wishes.",2003.0,44.0,243.0,False,,"{'volume': '3 2', 'pages': '\n          150-66\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Horstmann2003WhatDF,\n author = {G. Horstmann},\n journal = {Emotion},\n pages = {\n          150-66\n        },\n title = {What do facial expressions convey: feeling states, behavioral intentions, or action requests?},\n volume = {3 2},\n year = {2003}\n}\n'}","[{'authorId': '1935524', 'name': 'G. Horstmann'}]"
1251,6a2d3d7f5c3c2986d0f5e067f3fd1579337bc971,Our Companion Modelling Approach,"This paper is a charter presenting a scientific posture shared by signatories in the use of simulation tools when dealing with complex systems. This posture is based on a cycling approach, in interaction with field processes, including discussion of assumptions and feedbacks on the field process. Confrontation between field and modelling processes has to be permanent because of openness and uncertainty features of these systems. This approach is used with two possible aims: learn on systems or support collective decision processes in these systems, which corresponds to an objective of increasing knowledge either for the scientist or the field actors, always through an interaction between them mediated by an evolutionary model. Both aims lead to different implementations of this companion modelling approach, but each one is side effect of the other one, and has to be taken in account as such. Scientists ready to work in that way and make this posture alive are kindly invited to join. (Resume d'auteur)",2003.0,0.0,314.0,False,,"{'volume': '6', 'name': 'J. Artif. Soc. Soc. Simul.'}","{'bibtex': '@Article{Barreteau2003OurCM,\n author = {O. Barreteau},\n journal = {J. Artif. Soc. Soc. Simul.},\n title = {Our Companion Modelling Approach},\n volume = {6},\n year = {2003}\n}\n'}","[{'authorId': '3280761', 'name': 'O. Barreteau'}]"
1252,6a2e5bad38dad2f0277357c8607efc22f693ddc8,A VIRTUAL CHARACTER'S EMOTIONAL PERSUASIVENESS,"Most of the researches so far have focused on emotional impulsive virtual characters, i.e virtual characters that express their own felt emotions without taking into account the socio-emotional context of the interaction. However, research in Human and Social Sciences has shown that during interpersonal interaction, people express very often emotions different from their felt emotions because they have to follow some sociocultural norms or they are pursuing specific goals. In this paper, we address the emotions that a virtual character should express to try to convince someone else during a negotiation. A model of an emotional persuasive virtual character and its implementation in the virtual world Second Life are presented. Such character is endowed with strategies of emotion expression that enable it to identify dynamically the emotion that it should express, depending on its interlocutor’s emotional reaction, to try to influence his opinion during a negotiation. The emotional persuasive virtual character has been evaluated in indirect interaction (i.e. when the user watches a conversation between two virtual characters). The results show than the proposed model of strategic expressions of emotion enables one to significantly improve the virtual character’s persuasiveness.",2010.0,21.0,5.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Ochs2010AVC,\n author = {M. Ochs and H. Prendinger},\n title = {A VIRTUAL CHARACTER'S EMOTIONAL PERSUASIVENESS},\n year = {2010}\n}\n""}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '2356111', 'name': 'H. Prendinger'}]"
1253,6a543508d46893d6fb8f86c86ad60902615c7140,Conveying Social Relations in Virtual Agents Through an Emotion Sharing and Response Model: (Extended Abstract),"The impact of social relationships in human behavior is a complex topic but it is an important aspect to consider when creating believable agents. To achieve more believable social relations, we focus on a phenomenon of human interaction that is tightly coupled to social relationships but has been overlooked in most agent models of emotions: the “social sharing of emotions”. It corresponds to a common daily event where a person, the sharer, tells another, the listener, about an emotional episode he experienced in the past. This phenomenon happens on a daily basis and it is important for social relationships as it signals some level of intimacy. Therefore, we propose an agent model that endows agents with the capability to speak about their past emotional experiences, and provide a supportive response in case they are the listeners. For evaluation purposes, we developed a case study that consists in a simulation of a distressful situation in a 3D environment involving three autonomous characters. Two variations of this situation were designed: one in which our model causes a character to share the negative emotion it experiences and another where the character does not share any emotion. An user study was then conducted to assess the impact of the emotional sharing concerning the characters’ believability and perceived relationship with each other.",2016.0,6.0,1.0,False,,{'pages': '1415-1416'},"{'bibtex': '@Article{Salvador2016ConveyingSR,\n author = {Nuno Salvador and João Dias and S. Mascarenhas and Ana Paiva},\n booktitle = {Adaptive Agents and Multi-Agent Systems},\n pages = {1415-1416},\n title = {Conveying Social Relations in Virtual Agents Through an Emotion Sharing and Response Model: (Extended Abstract)},\n year = {2016}\n}\n'}","[{'authorId': '2969405', 'name': 'Nuno Salvador'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1254,6a67fd0f37ec92b07d22a596eb4cf7394e77a048,Electroencephalograph (EEG) Based Emotion Recognition System: A Review,,2018.0,50.0,28.0,False,,{'name': 'Lecture Notes in Networks and Systems'},"{'bibtex': '@Article{Wagh2018ElectroencephalographB,\n author = {K. Wagh and K. Vasanth},\n journal = {Lecture Notes in Networks and Systems},\n title = {Electroencephalograph (EEG) Based Emotion Recognition System: A Review},\n year = {2018}\n}\n'}","[{'authorId': '69039208', 'name': 'K. Wagh'}, {'authorId': '72058167', 'name': 'K. Vasanth'}]"
1255,6a6f1b8ef3eefaf8027a76134859b44886a5f795,EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks,"Accurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding individuals and their lives. However, progress on emotion detection has been hampered by the absence of large labeled datasets. In this work, we build a very large dataset for fine-grained emotions and develop deep learning models on it. We achieve a new state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58%). We also extend the task beyond emotion types to model Robert Plutick’s 8 primary emotion dimensions, acquiring a superior accuracy of 95.68%.",2017.0,63.0,271.0,True,"{'url': 'https://www.aclweb.org/anthology/P17-1067.pdf', 'status': None}",{'pages': '718-728'},"{'bibtex': '@Inproceedings{Abdul-Mageed2017EmoNetFE,\n author = {Muhammad Abdul-Mageed and L. Ungar},\n pages = {718-728},\n title = {EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks},\n year = {2017}\n}\n'}","[{'authorId': '1388437494', 'name': 'Muhammad Abdul-Mageed'}, {'authorId': '1412391493', 'name': 'L. Ungar'}]"
1256,6a78a121d918cd2a1f0dc337bbc5c0dae7f9c134,"Source (or Part of the following Source): Type Article Title Emotional Signals from Faces, Bodies and Scenes Influence Observers' Face Expressions, Fixations and Pupil-size Author(s) Emotional Signals from Faces, Bodies and Scenes Influence Observers' Face Expressions, Fixations and Pupil-size","Copyright It is not permitted to download or to forward/distribute the text or part of it without the consent of the author(s) and/or copyright holder(s), other than for strictly personal, individual use, unless the work is under an open content licence (like Creative Commons). UvA-DARE is a service provided by the library of the University of Amsterdam (http://dare.uva.nl) We receive emotional signals from different sources, including the face, the whole body, and the natural scene. Previous research has shown the importance of context provided by the whole body and the scene on the recognition of facial expressions. This study measured physiological responses to face-body-scene combinations. Participants freely viewed emotionally congruent and incongruent face-body and body-scene pairs whilst eye fixations, pupil-size, and electromyography (EMG) responses were recorded. Participants attended more to angry and fearful vs. happy or neutral cues, independent of the source and relatively independent from whether the face body and body scene combinations were emotionally congruent or not. Moreover, angry faces combined with angry bodies and angry bodies viewed in aggressive social scenes elicited greatest pupil dilation. Participants' face expressions matched the valence of the stimuli but when face-body compounds were shown, the observed facial expression influenced EMG responses more than the posture. Together, our results show that the perception of emotional signals from faces, bodies and scenes depends on the natural context, but when threatening cues are presented, these threats attract attention, induce arousal, and evoke congruent facial reactions.",,39.0,137.0,False,,,"{'bibtex': ""@Misc{None,\n author = {M. Kret and Koen W.H. Roelofs and J. Stekelenburg and B. de Gelder and M. Kret and Karin Roelofs and J. Stekelenburg and B. de Gelder and John J. Foxe and Albert and C. H. Attar},\n title = {Source (or Part of the following Source): Type Article Title Emotional Signals from Faces, Bodies and Scenes Influence Observers' Face Expressions, Fixations and Pupil-size Author(s) Emotional Signals from Faces, Bodies and Scenes Influence Observers' Face Expressions, Fixations and Pupil-size}\n}\n""}","[{'authorId': '27448594', 'name': 'M. Kret'}, {'authorId': '71890283', 'name': 'Koen W.H. Roelofs'}, {'authorId': '32734830', 'name': 'J. Stekelenburg'}, {'authorId': '4628064', 'name': 'B. de Gelder'}, {'authorId': '2512383', 'name': 'M. Kret'}, {'authorId': '2229103738', 'name': 'Karin Roelofs'}, {'authorId': '32734830', 'name': 'J. Stekelenburg'}, {'authorId': '4628064', 'name': 'B. de Gelder'}, {'authorId': '3229047', 'name': 'John J. Foxe'}, {'authorId': '2074222905', 'name': 'Albert'}, {'authorId': '2440064', 'name': 'C. H. Attar'}]"
1257,6a884f9d3e898c771bdd2c093f1d1df93c39a7d9,Crowd Simulation,"Research into the methods and techniques used in simulating crowds has developed extensively within the last few years, particularly in the areas of video games and film. Despite recent impressive results when simulating and rendering thousands of individuals, many challenges still exist in this area. The comparison of simulation with reality, the realistic appearance of virtual humans and their behavior, group structure and their motion, and collision avoidance are just some examples of these challenges. For most of the applications of crowds, it is now a requirement to have real-time simulations which is an additional challenge, particularly when crowds are very large. Crowd Simulation analyses these challenges in depth and suggests many possible solutions. Daniel Thalmann and Soraia Musse share their experiences and expertise in the application of: Population modeling Virtual human animation Behavioral models for crowds The connection between virtual and real crowds Path planning and navigation Visual attention models Geometric and populated semantic environments Crowd rendering The second edition presents techniques and methods developed since the authors first covered the simulation of crowds in 2007. Crowd Simulation includes in-depth discussions on the techniques of path planning, including a new hybrid approach between navigation graphs and potential-based methods. The importance of gaze attention individuals appearing conscious of their environment and of others is introduced, and a free-of-collision method for crowds is also discussed.",2007.0,55.0,190.0,True,,"{'pages': 'I-XII, 1-242'}","{'bibtex': '@Inproceedings{Thalmann2007CrowdS,\n author = {Daniel Thalmann},\n pages = {I-XII, 1-242},\n title = {Crowd Simulation},\n year = {2007}\n}\n'}","[{'authorId': '2253503834', 'name': 'Daniel Thalmann'}]"
1258,6a96bac30730217d7a25d723466038352925954f,Automating the Production of Communicative Gestures in Embodied Characters,"In this paper we highlight the different challenges in modeling communicative gestures for Embodied Conversational Agents (ECAs). We describe models whose aim is to capture and understand the specific characteristics of communicative gestures in order to envision how an automatic communicative gesture production mechanism could be built. The work is inspired by research on how human gesture characteristics (e.g., shape of the hand, movement, orientation and timing with respect to the speech) convey meaning. We present approaches to computing where to place a gesture, which shape the gesture takes and how gesture shapes evolve through time. We focus on a particular model based on theoretical frameworks on metaphors and embodied cognition that argue that people can represent, reason about and convey abstract concepts using physical representations and processes, which can be conveyed through physical gestures.",2018.0,74.0,29.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01144/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Ravenet2018AutomatingTP,\n author = {Brian Ravenet and C. Pelachaud and C. Clavel and S. Marsella},\n journal = {Frontiers in Psychology},\n title = {Automating the Production of Communicative Gestures in Embodied Characters},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '1682486', 'name': 'Brian Ravenet'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
1259,6a97ba1d89ac978a134f5149f073312710959e75,Mixed feelings: expression of non-basic emotions in a muscle-based talking head,,2005.0,50.0,111.0,False,,"{'volume': '8', 'pages': '201-212', 'name': 'Virtual Reality'}","{'bibtex': '@Article{Albrecht2005MixedFE,\n author = {I. Albrecht and M. Schröder and Jörg Haber and H. Seidel},\n journal = {Virtual Reality},\n pages = {201-212},\n title = {Mixed feelings: expression of non-basic emotions in a muscle-based talking head},\n volume = {8},\n year = {2005}\n}\n'}","[{'authorId': '33578779', 'name': 'I. Albrecht'}, {'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '144213705', 'name': 'Jörg Haber'}, {'authorId': '145156858', 'name': 'H. Seidel'}]"
1260,6ab3d3c50d21b5b2351826975fad765e4309e791,Cognitive behavioral therapy for adherence and depression (CBT-AD) in HIV-infected injection drug users: a randomized controlled trial.,"OBJECTIVE
Depression and substance use, the most common comorbidities with HIV, are both associated with poor treatment adherence. Injection drug users comprise a substantial portion of individuals with HIV in the United States and globally. The present study tested cognitive behavioral therapy for adherence and depression (CBT-AD) in patients with HIV and depression in active substance abuse treatment for injection drug use.


METHOD
This is a 2-arm, randomized controlled trial (N = 89) comparing CBT-AD with enhanced treatment as usual (ETAU). Analyses were conducted for two time-frames: (a) baseline to post-treatment and (b) post-treatment to follow-up at 3 and 6 months after intervention discontinuation.


RESULTS
At post-treatment, the CBT-AD condition showed significantly greater improvement than ETAU in MEMS (electronic pill cap) based adherence, γslope = 0.8873, t(86) = 2.38, p = .02; dGMA-raw = 0.64, and depression, assessed by blinded assessor: Mongomery-Asberg Depression Rating Scale, F(1, 79) = 6.52, p < .01, d = 0.55; clinical global impression, F(1, 79) = 14.77, p < .001, d = 0.85. After treatment discontinuation, depression gains were maintained, but adherence gains were not. Viral load did not differ across condition; however, the CBT-AD condition had significant improvements in CD4 cell counts over time compared with ETAU, γslope = 2.09, t(76) = 2.20, p = .03, dGMA-raw = 0.60.


CONCLUSIONS
In patients managing multiple challenges including HIV, depression, substance dependence, and adherence, CBT-AD is a useful way to integrate treatment of depression with an adherence intervention. Continued adherence counseling is likely needed, however, to maintain or augment adherence gains in this population.",2012.0,67.0,199.0,True,"{'url': 'https://europepmc.org/articles/pmc3365619?pdf=render', 'status': None}","{'volume': '80 3', 'pages': '\n          404-15\n        ', 'name': 'Journal of consulting and clinical psychology'}","{'bibtex': '@Article{Safren2012CognitiveBT,\n author = {S. Safren and C. O’Cleirigh and J. Bullis and M. Otto and M. Stein and M. Pollack},\n journal = {Journal of consulting and clinical psychology},\n pages = {\n          404-15\n        },\n title = {Cognitive behavioral therapy for adherence and depression (CBT-AD) in HIV-infected injection drug users: a randomized controlled trial.},\n volume = {80 3},\n year = {2012}\n}\n'}","[{'authorId': '4545487', 'name': 'S. Safren'}, {'authorId': '1389265190', 'name': 'C. O’Cleirigh'}, {'authorId': '4458881', 'name': 'J. Bullis'}, {'authorId': '1747366', 'name': 'M. Otto'}, {'authorId': '2233795295', 'name': 'M. Stein'}, {'authorId': '2251472', 'name': 'M. Pollack'}]"
1261,6ab8b2554c43366c390ec4a0080b33417beb9f7d,Human Physiology as a Basis for Designing and Evaluating Affective Communication with Life-Like Characters,"This paper highlights some of our recent research efforts in designing and evaluating life-like characters that are capable of entertaining affective and social communication with human users. The key novelty of our approach is the use of human physiological information: first, as a method to evaluate the effect of life-like character behavior on a moment-to-moment basis, and second, as an input modality for a new generation of interface agents that we call 'physiologically perceptive' life-like characters. By exploiting the stream of primarily involuntary human responses, such as autonomic nervous system activity or eye movements, those characters are expected to respond to users' affective and social needs in a truly sensitive, and hence effective, friendly, and beneficial way.",2005.0,42.0,18.0,False,,"{'volume': '88-D', 'pages': '2453-2460', 'name': 'IEICE Trans. Inf. Syst.'}","{'bibtex': '@Article{Prendinger2005HumanPA,\n author = {H. Prendinger and M. Ishizuka},\n journal = {IEICE Trans. Inf. Syst.},\n pages = {2453-2460},\n title = {Human Physiology as a Basis for Designing and Evaluating Affective Communication with Life-Like Characters},\n volume = {88-D},\n year = {2005}\n}\n'}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
1262,6ae67d7daa599c2935eac8211c0d845d29375acb,Leveraging Adaptive Sessions Based on Therapeutic Empathy Through a Virtual Agent,"This document describes the work under development as part of a PhD Thesis carried out in the context of the European Project “Help4Mood – A Distributed System to Support the Treatment of Patients with Major Depression” (www.help4mood.info) [FP7-ICT-2009-4; 248765]. Help4Mood aims to support the treatment of patients with Major Depression using Information and Communications Technology (ICT). The resultant Personal Health System (PHS) of Help4Mood uses a set of activity sensors (such as wrist watch, key ring, or under-mattress sensor) that gather information about the daily physical and sleep activities from the patient. This information and other data obtained through standardized questionnaires are analysed in order to infer some recommendations (or alerts) and offer adaptive and tailored tasks as part of the treatment in the form of daily interactive sessions provided by a Virtual Agent (VA). The initial developed work for the project resulted in the MSc Thesis entitled “Generic Data Processing & Analysis Architecture of a Personal Health System to Manage Daily Interactive Sessions in Patients with Major Depression” (Breso, 2013) within the Artificial Intelligence, Pattern Recognition and Digital Imaging MSc program at the Technical University of Valencia. In this MSc Thesis, the author describes the design and the implementation of the Data Processing & Analysis layer of the Help4Mood’s PHS. It had been conceived as the module responsible to analyse relevant patient’s data, plan the daily interactive sessions and recommend a set of tailored activities configured by clinicians that help in the recovery of the patient. Additionally, this system included an initial cognitive-emotional module aimed to infer the specific set of emotions to be displayed by the VA during the interaction The research work presented in this document is an extension of the work done in the MSc's Thesis. The proposed extension will allow a deeper research on how to improve current Human-Agent Interactions particularly addressed to users that are under treatment of Major Depression. Some theories in the areas of psychology and cognitive science will be the basis of a computational model that is expected to improve the production of the daily session’s content and the adequate –emotional– fashion for a better engagement of the users promoting the long-term use of the system.",2017.0,53.0,9.0,False,,"{'name': '', 'pages': '46-55', 'volume': ''}","{'bibtex': '@Inproceedings{Bresó2017LeveragingAS,\n author = {A. Bresó and J. Martínez-Miranda and J. M. García-Gómez},\n pages = {46-55},\n title = {Leveraging Adaptive Sessions Based on Therapeutic Empathy Through a Virtual Agent},\n year = {2017}\n}\n'}","[{'authorId': '3352168', 'name': 'A. Bresó'}, {'authorId': '1398008961', 'name': 'J. Martínez-Miranda'}, {'authorId': '1388884721', 'name': 'J. M. García-Gómez'}]"
1263,6ae7e6a11515cfc8d3fe6e5b53c951f4de31e0b7,HOW MANY SEPARATELY EVOLVED EMOTIONAL BEASTIES LIVE WITHIN US,"A problem which bedevils the study of emotions, and the study of consciousness, is that we assume a shared understanding of many everyday concepts, such as ‘emotion’, ‘feeling’, ‘pleasure’, ‘pain’, ‘desire’, ‘awareness’, etc. Unfortunately, these concepts are inherently very complex, ill-defined, and used with different meanings by different people. Moreover this goes unnoticed, so that people think they understand what they are referring to even when their understanding is very unclear. Consequently there is much discussion that is inherently vague, often at cross-purposes, and with apparent disagreements that arise out of people unwittingly talking about different things. We need a framework which explains how there can be all the diverse phenomena that different people refer to when they talk about emotions and other affective states and processes. The conjecture on which this paper is based is that adult humans have a type of information-processing architecture, with components which evolved at different times, including a rich and varied collection of components whose interactions can generate all the sorts of phenomena that different researchers have labelled “emotions”. Within this framework we can provide rational reconstructions of many everyday concepts of mind. We can also allow a variety of different architectures, found in children, brain damaged adults, other animals, robots, software agents, etc., where different architectures support different classes of states and processes, and therefore different mental ontologies. Thus concepts like ‘emotion’, ‘awareness’, etc. will need to be interpreted differently when referring to different architectures. We need to limit the class of architectures under consideration, since for any class of behaviours there are indefinitely many architectures which can produce those behaviours. One important constraint is to consider architectures which might have been produced by biological evolution. This leads to the notion of a human architecture composed of many components which evolved under the influence of the other components as well as environmental needs and pressures. From this viewpoint, a mind is a kind of ecosystem1 of co-evolved sub-organisms acquiring and using different kinds of information and processing it in different ways, sometimes cooperating with one another and sometimes competing. Within this framework we can hope to study not only mechanisms underlying affective states and processes, but also other mechanisms which are often studied in isolation, e.g. vision, action mechanisms, learning mechanisms, ‘alarm’ mechanisms, etc. We can also explain why some models, and corresponding conceptions of emotion, are shallow whereas others are deeper. Shallow models may be of practical use, e.g. in entertainment and interface design. Deeper models are required if we are to understand what we are, how we can go wrong, etc. This paper is a snapshot of a long term project addressing all these issues. 1 What kinds of emotions? The study of emotions has recently become fashionable within AI and Cognitive Science. Unfortunately all sorts of different things are labelled as ‘emotions’. This is perhaps understandable among young engineers who have not been trained in philosophy or psychology. However even among specialists there many different definitions of ‘emotion’ and related concepts, such as ‘feeling’, ‘affect’, ‘motivation’, ‘mood’, etc. For instance some define emotions in terms of observable physical behaviours (such as weeping, grimacing, smiling, jumping for joy, etc.). Some define them in terms of measurable physiological changes which need 1The published version of this paper used the word ‘ecology’ here. not be easily discernible externally, though they may be sensed internally (referred to by Picard as ‘sentic modulation’). Some define them in terms of the kinds of conscious experiences involved in having them – their phenomenology. Some define them in terms of the brain mechanisms which may be activated. Even when behavioural manifestations do occur they may be to some extent culturally determined, casting doubt on behavioural criteria for emotions. For instance the sounds people make when exhibiting pain can vary according to culture: ‘ouch’ in English is replaced by ‘eina’ in Afrikaans! Some researchers regard emotions as inherently social or cultural in nature, though this may be more true of having a guilty conscience than being terrified during an earthquake. There is also disagreement over what sorts of evidence can be taken as relevant to the study of emotions. For instance, some will regard the behaviour of skilled actors when asked to show certain emotions as demonstrating connections between emotions and externally observable behaviour. Others will object that that merely reveals what happens when people are asked to act as if they had certain emotions, whereas naturally occurring emotions may be quite different. In some cases they may have no external manifestations, since people can often conceal their emotions. For some researchers, emotions, by definition, are linked to and differentiable in observable behaviour, like weeping, grimacing, jumping for joy, growing tense, etc., whereas others are more interested in semantically rich emotions for which there are no characteristic, non-verbal, behavioural expressions, e.g. ‘Being worried that your work is not appreciated by your colleagues’ vs. ‘Being worried that your political party is going to lose the next election’, or ‘Being delighted that the there is a sunny weather forecast for the day you have planned a picnic’ vs. ‘Being delighted that someone you admire very much is impressed by your research’, etc. Most of the empirical, laboratory, research on emotions has studied only simple, shallow emotions, largely ignoring semantic content, whereas most of the important human emotions (the ones that are important in our social lives, and which are the subject matter of gossip, poems, stories, plays, etc.) are deep and semantically rich. Another common difficulty is that some people use the word ‘emotion’ so loosely that it covers almost any affective state, including having a desire or motive, whereas in ordinary parlance we do not normally describe someone as being emotional just because they have goals, purposes, or preferences, or because they are enjoying a meal or finding their chair uncomfortable to sit in. If all such affective states were included as emotions, it would follow that people constantly have a large number of different emotions, since we all have multiple enduring goals, ambitions, tastes, preferences, ideals, etc. Another source of confusion concerns whether having an emotion necessarily involves being conscious of the emotion. According to some this is a defining criterion, yet that does not square with the common observation that people can sometimes be angry, jealous, infatuated, or pleased at being flattered, etc. without being aware of being so, even though it may be obvious to others. Another problem with the criterion is that it may rule out certain animals having emotions if they lack the ability to monitor and characterise their own states or lack the conceptual framework required to classify some states as emotions. Presumably a newborn infant cannot classify its own mental states using our adult categories. Does that mean that it has no emotions? Perhaps it has them but does not feel them? Perhaps an infant’s behavioural manifestations of pain, distress, discomfort, pleasure, etc. are simply part of the biologically important process of generating appropriate nurturing behaviour in parents rather than being expressions of what the infant is aware of? There is no obvious way of resolving disagreements on these issues because of the ambiguities and confusion in the key concepts used. Yet another confusion concerns whether, in order to have emotions, an organism or machine must contain an emotion-producing module of some kind, or whether some or all emotions are simply states involving interactions between a host of processes which are not intrinsically emotional, as was argued in (Wright et al., 1996). On the first view it makes sense to ask how the emotion mechanism evolved, and what biological function it has, whereas on the second view such questions make no sense. Another possibility is that the ambiguous word ‘emotion’ sometimes refers to states and processes conforming to the first view, and sometimes to the second, because our usage is inconsistent. Because of this conceptual mess, anyone can produce a program, label some component of it the ‘emotion module’ and proudly announce that they have developed a robot or software agent which has emotions. It will be hard to argue against such claims when there is no agreement on what emotions are. This is an extreme form of the phenomenon in AI of attributing mental states and human capabilities to programs on the basis of very shallow analogies, for which McDermott chided the AI community in (McDermott, 1981) many years ago, though he was concerned with the undisciplined use of labels such as ‘plan’, ‘goal’, ‘infer’.",2002.0,59.0,97.0,True,"{'url': 'http://www.cs.bham.ac.uk/research/cogaff/sloman.vienna99.pdf', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sloman2002HOWMS,\n author = {A. Sloman},\n title = {HOW MANY SEPARATELY EVOLVED EMOTIONAL BEASTIES LIVE WITHIN US},\n year = {2002}\n}\n'}","[{'authorId': '145788442', 'name': 'A. Sloman'}]"
1264,6b20726425e78845e854db6e8da03a451be45098,Impact of Online Discussions on Web Based Assessments,"The﻿practice﻿of﻿including﻿online﻿discussion﻿posts﻿to﻿traditional﻿courses﻿is﻿increasing.﻿Online﻿discussions﻿ allow﻿for﻿active﻿learning﻿to﻿occur﻿as﻿students﻿express﻿their﻿ideas﻿and﻿respond﻿to﻿others.﻿The﻿time﻿and﻿ thought﻿provided﻿by﻿online﻿discussion﻿posts﻿allows﻿students﻿to﻿utilize﻿higher﻿level﻿cognitive﻿skills.﻿ Web-based﻿assessments﻿are﻿another﻿technology﻿tool﻿that﻿instructors﻿are﻿including﻿in﻿their﻿courses.﻿ This﻿study﻿examined﻿the﻿impact﻿of﻿online﻿discussion﻿posts﻿on﻿achievement﻿of﻿web-based﻿assessments﻿ for﻿an﻿upper﻿level﻿undergraduate﻿business﻿and﻿technology﻿writing﻿intensive﻿course.﻿Using﻿a﻿treatment﻿ group﻿and﻿a﻿control﻿group,﻿student﻿achievement﻿scores﻿for﻿the﻿online﻿assessments﻿were﻿measured.﻿ Results﻿indicate﻿that﻿assessed﻿grades﻿of﻿the﻿treatment﻿groups﻿were﻿higher﻿than﻿the﻿control﻿group,﻿ however﻿statistical﻿significance﻿was﻿mixed﻿among﻿the﻿web﻿assessments.﻿The﻿results﻿further﻿illustrate﻿ the﻿need﻿for﻿additional﻿research﻿into﻿online﻿discussions﻿applied﻿to﻿web-based﻿assessments. KEyWORDS Active Learning, Online Discussions, Student Achievement, Web Based Assessments, Writing Intensive Courses",2017.0,40.0,4.0,False,,"{'volume': '15', 'pages': '99-111', 'name': 'Int. J. Distance Educ. Technol.'}","{'bibtex': '@Article{Powell2017ImpactOO,\n author = {L. Powell and H. Wimmer and Lawrence Kilgus and C. Force},\n journal = {Int. J. Distance Educ. Technol.},\n pages = {99-111},\n title = {Impact of Online Discussions on Web Based Assessments},\n volume = {15},\n year = {2017}\n}\n'}","[{'authorId': '144605164', 'name': 'L. Powell'}, {'authorId': '29394742', 'name': 'H. Wimmer'}, {'authorId': '8797671', 'name': 'Lawrence Kilgus'}, {'authorId': '25654478', 'name': 'C. Force'}]"
1265,6b29199b5f7e796f7f266cd6e957fadb4494e0e3,Socially assistive robotics [Grand Challenges of Robotics],"Socially intelligent robotics is the pursuit of creating robots capable of exhibiting natural-appearing social qualities. Beyond the basic capabilities of moving and acting autonomously, the field has focused on the use of the robot's physical embodiment to communicate and interact with users in a social and engaging manner. One of its components, socially assistive robotics, focuses on helping human users through social rather than physical interaction. Early results already demonstrate the promises of socially assistive robotics, a new interdisciplinary research area with large horizons of fascinating and much needed research. Even as socially assistive robotic technology is still in its early stages of development, the next decade promises systems that will be used in hospitals, schools, and homes in therapeutic programs that monitor, encourage, and assist their users. This is an important time in the development of the field, when the board technical community and the beneficiary populations must work together to shape the field toward its intended impact on improved human quality of life",2007.0,26.0,405.0,False,,"{'volume': '14', 'pages': '35-42', 'name': 'IEEE Robotics & Automation Magazine'}","{'bibtex': '@Article{Tapus2007SociallyAR,\n author = {A. Tapus and M. Matarić and B. Scassellati},\n journal = {IEEE Robotics & Automation Magazine},\n pages = {35-42},\n title = {Socially assistive robotics [Grand Challenges of Robotics]},\n volume = {14},\n year = {2007}\n}\n'}","[{'authorId': '1738469', 'name': 'A. Tapus'}, {'authorId': '1742183', 'name': 'M. Matarić'}, {'authorId': '1792053', 'name': 'B. Scassellati'}]"
1266,6b2e1c4fa51c1fc00bdb9672aef30dc769e7b253,Computational Models of Emotion Inference in Theory of Mind: A Review and Roadmap,"Abstract Research on social cognition has fruitfully applied computational modeling approaches to explain how observers understand and reason about others’ mental states. By contrast, there has been less work on modeling observers’ understanding of emotional states. We propose an intuitive theory framework to studying affective cognition—how humans reason about emotions—and derive a taxonomy of inferences within affective cognition. Using this taxonomy, we review formal computational modeling work on such inferences, including causal reasoning about how others react to events, reasoning about unseen causes of emotions, reasoning with multiple cues, as well as reasoning from emotions to other mental states. In addition, we provide a roadmap for future research by charting out inferences—such as hypothetical and counterfactual reasoning about emotions—that are ripe for future computational modeling work. This framework proposes unifying these various types of reasoning as Bayesian inference within a common “intuitive Theory of Emotion.” Finally, we end with a discussion of important theoretical and methodological challenges that lie ahead in modeling affective cognition.",2018.0,117.0,77.0,True,,"{'volume': '11', 'pages': '338 - 357', 'name': 'Topics in Cognitive Science'}","{'bibtex': '@Article{Ong2018ComputationalMO,\n author = {Desmond C. Ong and Jamil Zaki and Noah D. Goodman},\n journal = {Topics in Cognitive Science},\n pages = {338 - 357},\n title = {Computational Models of Emotion Inference in Theory of Mind: A Review and Roadmap},\n volume = {11},\n year = {2018}\n}\n'}","[{'authorId': '144799222', 'name': 'Desmond C. Ong'}, {'authorId': '2268731', 'name': 'Jamil Zaki'}, {'authorId': '144002017', 'name': 'Noah D. Goodman'}]"
1267,6b31942478e7aca6f1998b8d1506167fd8a0bf86,An ethological and emotional basis for human-robot interaction,,2003.0,18.0,309.0,True,"{'url': 'https://smartech.gatech.edu/bitstream/1853/21544/1/sony-iros.pdf', 'status': None}","{'volume': '42', 'pages': '191-201', 'name': 'Robotics Auton. Syst.'}","{'bibtex': '@Article{Arkin2003AnEA,\n author = {R. Arkin and M. Fujita and Tsuyoshi Takagi and R. Hasegawa},\n journal = {Robotics Auton. Syst.},\n pages = {191-201},\n title = {An ethological and emotional basis for human-robot interaction},\n volume = {42},\n year = {2003}\n}\n'}","[{'authorId': '1706062', 'name': 'R. Arkin'}, {'authorId': '69954988', 'name': 'M. Fujita'}, {'authorId': '2052774919', 'name': 'Tsuyoshi Takagi'}, {'authorId': '2062296789', 'name': 'R. Hasegawa'}]"
1268,6b3f8bab8b358cba5f81d7ff3ddf02dacdbdeb32,Using Augmented Reality in Patients with Autism: A Systematic Review,,2019.0,45.0,30.0,False,,{'name': 'VipIMAGE 2019'},"{'bibtex': '@Article{Marto2019UsingAR,\n author = {Anabela Marto and H. Almeida and Alexandrino Gonçalves},\n journal = {VipIMAGE 2019},\n title = {Using Augmented Reality in Patients with Autism: A Systematic Review},\n year = {2019}\n}\n'}","[{'authorId': '21052747', 'name': 'Anabela Marto'}, {'authorId': '8029017', 'name': 'H. Almeida'}, {'authorId': '3068581', 'name': 'Alexandrino Gonçalves'}]"
1269,6b5c913046650a79c0a23babe3d1841ce2a58f67,Emotion Recognition with Machine Learning Using EEG Signals,"In this research, an emotion recognition system is developed based on valence/arousal model using electroencephalography (EEG) signals. EEG signals are decomposed into the gamma, beta, alpha and theta frequency bands using discrete wavelet transform (DWT), and spectral features are extracted from each frequency band. Principle component analysis (PCA) is applied to the extracted features by preserving the same dimensionality, as a transform, to make the features mutually uncorrelated. Support vector machine (SVM), K-nearest neighbor (KNN) and artificial neural network (ANN) are used to classify emotional states. The cross- validated SVM with radial basis function (RBF) kernel using extracted features of 10 EEG channels, performs with 91.3% accuracy for arousal and 91.1% accuracy for valence, both in the beta frequency band. Our approach shows better performance compared to existing algorithms applied to the ""DEAP"" dataset.",2018.0,22.0,69.0,True,"{'url': 'https://arxiv.org/pdf/1903.07272', 'status': None}","{'pages': '1-5', 'name': '2018 25th National and 3rd International Iranian Conference on Biomedical Engineering (ICBME)'}","{'bibtex': '@Article{Bazgir2018EmotionRW,\n author = {Omid Bazgir and Z. Mohammadi and S. Habibi},\n journal = {2018 25th National and 3rd International Iranian Conference on Biomedical Engineering (ICBME)},\n pages = {1-5},\n title = {Emotion Recognition with Machine Learning Using EEG Signals},\n year = {2018}\n}\n'}","[{'authorId': '31052087', 'name': 'Omid Bazgir'}, {'authorId': '89814248', 'name': 'Z. Mohammadi'}, {'authorId': '10801568', 'name': 'S. Habibi'}]"
1270,6b6d357fb4ef19f2330596183ce00d2f3797740d,Algorithms for the Longest Common Subsequence Problem,"We start by def ining conven t ions and t e rmino logy that will be used th roughou t this paper . String C = clc~ ... cp is a subsequence of string A = aja2 ""'"" am if there is a mapp ing F : {1, 2 . . . . , p} ~ {1, 2, ... , m} such that F(i) = k only if c~ = ak and F is a m o n o t o n e strictly increasing funct ion (i .e. F(i) = u, F(]) = v, and i < j imply that u < v). C can be fo rmed by delet ing m p (not necessari ly ad jacen t ) symbols f rom A . F o r example , "" c o u r s e "" is a subsequence of "" c o m p u t e r sc ience . "" Str ing C is a c o m m o n s ubs equence of strings A and B if C is a s u b s e q u e n c e of A and also a subsequence of B. String C is a longest c o m m o n subsequence (abbrev ia ted LCS) of string A and B if C is a c o m m o n subsequence of A and B of maximal length , i .e. there is no c o m m o n subsequence of A and B that has grea te r length. Th roughou t this paper , we assume that A and B are strings of lengths m and n , m _< n , that have an LCS C of (unknown) length p . We assume that the symbols that may appea r in these strings c o m e f rom some a lphabet of size t . A symbol can be s tored in m e m o r y by using log t bits, which we assume will fit in one word of memory . Symbols can be c o m p a r e d (a -< b?) in one t ime unit . The n u m b e r of di f ferent symbols that actual ly appear in string B is def ined to be s (which must be less than n and t). The longest c o m m o n s u b s e q u e n c e prob lem has been solved by using a recurs ion re la t ionship on the length of the solut ion [7, 12, 16, 21]. These are general ly appl icable a lgor i thms that take O ( m n ) t ime for any input strings o f lengths m and n even though the lower bound on t ime of O ( m n ) need not apply to all inputs [2]. We present a lgor i thms that , depend ing on the na ture of the Input, may not requ i re quadra t ic t ime to r ecove r an LCS. The first a lgor i thm is appl icable in the genera l case and requi res O ( p n + n log n) t ime. T h e second a lgor i thm requi res t ime b o u n d e d by O((m + 1 p )p log n). In the c o m m o n special case where p is close to m , this a lgor i thm takes t ime",1977.0,23.0,817.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/322033.322044', 'status': None}","{'volume': '24', 'pages': '664-675', 'name': 'J. ACM'}","{'bibtex': '@Article{Hirschberg1977AlgorithmsFT,\n author = {D. Hirschberg},\n journal = {J. ACM},\n pages = {664-675},\n title = {Algorithms for the Longest Common Subsequence Problem},\n volume = {24},\n year = {1977}\n}\n'}","[{'authorId': '2561382', 'name': 'D. Hirschberg'}]"
1271,6b84e730bfc174f7a02b15c0c16f2a75f609a1bb,Computational models of emotion,"Recent years have seen a significant expansion in research on computational models of human emotional processes, driven both by their potential for basic research on emotion and cognition as well as their promise for an ever-increasing range of applications. This has led to a truly interdisciplinary, mutually beneficial partnership between emotion research in psychology and in computational science, of which this volume is an exemplar. To understand this partnership and its potential for transforming existing practices in emotion research across disciplines and for disclosing important novel areas of research, we explore in this chapter the history of work in computational models of emotion including the various uses to which they have been put, the theoretical traditions that have shaped their development, and how these uses and traditions are reflected in their underlying architectures. For an outsider to the field, the last 15 years have seen the development of a seemingly bewildering array of competing and complementary computational models. Figure 1.2.1 lists a ‘family tree’ of a few of the significant models and the theoretical traditions from which they stem. Although there has been a proliferation of work, the field is far from mature: the goals that a model is designed to achieve are not always clearly articulated; research is rarely incremental, more often returning to motivating theories rather than extending prior computational approaches; and rarely are models contrasted with each other in terms of their ability to achieve their set goals. Contributing to potential confusion is the reality that computational models are complex systems embodying a number of, sometimes unarticulated, design decisions and assumptions inherited from the psychological and computational traditions from which they emerged, a circumstance made worse by the lack of a commonly accepted lexicon even for designating these distinctions. In this chapter, we lay out the work on computational models of emotion in an attempt to reveal the common uses to which they may be put and the underlying techniques and assumptions from which the models are built. Our aim is to present conceptual distinctions and common terminology that can aid in discussion and comparison of competing models. Our hope is that this will not only facilitate an understanding of the field for outside researchers but work towards a lexicon that can help foster the maturity of the field towards more incremental research. In characterizing different computational models of emotion, we begin by describing interdisciplinary uses to which computational models may be put, including their uses in improving human–computer interaction, in enhancing general models of intelligence, and as methodological tools for furthering our understanding of human behaviour. We next discuss how models have been built, including the underlying theoretical traditions that have shaped their development. These differing theoretical perspectives often conceptualize emotion in quite different ways, emphasizing different scenarios and proposed functions, different component processes, and different linkages between these components. It should then come as no surprise that such",2010.0,113.0,394.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Marsella2010ComputationalMO,\n author = {S. Marsella and J. Gratch and P. Petta},\n title = {Computational models of emotion},\n year = {2010}\n}\n'}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1764052', 'name': 'P. Petta'}]"
1272,6b87cf6aaa8cc69123bc82698be6247f246e5326,An Affective Agent Playing Tic-Tac-Toe as Part of a Healing Environment,,2009.0,28.0,3.0,False,,{'pages': '33-47'},"{'bibtex': '@Inproceedings{Pontier2009AnAA,\n author = {M. Pontier and G. F. Siddiqui},\n pages = {33-47},\n title = {An Affective Agent Playing Tic-Tac-Toe as Part of a Healing Environment},\n year = {2009}\n}\n'}","[{'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}]"
1273,6b8df26dc31cbb7d64a31083b8b307ab2e0a6207,Intrapersonal dependencies in multimodal behavior,"Human interlocutors automatically adapt verbal and non-verbal signals so that different behaviors become synchronized over time. Multimodal communication comes naturally to humans, while this is not the case for Embodied Conversational Agents (ECAs). Knowing which behavioral channels synchronize within and across speakers and how they align seems critical in the development of ECAs. Yet, there exists little data-driven research that provides guidelines for the synchronization of different channels within an interlocutor. This study focuses on intrapersonal dependencies of multimodal behavior by using cross-recurrence analysis on a multimodal communication dataset to better understand the temporal relationships between language and gestural behavior channels. By shedding light on the intrapersonal synchronization of communicative channels in humans, we provide an initial manual for modality synchronisation in ECAs.",2020.0,50.0,3.0,False,,{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Blomsma2020IntrapersonalDI,\n author = {P. A. Blomsma and Guido M. Linders and Julija Vaitonyte and M. Louwerse},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Intrapersonal dependencies in multimodal behavior},\n year = {2020}\n}\n'}","[{'authorId': '1394735166', 'name': 'P. A. Blomsma'}, {'authorId': '50816019', 'name': 'Guido M. Linders'}, {'authorId': '51211594', 'name': 'Julija Vaitonyte'}, {'authorId': '2073332', 'name': 'M. Louwerse'}]"
1274,6bb1c473507ac38923b42b2c7d4ba765327ee88a,Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy.,,2001.0,44.0,571.0,False,,"{'volume': '40 2', 'pages': '\n          129-41\n        ', 'name': 'International journal of psychophysiology : official journal of the International Organization of Psychophysiology'}","{'bibtex': '@Article{Hess2001FacialMA,\n author = {U. Hess and S. Blairy},\n journal = {International journal of psychophysiology : official journal of the International Organization of Psychophysiology},\n pages = {\n          129-41\n        },\n title = {Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy.},\n volume = {40 2},\n year = {2001}\n}\n'}","[{'authorId': '3067657', 'name': 'U. Hess'}, {'authorId': '50716507', 'name': 'S. Blairy'}]"
1276,6bdacaf992b0394cc73ff94fcbf6b31483406286,A Flexible New Technique for Camera Calibration,"We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.",2000.0,28.0,13100.0,False,,"{'volume': '22', 'pages': '1330-1334', 'name': 'IEEE Trans. Pattern Anal. Mach. Intell.'}","{'bibtex': '@Article{Zhang2000AFN,\n author = {Zhengyou Zhang},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {1330-1334},\n title = {A Flexible New Technique for Camera Calibration},\n volume = {22},\n year = {2000}\n}\n'}","[{'authorId': '51064498', 'name': 'Zhengyou Zhang'}]"
1277,6c134a4a6b1aae03decf7f38a23d762d6baed8ad,The Next Step towards a Function Markup Language,,2008.0,31.0,82.0,True,"{'url': 'https://research.utwente.nl/files/232516848/Heylen2008next.pdf', 'status': None}",{'pages': '270-280'},"{'bibtex': '@Inproceedings{Heylen2008TheNS,\n author = {D. Heylen and S. Kopp and S. Marsella and C. Pelachaud and H. Vilhjálmsson},\n pages = {270-280},\n title = {The Next Step towards a Function Markup Language},\n year = {2008}\n}\n'}","[{'authorId': '1678537', 'name': 'D. Heylen'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}]"
1278,6c2b28f9354f667cd5bd07afc0471d8334430da7,A Neural Probabilistic Language Model,"A goal of statistical language modeling is to learn the joint probability function of sequences of words. This is intrinsically difficult because of the curse of dimensionality: we propose to fight it with its own weapons. In the proposed approach one learns simultaneously (1) a distributed representation for each word (i.e. a similarity between words) along with (2) the probability function for word sequences, expressed with these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar to words forming an already seen sentence. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach very significantly improves on a state-of-the-art trigram model.",2003.0,39.0,6981.0,False,,"{'volume': '3', 'pages': '1137-1155', 'name': 'J. Mach. Learn. Res.'}","{'bibtex': '@Article{Bengio2003ANP,\n author = {Yoshua Bengio and Réjean Ducharme and Pascal Vincent and Christian Janvin},\n journal = {J. Mach. Learn. Res.},\n pages = {1137-1155},\n title = {A Neural Probabilistic Language Model},\n volume = {3},\n year = {2003}\n}\n'}","[{'authorId': '1751762', 'name': 'Yoshua Bengio'}, {'authorId': '36037226', 'name': 'Réjean Ducharme'}, {'authorId': '120247189', 'name': 'Pascal Vincent'}, {'authorId': '1909943744', 'name': 'Christian Janvin'}]"
1279,6caf0c6ef11b641c283e15652c1d05acbad8d6e4,On the Origins of Human Emotions: A Sociological Inquiry into the Evolution of Human Affect,"Quienes somos y como hemos llegado a ser quienes somos son los eternos enigmas a cuya resolucion se consagran, directa o indirectamente, multiples disciplinas en un intento por resolver una parte del puzzle. J. Turner tambien se embarca a traves de las paginas de la presente obra en esta investigacion concretando la pregunta en un aspecto de nuestra naturaleza, a saber, el social, transformando asi el enigma inicial en como hemos llegado a ser seres sociales. Para responder a ello el presente libro aporta pistas sumamente valiosas en la reconstruccion del puzzle, reparando en una pieza olvidada y al mismo tiempo clave para entender la identidad de los humanos: las emociones, llegando asi a defender la sorprendente y poco frecuente tesis de que las emociones son el fundamento de los lazos sociales en los humanos. On the origins of human emotions trata, pues, de descifrar mediante una historia logica y factible como opero la seleccion para hacer de los humanos los animales mas emocionales que existen sobre la tierra.1 Para ello J. Turner, profesor de sociologia de las emociones en la Universidad de California (Riverside), realiza un recorrido interdisciplinar, sin por ello abandonar su enfoque sociologico, con el fin de anclar su tesis en distintos puertos intelectuales, mostrando asi, como el mismo senala, que la trasgresion de estas fronteras en el conocimiento se perfila cada vez mas necesaria en cualquier estudio del ser humano. Asi, con el fin de entender mejor la dinamica de las emociones en las relaciones humanas desde una perspectiva sociologica y evolucionista, J. Turner elabora un argumento original y riguroso, transportandonos al comienzodenuestra historia como especie. Para el autor se hace evidente, siendo este el punto central de toda su argumentacion, que la capacidad emocional fue la manera mas eficaz que tuvo la evolucion para garantizar nuestra supervivencia; y esto",2000.0,0.0,251.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Turner2000OnTO,\n author = {J. Turner},\n title = {On the Origins of Human Emotions: A Sociological Inquiry into the Evolution of Human Affect},\n year = {2000}\n}\n'}","[{'authorId': '118688586', 'name': 'J. Turner'}]"
1280,6d067a072b9cf8f226eabca90d7bb1d93867a8f6,The chameleon effect: the perception-behavior link and social interaction.,"The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception-behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, & L. Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people.",1999.0,110.0,3950.0,False,,"{'volume': '76 6', 'pages': '\n          893-910\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Chartrand1999TheCE,\n author = {T. Chartrand and J. Bargh},\n journal = {Journal of personality and social psychology},\n pages = {\n          893-910\n        },\n title = {The chameleon effect: the perception-behavior link and social interaction.},\n volume = {76 6},\n year = {1999}\n}\n'}","[{'authorId': '6026289', 'name': 'T. Chartrand'}, {'authorId': '2536558', 'name': 'J. Bargh'}]"
1284,6d624ea0367fdaa0cf8c7810615f404633630358,"Emotion in the perspective of an integrated nervous system
 1
 Published on the World Wide Web on 27 January 1998.
 
 
 1
 
",,1998.0,19.0,458.0,False,,"{'volume': '26', 'pages': '83-86', 'name': 'Brain Research Reviews'}","{'bibtex': '@Article{Damasio1998EmotionIT,\n author = {A. Damasio},\n journal = {Brain Research Reviews},\n pages = {83-86},\n title = {Emotion in the perspective of an integrated nervous system\n 1\n Published on the World Wide Web on 27 January 1998.\n \n \n 1\n \n},\n volume = {26},\n year = {1998}\n}\n'}","[{'authorId': '2656777', 'name': 'A. Damasio'}]"
1285,6d7151e1fec4891917118247b899eeaba51ef3c2,The TaSSt: Tactile sleeve for social touch,"In this paper we outline the design process of the TaSST (Tactile Sleeve for Social Touch), a touch-sensitive vibrotactile arm sleeve. The TaSST was designed to enable two people to communicate different types of touch over a distance. The touch-sensitive surface of the sleeve consists of a grid of 4×3 sensor compartments filled with conductive wool. Each compartment controls the vibration intensity of a vibration motor, located in a grid of 4×3 motors beneath the touch-sensitive layer. An initial evaluation of the TaSST revealed that it was mainly suitable for communicating protracted (e.g. pressing), and simple (e.g. poking) touches.",2013.0,34.0,105.0,True,"{'url': 'https://research.hva.nl/files/144475/495905_Huisman_et_al.__2013__-_The_TaSST_-_Tactile_Sleeve_for_Social_Touch.pdf', 'status': None}","{'pages': '211-216', 'name': '2013 World Haptics Conference (WHC)'}","{'bibtex': '@Article{Huisman2013TheTT,\n author = {Gijs Huisman and A. D. Frederiks and B. V. Dijk and D. Heylen and B. Kröse},\n journal = {2013 World Haptics Conference (WHC)},\n pages = {211-216},\n title = {The TaSSt: Tactile sleeve for social touch},\n year = {2013}\n}\n'}","[{'authorId': '145248077', 'name': 'Gijs Huisman'}, {'authorId': '2607514', 'name': 'A. D. Frederiks'}, {'authorId': '1727902', 'name': 'B. V. Dijk'}, {'authorId': '1678537', 'name': 'D. Heylen'}, {'authorId': '1804676', 'name': 'B. Kröse'}]"
1286,6d75df4360a3d56514dcb775c832fdc572bab64b,Universals and cultural differences in the judgments of facial expressions of emotion.,"We present here new evidence of cross-cultural agreement in the judgement of facial expression. Subjects in 10 cultures performed a more complex judgment task than has been used in previous cross-cultural studies. Instead of limiting the subjects to selecting only one emotion term for each expression, this task allowed them to indicate that multiple emotions were evident and the intensity of each emotion. Agreement was very high across cultures about which emotion was the most intense. The 10 cultures also agreed about the second most intense emotion signaled by an expression and about the relative intensity among expressions of the same emotion. However, cultural differences were found in judgments of the absolute level of emotional intensity.",1987.0,25.0,1609.0,False,,"{'volume': '53 4', 'pages': '\n          712-7\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Ekman1987UniversalsAC,\n author = {P. Ekman and Wallace V. Friesen and Maureen O’Sullivan and Anthony Chan and Irene Diacoyanni-Tarlatzis and K. Heider and R. Krause and W. LeCompte and T. Pitcairn and P. Ricci-Bitti and K. Scherer and M. Tomita and A. Tzavaras},\n journal = {Journal of personality and social psychology},\n pages = {\n          712-7\n        },\n title = {Universals and cultural differences in the judgments of facial expressions of emotion.},\n volume = {53 4},\n year = {1987}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}, {'authorId': '1456140296', 'name': 'Maureen O’Sullivan'}, {'authorId': '2223648361', 'name': 'Anthony Chan'}, {'authorId': '2223647683', 'name': 'Irene Diacoyanni-Tarlatzis'}, {'authorId': '8729784', 'name': 'K. Heider'}, {'authorId': '50392108', 'name': 'R. Krause'}, {'authorId': '5121013', 'name': 'W. LeCompte'}, {'authorId': '4481972', 'name': 'T. Pitcairn'}, {'authorId': '147835851', 'name': 'P. Ricci-Bitti'}, {'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '113860467', 'name': 'M. Tomita'}, {'authorId': '40029778', 'name': 'A. Tzavaras'}]"
1289,6d800d776db1c0a126d2184b90df033dee75ab8d,More than true: Developmental changes in use of the inductive strength for selective trust,"When learning from others, it is important to take a critical stance—evaluating both the informants themselves as well as the content of their claims. In addition to accuracy, one can evaluate claims based on quality. The current study investigates developmental change in learners’ evaluations of evidence that varies in quality—inductive strength based on typicality or diversity. We found that while younger children track which informant provides which examples, they do not have clear preferences for the informant who provides stronger examples. Older children, on the other hand, are in the middle of a developmental transition. They rate informants who provide inductively strong examples as more trustworthy, but only reliably choose the informant who provides diverse examples.",2015.0,18.0,3.0,False,,"{'volume': '', 'name': 'Cognitive Science'}","{'bibtex': '@Article{Landrum2015MoreTT,\n author = {A. Landrum and Joshua Cloudy and Patrick Shafto},\n journal = {Cognitive Science},\n title = {More than true: Developmental changes in use of the inductive strength for selective trust},\n year = {2015}\n}\n'}","[{'authorId': '2895785', 'name': 'A. Landrum'}, {'authorId': '2426641', 'name': 'Joshua Cloudy'}, {'authorId': '3210220', 'name': 'Patrick Shafto'}]"
1290,6d815bfbf2255ee34347fdf9661a3552b235a05a,Improving Social Behaviour in Schizophrenia Patients using an Integrated Virtual Reality Programme: A Case Study,"Social skills training programmes are among the treatments of choice in schizophrenia. Virtual reality (VR) can improve the results obtained with traditional social skills programmes by helping to generalize the acquired responses to patients' daily lives. We present the results of a case study involving the application of an integrated VR programme for social skills training. A 30-year-old woman with a well-established diagnosis of schizophrenia was enrolled in the study. She completed four baseline sessions, 16 treatment sessions and four follow-up sessions three months after the end of the treatment. Using a multiple baseline across-behaviours design, three target behaviours were analysed: facial emotion recognition, social anxiety and conversation time. Symptoms and social function variables were also assessed. The results showed a positive change in the three target behaviours and improvements in interpersonal communication, assertiveness and negative symptoms. The VR programme proved useful for training the patient's social behaviour and, consequently, for improving her performance.",2012.0,8.0,15.0,False,,"{'volume': '181', 'pages': '\n          283-6\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Rus-Calafell2012ImprovingSB,\n author = {M. Rus-Calafell and J. Gutiérrez-Maldonado and J. Ribas-Sabaté},\n journal = {Studies in health technology and informatics},\n pages = {\n          283-6\n        },\n title = {Improving Social Behaviour in Schizophrenia Patients using an Integrated Virtual Reality Programme: A Case Study},\n volume = {181},\n year = {2012}\n}\n'}","[{'authorId': '1404488371', 'name': 'M. Rus-Calafell'}, {'authorId': '1398030059', 'name': 'J. Gutiérrez-Maldonado'}, {'authorId': '1403595798', 'name': 'J. Ribas-Sabaté'}]"
1291,6d8795b5aed51e4951763974cb391047ca94b75b,A dynamic goal adapted task oriented dialogue agent,"Purpose Existing virtual agents (VAs) present in dialogue systems are either information retrieval based or static goal-driven. However, in real-world situations, end-users might not have a known and fixed goal beforehand for the task, i.e., they may upgrade/downgrade/update their goal components in real-time to maximize their utility values. Existing VAs are unable to handle such dynamic goal-oriented situations. Methodology Due to the absence of any related dialogue dataset where such choice deviations are present, we have created a conversational dataset called Deviation adapted Virtual Agent(DevVA), with the manual annotation of its corresponding intents, slots, and sentiment labels. A Dynamic Goal Driven Dialogue Agent (DGDVA) has been developed by incorporating a Dynamic Goal Driven Module (GDM) on top of a deep reinforcement learning based dialogue manager. In the course of a conversation, the user sentiment provides grounded feedback about agent behavior, including goal serving action. User sentiment appears to be an appropriate indicator for goal discrepancy that guides the agent to complete the user’s desired task with gratification. The negative sentiment expressed by the user about an aspect of the provided choice is treated as a discrepancy that is being resolved by the GDM depending upon the observed discrepancy and current dialogue state. The goal update capability and the VA’s interactiveness trait enable end-users to accomplish their desired task satisfactorily. Findings The obtained experimental results illustrate that DGDVA can handle dynamic goals with maximum user satisfaction and a significantly higher success rate. The interaction drives the user to decide its final goal through the latent specification of possible choices and information retrieved and provided by the dialogue agent. Through the experimental results (qualitative and quantitative), we firmly conclude that the proposed sentiment-aware VA adapts users’ dynamic behavior for its goal setting with substantial efficacy in terms of primary objective i.e., task success rate (0.88). Practical implications In real world, it can be argued that many people do not have a predefined and fixed goal for tasks such as online shopping, movie booking & restaurant booking, etc. They tend to explore the available options first which are aligned with their minimum requirements and then decide one amongst them. The DGDVA provides maximum user satisfaction as it enables them to accomplish a dynamic goal that leads to additional utilities along with the essential ones. Originality To the best of our knowledge, this is the first effort towards the development of A Dynamic Goal Adapted Task-Oriented Dialogue Agent that can serve user goals dynamically until the user is satisfied.",2021.0,73.0,9.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0249030&type=printable', 'status': None}","{'volume': '16', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Tiwari2021ADG,\n author = {Abhisek Tiwari and Tulika Saha and S. Saha and Shubhashis Sengupta and Anutosh Maitra and Roshni Ramnani and P. Bhattacharyya},\n journal = {PLoS ONE},\n title = {A dynamic goal adapted task oriented dialogue agent},\n volume = {16},\n year = {2021}\n}\n'}","[{'authorId': '2063522518', 'name': 'Abhisek Tiwari'}, {'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '2062808558', 'name': 'Shubhashis Sengupta'}, {'authorId': '40585053', 'name': 'Anutosh Maitra'}, {'authorId': '3040439', 'name': 'Roshni Ramnani'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
1292,6da8b91ddc4c8c138108ee28b0fc1fb19a2a64d4,A Vocabulary Flood: Making Words “Sticky” With Computer-Response Activities,"Children's literature is a primary source for introducing young children to new words at home and at school, and children's early vocabulary knowledge is a key component of oral language, which is essential for comprehension. This column is focused on children from low socioeconomic backgrounds who frequently find themselves in a vocabulary crisis. It describes how computer-related activities may play a role in tackling this problem. Furthermore, this column provides the background, rationale, and steps for using vocabulary flood—a five-day instructional cycle the authors developed that uses computer technologies and related activities.",2007.0,14.0,27.0,False,,"{'volume': '60', 'pages': '582-588', 'name': 'The Reading Teacher'}","{'bibtex': '@Article{Labbo2007AVF,\n author = {L. Labbo and M. W. Love and Tammy Ryan},\n journal = {The Reading Teacher},\n pages = {582-588},\n title = {A Vocabulary Flood: Making Words “Sticky” With Computer-Response Activities},\n volume = {60},\n year = {2007}\n}\n'}","[{'authorId': '52641148', 'name': 'L. Labbo'}, {'authorId': '66451264', 'name': 'M. W. Love'}, {'authorId': '51437943', 'name': 'Tammy Ryan'}]"
1293,6db2b93a2d4007371030644173f1001c959214d2,Learning to Write with Cooperative Discriminators,"Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory. We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as Grice’s maxims, and are collectively combined with the base RNN generator through a composite decoding objective. Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.",2018.0,57.0,194.0,True,"{'url': 'https://www.aclweb.org/anthology/P18-1152.pdf', 'status': None}","{'volume': 'abs/1805.06087', 'name': 'ArXiv'}","{'bibtex': '@Article{Holtzman2018LearningTW,\n author = {Ari Holtzman and Jan Buys and Maxwell Forbes and Antoine Bosselut and David Golub and Yejin Choi},\n journal = {ArXiv},\n title = {Learning to Write with Cooperative Discriminators},\n volume = {abs/1805.06087},\n year = {2018}\n}\n'}","[{'authorId': '14487640', 'name': 'Ari Holtzman'}, {'authorId': '144685020', 'name': 'Jan Buys'}, {'authorId': '39191185', 'name': 'Maxwell Forbes'}, {'authorId': '2691021', 'name': 'Antoine Bosselut'}, {'authorId': '145798491', 'name': 'David Golub'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]"
1294,6ded9ee35e82f8ccb69ea563b68b8dd0c323a328,Brain Activation during Facial Emotion Processing,"Functional neuroimaging studies have helped identify neural systems involved in cognitive processing and more recently have indicated limbic activation to emotional stimuli. Some functional magnetic resonance imaging (fMRI) studies have reported increased amygdala response during exposure to emotional stimuli while others have not shown such activation. The present study was designed to test the hypothesis that activation of the amygdala is related to the relevance of the emotional valence of stimuli. Healthy young participants (7 men, 7 women) were studied in a high-field (4 tesla) scanner using blood oxygenation-level dependent (BOLD) signal changes in a blocked ""box car"" design. They viewed facial displays of happiness, sadness, anger, fear, and disgust as well as neutral faces obtained from professional actors and actresses of diverse ethnicity and age. Their task alternated between emotion discrimination (indicating whether the emotion was positive or negative) and age discrimination (indicating whether the poser was older or younger than 30). Blocks contained the same proportion of emotional and neutral faces. Limbic response was greater during the emotion than during the age discrimination conditions. The response was most pronounced in the amygdala, but was also present in the hippocampus and circumscribed voxels in other limbic regions. These results support the central role of the amygdala in emotion processing, and indicate its sensitivity to the task relevance of the emotional display.",2002.0,60.0,321.0,False,,"{'volume': '16', 'pages': '651-662', 'name': 'NeuroImage'}","{'bibtex': '@Article{Gur2002BrainAD,\n author = {R. Gur and L. Schroeder and T. Turner and Claire McGrath and Robin M. Chan and B. Turetsky and D. Alsop and J. Maldjian and R. Gur},\n journal = {NeuroImage},\n pages = {651-662},\n title = {Brain Activation during Facial Emotion Processing},\n volume = {16},\n year = {2002}\n}\n'}","[{'authorId': '144762538', 'name': 'R. Gur'}, {'authorId': '2074403489', 'name': 'L. Schroeder'}, {'authorId': '144898011', 'name': 'T. Turner'}, {'authorId': '2060357717', 'name': 'Claire McGrath'}, {'authorId': '32210122', 'name': 'Robin M. Chan'}, {'authorId': '2561467', 'name': 'B. Turetsky'}, {'authorId': '3112570', 'name': 'D. Alsop'}, {'authorId': '2481890', 'name': 'J. Maldjian'}, {'authorId': '2406788', 'name': 'R. Gur'}]"
1295,6e2e9e86bb94e9cf382b0d085da91561df39b1ff,A Practical Guide to Sentiment Annotation: Challenges and Solutions,"Sentences and tweets are often annotated for sentiment simply by asking respondents to label them as positive, negative, or neutral. This works well for simple expressions of sentiment; however, for many other types of sentences, respondents are unsure of how to annotate, and produce inconsistent labels. In this paper, we outline several types of sentences that are particularly challenging for manual sentiment annotation. Next we propose two annotation schemes that address these challenges, and list benefits and limitations for both.",2016.0,15.0,86.0,True,"{'url': 'https://www.aclweb.org/anthology/W16-0429.pdf', 'status': None}",{'pages': '174-179'},"{'bibtex': '@Inproceedings{Mohammad2016APG,\n author = {Saif M. Mohammad},\n pages = {174-179},\n title = {A Practical Guide to Sentiment Annotation: Challenges and Solutions},\n year = {2016}\n}\n'}","[{'authorId': '143880621', 'name': 'Saif M. Mohammad'}]"
1296,6e9d2a77d174f95145a30e6d0b0114d5ffddcd95,Emotion and cognition: insights from studies of the human amygdala.,"Traditional approaches to the study of cognition emphasize an information-processing view that has generally excluded emotion. In contrast, the recent emergence of cognitive neuroscience as an inspiration for understanding human cognition has highlighted its interaction with emotion. This review explores insights into the relations between emotion and cognition that have resulted from studies of the human amygdala. Five topics are explored: emotional learning, emotion and memory, emotion's influence on attention and perception, processing emotion in social stimuli, and changing emotional responses. Investigations into the neural systems underlying human behavior demonstrate that the mechanisms of emotion and cognition are intertwined from early perception to reasoning. These findings suggest that the classic division between the study of emotion and cognition may be unrealistic and that an understanding of human cognition requires the consideration of emotion.",2012.0,148.0,1596.0,False,,"{'volume': '57', 'pages': '\n          27-53\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Phelps2012EmotionAC,\n author = {E. Phelps},\n journal = {Annual review of psychology},\n pages = {\n          27-53\n        },\n title = {Emotion and cognition: insights from studies of the human amygdala.},\n volume = {57},\n year = {2012}\n}\n'}","[{'authorId': '2471431', 'name': 'E. Phelps'}]"
1297,6e9e10b250492d44b807b0d0298cc7a8161bea61,Attitude Modeling for Virtual Character Based on Temporal Sequence Mining: Extraction and Evaluation,"Virtual agents are increasingly being integrated in our everyday life thanks to their communicative skills and abilities to express social affects like emotions and attitudes. The goal of this work is to evaluate the perception of agents expressing interpersonal attitudes through non-verbal behaviors. The interpretation of these behaviors depends on how they are sequenced and coordinated over time. To encompass the sequentiality and the dynamics of non-verbal signals, we rely on temporal sequence mining. From a multimodal corpus, this algorithm produces meaningful sequences resulting in more adapted expression of social attitudes of the agent.",2018.0,41.0,1.0,False,,{'name': 'Proceedings of the 5th International Conference on Movement and Computing'},"{'bibtex': '@Article{Dermouche2018AttitudeMF,\n author = {Soumia Dermouche and C. Pelachaud},\n journal = {Proceedings of the 5th International Conference on Movement and Computing},\n title = {Attitude Modeling for Virtual Character Based on Temporal Sequence Mining: Extraction and Evaluation},\n year = {2018}\n}\n'}","[{'authorId': '8447202', 'name': 'Soumia Dermouche'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1298,6ea74bbce2629136e1ebe2d4bc9ba2913c131130,The relationship between verbal teacher immediacy behaviors and student learning,"Previous research has indicated that nonverbal teacher behaviors such as smiling, vocal expressiveness, movement about the classroom, and relaxed body position are salient low‐inference variables of a process which results in a product of increased cognitive and affective learning. This study identified a set of verbal teacher immediacy behaviors which similarly relate to increased student learning. Results indicated differentiated use of various types of verbal immediacy messages between small and larger classes, and that the impact of teacher immediacy behaviors (both verbal and nonverbal) on learning is coincidentally enhanced as class size increases. The study provides empirical definition of a specific set of low‐inference verbal variables which, in combination with previously identified nonverbal variables, clarify a single process‐product model for effective instructional interaction.",1988.0,16.0,848.0,False,,"{'volume': '37', 'pages': '40-53', 'name': 'Communication Education'}","{'bibtex': '@Article{Gorham1988TheRB,\n author = {J. Gorham},\n journal = {Communication Education},\n pages = {40-53},\n title = {The relationship between verbal teacher immediacy behaviors and student learning},\n volume = {37},\n year = {1988}\n}\n'}","[{'authorId': '47054519', 'name': 'J. Gorham'}]"
1299,6ec802c9a6032391c68c75bf5c7b3d0057c17e31,Identifying Expressions of Emotion in Text,,2007.0,22.0,455.0,False,,{'pages': '196-205'},"{'bibtex': '@Inproceedings{Aman2007IdentifyingEO,\n author = {Saima Aman and S. Szpakowicz},\n pages = {196-205},\n title = {Identifying Expressions of Emotion in Text},\n year = {2007}\n}\n'}","[{'authorId': '145658080', 'name': 'Saima Aman'}, {'authorId': '66114340', 'name': 'S. Szpakowicz'}]"
1300,6ed3deb057d7469959901368a17493e49344e291,Generalized adaptive view-based appearance model: Integrated framework for monocular head pose estimation,"Accurately estimating the person's head position and orientation is an important task for a wide range of applications such as driver awareness and human-robot interaction. Over the past two decades, many approaches have been suggested to solve this problem, each with its own advantages and disadvantages. In this paper, we present a probabilistic framework called generalized adaptive viewbased appearance model (GAVAM) which integrates the advantages from three of these approaches: (1) the automatic initialization and stability of static head pose estimation, (2) the relative precision and user-independence of differential registration, and (3) the robustness and bounded drift of keyframe tracking. In our experiments, we show how the GAVAM model can be used to estimate head position and orientation in real-time using a simple monocular camera. Our experiments on two previously published datasets show that the GAVAM framework can accurately track for a long period of time (>2 minutes) with an average accuracy of 3.5deg and 0.75 in with an inertial sensor and a 3D magnetic sensor.",2008.0,33.0,112.0,True,"{'url': 'http://mplab.ucsd.edu/%7Ejake/gavam.pdf', 'status': None}","{'pages': '1-8', 'name': '2008 8th IEEE International Conference on Automatic Face & Gesture Recognition'}","{'bibtex': '@Article{Morency2008GeneralizedAV,\n author = {Louis-Philippe Morency and J. Whitehill and J. Movellan},\n journal = {2008 8th IEEE International Conference on Automatic Face & Gesture Recognition},\n pages = {1-8},\n title = {Generalized adaptive view-based appearance model: Integrated framework for monocular head pose estimation},\n year = {2008}\n}\n'}","[{'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '143973061', 'name': 'J. Whitehill'}, {'authorId': '1741200', 'name': 'J. Movellan'}]"
1301,6ef28652cc35b3fce218c937315435ee39c59ce9,Computational Modeling of Emotion: Toward Improving the Inter- and Intradisciplinary Exchange,"The past years have seen increasing cooperation between psychology and computer science in the field of computational modeling of emotion. However, to realize its potential, the exchange between the two disciplines, as well as the intradisciplinary coordination, should be further improved. We make three proposals for how this could be achieved. The proposals refer to: 1) systematizing and classifying the assumptions of psychological emotion theories; 2) formalizing emotion theories in implementation-independent formal languages (set theory, agent logics); and 3) modeling emotions using general cognitive architectures (such as Soar and ACT-R), general agent architectures (such as the BDI architecture) or general-purpose affective agent architectures. These proposals share two overarching themes. The first is a proposal for modularization: deconstruct emotion theories into basic assumptions; modularize architectures. The second is a proposal for unification and standardization: Translate different emotion theories into a common informal conceptual system or a formal language, or implement them in a common architecture.",2013.0,236.0,140.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-01130827/file/Reisenzein_12583.pdf', 'status': None}","{'volume': '4', 'pages': '246-266', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Reisenzein2013ComputationalMO,\n author = {R. Reisenzein and E. Hudlicka and M. Dastani and J. Gratch and K. Hindriks and E. Lorini and J. Meyer},\n journal = {IEEE Transactions on Affective Computing},\n pages = {246-266},\n title = {Computational Modeling of Emotion: Toward Improving the Inter- and Intradisciplinary Exchange},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '3213879', 'name': 'R. Reisenzein'}, {'authorId': '2348728', 'name': 'E. Hudlicka'}, {'authorId': '1707738', 'name': 'M. Dastani'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1751831', 'name': 'K. Hindriks'}, {'authorId': '1698475', 'name': 'E. Lorini'}, {'authorId': '1691228', 'name': 'J. Meyer'}]"
1303,6f0ff5d9beb65b490c79cde1c8cafeaa1210fcee,EMBR: A realtime animation engine for interactive embodied agents,,2009.0,19.0,65.0,False,,"{'pages': '1-2', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Héloir2009EMBRAR,\n author = {A. Héloir and Michael Kipp},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-2},\n title = {EMBR: A realtime animation engine for interactive embodied agents},\n year = {2009}\n}\n'}","[{'authorId': '2812935', 'name': 'A. Héloir'}, {'authorId': '145616714', 'name': 'Michael Kipp'}]"
1304,6f522352a3f42333e8eb0820fc95233eecc79baa,Significance of posture and posiion in the communication of attitude and status relationships.,,1969.0,0.0,500.0,False,,"{'volume': '71 5', 'pages': '\n          359-72\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Mehrabian1969SignificanceOP,\n author = {A. Mehrabian},\n journal = {Psychological bulletin},\n pages = {\n          359-72\n        },\n title = {Significance of posture and posiion in the communication of attitude and status relationships.},\n volume = {71 5},\n year = {1969}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}]"
1305,6f6c8098453655cb7ed5ce4e90d64bef8ecaef93,Equilibrium Theory Revisited: Mutual Gaze and Personal Space in Virtual Environments,"During the last half of the twentieth century, psychologists and anthropologists have studied proxemics, or spacing behavior, among people in many contexts. As we enter the twenty-first century, immersive virtual environment technology promises new experimental venues in which researchers can study proxemics. Immersive virtual environments provide realistic and compelling experimental settings without sacrificing experimental control. The experiment reported here tested Argyle and Dean's (1965) equilibrium theory's specification of an inverse relationship between mutual gaze, a nonverbal cue signaling intimacy, and interpersonal distance. Participants were immersed in a three-dimensional virtual room in which a virtual human representation (that is, an embodied agent) stood. Under the guise of a memory task, participants walked towards and around the agent. Distance between the participant and agent was tracked automatically via our immersive virtual environment system. All participants maintained more space around agents than they did around similarly sized and shaped but nonhuman-like objects. Female participants maintained more interpersonal distance between themselves and agents who engaged them in eye contact (that is, mutual gaze behavior) than between themselves and agents who did not engage them in eye contact, whereas male participants did not. Implications are discussed for the study of proxemics via immersive virtual environment technology, as well as the design of virtual environments and virtual humans.",2001.0,68.0,473.0,False,,"{'volume': '10', 'pages': '583-598', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Bailenson2001EquilibriumTR,\n author = {J. Bailenson and Christopher Rex and A. Beall and J. Loomis},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {583-598},\n title = {Equilibrium Theory Revisited: Mutual Gaze and Personal Space in Virtual Environments},\n volume = {10},\n year = {2001}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '1990740', 'name': 'Christopher Rex'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2386187', 'name': 'J. Loomis'}]"
1306,6f737e4da5e91f038685a7c5c96baf8cf21dd841,Affective touch communication in close adult relationships,"Inter-personal touch is a powerful aspect of social interaction that we expect to be particularly important for emotional communication. We studied the capacity of closely acquainted humans to signal the meaning of several word cues (e.g. gratitude, sadness) using touch sensation alone. Participants communicated all cues with above chance performance. We show that emotionally close people can accurately signal the meaning of different words through touch, and that performance is affected by the amount of contextual information available. Even with minimal context and feedback, both attention-getting and love were communicated surprisingly well. Neither the type of close relationship, nor self-reported comfort with touch significantly affected performance.",2019.0,18.0,14.0,True,"{'url': 'https://arxiv.org/pdf/1905.02613', 'status': None}","{'pages': '175-180', 'name': '2019 IEEE World Haptics Conference (WHC)'}","{'bibtex': '@Article{McIntyre2019AffectiveTC,\n author = {S. McIntyre and A. Moungou and Rebecca Boehme and P. Isager and Frances Lau and A. Israr and E. Lumpkin and F. Abnousi and H. Olausson},\n journal = {2019 IEEE World Haptics Conference (WHC)},\n pages = {175-180},\n title = {Affective touch communication in close adult relationships},\n year = {2019}\n}\n'}","[{'authorId': '152197729', 'name': 'S. McIntyre'}, {'authorId': '2613936', 'name': 'A. Moungou'}, {'authorId': '37612752', 'name': 'Rebecca Boehme'}, {'authorId': '35330018', 'name': 'P. Isager'}, {'authorId': '48635416', 'name': 'Frances Lau'}, {'authorId': '1769549', 'name': 'A. Israr'}, {'authorId': '3118889', 'name': 'E. Lumpkin'}, {'authorId': '49092099', 'name': 'F. Abnousi'}, {'authorId': '144819271', 'name': 'H. Olausson'}]"
1307,6f9c548b05b06f86a7c49e2e8eaf1027d4145bdb,Animating cartoon faces by multi-view drawings,"In this paper, we present a novel framework for creating cartoon facial animation from multi-view hand-drawn sketches. The input sketches are first employed to construct a base mesh model by using a hybrid sketch-based method. The model is then deformed for each key viewpoint, yielding a set of models that closely match the corresponding sketches. We introduce a view-dependent facial expression space defined by the key viewpoints and the basic emotions to generate various facial expressions viewed from arbitrary angles. The output facial animation conforms to the input sketches and maintains frame-to-frame correspondence. We demonstrate the potential of our approach through an easy-to-use system, where the animating of cartoon faces is automated once the user accomplishes sketching and configuration. Copyright © 2010 John Wiley & Sons, Ltd. 
 
In this paper, we present a sketch-based framework for the creation of cartoon faces, which are animated depending on both the viewpoints and the emotions. For each basic emotion, the multi-view sketches (a) are employed to construct a view-dependent model (b) that closely matches the input sketches. A view-dependent facial expression space defined by the key viewpoints and the basic emotions is introduced to generate various facial expressions (c) viewed from arbitrary angles.",2010.0,642.0,125.0,False,,"{'volume': '21', 'pages': '193-201', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Li2010AnimatingCF,\n author = {Xiang Li and Jun Xu and Yangchun Ren and Weidong Geng},\n journal = {Computer Animation and Virtual Worlds},\n pages = {193-201},\n title = {Animating cartoon faces by multi-view drawings},\n volume = {21},\n year = {2010}\n}\n'}","[{'authorId': '2144440849', 'name': 'Xiang Li'}, {'authorId': '2150637563', 'name': 'Jun Xu'}, {'authorId': '1690266', 'name': 'Yangchun Ren'}, {'authorId': '2257808072', 'name': 'Weidong Geng'}]"
1308,6fa16f9d4e50a6923b4d0525ffe3057147a2c4d3,Smoothing and differentiation of data by simplified least square procedure.,,1964.0,6.0,16218.0,False,,"{'volume': '44 11', 'pages': '\n          1906-9\n        ', 'name': 'Analytical chemistry'}","{'bibtex': '@Article{Steinier1964SmoothingAD,\n author = {Jean. Steinier and Yves. Termonia and Jules. Deltour},\n journal = {Analytical chemistry},\n pages = {\n          1906-9\n        },\n title = {Smoothing and differentiation of data by simplified least square procedure.},\n volume = {44 11},\n year = {1964}\n}\n'}","[{'authorId': '2253263941', 'name': 'Jean. Steinier'}, {'authorId': '2253276011', 'name': 'Yves. Termonia'}, {'authorId': '2253290223', 'name': 'Jules. Deltour'}]"
1309,6fbbfb23dfc79f69b72c663b928609623e27e86d,Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network,"Real-time emotion recognition (RTER) in conversations is significant for developing emotionally intelligent chatting machines. Without the future context in RTER, it becomes critical to build the memory bank carefully for capturing historical context and summarize the memories appropriately to retrieve relevant information. We propose an Attention Gated Hierarchical Memory Network (AGHMN) to address the problems of prior work: (1) Commonly used convolutional neural networks (CNNs) for utterance feature extraction are less compatible in the memory modules; (2) Unidirectional gated recurrent units (GRUs) only allow each historical utterance to have context before it, preventing information propagation in the opposite direction; (3) The Soft Attention for summarizing loses the positional and ordering information of memories, regardless of how the memory bank is built. Particularly, we propose a Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the utterance reader and a BiGRU fusion layer for the interaction between historical utterances. For memory summarizing, we propose an Attention GRU (AGRU) where we utilize the attention weights to update the internal state of GRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance the contextual information from recent memories and that from distant memories. We conduct experiments on two emotion conversation datasets with extensive analysis, demonstrating the efficacy of our AGHMN models.",2019.0,28.0,84.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/6309/6165', 'status': None}",{'pages': '8002-8009'},"{'bibtex': '@Inproceedings{Jiao2019RealTimeER,\n author = {Wenxiang Jiao and M. Lyu and I. King},\n pages = {8002-8009},\n title = {Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network},\n year = {2019}\n}\n'}","[{'authorId': '12386833', 'name': 'Wenxiang Jiao'}, {'authorId': '145609003', 'name': 'M. Lyu'}, {'authorId': '145310659', 'name': 'I. King'}]"
1310,6fc660745dcbafa5f3f2756bcec5519cecbcad58,Application of Basic Emotions Theory in Construction of Artificial Psychology Model,"According to the basic emotions theory,this paper puts forward a new artificial psychology model.It is believed that people’s general emotions are mixed states of basic emotions and are impacted by “drives” which reflect people’s general emotions theory.This artificial psychology model is constructed based on self-organization,fuzzy and optimization theories.The emotion characters constructed in this model can be changed to generate different personality by adjusting emotion parameters.Computer simulation demonstrates the validity of this model.",2005.0,0.0,8.0,False,,"{'volume': '', 'name': 'Computer Engineering'}","{'bibtex': '@Article{Zhiliang2005ApplicationOB,\n author = {Wang Zhiliang},\n journal = {Computer Engineering},\n title = {Application of Basic Emotions Theory in Construction of Artificial Psychology Model},\n year = {2005}\n}\n'}","[{'authorId': '1934202', 'name': 'Wang Zhiliang'}]"
1311,6ff235fada49d60a7e7d6b4add7d53ae0a97b075,Emotional information processing in mood disorders: a review of behavioral and neuroimaging findings,"Purpose of review A relatively long history of research has shown that mood disorders are associated with abnormalities in the processing of emotional stimuli. Only the most recent studies, however, have begun to elucidate the specificity and neural basis of these abnormalities. This article reviews and discusses the results of these studies. Recent findings Individuals diagnosed with major depressive disorder exhibit an attentional bias toward negative emotional cues (e.g. sad faces), an attentional bias away from positive emotional cues (e.g. happy faces), and an enhanced memory for negative emotional material. Compared with healthy controls, individuals with major depressive disorder show increased neural activity in response to sad faces and diminished neural activity in response to happy faces in emotion-related brain circuits (e.g. amygdala and ventral striatum). Some of these abnormalities in the processing of emotional information persist after symptom remission and they have also been found in healthy individuals who are at heightened risk for the development of mood disorders. Summary The reviewed data show that major depressive disorder involves specific abnormalities in the cognitive and neural processing of emotional information and that these abnormalities may potentially contribute to the vulnerability for negative emotion and onset of depressive episodes.",2006.0,56.0,629.0,False,,"{'volume': '19', 'pages': '34–39', 'name': 'Current Opinion in Psychiatry'}","{'bibtex': '@Article{Leppänen2006EmotionalIP,\n author = {J. Leppänen},\n journal = {Current Opinion in Psychiatry},\n pages = {34–39},\n title = {Emotional information processing in mood disorders: a review of behavioral and neuroimaging findings},\n volume = {19},\n year = {2006}\n}\n'}","[{'authorId': '49764942', 'name': 'J. Leppänen'}]"
1312,6ff61f1ea6d4acfcda1bfd1be5721b44d673e1ed,Deep learning for language understanding of mental health concepts derived from Cognitive Behavioural Therapy,"In recent years, we have seen deep learning and distributed representations of words and sentences make impact on a number of natural language processing tasks, such as similarity, entailment and sentiment analysis. Here we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We define a mental health ontology based on the CBT principles, annotate a large corpus where this phenomena is exhibited and perform understanding using deep learning and distributed representations. Our results show that the performance of deep learning models combined with word embeddings or sentence embeddings significantly outperform non-deep-learning models in this difficult task. This understanding module will be an essential component of a statistical dialogue system delivering therapy.",2018.0,51.0,20.0,True,"{'url': 'https://www.aclweb.org/anthology/W18-5606.pdf', 'status': None}","{'volume': 'abs/1809.00640', 'name': 'ArXiv'}","{'bibtex': '@Article{Rojas-Barahona2018DeepLF,\n author = {L. Rojas-Barahona and Bo-Hsiang Tseng and Yinpei Dai and Clare Mansfield and Osman Ramadan and Stefan Ultes and Michael Crawford and M. Gašić},\n journal = {ArXiv},\n title = {Deep learning for language understanding of mental health concepts derived from Cognitive Behavioural Therapy},\n volume = {abs/1809.00640},\n year = {2018}\n}\n'}","[{'authorId': '1388702112', 'name': 'L. Rojas-Barahona'}, {'authorId': '33870107', 'name': 'Bo-Hsiang Tseng'}, {'authorId': '30087809', 'name': 'Yinpei Dai'}, {'authorId': '80905709', 'name': 'Clare Mansfield'}, {'authorId': '2065760904', 'name': 'Osman Ramadan'}, {'authorId': '2295429', 'name': 'Stefan Ultes'}, {'authorId': '2114765392', 'name': 'Michael Crawford'}, {'authorId': '51175233', 'name': 'M. Gašić'}]"
1313,6ffb361144360de3271a9453dc034a721dca8ad5,An Introduction to Cognitive Architectures for Modeling and Simulation,"Randolph M. Jones Soar Technology, Inc. and Colby College rjones@soartech.com ABSTRACT Increasingly, across the broad spectrum of modeling and simulation, as well as in battlefield information and control systems, autonomous reasoning ability is required, and the “intelligence” developed and tested in simulation is migrating to real -world entities. Cognitive and agent architectures represent maturing computational approaches t o intelligence that can provide robust, scalable, and realistic intelligence. This tutorial will provide an introduction to cognitive architectures, concentrating on production system computation. Examples will be presented from the ACT-R, GOMS, and Soar cognitive architectures. Differences and similarities in cognitive modeling and human behavior representation will be discussed. Attendees will also learn to recognize some of the requirements that suggest the need for a cognitive architecture as compar ed to other approaches and be better able to assess risks, costs, and benefits of different approaches. ABOUT THE AUTHOR Randolph M. Jones , PhD is Chief Scientist at Soar Technology, Inc. and Assistant Professor of Computer Science at Colby College. He has been principal investigator for a variety of Soar Technology’s advanced R&D projects funded by ONR, ARI, DMSO, DARPA and other DOD agencies. He has previously held research positions at the University of Michigan, the University of Pittsburgh, and Carnegie Mellon University. His general areas of research include computational models of human learning and problem solving, executable psychological models, and automated intelligent actors for training and entertainment systems. He earned a BS in Mathematics and Computer Science at UCLA, and MS (1987) and PhD (1989) degrees from the Department of Information and Computer Science at the University of California, Irvine.",2004.0,8.0,11.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Jones2004AnIT,\n author = {Randolph M. Jones},\n title = {An Introduction to Cognitive Architectures for Modeling and Simulation},\n year = {2004}\n}\n'}","[{'authorId': '153788834', 'name': 'Randolph M. Jones'}]"
1314,7019a847bece32c80f693fcd1a411e577230e46a,An Exploration of Friendships and Socialization for Adolescents with Autism Engaged in Massively Multiplayer Online Role-Playing Games (MMORPG),"A phenomenological study was conducted to investigate the social experiences and perceptions of friendship among three adolescents with an Autism Spectrum Disorder (ASD) engaged in online videogame play in the context of a massively multiplayer online role-playing game (MMORPG). Semi-structured interviews with three participants, diagnosed with ASD between the ages of 16–21 years, yielded four themes that illustrated the social experiences of participants in this study. Emerging themes and participant comments identified in this study parallel those identified in the most recent research literature that has also sought to identify experiences and attributes that may lead to successful interpersonal relationships for individuals identified with ASD. Participants in this study articulated the desire to socialize, interact, and frequently communicate in a virtual environment; challenges with being misunderstood; issues with identification and perceptions of friends; and awareness of rules specific to face-to-face and virtual environments. A review of the current research literature related to adolescents with Autism Spectrum Disorder (ASD) revealed a focus on adolescent social challenges and language development as well as strategies to increase the acquisition of functional social skills. However, there was a notable absence of research on the social and relational impact of the use of virtual environments and online gaming for individuals with ASD. The focus of this study was the examination of the social interactions of adolescents with ASD as they engaged in massively multiplayer online role-playing games (MMORPG). This article begins by providing context for the development of the study rationale through a review of the extant literature on individuals with ASD and participation in virtual environments and online gaming. Next the study’s purpose is connected to the documented social and relational needs of individuals with ASD and the potential of virtual environments and online gaming to meet those needs. A description of the research study and methodology follows along with a summary of results and implications for individuals with ASD. Concluding remarks address the potential implications of an expanded research effort in this area on the postsecondary outcomes of adolescents and young adults with ASD. Autism Spectrum Disorder A defining characteristic of ASD is the lack of appropriate social skills, lack of appropriate responses during a conversation, limited social interactions, low to no maintained friendships or interactions outside of school or work that include phone calls or face-to-face interactions (Cihak, 2011; Seltzer, Greenberg, Floyd, & Hong, 2004). An increasing number of individuals are being diagnosed with ASD. Current estimates indicate that 1:68 individuals have some form of ASD (Center for Disease Control, 2014). This increase in prevalence has lead to revision and refinement in Correspondence concerning this article should be addressed to Jennifer Gallup, 749 Jefferson Ave., Pocatello, ID 83201. E-mail: jgallup321@gmail.com Education and Training in Autism and Developmental Disabilities, 2016, 51(3), 223–237 © Division on Autism and Developmental Disabilities Adolescents with Autism Engaged in Online Gaming / 223 definitions of ASD including these that describe the disorder as: ● A developmental disorder of the human nervous system, (Mintz, Branch, March, & Lerman, 2012) that currently affects 1% of the global population (Charman & Gotham, 2013). ● A developmental disorder categorized by deficits in social interactions and communication skills as well as the presence of stereotypic and repetitive behaviors (American Psychiatric Association, 2013). ● A complex disorder (Schafer et al., 2013) with the degree of challenge individualized and specific to each person – with severity ranging from mild to severe impairment (National Institute of Mental Health, 2012). In addition to social challenges, individuals with ASD also experience challenges with awareness and emotional recognition that leads to debility of self (Duff & Flattery, 2014). Unaware of how others think and perceive them, individuals with ASD have ever-present difficulties with socialization that often result in social rejection, that follows them throughout their lives, resulting in barriers and challenges in education, postsecondary education, and other aspects of daily living (Carrington, Papinczak, & Templeton, 2003). The purpose of this study was to (1) describe the social interactions of adolescents with ASD in the context of a virtual environment, (2) identify if they are socializing, and (3) describe how they socialized and related information pertaining to their daily living. Absence of Interventions for Adolescents and Young Adults with ASD As early as elementary school, educators and other practitioners attempt to remediate social skill difficulties in individuals with ASD. Much of the current research focuses on the impact of early intervention, through techniques such as Discrete Trial Training, for basic communication skills. The National Professional Development Center (2014) and National Research Council have identified 27 evidence-based practices used to support social and behavioral challenges for individuals with ASD. Of the 27, 19 have been evidence based for adolescents and 11 for young adults with ASD up to the age of 22 years. However, these strategies have not proven to be as successful in helping adolescents and young adults with high functioning ASD engage with peers, learn complex communication, and achieve transition post-high school (Schall & McDonough, 2010). Although childhood research is valuable, research on social skill and communication development beyond this period has been neglected (Schall & McDonough, 2010). Few studies discuss the need to reach adolescents; and even fewer studies have targeted those with high functioning autism as defined by the DSM-V (2014) who would require level one support. Social and Relational Deficits Adolescents with ASD have social and relational deficits that differ dramatically from students with other disabilities. Adolescents with ASD are significantly more likely to never see friends outside of school (43.3%), never get called by friends (54.4%), and never be invited to activities (50.4%) “when compared to those with other disabilities such as intellectual disabilities, speech and language impairment, or learning disabilities” (Shattuck, Orsmond, Wagner, & Cooper, 2011, p. 5). In addition, adolescents with ASD are less likely to participate in social activities with friends, or community activities with peers than those in other disability categories (Shattuck et al., 2011). Social challenges remain problematic through adulthood affecting their postsecondary transitions to college and careers (Church, Alisanski, & Amanullah, 2000). For example, nearly 85% of individuals with ASD live with a family member (NLTS-2 W-5, 2009), only 54% graduate high school (Shattuck et al., 2011) and as a result only 13% go onto postsecondary education, which contributes to having the lowest average wage amongst all other disability categories at $8.70/hr (Wei et al., 2013). Transition to Adulthood A large population of individuals with ASD is maturing into adolescence and adulthood; however, there exists a paucity of research on 224 / Education and Training in Autism and Developmental Disabilities-September 2016 postsecondary supports and interventions to support success in postsecondary settings (Shattuck et al., 2011). Due to their unique characteristics, individuals with ASD often possess strengths in the area of complex problem solving, attention to detail, the ability to hyper focus on a given task, conceptualization of solutions to often complex problems, and are often high achieving in the areas of science, technology, engineering, and mathematics (STEM) (Baron-Cohen, Wheelwright, Burtenshaw, & Hobson, 2007; Fessenden, 2013; Shattuck et al., 2011; Wei et al., 2013). Adolescents and young adults with ASD choose majors in STEM at a much higher rate than their typically developing peers, yet fail to achieve commensurate with their peers (Wei et al., 2013). As a result of the persistent deficit in social communication and interactions within a group, individuals with ASD hold the third lowest matriculation rate to college and are the lowest of all diverse populations in the area of STEM. Science, Technology, Engineering, and Mathematics Predisposed to experience persistent challenges in social skill and soft skill development, individuals with ASD possess a high level of interest and hold the potential to contribute to future science breakthroughs in STEM (Grandin, 2012). However, reports on postsecondary outcomes for individuals with ASD indicate these students have the third lowest matriculation rate (into college) and as a result, are chronically underrepresented in STEM careers (Wei et al., 2013). Many of the characteristics of ASD that often present challenges in social situations can benefits students with ASD in STEM areas. For example, their ability to hyper focus on a specific analytical task and critically and systematically conceptualize solutions to complex problems (Wei et al., 2013) all can enhance their acquisition of STEM knowledge. Despite their demonstrated aptitude for STEM fields, individuals with ASD are not being assimilated into STEM professions (Grandin, 2012). Postsecondary outcomes for individuals with ASD remain grim (Shattuck et al., 2012). One contributing factor in poor postsecondary outcomes is a persistent deficit in social skills that impedes the ability of adolescents with ASD to socially connect and develop supportive friendships; a highly desirable soft skill that predicates success in securing and maintaining employment (Alpern & Zager, 2007; Baron-Cohen et al., 2007; Fessenden, 2013; Wei et al., 2013). Soft skills are necessary to su",2016.0,49.0,22.0,False,,"{'volume': '51', 'pages': '223-237', 'name': 'Education and training in autism and developmental disabilities'}","{'bibtex': '@Article{Gallup2016AnEO,\n author = {Jennifer L. Gallup and C. Duff and Barbara A. Serianni and Adam Gallup},\n journal = {Education and training in autism and developmental disabilities},\n pages = {223-237},\n title = {An Exploration of Friendships and Socialization for Adolescents with Autism Engaged in Massively Multiplayer Online Role-Playing Games (MMORPG)},\n volume = {51},\n year = {2016}\n}\n'}","[{'authorId': '83458713', 'name': 'Jennifer L. Gallup'}, {'authorId': '145418887', 'name': 'C. Duff'}, {'authorId': '69023145', 'name': 'Barbara A. Serianni'}, {'authorId': '117057305', 'name': 'Adam Gallup'}]"
1315,70593a5a6c9607c73fc44c7b16640ed50786042d,A Virtual Agent as Vocabulary Trainer: Iconic Gestures Help to Improve Learners' Memory Performance,,2013.0,20.0,48.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/2610732/2628750', 'status': None}",{'pages': '139-148'},"{'bibtex': ""@Inproceedings{Bergmann2013AVA,\n author = {K. Bergmann and M. Macedonia},\n pages = {139-148},\n title = {A Virtual Agent as Vocabulary Trainer: Iconic Gestures Help to Improve Learners' Memory Performance},\n year = {2013}\n}\n""}","[{'authorId': '2025591', 'name': 'K. Bergmann'}, {'authorId': '2747728', 'name': 'M. Macedonia'}]"
1316,7066dfda88fbd0ecc803753ca41fb28c176bde44,TSI-Enhanced Pedagogical Agents to Engage Learners in Virtual Worlds,"Building pedagogical applications in virtual worlds is a multi-disciplinary endeavor that involves learning theories, application development framework, and mediated communication theories. This paper presents a project that integrates game-based learning, multi-agent system architecture (MAS), and the theory of Transformed Social Interaction (TSI), The project implements a group of engaging, affectionate and effective pedagogical agents equipped with abilities of selfrepresentation, emotional states reasoning and situational awareness. A prototype of a virtual quiz show, QuizMASter, has been implemented to realize these abilities, and will be used to test for the effectiveness of the approach. Keywordsvirtual quiz games, pedagogical agent, transformed social interaction(TSI) theory, BDI agent, multiagent systems.",2013.0,29.0,18.0,False,,"{'volume': '11', 'pages': '1-13', 'name': 'Int. J. Distance Educ. Technol.'}","{'bibtex': '@Article{Leung2013TSIEnhancedPA,\n author = {Steve Leung and Sandeep Virwaney and F. Lin and A. J. Armstrong and Adien Dubbelboer},\n journal = {Int. J. Distance Educ. Technol.},\n pages = {1-13},\n title = {TSI-Enhanced Pedagogical Agents to Engage Learners in Virtual Worlds},\n volume = {11},\n year = {2013}\n}\n'}","[{'authorId': '2052862892', 'name': 'Steve Leung'}, {'authorId': '3261352', 'name': 'Sandeep Virwaney'}, {'authorId': '1757617', 'name': 'F. Lin'}, {'authorId': '153280757', 'name': 'A. J. Armstrong'}, {'authorId': '2004143', 'name': 'Adien Dubbelboer'}]"
1317,707c4efd5452de0ef4f3806f8f90529b41f995bd,An Introduction to MultiAgent Systems,,2003.0,0.0,4022.0,False,,"{'volume': '17', 'pages': '58-', 'name': 'Künstliche Intell.'}","{'bibtex': '@Article{Messing2003AnIT,\n author = {Barbara Messing},\n journal = {Künstliche Intell.},\n pages = {58-},\n title = {An Introduction to MultiAgent Systems},\n volume = {17},\n year = {2003}\n}\n'}","[{'authorId': '2059684142', 'name': 'Barbara Messing'}]"
1319,70b7ba7423778df1e80a820b83af68cda41978e1,Towards a Dyadic Computational Model of Rapport Management for Human-Virtual Agent Interaction,,2014.0,40.0,122.0,False,,{'pages': '514-527'},"{'bibtex': '@Inproceedings{Zhao2014TowardsAD,\n author = {Ran Zhao and A. Papangelis and Justine Cassell},\n pages = {514-527},\n title = {Towards a Dyadic Computational Model of Rapport Management for Human-Virtual Agent Interaction},\n year = {2014}\n}\n'}","[{'authorId': '2114012102', 'name': 'Ran Zhao'}, {'authorId': '1710287', 'name': 'A. Papangelis'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
1321,70bf86727af633e0dcad2a9b4259f2de94af8b3c,What is user engagement? A conceptual framework for defining user engagement with technology,"The purpose of this article is to critically deconstruct the term engagement as it applies to peoples' experiences with technology. Through an extensive, critical multidisciplinary literature review and exploratory study of users of Web searching, online shopping, Webcasting, and gaming applications, we conceptually and operationally defined engagement. Building on past research, we conducted semistructured interviews with the users of four applications to explore their perception of being engaged with the technology. Results indicate that engagement is a process comprised of four distinct stages: point of engagement, period of sustained engagement, disengagement, and reengagement. Furthermore, the process is characterized by attributes of engagement that pertain to the user, the system, and user-system interaction. We also found evidence of the factors that contribute to nonengagement. Emerging from this research is a definition of engagement—a term not defined consistently in past work—as a quality of user experience characterized by attributes of challenge, positive affect, endurability, aesthetic and sensory appeal, attention, feedback, variety-novelty, interactivity, and perceived user control. This exploratory work provides the foundation for future work to test the conceptual model in various application areas, and to develop methods to measure engaging user experiences. © 2008 Wiley Periodicals, Inc.",2008.0,69.0,1396.0,True,"{'url': 'http://eprints.whiterose.ac.uk/78832/6/WRRO_78832.pdf', 'status': None}","{'volume': '59', 'pages': '938-955', 'name': 'J. Assoc. Inf. Sci. Technol.'}","{'bibtex': ""@Article{O'Brien2008WhatIU,\n author = {H. O'Brien and Elaine Toms},\n journal = {J. Assoc. Inf. Sci. Technol.},\n pages = {938-955},\n title = {What is user engagement? A conceptual framework for defining user engagement with technology},\n volume = {59},\n year = {2008}\n}\n""}","[{'authorId': '1398075881', 'name': ""H. O'Brien""}, {'authorId': '144409084', 'name': 'Elaine Toms'}]"
1322,71054b3a96ca9feb4753749fabbe697145c0fdcf,"Interactivity in human–computer interaction: a study of credibility, understanding, and influence",,2000.0,45.0,352.0,False,,"{'volume': '16', 'pages': '553-574', 'name': ''}","{'bibtex': '@Inproceedings{Burgoon2000InteractivityIH,\n author = {J. Burgoon and J. Bonito and Bjorn Bengtsson and C. Cederberg and M. Lundeberg and L. Allspach},\n pages = {553-574},\n title = {Interactivity in human–computer interaction: a study of credibility, understanding, and influence},\n volume = {16},\n year = {2000}\n}\n'}","[{'authorId': '2896960', 'name': 'J. Burgoon'}, {'authorId': '3061342', 'name': 'J. Bonito'}, {'authorId': '118258992', 'name': 'Bjorn Bengtsson'}, {'authorId': '12830628', 'name': 'C. Cederberg'}, {'authorId': '3478732', 'name': 'M. Lundeberg'}, {'authorId': '116526038', 'name': 'L. Allspach'}]"
1323,7133faf529e2ced7a2a69615ab048e148ba5cef3,Emotional expression in upside-down faces: evidence for configurational and componential processing.,"In two experiments, a total of 126 subjects judged the seven emotional expressions of Ekman & Friesen's (1976) pictures of facial affect presented upright or inverted. Inversion reduced accuracy for sad, fear, anger and disgust, and sad was identified as neutral. However, happy was identified almost perfectly on upright and inverted faces, and both anger and disgust were identified significantly often on inverted faces. In addition, the classic confusions between surprise and fear and between disgust and anger occurred on both upright and inverted faces. It is argued that expressions are difficult to identify on inverted faces when they are based on configural information. However, accurate performance on inverted faces and similar confusions on upright and inverted faces are due to componential processing.",1995.0,0.0,169.0,False,,"{'volume': '34 ( Pt 3)', 'pages': '\n          325-34\n        ', 'name': 'The British journal of social psychology'}","{'bibtex': '@Article{McKelvie1995EmotionalEI,\n author = {S. McKelvie},\n journal = {The British journal of social psychology},\n pages = {\n          325-34\n        },\n title = {Emotional expression in upside-down faces: evidence for configurational and componential processing.},\n volume = {34 ( Pt 3)},\n year = {1995}\n}\n'}","[{'authorId': '145639166', 'name': 'S. McKelvie'}]"
1324,713d3dc68aa8e44567ef8d89e36e82281151e0ae,Evaluating Children's Interactive Products: Principles and Practices for Interaction Designers,,2008.0,130.0,246.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Markopoulos2008EvaluatingCI,\n author = {P. Markopoulos and J. Read and S. MacFarlane and Johanna Höysniemi},\n title = {Evaluating Children's Interactive Products: Principles and Practices for Interaction Designers},\n year = {2008}\n}\n""}","[{'authorId': '1753368', 'name': 'P. Markopoulos'}, {'authorId': '1743424', 'name': 'J. Read'}, {'authorId': '39865435', 'name': 'S. MacFarlane'}, {'authorId': '1756065', 'name': 'Johanna Höysniemi'}]"
1325,7142b58e2b74991b4b4090180648b4cf98426f44,"The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion","Two experiments focused on nonverbal mirroring in a group discussion. In Experiment 1, each participant interacted with two confederates. Confederates disagreed with each other and with the participant during discussion. One confederate mirrored the nonverbal behavior of the participant; the other did not. Participants rated the imitating confederate as more confident and persuasive. However, they were not more likely to change their viewpoint to match that of this confederate. Independent coders, unaware of the hypotheses, did not rate the two confederates as significantly different. In Experiment 2, each participant again interacted with two confederates. One confederate agreed with the participant during the discussion, and the other disagreed. One confederate rubbed his or her face during the discussion. The other shook his or her foot. The hypothesis that participants would be more likely to mirror the nonverbal behavior of the confederate who agreed with them during discussion received no support.",2003.0,30.0,58.0,False,,"{'volume': '30', 'pages': '461-480', 'name': 'Commun. Res.'}","{'bibtex': '@Article{Swol2003TheEO,\n author = {L. M. Swol},\n journal = {Commun. Res.},\n pages = {461-480},\n title = {The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion},\n volume = {30},\n year = {2003}\n}\n'}","[{'authorId': '4931453', 'name': 'L. M. Swol'}]"
1326,7176ab988d90a6297ed8539f82b54bce5bebbfc3,"On the Role of Personality and Empathy in Human-Human, Human-Agent, and Human-Robot Mimicry",,2020.0,44.0,7.0,False,,{'pages': '120-131'},"{'bibtex': '@Inproceedings{Perugia2020OnTR,\n author = {G. Perugia and Maike Paetzel and Ginevra Castellano},\n pages = {120-131},\n title = {On the Role of Personality and Empathy in Human-Human, Human-Agent, and Human-Robot Mimicry},\n year = {2020}\n}\n'}","[{'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '2710492', 'name': 'Maike Paetzel'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
1327,71bfcb2c163f42b03a8ac19cbbf9f0b9e1abd106,Emotion-led modelling for people-oriented requirements engineering: The case study of emergency systems,,2015.0,70.0,90.0,True,"{'url': 'http://minerva-access.unimelb.edu.au/bitstreams/1989f8cb-787e-5226-98cc-31fa83023a84/download', 'status': None}","{'volume': '105', 'pages': '54-71', 'name': 'J. Syst. Softw.'}","{'bibtex': '@Article{Miller2015EmotionledMF,\n author = {Tim Miller and S. Pedell and A. Lopez-Lorca and Antonette Mendoza and L. Sterling and Alen Keirnan},\n journal = {J. Syst. Softw.},\n pages = {54-71},\n title = {Emotion-led modelling for people-oriented requirements engineering: The case study of emergency systems},\n volume = {105},\n year = {2015}\n}\n'}","[{'authorId': '144658641', 'name': 'Tim Miller'}, {'authorId': '3199529', 'name': 'S. Pedell'}, {'authorId': '1401292565', 'name': 'A. Lopez-Lorca'}, {'authorId': '6857534', 'name': 'Antonette Mendoza'}, {'authorId': '145977411', 'name': 'L. Sterling'}, {'authorId': '3011330', 'name': 'Alen Keirnan'}]"
1328,7225c3408bd6f8e80df0aeee9e0167a573ad3c0e,NovA: Automated Analysis of Nonverbal Signals in Social Interactions,,2013.0,39.0,41.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/48446/48446.pdf', 'status': None}",{'pages': '160-171'},"{'bibtex': '@Inproceedings{Baur2013NovAAA,\n author = {Tobias Baur and Ionut Damian and Florian Lingenfelser and J. Wagner and E. André},\n pages = {160-171},\n title = {NovA: Automated Analysis of Nonverbal Signals in Social Interactions},\n year = {2013}\n}\n'}","[{'authorId': '2230836', 'name': 'Tobias Baur'}, {'authorId': '3048626', 'name': 'Ionut Damian'}, {'authorId': '2565410', 'name': 'Florian Lingenfelser'}, {'authorId': '6164138', 'name': 'J. Wagner'}, {'authorId': '1742930', 'name': 'E. André'}]"
1329,724e1943cd21cc41cc517d8367889e28ceb5628a,An approach for a social robot to understand human relationships: Friendship estimation through interaction with robots,"This paper reports our research efforts on social robots that recognize interpersonal relationships. These investigations are carried out by observing group behaviors while the robot interacts with people. Our humanoid robot interacts with children by speaking and making various gestures. It identifies individual children by using a wireless tag system, which helps to promote interaction such as the robot calling a child by name. Accordingly, the robot is capable of interacting with many children, causing spontaneous group behavior from the children around it. Here, group behavior is associated with social relationships among the children themselves. For example, a child may be accompanied by his or her friends and then play together with them. We propose the hypothesis that our interactive robot prompts a child’s friends to accompany him or her; thus, we can estimate their friendship by simply observing their accompanying behaviors.
 
We conducted a field experiment for two weeks in a Japanese elementary school to verify this hypothesis. In the experiment, two “Robovie” robots were placed where children could freely interact with them during recesses. As a result, we found that they mostly prompted friend-accompanying behavior. Moreover, we could estimate some of their friendly relationships, in particular among the children who often appeared around the robot. For example, we could estimate 5% of all friendships with 80% accuracy, and 15% of them with nearly 50% accuracy. Thus, this result basically supports our hypothesis on friendship estimation from an interactive humanoid robot. We believe that this ability to estimate human relationships is essential for robots to behave socially.",2006.0,48.0,18.0,True,"{'url': 'http://www.irc.atr.jp/~kanda/pdf/kanda-IS-friendship-estimation.pdf', 'status': None}","{'volume': '7', 'pages': '369-403', 'name': 'Interaction Studies'}","{'bibtex': '@Article{Kanda2006AnAF,\n author = {T. Kanda and H. Ishiguro},\n journal = {Interaction Studies},\n pages = {369-403},\n title = {An approach for a social robot to understand human relationships: Friendship estimation through interaction with robots},\n volume = {7},\n year = {2006}\n}\n'}","[{'authorId': '48309591', 'name': 'T. Kanda'}, {'authorId': '1687808', 'name': 'H. Ishiguro'}]"
1330,7254ce176d69ac8708217ab84ae34e0cdb10763a,The Output Hypothesis: Theory and Research,,2005.0,0.0,850.0,False,,"{'volume': '', 'pages': '495-508', 'name': ''}","{'bibtex': '@Inproceedings{Swain2005TheOH,\n author = {M. Swain},\n pages = {495-508},\n title = {The Output Hypothesis: Theory and Research},\n year = {2005}\n}\n'}","[{'authorId': '2027127', 'name': 'M. Swain'}]"
1331,726fe9544b2e28133d32bc8fdcd967c1e6f89524,The Role of Body Postures in the Recognition of Emotions in Contextually Rich Scenarios,"In this article the role of different categories of postures in the detection, recognition, and interpretation of emotion in contextually rich scenarios, including ironic items, is investigated. Animated scenarios are designed with 3D virtual agents in order to test 3 conditions: In the “still” condition, the narrative content was accompanied by emotional facial expressions without any body movements; in the “idle” condition, emotionally neutral body movements were introduced; and in the “congruent” condition, emotional body postures congruent with the character's facial expressions were displayed. Those conditions were examined by 27 subjects, and their impact on the viewers’ attentional and emotional processes was assessed. The results highlight the importance of the contextual information to emotion recognition and irony interpretation. It is also shown that both idle and emotional postures improve the detection of emotional expressions. Moreover, emotional postures increase the perceived intensity of emotions and the realism of the animations.",2014.0,61.0,29.0,False,,"{'volume': '30', 'pages': '52 - 62', 'name': 'International Journal of Human–Computer Interaction'}","{'bibtex': '@Article{Buisine2014TheRO,\n author = {S. Buisine and M. Courgeon and Aurélien Charles and C. Clavel and Jean-Claude Martin and Ning Tan and O. Grynszpan},\n journal = {International Journal of Human–Computer Interaction},\n pages = {52 - 62},\n title = {The Role of Body Postures in the Recognition of Emotions in Contextually Rich Scenarios},\n volume = {30},\n year = {2014}\n}\n'}","[{'authorId': '1742939', 'name': 'S. Buisine'}, {'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '2058881883', 'name': 'Aurélien Charles'}, {'authorId': '1724799', 'name': 'C. Clavel'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '2057776275', 'name': 'Ning Tan'}, {'authorId': '2791712', 'name': 'O. Grynszpan'}]"
1332,728b1c6e171a61705e3f552b8b2cbfeb395c7616,A naturalistic study of the meanings of touch,"The present study employed an adapted version of the contextual analysis method developed by Scheflen and others to examine the meanings‐in‐context of touches reported by persons from their daily interactions. The results revealed 12 distinct and relatively unambiguous meanings: support, appreciation, inclusion, sexual interest or intent, affection, playful affection, playful aggression, compliance, attention‐getting, announcing a response, greetings, and departure. There were also several kinds of hybrid meanings, the main ones being greeting/affection and departure/affection, and four categories of potentially ambiguous touches: reference to appearance, instrumental ancillary, instrumental intrinsic, and accidental. Finally, the analysis revealed a number of types of “touch sequences,” patterns of behavior consisting of a series of related touches, which took two primary forms, repetitive sequences and strategic sequences. These results are discussed in terms of three emergent generalizations about the ...",1985.0,26.0,263.0,False,,"{'volume': '52', 'pages': '19-56', 'name': 'Communication Monographs'}","{'bibtex': '@Article{Jones1985ANS,\n author = {Stanley E. Jones and A. Yarbrough},\n journal = {Communication Monographs},\n pages = {19-56},\n title = {A naturalistic study of the meanings of touch},\n volume = {52},\n year = {1985}\n}\n'}","[{'authorId': '2115301525', 'name': 'Stanley E. Jones'}, {'authorId': '31533870', 'name': 'A. Yarbrough'}]"
1333,72bb12707969ce9779c5229b7d3a480a2571471b,"The Independent and Interactive Effects of Embodied-Agent Appearance and Behavior on Self-Report, Cognitive, and Behavioral Markers of Copresence in Immersive Virtual Environments","The current study examined how assessments of copresence in an immersive virtual environment are influenced by variations in how much an embodied agent resembles a human being in appearance and behavior. We measured the extent to which virtual representations were both perceived and treated as if they were human via self-report, behavioral, and cognitive dependent measures. Distinctive patterns of findings emerged with respect to the behavior and appearance of embodied agents depending on the definition and operationalization of copresence. Independent and interactive effects for appearance and behavior were found suggesting that assessing the impact of behavioral realism on copresence without taking into account the appearance of the embodied agent (and vice versa) can lead to misleading conclusions. Consistent with the results of previous research, copresence was lowest when there was a large mismatch between the appearance and behavioral realism of an embodied agent.",2005.0,44.0,366.0,False,,"{'volume': '14', 'pages': '379-393', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Bailenson2005TheIA,\n author = {J. Bailenson and Kimberly R. Swinth and Crystal L. Hoyt and S. Persky and Alex Dimov and J. Blascovich},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {379-393},\n title = {The Independent and Interactive Effects of Embodied-Agent Appearance and Behavior on Self-Report, Cognitive, and Behavioral Markers of Copresence in Immersive Virtual Environments},\n volume = {14},\n year = {2005}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '2396884', 'name': 'Kimberly R. Swinth'}, {'authorId': '32047738', 'name': 'Crystal L. Hoyt'}, {'authorId': '2380439', 'name': 'S. Persky'}, {'authorId': '50403647', 'name': 'Alex Dimov'}, {'authorId': '2307657', 'name': 'J. Blascovich'}]"
1334,72d942abe12e74c521fb7304d359da9b0b70410f,Fear fosters flight: a mechanism for fear contagion when perceiving emotion expressed by a whole body.,"Darwin regarded emotions as predispositions to act adaptively, thereby suggesting that characteristic body movements are associated with each emotional state. To this date, investigations of emotional cognition have predominantly concentrated on processes associated with viewing facial expressions. However, expressive body movements may be just as important for understanding the neurobiology of emotional behavior. Here, we used functional MRI to clarify how the brain recognizes happiness or fear expressed by a whole body. Our results indicate that observing fearful body expressions produces increased activity in brain areas narrowly associated with emotional processes and that this emotion-related activity occurs together with activation of areas linked with representation of action and movement. The mechanism of fear contagion hereby suggested may automatically prepare the brain for action.",2004.0,69.0,450.0,True,"{'url': 'https://europepmc.org/articles/pmc528902?pdf=render', 'status': None}","{'volume': '101 47', 'pages': '\n          16701-6\n        ', 'name': 'Proceedings of the National Academy of Sciences of the United States of America'}","{'bibtex': '@Article{Gelder2004FearFF,\n author = {B. de Gelder and Josh Snyder and Doug Greve and George Gerard and N. Hadjikhani},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {\n          16701-6\n        },\n title = {Fear fosters flight: a mechanism for fear contagion when perceiving emotion expressed by a whole body.},\n volume = {101 47},\n year = {2004}\n}\n'}","[{'authorId': '4628064', 'name': 'B. de Gelder'}, {'authorId': '143809175', 'name': 'Josh Snyder'}, {'authorId': '2064575931', 'name': 'Doug Greve'}, {'authorId': '2076692723', 'name': 'George Gerard'}, {'authorId': '2830760', 'name': 'N. Hadjikhani'}]"
1335,72ec06bf1266836e3b028f4c6896b8f24d39f54f,Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies.,"Emotions are universally recognized from facial expressions--or so it has been claimed. To support that claim, research has been carried out in various modern cultures and in cultures relatively isolated from Western influence. A review of the methods used in that research raises questions of its ecological, convergent, and internal validity. Forced-choice response format, within-subject design, preselected photographs of posed facial expressions, and other features of method are each problematic. When they are altered, less supportive or nonsupportive results occur. When they are combined, these method factors may help to shape the results. Facial expressions and emotion labels are probably associated, but the association may vary with culture and is loose enough to be consistent with various alternative accounts, 8 of which are discussed.",1994.0,195.0,1523.0,False,,"{'volume': '115 1', 'pages': '\n          102-41\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Russell1994IsTU,\n author = {J. Russell},\n journal = {Psychological bulletin},\n pages = {\n          102-41\n        },\n title = {Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies.},\n volume = {115 1},\n year = {1994}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}]"
1336,72ecd8711e0cfaf356c55fcd7a415336cd504db1,Embodiment of an Agent by Anthropomorphization of a Common Object,"We propose a direct anthropomorphization to improve human-agent interaction. It agentizes an artifact by attaching humanoid parts to it. There have been many studies that can provide valuable information on using spoken directions and gestures via anthropomorphic agents such as CG (computer graphics) agents and communication robots. Our method directly anthropomorphizes the artifact through robotic bodily parts shaped like those of humans. An anthropomorphized artifact with these parts can provide information to people by giving them spoken directions and expressing themselves through body language. This makes people pay more attentions to the artifact, than when using anthropomorphic CG or robot agents. We conducted an experiment to verify the difference between receiving an explanation of the functions of the artifact using the direct anthropomorphization method and that from using the independent humanoid agent ""Robovie"". The results from participants' questionnaires and gazes during the experiment indicated that they noticed the target artifact and memorized the functions more quickly and easily from using the direct anthropomorphization method than from the ""Robovie"".",2008.0,23.0,19.0,False,,"{'volume': '2', 'pages': '484-490', 'name': '2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology'}","{'bibtex': '@Article{Osawa2008EmbodimentOA,\n author = {Hirotaka Osawa and Yuji Matsuda and Ren Ohmura and M. Imai},\n journal = {2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},\n pages = {484-490},\n title = {Embodiment of an Agent by Anthropomorphization of a Common Object},\n volume = {2},\n year = {2008}\n}\n'}","[{'authorId': '145978249', 'name': 'Hirotaka Osawa'}, {'authorId': '29348114', 'name': 'Yuji Matsuda'}, {'authorId': '34922599', 'name': 'Ren Ohmura'}, {'authorId': '1752970', 'name': 'M. Imai'}]"
1337,72f463e6a50bc9738a45aea57062b495331f4031,SimSensei kiosk: a virtual human interviewer for healthcare decision support,"We present SimSensei Kiosk, an implemented virtual human interviewer designed to create an engaging face-to-face interaction where the user feels comfortable talking and sharing information. SimSensei Kiosk is also designed to create interactional situations favorable to the automatic assessment of distress indicators, defined as verbal and nonverbal behaviors correlated with depression, anxiety or post-traumatic stress disorder (PTSD). In this paper, we summarize the design methodology, performed over the past two years, which is based on three main development cycles: (1) analysis of face-to-face human interactions to identify potential distress indicators, dialogue policies and virtual human gestures, (2) development and analysis of a Wizard-of-Oz prototype system where two human operators were deciding the spoken and gestural responses, and (3) development of a fully automatic virtual interviewer able to engage users in 15-25 minute interactions. We show the potential of our fully automatic virtual human interviewer in a user study, and situate its performance in relation to the Wizard-of-Oz prototype.",2014.0,40.0,524.0,False,,{'pages': '1061-1068'},"{'bibtex': '@Inproceedings{DeVault2014SimSenseiKA,\n author = {D. DeVault and Ron Artstein and G. Benn and Teresa Dey and Edward Fast and Alesia Gainer and Kallirroi Georgila and J. Gratch and Arno Hartholt and Margot Lhommet and Gale M. Lucas and S. Marsella and Fabrizio Morbini and Angela Nazarian and Stefan Scherer and Giota Stratou and Apar Suri and D. Traum and Rachel Wood and Yuyu Xu and A. Rizzo and Louis-Philippe Morency},\n pages = {1061-1068},\n title = {SimSensei kiosk: a virtual human interviewer for healthcare decision support},\n year = {2014}\n}\n'}","[{'authorId': '144662324', 'name': 'D. DeVault'}, {'authorId': '2038490', 'name': 'Ron Artstein'}, {'authorId': '31624455', 'name': 'G. Benn'}, {'authorId': '2069141814', 'name': 'Teresa Dey'}, {'authorId': '2432742', 'name': 'Edward Fast'}, {'authorId': '49406416', 'name': 'Alesia Gainer'}, {'authorId': '3194430', 'name': 'Kallirroi Georgila'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '1930380', 'name': 'Margot Lhommet'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2223582', 'name': 'Fabrizio Morbini'}, {'authorId': '2551269', 'name': 'Angela Nazarian'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '50562753', 'name': 'Apar Suri'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '2072346682', 'name': 'Rachel Wood'}, {'authorId': '1884967', 'name': 'Yuyu Xu'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
1341,72f5bec99bf961fd8cf3ac2558fad01317ec099d,"Emotion, regulation, and moral development.","Research and theory on the role of emotion and regulation in morality have received considerable attention in the last decade. Much relevant work has concerned the role of moral emotions in moral behavior. Research on differences between embarrassment, guilt, and shame and their relations to moral behavior is reviewed, as is research on the association of these emotions with negative emotionality and regulation. Recent issues concerning the role of such empathy-related responses as sympathy and personal distress to prosocial and antisocial behavior are discussed, as is the relation of empathy-related responding to situational and dispositional emotionality and regulation. The development and socialization of guilt, shame, and empathy also are discussed briefly. In addition, the role of nonmoral emotions (e.g. anger and sadness), including moods and dispositional differences in negative emotionality and its regulation, in morally relevant behavior, is reviewed.",2000.0,188.0,2131.0,False,,"{'volume': '51', 'pages': '\n          665-97\n        ', 'name': 'Annual review of psychology'}","{'bibtex': '@Article{Eisenberg2000EmotionRA,\n author = {N. Eisenberg},\n journal = {Annual review of psychology},\n pages = {\n          665-97\n        },\n title = {Emotion, regulation, and moral development.},\n volume = {51},\n year = {2000}\n}\n'}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}]"
1342,73021441e867b563b7207c91aa768cb6de62b59f,Multiway Contingency Tables Analysis for the Social Sciences,Contents: Introduction. Two-way Tables. Models for Three-Way Tables. The Statistical Basis of Sampling and Testing. Fitting and Testing Models. Testing Specific Hypotheses. Predictor-Outcome Models. Analyzing Unstructured Tables. Measures of Effect Size. Structurally Incomplete Tables. Descriptions of Association. Least-Squares Models. Ordered Categories. Appendices: Percentage Points of the Chi-Square Distribution. Bonferroni Chi-Square. Power Chart for Chi-Square Tests. Percentage Points of the Normal Distribution. Percentage Points of the Largest Root of a Wishart Matrix. The Greek Alphabet.,1989.0,0.0,376.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Wickens1989MultiwayCT,\n author = {T. Wickens},\n title = {Multiway Contingency Tables Analysis for the Social Sciences},\n year = {1989}\n}\n'}","[{'authorId': '3426712', 'name': 'T. Wickens'}]"
1343,73461123840be9cde94e6e5d0cbeca9ecc1d7c09,The effect of negative emotion on multiple object tracking task: An ERP study,,2017.0,33.0,8.0,False,,"{'volume': '641', 'pages': '15-20', 'name': 'Neuroscience Letters'}","{'bibtex': '@Article{Su2017TheEO,\n author = {J. Su and D. Duan and Xuemin Zhang and Huanyu Lei and Chundi Wang and Heng Guo and Xiaoqian Yan},\n journal = {Neuroscience Letters},\n pages = {15-20},\n title = {The effect of negative emotion on multiple object tracking task: An ERP study},\n volume = {641},\n year = {2017}\n}\n'}","[{'authorId': '2116964984', 'name': 'J. Su'}, {'authorId': '4344061', 'name': 'D. Duan'}, {'authorId': '2108069824', 'name': 'Xuemin Zhang'}, {'authorId': '6767169', 'name': 'Huanyu Lei'}, {'authorId': '48585702', 'name': 'Chundi Wang'}, {'authorId': '2110655266', 'name': 'Heng Guo'}, {'authorId': '4765443', 'name': 'Xiaoqian Yan'}]"
1344,73b0ded0ea6704dd0e02a60b4693891ece22d8b2,EUROGRAPHICS 2006 STAR – State of The Art Report Building Expression into Virtual Characters,,,0.0,144.0,False,,,"{'bibtex': '@Misc{None,\n title = {EUROGRAPHICS 2006 STAR – State of The Art Report Building Expression into Virtual Characters}\n}\n'}",[]
1348,73b6587c320f2ccb5cefae6c6eebdde9ad73bb33,A Serious Game using Physiological Interfaces for Emotion regulation Training in the Context of Financial Decision-Making,"Abstract Research on financial decision-making shows that traders and investors with high emotion regulation capabilities perform better in trading. But how can the others learn to regulate their emotions? ‘Learning by doing’ sounds like a straightforward approach. But how can one perform ‘learning by doing’ when there is no feedback? This problem particularly applies to learning emotion regulation, because learners can get practically no feedback on their level of emotion regulation. Our research aims at providing a learning environment that can help decision-makers to improve their emotion regulation. The approach is based on a serious game with real-time biofeedback. The game is settled in a financial context and the decision scenario is directly linked to the individual biofeedback of the learner’s heart rate data. More specifically, depending on the learner’s ability to regulate emotions, the decision scenario of the game continuously adjusts and thereby becomes more (or less) difficult. The learner wears an electrocardiogram sensor that transfers the data via Bluetooth to the game. The game itself is evaluated at several levels. Keywords: Serious Games, Emotion Regulation, Biofeedback.",2012.0,48.0,56.0,False,,{'pages': '207'},"{'bibtex': '@Inproceedings{Jerčić2012ASG,\n author = {Petar Jerčić and Philipp J. Astor and M. Adam and O. Hilborn},\n pages = {207},\n title = {A Serious Game using Physiological Interfaces for Emotion regulation Training in the Context of Financial Decision-Making},\n year = {2012}\n}\n'}","[{'authorId': '2164864', 'name': 'Petar Jerčić'}, {'authorId': '2112197', 'name': 'Philipp J. Astor'}, {'authorId': '24235135', 'name': 'M. Adam'}, {'authorId': '2947508', 'name': 'O. Hilborn'}]"
1349,73bd1e471a222aa14cdfffd769f6a4af84fd2290,"Training Adaptive Emotion Regulation Skills in Early Adolescents: The Effects of Distraction, Acceptance, Cognitive Reappraisal, and Problem Solving",,2019.0,115.0,19.0,False,,"{'volume': '44', 'pages': '678-696', 'name': 'Cognitive Therapy and Research'}","{'bibtex': '@Article{Volkaert2019TrainingAE,\n author = {Brenda Volkaert and Laura Wante and M. Van Beveren and L. Vervoort and C. Braet},\n journal = {Cognitive Therapy and Research},\n pages = {678-696},\n title = {Training Adaptive Emotion Regulation Skills in Early Adolescents: The Effects of Distraction, Acceptance, Cognitive Reappraisal, and Problem Solving},\n volume = {44},\n year = {2019}\n}\n'}","[{'authorId': '2080636017', 'name': 'Brenda Volkaert'}, {'authorId': '4742900', 'name': 'Laura Wante'}, {'authorId': '49147545', 'name': 'M. Van Beveren'}, {'authorId': '47691208', 'name': 'L. Vervoort'}, {'authorId': '3768756', 'name': 'C. Braet'}]"
1350,74093f46bd53222fd7ae1dc7a92030991e76d4d9,Enhancing Our Lives with Immersive Virtual Reality,,2016.0,362.0,834.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2016.00074/pdf', 'status': None}","{'volume': '3', 'pages': '74', 'name': 'Frontiers Robotics AI'}","{'bibtex': '@Article{Slater2016EnhancingOL,\n author = {M. Slater and Maria V. Sanchez-Vives},\n journal = {Frontiers Robotics AI},\n pages = {74},\n title = {Enhancing Our Lives with Immersive Virtual Reality},\n volume = {3},\n year = {2016}\n}\n'}","[{'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '1384107200', 'name': 'Maria V. Sanchez-Vives'}]"
1351,744311d96e757e4f5a05c56031e738501ffb92e8,Progress in Artificial Intelligence,,1995.0,0.0,454.0,False,,{'volume': '990'},"{'bibtex': '@Inproceedings{Steels1995ProgressIA,\n author = {L. Steels and A. Campbell},\n title = {Progress in Artificial Intelligence},\n volume = {990},\n year = {1995}\n}\n'}","[{'authorId': '145091664', 'name': 'L. Steels'}, {'authorId': '145005045', 'name': 'A. Campbell'}]"
1352,7476510064eea3767b66312e5a44ea3de4e62598,Intelligent Agents Who Wear Your Face: Users' Reactions to the Virtual Self,,2001.0,12.0,83.0,False,,{'pages': '86-99'},"{'bibtex': ""@Inproceedings{Bailenson2001IntelligentAW,\n author = {J. Bailenson and A. Beall and J. Blascovich and Mike Raimundo and Max Weisbuch},\n pages = {86-99},\n title = {Intelligent Agents Who Wear Your Face: Users' Reactions to the Virtual Self},\n year = {2001}\n}\n""}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '37975320', 'name': 'Mike Raimundo'}, {'authorId': '3259102', 'name': 'Max Weisbuch'}]"
1353,74b45bcb68590e8387f230f7dd882813432e6336,Art. XXIV.—Test-Types for the Determination of the Acuteness of Vision.,,1863.0,0.0,55.0,True,"{'url': 'https://zenodo.org/record/1641626/files/article.pdf', 'status': None}","{'volume': '44', 'pages': '520', 'name': 'The American Journal of the Medical Sciences'}","{'bibtex': '@Article{Snellen1863ArtXF,\n author = {H. Snellen},\n journal = {The American Journal of the Medical Sciences},\n pages = {520},\n title = {Art. XXIV.—Test-Types for the Determination of the Acuteness of Vision.},\n volume = {44},\n year = {1863}\n}\n'}","[{'authorId': '5375813', 'name': 'H. Snellen'}]"
1354,74b4c51f5d446542b50ce550888be806ab7a221f,Predictors of Adherence by Adolescents to a Cognitive Behavior Therapy Website in School and Community-Based Settings,"Background There have been no previous studies of the variables that predict adherence to online depression and anxiety intervention programs among adolescents. However, research of traditionally delivered intervention programs for a variety of health conditions in adolescence suggests that health knowledge, type and level of symptomatology, race, socioeconomic status, treatment setting, and support may predict adherence. Objective The aim was to compare adherence rates and identify the predictors of adherence to a cognitive behavior therapy website in two adolescent samples that were offered the program in different settings and under different conditions of support. Methods The first adolescent sample consisted of 1000 school students who completed the MoodGYM program in a classroom setting over five weeks as part of a randomized controlled trial. The second sample consisted of 7207 adolescents who accessed the MoodGYM program spontaneously and directly through the open access URL. All users completed a brief survey before the start of the program that measured background characteristics, depression history, symptoms of depression and anxiety, and dysfunctional thinking. Results Adolescents in the school-based sample completed significantly more online exercises (mean = 9.38, SD = 6.84) than adolescents in the open access community sample (mean = 3.10, SD = 3.85; t 1088.62 = −28.39, P < .001). A multiple linear regression revealed that school-based setting (P < .001) and female gender (P < .001) were predictive of greater adherence, as were living in a rural area (P < .001) and lower pre-test anxiety (P = .04) scores for the school-based sample and higher pre-test depression scores (P = .01) for the community sample. A history of depression (P = .33) and pre-test warpy thoughts scores (P = .35) were not predictive of adherence in the school-based or community sample. Conclusion Adherence is greater in monitored settings, and the predictors of adherence differ between settings. Understanding these differences may improve program effectiveness and efficiency.",2009.0,17.0,132.0,True,"{'url': 'https://www.jmir.org/2009/1/e6/PDF', 'status': None}","{'volume': '11', 'name': 'Journal of Medical Internet Research'}","{'bibtex': '@Article{Neil2009PredictorsOA,\n author = {A. Neil and P. Batterham and H. Christensen and Kylie Bennett and K. Griffiths},\n journal = {Journal of Medical Internet Research},\n title = {Predictors of Adherence by Adolescents to a Cognitive Behavior Therapy Website in School and Community-Based Settings},\n volume = {11},\n year = {2009}\n}\n'}","[{'authorId': '31613912', 'name': 'A. Neil'}, {'authorId': '3193868', 'name': 'P. Batterham'}, {'authorId': '144174775', 'name': 'H. Christensen'}, {'authorId': '31742704', 'name': 'Kylie Bennett'}, {'authorId': '4743339', 'name': 'K. Griffiths'}]"
1355,74c9dc1d9c5fe5c5bfc7b2db7d96aad0d00bb0fc,A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents,"Embodied conversational agents (ECAs) benefit from non-verbal behavior for natural and efficient interaction with users. Gesticulation - hand and arm movements accompanying speech - is an essential part of non-verbal behavior. Gesture generation models have been developed for several decades: starting with rule-based and ending with mainly data-driven methods. To date, recent end-to-end gesture generation methods have not been evaluated in a real-time interaction with users. We present a proof-of-concept framework, which is intended to facilitate evaluation of modern gesture generation models in interaction. We demonstrate an extensible open-source framework that contains three components: 1) a 3D interactive agent; 2) a chatbot backend; 3) a gesticulating system. Each component can be replaced, making the proposed framework applicable for investigating the effect of different gesturing models in real-time interactions with different communication modalities, chatbot backends, or different agent appearances. The code and video are available at the project page https://nagyrajmund.github.io/project/gesturebot.",2021.0,23.0,6.0,False,,{'pages': '1779-1781'},"{'bibtex': '@Inproceedings{Nagy2021AFF,\n author = {Rajmund Nagy and Taras Kucherenko and Birger Moell and André Pereira and Hedvig Kjellstrom and Ulysses Bernardet},\n pages = {1779-1781},\n title = {A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents},\n year = {2021}\n}\n'}","[{'authorId': '2051502134', 'name': 'Rajmund Nagy'}, {'authorId': '145372964', 'name': 'Taras Kucherenko'}, {'authorId': '117376362', 'name': 'Birger Moell'}, {'authorId': '11845717', 'name': 'André Pereira'}, {'authorId': '9167315', 'name': 'Hedvig Kjellstrom'}, {'authorId': '2964656', 'name': 'Ulysses Bernardet'}]"
1356,74d9c58c2f238b66a8f842801e14aa3d3406c250,New Perspectives on Emotional Contagion: A Review of Classic and Recent Research on Facial Mimicry and Contagion,"Recently, scholars from a wide variety of disciplines, using a variety of scientific techniques, have begun to study the influence of attention, facial mimicry, and social context on emotional contagion. In this paper we will review the classic evidence documenting the role of attention, facial mimicry, and feedback in sparking primitive emotional contagion. Then we will discuss the new evidence which scholars have amassed to help us better understand the role of facial mimicry in fostering contagion and the ability to “read” others’ thoughts, feelings, and emotions. Finally, we will briefly speculate as to where future research might be headed.",2014.0,114.0,188.0,True,"{'url': 'https://interpersona.psychopen.eu/index.php/interpersona/article/download/3419/3419.pdf', 'status': None}","{'volume': '8', 'pages': '159-179', 'name': 'Interpersona: an international journal on personal relationships'}","{'bibtex': '@Article{Hatfield2014NewPO,\n author = {E. Hatfield and L. Bensman and Paul Thornton and Richard L. Rapson},\n journal = {Interpersona: an international journal on personal relationships},\n pages = {159-179},\n title = {New Perspectives on Emotional Contagion: A Review of Classic and Recent Research on Facial Mimicry and Contagion},\n volume = {8},\n year = {2014}\n}\n'}","[{'authorId': '48279878', 'name': 'E. Hatfield'}, {'authorId': '52403871', 'name': 'L. Bensman'}, {'authorId': '2067418271', 'name': 'Paul Thornton'}, {'authorId': '8611261', 'name': 'Richard L. Rapson'}]"
1357,74e25d61e0f090405be9fb6c4f183459f5e31652,Virtual reality exposure therapy of anxiety disorders: a review.,,2004.0,54.0,468.0,False,,"{'volume': '24 3', 'pages': '\n          259-81\n        ', 'name': 'Clinical psychology review'}","{'bibtex': '@Article{Krijn2004VirtualRE,\n author = {M. Krijn and P. Emmelkamp and Ragnar P. Ólafsson and R. Biemond},\n journal = {Clinical psychology review},\n pages = {\n          259-81\n        },\n title = {Virtual reality exposure therapy of anxiety disorders: a review.},\n volume = {24 3},\n year = {2004}\n}\n'}","[{'authorId': '2879486', 'name': 'M. Krijn'}, {'authorId': '2282500', 'name': 'P. Emmelkamp'}, {'authorId': '2180893608', 'name': 'Ragnar P. Ólafsson'}, {'authorId': '4353812', 'name': 'R. Biemond'}]"
1358,74fdaeb2678aba886c3d899f66b4197b901483d7,Deep Neural Networks in Machine Translation: An Overview,Deep neural networks (DNNs) are widely used in machine translation (MT). This article gives an overview of DNN applications in various aspects of MT.,2015.0,32.0,183.0,False,,"{'volume': '30', 'pages': '16-25', 'name': 'IEEE Intelligent Systems'}","{'bibtex': '@Article{Zhang2015DeepNN,\n author = {Jiajun Zhang and Chengqing Zong},\n journal = {IEEE Intelligent Systems},\n pages = {16-25},\n title = {Deep Neural Networks in Machine Translation: An Overview},\n volume = {30},\n year = {2015}\n}\n'}","[{'authorId': '38358352', 'name': 'Jiajun Zhang'}, {'authorId': '2423168', 'name': 'Chengqing Zong'}]"
1359,75165e42551ddfe70a07fdf61a117ddc2e1a7ddb,Population-Based Initiatives in College Mental Health: Students Helping Students to Overcome Obstacles,,2014.0,40.0,66.0,False,,"{'volume': '16', 'pages': '1-8', 'name': 'Current Psychiatry Reports'}","{'bibtex': '@Article{Kirsch2014PopulationBasedII,\n author = {D. Kirsch and S. Pinder-Amaker and C. Morse and M. Ellison and L. Doerfler and M. Riba},\n journal = {Current Psychiatry Reports},\n pages = {1-8},\n title = {Population-Based Initiatives in College Mental Health: Students Helping Students to Overcome Obstacles},\n volume = {16},\n year = {2014}\n}\n'}","[{'authorId': '49748427', 'name': 'D. Kirsch'}, {'authorId': '1400956691', 'name': 'S. Pinder-Amaker'}, {'authorId': '82694128', 'name': 'C. Morse'}, {'authorId': '3151507', 'name': 'M. Ellison'}, {'authorId': '3622974', 'name': 'L. Doerfler'}, {'authorId': '144862095', 'name': 'M. Riba'}]"
1360,75259e9c2b49b0df8f7810ad5cef80c848b0af82,A Comprehensive Computational Model of Emotions,,2008.0,0.0,11.0,False,,"{'volume': '45', 'pages': '579', 'name': 'Journal of Computer Research and Development'}","{'bibtex': '@Article{Hongwei2008ACC,\n author = {Yang Hongwei and Pan Zhigeng and Liu Gengdai},\n journal = {Journal of Computer Research and Development},\n pages = {579},\n title = {A Comprehensive Computational Model of Emotions},\n volume = {45},\n year = {2008}\n}\n'}","[{'authorId': '48644058', 'name': 'Yang Hongwei'}, {'authorId': '31151520', 'name': 'Pan Zhigeng'}, {'authorId': '1411327472', 'name': 'Liu Gengdai'}]"
1362,7527ea4b387d5030a8af0e72157da28f2bbc65ee,Effects of Embodied Interface Agents and Their Gestural Activity,,2003.0,16.0,52.0,False,,{'pages': '292-300'},"{'bibtex': '@Inproceedings{Krämer2003EffectsOE,\n author = {N. Krämer and Bernd Tietz and G. Bente},\n pages = {292-300},\n title = {Effects of Embodied Interface Agents and Their Gestural Activity},\n year = {2003}\n}\n'}","[{'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '2642748', 'name': 'Bernd Tietz'}, {'authorId': '2487649', 'name': 'G. Bente'}]"
1363,75308067ddd3c53721430d7984295838c81d4106,Rapid Facial Reactions in Response to Facial Expressions of Emotion Displayed by Real Versus Virtual Faces,"Facial expressions of emotion provide relevant cues for understanding social interactions and the affective processes involved in emotion perception. Virtual human faces are useful for conducting controlled experiments. However, little is known regarding the possible differences between physiological responses elicited by virtual versus real human facial expressions. The aim of the current study was to determine if virtual and real emotional faces elicit the same rapid facial reactions for the perception of facial expressions of joy, anger, and sadness. Facial electromyography (corrugator supercilii, zygomaticus major, and depressor anguli) was recorded in 30 participants during the presentation of dynamic or static and virtual or real faces. For the perception of dynamic facial expressions of joy and anger, analyses of electromyography data revealed that rapid facial reactions were stronger when participants were presented with real faces compared with virtual faces. These results suggest that the processes underlying the perception of virtual versus real emotional faces might differ.",2018.0,54.0,15.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/2041669518786527', 'status': None}","{'volume': '9', 'name': 'i-Perception'}","{'bibtex': '@Article{Philip2018RapidFR,\n author = {L. Philip and Jean-Claude Martin and C. Clavel},\n journal = {i-Perception},\n title = {Rapid Facial Reactions in Response to Facial Expressions of Emotion Displayed by Real Versus Virtual Faces},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '2560627', 'name': 'L. Philip'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '1724799', 'name': 'C. Clavel'}]"
1364,7548ff9ea42d71376e14385bb7c6930254b67170,A Handheld Animated Advisor for Physical Activity Promotion,We have developed an animated PDA-based advisor that can engage sedentary adults in dialogues about their physical activity throughout the day. An integrated accelerometer enables the advisor to initiate interactions and provide real-time feedback. Results of preliminary usability testing of interaction modalities are presented and a planned efficacy study using free-living sedentary adults is described.,2006.0,3.0,10.0,False,,"{'pages': '\n          855\n        ', 'name': 'AMIA ... Annual Symposium proceedings. AMIA Symposium'}","{'bibtex': '@Article{Bickmore2006AHA,\n author = {T. Bickmore and A. Gruber and S. Intille and Daniel Mauer},\n journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},\n pages = {\n          855\n        },\n title = {A Handheld Animated Advisor for Physical Activity Promotion},\n year = {2006}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '38963597', 'name': 'A. Gruber'}, {'authorId': '1705903', 'name': 'S. Intille'}, {'authorId': '34374128', 'name': 'Daniel Mauer'}]"
1365,755551038d6bb1749b0d5deddc38f482988c632d,Dimensional models of personality: the five-factor model and the DSM-5,"It is evident that the classification of personality disorder is shifting toward a dimensional trait model and, more specifically, the five-factor model (FFM). The purpose of this paper is to provide an overview of the FFM of personality disorder. It will begin with a description of this dimensional model of normal and abnormal personality functioning, followed by a comparison with a proposal for future revisions to DSM-5 and a discussion of its potential advantages as an integrative hierarchical model of normal and abnormal personality structure.",2013.0,99.0,157.0,True,,"{'volume': '15', 'pages': '135 - 146', 'name': 'Dialogues in Clinical Neuroscience'}","{'bibtex': '@Article{Trull2013DimensionalMO,\n author = {T. Trull and T. Widiger},\n journal = {Dialogues in Clinical Neuroscience},\n pages = {135 - 146},\n title = {Dimensional models of personality: the five-factor model and the DSM-5},\n volume = {15},\n year = {2013}\n}\n'}","[{'authorId': '4503414', 'name': 'T. Trull'}, {'authorId': '5197542', 'name': 'T. Widiger'}]"
1366,75b3ef23d97b10b4599d7efa3c3084407dbc522c,THE MEASUREMENT OF TRUST AND ITS RELATIONSHIP TO SELF‐DISCLOSURE,"This study examined the relationship of trust to self-disclosure. A measure of individualized trust was developed and used in conjunction with a multidimensional measure of disclosure to reassess the relationship between the two. A modest, linear relationship between individualized trust and various dimensions of self-disclosure was discovered. Moreover, a higher level of trust (as opposed to lesser trust as well as distrust) was found to be associated with more consciously intended disclosure and a greater amount of disclosure.",1977.0,23.0,453.0,False,,"{'volume': '3', 'pages': '250-257', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Wheeless1977THEMO,\n author = {Lawrence R. Wheeless and Janis Grotz},\n journal = {Human Communication Research},\n pages = {250-257},\n title = {THE MEASUREMENT OF TRUST AND ITS RELATIONSHIP TO SELF‐DISCLOSURE},\n volume = {3},\n year = {1977}\n}\n'}","[{'authorId': '118894644', 'name': 'Lawrence R. Wheeless'}, {'authorId': '114495308', 'name': 'Janis Grotz'}]"
1367,76214bf3d19fa8fc8a7b773153fbf793c4d861c2,Automatic Micro-Expression Analysis: Open Challenges,"Micro-expressions, the fleeting and involuntary facial expression, often occurring in high-stake situations when people try to conceal or mask their true feelings, became well-known since 1960s, from the work of Haggard and Isaacs (1966) in which micro-expression was firstly termed as micromomentary facial expressions, and later from the work of Ekman and Friesen (1969). Micro-expressions are too short (1/25 to 1/2 s) and subtle for human eyes to perceive. Study (Ekman, 2002) shows that for micro-expression recognition tasks, ordinary people without training only perform slightly better than chance on average. So computer vision and machine learning methods for automatic micro-expression analysis become appealing. Pfister et al. (2011) started pioneering research on spontaneousmicro-expression recognition with the first publically available spontaneous micro-expression dataset: SMIC, and achieved very promising results that compare favorably with the human accuracy. Since then micro-expression study in computer vision field has been attracting attentions from more and more researchers. A number of works have been contributing to the automatic micro-expression analysis from the aspects of new datasets collection (from emotion level annotation to action unit level annotation; Li et al., 2013; Davison et al., 2018), micro-expression recognition (from signal apex frame recognition to whole video recognition; Wang et al., 2015; Liu et al., 2016; Li Y. et al., 2018; Huang et al., 2019) and microexpression detection (from micro-expression peak detection to micro-expression onset and offset detection; Patel et al., 2015; Xia et al., 2016; Jain et al., 2018). First completed system integrating micro-expression recognition and detection toward reading hidden emotions (Li X. et al., 2018) has been reported by MIT Technology Review (2015) and achieved increasing attention, in which the machine learning method obtained 80.28% for three class (positive/negative/surprise) recognition for 71 micro-expression video clips recorded from eight subjects and 57.49% for five class (happiness, disgust, surprise, repression, and other) recognition for 247 micro-expression video clips recorded from 26 subjects (Li X. et al., 2018), which has outperformed the recognition capability of human subjects (Li X. et al., 2018). However, there are still many open challenges which need to be considered in the future research. Several main challenges related with micro-expression study are discussed in details in the following.",2019.0,29.0,18.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.01833/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Zhao2019AutomaticMA,\n author = {Guoying Zhao and Xiaobai Li},\n journal = {Frontiers in Psychology},\n title = {Automatic Micro-Expression Analysis: Open Challenges},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '1502872895', 'name': 'Xiaobai Li'}]"
1368,76248f657a25c4e4d086d88773f000cc7fadcbd4,The Communicative Function of Sad Facial Expressions,"What are the communicative functions of sad facial expressions? Research shows that people feel sadness in response to losses but it’s unclear whether sad expressions function to communicate losses to others and if so, what makes these signals credible. Here we use economic games to test the hypothesis that sad expressions lend credibility to claims of loss. Participants play the role of either a proposer or recipient in a game with a fictional backstory and real monetary payoffs. The proposers view a (fictional) video of the recipient’s character displaying either a neutral or sad expression paired with a claim of loss. The proposer then decided how much money to give to the recipient. In three experiments, we test alternative theories by using situations in which the recipient’s losses were uncertain (Experiment 1), the recipient’s losses were certain (Experiment 2), or the recipient claims failed gains rather than losses (Experiment 3). Overall, we find that participants gave more money to recipients who displayed sad expressions compared to neutral expressions, but only under conditions of uncertain loss. This finding supports the hypothesis that sad expressions function to increase the credibility of claims of loss.",2017.0,52.0,25.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1474704917700418', 'status': None}","{'volume': '15', 'name': 'Evolutionary Psychology'}","{'bibtex': '@Article{Reed2017TheCF,\n author = {L. I. Reed and Peter DeScioli},\n journal = {Evolutionary Psychology},\n title = {The Communicative Function of Sad Facial Expressions},\n volume = {15},\n year = {2017}\n}\n'}","[{'authorId': '46301322', 'name': 'L. I. Reed'}, {'authorId': '4304962', 'name': 'Peter DeScioli'}]"
1369,76278b9afb45ccb7c6e633a5747054f94e5fcc23,Artificial Intelligence MArkup Language: A Brief Tutorial,"The purpose of this paper is to serve as a reference guide for the development of chatterbots implemented with the AIML language. In order to achieve this, the main concepts in Pattern Recognition area are described because the AIML uses such theoretical framework in their syntactic and semantic structures. After that, AIML language is described and each AIML command/tag is followed by an application example. Also, the usage of AIML embedded tags for the handling of sequence dialogue limitations between humans and machines is shown. Finally, computer systems that assist in the design of chatterbots with the AIML language are classified and described.",2013.0,18.0,84.0,True,"{'url': 'https://doi.org/10.5121/ijcses.2013.4301', 'status': None}","{'volume': 'abs/1307.3091', 'name': 'ArXiv'}","{'bibtex': '@Article{Marietto2013ArtificialIM,\n author = {M. Marietto and Rafael Varago de Aguiar and Gislene de Oliveira Barbosa and W. Botelho and E. Pimentel and R. S. França and Vera Lúcia da Silva},\n journal = {ArXiv},\n title = {Artificial Intelligence MArkup Language: A Brief Tutorial},\n volume = {abs/1307.3091},\n year = {2013}\n}\n'}","[{'authorId': '2724580', 'name': 'M. Marietto'}, {'authorId': '2358716', 'name': 'Rafael Varago de Aguiar'}, {'authorId': '3134217', 'name': 'Gislene de Oliveira Barbosa'}, {'authorId': '3198022', 'name': 'W. Botelho'}, {'authorId': '2071578459', 'name': 'E. Pimentel'}, {'authorId': '2121691', 'name': 'R. S. França'}, {'authorId': '2105563358', 'name': 'Vera Lúcia da Silva'}]"
1370,7637e367d65dd3dc9ad368e77f03db5c2383baab,Virtual Reality Exposure Therapy,,2016.0,14.0,157.0,True,"{'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3330462/pdf', 'status': None}","{'volume': '', 'pages': '370-374', 'name': ''}","{'bibtex': '@Inproceedings{Rothbaum2016VirtualRE,\n author = {B. Rothbaum},\n pages = {370-374},\n title = {Virtual Reality Exposure Therapy},\n year = {2016}\n}\n'}","[{'authorId': '1831766', 'name': 'B. Rothbaum'}]"
1371,7657870b28a5386ce22a8219e904e4d76a9ee63b,"Designing Human-Agent Collaborations: Commitment, responsiveness, and support","With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents’ behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman's Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.",2022.0,176.0,14.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3491102.3517500', 'status': None}",{'name': 'Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Cila2022DesigningHC,\n author = {Nazli Cila},\n journal = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},\n title = {Designing Human-Agent Collaborations: Commitment, responsiveness, and support},\n year = {2022}\n}\n'}","[{'authorId': '3396650', 'name': 'Nazli Cila'}]"
1372,76ad25c4d0693d17710fb4f334c6ef68b732a624,"Emotion regulation: affective, cognitive, and social consequences.","One of life's great challenges is successfully regulating emotions. Do some emotion regulation strategies have more to recommend them than others? According to Gross's (1998, Review of General Psychology, 2, 271-299) process model of emotion regulation, strategies that act early in the emotion-generative process should have a different profile of consequences than strategies that act later on. This review focuses on two commonly used strategies for down-regulating emotion. The first, reappraisal, comes early in the emotion-generative process. It consists of changing the way a situation is construed so as to decrease its emotional impact. The second, suppression, comes later in the emotion-generative process. It consists of inhibiting the outward signs of inner feelings. Experimental and individual-difference studies find reappraisal is often more effective than suppression. Reappraisal decreases emotion experience and behavioral expression, and has no impact on memory. By contrast, suppression decreases behavioral expression, but fails to decrease emotion experience, and actually impairs memory. Suppression also increases physiological responding for suppressors and their social partners. This review concludes with a consideration of five important directions for future research on emotion regulation processes.",2002.0,83.0,3717.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1017/S0048577201393198', 'status': None}","{'volume': '39 3', 'pages': '\n          281-91\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Gross2002EmotionRA,\n author = {J. Gross},\n journal = {Psychophysiology},\n pages = {\n          281-91\n        },\n title = {Emotion regulation: affective, cognitive, and social consequences.},\n volume = {39 3},\n year = {2002}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}]"
1373,76b532e2cb573fdf29f3ae68dc1372f3319c93c2,Active Appearance Models,,1998.0,34.0,7719.0,True,"{'url': 'http://www.cs.cmu.edu/~efros/courses/AP06/Papers/cootes-pami-01.pdf', 'status': None}",{'pages': '484-498'},"{'bibtex': '@Inproceedings{Cootes1998ActiveAM,\n author = {Tim Cootes and G. Edwards and C. Taylor},\n pages = {484-498},\n title = {Active Appearance Models},\n year = {1998}\n}\n'}","[{'authorId': '7205190', 'name': 'Tim Cootes'}, {'authorId': '50564384', 'name': 'G. Edwards'}, {'authorId': '144482985', 'name': 'C. Taylor'}]"
1374,76cc49341006018c2c9d12d6a9b4092316900b17,Status,,2020.0,0.0,268.0,False,,{'name': 'Max Weber on Power and Social Stratification'},"{'bibtex': '@Article{Brennan2020Status,\n author = {Catherine Brennan},\n journal = {Max Weber on Power and Social Stratification},\n title = {Status},\n year = {2020}\n}\n'}","[{'authorId': '144157104', 'name': 'Catherine Brennan'}]"
1375,76d3c851ab8a6d028d0047a8e6d0d999949ea44e,"Synthetic faces, face cubes, and the geometry of face space",,2002.0,67.0,183.0,True,,"{'volume': '42', 'pages': '2909-2923', 'name': 'Vision Research'}","{'bibtex': '@Article{Wilson2002SyntheticFF,\n author = {H. Wilson and Gunter Loffler and F. Wilkinson},\n journal = {Vision Research},\n pages = {2909-2923},\n title = {Synthetic faces, face cubes, and the geometry of face space},\n volume = {42},\n year = {2002}\n}\n'}","[{'authorId': '32733837', 'name': 'H. Wilson'}, {'authorId': '2042936', 'name': 'Gunter Loffler'}, {'authorId': '2040767', 'name': 'F. Wilkinson'}]"
1376,7723484429d2d299c17c896aae0d74c3038de29f,Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments,"In this paper, I address the question as to why participants tend to respond realistically to situations and events portrayed within an immersive virtual reality system. The idea is put forward, based on the experience of a large number of experimental studies, that there are two orthogonal components that contribute to this realistic response. The first is ‘being there’, often called ‘presence’, the qualia of having a sensation of being in a real place. We call this place illusion (PI). Second, plausibility illusion (Psi) refers to the illusion that the scenario being depicted is actually occurring. In the case of both PI and Psi the participant knows for sure that they are not ‘there’ and that the events are not occurring. PI is constrained by the sensorimotor contingencies afforded by the virtual reality system. Psi is determined by the extent to which the system can produce events that directly relate to the participant, the overall credibility of the scenario being depicted in comparison with expectations. We argue that when both PI and Psi occur, participants will respond realistically to the virtual reality.",2009.0,49.0,1520.0,True,"{'url': 'https://europepmc.org/articles/pmc2781884?pdf=render', 'status': None}","{'volume': '364', 'pages': '3549 - 3557', 'name': 'Philosophical Transactions of the Royal Society B: Biological Sciences'}","{'bibtex': '@Article{Slater2009PlaceIA,\n author = {M. Slater},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n pages = {3549 - 3557},\n title = {Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments},\n volume = {364},\n year = {2009}\n}\n'}","[{'authorId': '144931212', 'name': 'M. Slater'}]"
1377,772ce66315c2f6d0108e6404ce91034fae3a37ae,Interpersonal effects of expressed anger and sorrow in morally charged negotiation,"The expression of emotion can play a significant role in strategic decision-making. In this study, we hypothesized that emotion expression alters behavior in morally charged negotiation. We investigated the impact of facial displays of discrete emotions, specifically anger and sadness, in a morally charged multi-issue negotiation task. Our results indicate that if a negotiator associated moral significance to the object of the negotiation, displays of anger resulted in reduced concession making whereas displays of sadness increased concession making. Moral significance of the issues fostered an emotional matching mechanism of sorrow, where a sorrow expression from one party elicited a sorrow expression from the other. Taken together, the results indicate that emotional expressions can affect morally charged negotiation in ways that can inhibit as well as promote cooperation.",2014.0,46.0,34.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/22729FD6F0D5E43D636E20C6C60BAB97/S1930297500005477a.pdf/div-class-title-interpersonal-effects-of-expressed-anger-and-sorrow-in-morally-charged-negotiation-div.pdf', 'status': None}",{'name': 'Judgment and Decision Making'},"{'bibtex': '@Article{Dehghani2014InterpersonalEO,\n author = {Morteza Dehghani and P. Carnevale and J. Gratch},\n journal = {Judgment and Decision Making},\n title = {Interpersonal effects of expressed anger and sorrow in morally charged negotiation},\n year = {2014}\n}\n'}","[{'authorId': '145707560', 'name': 'Morteza Dehghani'}, {'authorId': '48755211', 'name': 'P. Carnevale'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
1378,772fdadb73f9c62d47b855539b1d6840f5c3e0de,The TARDIS Framework: Intelligent Virtual Agents for Social Coaching in Job Interviews,,2013.0,37.0,125.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/48445/48445.pdf', 'status': None}",{'pages': '476-491'},"{'bibtex': '@Inproceedings{Anderson2013TheTF,\n author = {Keith Anderson and E. André and Tobias Baur and S. Bernardini and Mathieu Chollet and E. Chryssafidou and Ionut Damian and Cathy Ennis and A. Egges and Patrick Gebhard and H. Jones and M. Ochs and C. Pelachaud and K. Porayska-Pomsta and Paola Rizzo and N. Sabouret},\n pages = {476-491},\n title = {The TARDIS Framework: Intelligent Virtual Agents for Social Coaching in Job Interviews},\n year = {2013}\n}\n'}","[{'authorId': '2113606401', 'name': 'Keith Anderson'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '2230836', 'name': 'Tobias Baur'}, {'authorId': '2282728', 'name': 'S. Bernardini'}, {'authorId': '40325099', 'name': 'Mathieu Chollet'}, {'authorId': '2111629', 'name': 'E. Chryssafidou'}, {'authorId': '3048626', 'name': 'Ionut Damian'}, {'authorId': '31894925', 'name': 'Cathy Ennis'}, {'authorId': '2479558', 'name': 'A. Egges'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '31600786', 'name': 'H. Jones'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1400276226', 'name': 'K. Porayska-Pomsta'}, {'authorId': '1773424', 'name': 'Paola Rizzo'}, {'authorId': '1731432', 'name': 'N. Sabouret'}]"
1380,77338e2fe5cdac5c560555fbcb57d293a8523a33,Massively Multiplayer Online Games and Well-Being: A Systematic Literature Review,"Background: Massively multiplayer online games (MMOs) evolve online, whilst engaging large numbers of participants who play concurrently. Their online socialization component is a primary reason for their high popularity. Interestingly, the adverse effects of MMOs have attracted significant attention compared to their potential benefits. Methods: To address this deficit, employing PRISMA guidelines, this systematic review aimed to summarize empirical evidence regarding a range of interpersonal and intrapersonal MMO well-being outcomes for those older than 13. Results: Three databases identified 18 relevant English language studies, 13 quantitative, 4 qualitative and 1 mixed method published between January 2012 and August 2020. A narrative synthesis methodology was employed, whilst validated tools appraised risk of bias and study quality. Conclusions: A significant positive relationship between playing MMOs and social well-being was concluded, irrespective of one's age and/or their casual or immersed gaming patterns. This finding should be considered in the light of the limited: (a) game platforms investigated; (b) well-being constructs identified; and (c) research quality (i.e., modest). Nonetheless, conclusions are of relevance for game developers and health professionals, who should be cognizant of the significant MMOs-well-being association(s). Future research should focus on broadening the well-being constructs investigated, whilst enhancing the applied methodologies.",2021.0,57.0,31.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.698799/pdf', 'status': None}","{'volume': '12', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Raith2021MassivelyMO,\n author = {Lisa Raith and Julie Bignill and V. Stavropoulos and P. Millear and Andrew Allen and H. Stallman and J. Mason and T. De Regt and Andrew P Wood and L. Kannis-Dymand},\n journal = {Frontiers in Psychology},\n title = {Massively Multiplayer Online Games and Well-Being: A Systematic Literature Review},\n volume = {12},\n year = {2021}\n}\n'}","[{'authorId': '47350491', 'name': 'Lisa Raith'}, {'authorId': '2116207853', 'name': 'Julie Bignill'}, {'authorId': '10710994', 'name': 'V. Stavropoulos'}, {'authorId': '82279497', 'name': 'P. Millear'}, {'authorId': '48780063', 'name': 'Andrew Allen'}, {'authorId': '4709623', 'name': 'H. Stallman'}, {'authorId': '2142470286', 'name': 'J. Mason'}, {'authorId': '115433572', 'name': 'T. De Regt'}, {'authorId': '1659993891', 'name': 'Andrew P Wood'}, {'authorId': '1399153630', 'name': 'L. Kannis-Dymand'}]"
1381,775bba31770cebbf8a81ac08e34f6c3471388361,PRIMER: An Emotionally Aware Virtual Agent,"PRIMER is a proof-of-concept system designed to show the potential of immersive dialogue agents and virtual environments that adapt and respond to both direct verbal input and indirect emotional input. The system has two novel interfaces: (1) for the user, an immersive VR environment and an animated virtual agent both of which adapt and react to the user’s direct input as well as the user’s perceived emotional state, and (2) for an observer, an interface that helps track the perceived emotional state of the user, with visualizations to provide insight into the system’s decision making process. While the basic system architecture can be adapted for many potential real world applications, the initial version of this system was designed to assist clinical social workers in helping children cope with bullying. The virtual agent produces verbal and non-verbal behaviors guided by a plan for the counseling session, based on in-depth discussions with experienced counselors, but is also reactive to both initiatives that the user takes, e.g. asking their own questions, and the user’s perceived emotional state.",2019.0,12.0,11.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gordon2019PRIMERAE,\n author = {Carla Gordon and A. Leuski and G. Benn and E. Klassen and Edward Fast and Matt Liewer and Arno Hartholt and D. Traum},\n title = {PRIMER: An Emotionally Aware Virtual Agent},\n year = {2019}\n}\n'}","[{'authorId': '40325729', 'name': 'Carla Gordon'}, {'authorId': '3201827', 'name': 'A. Leuski'}, {'authorId': '31624455', 'name': 'G. Benn'}, {'authorId': '144984764', 'name': 'E. Klassen'}, {'authorId': '2432742', 'name': 'Edward Fast'}, {'authorId': '2138666', 'name': 'Matt Liewer'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '144518646', 'name': 'D. Traum'}]"
1382,776ab65a1caac831574f2a034110c841a44e1e90,Animated Pedagogical Agents and Emotion,,2016.0,36.0,3.0,False,,"{'volume': '', 'pages': '225-237', 'name': ''}","{'bibtex': '@Inproceedings{Romero-Hall2016AnimatedPA,\n author = {Enilda Romero-Hall},\n pages = {225-237},\n title = {Animated Pedagogical Agents and Emotion},\n year = {2016}\n}\n'}","[{'authorId': '1402222068', 'name': 'Enilda Romero-Hall'}]"
1383,77b77b5f8e7a3aa01a325c19c15c321da22150da,A ChatBot for Learning Chinese: Learning Achievement and Technology Acceptance,"ChatBot has potential as a language learning tool, especially for learning Chinese vocabulary. This study aimed to investigate the impact of using a newly developed ChatBot to learn Chinese vocabulary by comparing how it works in different learning environments and to explore the ChatBot with reference to the Technology Acceptance Model (TAM). This study was conducted with 58 students divided into two independent groups. The control group used ChatBot in a one-on-many classroom. The experimental group applied the ChatBot in one-on-one tutor sessions. A pretest and a posttest were used to measure the effect of the ChatBot, while TAM was explored through questionnaire and interview. Data analysis includes a paired-sample t test, analysis of covariance, and levels of effect. The results indicated that the ChatBot significantly improved the students’ learning achievement and that having a one-on-one environment may lead to better outcome than what could be achieved in a classroom. The TAM model was tested using partial least square. The result showed that perceived usefulness was the predictor of behavioral intention, whereas perceived ease of use was not. The students agreed that the ChatBot benefited their learning of Chinese vocabulary, with several adjustments need to be made for further progress.",2020.0,62.0,56.0,False,,"{'volume': '58', 'pages': '1161 - 1189', 'name': 'Journal of Educational Computing Research'}","{'bibtex': '@Article{Chen2020ACF,\n author = {Hsiu-Ling Chen and Gracia Vicki Widarso and H. Sutrisno},\n journal = {Journal of Educational Computing Research},\n pages = {1161 - 1189},\n title = {A ChatBot for Learning Chinese: Learning Achievement and Technology Acceptance},\n volume = {58},\n year = {2020}\n}\n'}","[{'authorId': '2145278581', 'name': 'Hsiu-Ling Chen'}, {'authorId': '1844297259', 'name': 'Gracia Vicki Widarso'}, {'authorId': '32143875', 'name': 'H. Sutrisno'}]"
1384,77c771a87f8a09652634edacad5b07f3d6b9146e,Empathy in counseling,,1951.0,0.0,3.0,False,,"{'volume': '1', 'pages': '25-30', 'name': 'Pastoral Psychology'}","{'bibtex': '@Article{Hiltner1951EmpathyIC,\n author = {S. Hiltner},\n journal = {Pastoral Psychology},\n pages = {25-30},\n title = {Empathy in counseling},\n volume = {1},\n year = {1951}\n}\n'}","[{'authorId': '35498769', 'name': 'S. Hiltner'}]"
1385,7809503308492b62e67d125b9c13f5a706b39171,Research on the Agent's Behavior Decision-making Based on Artificial Emotion,"Emotional intelligence is an important branch of artificial intelligence, it is an important way to achieve the truly intelligent robot. This paper regards an Agent living in a virtual environment as the research object and proposes a fuzzy emotion model based on particle system, and combines the feedback signal of emotion with associative learning mechanism based on CMAC neural network. Finally, combined the environment, emotion model and CMAC network we propose a new Agent's behavior decision-making model based on artificial emotion, the results show that this model can improve the performance of the agent.",2014.0,0.0,6.0,False,,"{'name': 'The Journal of Information and Computational Science', 'pages': '2723-2733', 'volume': '11'}","{'bibtex': ""@Article{Yang2014ResearchOT,\n author = {Fuping Yang and Xuewen Zhen},\n journal = {The Journal of Information and Computational Science},\n pages = {2723-2733},\n title = {Research on the Agent's Behavior Decision-making Based on Artificial Emotion},\n volume = {11},\n year = {2014}\n}\n""}","[{'authorId': '3174138', 'name': 'Fuping Yang'}, {'authorId': '2053079410', 'name': 'Xuewen Zhen'}]"
1386,7829c1be330980199cbe1b4e043f1254df84833b,Agents that Combine Emotions and Rationality : a Context Independent Cognitive Architecture,"Intelligent behaviours have been traditionally considered exclusively as products of pure rationality processes. Considering other influential factors, such as emotions, has been accused of being “non scientific”. However, pure rational processes fail when trying to explain most of human behaviours, in which emotion plays a key role. Nevertheless, emotional factors add an extra complexity to agent architectures, making them, hitherto, either few efficient or few reusable. This paper presents a context independent cognitive architecture for agents that combine emotions and rationality, named COGNITIVA, which bets on adaptivity as a weapon to fight against that complexity. Key-Words: Cognitive agent architecture, specification process, emotion, personality, virtual characters, adaptivity 1 The Role of Emotions in the Rational Process 1.1 Emotion and Reason, Oil and Water? Emotions and reason have been traditionally considered as two sides of the same coin and, therefore, antagonistic and non combinable. Emotions are something rather irrational that plays down value to human rationality [1], something “non scientific” [2]. However, recent theories [3] [4] suggest that emotions are an essential part of human intelligence, playing a critical role in processes such as perception, learning, attention, memory, rational decision making and other abilities usually associated to intelligent behaviours. The initial approach fails, probably, in considering “emotional systems” as systems that lose the desirable rationality and control. However, it is not right considering laws and rational norms as the unique and more important parts when interpreting human behaviour and intelligence. It is also an error considering human behaviour independent of any emotional process. Up to this point, it is worth to remark that, from the neurological perspective, no polarization, or clean dividing line occurs between thinking and emotions [2]. 1.2 Emotional Architectures Most of the theoretical models of emotion, coming from Psychology are not appropriate to be applied into computer systems, since they weren’t conceived with that purpose. The adaptation of these approaches and the development of new theories, more suitable to the automation of their elements and processes, have reduced the number of theoretical models of emotion present in most of the emotional systems: appraisal models, motivational models, dimensional models... However, neither these models nor the architectures and systems developed from them incorporate successfully emotions to the general rational process. Some deficiency or drawback is always imputed to each one, although, depending on the contexts and problems, they also prove sometimes to be acceptably adequate. The empirical results of these approaches show that emotional factors cannot be considered as yet another component in the agent's architecture, but all the architecture must exhibit an emotional orientation. 1.3 Adaptivity vs. Specificity or Generality Behind these architectures (usually agent-oriented) underlies a very intricate structure. Sometimes, their elements and dynamics are interwoven with the restrictions and particularities of the application context, mingling with them, making these approaches few reusable (cf. [5], [6], [7], [8], [9]). Other times, architectures are intrinsically very generic, independent from any specific problem (cf. [10], [11], [12]). The lack of an adaptation to the particular needs of the problem originates less-efficient, computationally demanding mechanisms. This forces to reconsider the whole structure of the architecture and to simplify some of their original capabilities, in order to offer viable developments. In our opinion, nowadays solutions do not provide the level of desired quality/satisfaction because they – just– fail in the “attitudes” with which complexity is faced: instead of looking for specificity or generality, the key is in adaptivity. A new perspective is needed. A perspective considering the complexity of this kind of systems in an efficient, reusable way; a perspective allowing an adaptation to the specific problem and context needs without loosing the generic purpose of the architecture; a perspective maintaining a structure, components and processes coherent and understandable. 2 Adaptable Cognitive Architecture This paper proposes the definition of a generic architecture, named COGNITIVA, to develop agents whose behaviours are emotionally influenced. Considering an agent as a continuous perception-cognition-action cycle, the scope of this architecture is circumscribed to its cognitive activity, although it does not restrict any of the other two modules (perceptual and actuation). Different from the generic preceding architectures, COGNITIVA provides mechanisms to be adapted to each specific context and problem, from a double perspective: • Adaptation of its structure: COGNITIVA is a multilayered architecture that covers several kinds of behaviour: reactive, deliberative and social. Besides, it includes a flexible model that allows establishing dependencies and influences among elements such as personality traits, attitudes, physical states, concerns and emotions. Even more, both the behaviour modes and the elements are configurable, according to the particular needs of every situation. • Adaptation of its process of application: from the generic architecture, a progressive specification process has been designed, to apply it to every particular context. This process begins with a functional specification of the architecture, which provides a particular design and implementation of each one of the information structures and functions defined in the generic architecture. This first specification is yet too context independent to the application context. In fact, the same functional specification may be used as a basis for many different contexts. The approach to each one of them is made in a second specification phase, the contextual specification, in which all the particular values and procedures of the application environment are included. In the following sections, COGNITIVA and its main components are described with a deeper detail, along with some results obtained from its application. 3 Description of COGNITIVA Internally, COGNITIVA can be considered as a hybrid architecture, combining reactive, deliberative and social skills. Fig. 1 shows a schematic perspective of the three quasi-horizontal levels, namely: • Reactive layer, to provide the agent with immediate responses to the perceived changes in the environment. • Deliberative layer, to provide the agent with goal-directed behaviours, from its individual abilities point of view. • Social layer, to provide the agent with behaviours in which the existence of other agents and the interaction with them is considered. Fig. 1. General Schema of COGNITIVA. 3.1 Management of the Current State of the Agent: Beliefs With independence of the decision making process carried out in each one of the layers, it is very difficult for an agent to exhibit coherent behaviours exclusively from the perceptual input coming from the sensors (perceptual module). It is necessary to consider other information sources, such as its knowledge about the environment, about other agents and, even more, about itself. All this information is represented internally as a beliefs set. To manage the beliefs, a taxonomy has been defined. In a first level, the taxonomy differentiates the object of the belief: places –physical, conceptual or virtual–, objects, individuals and the current situation. Besides, the agent beliefs related to places, objects and individuals are classified into: • Beliefs related to defining characteristics (DCs), that describe the general traits of places, objects and individuals. DCs are fundamental to understand them. The DCs value hardly changes over the time. • Beliefs related to transitory states (TSs), characteristics whose values represent the current state of places, objects and individuals. TSs’ values have a much more dynamic nature, compared to DCs. • Beliefs related to attitudes, useful to determine the behaviour of an agent towards other environment components (places, objects and individuals). Attitudes’ values are less variable than TSs’, but more than DCs’. Among the whole set of agent's beliefs, COGNITIVA distinguishes a small subset related to the agent itself, which is fundamental in the architecture. This subset constitutes what is called the agent's personal model, and includes DCs such as its personality traits, whose values determine the coherent and stable behaviour of the individual; TSs such as its moods and its physical states, identifying the state of the mind and the body of the agent, respectively; and also its attitudes towards others. Many of these characteristics are intrinsically related, and exert some influence on other beliefs of the personal model. So, for instance, the personality traits influence the value of the emotions. 3.2 Management of the Past State: History Agent behaviours that do not take into account events occurred in past moments are specially disappointing for human observers. The architecture proposed considers two mechanisms to maintain the agent's past history information: • Accumulative management of the past: this is an implicit mechanism, related to the way in which beliefs are managed. External changes in the environment or internal modifications in the agent internal state may produce an update of the agent beliefs. However, this update is performed as a variation ---of higher or lower intensity--of the previous beliefs, avoiding abrupt alterations in the individual behaviour. • Explicit management of the past state: an accumulative effect of the past events may not be enough to manage efficiently the past state, because it does not consider information related to the events themselves or to the temporal instant in which they took place. Our ",2005.0,19.0,2.0,False,,,"{'bibtex': '@Inproceedings{Imbert2005AgentsTC,\n author = {R. Imbert},\n title = {Agents that Combine Emotions and Rationality : a Context Independent Cognitive Architecture},\n year = {2005}\n}\n'}","[{'authorId': '2096718980', 'name': 'R. Imbert'}]"
1387,782ab35a0c12981e43db607ebfbf3e34cd04f4d5,Exposure Therapy.,"American Psychological Association | Division 12 http://www.div12.org/ Exposure therapy is a psychological treatment that was developed to help people confront their fears. When people are fearful of something, they tend to avoid the feared objects, activities, or situations. Although this avoidance might help reduce feelings of fear in the short term, over the long term it can make the fear become even worse. In such situations, a psychologist might recommend a program of exposure therapy in order to help break the pattern of avoidance and fear. In this form of therapy, psychologists create a safe environment in which to ""expose"" individuals to the things they fear and avoid. The exposure to the feared objects, activities, or situations in a safe environment helps reduce fear and decrease avoidance.",2018.0,5.0,61.0,True,"{'url': 'https://academic.oup.com/schizophreniabulletin/article-pdf/44/2/229/23945848/sbv049.pdf', 'status': None}","{'volume': '44 2', 'pages': '\n          229-230\n        ', 'name': 'Schizophrenia bulletin'}","{'bibtex': '@Article{Colori2018ExposureT,\n author = {Steve Colori},\n journal = {Schizophrenia bulletin},\n pages = {\n          229-230\n        },\n title = {Exposure Therapy.},\n volume = {44 2},\n year = {2018}\n}\n'}","[{'authorId': '16015593', 'name': 'Steve Colori'}]"
1389,782ce13c8cd76aa39e8ca01b8d1a121dcdec1523,Virtual Experiments and Environmental Policy,,2009.0,181.0,129.0,True,"{'url': 'http://yosemite.epa.gov/ee/epa/eerm.nsf/vwAN/EE-0508-07.pdf/$file/EE-0508-07.pdf', 'status': None}","{'volume': '57', 'pages': '65-86', 'name': 'Journal of Environmental Economics and Management'}","{'bibtex': '@Article{Fiore2009VirtualEA,\n author = {S. Fiore and G. Harrison and C. Hughes and E. Rutström},\n journal = {Journal of Environmental Economics and Management},\n pages = {65-86},\n title = {Virtual Experiments and Environmental Policy},\n volume = {57},\n year = {2009}\n}\n'}","[{'authorId': '35145855', 'name': 'S. Fiore'}, {'authorId': '46384423', 'name': 'G. Harrison'}, {'authorId': '32827434', 'name': 'C. Hughes'}, {'authorId': '145349330', 'name': 'E. Rutström'}]"
1390,787573032d06d60838ae3035d9e15f0e4b6e997b,Escalas PANAS de afecto positivo y negativo: validación factorial y convergencia transcultural,"The PANAS Scales of Positive and Negative Affect: Factor Analytic Validation and Cross-cultural Convergence. Recent evidence suggests that the structure of mood is composed of two dominant and relatively independent dimensions, i.e., positive and negative affect. Such dimensions have consistently emerged as the first two factors in factor analyses (orthogonal or oblique solutions). The Positive and Negative Affect Schedule (PANAS; Watson, Clark y Tellegen, 1988a), a 20-item self-report questionnaire, is one of the most widely used measure of affectivity and has been reported to have excelent psychometric properties with U.S. samples. This study investigated the structure of mood, as well as factorial validity of the Spanish version of the PANAS, in a sample of 712 undergraduates in Madrid. Using exploratory and confirmatory factor analytic techniques (EQS), the autores tested the PANAS structure as well as the two-factor model of mood, and examined gender differences. Results revealed a robust and stable two-dimensional structure (positive and negative affect), and provide strong support to construct validity, reliability (internal consistency) and cross-cultural validation of the Spanish PANAS.",1999.0,0.0,570.0,False,,"{'volume': '11', 'pages': '37-51', 'name': 'Psicothema'}","{'bibtex': '@Article{Sandín1999EscalasPD,\n author = {B. Sandín and Paloma Chorot and Lourdes Lostao and T. Joiner and Miguel A. Santed and R. Valiente},\n journal = {Psicothema},\n pages = {37-51},\n title = {Escalas PANAS de afecto positivo y negativo: validación factorial y convergencia transcultural},\n volume = {11},\n year = {1999}\n}\n'}","[{'authorId': '6128073', 'name': 'B. Sandín'}, {'authorId': '4132781', 'name': 'Paloma Chorot'}, {'authorId': '2075116655', 'name': 'Lourdes Lostao'}, {'authorId': '2067415352', 'name': 'T. Joiner'}, {'authorId': '2089485189', 'name': 'Miguel A. Santed'}, {'authorId': '5895762', 'name': 'R. Valiente'}]"
1391,788b15af6cf5f787dd41b20cf4f6323e148d9ca6,Young and Elderly Users' Emotion Recognition of Dynamically Formed Expressions Made by a Non-Human Virtual Agent,"The development of non-human robots and virtual agents is focused on encouraging affective communication between humans and agents while supporting the daily life of individuals. For an agent to achieve affective communication with a wide range of users, understanding emotion recognition of an agent's expression is important. In previous studies, age has had an obvious effect on emotion recognition. However, the effect of age on emotion recognition in the context of non-human agents is not yet well understood. In this study, we investigated emotion recognition of young and elderly users when confronted with a non-human agent's expressions. A questionnaire with a seven-emotion alternative forced choice task was used to analyze emotion recognition in 62 young and 39 elderly users. Dynamically formed virtual agent expressions were used to analyze the effect of non-human expressions on emotion recognition. The elderly users had a higher variability of emotion recognition compared with the young users. Studying the individual characteristics of emotion recognition should be prioritized would allow for more affective communication between elderly users and non-human agents.",2019.0,14.0,4.0,False,,{'name': 'Proceedings of the 7th International Conference on Human-Agent Interaction'},"{'bibtex': ""@Book{Numata2019YoungAE,\n author = {Takashi Numata and Yasuhiro Asa and T. Kitagaki and T. Hashimoto and K. Karasawa},\n booktitle = {International Conference on Human-Agent Interaction},\n journal = {Proceedings of the 7th International Conference on Human-Agent Interaction},\n title = {Young and Elderly Users' Emotion Recognition of Dynamically Formed Expressions Made by a Non-Human Virtual Agent},\n year = {2019}\n}\n""}","[{'authorId': '2069073454', 'name': 'Takashi Numata'}, {'authorId': '2661328', 'name': 'Yasuhiro Asa'}, {'authorId': '1391465021', 'name': 'T. Kitagaki'}, {'authorId': '2087690212', 'name': 'T. Hashimoto'}, {'authorId': '3323578', 'name': 'K. Karasawa'}]"
1392,78b780eb6f07e0b36aeaf3af2bf743ee67594373,Empathy-Related Responding and Cognition: A “Chicken and the Egg” Dilemma,,2014.0,0.0,148.0,False,,"{'volume': '', 'pages': '85-110', 'name': ''}","{'bibtex': '@Inproceedings{Eisenberg2014EmpathyRelatedRA,\n author = {N. Eisenberg and Cindy Shea and G. Carlo and G. Knight},\n pages = {85-110},\n title = {Empathy-Related Responding and Cognition: A “Chicken and the Egg” Dilemma},\n year = {2014}\n}\n'}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}, {'authorId': '117097339', 'name': 'Cindy Shea'}, {'authorId': '144124312', 'name': 'G. Carlo'}, {'authorId': '15673391', 'name': 'G. Knight'}]"
1393,78c72d21b62656f71c294133f544a655546c6af6,Emotion-Driven Reinforcement Learning,"Emotion-Driven Reinforcement Learning Robert P. Marinier III, John E. Laird ({rmarinie,laird}@umich.edu) Electrical Engineering and Computer Science Department, 2260 Hayward Ann Arbor, MI 48109 USA augmented Soar with a new module, our emotion system, described below. Abstract Existing computational models of emotion are primarily concerned with creating more realistic agents, with recent efforts looking into matching human data, including qualitative emotional responses and dynamics. In this paper, our work focuses on the functional benefits of emotion in a cognitive system where emotional feedback helps drive reinforcement learning. Our system is an integration of our emotion theory with Soar, an independently-motivated cognitive architecture. Integrating Appraisal Theories and Cognition Our work is grounded in appraisal theories (Roseman & Smith, 2001, for an overview) and Newell’s (1990) PEACTIDM (pronounced PEE-ACK-TEH-DIM). Appraisal theories hypothesize that an emotional reaction to a stimulus is the result of an evaluation of that stimulus along a number of dimensions, most of which relate it to current goals. The particular appraisals that our system uses is a subset of the appraisals described by Scherer (2001) (see Table 1). The subset our system uses can be split into two main groups: appraisals that help the agent decide which stimulus attend to (Suddenness, Unpredictability, Intrinsic Pleasantness, Relevance) and those appraisals that help the agent decide what do in response to an attended stimulus (causal agent and motive, outcome probability, discrepancy from expectation, conduciveness, control, power). Appraisal theories generally do not give much detail about how appraisals are generated or why. That is, the details of the process are left unspecified. Thus, computational models must fill in those details, but with little or no direction from appraisal theory, the details are often arbitrary. PEACTIDM, on the other hand, describes necessary and sufficient processes for immediate behavior (see Table 2). The PEACTIDM hypothesis is that stimuli are Perceived and Encoded so cognition can work with them. Then Attend focuses cognition on one stimulus to process, which is then Comprehended. Tasking is managing tasks and goals (e.g., in response to a change in the situation), whereas Intend is determining what actions to take. Decode and Motor are translating cognitive choices into physical actions. PEACTIDM, however, does not describe the data upon which these processes operate. The basis of our theory is that appraisals are the information upon which the PEACTIDM theory operates (Marinier & Laird, 2006) (see Table 3). For example, the attend process determines what to process next based on appraisal information generated by the perceive and encode processes (i.e., suddenness, unpredictability, intrinsic pleasantness, and relevance). Thus, appraisals not only determine the information that PEACTIDM processes, PEACTIDM also imposes dependencies between the appraisals (e.g., the appraisals for Comprehend cannot occur until after appraisals for Attend have been generated). Keywords: Emotion, reinforcement learning, intrinsic reward, cognitive architecture, appraisal theories. Introduction Folk psychology often casts emotions in a negative light. For example, in Star Trek, Vulcans are portrayed as superior to humans because they are not distracted by emotions, and thus can make purely logical decisions. As far back as Phineas Gage, however, it has been clear that emotions play a critical role in proper functioning in humans, and over the last several decades psychological research has explored how emotions influence behavior. We are interested in exploring how some of the functional capabilities of emotion can be utilized in computational agents; that is, we want to bring the functionality of emotions to artificial intelligence. This is in contrast to most existing computational models of emotion, which focused primarily on creating believable agents (Gratch & Marsella, 2004; Hudlicka, 2004), modeling human data (Marsella & Gratch 2006; Gratch, Marsella, and Mao, 2006), or entertainment (Loyall, Neal Reilly, Bates, and Weyhrauch, 2004). In this paper, we present work in which reinforcement learning is driven by emotion. Intuitively, feelings serve as a reward signal. The agent learns to behave in a way that makes it feel good while avoiding feeling bad. Coupled with a task that the agent wants to complete, the agent learns that completing the task makes it feel good. This work contributes not only to research on emotion in providing a functional computational grounding for feelings, but it also contributes to research in reinforcement learning by providing a detailed theory of the origin and basis of intrinsically-motivated reward. Background Our system in implemented in the Soar cognitive architecture (Newell, 1990). Soar is a complete agent framework composed of interacting, task-independent memory and processing modules that include short- and long-term memory, decision making, learning, and perception. We have",2008.0,18.0,70.0,False,,"{'volume': '30', 'name': ''}","{'bibtex': '@Inproceedings{Marinier2008EmotionDrivenRL,\n author = {Robert P. Marinier and J. Laird},\n title = {Emotion-Driven Reinforcement Learning},\n volume = {30},\n year = {2008}\n}\n'}","[{'authorId': '144843807', 'name': 'Robert P. Marinier'}, {'authorId': '1715438', 'name': 'J. Laird'}]"
1394,78fee77bed169df1895cf8d50593ef1ba23ff58c,"Abuse of technology in adolescence and its relation to social and emotional competencies, emotions in online communication, and bullying",,2018.0,68.0,26.0,False,,"{'volume': '88', 'pages': '114-120', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Nasaescu2018AbuseOT,\n author = {Elena Nasaescu and Inmaculada Marín-López and Vicente J. Llorent and Rosario Ortega-Ruiz and Izabela Zych},\n journal = {Comput. Hum. Behav.},\n pages = {114-120},\n title = {Abuse of technology in adolescence and its relation to social and emotional competencies, emotions in online communication, and bullying},\n volume = {88},\n year = {2018}\n}\n'}","[{'authorId': '51209154', 'name': 'Elena Nasaescu'}, {'authorId': '1403057547', 'name': 'Inmaculada Marín-López'}, {'authorId': '7532567', 'name': 'Vicente J. Llorent'}, {'authorId': '1410571756', 'name': 'Rosario Ortega-Ruiz'}, {'authorId': '2300217', 'name': 'Izabela Zych'}]"
1395,7915637dde7f78fbfd654b77eb7d558e7be7d4b4,Some functions of gaze-direction in social interaction.,,1967.0,30.0,2036.0,False,,"{'volume': '26 1', 'pages': '\n          22-63\n        ', 'name': 'Acta psychologica'}","{'bibtex': '@Article{Kendon1967SomeFO,\n author = {A. Kendon},\n journal = {Acta psychologica},\n pages = {\n          22-63\n        },\n title = {Some functions of gaze-direction in social interaction.},\n volume = {26 1},\n year = {1967}\n}\n'}","[{'authorId': '47985333', 'name': 'A. Kendon'}]"
1396,7925e138e94f926836f3373c7f32b03653077f46,The IRM4S model: the influence/reaction principle for multiagent based simulation,The IRM4S model (Influence Reaction Model for Simulation) is an adaptation of the formalism of [2] for multiagent based simulations (MABS). The goal of IRM4S is to provide a framework that eases the use of the Influence/Reaction principle within MABS.,2007.0,8.0,68.0,True,"{'url': 'https://hal-lirmm.ccsd.cnrs.fr/lirmm-00394198/file/Michel_28.pdf', 'status': None}",{'pages': '133'},"{'bibtex': '@Inproceedings{Michel2007TheIM,\n author = {F. Michel},\n pages = {133},\n title = {The IRM4S model: the influence/reaction principle for multiagent based simulation},\n year = {2007}\n}\n'}","[{'authorId': '1750451', 'name': 'F. Michel'}]"
1397,79439ceba4f6731a900445afff086d1f16c4750b,Gaze and Attention Management for Embodied Conversational Agents,"To facilitate natural interactions between humans and embodied conversational agents (ECAs), we need to endow the latter with the same nonverbal cues that humans use to communicate. Gaze cues in particular are integral in mechanisms for communication and management of attention in social interactions, which can trigger important social and cognitive processes, such as establishment of affiliation between people or learning new information. The fundamental building blocks of gaze behaviors are gaze shifts: coordinated movements of the eyes, head, and body toward objects and information in the environment. In this article, we present a novel computational model for gaze shift synthesis for ECAs that supports parametric control over coordinated eye, head, and upper body movements. We employed the model in three studies with human participants. In the first study, we validated the model by showing that participants are able to interpret the agent’s gaze direction accurately. In the second and third studies, we showed that by adjusting the participation of the head and upper body in gaze shifts, we can control the strength of the attention signals conveyed, thereby strengthening or weakening their social and cognitive effects. The second study shows that manipulation of eye--head coordination in gaze enables an agent to convey more information or establish stronger affiliation with participants in a teaching task, while the third study demonstrates how manipulation of upper body coordination enables the agent to communicate increased interest in objects in the environment.",2015.0,86.0,49.0,False,,"{'volume': '5', 'pages': '1 - 34', 'name': 'ACM Transactions on Interactive Intelligent Systems (TiiS)'}","{'bibtex': '@Article{Pejsa2015GazeAA,\n author = {T. Pejsa and Sean Andrist and Michael Gleicher and Bilge Mutlu},\n journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},\n pages = {1 - 34},\n title = {Gaze and Attention Management for Embodied Conversational Agents},\n volume = {5},\n year = {2015}\n}\n'}","[{'authorId': '2633572', 'name': 'T. Pejsa'}, {'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}]"
1398,79596de8da82cbb219e88b45c808b052606f765d,SUS: A 'Quick and Dirty' Usability Scale,"Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts. This, in turn, means that there are no absolute measures of usability, since, if the usability of an artefact is defined by the context in which that artefact is used, measures of usability must of necessity be defined by that context too. Despite this, there is a need for broad general measures which can be used to compare usability across a range of contexts. In addition, there is a need for “quick and dirty” methods to allow low cost assessments of usability in industrial systems evaluation. This chapter describes the System Usability Scale (SUS) a reliable, low-cost usability scale that can be used for global assessments of systems usability",1996.0,5.0,10940.0,False,,"{'volume': '', 'pages': '207-212', 'name': ''}","{'bibtex': ""@Inproceedings{Brooke1996SUSA,\n author = {J. Brooke},\n pages = {207-212},\n title = {SUS: A 'Quick and Dirty' Usability Scale},\n year = {1996}\n}\n""}","[{'authorId': '145239431', 'name': 'J. Brooke'}]"
1399,7959718ba698e515eef07a6e02bb30fa5bf19e72,Decoding Virtual Agent's Emotion and Strategy from Brain Patterns,"Recent advances in technology have paved the way for humanagent interactions to become ubiquitous in our daily lives, and decades worth of research on virtual agents have enhanced these interactions. However, for the most part, the effect of different types of agents on the human brain is unknown, and the neuroscience of human-agent interactions is rarely studied. In this study, we examine the underlying neural systems involved in processing and responding to different types of negotiating agents. More specifically, we show that different brain patterns are observed for various types of virtual agents; consequently, we can decode the strategy and emotional display of the agent based on the counterpart’s brain activity. Using fMRI data, we analyzed participants’ brain activity during negotiations with agents who show three different emotional expressions and use two different types of negotiation strategies. We demonstrate that, using Multi-Voxel Pattern Analysis, we can reliably decode agents’ emotional expressions based on the activity in the left dorsal anterior insula, and also agents’ strategies based on the activity in the frontal pole.",2017.0,28.0,1.0,False,,"{'name': 'Cognitive Science', 'volume': ''}","{'bibtex': ""@Article{Kim2017DecodingVA,\n author = {Eunkyung Kim and Sarah I. Gimbel and A. Litvinova and J. Kaplan and Morteza Dehghani},\n booktitle = {Annual Meeting of the Cognitive Science Society},\n journal = {Cognitive Science},\n title = {Decoding Virtual Agent's Emotion and Strategy from Brain Patterns},\n year = {2017}\n}\n""}","[{'authorId': '47056370', 'name': 'Eunkyung Kim'}, {'authorId': '40026778', 'name': 'Sarah I. Gimbel'}, {'authorId': '144423532', 'name': 'A. Litvinova'}, {'authorId': '2253951', 'name': 'J. Kaplan'}, {'authorId': '145707560', 'name': 'Morteza Dehghani'}]"
1400,79bf3910522048053206146bedd54d61564f63cb,ENGAGE-DEM: A Model of Engagement of People With Dementia,"One of the most effective ways to improve quality of life in dementia is by exposing people to meaningful activities. The study of engagement is crucial to identify which activities are significant for persons with dementia and customize them. Previous work has mainly focused on developing assessment tools and the only available model of engagement for people with dementia focused on factors influencing engagement or influenced by engagement. This article focuses on the internal functioning of engagement and presents the development and testing of a model specifying the components of engagement, their measures, and the relationships they entertain. We collected behavioral and physiological data while participants with dementia (N = 14) were involved in six sessions of play, three of game-based cognitive stimulation and three of robot-based free play. We tested the concurrent validity of the measures employed to gauge engagement and ran factorial analysis and Structural Equation Modeling to determine whether the components of engagement and their relationships were those hypothesized. The model we constructed, which we call the ENGAGE-DEM, achieved excellent goodness of fit and can be considered a scaffold to the development of affective computing frameworks for measuring engagement online and offline, especially in HCI and HRI.",2020.0,110.0,17.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/5165369/9786538/09035425.pdf', 'status': None}","{'volume': '13', 'pages': '926-943', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Perugia2020ENGAGEDEMAM,\n author = {G. Perugia and Marta Díaz-Boladeras and Andreu Català-Mallofré and E. Barakova and G.W.M. Rauterberg},\n journal = {IEEE Transactions on Affective Computing},\n pages = {926-943},\n title = {ENGAGE-DEM: A Model of Engagement of People With Dementia},\n volume = {13},\n year = {2020}\n}\n'}","[{'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '1413855572', 'name': 'Marta Díaz-Boladeras'}, {'authorId': '1423350437', 'name': 'Andreu Català-Mallofré'}, {'authorId': '145741020', 'name': 'E. Barakova'}, {'authorId': '1736974', 'name': 'G.W.M. Rauterberg'}]"
1401,79f2e8a93993d51574a14ee08ba81a73abd8065d,Towards more behaviours in crowd simulation,"While collision avoidance has been the most active topic in pedestrian simulation, the modelling of other kinds of behaviours appears to be essential for better realism. Thus higher cognitive levels of perception and behaviour improve simulation quality. Furthermore, giving an agent the possibility to choose the nature of its interactions with the others can not only improve simulation realism but also bring heterogeneity in the simulated population because each agent individually perceives the situation according to its own characteristics. In this paper, we aim at providing the pedestrian agent the ability to obtain an individual representation of the environment that allows him to adapt its behaviour according to the situation. We base our work on the analysis and interpretation of the environment, which makes the agent decide the behaviour it is going to adopt. We focus on two kinds of behaviours, following and group avoidance behaviours, and on their integration in classical avoidance simulations. We integrate recent works about following behaviour and propose to model interactions directly with groups of people instead of individuals. We aim at providing perception rules totally independent from the collision avoidance model used in the simulation. Because of the improved perception process, we observe emerging speed waves, group behaviours and lane formation in our simulations. Our results demonstrate the interest of modelling such behaviours to obtain more realistic simulations and show that specific patterns and collective behaviours emerge when using several types of behaviours in simulations. Copyright © 2015 John Wiley & Sons, Ltd.",2016.0,47.0,23.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cav.1629', 'status': None}","{'volume': '27', 'pages': '24 - 34', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Lemercier2016TowardsMB,\n author = {S. Lemercier and J. Auberlet},\n journal = {Computer Animation and Virtual Worlds},\n pages = {24 - 34},\n title = {Towards more behaviours in crowd simulation},\n volume = {27},\n year = {2016}\n}\n'}","[{'authorId': '2341240', 'name': 'S. Lemercier'}, {'authorId': '1974013', 'name': 'J. Auberlet'}]"
1402,7a0c01f4cbca7b633001058c93311d7d1806808f,"A virtual reality application in role-plays of social skills training for schizophrenia: A randomized, controlled trial",,2011.0,26.0,196.0,False,,"{'volume': '189', 'pages': '166-172', 'name': 'Psychiatry Research'}","{'bibtex': '@Article{Park2011AVR,\n author = {Kyung-Min Park and J. Ku and Soo-Hee Choi and H. Jang and Ji-Yeon Park and Sun I. Kim and Jae-Jin Kim},\n journal = {Psychiatry Research},\n pages = {166-172},\n title = {A virtual reality application in role-plays of social skills training for schizophrenia: A randomized, controlled trial},\n volume = {189},\n year = {2011}\n}\n'}","[{'authorId': '2152042882', 'name': 'Kyung-Min Park'}, {'authorId': '143720898', 'name': 'J. Ku'}, {'authorId': '2108644920', 'name': 'Soo-Hee Choi'}, {'authorId': '3287618', 'name': 'H. Jang'}, {'authorId': '2124232695', 'name': 'Ji-Yeon Park'}, {'authorId': '1455996091', 'name': 'Sun I. Kim'}, {'authorId': '2145449477', 'name': 'Jae-Jin Kim'}]"
1403,7a2072d69e2538de875434ba3cb0b74f467a99fb,Does the chimpanzee have a theory of mind?,"Abstract An individual has a theory of mind if he imputes mental states to himself and others. A system of inferences of this kind is properly viewed as a theory because such states are not directly observable, and the system can be used to make predictions about the behavior of others. As to the mental states the chimpanzee may infer, consider those inferred by our own species, for example, purpose or intention, as well as knowledge, belief, thinking, doubt, guessing, pretending, liking, and so forth. To determine whether or not the chimpanzee infers states of this kind, we showed an adult chimpanzee a series of videotaped scenes of a human actor struggling with a variety of problems. Some problems were simple, involving inaccessible food – bananas vertically or horizontally out of reach, behind a box, and so forth – as in the original Kohler problems; others were more complex, involving an actor unable to extricate himself from a locked cage, shivering because of a malfunctioning heater, or unable to play a phonograph because it was unplugged. With each videotape the chimpanzee was given several photographs, one a solution to the problem, such as a stick for the inaccessible bananas, a key for the locked up actor, a lit wick for the malfunctioning heater. The chimpanzee's consistent choice of the correct photographs can be understood by assuming that the animal recognized the videotape as representing a problem, understood the actor's purpose, and chose alternatives compatible with that purpose.",1978.0,22.0,6047.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/1E96B02CD9850016B7C93BC6D2FEF1D0/S0140525X00076512a.pdf/div-class-title-does-the-chimpanzee-have-a-theory-of-mind-div.pdf', 'status': None}","{'volume': '1', 'pages': '515 - 526', 'name': 'Behavioral and Brain Sciences'}","{'bibtex': '@Article{Premack1978DoesTC,\n author = {D. Premack},\n journal = {Behavioral and Brain Sciences},\n pages = {515 - 526},\n title = {Does the chimpanzee have a theory of mind?},\n volume = {1},\n year = {1978}\n}\n'}","[{'authorId': '3797168', 'name': 'D. Premack'}]"
1404,7a20a3c31bf313f1c91784bd10b136b67231569c,Embodied conversational agents in computer assisted language learning,,2009.0,42.0,136.0,True,"{'url': 'http://www.speech.kth.se/prod/publications/files/3350.pdf', 'status': None}","{'volume': '51', 'pages': '1024-1037', 'name': 'Speech Commun.'}","{'bibtex': '@Article{Wik2009EmbodiedCA,\n author = {Preben Wik and Anna Hjalmarsson},\n journal = {Speech Commun.},\n pages = {1024-1037},\n title = {Embodied conversational agents in computer assisted language learning},\n volume = {51},\n year = {2009}\n}\n'}","[{'authorId': '3113645', 'name': 'Preben Wik'}, {'authorId': '2524288', 'name': 'Anna Hjalmarsson'}]"
1405,7a2bbe6de1084900e2a7022b53a5a36aaff66668,From Non-verbal Signals Sequence Mining to Bayesian Networks for Interpersonal Attitudes Expression,,2014.0,48.0,33.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-01074880/file/iva2014camreadyv3nocolor.pdf', 'status': None}",{'pages': '120-133'},"{'bibtex': '@Inproceedings{Chollet2014FromNS,\n author = {Mathieu Chollet and M. Ochs and C. Pelachaud},\n pages = {120-133},\n title = {From Non-verbal Signals Sequence Mining to Bayesian Networks for Interpersonal Attitudes Expression},\n year = {2014}\n}\n'}","[{'authorId': '40325099', 'name': 'Mathieu Chollet'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1407,7a3362a372a888dfd4662a6b7dffb33b0a70f582,An ADRC Method for Noncascaded Integral Systems Based on Algebraic Substitution Method and Its Structure,"The Active Disturbance Rejection Control (ADRC) prefers the cascaded integral system for a convenient design or better control effect and takes it as a typical form. However, the state variables of practical system do not necessarily have a cascaded integral relationship. Therefore, this paper proposes an algebraic substitution method and its structure, which can convert a noncascaded integral system of PID control into a cascaded integral form. The adjusting parameters of the ADRC controller are also demonstrated. Meanwhile, a numerical example and the oscillation control of a flexible arm are demonstrated to show the conversion, controller design, and control effect. The converted system is proved to be more suitable for a direct ADRC control. In addition, for the numerical example, its control effect for the converted system is compared with a PID controller under different disturbances. The result shows that the converted system can achieve a better control effect under the ADRC than that of a PID. The theory is a guide before practice. This converting method not only solves the ADRC control problem of some noncascaded integral systems in theory and simulation but also expands the application scope of the ADRC method.",2018.0,32.0,92.0,True,,{'name': 'Mathematical Problems in Engineering'},"{'bibtex': '@Article{Huang2018AnAM,\n author = {Zhijian Huang and Yudong Li and Yihua Liu and Wenbo Sui and Gui-chen Zhang},\n journal = {Mathematical Problems in Engineering},\n title = {An ADRC Method for Noncascaded Integral Systems Based on Algebraic Substitution Method and Its Structure},\n year = {2018}\n}\n'}","[{'authorId': '144829273', 'name': 'Zhijian Huang'}, {'authorId': '2111162773', 'name': 'Yudong Li'}, {'authorId': '2015975461', 'name': 'Yihua Liu'}, {'authorId': '153799202', 'name': 'Wenbo Sui'}, {'authorId': '3214953', 'name': 'Gui-chen Zhang'}]"
1408,7a3db5fe8dc49d893851e4bc0ffa9d87944c8cea,"Multi-party, Multi-issue, Multi-strategy Negotiation for Multi-modal Virtual Agents",,2008.0,34.0,169.0,True,"{'url': 'http://www.ict.usc.edu/~traum/Papers/multi-neg5.pdf', 'status': None}",{'pages': '117-130'},"{'bibtex': '@Inproceedings{Traum2008MultipartyMM,\n author = {D. Traum and S. Marsella and J. Gratch and Jina Lee and Arno Hartholt},\n pages = {117-130},\n title = {Multi-party, Multi-issue, Multi-strategy Negotiation for Multi-modal Virtual Agents},\n year = {2008}\n}\n'}","[{'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '9174234', 'name': 'Jina Lee'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}]"
1409,7a49d92e9d7f7a526996f27f139b9ff6fab27dbf,Creative People Create Values: Creativity and Positive Arousal in Negotiations,"Most negotiations are ill-structured situations, and the ability to identify novel options is likely to be crucial for success. This study, therefore, examined how creativity impacts negotiation processes and outcomes, and how this effect is moderated by positive arousal. The negotiators’ creative personality and their state of positive arousal were measured before they participated in a simulated negotiation, with the results demonstrating that the level of creativity in negotiation dyads was positively related to the negotiators’ joint outcome. Negotiators in high creativity dyads searched for more information by asking questions about priorities and were less narrowly focused by providing fewer single-issue offers than negotiators in low creativity dyads. Positive arousal did not affect outcome directly, but moderated the effect of creativity on joint outcomes; the effect of creativity was strongest under high levels of positive arousal. The discussion section emphasizes that future research may find creativity to have even more of a positive effect when negotiations become more complex.",2013.0,46.0,9.0,False,,"{'volume': '25', 'pages': '408 - 417', 'name': 'Creativity Research Journal'}","{'bibtex': '@Article{Schei2013CreativePC,\n author = {Vidar Schei},\n journal = {Creativity Research Journal},\n pages = {408 - 417},\n title = {Creative People Create Values: Creativity and Positive Arousal in Negotiations},\n volume = {25},\n year = {2013}\n}\n'}","[{'authorId': '4235481', 'name': 'Vidar Schei'}]"
1410,7a7c02442477274ca59f8933ed91454eb0686ca8,"Intelligent virtual agent, learning how to reach a goal by making the least number of compromises","The learning process in the Q-learning algorithm is characterized by maximizing a single, numerical reward signal. However, there are tasks for which the requirements toward the way to reach a goal are complex. This paper proposes a modification to the Q-learning algorithm. In order to make the Q-learning agent find the optimal path to the goal by meeting particular complex criteria, the use of measures model (a model of environment criteria), represented as a new memory matrix, is introduced. If the goal cannot be reached by following the pre-set criteria, the learning agent can compromise a given criterion. The agent makes the least possible number of tradeoffs in order to reach the goal. If the criteria are arranged by their level of importance, then the agent can choose more in number and more acceptable compromises. The aim of the modification is to empower the learning agent to control the way of reaching a goal. The modified algorithm has been applied to training smart shopping-cart learning agents. The tests show improvement in their behaviour.",2020.0,11.0,1.0,True,,"{'volume': '878', 'name': 'IOP Conference Series: Materials Science and Engineering'}","{'bibtex': '@Article{Budakova2020IntelligentVA,\n author = {D. Budakova and Veselka Petrova-Dimitrova and L. Dakovski},\n journal = {IOP Conference Series: Materials Science and Engineering},\n title = {Intelligent virtual agent, learning how to reach a goal by making the least number of compromises},\n volume = {878},\n year = {2020}\n}\n'}","[{'authorId': '1799528', 'name': 'D. Budakova'}, {'authorId': '1581448954', 'name': 'Veselka Petrova-Dimitrova'}, {'authorId': '1753312', 'name': 'L. Dakovski'}]"
1411,7aa83dc8d507fc38aa97e22233d96fd878ff7e51,NEUROCEPTION: A Subconscious System for Detecting Threats and Safety,"W hat determines how two human beings will act toward each other when they meet? Is this initial response a product of learning from culture, family experiences, and other socialization processes? Or is the response the expression of a neurobiological process that is programmed into the very DNA of our species? If the response has a neurobiological basis, are there specific features of the other person’s behavior that trigger either feelings of safety, love, and comfort or feelings of danger? Why do some children cuddle and warmly conform to embraces, yet others stiffen and pull back from the same overture? Why do some children smile and actively engage a new person, while others avert their gaze and withdraw? Does knowledge of human biology help us to understand the triggers and mechanisms of these behaviors during normal development? If we learn how behavioral features trigger neural circuits that facilitate social behavior, will we be better able to help children with severe developmental disabilities, such as autism, improve their social behavior? By processing information from the environment through the senses, the nervous system continually evaluates risk. I have coined the term neuroception to describe how PHOTO: MARILYN NOLT",2004.0,8.0,132.0,False,,"{'volume': '24', 'pages': '19-24', 'name': 'Zero to Three'}","{'bibtex': '@Article{Porges2004NEUROCEPTIONAS,\n author = {S. Porges},\n journal = {Zero to Three},\n pages = {19-24},\n title = {NEUROCEPTION: A Subconscious System for Detecting Threats and Safety},\n volume = {24},\n year = {2004}\n}\n'}","[{'authorId': '4226466', 'name': 'S. Porges'}]"
1412,7ac39f2da12e4a4d25b2806d47e6655d1f9e4cbf,Designing presentation in multimedia interfaces,"We investigated subjects’ responses to a synthesized talking face displayed on a computer screen in the context of a questionnaire study. Compared to subjects who answered questions presented via text display on a screen, subjects who answered the same questions spoken by a talking face spent more time, made fewer mistakes, and wrote more comments. When we compared responses to two different talking faces, subjects who answered questions spoken by a stern face, compared to subjects who answered questions spoken by a neutral face, spent more time, made fewer mistakes, and wrote more comments. They also liked the experience and the face less. We interpret this study in the light of desires to anthropomorphize computer interfaces and suggest that incautiously adding human characteristics, like face, voice, and facial expressions, could make the experience for users worse rather than better.",1994.0,60.0,261.0,True,,{'name': 'Conference Companion on Human Factors in Computing Systems'},"{'bibtex': '@Article{Sutcliffe1994DesigningPI,\n author = {A. Sutcliffe and Peter Faraday},\n journal = {Conference Companion on Human Factors in Computing Systems},\n title = {Designing presentation in multimedia interfaces},\n year = {1994}\n}\n'}","[{'authorId': '1683823', 'name': 'A. Sutcliffe'}, {'authorId': '2613856', 'name': 'Peter Faraday'}]"
1414,7acd939a05ff4fb7480d21dc38b6a5b06d4e36de,CyberCode: designing augmented reality environments with visual tags,"The CyberCode is a visual tagging system based on a 2D-barcode technology and provides several features not provided by other tagging systems. CyberCode tags can be recognized by the low-cost CMOS or CCD cameras found in more and more mobile devices, and it can also be used to determine the 3D position of the tagged object as well as its ID number. This paper describes examples of augmented reality applications based on CyberCode, and discusses some key characteristics of tagging technologies that must be taken into account when designing augmented reality environments.",2000.0,25.0,517.0,False,,{'pages': '1-10'},"{'bibtex': '@Inproceedings{Rekimoto2000CyberCodeDA,\n author = {J. Rekimoto and Y. Ayatsuka},\n pages = {1-10},\n title = {CyberCode: designing augmented reality environments with visual tags},\n year = {2000}\n}\n'}","[{'authorId': '1685962', 'name': 'J. Rekimoto'}, {'authorId': '2446448', 'name': 'Y. Ayatsuka'}]"
1415,7ad046adf456f0b734585e1f6789fafb8ead1d30,Modelling Two Emotion Regulation Strategies as Key Features of Therapeutic Empathy,,2014.0,39.0,16.0,False,,{'pages': '115-133'},"{'bibtex': '@Inproceedings{Martínez-Miranda2014ModellingTE,\n author = {J. Martínez-Miranda and A. Bresó and J. M. García-Gómez},\n pages = {115-133},\n title = {Modelling Two Emotion Regulation Strategies as Key Features of Therapeutic Empathy},\n year = {2014}\n}\n'}","[{'authorId': '1398008961', 'name': 'J. Martínez-Miranda'}, {'authorId': '3352168', 'name': 'A. Bresó'}, {'authorId': '1388884721', 'name': 'J. M. García-Gómez'}]"
1416,7ad1c4547b76d51398c1e2ca66173ffb2f78f838,Primitive emotional contagion.,,1992.0,0.0,557.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hatfield1992PrimitiveEC,\n author = {E. Hatfield and J. Cacioppo and Richard L. Rapson},\n title = {Primitive emotional contagion.},\n year = {1992}\n}\n'}","[{'authorId': '48279878', 'name': 'E. Hatfield'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}, {'authorId': '8611261', 'name': 'Richard L. Rapson'}]"
1417,7ae345d187bfb582edf51e0f152f02969f270c70,A Framework for Mobile-Assisted Formative Assessment to Promote Students' Self-Determination,"Motivation is an important issue to consider when designing learning activities, including mobile learning and assessment. While previous research provides evidence for the motivational impact of mobile learning, not many pedagogical frameworks exist for the design of mobile-assisted learning and assessment. The current study is grounded in the Self-Determination Theory of motivation and proposes a pedagogical framework for mobile-assisted formative assessment, aiming at enhancing student motivation. For a preliminary evaluation of the framework, fifty-one students from a public European high school participated in a series of formative assessment activities. The tasks that were implemented according to the proposed mobile-based formative assessment framework had a significant positive impact on student perceived levels of autonomy, competence, and relatedness, enhancing students’ intrinsic motivation levels. Study findings highlighted the capacity of the proposed framework to guide the design of mobile-based formative assessment activities that enhance and promote student motivation. The study makes a theoretical contribution by proposing a framework that aligns mobile learning and assessment with elements of the Self-Determination Theory of motivation and also has a practical contribution by implementing mobile learning and assessment practices that have the potential to promote student motivation.",2021.0,79.0,6.0,True,"{'url': 'https://www.mdpi.com/1999-5903/13/5/116/pdf?version=1619766567', 'status': None}","{'volume': '13', 'pages': '116', 'name': 'Future Internet'}","{'bibtex': ""@Article{Nikou2021AFF,\n author = {S. Nikou and A. Economides},\n journal = {Future Internet},\n pages = {116},\n title = {A Framework for Mobile-Assisted Formative Assessment to Promote Students' Self-Determination},\n volume = {13},\n year = {2021}\n}\n""}","[{'authorId': '1786903', 'name': 'S. Nikou'}, {'authorId': '1741577', 'name': 'A. Economides'}]"
1418,7ae756121b6a56d6bb3ecc2476519a29fdc30a61,"Activity Theory: who is doing what, why and how","In simple terms, Activity Theory is all about 'who is doing what, why and how'. However, things are rarely that simple. Sometimes referred to as the Cultural-Historical Activity Theory (CHAT), Activity Theory is grounded in the work of the Russian psychologist Vygotsky and his students, in particular, Leontiev, in the 1920s. Activity Theory provides a lens with which to tease out and to better understand human activity.",2014.0,10.0,73.0,False,,"{'volume': '', 'pages': '9', 'name': ''}","{'bibtex': '@Inproceedings{Hasan2014ActivityTW,\n author = {H. Hasan and A. Kazlauskas},\n pages = {9},\n title = {Activity Theory: who is doing what, why and how},\n year = {2014}\n}\n'}","[{'authorId': '143812974', 'name': 'H. Hasan'}, {'authorId': '1768405', 'name': 'A. Kazlauskas'}]"
1419,7b1120af8f4fe4154a9549118b4c7f7e9e2b0114,An Event-Based Architecture to Manage Virtual Human Non-Verbal Communication in 3D Chatting Environment,,2012.0,21.0,16.0,False,,{'pages': '58-68'},"{'bibtex': '@Inproceedings{Gobron2012AnEA,\n author = {S. Gobron and Junghyun Ahn and David García and Quentin Silvestre and D. Thalmann and R. Boulic},\n pages = {58-68},\n title = {An Event-Based Architecture to Manage Virtual Human Non-Verbal Communication in 3D Chatting Environment},\n year = {2012}\n}\n'}","[{'authorId': '1696846', 'name': 'S. Gobron'}, {'authorId': '1683972', 'name': 'Junghyun Ahn'}, {'authorId': '144240725', 'name': 'David García'}, {'authorId': '2007169', 'name': 'Quentin Silvestre'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}, {'authorId': '1696973', 'name': 'R. Boulic'}]"
1420,7b221cce8fdbc1105956b27c938730fce8c1fc10,Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory,"
 
 Perception and expression of emotion are key factors to the success of dialogue systems or conversational agents. However, this problem has not been studied in large-scale conversation generation so far. In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor using three new mechanisms that respectively (1) models the high-level abstraction of emotion expressions by embedding emotion categories, (2) captures the change of implicit internal emotion states, and (3) uses explicit emotion expressions with an external emotion vocabulary. Experiments show that the proposed model can generate responses appropriate not only in content but also in emotion.
 
",2017.0,61.0,633.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/11325/11184', 'status': None}",{'pages': '730-739'},"{'bibtex': '@Inproceedings{Zhou2017EmotionalCM,\n author = {Hao Zhou and Minlie Huang and Tianyang Zhang and Xiaoyan Zhu and Bing-Qian Liu},\n pages = {730-739},\n title = {Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory},\n year = {2017}\n}\n'}","[{'authorId': '144751955', 'name': 'Hao Zhou'}, {'authorId': '1730108', 'name': 'Minlie Huang'}, {'authorId': '50615630', 'name': 'Tianyang Zhang'}, {'authorId': '145213540', 'name': 'Xiaoyan Zhu'}, {'authorId': '2149124481', 'name': 'Bing-Qian Liu'}]"
1421,7b2dc1e9955d5891f9bcd5b612d99091597a671b,"Felt, false, and miserable smiles",,1982.0,29.0,923.0,False,,"{'volume': '6', 'pages': '238-252', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Ekman1982FeltFA,\n author = {P. Ekman and Wallace V. Friesen},\n journal = {Journal of Nonverbal Behavior},\n pages = {238-252},\n title = {Felt, false, and miserable smiles},\n volume = {6},\n year = {1982}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}]"
1422,7b329ca8d2afe053c8eb13c3562b3aa37acdb54f,Evidence for a three-factor theory of emotions,,1977.0,28.0,1691.0,False,,"{'volume': '11', 'pages': '273-294', 'name': 'Journal of Research in Personality'}","{'bibtex': '@Article{Russell1977EvidenceFA,\n author = {J. Russell and A. Mehrabian},\n journal = {Journal of Research in Personality},\n pages = {273-294},\n title = {Evidence for a three-factor theory of emotions},\n volume = {11},\n year = {1977}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '144102217', 'name': 'A. Mehrabian'}]"
1423,7b388c66af4cf854beffaffbf43abce123a557d4,Multimodal human emotion/expression recognition,"Recognizing human facial expression and emotion by computer is an interesting and challenging problem. Many have investigated emotional contents in speech alone, or recognition of human facial expressions solely from images. However, relatively little has been done in combining these two modalities for recognizing human emotions. L.C. De Silva et al. (1997) studied human subjects' ability to recognize emotions from viewing video clips of facial expressions and listening to the corresponding emotional speech stimuli. They found that humans recognize some emotions better by audio information, and other emotions better by video. They also proposed an algorithm to integrate both kinds of inputs to mimic human's recognition process. While attempting to implement the algorithm, we encountered difficulties which led us to a different approach. We found these two modalities to be complimentary. By using both, we show it is possible to achieve higher recognition rates than either modality alone.",1998.0,17.0,194.0,False,,"{'pages': '366-371', 'name': 'Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition'}","{'bibtex': '@Article{Chen1998MultimodalHE,\n author = {Lawrence S. Chen and Thomas S. Huang and T. Miyasato and R. Nakatsu},\n journal = {Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition},\n pages = {366-371},\n title = {Multimodal human emotion/expression recognition},\n year = {1998}\n}\n'}","[{'authorId': '2108579847', 'name': 'Lawrence S. Chen'}, {'authorId': '153652752', 'name': 'Thomas S. Huang'}, {'authorId': '2407080', 'name': 'T. Miyasato'}, {'authorId': '2458123', 'name': 'R. Nakatsu'}]"
1424,7b70ff3fbc3e9fdee619b445af17d34c3a964f68,The Attractiveness Stereotype in the Evaluation of Embodied Conversational Agents,,2009.0,27.0,32.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-642-03655-2_10.pdf', 'status': None}",{'pages': '85-97'},"{'bibtex': '@Inproceedings{Khan2009TheAS,\n author = {R. Khan and A. D. Angeli},\n pages = {85-97},\n title = {The Attractiveness Stereotype in the Evaluation of Embodied Conversational Agents},\n year = {2009}\n}\n'}","[{'authorId': '153914091', 'name': 'R. Khan'}, {'authorId': '34919047', 'name': 'A. D. Angeli'}]"
1425,7b9038848463f0306bc527a46241c16b28b12411,Probabilistic assessment of user's emotions in educational games,"We present a probabilistic model to monitor a user's emotions and engagement during the interaction with educational games. We illustrate how our probabilistic model assesses affect by integrating evidence on both possible causes of the user's emotional arousal (i.e., the state of the interaction) and its effects (i.e., bodily expressions that are known to be influenced by emotional reactions). The probabilistic model relies on a Dynamic Decision Network to leverage any indirect evidence on the user's emotional state, in order to estimate this state and any other related variable in the model. This is crucial in a modeling task in which the available evidence usually varies with the user and with each particular interaction. The probabilistic model we present is to be used by decision theoretic pedagogical agents to generate interventions aimed at achieving the best tradeoff between a user's learning and engagement during the interaction with educational games.",2002.0,44.0,579.0,True,"{'url': 'http://www.cs.ubc.ca/~conati/my-papers/jaai02.pdf', 'status': None}","{'volume': '16', 'pages': '555 - 575', 'name': 'Applied Artificial Intelligence'}","{'bibtex': ""@Article{Conati2002ProbabilisticAO,\n author = {C. Conati},\n journal = {Applied Artificial Intelligence},\n pages = {555 - 575},\n title = {Probabilistic assessment of user's emotions in educational games},\n volume = {16},\n year = {2002}\n}\n""}","[{'authorId': '1692714', 'name': 'C. Conati'}]"
1428,7b99024ec3c346929da5eb95fa1aa6b1cb4590c8,The development and evaluation of an emotional support algorithm for carers,"Carers - people who provide regular support for a friend or relative who could not manage without them - frequently report high levels of stress. Good emotional support could help relieve this stress. This study uses seven scenarios that depict different types of stress and acquires emotional support messages for them. We then categorize and evaluate the emotional support for different types of stress. We found that telling the carer they are appreciated and offering support are the best types of emotional support. Additionally, we found that how well a supporter sympathises with a situation affects the type of support they consider suitable. We describe and evaluate an algorithm that selects different categories of support to be used by an intelligent virtual agent to provide emotional support to carers experiencing different types of stress.",2014.0,27.0,15.0,True,"{'url': 'https://aura.abdn.ac.uk/bitstream/2164/4563/1/AIHCIpaper.pdf', 'status': None}","{'volume': '8', 'pages': '181-196', 'name': 'Intelligenza Artificiale'}","{'bibtex': '@Article{Smith2014TheDA,\n author = {K. Smith and J. Masthoff and N. Tintarev and Wendy Moncur},\n journal = {Intelligenza Artificiale},\n pages = {181-196},\n title = {The development and evaluation of an emotional support algorithm for carers},\n volume = {8},\n year = {2014}\n}\n'}","[{'authorId': '1400110905', 'name': 'K. Smith'}, {'authorId': '145428594', 'name': 'J. Masthoff'}, {'authorId': '1803171', 'name': 'N. Tintarev'}, {'authorId': '1758268', 'name': 'Wendy Moncur'}]"
1429,7bb9285380b76cb1a330129a94e7b7c3c86551f6,Propagating temporal relations of intervals by matrix,"Traditional temporal relations propagating is based on Allen's Interval Algebra. This paper proposes an alternative method to propagate temporal relations among intervals, in which 5 2 5 matrices are used to represent temporal relations of intervals. Hence, the propagation of temporal relations is transformed into a numerical computation. For efficiency, we use the special values of the thirteen matrices to determine the possible temporal relations between two given intervals by using only the final resultant matrix so as to optimize the propagation. To evaluate the utility of the proposed technique, we have implemented the matrix representation in Java. The experimental results demonstrate that the approach is efficient and promising.",2002.0,48.0,24.0,False,,"{'volume': '16', 'pages': '1 - 27', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Zhang2002PropagatingTR,\n author = {Shichao Zhang and Chengqi Zhang},\n journal = {Applied Artificial Intelligence},\n pages = {1 - 27},\n title = {Propagating temporal relations of intervals by matrix},\n volume = {16},\n year = {2002}\n}\n'}","[{'authorId': '1734695', 'name': 'Shichao Zhang'}, {'authorId': '32076894', 'name': 'Chengqi Zhang'}]"
1430,7bbee726f872db1326e0e726463eaa4c837dc581,Estrategias para mejorar el cumplimiento terapéutico,,2001.0,106.0,42.0,False,,"{'volume': '8', 'pages': '558-573', 'name': 'FMC - Formación Médica Continuada en Atención Primaria'}","{'bibtex': '@Article{Contreras2001EstrategiasPM,\n author = {E. M. Contreras and J. C. Martínez and J. J. M. Cabeza},\n journal = {FMC - Formación Médica Continuada en Atención Primaria},\n pages = {558-573},\n title = {Estrategias para mejorar el cumplimiento terapéutico},\n volume = {8},\n year = {2001}\n}\n'}","[{'authorId': '48119803', 'name': 'E. M. Contreras'}, {'authorId': '15888485', 'name': 'J. C. Martínez'}, {'authorId': '144747772', 'name': 'J. J. M. Cabeza'}]"
1431,7be5e7f4acebda9adb9a864feeb1640423c0ce49,Toward an Understanding of Authentic Learning: Student Perceptions of an Authentic Classroom,,2000.0,35.0,97.0,False,,"{'volume': '9', 'pages': '79-94', 'name': 'Journal of Science Education and Technology'}","{'bibtex': '@Article{Nicaise2000TowardAU,\n author = {Molly Nicaise and T. Gibney and M. Crane},\n journal = {Journal of Science Education and Technology},\n pages = {79-94},\n title = {Toward an Understanding of Authentic Learning: Student Perceptions of an Authentic Classroom},\n volume = {9},\n year = {2000}\n}\n'}","[{'authorId': '66949899', 'name': 'Molly Nicaise'}, {'authorId': '2097029242', 'name': 'T. Gibney'}, {'authorId': '2058958391', 'name': 'M. Crane'}]"
1432,7bf2d2bdde14b0dcd9a73f97f8df4743bc33630b,An embodiment effect in computer-based learning with animated pedagogical agents.,"How do social cues such as gesturing, facial expression, eye gaze, and human-like movement affect multimedia learning with onscreen agents? To help address this question, students were asked to twice view a 4-min narrated presentation on how solar cells work in which the screen showed an animated pedagogical agent standing to the left of 11 successive slides. Across three experiments, learners performed better on a transfer test when a human-voiced agent displayed human-like gestures, facial expression, eye gaze, and body movement than when the agent did not, yielding an embodiment effect. In Experiment 2 the embodiment effect was found when the agent spoke in a human voice but not in a machine voice. In Experiment 3, the embodiment effect was found both when students were told the onscreen agent was consistent with their choice of agent characteristics and when inconsistent. Students who viewed a highly embodied agent also rated the social attributes of the agent more positively than did students who viewed a nongesturing agent. The results are explained by social agency theory, in which social cues in a multimedia message prime a feeling of social partnership in the learner, which leads to deeper cognitive processing during learning, and results in a more meaningful learning outcome as reflected in transfer test performance.",2012.0,68.0,213.0,False,,"{'volume': '18 3', 'pages': '\n          239-52\n        ', 'name': 'Journal of experimental psychology. Applied'}","{'bibtex': '@Article{Mayer2012AnEE,\n author = {R. Mayer and C. Dapra},\n journal = {Journal of experimental psychology. Applied},\n pages = {\n          239-52\n        },\n title = {An embodiment effect in computer-based learning with animated pedagogical agents.},\n volume = {18 3},\n year = {2012}\n}\n'}","[{'authorId': '1819200', 'name': 'R. Mayer'}, {'authorId': '8359211', 'name': 'C. Dapra'}]"
1433,7c0220f4a3f19b24fce735382a863b60d7f28c5e,Pupil size variation as an indication of affective processing,,2003.0,51.0,747.0,False,,"{'volume': '59', 'pages': '185-198', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Partala2003PupilSV,\n author = {Timo Partala and Veikko Surakka},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {185-198},\n title = {Pupil size variation as an indication of affective processing},\n volume = {59},\n year = {2003}\n}\n'}","[{'authorId': '1729279', 'name': 'Timo Partala'}, {'authorId': '1718377', 'name': 'Veikko Surakka'}]"
1434,7c1d4fbaff6a275e8cd384c281668ffb6d038dd5,"Who, Me? How Virtual Agents Can Shape Conversational Footing in Virtual Reality",,2017.0,31.0,16.0,False,,{'pages': '347-359'},"{'bibtex': '@Inproceedings{Pejsa2017WhoMH,\n author = {T. Pejsa and Michael Gleicher and Bilge Mutlu},\n pages = {347-359},\n title = {Who, Me? How Virtual Agents Can Shape Conversational Footing in Virtual Reality},\n year = {2017}\n}\n'}","[{'authorId': '2633572', 'name': 'T. Pejsa'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}]"
1435,7c287f054c96d16f643eb2d7bfbfffc23147d00b,An AR Puzzle Application for Improving Emotion Recognition for AS Children,"Affecting to around 1% of the population, Autism is sometimes described as a different approach to interacting with the world. Adapting the surrounding objects and systems can improve their experience and their relative's. This project is based on previous research where it has been shown that toys can influence positively in a child's development. Also, new technologies as Augmented Reality (AR) can be beneficial for these children in attracting and keeping their attention. The proposed game would engage the player by first creating a customized monster with the help of different AR markers. In a second stage, the player would try to guess the emotion of different monsters or virtual humans. The game will be tested in further stages to check its suitability for the AS children and the effect on their emotion recognition skills.",2019.0,30.0,4.0,False,,{'name': 'Proceedings of the 3rd International Conference on Digital Technology in Education'},"{'bibtex': '@Article{Daniel2019AnAP,\n author = {Vicente Lopez Trompo Daniel and Han Ting and P. Ratsamee and Haruo Takemura},\n journal = {Proceedings of the 3rd International Conference on Digital Technology in Education},\n title = {An AR Puzzle Application for Improving Emotion Recognition for AS Children},\n year = {2019}\n}\n'}","[{'authorId': '2072583196', 'name': 'Vicente Lopez Trompo Daniel'}, {'authorId': '2072508081', 'name': 'Han Ting'}, {'authorId': '3320826', 'name': 'P. Ratsamee'}, {'authorId': '2204175823', 'name': 'Haruo Takemura'}]"
1436,7c3708e5cf52f6354916d7b565f33b35b5595e92,Challenges in real-life emotion annotation and machine learning based detection,,2005.0,39.0,359.0,False,,"{'volume': '18 4', 'pages': '\n          407-22\n        ', 'name': 'Neural networks : the official journal of the International Neural Network Society'}","{'bibtex': '@Article{Devillers2005ChallengesIR,\n author = {L. Devillers and L. Vidrascu and L. Lamel},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          407-22\n        },\n title = {Challenges in real-life emotion annotation and machine learning based detection},\n volume = {18 4},\n year = {2005}\n}\n'}","[{'authorId': '1713369', 'name': 'L. Devillers'}, {'authorId': '1766081', 'name': 'L. Vidrascu'}, {'authorId': '145204681', 'name': 'L. Lamel'}]"
1437,7c4a4b065cf18f7b13e6648ef12c42fd8bb79735,Dynamic Emotional Language Adaptation in Multiparty Interactions with Agents,"In order to achieve more believable interactions with artificial agents, there is a need to produce dialogue that is not only relevant, but also emotionally appropriate and consistent. This paper presents a comprehensive system that models the emotional state of users and an agent to dynamically adapt dialogue utterance selection. A Partially Observable Markov Decision Process (POMDP) with an online solver is used to model user reactions in real-time. The model decides the emotional content of the next utterance based on the rewards from the users and the agent. The previous approaches are extended through jointly modeling the user and agent emotions, maintaining this model over time with a memory, and enabling interactions with multiple users. A proof of concept user study is used to demonstrate that the system can deliver and maintain distinct agent personalities during multiparty interactions.",2020.0,47.0,3.0,True,"{'url': 'https://pearl.plymouth.ac.uk/bitstream/10026.1/16700/1/irfan2020iva.pdf', 'status': None}",{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Irfan2020DynamicEL,\n author = {Bahar Irfan and Anika Narayanan and James Kennedy},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Dynamic Emotional Language Adaptation in Multiparty Interactions with Agents},\n year = {2020}\n}\n'}","[{'authorId': '9538117', 'name': 'Bahar Irfan'}, {'authorId': '1999878327', 'name': 'Anika Narayanan'}, {'authorId': '143953789', 'name': 'James Kennedy'}]"
1438,7c79e32240ade9b3c51dc9d6369f7f7b8df0d297,Behavior Matching in Multimodal Communication Is Synchronized,"A variety of theoretical frameworks predict the resemblance of behaviors between two people engaged in communication, in the form of coordination, mimicry, or alignment. However, little is known about the time course of the behavior matching, even though there is evidence that dyads synchronize oscillatory motions (e.g., postural sway). This study examined the temporal structure of nonoscillatory actions-language, facial, and gestural behaviors-produced during a route communication task. The focus was the temporal relationship between matching behaviors in the interlocutors (e.g., facial behavior in one interlocutor vs. the same facial behavior in the other interlocutor). Cross-recurrence analysis revealed that within each category tested (language, facial, gestural), interlocutors synchronized matching behaviors, at temporal lags short enough to provide imitation of one interlocutor by the other, from one conversational turn to the next. Both social and cognitive variables predicted the degree of temporal organization. These findings suggest that the temporal structure of matching behaviors provides low-level and low-cost resources for human interaction.",2012.0,75.0,261.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1551-6709.2012.01269.x', 'status': None}","{'volume': '36 8', 'pages': '\n          1404-26\n        ', 'name': 'Cognitive science'}","{'bibtex': '@Article{Louwerse2012BehaviorMI,\n author = {M. Louwerse and Rick Dale and E. Bard and Patrick Jeuniaux},\n journal = {Cognitive science},\n pages = {\n          1404-26\n        },\n title = {Behavior Matching in Multimodal Communication Is Synchronized},\n volume = {36 8},\n year = {2012}\n}\n'}","[{'authorId': '2073332', 'name': 'M. Louwerse'}, {'authorId': '144301561', 'name': 'Rick Dale'}, {'authorId': '2695814', 'name': 'E. Bard'}, {'authorId': '1961178', 'name': 'Patrick Jeuniaux'}]"
1439,7c9da7aa284bbb035ac97335e6ff7dc03c39ca76,Video Games for Prosocial Learning,"In this chapter, we consider the capabilities video games offer to educators who seek to foster prosocial development using three popular frameworks: moral education, character education, and care ethics. While all three of these frameworks previously considered literature and film as helpful tools, we suggest that video games are unique from these other media in the multiple levers through which they can influence the worldview, values, and behaviors of players. Similar to literature and film, video games possess content — plot, characters, conflict, themes, and imagery — with which participants interact. Unlike other media, however, video games scaffold players’ experiences not only via narrative and audiovisual content but by the rules, principles, and objectives governing what participants do. Moreover, many video games possess an ecosystem that impacts players’ interpretation of the game itself — for example, on-line hint guides and discussion groups as well as the opportunity to play in the company of peers in either physical or virtual proximity. We consider opportunities and challenges presented by each of these unique facets of video games for fostering the prosocial development of participants.",2010.0,43.0,30.0,False,,"{'volume': '', 'pages': '16-33', 'name': ''}","{'bibtex': '@Inproceedings{Koo2010VideoGF,\n author = {Gene Koo and S. Seider},\n pages = {16-33},\n title = {Video Games for Prosocial Learning},\n year = {2010}\n}\n'}","[{'authorId': '98041256', 'name': 'Gene Koo'}, {'authorId': '145678364', 'name': 'S. Seider'}]"
1440,7caaedb86c80b6f97f08068a3786dbf4a6c9dfa6,"Modeling the Internet of Things, Self-Organizing and Other Complex Adaptive Communication Networks: A Cognitive Agent-Based Computing Approach","Background Computer Networks have a tendency to grow at an unprecedented scale. Modern networks involve not only computers but also a wide variety of other interconnected devices ranging from mobile phones to other household items fitted with sensors. This vision of the ""Internet of Things"" (IoT) implies an inherent difficulty in modeling problems. Purpose It is practically impossible to implement and test all scenarios for large-scale and complex adaptive communication networks as part of Complex Adaptive Communication Networks and Environments (CACOONS). The goal of this study is to explore the use of Agent-based Modeling as part of the Cognitive Agent-based Computing (CABC) framework to model a Complex communication network problem. Method We use Exploratory Agent-based Modeling (EABM), as part of the CABC framework, to develop an autonomous multi-agent architecture for managing carbon footprint in a corporate network. To evaluate the application of complexity in practical scenarios, we have also introduced a company-defined computer usage policy. Results The conducted experiments demonstrated two important results: Primarily CABC-based modeling approach such as using Agent-based Modeling can be an effective approach to modeling complex problems in the domain of IoT. Secondly, the specific problem of managing the Carbon footprint can be solved using a multiagent system approach.",2016.0,61.0,54.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0146760&type=printable', 'status': None}","{'volume': '11', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Laghari2016ModelingTI,\n author = {S. Laghari and M. Niazi},\n journal = {PLoS ONE},\n title = {Modeling the Internet of Things, Self-Organizing and Other Complex Adaptive Communication Networks: A Cognitive Agent-Based Computing Approach},\n volume = {11},\n year = {2016}\n}\n'}","[{'authorId': '2069416', 'name': 'S. Laghari'}, {'authorId': '1795560', 'name': 'M. Niazi'}]"
1441,7cbac9e38d6d0bf3d156093b7f7b605b7d04d4c2,FLAME—Fuzzy Logic Adaptive Model of Emotions,,2000.0,97.0,522.0,False,,"{'volume': '3', 'pages': '219-257', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{El-Nasr2000FLAMEFuzzyLA,\n author = {M. S. El-Nasr and J. Yen and T. Ioerger},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {219-257},\n title = {FLAME—Fuzzy Logic Adaptive Model of Emotions},\n volume = {3},\n year = {2000}\n}\n'}","[{'authorId': '1381933697', 'name': 'M. S. El-Nasr'}, {'authorId': '143674364', 'name': 'J. Yen'}, {'authorId': '1681317', 'name': 'T. Ioerger'}]"
1445,7cbb8d75d25ae34d41a0fe7299275c7b238f8314,Emotional Mimicry Beyond the Face?,"Emotional mimicry—quick and spontaneous matching of another’s expressions—is a well-documented phenomenon that is associated with numerous social outcomes. Although the mechanisms underlying mimicry are not fully understood, there is growing awareness that it is more than a one-to-one motor matching of others’ expressions and may be the result of neural simulation. If true, it is possible that mimicry could extend to other parts of the body, even in the absence of visual information from that body part. Indeed, we found that passively viewing anger and fear expressions, without accompanying information from the body, voice or other channels, produced both facial mimicry and corresponding responses in arm muscles that make a fist or a defensive posture. This suggests that observers simulated observed expressions and that activity may have spilled over to other areas to create a body response.",2018.0,52.0,18.0,False,,"{'volume': '9', 'pages': '844 - 852', 'name': 'Social Psychological and Personality Science'}","{'bibtex': '@Article{Moody2018EmotionalMB,\n author = {E. Moody and C. Reed and Tara Van Bommel and B. App and D. McIntosh},\n journal = {Social Psychological and Personality Science},\n pages = {844 - 852},\n title = {Emotional Mimicry Beyond the Face?},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '48254408', 'name': 'E. Moody'}, {'authorId': '145182723', 'name': 'C. Reed'}, {'authorId': '1753404815', 'name': 'Tara Van Bommel'}, {'authorId': '145972787', 'name': 'B. App'}, {'authorId': '21464189', 'name': 'D. McIntosh'}]"
1446,7cc71e4c0bb39c2d3ff3cd039c5e62f726f6d493,"MARSSI: Model of Appraisal, Regulation, and Social Signal Interpretation","Understanding emotions of others requires a theory of mind approach providing knowledge of internal appraisal and regulation processes of emotions. Multi-modal social signal classification is insufficient for understanding emotional expressions. Mainly, because many communicative, emotional expressions are not directly related to internal emotional states. Moreover, the recognition of the expression's direction is neglected so far. Even if social signals reveal emotional aspects, the recognition with signal classifiers cannot explain internal appraisal or regulation processes. Using that information is one approach for building cognitive empathic agents with the ability to address observations and motives in an empathic dialogue. In this paper, we introduce a computational model of user emotions for empathic agents. It combines a simulation of appraisal and regulation processes with a social signal interpretation taking directions of expressions into account. Our evaluation shows that social signal sequences can be related to emotion regulation processes. Their recognition and using appraisal and regulation knowledge enables our agent to react empathically.",2018.0,80.0,22.0,False,,{'pages': '497-506'},"{'bibtex': '@Inproceedings{Gebhard2018MARSSIMO,\n author = {Patrick Gebhard and T. Schneeberger and Tobias Baur and E. André},\n pages = {497-506},\n title = {MARSSI: Model of Appraisal, Regulation, and Social Signal Interpretation},\n year = {2018}\n}\n'}","[{'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '2375527', 'name': 'T. Schneeberger'}, {'authorId': '2230836', 'name': 'Tobias Baur'}, {'authorId': '1742930', 'name': 'E. André'}]"
1447,7ce7b3bbd6457356215f822211cbe40ab619d65e,ubiGaze: ubiquitous augmented reality messaging using gaze gestures,"We describe ubiGaze, a novel wearable ubiquitous method to augment any real-world object with invisible messages through gaze gestures that lock the message into the object. This enables a context and location dependent messaging service, which users can utilize discreetly and effortlessly. Further, gaze gestures can be used as an authentication method, even when the augmented object is publicly known. We developed a prototype using two wearable devices: a Pupil eye tracker equipped with a scene camera and a Sony Smartwatch 3. The eye tracker follows the users' gaze, the scene camera captures distinct features from the selected real-world object, and the smartwatch provides both input and output modalities for selecting and displaying messages. We describe the concept, design, and implementation of our real-world system. Finally, we discuss research implications and address future work.",2016.0,19.0,37.0,True,"{'url': 'https://eprints.lancs.ac.uk/id/eprint/124692/1/a11_bace.pdf', 'status': None}",{'name': 'SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications'},"{'bibtex': '@Article{Bâce2016ubiGazeUA,\n author = {Mihai Bâce and T. Leppänen and David Gil de Gomez and Argenis Ramirez Gomez},\n journal = {SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications},\n title = {ubiGaze: ubiquitous augmented reality messaging using gaze gestures},\n year = {2016}\n}\n'}","[{'authorId': '31944767', 'name': 'Mihai Bâce'}, {'authorId': '35202419', 'name': 'T. Leppänen'}, {'authorId': '40249938', 'name': 'David Gil de Gomez'}, {'authorId': '21475281', 'name': 'Argenis Ramirez Gomez'}]"
1448,7d0531aaaa4dbf4033da964289843e7812262702,"Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus","There is a rich variety of data sets for sentiment analysis (viz., polarity and subjectivity classification). For the more challenging task of detecting discrete emotions following the definitions of Ekman and Plutchik, however, there are much fewer data sets, and notably no resources for the social media domain. This paper contributes to closing this gap by extending the SemEval 2016 stance and sentiment dataset with emotion annotation. We (a) analyse annotation reliability and annotation merging; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment); (c) report modelling results as a baseline for future work.",2017.0,54.0,78.0,True,"{'url': 'https://www.aclweb.org/anthology/W17-5203.pdf', 'status': None}",{'pages': '13-23'},"{'bibtex': '@Inproceedings{Schuff2017AnnotationMA,\n author = {Hendrik Schuff and Jeremy Barnes and Julian Mohme and Sebastian Padó and Roman Klinger},\n pages = {13-23},\n title = {Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus},\n year = {2017}\n}\n'}","[{'authorId': '7959237', 'name': 'Hendrik Schuff'}, {'authorId': '144435436', 'name': 'Jeremy Barnes'}, {'authorId': '25079660', 'name': 'Julian Mohme'}, {'authorId': '1708581', 'name': 'Sebastian Padó'}, {'authorId': '66339110', 'name': 'Roman Klinger'}]"
1449,7d15d87384b4542fc1c72be6a4a9d9380190f614,Personality and Emotion-Based High-Level Control of Affective Story Characters,"Human emotional behavior, personality, and body language are the essential elements in the recognition of a believable synthetic story character. This paper presents an approach using story scripts and action descriptions in a form similar to the content description of storyboards to predict specific personality and emotional states. By adopting the Abridged Big Five Circumplex (AB5C) Model of personality from the study of psychology as a basis for a computational model, we construct a hierarchical fuzzy rule-based system to facilitate the personality and emotion control of the body language of a dynamic story character. The story character can consistently perform specific postures and gestures based on his/her personality type. Story designers can devise a story context in the form of our story interface which predictably motivates personality and emotion values to drive the appropriate movements of the story characters. Our system takes advantage of relevant knowledge described by psychologists and researchers of storytelling, nonverbal communication, and human movement. Our ultimate goal is to facilitate the high-level control of a synthetic character",2007.0,42.0,62.0,True,"{'url': 'https://research-repository.griffith.edu.au/bitstream/10072/38855/1/65839_1.pdf', 'status': None}","{'volume': '13', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Su2007PersonalityAE,\n author = {Wen-Poh Su and Binh Pham and Aster Wardhani},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n title = {Personality and Emotion-Based High-Level Control of Affective Story Characters},\n volume = {13},\n year = {2007}\n}\n'}","[{'authorId': '3062715', 'name': 'Wen-Poh Su'}, {'authorId': '144809479', 'name': 'Binh Pham'}, {'authorId': '144305327', 'name': 'Aster Wardhani'}]"
1451,7d1f329a4831f02772505bbdca1f5468b52559e7,The Impact of Pedagogical Agents' Gender on Academic Learning: A Systematic Review,"Virtual learning environments often use virtual characters to facilitate and improve the learning process. These characters, known as pedagogical agents, can take on different roles, such as tutors or companions. Research has highlighted the importance of various characteristics of virtual agents, including their voice or non-verbal behaviors. Little attention has been paid to the gender-specific design of pedagogical agents, although gender has an important influence on the educational process. In this article, we perform an extensive review of the literature regarding the impact of the gender of pedagogical agents on academic outcomes. Based on a detailed review of 59 articles, we analyze the influence of pedagogical agents' gender on students' academic self-evaluations and achievements to answer the following questions: (1) Do students perceive virtual agents differently depending on their own gender and the gender of the agent? (2) Does the gender of pedagogical agents influence students' academic performance and self-evaluations? (3) Are there tasks or academic situations to which a male virtual agent is better suited than a female virtual agent, and vice versa, according to empirical evidence? (4) How do a virtual agent's pedagogical roles impact these results? (5) How do a virtual agent's appearance and interactive capacities impact these results? (6) Are androgynous virtual agents a potential solution to combatting gender stereotypes? This review provides important insight to researchers on how to approach gender when designing pedagogical agents in virtual learning environments.",2022.0,103.0,5.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frai.2022.862997/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Artificial Intelligence'}","{'bibtex': ""@Article{Armando2022TheIO,\n author = {Marjorie Armando and M. Ochs and I. Régner},\n journal = {Frontiers in Artificial Intelligence},\n title = {The Impact of Pedagogical Agents' Gender on Academic Learning: A Systematic Review},\n volume = {5},\n year = {2022}\n}\n""}","[{'authorId': '2171758808', 'name': 'Marjorie Armando'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '3637793', 'name': 'I. Régner'}]"
1452,7d5b2388945b5ba53512ab775d80f4659092307f,Towards Empathetic Dialogue Generation over Multi-type Knowledge.,"Enabling the machines with empathetic abilities to provide context-consistent responses is crucial on both semantic and emotional levels. The task of empathetic dialogue generation is proposed to address this problem. However, lacking external knowledge makes it difficult to perceive implicit emotions from limited dialogue history. To address the above challenges, we propose to leverage multi-type knowledge, i.e, the commonsense knowledge and emotional lexicon, to explicitly understand and express emotions in empathetic dialogue generation. We first enrich the dialogue history by jointly interacting with two-type knowledge and construct an emotional context graph. Then we introduce a multi-type knowledge-aware context encoder to learn emotional context representations and distill emotional signals, which are the prerequisites to predicate emotions expressed in responses. Finally, we propose an emotional cross-attention mechanism to exploit the emotional dependencies between the emotional context graph and the target empathetic response. Conducted on a benchmark dataset, extensive experimental results show that our proposed framework outperforms state-of-the-art baselines in terms of automatic metrics and human evaluations.",2020.0,55.0,16.0,False,,"{'volume': '', 'name': 'arXiv: Computation and Language'}","{'bibtex': '@Article{Li2020TowardsED,\n author = {Qintong Li and Piji Li and Zhumin Chen and Z. Ren},\n journal = {arXiv: Computation and Language},\n title = {Towards Empathetic Dialogue Generation over Multi-type Knowledge.},\n year = {2020}\n}\n'}","[{'authorId': '47422209', 'name': 'Qintong Li'}, {'authorId': '2193560', 'name': 'Piji Li'}, {'authorId': '1721165', 'name': 'Zhumin Chen'}, {'authorId': '2780667', 'name': 'Z. Ren'}]"
1453,7d62f1b94a62f9f649d27eb1396379654498feee,AFFDEX SDK: A Cross-Platform Real-Time Multi-Face Expression Recognition Toolkit,"We present a real-time facial expression recognition toolkit that can automatically code the expressions of multiple people simultaneously. The toolkit is available across major mobile and desktop platforms (Android, iOS, Windows). The system is trained on the world's largest dataset of facial expressions and has been optimized to operate on mobile devices and with very few false detections. The toolkit offers the potential for the design of novel interfaces that respond to users' emotional states based on their facial expressions. We present a demonstration application that provides real-time visualization of the expressions captured by the camera.",2016.0,10.0,282.0,False,,{'name': 'Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems'},"{'bibtex': '@Article{McDuff2016AFFDEXSA,\n author = {Daniel J. McDuff and A. Mahmoud and Mohammad Mavadati and M. Amr and Jay Turcot and R. E. Kaliouby},\n journal = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},\n title = {AFFDEX SDK: A Cross-Platform Real-Time Multi-Face Expression Recognition Toolkit},\n year = {2016}\n}\n'}","[{'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '3100369', 'name': 'A. Mahmoud'}, {'authorId': '3396867', 'name': 'Mohammad Mavadati'}, {'authorId': '145354041', 'name': 'M. Amr'}, {'authorId': '40463348', 'name': 'Jay Turcot'}, {'authorId': '1754451', 'name': 'R. E. Kaliouby'}]"
1454,7dcdfe89a36e4e54d33362c164e09709a19bef7f,The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression,"In 2000, the Cohn-Kanade (CK) database was released for the purpose of promoting research into automatically detecting individual facial expressions. Since then, the CK database has become one of the most widely used test-beds for algorithm development and evaluation. During this period, three limitations have become apparent: 1) While AU codes are well validated, emotion labels are not, as they refer to what was requested rather than what was actually performed, 2) The lack of a common performance metric against which to evaluate new algorithms, and 3) Standard protocols for common databases have not emerged. As a consequence, the CK database has been used for both AU and emotion detection (even though labels for the latter have not been validated), comparison with benchmark algorithms is missing, and use of random subsets of the original database makes meta-analyses difficult. To address these and other concerns, we present the Extended Cohn-Kanade (CK+) database. The number of sequences is increased by 22% and the number of subjects by 27%. The target expression for each sequence is fully FACS coded and emotion labels have been revised and validated. In addition to this, non-posed sequences for several types of smiles and their associated metadata have been added. We present baseline results using Active Appearance Models (AAMs) and a linear support vector machine (SVM) classifier using a leave-one-out subject cross-validation for both AU and emotion detection for the posed data. The emotion and AU labels, along with the extended image data and tracked landmarks will be made available July 2010.",2010.0,29.0,3319.0,True,"{'url': 'http://www.pitt.edu/%7Ejeffcohn/CVPR2010_CK%2B2.pdf', 'status': None}","{'pages': '94-101', 'name': '2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops'}","{'bibtex': '@Article{Lucey2010TheEC,\n author = {P. Lucey and J. Cohn and T. Kanade and Jason M. Saragih and Z. Ambadar and I. Matthews},\n journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops},\n pages = {94-101},\n title = {The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression},\n year = {2010}\n}\n'}","[{'authorId': '1713496', 'name': 'P. Lucey'}, {'authorId': '1737918', 'name': 'J. Cohn'}, {'authorId': '1733113', 'name': 'T. Kanade'}, {'authorId': '2398245', 'name': 'Jason M. Saragih'}, {'authorId': '2059653', 'name': 'Z. Ambadar'}, {'authorId': '1711695', 'name': 'I. Matthews'}]"
1455,7dd06cf1132d8244a7db77768d024be7362022c5,An Emotionally Aware Embodied Conversational Agent,,2018.0,17.0,8.0,False,,{'pages': '2250-2252'},"{'bibtex': '@Inproceedings{Sohn2018AnEA,\n author = {Samuel S. Sohn and Xun Zhang and F. Geraci and Mubbasir Kapadia},\n pages = {2250-2252},\n title = {An Emotionally Aware Embodied Conversational Agent},\n year = {2018}\n}\n'}","[{'authorId': '51118484', 'name': 'Samuel S. Sohn'}, {'authorId': '2108143874', 'name': 'Xun Zhang'}, {'authorId': '31899849', 'name': 'F. Geraci'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
1456,7dd4a0fb7368a510840cffd7dcad618962d3b8e4,"An Architecture for Action, Emotion, and Social Behavior",,1992.0,37.0,321.0,False,,{'pages': '55-68'},"{'bibtex': '@Inproceedings{Bates1992AnAF,\n author = {J. Bates and A. B. Loyall and W. S. Reilly},\n pages = {55-68},\n title = {An Architecture for Action, Emotion, and Social Behavior},\n year = {1992}\n}\n'}","[{'authorId': '145207410', 'name': 'J. Bates'}, {'authorId': '2695299', 'name': 'A. B. Loyall'}, {'authorId': '145034916', 'name': 'W. S. Reilly'}]"
1457,7e121dac778725f891ab8e43463db2ec216039d0,Recent Advances on Human-Computer Dialogue,,2016.0,66.0,22.0,True,,"{'volume': '1', 'pages': '303-312', 'name': 'CAAI Trans. Intell. Technol.'}","{'bibtex': '@Article{Wang2016RecentAO,\n author = {Xiaojie Wang and Caixia Yuan},\n journal = {CAAI Trans. Intell. Technol.},\n pages = {303-312},\n title = {Recent Advances on Human-Computer Dialogue},\n volume = {1},\n year = {2016}\n}\n'}","[{'authorId': '38542466', 'name': 'Xiaojie Wang'}, {'authorId': '2006373', 'name': 'Caixia Yuan'}]"
1458,7e13f84ddecd8e37a3cfb7c590656d111e6d4d6b,Emotion recognition and social competence in chronic schizophrenia.,"This study evaluated (a) whether chronic, medicated schizophrenia patients show deficits in emotion recognition compared to nonpatients, and (b) whether deficits in emotion recognition are related to poorer social competence. Two emotion recognition tests developed by S. L. Kerr and J. M. Neale (1993) and Benton's Test of Facial Recognition (A. Benton, M. VanAllen, K. Hamsher, & H. Levin, 1978) were given to patients with chronic schizophrenia and nonpatient controls. Patients' social skills, social adjustment, and symptomatology were assessed. Like Kerr and Neale's unmedicated patients, these patients performed worse than controls on both emotion recognition tests and the control test. For patients, facial perception was related to the chronicity of illness and social competence. Chronicity of illness may contribute to face perception deficits in schizophrenia, which may affect social competence.",1996.0,17.0,388.0,False,,"{'volume': '105 2', 'pages': '\n          271-5\n        ', 'name': 'Journal of abnormal psychology'}","{'bibtex': '@Article{Mueser1996EmotionRA,\n author = {K. Mueser and R. Doonan and D. Penn and J. Blanchard and A. Bellack and P. Nishith and J. DeLeon},\n journal = {Journal of abnormal psychology},\n pages = {\n          271-5\n        },\n title = {Emotion recognition and social competence in chronic schizophrenia.},\n volume = {105 2},\n year = {1996}\n}\n'}","[{'authorId': '6109291', 'name': 'K. Mueser'}, {'authorId': '34054181', 'name': 'R. Doonan'}, {'authorId': '2451983', 'name': 'D. Penn'}, {'authorId': '4423912', 'name': 'J. Blanchard'}, {'authorId': '4338201', 'name': 'A. Bellack'}, {'authorId': '6299312', 'name': 'P. Nishith'}, {'authorId': '32891446', 'name': 'J. DeLeon'}]"
1459,7e297a8431974c92e779fa16a2f40dec32b60e43,Does render style affect perception of personality in virtual humans?,"Delivering appealing virtual characters conveying personality is becoming extremely important in the entertainment industry and beyond. A theory called the 'Uncanny Valley' has been used to describe the phenomenon that the appearance of a virtual character can contribute to negative/positive audience reactions to that character [Mori 1970]. Since the style used to render a character strongly changes the appearance, we investigate whether a difference in render style can indirectly influence audience reaction, which we measure based on perception of personality. Based on psychology research, we first scripted original character dialogues in order to convey a range of ten typical personality types. Then, a professional actor was recruited to act out these dialogues, while his face and body motion and audio were recorded. The performances were mapped onto a virtual character rendered in two styles that differ in appearance: an appealing cartoon style and unappealing ill style (Figure 1). In our experiment, participants were asked questions about the character's personality in order for us to test if the difference in render style causes differences in personality perception. Our results found an indirect effect of render style where the cartoon style was rated as having a more agreeable personality than the ill style. This result has implications for developers interested in creating appealing virtual humans, avoiding the 'Uncanny Valley' phenomenon.",2014.0,26.0,39.0,False,,{'name': 'Proceedings of the ACM Symposium on Applied Perception'},"{'bibtex': '@Article{Zibrek2014DoesRS,\n author = {Katja Zibrek and R. Mcdonnell},\n journal = {Proceedings of the ACM Symposium on Applied Perception},\n title = {Does render style affect perception of personality in virtual humans?},\n year = {2014}\n}\n'}","[{'authorId': '1710384', 'name': 'Katja Zibrek'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
1460,7e50dc06947a829dbdd2b68cba7a78389b3bfbd4,The Animal in Me: Enhancing Emotion Recognition in Adolescents with Autism Using Animal Filters,,2019.0,27.0,14.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10803-019-04179-7.pdf', 'status': None}","{'volume': '49', 'pages': '4482 - 4487', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Cross2019TheAI,\n author = {Liam B. Cross and M. Farha and Gray Atherton},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {4482 - 4487},\n title = {The Animal in Me: Enhancing Emotion Recognition in Adolescents with Autism Using Animal Filters},\n volume = {49},\n year = {2019}\n}\n'}","[{'authorId': '143784184', 'name': 'Liam B. Cross'}, {'authorId': '1393539567', 'name': 'M. Farha'}, {'authorId': '143639742', 'name': 'Gray Atherton'}]"
1461,7e9b8ebeec120009d9a85203faca20e505486d5a,Facing the challenge of teaching emotions to individuals with low- and high-functioning autism using a new Serious game: a pilot study,,2014.0,76.0,103.0,True,"{'url': 'https://molecularautism.biomedcentral.com/counter/pdf/10.1186/2040-2392-5-37', 'status': None}","{'volume': '5', 'pages': '37 - 37', 'name': 'Molecular Autism'}","{'bibtex': '@Article{Serret2014FacingTC,\n author = {S. Serret and S. Hun and G. Iakimova and J. Lozada and M. Anastassova and Andreia Santos and S. Vespérini and F. Askenazy},\n journal = {Molecular Autism},\n pages = {37 - 37},\n title = {Facing the challenge of teaching emotions to individuals with low- and high-functioning autism using a new Serious game: a pilot study},\n volume = {5},\n year = {2014}\n}\n'}","[{'authorId': '6312012', 'name': 'S. Serret'}, {'authorId': '7737732', 'name': 'S. Hun'}, {'authorId': '4441479', 'name': 'G. Iakimova'}, {'authorId': '1741816787', 'name': 'J. Lozada'}, {'authorId': '2450105', 'name': 'M. Anastassova'}, {'authorId': '2116954332', 'name': 'Andreia Santos'}, {'authorId': '4207552', 'name': 'S. Vespérini'}, {'authorId': '7025907', 'name': 'F. Askenazy'}]"
1462,7eadf58d97f0d5631fefc0d9426ce1d3ebb83b4c,Self-presentation through multimedia : A Bakhtinian perspective on digital storytelling,,2008.0,0.0,36.0,False,,"{'volume': '', 'pages': '123-144', 'name': ''}","{'bibtex': '@Inproceedings{Nelson2008SelfpresentationTM,\n author = {M. Nelson and G. Hull},\n pages = {123-144},\n title = {Self-presentation through multimedia : A Bakhtinian perspective on digital storytelling},\n year = {2008}\n}\n'}","[{'authorId': '32115201', 'name': 'M. Nelson'}, {'authorId': '26371940', 'name': 'G. Hull'}]"
1463,7ebc5f16a9ace2d00036ffb6a81562760a5e042e,Impression Detection and Management Using an Embodied Conversational Agent,,2020.0,42.0,2.0,True,"{'url': 'https://cora.ucc.ie/bitstreams/7bfe9e4e-4862-4723-a186-3ec1f28ada81/download', 'status': None}",{'pages': '260-278'},"{'bibtex': '@Inproceedings{Wang2020ImpressionDA,\n author = {Chen Wang and Béatrice Biancardi and M. Mancini and Angelo Cafaro and C. Pelachaud and T. Pun and G. Chanel},\n pages = {260-278},\n title = {Impression Detection and Management Using an Embodied Conversational Agent},\n year = {2020}\n}\n'}","[{'authorId': '2109116473', 'name': 'Chen Wang'}, {'authorId': '23567239', 'name': 'Béatrice Biancardi'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1809085', 'name': 'T. Pun'}, {'authorId': '2343145', 'name': 'G. Chanel'}]"
1464,7ebf346b96f9cb042309019b390a767c49596256,Empathic concern and the effect of stories in human-robot interaction,"People have been shown to project lifelike attributes onto robots and to display behavior indicative of empathy in human-robot interaction. Our work explores the role of empathy by examining how humans respond to a simple robotic object when asked to strike it. We measure the effects of lifelike movement and stories on people's hesitation to strike the robot, and we evaluate the relationship between hesitation and people's trait empathy. Our results show that people with a certain type of high trait empathy (empathic concern) hesitate to strike the robots. We also find that high empathic concern and hesitation are more strongly related for robots with stories. This suggests that high trait empathy increases people's hesitation to strike a robot, and that stories may positively influence their empathic responses.",2015.0,32.0,113.0,True,"{'url': 'https://dspace.mit.edu/bitstream/1721.1/109059/1/Breazeal_Empathetic%20concern.pdf', 'status': None}","{'pages': '770-775', 'name': '2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)'}","{'bibtex': '@Article{Darling2015EmpathicCA,\n author = {K. Darling and Palash Nandy and C. Breazeal},\n journal = {2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {770-775},\n title = {Empathic concern and the effect of stories in human-robot interaction},\n year = {2015}\n}\n'}","[{'authorId': '48891226', 'name': 'K. Darling'}, {'authorId': '2700513', 'name': 'Palash Nandy'}, {'authorId': '1711777', 'name': 'C. Breazeal'}]"
1465,7ec28158204afd9d0e3bcc0f0dcec8a9b730bf6a,Therapeutic programs aimed at developing the theory of mind in patients with autism spectrum disorders - available methods and their effectiveness.,"Autism spectrum disorders (ASD) are neurodevelopmental disorders characterized by the presence of deficits in social skills and communication as well as repetitive patterns of behavior and interests. Among the theories explaining the mechanisms of the formation of the above cited symptoms, an important role is attributed to the theory of the mind, or the ability to draw conclusions about the state of mind of other people, assigning mental states to others and interpreting their behaviors. According to guidelines of the National Institute for Health and Care Excellence on the therapeutic procedures in autism spectrum disorders, the proceedings include various methods, adjusted to the level of functioning and presented difficulties. In the most widely used behavioral social skills trainings, the goal is to practice behaviors using modelling and role-playing techniques. Less attention is devoted to the issue of social understanding, theory of mind or the cognitive aspects of therapeutic interventions. There are studies demonstrating the possibility of developing competence in the theory of mind in people with ASD, as well as generalizing the acquired skills. The article reviews the literature on the use of therapeutic programs aimed at developing the theory of mind in patients with ASD and their effectiveness. As it seems, these are promising interventions, although they require further assessment.",2020.0,31.0,5.0,True,,"{'volume': '54 3', 'pages': '\n          591-602\n        ', 'name': 'Psychiatria polska'}","{'bibtex': '@Article{Dyrda2020TherapeuticPA,\n author = {Karolina Dyrda and K. Lucci and Renata Bieniek-Pocielej and A. Bryńska},\n journal = {Psychiatria polska},\n pages = {\n          591-602\n        },\n title = {Therapeutic programs aimed at developing the theory of mind in patients with autism spectrum disorders - available methods and their effectiveness.},\n volume = {54 3},\n year = {2020}\n}\n'}","[{'authorId': '2094161112', 'name': 'Karolina Dyrda'}, {'authorId': '113126056', 'name': 'K. Lucci'}, {'authorId': '1993719228', 'name': 'Renata Bieniek-Pocielej'}, {'authorId': '4853679', 'name': 'A. Bryńska'}]"
1466,7ec9a8bbffca6867a9b225d6c7c3e606b2a02894,SteerBench: a benchmark suite for evaluating steering behaviors,"Steering is a challenging task, required by nearly all agents in virtual worlds. There is a large and growing number of approaches for steering, and it is becoming increasingly important to ask a fundamental question: how can we objectively compare steering algorithms? To our knowledge, there is no standard way of evaluating or comparing the quality of steering solutions. This paper presents SteerBench: a benchmark framework for objectively evaluating steering behaviors for virtual agents. We propose a diverse set of test cases, metrics of evaluation, and a scoring method that can be used to compare different steering algorithms. Our framework can be easily customized by a user to evaluate specific behaviors and new test cases. We demonstrate our benchmark process on two example steering algorithms, showing the insight gained from our metrics. We hope that this framework can grow into a standard for steering evaluation. Copyright © 2009 John Wiley & Sons, Ltd.",2009.0,28.0,97.0,False,,"{'volume': '20', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Singh2009SteerBenchAB,\n author = {Shawn Singh and Mubbasir Kapadia and P. Faloutsos and Glenn D. Reinman},\n journal = {Computer Animation and Virtual Worlds},\n title = {SteerBench: a benchmark suite for evaluating steering behaviors},\n volume = {20},\n year = {2009}\n}\n'}","[{'authorId': '38940063', 'name': 'Shawn Singh'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '1737527', 'name': 'P. Faloutsos'}, {'authorId': '1718128', 'name': 'Glenn D. Reinman'}]"
1467,7ed2bfa5487756e7de8ed3a895644c8e4d4cb9e1,An immersive virtual reality mobile platform for self-attachment,"Psychotherapy is among the most effective techniques for combating mental health issues, and virtual reality is beginning to be explored as a way to enhance the efficacy of various psychotherapeutic treatments. In this paper we propose an immersive virtual reality mobile platform for Self-Attachment psychotherapy. Under the SelfAttachment therapeutic framework, the causes of disorders such as chronic anxiety and depression are traced back to the quality of the individual’s attachment with their primary caregiver during childhood. Our proposed platform aims to assist the user in enhancing their capacities for self-regulation of emotion, by means of earning secure attachment through the experience of positive attachment interactions, missed in their childhood. In the virtual environment provided by the platform, the adult-self of the user learns to create and strengthen an affectional and supportive bond with the inner-child. It is hypothesised that by long term potentiation and neuroplasticity, the user gradually develops new neural pathways and matures into an effective secure attachment object for the inner-child, thereby enabling the self-regulation of emotions.",2017.0,31.0,6.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cittern2017AnIV,\n author = {David Cittern and A. Edalat and I. Ghaznavi},\n title = {An immersive virtual reality mobile platform for self-attachment},\n year = {2017}\n}\n'}","[{'authorId': '2585368', 'name': 'David Cittern'}, {'authorId': '1694989', 'name': 'A. Edalat'}, {'authorId': '2485535', 'name': 'I. Ghaznavi'}]"
1469,7f00fdba4fdcb1c8887dd375d3a7186486121356,"The Effects of Pedagogical Agent Voice and Animation on Learning, Motivation and Perceived Persona",,2003.0,23.0,69.0,False,,"{'volume': '2003', 'pages': '452-458', 'name': ''}","{'bibtex': '@Inproceedings{Baylor2003TheEO,\n author = {A. L. Baylor and Jeeheon Ryu and E. Shen},\n pages = {452-458},\n title = {The Effects of Pedagogical Agent Voice and Animation on Learning, Motivation and Perceived Persona},\n volume = {2003},\n year = {2003}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '1975046', 'name': 'Jeeheon Ryu'}, {'authorId': '48977180', 'name': 'E. Shen'}]"
1470,7f290e4bbb14e01308144ed37b41d3165131fe60,An attachment perspective on psychopathology,,2012.0,41.0,708.0,True,"{'url': 'https://europepmc.org/articles/pmc3266769?pdf=render', 'status': None}","{'volume': '11', 'name': 'World Psychiatry'}","{'bibtex': '@Article{Mikulincer2012AnAP,\n author = {M. Mikulincer and P. Shaver},\n journal = {World Psychiatry},\n title = {An attachment perspective on psychopathology},\n volume = {11},\n year = {2012}\n}\n'}","[{'authorId': '4021295', 'name': 'M. Mikulincer'}, {'authorId': '32963249', 'name': 'P. Shaver'}]"
1471,7f3dbf6bf8d96614a3c7070f419fba7fddd09cd8,DoItRight: An Arabic Gamified Mobile Application to Raise Awareness about the Effect of Littering among Children,,2021.0,0.0,1.0,True,,{'name': 'International Journal of Advanced Computer Science and Applications'},"{'bibtex': '@Article{Alfahid2021DoItRightAA,\n author = {Ayman Alfahid and Hind Bitar and Mayda Alrige and Hend Abeeri and Eman Sulami},\n journal = {International Journal of Advanced Computer Science and Applications},\n title = {DoItRight: An Arabic Gamified Mobile Application to Raise Awareness about the Effect of Littering among Children},\n year = {2021}\n}\n'}","[{'authorId': '115140933', 'name': 'Ayman Alfahid'}, {'authorId': '8478238', 'name': 'Hind Bitar'}, {'authorId': '2241683', 'name': 'Mayda Alrige'}, {'authorId': '2148629044', 'name': 'Hend Abeeri'}, {'authorId': '2148619979', 'name': 'Eman Sulami'}]"
1472,7f4ad37feac723ae60701d83b70862c7921817d8,Émile: Marshalling passions in training and education,"Emotional reasoning can be an important contribution to automated tutoring and training systems. This paper describes Emile, a model of emotional reasoning that builds upon existing approaches and significantly generalizes and extends their capabilities. The main contribution is to show how an explicit planning model allows a more general treatment of several stages of the reasoning process. The model supports educational applications by allowing agents to appraise the emotional significance of events as they relate to students' (or their own) plans and goals, model and predict the emotional state of others, and alter behavior accordingly.",2000.0,40.0,176.0,False,,{'pages': '325-332'},"{'bibtex': '@Inproceedings{Gratch2000ÉmileMP,\n author = {J. Gratch},\n pages = {325-332},\n title = {Émile: Marshalling passions in training and education},\n year = {2000}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}]"
1473,7f62f4a76e5b2909600a01584e69871984ba23fa,Effects of picture content and intensity on affective physiological response.,"This study evaluated the effects of affective intensity and thematic content of foreground photographic stimuli on various physiological response systems. This was accomplished by assessing responses to pictures that varied systematically in these parameters. Along with overall effects of picture valence reported in previous work, we found effects of thematic content (i.e., specific nature of objects/events depicted) for all measures except heart rate. In addition, we found that the magnitude of startle blink, skin conductance, and corrugator muscle reactions increased with increasing affective intensity of pictures. Additionally, for these three measures, intensity effects also interacted with effects of picture content. These results indicate that stimulus parameters of intensity and thematic content exert separate-and in some cases interactive-modulatory effects on physiological reactions to emotional pictures.",2006.0,39.0,188.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1469-8986.2006.00380.x', 'status': None}","{'volume': '43 1', 'pages': '\n          93-103\n        ', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Bernat2006EffectsOP,\n author = {E. Bernat and C. Patrick and Stephen D. Benning and A. Tellegen},\n journal = {Psychophysiology},\n pages = {\n          93-103\n        },\n title = {Effects of picture content and intensity on affective physiological response.},\n volume = {43 1},\n year = {2006}\n}\n'}","[{'authorId': '2825853', 'name': 'E. Bernat'}, {'authorId': '2133311', 'name': 'C. Patrick'}, {'authorId': '5105463', 'name': 'Stephen D. Benning'}, {'authorId': '116114697', 'name': 'A. Tellegen'}]"
1474,7f6587a4811c6852d1015e469d0012b40bb5e336,"Gamification » Blog Archive » Gamification in Education: What, How, Why Bother?",,2014.0,0.0,199.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Brown2014GamificationB,\n author = {John Brown},\n title = {Gamification » Blog Archive » Gamification in Education: What, How, Why Bother?},\n year = {2014}\n}\n'}","[{'authorId': '2116698781', 'name': 'John Brown'}]"
1475,7f8baa24bdbefb0c5b1a0a98a52fa34defad8258,A Theory of Social Comparison Processes,"Hypothesis I: There exists, in the human organism, a drive to evaluate his opinions and his abilities. While opinions and abilities may, at first glance, seem to be quite different things, there is a close functional tie between them. They act together in the manner in which they affect behavior. A person’s cognition (his opinions and beliefs) about the situation in which he exists and his appraisals of what he is capable of doing (his evaluation of his abilities) will together have bearing on his behavior. The holding of incorrect opinions and/or inaccurate appraisals of one’s abilities can be punishing or even fatal in many situations. It is necessary, before we proceed, to clarify the distinction between opinions and evaluations of abilities since at first glance it may seem that one’s evaluation of one’s own ability is an opinion about it. Abilities are of course manifested only through performance which is assumed to depend upon the particular ability. The clarity of the manifestation or performance can vary from instances where there is no clear ordering criterion of the ability to instances where the performance which reflects the ability can be clearly ordered. In the former case, the evaluation of the ability does function like other opinions which are not directly testable in “objective reality’. For example, a person’s evaluation of his ability to write poetry will depend to a large extent on the opinions which others have of his ability to write poetry. In cases where the criterion is unambiguous and can be clearly ordered, this furnishes an objective reality for the evaluation of one’s ability so that it depends less on the opinions of other persons and depends more on actual comparison of one’s performance with the performance of others. Thus, if a person evaluates his running ability, he will do so by comparing his time to run some distance with the times that other persons have taken. In the following pages, when we talk about evaluating an ability, we shall mean specifically the evaluation of that ability in situations where the performance is unambiguous and is known. Most situations in real life will, of course, present situations which are a mixture of opinion and ability evaluation. In a previous article (7) the author posited the existence of a drive to determine whether or not one’s opinions were “correct”. We are here stating that this same drive also produces behavior in people oriented toward obtaining an accurate appraisal of their abilities. The behavioral implication of the existence of such a drive is that we would expect to observe behaviour on the part of persons which enables them to ascertain whether or not their opinions are correct and also behavior which enables them accurately to evaluate their abilities. It is consequently",1954.0,30.0,17507.0,False,,"{'volume': '7', 'pages': '117 - 140', 'name': 'Human Relations'}","{'bibtex': '@Article{Festinger1954ATO,\n author = {L. Festinger},\n journal = {Human Relations},\n pages = {117 - 140},\n title = {A Theory of Social Comparison Processes},\n volume = {7},\n year = {1954}\n}\n'}","[{'authorId': '5281667', 'name': 'L. Festinger'}]"
1476,7fc366a2deea99d42f2ac1babfb512f8782dc274,The Benefits of Interactions with Physically Present Robots over Video-Displayed Agents,,2011.0,31.0,386.0,False,,"{'volume': '3', 'pages': '41-52', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Bainbridge2011TheBO,\n author = {Wilma A. Bainbridge and Justin W. Hart and Elizabeth S. Kim and B. Scassellati},\n journal = {International Journal of Social Robotics},\n pages = {41-52},\n title = {The Benefits of Interactions with Physically Present Robots over\xa0Video-Displayed Agents},\n volume = {3},\n year = {2011}\n}\n'}","[{'authorId': '2553201', 'name': 'Wilma A. Bainbridge'}, {'authorId': '1802400', 'name': 'Justin W. Hart'}, {'authorId': '1748636', 'name': 'Elizabeth S. Kim'}, {'authorId': '1792053', 'name': 'B. Scassellati'}]"
1477,7fd1924effdeb367e64a3afbb54feec363b23f65,Audio-visual integration of emotion expression,,2008.0,40.0,320.0,False,,"{'volume': '1242', 'pages': '126-135', 'name': 'Brain Research'}","{'bibtex': '@Article{Collignon2008AudiovisualIO,\n author = {O. Collignon and S. Girard and F. Gosselin and Sylvain Roy and D. Saint-Amour and M. Lassonde and F. Lepore},\n journal = {Brain Research},\n pages = {126-135},\n title = {Audio-visual integration of emotion expression},\n volume = {1242},\n year = {2008}\n}\n'}","[{'authorId': '3141873', 'name': 'O. Collignon'}, {'authorId': '2074450745', 'name': 'S. Girard'}, {'authorId': '2074568', 'name': 'F. Gosselin'}, {'authorId': '153575521', 'name': 'Sylvain Roy'}, {'authorId': '1396743011', 'name': 'D. Saint-Amour'}, {'authorId': '2029452', 'name': 'M. Lassonde'}, {'authorId': '145042470', 'name': 'F. Lepore'}]"
1478,7fd3991f364514acb8cdea1e8181baca15c86d32,Emotional perseveration: an update on prefrontal-amygdala interactions in fear extinction.,"Fear extinction refers to the ability to adapt as situations change by learning to suppress a previously learned fear. This process involves a gradual reduction in the capacity of a fear-conditioned stimulus to elicit fear by presenting the conditioned stimulus repeatedly on its own. Fear extinction is context-dependent and is generally considered to involve the establishment of inhibitory control of the prefrontal cortex over amygdala-based fear processes. In this paper, we review research progress on the neural basis of fear extinction with a focus on the role of the amygdala and the prefrontal cortex. We evaluate two competing hypotheses for how the medial prefrontal cortex inhibits amygdala output. In addition, we present new findings showing that lesions of the basal amygdala do not affect fear extinction. Based on this result, we propose an updated model for integrating hippocampal-based contextual information with prefrontal-amygdala circuitry.",2004.0,187.0,413.0,True,"{'url': 'http://learnmem.cshlp.org/content/11/5/525.full.pdf', 'status': None}","{'volume': '11 5', 'pages': '\n          525-35\n        ', 'name': 'Learning & memory'}","{'bibtex': '@Article{Sotres-Bayon2004EmotionalPA,\n author = {Francisco Sotres-Bayon and D. Bush and Joseph E LeDoux},\n journal = {Learning & memory},\n pages = {\n          525-35\n        },\n title = {Emotional perseveration: an update on prefrontal-amygdala interactions in fear extinction.},\n volume = {11 5},\n year = {2004}\n}\n'}","[{'authorId': '1401568019', 'name': 'Francisco Sotres-Bayon'}, {'authorId': '47799076', 'name': 'D. Bush'}, {'authorId': '2332694', 'name': 'Joseph E LeDoux'}]"
1479,80140e972720787e7b295550f0659d8514112d64,EMOTION RECOGNITION DEFICITS IN THE ELDERLY,"In two studies, healthy elderly adults were poor at recognizing certain emotions. In study one, an emotion face morphed to express a new emotion. The elderly were impaired when recognizing anger and sadness, whereas no differences were found between the two age groups in recognizing fear or happiness, or in a task requiring reasoning about non=emotion stimuli. In study two, the elderly were impaired when judging which of two faces was more angry, sad, or fearful, but they were not impaired when judging other emotions or when judging which of two beakers was more full. The elderly were also impaired when matching emotion sounds to angry, sad, and disgusted faces, but not to other emotions and not when matching non-emotion (e.g., machine) sounds to machines. Elderly deficits were independent of performance on a task requiring basic face processing (gender recognition). Overall, the results provide support for an age-related decline in the recognition of some emotions that is independent of changes in perceptual abilities, processing speed, fluid IQ, basic face processing abilities, and reasoning- about non-face stimuli. Recognition of emotion stimuli might be mediated by regions of the brain that are independent from those associated with a more general cognitive decline",2004.0,60.0,268.0,False,,"{'volume': '114', 'pages': '403 - 432', 'name': 'International Journal of Neuroscience'}","{'bibtex': '@Article{Sullivan2004EMOTIONRD,\n author = {Susan Sullivan and T. Ruffman},\n journal = {International Journal of Neuroscience},\n pages = {403 - 432},\n title = {EMOTION RECOGNITION DEFICITS IN THE ELDERLY},\n volume = {114},\n year = {2004}\n}\n'}","[{'authorId': '116432126', 'name': 'Susan Sullivan'}, {'authorId': '3890791', 'name': 'T. Ruffman'}]"
1480,80183519a1e9c67b6996bea274cd5e6c251e6683,Augmented Reality to Enable Users in Learning Case Grammar from Their Real-World Interactions,"Augmented Reality (AR) provides a unique opportunity to situate learning content in one's environment. In this work, we investigated how AR could be developed to provide an interactive context-based language learning experience. Specifically, we developed a novel handheld-AR app for learning case grammar by dynamically creating quizzes, based on real-life objects in the learner's surroundings. We compared this to the experience of learning with a non-contextual app that presented the same quizzes with static photographic images. Participants found AR suitable for use in their everyday lives and enjoyed the interactive experience of exploring grammatical relationships in their surroundings. Nonetheless, Bayesian tests provide substantial evidence that the interactive and context-embedded AR app did not improve case grammar skills, vocabulary retention, and usability over the experience with equivalent static images. Based on this, we propose how language learning apps could be designed to combine the benefits of contextual AR and traditional approaches.",2020.0,44.0,23.0,False,,{'name': 'Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Draxler2020AugmentedRT,\n author = {Fiona Draxler and Audrey Labrie and A. Schmidt and L. Chuang},\n journal = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},\n title = {Augmented Reality to Enable Users in Learning Case Grammar from Their Real-World Interactions},\n year = {2020}\n}\n'}","[{'authorId': '1396850289', 'name': 'Fiona Draxler'}, {'authorId': '1666377025', 'name': 'Audrey Labrie'}, {'authorId': '145823914', 'name': 'A. Schmidt'}, {'authorId': '144710398', 'name': 'L. Chuang'}]"
1481,8018cb26bae66c31862199e3722291e3b1def203,WUW - wear Ur world: a wearable gestural interface,"Information is traditionally confined to paper or digitally to a screen. In this paper, we introduce WUW, a wearable gestural interface, which attempts to bring information out into the tangible world. By using a tiny projector and a camera mounted on a hat or coupled in a pendant like wearable device, WUW sees what the user sees and visually augments surfaces or physical objects the user is interacting with. WUW projects information onto surfaces, walls, and physical objects around us, and lets the user interact with the projected information through natural hand gestures, arm movements or interaction with the object itself.",2009.0,21.0,470.0,True,"{'url': 'https://dspace.mit.edu/bitstream/1721.1/61366/1/Maes_WUW%20Wear.pdf', 'status': None}","{'name': ""CHI '09 Extended Abstracts on Human Factors in Computing Systems""}","{'bibtex': ""@Article{Mistry2009WUWW,\n author = {Pranav Mistry and P. Maes and Liyan Chang},\n journal = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},\n title = {WUW - wear Ur world: a wearable gestural interface},\n year = {2009}\n}\n""}","[{'authorId': '145231524', 'name': 'Pranav Mistry'}, {'authorId': '1701876', 'name': 'P. Maes'}, {'authorId': '2122834469', 'name': 'Liyan Chang'}]"
1482,801afc8b3823ddba9e67689980aa48fcd9dc5a55,Nonverbal interaction of patients and therapists during psychiatric interviews.,,1982.0,28.0,57.0,False,,"{'volume': '91 2', 'pages': '\n          109-19\n        ', 'name': 'Journal of abnormal psychology'}","{'bibtex': '@Article{Fairbanks1982NonverbalIO,\n author = {L. Fairbanks and M. Mcguire and C. J. Harris},\n journal = {Journal of abnormal psychology},\n pages = {\n          109-19\n        },\n title = {Nonverbal interaction of patients and therapists during psychiatric interviews.},\n volume = {91 2},\n year = {1982}\n}\n'}","[{'authorId': '7518542', 'name': 'L. Fairbanks'}, {'authorId': '5054307', 'name': 'M. Mcguire'}, {'authorId': '150949871', 'name': 'C. J. Harris'}]"
1483,802fd9b4d336a0456567119d6145bad0b5fe2e8a,An action selection process to simulate the human behavior in virtual humans with real personality,,2011.0,32.0,13.0,False,,"{'volume': '27', 'pages': '275-285', 'name': 'The Visual Computer'}","{'bibtex': '@Article{Orozco-Aguirre2011AnAS,\n author = {Héctor Rafael Orozco-Aguirre and Félix F. Ramos and M. Ramos and D. Thalmann},\n journal = {The Visual Computer},\n pages = {275-285},\n title = {An action selection process to simulate the human behavior in\xa0virtual humans with real personality},\n volume = {27},\n year = {2011}\n}\n'}","[{'authorId': '1402194434', 'name': 'Héctor Rafael Orozco-Aguirre'}, {'authorId': '145054210', 'name': 'Félix F. Ramos'}, {'authorId': '144781300', 'name': 'M. Ramos'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}]"
1485,80371062f40dbaf17917ab4cd947fc67466e634f,"Deep Affect Prediction in-the-Wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond",,2018.0,88.0,335.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s11263-019-01158-4.pdf', 'status': None}","{'volume': '127', 'pages': '907 - 929', 'name': 'International Journal of Computer Vision'}","{'bibtex': '@Article{Kollias2018DeepAP,\n author = {D. Kollias and Panagiotis Tzirakis and M. Nicolaou and A. Papaioannou and Guoying Zhao and Björn Schuller and I. Kotsia and S. Zafeiriou},\n journal = {International Journal of Computer Vision},\n pages = {907 - 929},\n title = {Deep Affect Prediction in-the-Wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond},\n volume = {127},\n year = {2018}\n}\n'}","[{'authorId': '1811396', 'name': 'D. Kollias'}, {'authorId': '2829366', 'name': 'Panagiotis Tzirakis'}, {'authorId': '1752913', 'name': 'M. Nicolaou'}, {'authorId': '144848303', 'name': 'A. Papaioannou'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '145411696', 'name': 'Björn Schuller'}, {'authorId': '1754270', 'name': 'I. Kotsia'}, {'authorId': '1776444', 'name': 'S. Zafeiriou'}]"
1486,8061b1f1d0446eefc4451a6af858aa4e7d57bba3,A Multiagent System For Web-Based Risk Management in Small and Medium Business,,2011.0,27.0,4.0,True,"{'url': 'https://gredos.usal.es/bitstream/10366/134370/1/paams_de_paz_0.pdf', 'status': None}",{'pages': '9-17'},"{'bibtex': '@Inproceedings{Paz2011AMS,\n author = {J. F. D. Paz and J. Bajo and María Lourdes Borrajo Diz and J. Corchado},\n pages = {9-17},\n title = {A Multiagent System For Web-Based Risk Management in Small and Medium Business},\n year = {2011}\n}\n'}","[{'authorId': '1722543', 'name': 'J. F. D. Paz'}, {'authorId': '1722104', 'name': 'J. Bajo'}, {'authorId': '1749466', 'name': 'María Lourdes Borrajo Diz'}, {'authorId': '1729096', 'name': 'J. Corchado'}]"
1487,8073de0cf614f37c229265b57313b6131a7172fe,Gesture and speech in interaction: An overview,,2014.0,197.0,302.0,False,,"{'volume': '57', 'pages': '209-232', 'name': 'Speech Commun.'}","{'bibtex': '@Article{Wagner2014GestureAS,\n author = {P. Wagner and Zofia Malisz and S. Kopp},\n journal = {Speech Commun.},\n pages = {209-232},\n title = {Gesture and speech in interaction: An overview},\n volume = {57},\n year = {2014}\n}\n'}","[{'authorId': '1977041', 'name': 'P. Wagner'}, {'authorId': '3018492', 'name': 'Zofia Malisz'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
1488,807ac8ede9ac06de13142f269a394d53415c33a6,FAtiMA Modular: Towards an Agent Architecture with a Generic Appraisal Framework,,2014.0,16.0,229.0,False,,{'pages': '44-56'},"{'bibtex': '@Inproceedings{Dias2014FAtiMAMT,\n author = {João Dias and S. Mascarenhas and Ana Paiva},\n pages = {44-56},\n title = {FAtiMA Modular: Towards an Agent Architecture with a Generic Appraisal Framework},\n year = {2014}\n}\n'}","[{'authorId': '49647443', 'name': 'João Dias'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1496,80d9af06cad91d85e95a1504ce3f018c64cc9f17,Designing A Virtual Talking Companion to Support the Social-Emotional Learning of Children with ASD,"Conversational agents’ ability to communicate in natural language through voice and text interfaces poses an opportunity in helping children with autism spectrum disorder (ASD) develop their social communication skills. In this paper, we describe the design of Amy, a conversational agent that explains social situations to help guide a child in understanding when to use socially appropriate behavior. A breathing exercise feature for emotion regulation is activated when a negative emotion is detected from the child’s input. Interviews with parents and a child psychologist informed the design of Amy as well as the 12 social stories themes that Amy shares with children. Interview inputs and previous works suggested four design considerations for social-emotional learning companions to facilitate better interaction by including relevant social story themes, formulating open-domain conversation flow, incorporating appropriate and guided emotion regulation exercise, and using lively visual user interface.",2022.0,65.0,4.0,False,,{'name': 'Proceedings of the 21st Annual ACM Interaction Design and Children Conference'},"{'bibtex': '@Article{Gagan2022DesigningAV,\n author = {Isser Troy Gagan and Maria Angela Mikaela Matias and Ivy Tan and Christianne Marie Vinco and Ethel Ong and Ron R. Resurreccion},\n booktitle = {International Conference on Interaction Design and Children},\n journal = {Proceedings of the 21st Annual ACM Interaction Design and Children Conference},\n title = {Designing A Virtual Talking Companion to Support the Social-Emotional Learning of Children with ASD},\n year = {2022}\n}\n'}","[{'authorId': '2172981412', 'name': 'Isser Troy Gagan'}, {'authorId': '2172981437', 'name': 'Maria Angela Mikaela Matias'}, {'authorId': '2172791700', 'name': 'Ivy Tan'}, {'authorId': '2172969825', 'name': 'Christianne Marie Vinco'}, {'authorId': '8045848', 'name': 'Ethel Ong'}, {'authorId': '116323144', 'name': 'Ron R. Resurreccion'}]"
1497,80f30d2f1875e7637bd79ad98f3d22aa05cd4136,Towards Personalities for Animated Agents with Reactive and Planning Behaviors,,1997.0,44.0,59.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/85fb2fc9-b993-4ee3-a162-28c9acf4f146/download', 'status': None}",{'pages': '43-57'},"{'bibtex': '@Inproceedings{Badler1997TowardsPF,\n author = {N. Badler and Barry D. Reich and B. Webber},\n pages = {43-57},\n title = {Towards Personalities for Animated Agents with Reactive and Planning Behaviors},\n year = {1997}\n}\n'}","[{'authorId': '1699200', 'name': 'N. Badler'}, {'authorId': '145431802', 'name': 'Barry D. Reich'}, {'authorId': '1736049', 'name': 'B. Webber'}]"
1498,810baae4153f5d97eb213142e3144edde3f7d76a,An empirical methodology for writing user-friendly natural language computer applications,"A six-step, iterative, empirical, human factors design methodology was used to develop <bold><italic>CAL,</italic></bold>a natural language computer application to help computer-naive business professionals manage their personal calendars. Language is processed by a simple, non-parsing algorithm having limited storage requirements and a quick response time. <bold><italic>CAL</italic></bold> allows unconstrained English inputs from users with no training (except for a 5 minute introduction to the keyboard and display) and no manual (except for a two-page overview of the system). In a controlled test of performance, <bold><italic>CAL</italic></bold> correctly responded to between 86% and 97% of the inputs it received, according to various criteria. This research demonstrates that the methodological tools of the engineering psychologist can help build user-friendly software that accommodates the unruly language of computer-naive, first-time users by eliciting the cooperation of such users as partners in an iterative, empirical development process.
 The principal purpose of the research reported here was to design and test a systematic, empirical methodology for developing natural language computer applications. This paper describes that methodology and its successful use in the development of a natural language computer application: <bold><italic>CAL,</italic></bold><bold><italic>C</italic></bold>alendar <bold><italic>A</italic></bold>ccess <bold><italic>L</italic></bold>anguage. The limited context or domain in which the application operates is the management of a personal calendar, or appointment book, data base by computer-naive business professionals.",1983.0,7.0,269.0,False,,{'pages': '193-196'},"{'bibtex': '@Inproceedings{Kelley1983AnEM,\n author = {J. F. Kelley},\n pages = {193-196},\n title = {An empirical methodology for writing user-friendly natural language computer applications},\n year = {1983}\n}\n'}","[{'authorId': '2072865746', 'name': 'J. F. Kelley'}]"
1499,81113eab5fd886c371868bdbdfc875acf124072e,A computational model of trust and reputation,"Despite their many advantages, e-businesses lag behind brick and mortar businesses in several fundamental respects. This paper concerns one of these: relationships based on trust and reputation. Recent studies on simple reputation systems for e-Businesses such as eBay have pointed to the importance of such rating systems for deterring moral hazard and encouraging trusting interactions. However, despite numerous studies on trust and reputation systems, few have taken studies across disciplines to provide an integrated account of these concepts and their relationships. This paper first surveys existing literatures on trust, reputation and a related concept: reciprocity. Based on sociological and biological understandings of these concepts, a computational model is proposed. This model can be implemented in a real system to consistently calculate agents' trust and reputation scores.",2002.0,62.0,1062.0,True,"{'url': 'http://www.comp.nus.edu.sg/~ooibc/courses/cs6203/TrustReputationModel.pdf', 'status': None}","{'pages': '2431-2439', 'name': 'Proceedings of the 35th Annual Hawaii International Conference on System Sciences'}","{'bibtex': '@Article{Mui2002ACM,\n author = {L. Mui and M. Mohtashemi and A. Halberstadt},\n journal = {Proceedings of the 35th Annual Hawaii International Conference on System Sciences},\n pages = {2431-2439},\n title = {A computational model of trust and reputation},\n year = {2002}\n}\n'}","[{'authorId': '145124469', 'name': 'L. Mui'}, {'authorId': '2725157', 'name': 'M. Mohtashemi'}, {'authorId': '39863484', 'name': 'A. Halberstadt'}]"
1500,8120bee1fa392ece012356de0a9bc9f2aadc1f1b,Better Game Characters by Design - A Psychological Approach,,2006.0,0.0,138.0,False,,"{'pages': 'I-XXVII, 1-336'}","{'bibtex': '@Inproceedings{Isbister2006BetterGC,\n author = {K. Isbister},\n pages = {I-XXVII, 1-336},\n title = {Better Game Characters by Design - A Psychological Approach},\n year = {2006}\n}\n'}","[{'authorId': '1740889', 'name': 'K. Isbister'}]"
1501,8142668ad01565997cf8e1bd15fb23549f4b9a8d,"Towards Systems That Care: A Conceptual Framework based on Motivation, Metacognition and Affect","This paper describes a Conceptual Framework underpinning “Systems that Care” in terms of educational systems that take account of motivation, metacognition and affect, in addition to cognition. The main focus is on motivation, as learning requires the student to put in effort and be engaged, in other words to be motivated to learn. But motivation is not the whole story as it is strongly related to metacognition and affect. Traditional intelligent educational systems, whether learner-centred or teacher-centred in their pedagogy, are characterised as having deployed their intelligence to assist in the development of the learner's knowledge or skill in some domain. They have operated largely at the cognitive level and have assumed that the learner is already able to manage her own learning, is already in an appropriate affective state and also is already motivated to learn. This paper starts by outlining theories of motivation and their interactions with affect and with metacognition, as developed in the psychological and educational literatures. It then describes how such theories have been implemented in intelligent educational systems. The first part of the Conceptual Framework develops the notion of a partial hierarchy of systems in terms of their pedagogic focus. These range from traditional, cognitively intelligent systems, essentially concerned with cognition up to “Systems that Care”. Intermediate classes of system include Metacognitively Intelligent systems, Affectively Intelligent systems and Motivationally Intelligent systems. The second part of the Conceptual Framework is concerned with the design of systems. This is characterised in terms of (i) the kinds of diagnostic input data (such as the learner's facial expression offering clues as to her demeanour) and (ii) the repertoire of tactical and strategic pedagogic moves (such as offering encouragement), applicable at different levels of the hierarchy. Attention is paid to metacognition, meta-affect and meta-motivation covering the capability of both the learner and the educational system to understand, reason about and regulate cognition, affect and motivation. Finally, research questions and areas of further work are identified in theory development, the role of the meta levels, and design considerations.",2010.0,117.0,74.0,False,,"{'volume': '20', 'pages': '197-229', 'name': 'Int. J. Artif. Intell. Educ.'}","{'bibtex': '@Article{Boulay2010TowardsST,\n author = {John Benedict du Boulay and K. Avramides and R. Luckin and Erika Martínez-Mirón and G. Rebolledo-Méndez and Amanda Carr},\n journal = {Int. J. Artif. Intell. Educ.},\n pages = {197-229},\n title = {Towards Systems That Care: A Conceptual Framework based on Motivation, Metacognition and Affect},\n volume = {20},\n year = {2010}\n}\n'}","[{'authorId': '1738475', 'name': 'John Benedict du Boulay'}, {'authorId': '1715292', 'name': 'K. Avramides'}, {'authorId': '1804082', 'name': 'R. Luckin'}, {'authorId': '1403924770', 'name': 'Erika Martínez-Mirón'}, {'authorId': '1400900451', 'name': 'G. Rebolledo-Méndez'}, {'authorId': '31951571', 'name': 'Amanda Carr'}]"
1502,8159f3f1bc1155ff56bed7fea38d052c4524108b,"Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents**This work has been supported in part by ARO Grants W911NF1910069 and W911NF1910315, and Intel. Code and additional materials available at: https://gamma.umd.edu/t2g","We present Text2Gestures, a transformer-based learning method to interactively generate emotive full-body gestures for virtual agents aligned with natural language text inputs. Our method generates emotionally expressive gestures by utilizing the relevant biomechanical features for body expressions, also known as affective features. We also consider the intended task corresponding to the text and the target virtual agents' intended gender and handedness in our generation pipeline. We train and evaluate our network on the MPI Emotional Body Expressions Database and observe that our network produces state-of-the-art performance in generating gestures for virtual agents aligned with the text for narration or conversation. Our network can generate these gestures at interactive rates on a commodity GPU. We conduct a web-based user study and observe that around 91% of participants indicated our generated gestures to be at least plausible on a five-point Likert Scale. The emotions perceived by the participants from the gestures are also strongly positively correlated with the corresponding intended emotions, with a minimum Pearson coefficient of 0.77 in the valence dimension.",2021.0,72.0,75.0,True,"{'url': 'https://arxiv.org/pdf/2101.11101', 'status': None}","{'pages': '1-10', 'name': '2021 IEEE Virtual Reality and 3D User Interfaces (VR)'}","{'bibtex': '@Article{Bhattacharya2021Text2GesturesAT,\n author = {Uttaran Bhattacharya and Nicholas Rewkowski and A. Banerjee and P. Guhan and Aniket Bera and Dinesh Manocha},\n journal = {2021 IEEE Virtual Reality and 3D User Interfaces (VR)},\n pages = {1-10},\n title = {Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents**This work has been supported in part by ARO Grants W911NF1910069 and W911NF1910315, and Intel. Code and additional materials available at: https://gamma.umd.edu/t2g},\n year = {2021}\n}\n'}","[{'authorId': '50227009', 'name': 'Uttaran Bhattacharya'}, {'authorId': '10172108', 'name': 'Nicholas Rewkowski'}, {'authorId': '39373885', 'name': 'A. Banerjee'}, {'authorId': '6325349', 'name': 'P. Guhan'}, {'authorId': '2718563', 'name': 'Aniket Bera'}, {'authorId': '1699159', 'name': 'Dinesh Manocha'}]"
1503,815c464c53d29e62c476470aa0eb8eb7d47d0923,Emotional Facial and Vocal Expressions During Story Retelling by Children and Adolescents With High-Functioning Autism,"Purpose: People with high-functioning autism (HFA) have qualitative differences in facial expression and prosody production, which are rarely systematically quantified. The authors’ goals were to qualitatively and quantitatively analyze prosody and facial expression productions in children and adolescents with HFA. Method: Participants were 22 male children and adolescents with HFA and 18 typically developing (TD) controls (17 males, 1 female). The authors used a story retelling task to elicit emotionally laden narratives, which were analyzed through the use of acoustic measures and perceptual codes. Naı¨ve listeners coded all productions for emotion type, degree of expressiveness, and awkwardness. Results: The group with HFA was not significantly different in accuracy or expressiveness of facial productions, but was significantly more awkward than the TD group. Participants with HFA were significantly more expressive in their vocal productions, with a trend for greater awkwardness. Severity of social communication impairment, as captured by the Autism Diagnostic Observation Schedule (ADOS; Lord, Rutter, DiLavore, & Risi, 1999), was correlated with greater vocal and facial awkwardness. Conclusions: Facial and vocal expressions of participants with HFA were as recognizable as those of their TD peers but were qualitatively different, particularly when listeners coded samples with intact dynamic properties. These preliminary data show qualitative differences in nonverbal communication that may have significant negative impact on the social communication success of children and adolescents with HFA.",,32.0,89.0,False,,,"{'bibtex': '@Misc{None,\n author = {Ruth B. Grossman and Lisa R. Edelson and H. Tager-Flusberg and Janna Oetting and Nina Capone-Singleton},\n title = {Emotional Facial and Vocal Expressions During Story Retelling by Children and Adolescents With High-Functioning Autism}\n}\n'}","[{'authorId': '2112121541', 'name': 'Ruth B. Grossman'}, {'authorId': '5644208', 'name': 'Lisa R. Edelson'}, {'authorId': '1404511422', 'name': 'H. Tager-Flusberg'}, {'authorId': '2251496803', 'name': 'Janna Oetting'}, {'authorId': '2251468363', 'name': 'Nina Capone-Singleton'}]"
1504,8164a5c811c641ce9f7cb6a73cdc3ca02fc789d6,Prevalence of Depression Symptoms in US Adults Before and During the COVID-19 Pandemic,"Key Points Question What is the burden of depression symptoms among US adults during the coronavirus disease 2019 (COVID-19) pandemic compared with before COVID-19, and what are the risk factors associated with depression symptoms? Findings In this survey study that included 1441 respondents from during the COVID-19 pandemic and 5065 respondents from before the pandemic, depression symptom prevalence was more than 3-fold higher during the COVID-19 pandemic than before. Lower income, having less than $5000 in savings, and having exposure to more stressors were associated with greater risk of depression symptoms during COVID-19. Meaning These findings suggest that there is a high burden of depression symptoms in the US associated with the COVID-19 pandemic and that this burden falls disproportionately on individuals who are already at increased risk.",2020.0,30.0,1417.0,True,"{'url': 'https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2770146/ettman_2020_oi_200687_1602708692.31352.pdf', 'status': None}","{'volume': '3', 'name': 'JAMA Network Open'}","{'bibtex': '@Article{Ettman2020PrevalenceOD,\n author = {Catherine K. Ettman and S. Abdalla and Gregory H. Cohen and Laura A Sampson and P. Vivier and S. Galea},\n journal = {JAMA Network Open},\n title = {Prevalence of Depression Symptoms in US Adults Before and During the COVID-19 Pandemic},\n volume = {3},\n year = {2020}\n}\n'}","[{'authorId': '26428407', 'name': 'Catherine K. Ettman'}, {'authorId': '145247865', 'name': 'S. Abdalla'}, {'authorId': '7778047', 'name': 'Gregory H. Cohen'}, {'authorId': '3568083', 'name': 'Laura A Sampson'}, {'authorId': '39961865', 'name': 'P. Vivier'}, {'authorId': '1822602', 'name': 'S. Galea'}]"
1505,817078a19b41c435f95cd0eb3bc0d8b73f3adf76,Wizard of Oz studies: why and how,"Current approaches to the development of natural language dialogue systems are discussed, and it is claimed that they do not sufficiently consider the unique qualities of man-machine interaction as distinct from general human discourse. It is concluded that empirical studies of this unique communication situation are required for the development of user-friendly interactive systems. One way of achieving this is through the use of so-called Wizard of Oz studies. The focus of the work described in the paper is on the practical execution of the studies and the methodological conclusions drawn on the basis of the authors' experience. While the focus is on natural language interfaces, the methods used and the conclusions drawn from the results obtained are of relevance also to other kinds of intelligent interfaces.",1993.0,28.0,1276.0,True,"{'url': 'http://www.ida.liu.se/~arnjo/papers/kbs.pdf', 'status': None}","{'volume': '6', 'pages': '258-266', 'name': 'Knowl. Based Syst.'}","{'bibtex': '@Article{Dahlbäck1993WizardOO,\n author = {Nils Dahlbäck and Arne Jönsson and Lars Ahrenberg},\n journal = {Knowl. Based Syst.},\n pages = {258-266},\n title = {Wizard of Oz studies: why and how},\n volume = {6},\n year = {1993}\n}\n'}","[{'authorId': '2633619', 'name': 'Nils Dahlbäck'}, {'authorId': '144349151', 'name': 'Arne Jönsson'}, {'authorId': '1742056', 'name': 'Lars Ahrenberg'}]"
1506,819d3d76362925246bb735c05aaf6b3b4b4cc685,Does the Frequency of Pedagogical Agent Intervention Relate to Learners' Self-Reported Boredom while using Multiagent Intelligent Tutoring Systems?,"Pedagogical agents (PAs) have the ability to scaffold and regulate students' learning about complex topics while using intelligent tutoring systems (ITSs). Research on ITSs predominantly focuses on the impact that these systems have on overall learning, while the specific components of human-ITS interaction, such as student-PA dialogue within the system, are given little attention. One hundred undergraduate students interacted with MetaTutor, a multiagent hypermedia ITS, to learn about the human circulatory system. Data from these interactions were drawn from questionnaires and log-files to determine the extent to which a specific agent from MetaTutor, Sam the Strategizer, impacted students' overall emotions while using the system. Results indicated that Sam negatively impacted students' experiences of enjoyment, in relation to the other agents of MetaTutor, and the frequency of Sam's interactions with students significantly predicted their reports of boredom while using the system. Implications for the design of affect-sensitive multiagent ITSs are discussed.",2015.0,28.0,3.0,False,,"{'volume': '', 'pages': '1661-1666', 'name': 'Cognitive Science'}","{'bibtex': ""@Article{Mudrick2015DoesTF,\n author = {Nicholas V. Mudrick and R. Azevedo and M. Taub and François Bouchet},\n journal = {Cognitive Science},\n pages = {1661-1666},\n title = {Does the Frequency of Pedagogical Agent Intervention Relate to Learners' Self-Reported Boredom while using Multiagent Intelligent Tutoring Systems?},\n year = {2015}\n}\n""}","[{'authorId': '3408438', 'name': 'Nicholas V. Mudrick'}, {'authorId': '145394858', 'name': 'R. Azevedo'}, {'authorId': '37057683', 'name': 'M. Taub'}, {'authorId': '40845119', 'name': 'François Bouchet'}]"
1507,81a141d3346e4553352cfceb0feca9a053d3f62a,Is Fear in Your Head? A Comparison of Instructed and Real-Life Expressions of Emotion in the Face and Body,"The majority of emotion perception studies utilize instructed and stereotypical expressions of faces or bodies. While such stimuli are highly standardized and well-recognized, their resemblance to real-life expressions of emotion remains unknown. Here we examined facial and body expressions of fear and anger during real-life situations and compared their recognition to that of instructed expressions of the same emotions. In order to examine the source of the affective signal, expressions of emotion were presented as faces alone, bodies alone, and naturally, as faces with bodies. The results demonstrated striking deviations between recognition of instructed and real-life stimuli, which differed as a function of the emotion expressed. In real-life fearful expressions of emotion, bodies were far better recognized than faces, a pattern not found with instructed expressions of emotion. Anger reactions were better recognized from the body than from the face in both real-life and instructed stimuli. However, the real-life stimuli were overall better recognized than their instructed counterparts. These results indicate that differences between instructed and real-life expressions of emotion are prevalent and raise caution against an overreliance of researchers on instructed affective stimuli. The findings also demonstrate that in real life, facial expression perception may rely heavily on information from the contextualizing body.",2017.0,57.0,30.0,False,,"{'volume': '17', 'pages': '557–565', 'name': 'Emotion'}","{'bibtex': '@Article{Abramson2017IsFI,\n author = {Lior Abramson and Inbal Marom and Rotem Petranker and Hillel Aviezer},\n journal = {Emotion},\n pages = {557–565},\n title = {Is Fear in Your Head? A Comparison of Instructed and Real-Life Expressions of Emotion in the Face and Body},\n volume = {17},\n year = {2017}\n}\n'}","[{'authorId': '92120041', 'name': 'Lior Abramson'}, {'authorId': '50164286', 'name': 'Inbal Marom'}, {'authorId': '9757810', 'name': 'Rotem Petranker'}, {'authorId': '4387567', 'name': 'Hillel Aviezer'}]"
1508,81aba593a542b0188c0a4823b4f43628b5824c80,Quantifying facial expression recognition across viewing conditions,,2006.0,45.0,113.0,True,,"{'volume': '46', 'pages': '1253-1262', 'name': 'Vision Research'}","{'bibtex': '@Article{Goren2006QuantifyingFE,\n author = {Deborah Goren and H. Wilson},\n journal = {Vision Research},\n pages = {1253-1262},\n title = {Quantifying facial expression recognition across viewing conditions},\n volume = {46},\n year = {2006}\n}\n'}","[{'authorId': '50787260', 'name': 'Deborah Goren'}, {'authorId': '32733837', 'name': 'H. Wilson'}]"
1509,81abe72568697807addda1ea2f731419581ce112,Facial recognition deficits and cognition in schizophrenia,,2004.0,40.0,258.0,False,,"{'volume': '68', 'pages': '27-35', 'name': 'Schizophrenia Research'}","{'bibtex': '@Article{Sachs2004FacialRD,\n author = {G. Sachs and D. Steger-Wuchse and I. Kryspin-Exner and R. Gur and H. Katschnig},\n journal = {Schizophrenia Research},\n pages = {27-35},\n title = {Facial recognition deficits and cognition in schizophrenia},\n volume = {68},\n year = {2004}\n}\n'}","[{'authorId': '39906553', 'name': 'G. Sachs'}, {'authorId': '1404644570', 'name': 'D. Steger-Wuchse'}, {'authorId': '1398005104', 'name': 'I. Kryspin-Exner'}, {'authorId': '144762538', 'name': 'R. Gur'}, {'authorId': '6977570', 'name': 'H. Katschnig'}]"
1510,81b2098fc1454700ebe531d97d20409a017241a8,The Bodily Expressive Action Stimulus Test (BEAST). Construction and Validation of a Stimulus Basis for Measuring Perception of Whole Body Expression of Emotions,"Whole body expressions are among the main visual stimulus categories that are naturally associated with faces and the neuroscientific investigation of how body expressions are processed has entered the research agenda this last decade. Here we describe the stimulus set of whole body expressions termed bodily expressive action stimulus test (BEAST), and we provide validation data for use of these materials by the community of emotion researchers. The database was composed of 254 whole body expressions from 46 actors expressing 4 emotions (anger, fear, happiness, and sadness). In all pictures the face of the actor was blurred and participants were asked to categorize the emotions expressed in the stimuli in a four alternative-forced-choice task. The results show that all emotions are well recognized, with sadness being the easiest, followed by fear, whereas happiness was the most difficult. The BEAST appears a valuable addition to currently available tools for assessing recognition of affective signals. It can be used in explicit recognition tasks as well as in matching tasks and in implicit tasks, combined either with facial expressions, with affective prosody, or presented with affective pictures as context in healthy subjects as well as in clinical populations.",2011.0,50.0,131.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00181/pdf', 'status': None}","{'volume': '2', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Gelder2011TheBE,\n author = {B. de Gelder and J. van den Stock},\n journal = {Frontiers in Psychology},\n title = {The Bodily Expressive Action Stimulus Test (BEAST). Construction and Validation of a Stimulus Basis for Measuring Perception of Whole Body Expression of Emotions},\n volume = {2},\n year = {2011}\n}\n'}","[{'authorId': '4628064', 'name': 'B. de Gelder'}, {'authorId': '7202556', 'name': 'J. van den Stock'}]"
1511,81cc7979787490762e43e2048f670ffdf46bd267,Speech act classification,,1980.0,0.0,61.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ballmer1980SpeechAC,\n author = {T. Ballmer and W. Brennenstuhl},\n title = {Speech act classification},\n year = {1980}\n}\n'}","[{'authorId': '113331537', 'name': 'T. Ballmer'}, {'authorId': '66607572', 'name': 'W. Brennenstuhl'}]"
1512,8209a8703d8c48aaca1523cfa307dd1c069e58f3,ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning,"We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., “if X pays Y a compliment, then Y will likely return the compliment”). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By generatively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.",2019.0,29.0,665.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/4160/4038', 'status': None}","{'volume': 'abs/1811.00146', 'name': 'ArXiv'}","{'bibtex': '@Article{Sap2019ATOMICAA,\n author = {Maarten Sap and Ronan Le Bras and Emily Allaway and Chandra Bhagavatula and Nicholas Lourie and Hannah Rashkin and Brendan Roof and Noah A. Smith and Yejin Choi},\n journal = {ArXiv},\n title = {ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning},\n volume = {abs/1811.00146},\n year = {2019}\n}\n'}","[{'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '46208659', 'name': 'Emily Allaway'}, {'authorId': '1857797', 'name': 'Chandra Bhagavatula'}, {'authorId': '35219984', 'name': 'Nicholas Lourie'}, {'authorId': '2516777', 'name': 'Hannah Rashkin'}, {'authorId': '144166461', 'name': 'Brendan Roof'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]"
1513,820a7b066de4d236fd8f10374043c9c784bd6801,Mini-Me: An Adaptive Avatar for Mixed Reality Remote Collaboration,"We present Mini-Me, an adaptive avatar for enhancing Mixed Reality (MR) remote collaboration between a local Augmented Reality (AR) user and a remote Virtual Reality (VR) user. The Mini-Me avatar represents the VR user's gaze direction and body gestures while it transforms in size and orientation to stay within the AR user's field of view. A user study was conducted to evaluate Mini-Me in two collaborative scenarios: an asymmetric remote expert in VR assisting a local worker in AR, and a symmetric collaboration in urban planning. We found that the presence of the Mini-Me significantly improved Social Presence and the overall experience of MR collaboration.",2018.0,53.0,262.0,False,,{'name': 'Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Piumsomboon2018MiniMeAA,\n author = {Thammathip Piumsomboon and Gun A. Lee and J. Hart and Barrett Ens and R. Lindeman and B. Thomas and M. Billinghurst},\n journal = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},\n title = {Mini-Me: An Adaptive Avatar for Mixed Reality Remote Collaboration},\n year = {2018}\n}\n'}","[{'authorId': '2297177', 'name': 'Thammathip Piumsomboon'}, {'authorId': '48534381', 'name': 'Gun A. Lee'}, {'authorId': '153077675', 'name': 'J. Hart'}, {'authorId': '2502367', 'name': 'Barrett Ens'}, {'authorId': '1719686', 'name': 'R. Lindeman'}, {'authorId': '143885004', 'name': 'B. Thomas'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}]"
1514,82284e968c67325c614034b03e22bc5505379605,Varieties of Cues to Emotion in Naturally Occurring Situations,"People were asked to observe a person with whom they lived, to report when they noticed that person experiencing an emotion, and to report what cues they used to detect the emotion. In Phase 1, observers were told to ""list the cues they used""; in Phase 2, they were told to ""describe how they could tell"""" that the target person was experiencing an emotion. Results were similar in both phases. Only 5 of the 182 respondents reported using a single cue whereas 10 reported using at least a dozen cues. Two out of three respondents reported using vocal cues; over a half reported using facial, indirect verbal, and context cues; nearly a half reported using body and activity cues; about a quarter of the respondents reported using physiological, trait, and other cues; and fewer than a tenth reported using direct verbal cues. Roughly the same number of cues and the same distribution of cue categories was found regardless of the emotion being observed, the sex of the person observing, the sex of the person being obse...",1996.0,0.0,111.0,False,,"{'volume': '10', 'pages': '137-153', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Planalp1996VarietiesOC,\n author = {S. Planalp},\n journal = {Cognition & Emotion},\n pages = {137-153},\n title = {Varieties of Cues to Emotion in Naturally Occurring Situations},\n volume = {10},\n year = {1996}\n}\n'}","[{'authorId': '13712093', 'name': 'S. Planalp'}]"
1515,8236182aa4b26e1d2109e4d1ab392d1972d16b63,Affective computing with primary and secondary emotions in a virtual human,,2009.0,48.0,199.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/1588933/2645606/IVA08_Becker-Asano_Wachsmuth_JournalFinalV2.pdf', 'status': None}","{'volume': '20', 'pages': '32-49', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Becker-Asano2009AffectiveCW,\n author = {C. Becker-Asano and I. Wachsmuth},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {32-49},\n title = {Affective computing with primary and secondary emotions in a virtual human},\n volume = {20},\n year = {2009}\n}\n'}","[{'authorId': '1403827243', 'name': 'C. Becker-Asano'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
1517,823a726365fc6b20039691b1c41f04b72493ea5e,The intermediary agent's brain: supporting learning to collaborate at the inter-personal level,"We discuss the design of the Intermediary Agent's brain, the control module of an embodied conversational virtual peer in a simulation game aimed at providing learning experiences regarding the dynamics of collaboration at the inter-personal (IP) level. We derive the overall aims of the game from theoretical foundations in collaboration theory and pedagogical theory and related requirements for the virtual peer; present the overall modular design of the system; and then detail the design perspectives and the interplay of the related operationalised concepts leading to the control architecture of the Intermediary Agent, that is realised as a simple cognitive appraisal process driven by direct and indirect effects of the missionoriented and social interactions of players and agent on the agent's level of trust in its human peers. We conclude with coverage of related work and insights from first deployment experiences.",2008.0,71.0,13.0,False,,{'pages': '1277-1280'},"{'bibtex': ""@Inproceedings{Martínez-Miranda2008TheIA,\n author = {J. Martínez-Miranda and B. Jung and Sabine Payr and P. Petta},\n pages = {1277-1280},\n title = {The intermediary agent's brain: supporting learning to collaborate at the inter-personal level},\n year = {2008}\n}\n""}","[{'authorId': '1398008961', 'name': 'J. Martínez-Miranda'}, {'authorId': '144292204', 'name': 'B. Jung'}, {'authorId': '2117794', 'name': 'Sabine Payr'}, {'authorId': '1764052', 'name': 'P. Petta'}]"
1518,824195fcb3a60157f038ad4c2a702d5c2d6f1ee0,Creating Rapport with Virtual Agents,,2007.0,35.0,395.0,True,"{'url': 'http://people.ict.usc.edu/~gratch/GratchIVA07-rapport.pdf', 'status': None}",{'pages': '125-138'},"{'bibtex': '@Inproceedings{Gratch2007CreatingRW,\n author = {J. Gratch and Ning Wang and Jillian Gerten and Edward Fast and Robin Duffy},\n pages = {125-138},\n title = {Creating Rapport with Virtual Agents},\n year = {2007}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '3023920', 'name': 'Jillian Gerten'}, {'authorId': '2432742', 'name': 'Edward Fast'}, {'authorId': '2091935839', 'name': 'Robin Duffy'}]"
1522,824e392846e1b38787c39d8318d5f1e44e9a6c5b,Systematic Review: Trust-Building Factors and Implications for Conversational Agent Design,"ABSTRACT Off-the-shelf conversational agents are permeating people’s everyday lives. In these artificial intelligence devices, trust plays a key role in users’ initial adoption and successful utilization. Factors enhancing trust toward conversational agents include appearances, voice features, and communication styles. Synthesizing such work will be useful in designing evidence-based, trustworthy conversational agents appropriate for various contexts. We conducted a systematic review of the experimental studies that investigated the effect of conversational agents’ and users’ characteristics on trust. From a full-text review of 29 articles, we identified five agent design-themes affecting trust toward conversational agents: social intelligence of the agent, voice characteristics and communication style, look of the agent, non-verbal communication, and performance quality. We also found that participants’ demographic, personality, or use context moderate the effect of these themes. We discuss implications for designing trustworthy conversational agents and responsibilities around on stereotypes and social norm building through agent design.",2021.0,75.0,95.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Systematic_Review_Trust-Building_Factors_and_Implications_for_Conversational_Agent_Design/12905991/1/files/24548859.pdf', 'status': None}","{'volume': '37', 'pages': '81 - 96', 'name': 'International Journal of Human–Computer Interaction'}","{'bibtex': '@Article{Rheu2021SystematicRT,\n author = {M. Rheu and Ji Youn Shin and Wei Peng and Jina Huh-Yoo},\n journal = {International Journal of Human–Computer Interaction},\n pages = {81 - 96},\n title = {Systematic Review: Trust-Building Factors and Implications for Conversational Agent Design},\n volume = {37},\n year = {2021}\n}\n'}","[{'authorId': '102256902', 'name': 'M. Rheu'}, {'authorId': '39944054', 'name': 'Ji Youn Shin'}, {'authorId': '2067858512', 'name': 'Wei Peng'}, {'authorId': '1404330722', 'name': 'Jina Huh-Yoo'}]"
1523,82554b56858be7b1b1ef0209f839141670782264,Examining the Use of Nonverbal Communication in Virtual Agents,"ABSTRACT Virtual agents are systems that add a social dimension to computing, often featuring not only natural language input but also an embodiment or avatar. This allows them to take on a more social role and leverage the use of nonverbal communication (NVC). In humans, NVC is used for many purposes, including communicating intent, directing attention, and conveying emotion. As a result, researchers have developed agents that emulate these behaviors. However, challenges pervade the design and development of NVC in agents. Some articles reveal inconsistencies in the benefits of agent NVC; others show signs of difficulties in the process of analyzing and implementing behaviors. Thus, it is unclear what the specific outcomes and effects of incorporating NVC in agents and what outstanding challenges underlie development. This survey seeks to review the uses, outcomes, and development of NVC in virtual agents to identify challenges and themes to improve and motivate the design of future virtual agents.",2021.0,212.0,27.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/10447318.2021.1898851?needAccess=true', 'status': 'HYBRID'}","{'name': 'International Journal of Human–Computer Interaction', 'pages': '1648 - 1673', 'volume': '37'}","{'bibtex': '@Article{Wang2021ExaminingTU,\n author = {Isaac Wang and J. Ruiz},\n booktitle = {International journal of human computer interactions},\n journal = {International Journal of Human–Computer Interaction},\n pages = {1648 - 1673},\n title = {Examining the Use of Nonverbal Communication in Virtual Agents},\n volume = {37},\n year = {2021}\n}\n'}","[{'authorId': '10693895', 'name': 'Isaac Wang'}, {'authorId': '151062472', 'name': 'J. Ruiz'}]"
1524,8272bd76f36d195023f245735e23e6b5c8b19afd,"Attachment, exploration, and separation: illustrated by the behavior of one-year-olds in a strange situation.","cussed. As an illustration of these concepts, a study is reported of 56 white, middle-class infants, 49-51 weeks of age, in a strange situation. The presence of the mother was found to encourage exploratory behavior, her absence to depress exploration and to heighten attachment behaviors. In separation episodes such behaviors as crying and search increased. In reunion episodes proximity-seeking and contact-maintaining behaviors were heightened. In a substantial proportion of Ss, contact-resisting behaviors were also heightened in the reunion episodes, usually in conjunction with contactmaintaining behaviors, thus suggesting ambivalence. Some Ss also displayed proximity-avoiding behavior in relation to the mother in the reunion episodes. These findings are discussed in the context of relevant observational, clinical, and experimental studies of human and nonhuman primates, including studies of mother-child separation. In conclusion, it is urged that the concepts of attachment and attachment behavior be kept broad enough to comprehend the spectrum of the findings of this range of studies.",1970.0,36.0,1505.0,False,,"{'volume': '41 1', 'pages': '\n          49-67\n        ', 'name': 'Child development'}","{'bibtex': '@Article{Ainsworth1970AttachmentEA,\n author = {M. Ainsworth and S. M. Bell},\n journal = {Child development},\n pages = {\n          49-67\n        },\n title = {Attachment, exploration, and separation: illustrated by the behavior of one-year-olds in a strange situation.},\n volume = {41 1},\n year = {1970}\n}\n'}","[{'authorId': '144607047', 'name': 'M. Ainsworth'}, {'authorId': '152945687', 'name': 'S. M. Bell'}]"
1525,8273427401842f4110a7b0db8b116aa3dc5412a6,Nonverbal and Verbal Communication: Hand Gestures and Facial Displays as Part of Language Use in Face-to-face Dialogue.,,2006.0,0.0,56.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bavelas2006NonverbalAV,\n author = {J. Bavelas and Nicole Chovil},\n title = {Nonverbal and Verbal Communication: Hand Gestures and Facial Displays as Part of Language Use in Face-to-face Dialogue.},\n year = {2006}\n}\n'}","[{'authorId': '2816755', 'name': 'J. Bavelas'}, {'authorId': '7679798', 'name': 'Nicole Chovil'}]"
1526,8281d76e5c61b3ded3c397cfe8f81b042ab0f06a,A Neural Model of Empathic States in Attachment-Based Psychotherapy,"We build on a neuroanatomical model of how empathic states can motivate caregiving behavior, via empathy circuit-driven activation of regions in the hypothalamus and amygdala, which in turn stimulate a mesolimbic–ventral pallidum pathway, by integrating findings related to the perception of pain in self and others. On this basis, we propose a network to capture states of personal distress and (weak and strong forms of) empathic concern, which are particularly relevant for psychotherapists conducting attachment-based interventions. This model is then extended for the case of self-attachment therapy, in which conceptualized components of the self serve as both the source of and target for empathic resonance. In particular, we consider how states of empathic concern involving an other that is perceived as being closely related to the self might enhance the motivation for self-directed bonding (which in turn is proposed to lead the individual toward more compassionate states) in terms of medial prefrontal cortex–mediated activation of these caregiving pathways. We simulate our model computationally and discuss the interplay between the bonding and empathy protocols of the therapy.",2017.0,179.0,10.0,True,"{'url': 'https://www.mitpressjournals.org/doi/pdf/10.1162/CPSY_a_00006', 'status': None}","{'volume': '1', 'pages': '132 - 167', 'name': 'Computational Psychiatry (Cambridge, Mass.)'}","{'bibtex': '@Article{Cittern2017ANM,\n author = {David Cittern and A. Edalat},\n journal = {Computational Psychiatry (Cambridge, Mass.)},\n pages = {132 - 167},\n title = {A Neural Model of Empathic States in Attachment-Based Psychotherapy},\n volume = {1},\n year = {2017}\n}\n'}","[{'authorId': '2585368', 'name': 'David Cittern'}, {'authorId': '1694989', 'name': 'A. Edalat'}]"
1528,82ab7355f4c10428081cddd99271db1de7ecaaa9,Extending ACT-R ’ s Memory Capabilities,"To resolve several problems of ACT-R’s declarative memory (DM), Schultheis, Barkowsky, and Bertel (2006) developed a new long-term memory (LTM) component, called LTM . In this paper we present two ACT-R interfaces which integrate LTM into ACT-R. Such integrating LTM makes it easily accessible to ACT-R modelers and allows more thoroughly evaluating it in its interplay with other components of a cognitive architecture. By considering four different memory phenomena we show that ACT-R with LTM is superior to ACT-R employing only DM and, thus, (a) LTM ’s benefits are not impaired when integrating it into a cognitive architecture and (b) using the newly developed interfaces improves ACT-R. In particular, integrating LTM into ACT-R allows computationally exploring memory conceptions which cannot be modeled with ACT-R utilizing only DM.",2007.0,16.0,4.0,False,,,"{'bibtex': '@Inproceedings{Schultheis2007ExtendingA,\n author = {Holger Schultheis and S. Lile},\n title = {Extending ACT-R ’ s Memory Capabilities},\n year = {2007}\n}\n'}","[{'authorId': '2652839', 'name': 'Holger Schultheis'}, {'authorId': '72620112', 'name': 'S. Lile'}]"
1529,82c7e9a512f59264d7e045c55fe393930284278f,Emotion Recognition and Detection Methods: A Comprehensive Survey,"Human emotion recognition through artificial intelligence is one of the most popular research fields among researchers nowadays. The fields of Human Computer Interaction (HCI) and Affective Computing are being extensively used to sense human emotions. Humans generally use a lot of indirect and non-verbal means to convey their emotions. The presented exposition aims to provide an overall overview with the analysis of all the noteworthy emotion detection methods at a single location. To the best of our knowledge, this is the first attempt to outline all the emotion recognition models developed in the last decade. The paper is comprehended by expending more than hundred papers; a detailed analysis of the methodologies along with the datasets is carried out in the paper. The study revealed that emotion detection is predominantly carried out through four major methods, namely, facial expression recognition, physiological signals recognition, speech signals variation and text semantics on standard databases such as JAFFE, CK+, Berlin Emotional Database, SAVEE, etc. as well as self-generated databases. Generally seven basic emotions are recognized through these methods. Further, we have compared different methods employed for emotion detection in humans. The best results were obtained by using Stationary Wavelet Transform for Facial Emotion Recognition , Particle Swarm Optimization assisted Biogeography based optimization algorithms for emotion recognition through speech, Statistical features coupled with different methods for physiological signals, Rough set theory coupled with SVM for text semantics with respective accuracies of 98.83%,99.47%, 87.15%,87.02% . Overall, the method of Particle Swarm Optimization assisted Biogeography based optimization algorithms with an accuracy of 99.47% on BES dataset gave the best results.",2020.0,77.0,66.0,True,"{'url': 'https://iecscience.org/uploads/jpapers/202003/dnQToaqdF8IRjhE62pfIovCkDJ2jXAcZdK6KHRzM.pdf', 'status': None}",{'name': 'Journal of Artificial Intelligence and Systems'},"{'bibtex': '@Article{Saxena2020EmotionRA,\n author = {Anvita Saxena and Ashish Khanna and Deepak Gupta},\n journal = {Journal of Artificial Intelligence and Systems},\n title = {Emotion Recognition and Detection Methods: A Comprehensive Survey},\n year = {2020}\n}\n'}","[{'authorId': '145670067', 'name': 'Anvita Saxena'}, {'authorId': '47688201', 'name': 'Ashish Khanna'}, {'authorId': '1685090538', 'name': 'Deepak Gupta'}]"
1530,8323fd773b7b2eba2f38a416d1e43395fafe7f23,Bridging the Gap between the Home and the Lab: A Qualitative Study of Acceptance of an Avatar Feedback System,,2012.0,4.0,6.0,False,,{'pages': '251-255'},"{'bibtex': '@Inproceedings{Ruijten2012BridgingTG,\n author = {Peter A. M. Ruijten and Y. D. Kort and P. Kosnar},\n pages = {251-255},\n title = {Bridging the Gap between the Home and the Lab: A Qualitative Study of Acceptance of an Avatar Feedback System},\n year = {2012}\n}\n'}","[{'authorId': '3098701', 'name': 'Peter A. M. Ruijten'}, {'authorId': '2291357', 'name': 'Y. D. Kort'}, {'authorId': '3292087', 'name': 'P. Kosnar'}]"
1531,8386839cf792836efe9e3ff0e9e7891d8a479c00,Social Robots for Long-Term Interaction: A Survey,,2013.0,87.0,681.0,False,,"{'volume': '5', 'pages': '291-308', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Leite2013SocialRF,\n author = {Iolanda Leite and C. Martinho and Ana Paiva},\n journal = {International Journal of Social Robotics},\n pages = {291-308},\n title = {Social Robots for Long-Term Interaction: A Survey},\n volume = {5},\n year = {2013}\n}\n'}","[{'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '145813496', 'name': 'C. Martinho'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1532,83c237af46814777f17ff1e3798db2f7f9c4368e,AutoTutor and Family: A Review of 17 Years of Natural Language Tutoring,,2014.0,163.0,185.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2Fs40593-014-0029-5.pdf', 'status': None}","{'volume': '24', 'pages': '427-469', 'name': 'International Journal of Artificial Intelligence in Education'}","{'bibtex': '@Article{Nye2014AutoTutorAF,\n author = {Benjamin D. Nye and A. Graesser and Xiangen Hu},\n journal = {International Journal of Artificial Intelligence in Education},\n pages = {427-469},\n title = {AutoTutor and Family: A Review of 17 Years of Natural Language Tutoring},\n volume = {24},\n year = {2014}\n}\n'}","[{'authorId': '66257841', 'name': 'Benjamin D. Nye'}, {'authorId': '1769251', 'name': 'A. Graesser'}, {'authorId': '3350316', 'name': 'Xiangen Hu'}]"
1533,83e701b8d8797c764af2d3fb5c43e32109f755e6,Audio-visual speech recognition techniques in augmented reality environments,,2014.0,33.0,22.0,False,,"{'volume': '30', 'pages': '245-257', 'name': 'The Visual Computer'}","{'bibtex': '@Article{Mirzaei2014AudiovisualSR,\n author = {M. Mirzaei and S. Ghorshi and Mohammad Mortazavi},\n journal = {The Visual Computer},\n pages = {245-257},\n title = {Audio-visual speech recognition techniques in augmented reality environments},\n volume = {30},\n year = {2014}\n}\n'}","[{'authorId': '2066584531', 'name': 'M. Mirzaei'}, {'authorId': '3031660', 'name': 'S. Ghorshi'}, {'authorId': '145285466', 'name': 'Mohammad Mortazavi'}]"
1534,840826772e34d7eab002df2932522cd816e8d237,3D Calculation of Stopping-Sight Distance from GPS Data,"Sight distance is a key element in highway geometric design. Existing models for evaluating sight distance are applicable only to two-dimensional (213), separate horizontal, and vertical alignments or simple elements of these separate alignments (vertical curve, horizontal curve). A new model using global positioning system (GPS) data is presented for determining the available sight distance on 3D combined horizontal and vertical alignments. Piecewise parametric equations in the form of cubic B-splines are used to represent the highway surface and sight obstructions, including tangents (grades), horizontal curves, and vertical curves. The available sight distance is found analytically by examining the intersection between the sight line and the elements representing the highway surface and sight obstructions. A profile of available sight distance can be established and used to evaluate sight-distance deficiency. Application of the new model is illustrated using actual GPS data for highway K-177 in Kansas (United States). The model has been tested and verified on most of the highways in Kansas. Software has been developed and can be used for determining the available sight distance on any highway for which GPS data are available.",2006.0,8.0,48.0,False,,"{'volume': '132', 'pages': '691-698', 'name': 'Journal of Transportation Engineering-asce'}","{'bibtex': '@Article{Nehate20063DCO,\n author = {Girish Nehate and M. Rys},\n journal = {Journal of Transportation Engineering-asce},\n pages = {691-698},\n title = {3D Calculation of Stopping-Sight Distance from GPS Data},\n volume = {132},\n year = {2006}\n}\n'}","[{'authorId': '97519585', 'name': 'Girish Nehate'}, {'authorId': '35054724', 'name': 'M. Rys'}]"
1535,8408e30b80a5480eae6e3febd97ff256ec3cd9af,Testing whether posttraumatic stress disorder and major depressive disorder are similar or unique constructs.,,2011.0,38.0,105.0,False,,"{'volume': '25 3', 'pages': '\n          404-10\n        ', 'name': 'Journal of anxiety disorders'}","{'bibtex': '@Article{Elhai2011TestingWP,\n author = {J. Elhai and Lucas de Francisco Carvalho and F. Miguel and P. Palmieri and Ricardo Primi and B. Christopher Frueh},\n journal = {Journal of anxiety disorders},\n pages = {\n          404-10\n        },\n title = {Testing whether posttraumatic stress disorder and major depressive disorder are similar or unique constructs.},\n volume = {25 3},\n year = {2011}\n}\n'}","[{'authorId': '2067039', 'name': 'J. Elhai'}, {'authorId': '2253158295', 'name': 'Lucas de Francisco Carvalho'}, {'authorId': '2059921983', 'name': 'F. Miguel'}, {'authorId': '6976005', 'name': 'P. Palmieri'}, {'authorId': '2076129712', 'name': 'Ricardo Primi'}, {'authorId': '7233725', 'name': 'B. Christopher Frueh'}]"
1536,840acc3bf20d515551772190800994707b4041fb,A System to Make Signs Using Collaborative Approach,,2008.0,6.0,57.0,False,,{'pages': '670-677'},"{'bibtex': '@Inproceedings{Jemni2008AST,\n author = {M. Jemni and Oussama El Ghoul},\n pages = {670-677},\n title = {A System to Make Signs Using Collaborative Approach},\n year = {2008}\n}\n'}","[{'authorId': '1696756', 'name': 'M. Jemni'}, {'authorId': '2116027', 'name': 'Oussama El Ghoul'}]"
1537,840d2fa3c3625231acfdcef1856c20f67c8385e0,ABS-SOCI: An Agent-Based Simulator of Student Sociograms,"Sociograms can represent the social relations between students. Some kinds of sociograms are more suitable than others for achieving a high academic performance of students. However, for now, at the beginning of an educative period, it is not possible to know for sure how the sociogram of a group of students will be or evolve during a semester or an academic year. In this context, the current approach presents an Agent-Based Simulator (ABS) that predicts the sociogram of a group of students taking into consideration their psychological profiles, by evolving an initial sociogram through time. This simulator is referred to as ABS-SOCI (ABS for SOCIograms). For instance, this can be useful for organizing class groups for some subjects of engineering grades, anticipating additional learning assistance or testing some teaching strategies. As experimentation, ABS-SOCI has been executed 100 times for each one of four real scenarios. The results show that ABS-SOCI produces sociograms similar to the real ones considering certain sociometrics. This similarity has been corroborated by statistical binomial tests that check whether there are significant differences between the simulations and the real cases. This experimentation also includes cross-validation and an analysis of sensitivity. ABS-SOCI is free and open-source to (1) ensure the reproducibility of the experiments; (2) to allow practitioners to run simulations; and (3) to allow developers to adapt the simulator for different environments.",2017.0,31.0,4.0,True,"{'url': 'https://www.mdpi.com/2076-3417/7/11/1126/pdf?version=1509533592', 'status': None}","{'volume': '7', 'pages': '1126', 'name': 'Applied Sciences'}","{'bibtex': '@Article{García-Magariño2017ABSSOCIAA,\n author = {I. García-Magariño and A. Lombas and I. Plaza and C. Medrano},\n journal = {Applied Sciences},\n pages = {1126},\n title = {ABS-SOCI: An Agent-Based Simulator of Student Sociograms},\n volume = {7},\n year = {2017}\n}\n'}","[{'authorId': '1398294938', 'name': 'I. García-Magariño'}, {'authorId': '3420304', 'name': 'A. Lombas'}, {'authorId': '144220345', 'name': 'I. Plaza'}, {'authorId': '144426554', 'name': 'C. Medrano'}]"
1538,842254774243a56313626ba04582360f1659cb06,Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning,"Emotion recognition has become an important field of research in Human Computer Interactions as we improve upon the techniques for modelling the various aspects of behaviour. With the advancement of technology our understanding of emotions are advancing, there is a growing need for automatic emotion recognition systems. One of the directions the research is heading is the use of Neural Networks which are adept at estimating complex functions that depend on a large number and diverse source of input data. In this paper we attempt to exploit this effectiveness of Neural networks to enable us to perform multimodal Emotion recognition on IEMOCAP dataset using data from Speech, Text, and Motion capture data from face expressions, rotation and hand movements. Prior research has concentrated on Emotion detection from Speech on the IEMOCAP dataset, but our approach is the first that uses the multiple modes of data offered by IEMOCAP for a more robust and accurate emotion detection.",2018.0,15.0,118.0,False,,,"{'bibtex': '@Inproceedings{Tripathi2018MultiModalER,\n author = {Samarth Tripathi and Sarthak Tripathi and H. Beigi},\n title = {Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning},\n year = {2018}\n}\n'}","[{'authorId': '2265542260', 'name': 'Samarth Tripathi'}, {'authorId': '2265542262', 'name': 'Sarthak Tripathi'}, {'authorId': '144396601', 'name': 'H. Beigi'}]"
1540,8432819a61a34f200ee753b26c767d5d83fa010a,Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness,"This study examines the roles of gender and visual realism in the persuasiveness of speakers. Participants were presented with a persuasive passage delivered by a male or female person, virtual human, or virtual character. They were then assessed on attitude change and their ratings of the argument, message, and speaker. The results indicated that the virtual speakers were as effective at changing attitudes as real people. Male participants were more persuaded when the speaker was female than when the speaker was male, whereas female participants were more persuaded when the speaker was male than when the speaker was female. Cross gender interactions occurred across all conditions, suggesting that some of the gender stereotypes that occur with people may carry over to interaction with virtual characters. Ratings of the perceptions of the speaker were more favorable for virtual speakers than for human speakers. We discuss the application of these findings in the design of persuasive human computer interfaces.",2006.0,32.0,125.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Zanbaka2006CanAV,\n author = {Catherine A. Zanbaka and P. Goolkasian and L. Hodges},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness},\n year = {2006}\n}\n'}","[{'authorId': '1826425', 'name': 'Catherine A. Zanbaka'}, {'authorId': '2194713', 'name': 'P. Goolkasian'}, {'authorId': '1710833', 'name': 'L. Hodges'}]"
1541,8432aa15730df7432e1ca82ce48f0a90da2a86ec,SPSS and SAS procedures for estimating indirect effects in simple mediation models,,2004.0,41.0,15602.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03206553.pdf', 'status': None}","{'volume': '36', 'pages': '717-731', 'name': 'Behavior Research Methods, Instruments, & Computers'}","{'bibtex': '@Article{Preacher2004SPSSAS,\n author = {Kristopher J Preacher and A. Hayes},\n journal = {Behavior Research Methods, Instruments, & Computers},\n pages = {717-731},\n title = {SPSS and SAS procedures for estimating indirect effects in simple mediation models},\n volume = {36},\n year = {2004}\n}\n'}","[{'authorId': '4528719', 'name': 'Kristopher J Preacher'}, {'authorId': '23662196', 'name': 'A. Hayes'}]"
1542,843305cd48f9b43f0e7bb5414e6fdb3e78740e3b,Sequential Patterning of Facial Actions in the Production and Perception of Emotional Expressions,"Despite the fact that the facial expressions of emotions are naturally dynamic social signals, their communicative value has typically been studied using static photographs. In this paper, we focus on the perception of emotions from naturally occurring, dynamic facial displays produced in social interactions. In describing their impressions of 200 video records of spontaneous emotional expressions produced during a face-to-face emotional sharing task, observers were found to agree on five emotional factors: enjoyment, hostility, embarrassment, surprise, and sadness. FACS coding and sequential analysis using a pattern detection algorithm showed that recordings rated high on one emotional factor were characterized by unique sequences of facial actions coordinated with eye and/or gaze actions. Our results suggest that the dynamic unfolding of facial displays and their combination with additional nonverbal signals may play an important and still under-investigated role in emotion perception in face-to-face interactions.",2011.0,44.0,19.0,True,"{'url': 'https://archive-ouverte.unige.ch/unige:19371/ATTACHMENT01', 'status': None}","{'volume': '70', 'pages': '241-252', 'name': 'Swiss Journal of Psychology'}","{'bibtex': '@Article{Kaiser2011SequentialPO,\n author = {S. Kaiser},\n journal = {Swiss Journal of Psychology},\n pages = {241-252},\n title = {Sequential Patterning of Facial Actions in the Production and Perception of Emotional Expressions},\n volume = {70},\n year = {2011}\n}\n'}","[{'authorId': '10539662', 'name': 'S. Kaiser'}]"
1543,844df02b5f048640b315786a097a9f9c19795fe5,Measuring pedagogical agent persona and the influence of agent persona on learning,,2017.0,60.0,39.0,False,,"{'volume': '109', 'pages': '176-186', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Schroeder2017MeasuringPA,\n author = {Noah L. Schroeder and W. Romine and Scotty D. Craig},\n journal = {Comput. Educ.},\n pages = {176-186},\n title = {Measuring pedagogical agent persona and the influence of agent persona on learning},\n volume = {109},\n year = {2017}\n}\n'}","[{'authorId': '2854999', 'name': 'Noah L. Schroeder'}, {'authorId': '46960802', 'name': 'W. Romine'}, {'authorId': '2122336', 'name': 'Scotty D. Craig'}]"
1544,844ef462c0f75deb10ff748a3ee1fb93018146c5,Designing emotions for activity selection in autonomous agents,,2003.0,0.0,89.0,False,,,"{'bibtex': '@Inproceedings{Cañamero2003DesigningEF,\n author = {Dolores Cañamero},\n title = {Designing emotions for activity selection in autonomous agents},\n year = {2003}\n}\n'}","[{'authorId': '1719487', 'name': 'Dolores Cañamero'}]"
1545,846edce59df7ff2d7206412bed254d40a396451b,"Augmented Reality, Serious Games and Picture Exchange Communication System for People with ASD: Systematic Literature Review and Future Directions","For people with Autism Spectrum Disorder (ASD), using technological tools, such as augmented reality (AR) and serious games remain a new and unexplored option. To attract people with ASD who have communicative, social, emotional and attention deficit disorders to behavioral treatments, an attractive environment is needed that ensures continuity during treatment. The aim of the current work is to efficiently examine systematic reviews and relevant primary studies on ASD solutions from 2015 to 2020, particularly those using the traditional Picture Exchange Communication System (PECS), the application of augmented reality and those that propose serious games, thereby providing an overview of existing evidence and to identify strategies for future research. Five databases were searched for keywords that may be included within the broad Autism Spectrum Disorder ‘ASD’ umbrella term, alongside ‘augmented reality’, ‘serious games’ and ‘PECS’. We screened 1799 titles and abstracts, read, and retained 12 reviews and 43 studies. The studies scrutinized in our systematic review were examined to answer four primary and four sub-research questions, which we formulated to better understand general trends in the use of approaches for attracting people with ASD to behavioral therapies. Additionally, our systematic review also presents ongoing issues in this area of research and suggests promising future research directions. Our review is useful to researchers in this field as it facilitates the comparison of existing studies with work currently being conducted, based on the availability of a wide range of studies in three different areas (AR, SG and PECS).",2022.0,123.0,18.0,True,"{'url': 'https://www.mdpi.com/1424-8220/22/3/1250/pdf?version=1644474709', 'status': None}","{'volume': '22', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Almurashi2022AugmentedRS,\n author = {Haneen Almurashi and Rahma Bouaziz and Wallaa Alharthi and Mohammed Al-Sarem and Mohammed Hadwan and Slim Kammoun},\n journal = {Sensors (Basel, Switzerland)},\n title = {Augmented Reality, Serious Games and Picture Exchange Communication System for People with ASD: Systematic Literature Review and Future Directions},\n volume = {22},\n year = {2022}\n}\n'}","[{'authorId': '2091329259', 'name': 'Haneen Almurashi'}, {'authorId': '2620898', 'name': 'Rahma Bouaziz'}, {'authorId': '2153809321', 'name': 'Wallaa Alharthi'}, {'authorId': '1397312292', 'name': 'Mohammed Al-Sarem'}, {'authorId': '2058429', 'name': 'Mohammed Hadwan'}, {'authorId': '9286494', 'name': 'Slim Kammoun'}]"
1546,848049c55619a9295056664cc51fbd4b10aca84c,Algorithm discovery by protein folding game players,"Foldit is a multiplayer online game in which players collaborate and compete to create accurate protein structure models. For specific hard problems, Foldit player solutions can in some cases outperform state-of-the-art computational methods. However, very little is known about how collaborative gameplay produces these results and whether Foldit player strategies can be formalized and structured so that they can be used by computers. To determine whether high performing player strategies could be collectively codified, we augmented the Foldit gameplay mechanics with tools for players to encode their folding strategies as “recipes” and to share their recipes with other players, who are able to further modify and redistribute them. Here we describe the rapid social evolution of player-developed folding algorithms that took place in the year following the introduction of these tools. Players developed over 5,400 different recipes, both by creating new algorithms and by modifying and recombining successful recipes developed by other players. The most successful recipes rapidly spread through the Foldit player population, and two of the recipes became particularly dominant. Examination of the algorithms encoded in these two recipes revealed a striking similarity to an unpublished algorithm developed by scientists over the same period. Benchmark calculations show that the new algorithm independently discovered by scientists and by Foldit players outperforms previously published methods. Thus, online scientific game frameworks have the potential not only to solve hard scientific problems, but also to discover and formalize effective new strategies and algorithms.",2011.0,14.0,467.0,True,"{'url': 'https://www.pnas.org/content/pnas/108/47/18949.full.pdf', 'status': None}","{'volume': '108', 'pages': '18949 - 18953', 'name': 'Proceedings of the National Academy of Sciences'}","{'bibtex': '@Article{Khatib2011AlgorithmDB,\n author = {Firas Khatib and Seth Cooper and M. Tyka and Kefan Xu and I. Makedon and Zoran Popovic and D. Baker and Foldit players},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {18949 - 18953},\n title = {Algorithm discovery by protein folding game players},\n volume = {108},\n year = {2011}\n}\n'}","[{'authorId': '1694819', 'name': 'Firas Khatib'}, {'authorId': '145442343', 'name': 'Seth Cooper'}, {'authorId': '3158632', 'name': 'M. Tyka'}, {'authorId': '49343385', 'name': 'Kefan Xu'}, {'authorId': '1708939', 'name': 'I. Makedon'}, {'authorId': '1986848', 'name': 'Zoran Popovic'}, {'authorId': '2241617405', 'name': 'D. Baker'}, {'authorId': '1747520', 'name': 'Foldit players'}]"
1547,84986b977962f7f491b9243a2a52626771457542,Educational resources and implementation of a Greek sign language synthesis architecture,,2007.0,36.0,86.0,False,,"{'volume': '49', 'pages': '54-74', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Karpouzis2007EducationalRA,\n author = {K. Karpouzis and G. Caridakis and Stavroula-Evita Fotinea and E. Efthimiou},\n journal = {Comput. Educ.},\n pages = {54-74},\n title = {Educational resources and implementation of a Greek sign language synthesis architecture},\n volume = {49},\n year = {2007}\n}\n'}","[{'authorId': '1715144', 'name': 'K. Karpouzis'}, {'authorId': '2001300', 'name': 'G. Caridakis'}, {'authorId': '2358968', 'name': 'Stavroula-Evita Fotinea'}, {'authorId': '1893648', 'name': 'E. Efthimiou'}]"
1548,849bb402af1dd335e32a1bd253d1f5803942e9fe,Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems,"Open-domain human-computer conversation has attracted much attention in the field of NLP. Contrary to rule- or template-based domain-specific dialog systems, open-domain conversation usually requires data-driven approaches, which can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (called a query) in a large database, and return a reply that best matches the query. Generative approaches, typically based on recurrent neural networks (RNNs), can synthesize new replies, but they suffer from the problem of generating short, meaningless utterances. In this paper, we propose a novel ensemble of retrieval-based and generation-based dialog systems in the open domain. In our approach, the retrieved candidate, in addition to the original query, is fed to an RNN-based reply generator, so that the neural model is aware of more information. The generated reply is then fed back as a new candidate for post-reranking. Experimental results show that such ensemble outperforms each single part of it by a large margin.",2016.0,31.0,103.0,False,,"{'volume': 'abs/1610.07149', 'name': 'ArXiv'}","{'bibtex': '@Article{Song2016TwoAB,\n author = {Yiping Song and Rui Yan and Xiang Li and Dongyan Zhao and Ming Zhang},\n journal = {ArXiv},\n title = {Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems},\n volume = {abs/1610.07149},\n year = {2016}\n}\n'}","[{'authorId': '8281265', 'name': 'Yiping Song'}, {'authorId': '144539156', 'name': 'Rui Yan'}, {'authorId': '2144439440', 'name': 'Xiang Li'}, {'authorId': '144060462', 'name': 'Dongyan Zhao'}, {'authorId': '47474380', 'name': 'Ming Zhang'}]"
1549,84cd060b088012753fe94db021ec13bfa3499a0f,Facial Expression Recognition based on Electroencephalography,"Facial expressions and body postures contribute to convey the emotional state of a person as a nonverbal communicating act. Facial Expressions can be used to communicate the mood and mental state of a person to the observers especially for the paralyzed patients. Brain signals obtained by electroencephalography (EEG) are used for supervising different systems to facilitate humans. In this paper, brain signals of individuals have been used to recognize their facial expressions. Subjects are asked to express their facial expressions while watching a video clip and EEG data is recorded using a 14-channel Emotiv/EPOC EEG headset. Thirteen different statistical features are extracted to classify five facial expressions i.e., smile, looking up, looking down, eye wink and eye blink. Four different classifiers i.e., K-nearest neighbor, the Naive Bayes, support vector machine and multi-layer perceptron are used for the classification purpose. It is evident from the results that the accuracy of K-nearest neighbor classifier is superior to other classifiers when used to recognize facial expressions using brain signals.",2019.0,1.0,16.0,False,,"{'pages': '1-5', 'name': '2019 2nd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)'}","{'bibtex': '@Article{Raheel2019FacialER,\n author = {Aasim Raheel and Muhammad Majid and S. Anwar},\n journal = {2019 2nd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)},\n pages = {1-5},\n title = {Facial Expression Recognition based on Electroencephalography},\n year = {2019}\n}\n'}","[{'authorId': '1388353645', 'name': 'Aasim Raheel'}, {'authorId': '144974259', 'name': 'Muhammad Majid'}, {'authorId': '144608640', 'name': 'S. Anwar'}]"
1550,84d6423fb7764a8cbda4b3ef75a953d256d86298,Interacting with embodied agents that can see: how vision-enabled agents can assist in spatial tasks,"In this paper, we describe user experiences with a system equipped with cognitive vision that interacts with the user in the context of personal assistance in the office. A cognitive vision computer can see the user and user responses and react to situations that happen in the environment, crossing the boundary between the virtual and the physical world. How should such a seeing computer interact with its users? Three different interface styles -- a traditional GUI, a cartoon-like embodied agent and a realistic embodied agent -- are tested in two tasks where users are actively observed by a (simulated) cognitive vision system. The system assists them in problem solving. Both the non-embodied and the embodied interaction styles offer the user certain advantages and the pros and cons based on the experiment results are discussed in terms of performance, intelligence, trust, comfort, and social presence.",2006.0,25.0,19.0,False,,{'pages': '135-144'},"{'bibtex': '@Inproceedings{Geven2006InteractingWE,\n author = {A. Geven and Johann Schrammel and M. Tscheligi},\n pages = {135-144},\n title = {Interacting with embodied agents that can see: how vision-enabled agents can assist in spatial tasks},\n year = {2006}\n}\n'}","[{'authorId': '3002173', 'name': 'A. Geven'}, {'authorId': '2701197', 'name': 'Johann Schrammel'}, {'authorId': '1751253', 'name': 'M. Tscheligi'}]"
1553,84df6d9e5f7f5753a1c162a2d75dca78ecc42ddf,Suicide in College Students,"Despite substantial attention to the problem of suicide among college students over the past several decades, reports on the extent of the problem have been largely inconclusive. This article reviews the findings of major studies of college suicide, noting how variations in campus and student characteristics, as well as inconsistencies in the way student suicides are defined and measured, have limited comparison of conclusions. Current evidence is reviewed that points to significant mental health problems on college campuses and suggests the need for outreach programs to identify students at risk for suicide and encourage them into treatment. One such program under development by the American Foundation for Suicide Prevention is described in detail. Problems related to its implementation are identified and discussed, notably the reluctance of many university officials to know the actual identities of suicidal students.",2003.0,60.0,116.0,False,,"{'volume': '46', 'pages': '1224 - 1240', 'name': 'American Behavioral Scientist'}","{'bibtex': '@Article{Haas2003SuicideIC,\n author = {A. Haas and H. Hendin and J. J. Mann},\n journal = {American Behavioral Scientist},\n pages = {1224 - 1240},\n title = {Suicide in College Students},\n volume = {46},\n year = {2003}\n}\n'}","[{'authorId': '2060856762', 'name': 'A. Haas'}, {'authorId': '48701897', 'name': 'H. Hendin'}, {'authorId': '2249128744', 'name': 'J. J. Mann'}]"
1554,84fbdd5923781dba16b8343b2ab3bfd418180862,Introducing the Geneva Multimodal Emotion Portrayal (GEMEP) corpus,"In this chapter we outline the requirements for a systematic corpus of actor portrayals and describe the development, recording, editing, and validating of a major new corpus, the Geneva Multimodal Emotion Portrayal (GEMEP). This corpus consists of more than 7,000 audio-video emotion portrayals, representing 18 emotions (including rarely studied subtle emotions), portrayed by 10 professional actors who were coached by a professional director. The portrayals are recorded with optimal digital quality in multiple modalities, using both pseudo linguistic utterances and affect bursts. In addition, the corpus includes stimuli with systematically varied intensity levels, as well as instances of masked expressions. From the total corpus, 1,260 portrayals were selected and submitted to a first rating procedure in different modalities to establish validity in terms of inter-judge reliability and recognition accuracy. The results show that the portrayed expressions are recognized by lay judges with an accuracy level that, in the case of all emotions, largely exceeded chance and that compares very favorably with published tests of emotion recognition that use highly selected stimulus sets. The portrayals also reach very satisfactory levels of inter-rater reliability for category judgments and ratings of believability and intensity of the portrayals. The validity of the corpus is further confirmed by replicating results in earlier work on the role of expression modality and the corresponding communication channel for cue utilization in emotion recognition. We show that, as expected, the highest accuracy results if both auditory and visual information (voice, face, and gestures) is available, but that sizeable accuracy is achieved even when only one modality is available. The video modality is slightly superior to the audio modality, probably reflecting the fact that facial and gestural cues are more discrete and iconic than vocal cues. However, there are important interactions between emotion and modality, as particular emotions seem to be preferentially communicated by visual or audio cues. The results also raise important issues concerning the relationships",2010.0,40.0,198.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bänziger2010IntroducingTG,\n author = {T. Bänziger and K. Scherer},\n title = {Introducing the Geneva Multimodal Emotion Portrayal (GEMEP) corpus},\n year = {2010}\n}\n'}","[{'authorId': '2162242', 'name': 'T. Bänziger'}, {'authorId': '2462740', 'name': 'K. Scherer'}]"
1555,850899a151dfb8fb35c756ea9284249db01e496d,Can computers be teammates?,"This study investigated the claim that humans will readily form team relationships with computers . Drawing from the group dynamic literature in human – human interactions , a laboratory experiment ( n (cid:53) 56) manipulated identity and interdependence to create team af ﬁliation in a human – computer interaction . The data show that subjects who are told they are interdependent with the computer af ﬁliate with the computer as a team . The data also show that the ef fects of being in a team with a computer are the same as the ef fects of being in a team with another human : subjects in the interdependence conditions perceived the computer to be more similar to themselves , saw themselves as more cooperative , were more open to inﬂuence from the computer , thought the information from the computer was of higher quality , found the information from the computer friendlier , and conformed more to the computer’s information . Subjects in the identity conditions showed neither team af ﬁliation nor the ef fects of team af ﬁliation .",1996.0,35.0,289.0,False,,,"{'bibtex': '@Inproceedings{Lifford1996CanCB,\n author = {Lifford and Ass and F. B.J. and Ogg and Oungme and Oon},\n title = {Can computers be teammates?},\n year = {1996}\n}\n'}","[{'authorId': '123022889', 'name': 'Lifford'}, {'authorId': '69876593', 'name': 'Ass'}, {'authorId': '97612131', 'name': 'F. B.J.'}, {'authorId': '114718563', 'name': 'Ogg'}, {'authorId': '2105450908', 'name': 'Oungme'}, {'authorId': '2071008837', 'name': 'Oon'}]"
1556,8510c3197c40a15567e117c6404d0f05f1a92082,Relational Agents in Clinical Psychiatry,"&NA; Relational agents are computational artifacts, such as animated, screen‐based characters or social robots, that are designed to establish a sense of rapport, trust, and even therapeutic alliance with patients, using ideal therapeutic relationships between human counselors and patients as role models. We describe the development and evaluation of several such agents designed for health counseling and behavioral‐change interventions, in which a therapeutic alliance is established with patients in order to enhance the efficacy of the intervention. We also discuss the promise of using such agents as adjuncts to clinical psychiatry, a range of possible applications, and some of the challenges and ethical issues in developing and fielding them in psychiatric interventions.",2010.0,53.0,99.0,False,,"{'volume': '18', 'pages': '119–130', 'name': 'Harvard Review of Psychiatry'}","{'bibtex': '@Article{Bickmore2010RelationalAI,\n author = {T. Bickmore and A. Gruber},\n journal = {Harvard Review of Psychiatry},\n pages = {119–130},\n title = {Relational Agents in Clinical Psychiatry},\n volume = {18},\n year = {2010}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '38963597', 'name': 'A. Gruber'}]"
1557,854eca61a57d2c1ea1019663caf022bc8fd0b909,SciPy 1.0: fundamental algorithms for scientific computing in Python,,2019.0,144.0,15305.0,True,"{'url': 'https://www.nature.com/articles/s41592-019-0686-2.pdf', 'status': None}","{'volume': '17', 'pages': '261 - 272', 'name': 'Nature Methods'}","{'bibtex': '@Article{Virtanen2019SciPy1F,\n author = {Pauli Virtanen and R. Gommers and T. Oliphant and Matt Haberland and Tyler Reddy and D. Cournapeau and Evgeni Burovski and Pearu Peterson and Warren Weckesser and Jonathan Bright and Stéfan J. van der Walt and M. Brett and Joshua Wilson and K. Millman and N. Mayorov and Andrew R. J. Nelson and E. Jones and Robert Kern and Eric Larson and C. Carey and İlhan Polat and Yu Feng and Eric W. Moore and J. Vanderplas and D. Laxalde and Josef Perktold and R. Cimrman and Ian Henriksen and E. Quintero and Charles R. Harris and A. Archibald and Antônio H. Ribeiro and Fabian Pedregosa and P. van Mulbregt and Aditya Alessandro Pietro Alex Andreas Andreas Anthony Ant Vijaykumar Bardelli Rothberg Hilboll Kloeckner Sco and A. Vijaykumar and Alessandro Pietro Bardelli and Alex Rothberg and A. Hilboll and Andre Kloeckner and A. Scopatz and Antony Lee and A. Rokem and C. N. Woods and Chad Fulton and Charles Masson and C. Häggström and Clark Fitzgerald and D. Nicholson and David R. Hagen and D. Pasechnik and E. Olivetti and Eric Martin and Eric Wieser and Fabrice Silva and F. Lenders and Florian Wilhelm and G. Young and Gavin A. Price and G. Ingold and Gregory E. Allen and Gregory R. Lee and H. Audren and I. Probst and J. Dietrich and J. Silterra and James T. Webber and J. Slavič and J. Nothman and J. Buchner and Johannes Kulick and Johannes L. Schönberger and J. V. De Miranda Cardoso and J. Reimer and J. Harrington and Juan Rodríguez and Juan Nunez-Iglesias and Justin Kuczynski and K. Tritz and M. Thoma and M. Newville and Matthias Kümmerer and Maximilian Bolingbroke and Michael Tartre and M. Pak and Nathaniel J. Smith and N. Nowaczyk and Nikolay Shebanov and O. Pavlyk and P. A. Brodtkorb and Perry Lee and R. McGibbon and Roman Feldbauer and Sam Lewis and S. Tygier and Scott Sievert and S. Vigna and Stefan Peterson and S. More and Tadeusz Pudlik and T. Oshima and T. Pingel and T. Robitaille and Thomas Spura and T. Jones and T. Cera and Tim Leslie and Tiziano Zito and Tom Krauss and U. Upadhyay and Y. Halchenko and Y. Vázquez-Baeza},\n journal = {Nature Methods},\n pages = {261 - 272},\n title = {SciPy 1.0: fundamental algorithms for scientific computing in Python},\n volume = {17},\n year = {2019}\n}\n'}","[{'authorId': '2053486178', 'name': 'Pauli Virtanen'}, {'authorId': '3912995', 'name': 'R. Gommers'}, {'authorId': '35525979', 'name': 'T. Oliphant'}, {'authorId': '2065380893', 'name': 'Matt Haberland'}, {'authorId': '144896751', 'name': 'Tyler Reddy'}, {'authorId': '3084321', 'name': 'D. Cournapeau'}, {'authorId': '2143743195', 'name': 'Evgeni Burovski'}, {'authorId': '143825690', 'name': 'Pearu Peterson'}, {'authorId': '2214143', 'name': 'Warren Weckesser'}, {'authorId': '2065294575', 'name': 'Jonathan Bright'}, {'authorId': '2066718598', 'name': 'Stéfan J. van der Walt'}, {'authorId': '144082394', 'name': 'M. Brett'}, {'authorId': '2115849250', 'name': 'Joshua Wilson'}, {'authorId': '2061249', 'name': 'K. Millman'}, {'authorId': '101711386', 'name': 'N. Mayorov'}, {'authorId': '2072898697', 'name': 'Andrew R. J. Nelson'}, {'authorId': '48376304', 'name': 'E. Jones'}, {'authorId': '2066375342', 'name': 'Robert Kern'}, {'authorId': '144752199', 'name': 'Eric Larson'}, {'authorId': '144873258', 'name': 'C. Carey'}, {'authorId': '49005409', 'name': 'İlhan Polat'}, {'authorId': '2150672343', 'name': 'Yu Feng'}, {'authorId': '2054115424', 'name': 'Eric W. Moore'}, {'authorId': '2081469', 'name': 'J. Vanderplas'}, {'authorId': '98592399', 'name': 'D. Laxalde'}, {'authorId': '15571182', 'name': 'Josef Perktold'}, {'authorId': '2772998', 'name': 'R. Cimrman'}, {'authorId': '35265702', 'name': 'Ian Henriksen'}, {'authorId': '153037053', 'name': 'E. Quintero'}, {'authorId': '2065073027', 'name': 'Charles R. Harris'}, {'authorId': '6402888', 'name': 'A. Archibald'}, {'authorId': '19235619', 'name': 'Antônio H. Ribeiro'}, {'authorId': '2570016', 'name': 'Fabian Pedregosa'}, {'authorId': '1491359454', 'name': 'P. van Mulbregt'}, {'authorId': '2064378280', 'name': 'Aditya Alessandro Pietro Alex Andreas Andreas Anthony Ant Vijaykumar Bardelli Rothberg Hilboll Kloeckner Sco'}, {'authorId': '1491360442', 'name': 'A. Vijaykumar'}, {'authorId': '46473152', 'name': 'Alessandro Pietro Bardelli'}, {'authorId': '13044073', 'name': 'Alex Rothberg'}, {'authorId': '5301477', 'name': 'A. Hilboll'}, {'authorId': '117221049', 'name': 'Andre Kloeckner'}, {'authorId': '2860725', 'name': 'A. Scopatz'}, {'authorId': '2116599554', 'name': 'Antony Lee'}, {'authorId': '2842990', 'name': 'A. Rokem'}, {'authorId': '144291907', 'name': 'C. N. Woods'}, {'authorId': '80845765', 'name': 'Chad Fulton'}, {'authorId': '122327721', 'name': 'Charles Masson'}, {'authorId': '1491360726', 'name': 'C. Häggström'}, {'authorId': '73014178', 'name': 'Clark Fitzgerald'}, {'authorId': '46347313', 'name': 'D. Nicholson'}, {'authorId': '1491359271', 'name': 'David R. Hagen'}, {'authorId': '1721034', 'name': 'D. Pasechnik'}, {'authorId': '1759500', 'name': 'E. Olivetti'}, {'authorId': '2151071148', 'name': 'Eric Martin'}, {'authorId': '34422202', 'name': 'Eric Wieser'}, {'authorId': '2110243690', 'name': 'Fabrice Silva'}, {'authorId': '15628537', 'name': 'F. Lenders'}, {'authorId': '2052594289', 'name': 'Florian Wilhelm'}, {'authorId': '113071069', 'name': 'G. Young'}, {'authorId': '2058961413', 'name': 'Gavin A. Price'}, {'authorId': '40657747', 'name': 'G. Ingold'}, {'authorId': '2059529796', 'name': 'Gregory E. Allen'}, {'authorId': '87747838', 'name': 'Gregory R. Lee'}, {'authorId': '40936461', 'name': 'H. Audren'}, {'authorId': '35148114', 'name': 'I. Probst'}, {'authorId': '144455209', 'name': 'J. Dietrich'}, {'authorId': '2669435', 'name': 'J. Silterra'}, {'authorId': '38847103', 'name': 'James T. Webber'}, {'authorId': '31387499', 'name': 'J. Slavič'}, {'authorId': '3083916', 'name': 'J. Nothman'}, {'authorId': '2151427', 'name': 'J. Buchner'}, {'authorId': '2562288', 'name': 'Johannes Kulick'}, {'authorId': '3010882', 'name': 'Johannes L. Schönberger'}, {'authorId': '1491360335', 'name': 'J. V. De Miranda Cardoso'}, {'authorId': '145935219', 'name': 'J. Reimer'}, {'authorId': '2068517007', 'name': 'J. Harrington'}, {'authorId': '152794754', 'name': 'Juan Rodríguez'}, {'authorId': '1398851518', 'name': 'Juan Nunez-Iglesias'}, {'authorId': '48736174', 'name': 'Justin Kuczynski'}, {'authorId': '50159131', 'name': 'K. Tritz'}, {'authorId': '47049820', 'name': 'M. Thoma'}, {'authorId': '144620446', 'name': 'M. Newville'}, {'authorId': '2997408', 'name': 'Matthias Kümmerer'}, {'authorId': '48393751', 'name': 'Maximilian Bolingbroke'}, {'authorId': '2980014', 'name': 'Michael Tartre'}, {'authorId': '36917288', 'name': 'M. Pak'}, {'authorId': '2116828326', 'name': 'Nathaniel J. Smith'}, {'authorId': '28955794', 'name': 'N. Nowaczyk'}, {'authorId': '1491361121', 'name': 'Nikolay Shebanov'}, {'authorId': '144208188', 'name': 'O. Pavlyk'}, {'authorId': '96695635', 'name': 'P. A. Brodtkorb'}, {'authorId': '2111215482', 'name': 'Perry Lee'}, {'authorId': '144431879', 'name': 'R. McGibbon'}, {'authorId': '3449704', 'name': 'Roman Feldbauer'}, {'authorId': '2112242667', 'name': 'Sam Lewis'}, {'authorId': '152330021', 'name': 'S. Tygier'}, {'authorId': '34953991', 'name': 'Scott Sievert'}, {'authorId': '1737624', 'name': 'S. Vigna'}, {'authorId': '2053615130', 'name': 'Stefan Peterson'}, {'authorId': '5891171', 'name': 'S. More'}, {'authorId': '92169827', 'name': 'Tadeusz Pudlik'}, {'authorId': '66273392', 'name': 'T. Oshima'}, {'authorId': '1915727', 'name': 'T. Pingel'}, {'authorId': '144512158', 'name': 'T. Robitaille'}, {'authorId': '3419085', 'name': 'Thomas Spura'}, {'authorId': '2646100', 'name': 'T. Jones'}, {'authorId': '90587764', 'name': 'T. Cera'}, {'authorId': '1491358355', 'name': 'Tim Leslie'}, {'authorId': '2207047', 'name': 'Tiziano Zito'}, {'authorId': '1491360459', 'name': 'Tom Krauss'}, {'authorId': '10515643', 'name': 'U. Upadhyay'}, {'authorId': '1722413', 'name': 'Y. Halchenko'}, {'authorId': '1398440330', 'name': 'Y. Vázquez-Baeza'}]"
1559,855f193ba056a80a4bd0d925fa4add46b9b03f4b,Avatar culture: cross-cultural evaluations of avatar facial expressions,,2009.0,30.0,48.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/46143/46143.pdf', 'status': None}","{'volume': '24', 'pages': '237-250', 'name': 'AI & SOCIETY'}","{'bibtex': '@Article{Koda2009AvatarCC,\n author = {Tomoko Koda and T. Ishida and M. Rehm and E. André},\n journal = {AI & SOCIETY},\n pages = {237-250},\n title = {Avatar culture: cross-cultural evaluations of avatar facial expressions},\n volume = {24},\n year = {2009}\n}\n'}","[{'authorId': '2060600', 'name': 'Tomoko Koda'}, {'authorId': '143807934', 'name': 'T. Ishida'}, {'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '1742930', 'name': 'E. André'}]"
1560,8571611db04df42d9ddcca39b1a3c23c11d51b6d,Socially-Aware Animated Intelligent Personal Assistant Agent,"SARA (Socially-Aware Robot Assistant) is an embodied intelligent personal assistant that analyses the user’s visual (head and face movement), vocal (acoustic features) and verbal (conversational strategies) behaviours to estimate its rapport level with the user, and uses its own appropriate visual, vocal and verbal behaviors to achieve task and social goals. The presented agent aids conference attendees by eliciting their preferences through building rapport, and then making informed personalized recommendations about sessions to attend and people to meet.",2016.0,12.0,78.0,True,"{'url': 'https://www.aclweb.org/anthology/W16-3628.pdf', 'status': None}",{'pages': '224-227'},"{'bibtex': '@Inproceedings{Matsuyama2016SociallyAwareAI,\n author = {Yoichi Matsuyama and Arjun Bhardwaj and Ran Zhao and Oscar Romeo and Sushma A. Akoju and Justine Cassell},\n pages = {224-227},\n title = {Socially-Aware Animated Intelligent Personal Assistant Agent},\n year = {2016}\n}\n'}","[{'authorId': '2026985', 'name': 'Yoichi Matsuyama'}, {'authorId': '2061543783', 'name': 'Arjun Bhardwaj'}, {'authorId': '2114012102', 'name': 'Ran Zhao'}, {'authorId': '7903321', 'name': 'Oscar Romeo'}, {'authorId': '51200544', 'name': 'Sushma A. Akoju'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
1561,8577dec8a9c980cabfecfa73c8cf237bd123bed3,Emotion Recognition of Virtual Agents Facial Expressions: The Effects of Age and Emotion Intensity,"People make determinations about the social characteristics of an agent (e.g., robot or virtual agent) by interpreting social cues displayed by the agent, such as facial expressions. Although a considerable amount of research has been conducted investigating age-related differences in emotion recognition of human faces (e.g., Sullivan, & Ruffman, 2004), the effect of age on emotion identification of virtual agent facial expressions has been largely unexplored. Age-related differences in emotion recognition of facial expressions are an important factor to consider in the design of agents that may assist older adults in a recreational or healthcare setting. The purpose of the current research was to investigate whether age-related differences in facial emotion recognition can extend to emotion-expressive virtual agents. Younger and older adults performed a recognition task with a virtual agent expressing six basic emotions. Larger age-related differences were expected for virtual agents displaying negative emotions, such as anger, sadness, and fear. In fact, the results indicated that older adults showed a decrease in emotion recognition accuracy for a virtual agent's emotions of anger, fear, and happiness.",2009.0,6.0,18.0,True,"{'url': 'https://europepmc.org/articles/pmc4278580?pdf=render', 'status': None}","{'volume': '53', 'pages': '131 - 135', 'name': 'Proceedings of the Human Factors and Ergonomics Society Annual Meeting'}","{'bibtex': '@Article{Beer2009EmotionRO,\n author = {Jenay M. Beer and A. D. Fisk and W. Rogers},\n journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},\n pages = {131 - 135},\n title = {Emotion Recognition of Virtual Agents Facial Expressions: The Effects of Age and Emotion Intensity},\n volume = {53},\n year = {2009}\n}\n'}","[{'authorId': '1809740', 'name': 'Jenay M. Beer'}, {'authorId': '1689705', 'name': 'A. D. Fisk'}, {'authorId': '145912604', 'name': 'W. Rogers'}]"
1564,859262670d678f20756639228f8a7eae5d65b9b6,Computational Models of Emotion and Cognition,"In this paper, we seek to review the broad landscape of research in computational emotions and cognition. We begin by classifying and organizing an enumeration of recent models and systems and then discuss some of the landmark models from the literature, such as EMA and WASABI. We then discuss open problems with the current state of research. These issues are standardizing criteria for evaluation of models, the complexity and breadth of the domain, and the need to implement a working system which addresses integration with more of the rich history of AI research. We also provide suggestions for future research, particularly standardization to facilitate community collaboration.",2012.0,60.0,53.0,False,,"{'volume': '2', 'pages': '59-76', 'name': ''}","{'bibtex': '@Inproceedings{Lin2012ComputationalMO,\n author = {Jerry Lin and Marc Spraragen and M. Zyda},\n pages = {59-76},\n title = {Computational Models of Emotion and Cognition},\n volume = {2},\n year = {2012}\n}\n'}","[{'authorId': '2110344685', 'name': 'Jerry Lin'}, {'authorId': '3161354', 'name': 'Marc Spraragen'}, {'authorId': '51371300', 'name': 'M. Zyda'}]"
1565,85937bf421aa3c2367d27cf25ed0cbbebb973a4f,Individual differences in empathy among preschoolers: relation to attachment history.,Is the quality of early relationships linked to later emotional development? Children with secure attachments at twelve and eighteen months of age are more empathic and prosocial toward others.,1989.0,17.0,273.0,True,,"{'volume': '44', 'pages': '\n          51-64\n        ', 'name': 'New directions for child development'}","{'bibtex': '@Article{Kestenbaum1989IndividualDI,\n author = {R. Kestenbaum and E. A. Farber and L. Sroufe},\n journal = {New directions for child development},\n pages = {\n          51-64\n        },\n title = {Individual differences in empathy among preschoolers: relation to attachment history.},\n volume = {44},\n year = {1989}\n}\n'}","[{'authorId': '6741969', 'name': 'R. Kestenbaum'}, {'authorId': '123935992', 'name': 'E. A. Farber'}, {'authorId': '5244329', 'name': 'L. Sroufe'}]"
1566,8615d9ed779dfa793d900182e03bbaa5158461f9,Enhanced Experience of Emotional Arousal in Response to Dynamic Facial Expressions,,2007.0,47.0,109.0,False,,"{'volume': '31', 'pages': '119-135', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Sato2007EnhancedEO,\n author = {W. Sato and S. Yoshikawa},\n journal = {Journal of Nonverbal Behavior},\n pages = {119-135},\n title = {Enhanced Experience of Emotional Arousal in Response to Dynamic Facial Expressions},\n volume = {31},\n year = {2007}\n}\n'}","[{'authorId': '46581944', 'name': 'W. Sato'}, {'authorId': '2211534', 'name': 'S. Yoshikawa'}]"
1567,8662a17f17be821cb7a32e7206382e9f1ea6d946,Interpersonal distance and impression formation.,"Summary 
 
Impression formation was examined as a function of interpersonal physical distance in an interview. It was predicted that a confederate would be rated less socially active as the distance between him and the subject increased. The hypothesis was supported by a significant negative linear trend in the composite ratings of friendliness, aggressiveness, extraversion, and dominance A variation in this trend, indicating that confederates seated closest to the subject were seen as less socially active, was explained in terms of compensatory behaviors minimizing the effect of close physical proximity",1970.0,7.0,85.0,False,,"{'volume': '38 2', 'pages': '\n          161-6\n        ', 'name': 'Journal of personality'}","{'bibtex': '@Article{Patterson1970InterpersonalDA,\n author = {M. Patterson and L. Sechrest},\n journal = {Journal of personality},\n pages = {\n          161-6\n        },\n title = {Interpersonal distance and impression formation.},\n volume = {38 2},\n year = {1970}\n}\n'}","[{'authorId': '2521228', 'name': 'M. Patterson'}, {'authorId': '79781700', 'name': 'L. Sechrest'}]"
1568,866a3ee2a8630cf06739f02207d385e93c46744e,The effect of facial animation on a dancing character,"An important part of creating a new and immersive interactive experience for a user is to have the perception that the virtual character is 'paying attention' to the user during the interaction. Such perceived attention could be derived from subtle movements such as the eye glancing towards the user or with larger movements such as turning its face or even its body towards the user. This understanding forms the basis for existing research models.
 Our work describes a user study that evaluates the subject's perception of dancing with a virtual character. We attempt to investigate the relationship and relevance of the facial expressions and eye gazing contact animations on a virtual character which moves vigorously as compared to the idle one (i.e. without facial expression). For this experiment, a virtual character is shown on the screen using stereoscopic projection, while the participant wears shutter glasses at all times during the user study. The observations of the subject about the realism and perceived interactivity of the character is tabulated through the data collected of the perceived opinions during the experiments. Other perceived factors such as the enjoyment of the experience and attractiveness of the virtual character are also considered.",2009.0,14.0,1.0,False,,{'pages': '107-112'},"{'bibtex': '@Inproceedings{Loke2009TheEO,\n author = {M. Loke and K. Tang and G. G. Chua and O. Tan and F. Farbiz},\n pages = {107-112},\n title = {The effect of facial animation on a dancing character},\n year = {2009}\n}\n'}","[{'authorId': '2900145', 'name': 'M. Loke'}, {'authorId': '37704348', 'name': 'K. Tang'}, {'authorId': '1765531', 'name': 'G. G. Chua'}, {'authorId': '21743127', 'name': 'O. Tan'}, {'authorId': '2020444', 'name': 'F. Farbiz'}]"
1569,8674042a8d3e8939d3e3446a15dc3e4202173fa9,"Infants with autism: an investigation of empathy, pretend play, joint attention, and imitation.","Systematic studies of infants with autism have not been previously carried out. Taking advantage of a new prospective screening instrument for autism in infancy (S. Baron-Cohen et al., 1996), the present study found that, compared with developmentally delayed and normally developing children, 20-month-old children with autism were specifically impaired on some aspects of empathy, joint attention, and imitation. Infants with autism failed to use social gaze in the empathy and joint attention tasks. Both the infants with autism and the infants with developmental delay demonstrated functional play, but very few participants in either group produced spontaneous pretend play. In the developmental delay group, but not the autism group, pretend play was shown following prompting. The implications of these findings for developmental accounts of autism and for the early diagnosis of the disorder are discussed.",1997.0,52.0,785.0,False,,"{'volume': '33 5', 'pages': '\n          781-9\n        ', 'name': 'Developmental psychology'}","{'bibtex': '@Article{Charman1997InfantsWA,\n author = {T. Charman and J. Swettenham and S. Baron-Cohen and A. Cox and G. Baird and Auriol Drew},\n journal = {Developmental psychology},\n pages = {\n          781-9\n        },\n title = {Infants with autism: an investigation of empathy, pretend play, joint attention, and imitation.},\n volume = {33 5},\n year = {1997}\n}\n'}","[{'authorId': '3692247', 'name': 'T. Charman'}, {'authorId': '2498385', 'name': 'J. Swettenham'}, {'authorId': '2179290575', 'name': 'S. Baron-Cohen'}, {'authorId': '144851134', 'name': 'A. Cox'}, {'authorId': '2244046', 'name': 'G. Baird'}, {'authorId': '117539417', 'name': 'Auriol Drew'}]"
1570,86872ec55179b6cc03764b5af20529a5367ec6a2,Design and implementation of GEmA: A generic emotional agent,,2011.0,48.0,29.0,False,,"{'volume': '38', 'pages': '2640-2652', 'name': 'Expert Syst. Appl.'}","{'bibtex': '@Article{Kazemifard2011DesignAI,\n author = {M. Kazemifard and N. Ghasem-Aghaee and T. Ören},\n journal = {Expert Syst. Appl.},\n pages = {2640-2652},\n title = {Design and implementation of GEmA: A generic emotional agent},\n volume = {38},\n year = {2011}\n}\n'}","[{'authorId': '3136443', 'name': 'M. Kazemifard'}, {'authorId': '9312093', 'name': 'N. Ghasem-Aghaee'}, {'authorId': '2064368', 'name': 'T. Ören'}]"
1572,868a88d9140b55cc67d948b01b391b1a0c6d75b0,Social Presence as a Moderator of the Effect of Agent Behavior on Emotional Experience in Social Interactions in Virtual Reality,"Background: Exposure therapy involves exposure to feared stimuli and is considered to be the gold-standard treatment for anxiety disorders. While its application in Virtual Reality (VR) has been very successful for phobic disorders, the effects of exposure to virtual social stimuli in Social Anxiety Disorder are heterogeneous. This difference has been linked to demands on realism and presence, particularly social presence, as a pre-requisite in evoking emotional experiences in virtual social interactions. So far, however, the influence of social presence on emotional experience in social interactions with virtual agents remains unknown. Objective: We investigated the relationship between realism and social presence and the moderating effect of social presence on the relationship between agent behavior and experienced emotions in virtual social interaction. Methods: Healthy participants (N = 51) faced virtual agents showing supportive and dismissive behaviors in two virtual environments (short interactions and oral presentations). At first, participants performed five blocks of short one-on-one interactions with virtual agents (two male and two female agents per block). Secondly, participants gave five presentations in front of an audience of 16 agents. In each scenario, agent behavior was a within subjects factor, resulting in one block of neutral, two blocks of negative, and two blocks of positive agent behavior. Ratings of agent behavior (valence and realism), experience (valence and arousal), and presence (physical and social) were collected after every block. Moderator effects were investigated using mixed linear models with random intercepts. Correlations were analyzed via repeated measures correlations. Results: Ratings of valence of agent behaviors showed reliable relationships with experienced valence and less reliable relationships with experienced arousal. These relationships were moderated by social presence in the presentation scenario. Results for the interaction scenario were weaker but potentially promising for experimental studies. Variations in social presence and realism over time were correlated but social presence proved a more reliable moderator. Conclusion: Our findings emphasize the role of social presence for emotional experience in response to specific agent behaviors in virtual social interactions. While these findings should be replicated with experimental designs and in clinical samples, variability in social presence might account for heterogeneity in efficacy of virtual exposure to treat social anxiety disorder.",2021.0,39.0,3.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frvir.2021.741138/pdf', 'status': 'GOLD'}",{'volume': '2'},"{'bibtex': '@Article{Pfaller2021SocialPA,\n author = {Michael Pfaller and Leon O. H. Kroczek and B. Lange and Raymund Fülöp and Mathias Müller and A. Mühlberger},\n booktitle = {Frontiers in Virtual Reality},\n title = {Social Presence as a Moderator of the Effect of Agent Behavior on Emotional Experience in Social Interactions in Virtual Reality},\n volume = {2},\n year = {2021}\n}\n'}","[{'authorId': '2053795228', 'name': 'Michael Pfaller'}, {'authorId': '30692915', 'name': 'Leon O. H. Kroczek'}, {'authorId': '1471458840', 'name': 'B. Lange'}, {'authorId': '1921958', 'name': 'Raymund Fülöp'}, {'authorId': '2116236276', 'name': 'Mathias Müller'}, {'authorId': '1684604', 'name': 'A. Mühlberger'}]"
1573,868cff83a540f79c619f08148693493c931903c4,The Design of Web Games for Helping Young High-Functioning Autistics in Learning How to Manage Money,,2018.0,20.0,21.0,False,,"{'volume': '23', 'pages': '1735-1748', 'name': 'Mobile Networks and Applications'}","{'bibtex': '@Article{Caria2018TheDO,\n author = {Serena Caria and F. Paternò and C. Santoro and Valentina Semucci},\n journal = {Mobile Networks and Applications},\n pages = {1735-1748},\n title = {The Design of Web Games for Helping Young High-Functioning Autistics in Learning How to Manage Money},\n volume = {23},\n year = {2018}\n}\n'}","[{'authorId': '35195868', 'name': 'Serena Caria'}, {'authorId': '1793926', 'name': 'F. Paternò'}, {'authorId': '144355788', 'name': 'C. Santoro'}, {'authorId': '36571126', 'name': 'Valentina Semucci'}]"
1574,868fca5d103fd5901926005a2282a8e4916571b2,Simulation of Virtual Human's Mental State in Behavior Animation,,2007.0,11.0,6.0,False,,{'pages': '284-291'},"{'bibtex': ""@Inproceedings{Liu2007SimulationOV,\n author = {Z. Liu},\n pages = {284-291},\n title = {Simulation of Virtual Human's Mental State in Behavior Animation},\n year = {2007}\n}\n""}","[{'authorId': '46270580', 'name': 'Z. Liu'}]"
1575,86a10ae36ecb3b4fac560a5b03fc6ca6cf7ef7e9,Social Story™ Efficacy With a Child With Autism Spectrum Disorder and Moderate Intellectual Disability,"Social Stories™ have gained Wide acceptance as an intervention for children With autism spectrum disorders (ASD), yet extant research provides little empirical evidence in support of their efficacy. This study examines the use of Social Stories to target repetitive tapping behavior displayed by a child With ASD, moderate intellectual disability, and associated language impairment. Over an extended period there Was evidence of a decrease in the target behavior. Further, this decrease Was associated With increased comprehension of the Social Story. The findings suggest that it is appropriate to consider language skills When evaluating the suitability of this intervention for students With moderate intellectual disabilities and to monitor comprehension.",2007.0,40.0,61.0,False,,"{'volume': '22', 'pages': '173 - 181', 'name': 'Focus on Autism and Other Developmental Disabilities'}","{'bibtex': '@Article{Reynhout2007SocialSE,\n author = {Georgina Reynhout and M. Carter},\n journal = {Focus on Autism and Other Developmental Disabilities},\n pages = {173 - 181},\n title = {Social Story™ Efficacy With a Child With Autism Spectrum Disorder and Moderate Intellectual Disability},\n volume = {22},\n year = {2007}\n}\n'}","[{'authorId': '5446795', 'name': 'Georgina Reynhout'}, {'authorId': '144951154', 'name': 'M. Carter'}]"
1576,86e18f3a7f9311827d96970474d82ac92a017c15,Trusting Digital Chameleons: The Effect of Mimicry by a Virtual Social Agent on User Trust,,2013.0,26.0,50.0,False,,{'pages': '234-245'},"{'bibtex': '@Inproceedings{Verberne2013TrustingDC,\n author = {F. Verberne and Jaap Ham and Aditya Ponnada and C. Midden},\n pages = {234-245},\n title = {Trusting Digital Chameleons: The Effect of Mimicry by a Virtual Social Agent on User Trust},\n year = {2013}\n}\n'}","[{'authorId': '2327911', 'name': 'F. Verberne'}, {'authorId': '145960497', 'name': 'Jaap Ham'}, {'authorId': '2064022036', 'name': 'Aditya Ponnada'}, {'authorId': '3026039', 'name': 'C. Midden'}]"
1577,86f81c8a46a84cd969ed80e88395ba5de709794f,[Nonverbal communication].,"Whether you’re aware of it or not, when you interact with others, you’re continuously giving and receiving wordless signals. All of your nonverbal behaviors—the gestures you make, your posture, your tone of voice, how much eye contact you make—send strong messages. They can put people at ease, build trust, and draw others towards you, or they can offend, confuse, and undermine what you’re trying to convey. These messages don’t stop when you stop speaking either. Even when you’re silent, you’re still communicating nonverbally.",1990.0,10.0,1161.0,True,"{'url': 'http://essuir.sumdu.edu.ua/bitstream/123456789/16021/1/34.pdf', 'status': None}","{'volume': '43 10', 'pages': '\n          751-4\n        ', 'name': 'Deutsche Krankenpflegezeitschrift'}","{'bibtex': '@Article{Burgoon1990NonverbalC,\n author = {J. Burgoon},\n journal = {Deutsche Krankenpflegezeitschrift},\n pages = {\n          751-4\n        },\n title = {[Nonverbal communication].},\n volume = {43 10},\n year = {1990}\n}\n'}","[{'authorId': '2896960', 'name': 'J. Burgoon'}]"
1579,870b8904dadb6a2f40290dddddd5c989f3656e5e,Subjective cognitive decline: preclinical manifestation of Alzheimer’s disease,,2018.0,66.0,52.0,False,,"{'volume': '40', 'pages': '41-49', 'name': 'Neurological Sciences'}","{'bibtex': '@Article{Lin2018SubjectiveCD,\n author = {Yan Lin and Pei-yan Shan and Wenjing Jiang and Can Sheng and Lin Ma},\n journal = {Neurological Sciences},\n pages = {41-49},\n title = {Subjective cognitive decline: preclinical manifestation of Alzheimer’s disease},\n volume = {40},\n year = {2018}\n}\n'}","[{'authorId': '2149200216', 'name': 'Yan Lin'}, {'authorId': '8404908', 'name': 'Pei-yan Shan'}, {'authorId': '49408848', 'name': 'Wenjing Jiang'}, {'authorId': '38692969', 'name': 'Can Sheng'}, {'authorId': '2115502649', 'name': 'Lin Ma'}]"
1580,875aaba134119e8118ff735f092db3266f5f97b0,The Interpersonal Effects of Anger and Happiness on Negotiation Behavior and Outcomes,"How do emotions affect the opponent's behavior in a negotiation? Two experiments explored the interpersonal effects of anger and happiness. In Study 1 participants received information about the emotion (anger vs. happiness vs. no emotion) of their (fake) opponent. Participants with an angry opponent made lower demands and larger concessions than did participants with a happy opponent, those with a non-emotional opponent falling in between. Furthermore, the opponent's emotions induced similar emotions in the participants (i.e., ""emotional contagion""), and participants with a happy opponent evaluated the opponent and the negotiation more favorably than did participants with an angry opponent. In Study 2 participants received information about both the opponent's experienced and communicated emotions. As predicted, angry communications (unlike happy ones) induced fear and thereby mitigated the effect of the opponent's experienced emotion.",2003.0,57.0,64.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Kleef2003TheIE,\n author = {G. A. Kleef and C. Dreu and A. Manstead},\n title = {The Interpersonal Effects of Anger and Happiness on Negotiation Behavior and Outcomes},\n year = {2003}\n}\n'}","[{'authorId': '74691001', 'name': 'G. A. Kleef'}, {'authorId': '2893927', 'name': 'C. Dreu'}, {'authorId': '92736978', 'name': 'A. Manstead'}]"
1581,87cacc03f51582e64a6d0e3d7d068230f0e03a80,Affect-biased attention as emotion regulation,,2012.0,72.0,284.0,True,"{'url': 'https://osf.io/d7prg/download', 'status': None}","{'volume': '16', 'pages': '365-372', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Todd2012AffectbiasedAA,\n author = {R. Todd and William A. Cunningham and A. Anderson and Evan Thompson},\n journal = {Trends in Cognitive Sciences},\n pages = {365-372},\n title = {Affect-biased attention as emotion regulation},\n volume = {16},\n year = {2012}\n}\n'}","[{'authorId': '38124822', 'name': 'R. Todd'}, {'authorId': '2792268', 'name': 'William A. Cunningham'}, {'authorId': '5040426', 'name': 'A. Anderson'}, {'authorId': '48529647', 'name': 'Evan Thompson'}]"
1582,87d0fdb5f4df39ebf37a4ec12625e41b8e5e402a,Gender and Culture Differences in Touching Behavior,"The authors used gender and culture to examine the theory that touching behavior is an expression of dominance. Participants were 120 men and women from Italy, the Czech Republic, and the United States. The authors examined both hand touches and nonhand touches. For hand touches, there was a significant gender-by-culture interaction in that Czech men as a group touched more than any of the other groups. For nonhand touches, Czech and Italian women and Italian men as groups touched significantly more than any of the other groups. Taken in cultural context, these results seem to support the dominance theory for touches with the hand but not for nonhand touches. The authors discussed implications and future directions.",2004.0,34.0,87.0,False,,"{'volume': '144', 'pages': '49 - 62', 'name': 'The Journal of Social Psychology'}","{'bibtex': '@Article{DiBiase2004GenderAC,\n author = {Rosemarie DiBiase and Jaime Gunnoe},\n journal = {The Journal of Social Psychology},\n pages = {49 - 62},\n title = {Gender and Culture Differences in Touching Behavior},\n volume = {144},\n year = {2004}\n}\n'}","[{'authorId': '4634868', 'name': 'Rosemarie DiBiase'}, {'authorId': '2086417771', 'name': 'Jaime Gunnoe'}]"
1583,87e3b99195442cb37b3807c4d097b886b46a1458,Establish Trust and Express Attitude for a Non-Humanoid Robot,"In recent years, there has been an increasing interest in designing social robots to interact with people to provide therapy and companionship. Most social robots currently being used are light-weight and much smaller in size compared to people. In this work, we investigate designing interactions for larger and more physically capable robots as they have more potential to assist people physically. A modified version of Baxter robot was used, by sitting Baxter on top of an electronic wheelchair. Two experiments were designed for studying the role of facial expressions and body movements in establishing trust with the user and for expressing attitudes. Our results suggest that the robot is capable of expressing fine and distinguishable attitudes (proud vs. relaxed) using its body language, and the coupling between body movements and speech is essential for the robot to be viewed as a person.",2016.0,19.0,4.0,False,,"{'volume': '', 'name': 'Cognitive Science'}","{'bibtex': '@Article{Si2016EstablishTA,\n author = {Mei Si and Joseph Dean McDaniel},\n journal = {Cognitive Science},\n title = {Establish Trust and Express Attitude for a Non-Humanoid Robot},\n year = {2016}\n}\n'}","[{'authorId': '33432486', 'name': 'Mei Si'}, {'authorId': '2068949697', 'name': 'Joseph Dean McDaniel'}]"
1584,88064f0a67015777e1021862a1bf2e49613ebfb7,Fusion of facial expressions and EEG for implicit affective tagging,,2013.0,49.0,196.0,False,,"{'volume': '31', 'pages': '164-174', 'name': 'Image Vis. Comput.'}","{'bibtex': '@Article{Koelstra2013FusionOF,\n author = {Sander Koelstra and I. Patras},\n journal = {Image Vis. Comput.},\n pages = {164-174},\n title = {Fusion of facial expressions and EEG for implicit affective tagging},\n volume = {31},\n year = {2013}\n}\n'}","[{'authorId': '2079441', 'name': 'Sander Koelstra'}, {'authorId': '50058816', 'name': 'I. Patras'}]"
1585,88420722e8afff17c970b361944476249bafb402,Verbal or Visual? How Information is Distributed across Speech and Gesture in Spatial Dialog,"In spatial dialog like in direction giving humans make frequent use of speechaccompanying gestures. Some gestures 
convey largely the same information as speech while others complement speech. This paper reports a study on how speakers distribute meaning across speech and gesture, 
and depending on what factors. Utterance meaning and the wider dialog context were tested by statistically analyzing 
a corpus of direction-giving dialogs. Problems of speech production (as indicated by discourse markers and disfluencies), the communicative goals, and the information 
status were found to be influential, while feedback signals by the addressee do not have any influence.",2006.0,20.0,38.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bergmann2006VerbalOV,\n author = {K. Bergmann and S. Kopp},\n title = {Verbal or Visual? How Information is Distributed across Speech and Gesture in Spatial Dialog},\n year = {2006}\n}\n'}","[{'authorId': '2025591', 'name': 'K. Bergmann'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
1586,8867f29ae3275d2fa6448cd35bf2e705e7cfcd6b,Eye movement assessment of selective attentional capture by emotional pictures.,"The eye-tracking method was used to assess attentional orienting to and engagement on emotional visual scenes. In Experiment 1, unpleasant, neutral, or pleasant target pictures were presented simultaneously with neutral control pictures in peripheral vision under instruction to compare pleasantness of the pictures. The probability of first fixating an emotional picture, and the frequency of subsequent fixations, were greater than those for neutral pictures. In Experiment 2, participants were instructed to avoid looking at the emotional pictures, but these were still more likely to be fixated first and gazed longer during the first-pass viewing than neutral pictures. Low-level visual features cannot explain the results. It is concluded that overt visual attention is captured by both unpleasant and pleasant emotional content.",2006.0,49.0,413.0,False,,"{'volume': '6 2', 'pages': '\n          257-68\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Nummenmaa2006EyeMA,\n author = {L. Nummenmaa and J. Hyönä and M. Calvo},\n journal = {Emotion},\n pages = {\n          257-68\n        },\n title = {Eye movement assessment of selective attentional capture by emotional pictures.},\n volume = {6 2},\n year = {2006}\n}\n'}","[{'authorId': '2036051', 'name': 'L. Nummenmaa'}, {'authorId': '2464572', 'name': 'J. Hyönä'}, {'authorId': '144866673', 'name': 'M. Calvo'}]"
1587,887890ffc99081039f49dd7a06dff33442ea3722,Conceptualizing Empathy in Cognitive Behaviour Therapy: Making the Implicit Explicit,"Although empathy has been shown to play an important role in therapeutic outcomes for cognitive-behaviour therapy (CBT) as for other therapies, there has been remarkably little discussion or research on empathy in the CBT literature. This paper seeks to make the implicit explicit: to conceptualize the nature and function of therapeutic empathy within CBT. It proposes a model of therapeutic empathy with four key elements: Empathic attunement, Empathic attitude/stance, Empathic communication, and Empathy knowledge. The model points to the importance of the ""person of the therapist"" and self-reflection in the development of therapeutic empathy; and describes how the specific contribution of CBT knowledge and skills can help therapists understand clients' moment-to-moment experiences and, if used sensitively, can enhance the empathic process. The paper indicates how therapists may use different modes of empathic processing to process experience under different circumstances, and how empathy fulfils a variety of functions within CBT. This conceptualization has considerable implications for therapists, trainers, supervisors and researchers including: more accurate identification and targeted strategies to address therapeutic empathy problems; recognition of the value of personal experiential work and self-reflection in empathy training; increased understanding of the functions of empathy; and development of finer-grained clinical and research measures.",2007.0,54.0,80.0,False,,"{'volume': '35', 'pages': '591-612', 'name': 'Behavioural and Cognitive Psychotherapy'}","{'bibtex': '@Article{Thwaites2007ConceptualizingEI,\n author = {R. Thwaites and J. Bennett-Levy},\n journal = {Behavioural and Cognitive Psychotherapy},\n pages = {591-612},\n title = {Conceptualizing Empathy in Cognitive Behaviour Therapy: Making the Implicit Explicit},\n volume = {35},\n year = {2007}\n}\n'}","[{'authorId': '48906201', 'name': 'R. Thwaites'}, {'authorId': '1402128778', 'name': 'J. Bennett-Levy'}]"
1588,889ce7b8ee0e11d8729e0bd010eaa60275553b46,To Affect Theory,,2023.0,20.0,38.0,True,"{'url': 'http://capaciousjournal.com/cms/wp-content/uploads/2023/06/ingraham-to-affect-theory.pdf', 'status': None}",{'name': 'Capacious: Journal of Emerging Affect Inquiry'},"{'bibtex': '@Article{Ingraham2023ToAT,\n author = {Chris Ingraham},\n journal = {Capacious: Journal of Emerging Affect Inquiry},\n title = {To Affect Theory},\n year = {2023}\n}\n'}","[{'authorId': '39910563', 'name': 'Chris Ingraham'}]"
1589,88daafe9bffb7257d7a9675b72dccb06ed634831,"Put your best face forward: anthropomorphic agents, e-commerce consumers, and the law","Highly believable anthropomorphic agents endanger electronic consumers. Because of concerning tendencies in human-agent interaction arising from agents’ anthropomorphic qualities, consumers may unwittingly treat agents as competent, trustworthy, living counterparts. This paper concludes that developers must focus agent design on consumer welfare, not technical virtuosity, if legal and ethical perils are to be avoided.",2000.0,31.0,43.0,True,,{'pages': '435-442'},"{'bibtex': '@Inproceedings{Heckman2000PutYB,\n author = {Carey Heckman and J. Wobbrock},\n pages = {435-442},\n title = {Put your best face forward: anthropomorphic agents, e-commerce consumers, and the law},\n year = {2000}\n}\n'}","[{'authorId': '145950072', 'name': 'Carey Heckman'}, {'authorId': '1796045', 'name': 'J. Wobbrock'}]"
1590,88eda1b2fd61036c2ca682d4abc34e700ec8ba7e,Framing Factors: The Importance of Context and the Individual in Understanding Trust in Human-Robot Interaction,"In this paper we explore the factors and methodologies from a range of disciplines used to investigate trust in human-robot interaction (HRI). Our investigation highlights a growing field, which recognises the importance of understanding the deployment of robots in real-world settings, but where a lack of common definitions and experimental clarity impedes the development of a comprehensive framework for 
investigation. As a result, we propose a bottom-up approach that emphasises context and user perspective as the foundation for future investigations into trust in HRI.",2015.0,40.0,48.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cameron2015FramingFT,\n author = {David Cameron and J. Aitken and Emily C. Collins and L. Boorman and A. Chua and Samuel Fernando and O. McAree and U. M. Hernandez and J. Law},\n title = {Framing Factors: The Importance of Context and the Individual in Understanding Trust in Human-Robot Interaction},\n year = {2015}\n}\n'}","[{'authorId': '145971457', 'name': 'David Cameron'}, {'authorId': '40035385', 'name': 'J. Aitken'}, {'authorId': '2082714', 'name': 'Emily C. Collins'}, {'authorId': '2147696', 'name': 'L. Boorman'}, {'authorId': '35321396', 'name': 'A. Chua'}, {'authorId': '2164679', 'name': 'Samuel Fernando'}, {'authorId': '2226533', 'name': 'O. McAree'}, {'authorId': '2071395783', 'name': 'U. M. Hernandez'}, {'authorId': '145887557', 'name': 'J. Law'}]"
1591,88f08edabf757803c4b47b072bce56c6bdabb269,The detection of contingency and animacy from simple animations in the human brain.,"Contingencies between objects and people can be mechanical or intentional-social in nature. In this fMRI study we used simplified stimuli to investigate brain regions involved in the detection of mechanical and intentional contingencies. Using a factorial design we manipulated the 'animacy' and 'contingency' of stimulus movement, and the subject's attention to the contingencies. The detection of mechanical contingency between shapes whose movement was inanimate engaged the middle temporal gyrus and right intraparietal sulcus. The detection of intentional contingency between shapes whose movement was animate activated superior parietal networks bilaterally. These activations were unaffected by attention to contingency. Additional regions, the right middle frontal gyrus and left superior temporal sulcus, became activated by the animate-contingent stimuli when subjects specifically attended to the contingent nature of the stimuli. Our results help to clarify neural networks previously associated with 'theory of mind' and agency detection. In particular, the results suggest that low-level perception of agency in terms of objects reacting to other objects at a distance is processed by parietal networks. In contrast, the activation of brain regions traditionally associated with theory of mind tasks appears to require attention to be directed towards agency and contingency.",2003.0,34.0,245.0,True,"{'url': 'https://academic.oup.com/cercor/article-pdf/13/8/837/9752533/1300837.pdf', 'status': None}","{'volume': '13 8', 'pages': '\n          837-44\n        ', 'name': 'Cerebral cortex'}","{'bibtex': '@Article{Blakemore2003TheDO,\n author = {Sarah-Jayne Blakemore and Pascal Boyer and M. Pachot-Clouard and Andrew N. Meltzoff and Christoph Segebarth and Jean Decety},\n journal = {Cerebral cortex},\n pages = {\n          837-44\n        },\n title = {The detection of contingency and animacy from simple animations in the human brain.},\n volume = {13 8},\n year = {2003}\n}\n'}","[{'authorId': '2255585142', 'name': 'Sarah-Jayne Blakemore'}, {'authorId': '2255466533', 'name': 'Pascal Boyer'}, {'authorId': '1402207980', 'name': 'M. Pachot-Clouard'}, {'authorId': '2255611758', 'name': 'Andrew N. Meltzoff'}, {'authorId': '2255341971', 'name': 'Christoph Segebarth'}, {'authorId': '2243749813', 'name': 'Jean Decety'}]"
1592,890b82514abb9be893fd6054d3520956449b612e,What the face reveals : basic and applied studies of spontaneous expression using the facial action coding system (FACS),"Foreword Introduction The study of spontaneous facial expression in psychology I: BASIC RESEARCH ON EMOTION 1. Is the startle reaction an emotion? 2. The asymmetry of facial actions is inconsisten with models of hemispheric specialization 3. Coherence between expressive and experiential systmes in emotion 4. Will the real relationship between facial expression and affective experience please stand up: The case of exhilaration 5. Extraversion, alcohol, and enjoyment 6. Signs of appeasement: Evidence for the distinct displays of embarrassment, amusement, and shame 7. Genuine, suppressed, and faked facial behavior during exacerbation of chronic low back pain 8. The consistency of facial expressions of pain: a comparison across modalities 9. Smiles when lying 10. Behavioral markers and recognizability of the smile of enjoyment 11. Components and recognition of facial expression in the communication of emotion by actors 12. Differentiating emotion elicited and deliberate emotional facial expressions 13. Japanese and American infants' responses to arm restraint 14. Differential facial responses to four basic tests in newborns II: APPLIED RESEARCH 15. Facial expressions in affective disorders 16. Emotional experience and epxression in schizophrenia and depression 17. Interaction regulations used by schizophrenic and psychosomatic patients: Studies on facial behavior in dyadic interactions 18. Nonverbal expression of psychological states in psychiatric patients 19. Depression and suicide faces 20. Prototypical affective microsequences in psychotherapeutic interaction 21. Facial expressions of emotion and psychopathology in adolescent boys 22. Type A behavior pattern: Facial behavior and speech components Conclusion What we have learned by measuring the face Index",2005.0,0.0,1970.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman2005WhatTF,\n author = {P. Ekman and E. Rosenberg},\n title = {What the face reveals : basic and applied studies of spontaneous expression using the facial action coding system (FACS)},\n year = {2005}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '4935859', 'name': 'E. Rosenberg'}]"
1596,892c911ca68f5b4bad59cde7eeb6c738ec6c4586,"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English","The RAVDESS is a validated multimodal database of emotional speech and song. The database is gender balanced consisting of 24 professional actors, vocalizing lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. Each expression is produced at two levels of emotional intensity, with an additional neutral expression. All conditions are available in face-and-voice, face-only, and voice-only formats. The set of 7356 recordings were each rated 10 times on emotional validity, intensity, and genuineness. Ratings were provided by 247 individuals who were characteristic of untrained research participants from North America. A further set of 72 participants provided test-retest data. High levels of emotional validity and test-retest intrarater reliability were reported. Corrected accuracy and composite ""goodness"" measures are presented to assist researchers in the selection of stimuli. All recordings are made freely available under a Creative Commons license and can be downloaded at https://doi.org/10.5281/zenodo.1188976.",2018.0,198.0,1056.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0196391&type=printable', 'status': None}","{'volume': '13', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Livingstone2018TheRA,\n author = {S. R. Livingstone and F. Russo},\n journal = {PLoS ONE},\n title = {The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},\n volume = {13},\n year = {2018}\n}\n'}","[{'authorId': '50072876', 'name': 'S. R. Livingstone'}, {'authorId': '2940438', 'name': 'F. Russo'}]"
1597,89583fc4293d6b7bc3b8460833df7e90440d27ab,Empathic Responses of Behavioral-Synchronization in Human-Agent Interaction,": Artificial entities, such as virtual agents, have become more pervasive. Their long-term presence among humans requires the virtual agent’s ability to express appropriate emotions to elicit the necessary empathy from the users. Affective empathy involves behavioral mimicry, a synchronized co-movement between dyadic pairs. However, the characteristics of such synchrony between humans and virtual agents remain unclear in empathic interactions. Our study evaluates the participant’s behavioral synchronization when a virtual agent exhibits an emotional expression congruent with the emotional context through facial expressions, behavioral gestures, and voice. Participants viewed an emotion-eliciting video stimulus (negative or positive) with a virtual agent. The participants then conversed with the virtual agent about the video, such as how the participant felt about the content. The virtual agent expressed emotions congruent with the video or neutral emotion during the dialog. The participants’ facial expressions, such as the facial expressive intensity and facial muscle movement, were measured during the dialog using a camera. The results showed the participants’ significant behavioral synchronization (i.e., cosine similarity ≥ .05) in both the negative and positive emotion conditions, evident in the participant’s facial mimicry with the virtual agent. Additionally, the participants’ facial expressions, both movement and intensity, were significantly stronger in the emotional virtual agent than in the neutral virtual agent. In particular, we found that the facial muscle intensity of AU45 (Blink) is an effective index to assess the participant’s synchronization that differs by the individual’s empathic capability (low, mid, high). Based on the results, we suggest an appraisal criterion to provide empirical conditions to validate empathic interaction based on the facial expression measures.",2022.0,78.0,0.0,True,"{'url': 'https://www.techscience.com/cmc/v71n2/45877/pdf', 'status': 'GOLD'}","{'name': 'Computers, Materials & Continua'}","{'bibtex': '@Article{Park2022EmpathicRO,\n author = {Sung Park and Seongeon Park and Mincheol Whang},\n booktitle = {Computers Materials & Continua},\n journal = {Computers, Materials & Continua},\n title = {Empathic Responses of Behavioral-Synchronization in Human-Agent Interaction},\n year = {2022}\n}\n'}","[{'authorId': '2007043751', 'name': 'Sung Park'}, {'authorId': '2149246721', 'name': 'Seongeon Park'}, {'authorId': '38593989', 'name': 'Mincheol Whang'}]"
1598,8958ae7e240a6ce932c44ce5b67a14047fe90702,Virtual reality in the treatment of persecutory delusions: randomised controlled experimental study testing how to reduce delusional conviction,"Background Persecutory delusions may be unfounded threat beliefs maintained by safety-seeking behaviours that prevent disconfirmatory evidence being successfully processed. Use of virtual reality could facilitate new learning. Aims To test the hypothesis that enabling patients to test the threat predictions of persecutory delusions in virtual reality social environments with the dropping of safety-seeking behaviours (virtual reality cognitive therapy) would lead to greater delusion reduction than exposure alone (virtual reality exposure). Method Conviction in delusions and distress in a real-world situation were assessed in 30 patients with persecutory delusions. Patients were then randomised to virtual reality cognitive therapy or virtual reality exposure, both with 30 min in graded virtual reality social environments. Delusion conviction and real-world distress were then reassessed. Results In comparison with exposure, virtual reality cognitive therapy led to large reductions in delusional conviction (reduction 22.0%, P = 0.024, Cohen's d = 1.3) and real-world distress (reduction 19.6%, P = 0.020, Cohen's d = 0.8). Conclusion Cognitive therapy using virtual reality could prove highly effective in treating delusions.",2016.0,24.0,189.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7898DDD7E2B2343200EB9AE7CDDFD49B/S0007125000244371a.pdf/div-class-title-virtual-reality-in-the-treatment-of-persecutory-delusions-randomised-controlled-experimental-study-testing-how-to-reduce-delusional-conviction-div.pdf', 'status': None}","{'volume': '209', 'pages': '62 - 67', 'name': 'The British Journal of Psychiatry'}","{'bibtex': '@Article{Freeman2016VirtualRI,\n author = {D. Freeman and Jonathan Bradley and Angus Antley and Emilie Bourke and Natalie DeWeever and Nicole Evans and Emma Černis and Bryony Sheaves and Felicity Waite and G. Dunn and M. Slater and D. Clark},\n journal = {The British Journal of Psychiatry},\n pages = {62 - 67},\n title = {Virtual reality in the treatment of persecutory delusions: randomised controlled experimental study testing how to reduce delusional conviction},\n volume = {209},\n year = {2016}\n}\n'}","[{'authorId': '145331574', 'name': 'D. Freeman'}, {'authorId': '2086592052', 'name': 'Jonathan Bradley'}, {'authorId': '1705895', 'name': 'Angus Antley'}, {'authorId': '48176898', 'name': 'Emilie Bourke'}, {'authorId': '3558924', 'name': 'Natalie DeWeever'}, {'authorId': '46682899', 'name': 'Nicole Evans'}, {'authorId': '5152415', 'name': 'Emma Černis'}, {'authorId': '1883625', 'name': 'Bryony Sheaves'}, {'authorId': '144328468', 'name': 'Felicity Waite'}, {'authorId': '145301048', 'name': 'G. Dunn'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '144809882', 'name': 'D. Clark'}]"
1600,89624aae669fecb85fa7fb69a7e00d55c27428ff,Cognitive processes in the development of TOL performance,,2006.0,70.0,145.0,False,,"{'volume': '44', 'pages': '2259-2269', 'name': 'Neuropsychologia'}","{'bibtex': '@Article{Asato2006CognitivePI,\n author = {Miya R. Asato and J. Sweeney and B. Luna},\n journal = {Neuropsychologia},\n pages = {2259-2269},\n title = {Cognitive processes in the development of TOL performance},\n volume = {44},\n year = {2006}\n}\n'}","[{'authorId': '39944436', 'name': 'Miya R. Asato'}, {'authorId': '143606531', 'name': 'J. Sweeney'}, {'authorId': '143953194', 'name': 'B. Luna'}]"
1601,897fbf837c26f54bfbe9c0c0abb788cda3b9e14a,"Trust in information sources: seeking information from people, documents, and virtual agents",,2002.0,54.0,164.0,False,,"{'volume': '14', 'pages': '575-599', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Hertzum2002TrustII,\n author = {M. Hertzum and Hans H. K. Andersen and V. Andersen and C. B. Hansen},\n journal = {Interact. Comput.},\n pages = {575-599},\n title = {Trust in information sources: seeking information from people, documents, and virtual agents},\n volume = {14},\n year = {2002}\n}\n'}","[{'authorId': '1786701', 'name': 'M. Hertzum'}, {'authorId': '1699653', 'name': 'Hans H. K. Andersen'}, {'authorId': '143924209', 'name': 'V. Andersen'}, {'authorId': '2052328887', 'name': 'C. B. Hansen'}]"
1602,89a305ef13153a47de5879e28a5f42f6850660f1,Interpersonal emotion regulation in Asperger's syndrome and borderline personality disorder,"OBJECTIVES
Interpersonal emotion regulation (ER) plays a significant role in how individuals meet others' emotional needs and shape social interactions, as it is key to initiating and maintaining high-quality social relationships. Given that individuals with borderline personality disorder (BPD) or Asperger's syndrome (AS) exhibit problems in social interactions, the aim of this study was to examine their use of different interpersonal ER strategies compared to normative control participants.


METHODS
Thirty individuals with AS, 30 with BPD, and 60 age-, gender-, and education-matched control participants completed a battery of measures to assess interpersonal ER, which assessed to what extent participants tended to engage in interpersonal affect improvement and worsening and to what extent they used different strategies. Before completing those measures, all groups were screened for disorders of Axis I and Axis II with the Structured Clinical Interview for DSM-IV Axis I and Axis II Disorders.


RESULTS
Compared to controls, individuals with AS and with BPD engaged less in affect improvement. No differences were found for affect worsening. Individuals with AS reported to use less adaptive (attention deployment, cognitive change) and more maladaptive (expressive suppression) interpersonal ER strategies, compared to individuals with BPD and control participants who did not differ from each other.


CONCLUSIONS
The obtained results suggest the need to develop tailored ER interventions for each of the clinical groups studied. Furthermore, they highlight the need to study further potential differences in intrapersonal and interpersonal ER in clinical populations.


PRACTITIONER POINTS
Individuals with Asperger's syndrome (AS) and borderline personality disorder (BPD) engaged significantly less than healthy controls in interpersonal affect improvement. Individuals with BPD did not differ from healthy controls in the use of interpersonal strategies. Individuals with AS reported to use more maladaptive and less adaptive strategies than BPD individuals and healthy controls. Understanding differences in interpersonal emotion regulation in individuals with AS and with BPD and normative controls might help practitioners develop better interventions.",2017.0,45.0,17.0,False,,"{'volume': '56', 'pages': '103–113', 'name': 'British Journal of Clinical Psychology'}","{'bibtex': ""@Article{López-Pérez2017InterpersonalER,\n author = {B. López-Pérez and Tamara Ambrona and M. Gummerum},\n journal = {British Journal of Clinical Psychology},\n pages = {103–113},\n title = {Interpersonal emotion regulation in Asperger's syndrome and borderline personality disorder},\n volume = {56},\n year = {2017}\n}\n""}","[{'authorId': '1402994497', 'name': 'B. López-Pérez'}, {'authorId': '6384433', 'name': 'Tamara Ambrona'}, {'authorId': '4734400', 'name': 'M. Gummerum'}]"
1603,89a4c3a2e961e7690a185555d742042d33dea2a2,Observers' physiological measures in response to videos can be used to detect genuine smiles,,2019.0,55.0,9.0,False,,"{'volume': '122', 'pages': '232-241', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': ""@Article{Hossain2019ObserversPM,\n author = {Md. Zakir Hossain and Tom Gedeon},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {232-241},\n title = {Observers' physiological measures in response to videos can be used to detect genuine smiles},\n volume = {122},\n year = {2019}\n}\n""}","[{'authorId': '144063214', 'name': 'Md. Zakir Hossain'}, {'authorId': '27011207', 'name': 'Tom Gedeon'}]"
1604,8a3097249401d91b5cc59eb5ea9e9e631e24fd69,The Neuroscience of Psychotherapy: Healing the Social Brain,"저자 Louis Cozolino가 ‘Building and Rebuilding the Human Brain’이라는 부제를 가지고 처음 이 책을 출간했을 때, 많은 이들이 신경과학의 시선으로 정신치료를 설명하는 이 책의 등장에 많은 찬사를 보냈다. 사실 처음 신경과학이 대 두될 때 극단적인 환원주의들은 저마다 설익은 담론을 쏟아 내기 시작했고, 이에 대해 우려하는 사람들은 ‘어떤 사람이 무언가를 보고 있다고 해서 대뇌 후두엽이 무언가를 보고 있 다고 말하는 것은 웃기는 일’이라며 반박하기도 했다. 그도 그럴 것이, 초창기에는 신경과학과 심리학 사이에는 다소간 에 이분법적인 대립이 있었고 서로에 대한 몰이해 속에서 그 저 자신의 학문이 더 우월하다는 힘겨루기의 분위기가 있었 기 때문이리라 짐작해본다. 하지만 이 책에서 저자는 심리학 자로서의 자신의 다년간의 경험을 잘 녹여내어 신경과학과 정신치료의 틈을 좁히려는 노력을 시도하고 있다. 이번에 새 로 나온 그의 개정증보판은 ‘Healing the Social Brain’이라는 부제를 가지고 있다. 정신치료자이자 정신과 의사로서 환자 를 대하는 입장에서, 이 책에서 어떠한 내용을 소개하고 있고 어떠한 의미가 있는지를 살펴보고자 한다.",2014.0,0.0,154.0,False,,"{'volume': '25', 'pages': '83-86', 'name': ''}","{'bibtex': '@Inproceedings{Lee2014TheNO,\n author = {Tae Young Lee},\n pages = {83-86},\n title = {The Neuroscience of Psychotherapy: Healing the Social Brain},\n volume = {25},\n year = {2014}\n}\n'}","[{'authorId': '2152473740', 'name': 'Tae Young Lee'}]"
1605,8a388f43b366c4366d3d402f610b92c5422b3aff,Combining cognition and emotion in virtual agents,"Purpose 
 
 
 
 
The paper aims to explain the limitations of existing cognitive architectures and affective models, and propose a new cognitive-affective architecture that can be integrated in real intelligent agents to make them more realistic and believable. 
 
 
 
 
Design/methodology/approach 
 
 
 
 
The paper evaluates the state of the art, and describes the design and implementation of the cognitive-affective architecture in an agent. A brief evaluation of the agent is provided. 
 
 
 
 
Findings 
 
 
 
 
The paper clearly states that it is possible to use cognitive architectures to help, but there is a lack of architectures that address the problem of combining cognition and emotion in agents in a unified, simplified way. A cognitive-affective architecture is useful to make believable intelligent agents in an easier way. 
 
 
 
 
Research limitations/implications 
 
 
 
 
The paper does not explore a lot of possible future work that can be done to extend the emotional expressions of the agent, as well as including direct emotional-sensing capabilities in real time. 
 
 
 
 
Practical implications 
 
 
 
 
The paper argues about the need to include cognitive-affective architectures in modern intelligent agents. The architecture allows to influence and modify the behavior of the agent in real time, to achieve a more realistic and believable interaction with the user. 
 
 
 
 
Social implications 
 
 
 
 
The paper remarks the importance of a cognitive-affective architecture that makes intelligent agents able to help the users in different tasks and environments. 
 
 
 
 
Originality/value 
 
 
 
 
The paper describes a new cognitive-affective architecture and its utility for modern intelligent agents. This is proven by including it in a previous agent, which boosts its behavior and emotional expression possibilities and thus improves user experience.",2017.0,47.0,5.0,False,,"{'name': 'Kybernetes', 'pages': '933-946', 'volume': '46'}","{'bibtex': '@Article{Marco2017CombiningCA,\n author = {J. P. Marco and F. Serón and Eva Cerezo Bagdasari},\n booktitle = {Kybernetes},\n journal = {Kybernetes},\n pages = {933-946},\n title = {Combining cognition and emotion in virtual agents},\n volume = {46},\n year = {2017}\n}\n'}","[{'authorId': '20950778', 'name': 'J. P. Marco'}, {'authorId': '2123508', 'name': 'F. Serón'}, {'authorId': '2082630073', 'name': 'Eva Cerezo Bagdasari'}]"
1606,8a519a911b502146085da571f58db2a2088f166d,Agents with,,,0.0,1.0,False,,,"{'bibtex': '@Misc{None,\n title = {Agents with}\n}\n'}",[]
1607,8a93f26ccfff647e2da299f8870fbd1a2d9cb3cd,Neuropsychological Performance in Mild Cognitive Impairment with and without Apathy,"Objective: To investigate the neuropsychological characteristics of patients diagnosed with mild cognitive impairment (MCI) with and without apathy. Methods: A cohort of 245 MCI patients (mean age = 72 ± 5.5 years; mean MMSE = 27.5 ± 1.3) was divided into two subgroups according to their Apathy Inventory score and underwent an extensive neuropsychological battery. Results: There were 94 (38.4%) patients with and 151 (61.6%) patients without apathy. At baseline the apathetic subgroup had a significantly lower total score on the free and cued selective reminding test (FCSR). Furthermore, the apathetic subgroup showed a significant deterioration in FCSR total recall score between baseline and the 1-year assessment. In conclusion, the presence of apathy in MCI patients is not associated with frontal task performance but with a higher degree of memory impairment.",2006.0,32.0,79.0,False,,"{'volume': '21', 'pages': '192 - 197', 'name': 'Dementia and Geriatric Cognitive Disorders'}","{'bibtex': '@Article{Robert2006NeuropsychologicalPI,\n author = {P. Robert and C. Berr and M. Volteau and C. Bertogliati and M. Benoit and F. Mahieux and S. Legrain and B. Dubois},\n journal = {Dementia and Geriatric Cognitive Disorders},\n pages = {192 - 197},\n title = {Neuropsychological Performance in Mild Cognitive Impairment with and without Apathy},\n volume = {21},\n year = {2006}\n}\n'}","[{'authorId': '2282672', 'name': 'P. Robert'}, {'authorId': '6158356', 'name': 'C. Berr'}, {'authorId': '5893688', 'name': 'M. Volteau'}, {'authorId': '2080746895', 'name': 'C. Bertogliati'}, {'authorId': '46866294', 'name': 'M. Benoit'}, {'authorId': '4310818', 'name': 'F. Mahieux'}, {'authorId': '6715113', 'name': 'S. Legrain'}, {'authorId': '145400912', 'name': 'B. Dubois'}]"
1608,8ab11ccfddb7886c280725e46b89de1c14a47725,A fuzzy navigation system for mobile construction robots,,1997.0,14.0,40.0,False,,"{'volume': '6', 'pages': '97-107', 'name': 'Automation in Construction'}","{'bibtex': '@Article{Lee1997AFN,\n author = {Seungho Lee and T. Adams and B. Ryoo},\n journal = {Automation in Construction},\n pages = {97-107},\n title = {A fuzzy navigation system for mobile construction robots},\n volume = {6},\n year = {1997}\n}\n'}","[{'authorId': '2117177936', 'name': 'Seungho Lee'}, {'authorId': '30441083', 'name': 'T. Adams'}, {'authorId': '2920923', 'name': 'B. Ryoo'}]"
1609,8abee3db6616015964d99c2aa7b59d617e46b582,Investigating learners' attitudes toward virtual reality learning environments: Based on a constructivist approach,,2010.0,70.0,669.0,False,,"{'volume': '55', 'pages': '1171-1182', 'name': 'Comput. Educ.'}","{'bibtex': ""@Article{Huang2010InvestigatingLA,\n author = {Hsiu-Mei Huang and Ulrich Rauch and S. Liaw},\n journal = {Comput. Educ.},\n pages = {1171-1182},\n title = {Investigating learners' attitudes toward virtual reality learning environments: Based on a constructivist approach},\n volume = {55},\n year = {2010}\n}\n""}","[{'authorId': '1688528', 'name': 'Hsiu-Mei Huang'}, {'authorId': '48067182', 'name': 'Ulrich Rauch'}, {'authorId': '34874569', 'name': 'S. Liaw'}]"
1610,8aedd5026b05dc0e87616d1306902812c1b7b5ab,STEVE (video session): a pedagogical agent for virtual reality,"We are exploring the use of virtual reality for training people how to perform tasks, such as operating and maintaining complex equipment. This video describes Steve, an agent we are developing that assists in the training. Steve is an autonomous, animated agent that cohabits the virtual world with students. Steve continuously monitors the state of the virtual world, periodically manipulating it through virtual motor actions. His objective is to help students learn to perform physical, procedural tasks. He can demonstrate tasks, explaining his actions, as well as monitor students performing tasks, providing help when they need it. In addition to teaching students individual tasks, he can also help them learn to perform multi-person team tasks: he can serve as a tutor for a student learning a particular role in the team, and he can play the role of a teammate when a human teammate is unavailable. By integrating previous work in agent architectures, intelligent tutoring systems, and computer graphics, Steve illustrates a new breed of computer tutor: a human-like agent that can interact with students in a virtual world to help them learn.",1998.0,8.0,32.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/280765.280851', 'status': None}",{'pages': '332-333'},"{'bibtex': '@Inproceedings{Rickel1998STEVES,\n author = {J. Rickel and M. Rey},\n pages = {332-333},\n title = {STEVE (video session): a pedagogical agent for virtual reality},\n year = {1998}\n}\n'}","[{'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '144995564', 'name': 'M. Rey'}]"
1611,8af78f6f4fe2bdcd3c9d3bafc424b04a22d4e5ea,An integrated theory of the mind.,"Adaptive control of thought-rational (ACT-R; J. R. Anderson & C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.",2004.0,189.0,2953.0,False,,"{'volume': '111 4', 'pages': '\n          1036-60\n        ', 'name': 'Psychological review'}","{'bibtex': '@Article{Anderson2004AnIT,\n author = {John R. Anderson and Daniel Bothell and M. Byrne and Scott Douglass and C. Lebiere and Yulin Qin},\n journal = {Psychological review},\n pages = {\n          1036-60\n        },\n title = {An integrated theory of the mind.},\n volume = {111 4},\n year = {2004}\n}\n'}","[{'authorId': '2158597261', 'name': 'John R. Anderson'}, {'authorId': '3240261', 'name': 'Daniel Bothell'}, {'authorId': '1731836', 'name': 'M. Byrne'}, {'authorId': '2067498', 'name': 'Scott Douglass'}, {'authorId': '1749342', 'name': 'C. Lebiere'}, {'authorId': '39669695', 'name': 'Yulin Qin'}]"
1612,8b28d45e96fd2f8fb2dd07f4518dda0b992ef30d,Cyberball: A program for use in research on interpersonal ostracism and acceptance,,2006.0,15.0,775.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03192765.pdf', 'status': None}","{'volume': '38', 'pages': '174-180', 'name': 'Behavior Research Methods'}","{'bibtex': '@Article{Williams2006CyberballAP,\n author = {K. Williams and Blair J. Jarvis},\n journal = {Behavior Research Methods},\n pages = {174-180},\n title = {Cyberball: A program for use in research on interpersonal ostracism and acceptance},\n volume = {38},\n year = {2006}\n}\n'}","[{'authorId': '2242798922', 'name': 'K. Williams'}, {'authorId': '20719550', 'name': 'Blair J. Jarvis'}]"
1613,8b2a70839a3d68292aaa907b15b78c22cf20a579,Deep convolution network based emotion analysis towards mental health care,,2020.0,54.0,83.0,True,"{'url': 'https://strathprints.strath.ac.uk/72076/1/Fei_etal_Neurocomputing_2020_Deep_convolution_network_based_emotion_analysis_towards_mental.pdf', 'status': None}","{'volume': '388', 'pages': '212-227', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Fei2020DeepCN,\n author = {Zixiang Fei and Erfu Yang and Day-Uei Li and Stephen Butler and W. Ijomah and Xia Li and Huiyu Zhou},\n journal = {Neurocomputing},\n pages = {212-227},\n title = {Deep convolution network based emotion analysis towards mental health care},\n volume = {388},\n year = {2020}\n}\n'}","[{'authorId': '30441535', 'name': 'Zixiang Fei'}, {'authorId': '48553748', 'name': 'Erfu Yang'}, {'authorId': '2145163577', 'name': 'Day-Uei Li'}, {'authorId': '2060677585', 'name': 'Stephen Butler'}, {'authorId': '2793317', 'name': 'W. Ijomah'}, {'authorId': '2109496899', 'name': 'Xia Li'}, {'authorId': '46544755', 'name': 'Huiyu Zhou'}]"
1614,8b3468284a883eff59a05bab957b2840a1ad96cc,The human emotional brain without sleep — a prefrontal amygdala disconnect,,2007.0,9.0,1049.0,True,"{'url': 'http://www.cell.com/article/S0960982207017836/pdf', 'status': None}","{'volume': '17', 'pages': 'R877-R878', 'name': 'Current Biology'}","{'bibtex': '@Article{Yoo2007TheHE,\n author = {S. Yoo and N. Gujar and Peter Hu and F. Jolesz and M. Walker},\n journal = {Current Biology},\n pages = {R877-R878},\n title = {The human emotional brain without sleep — a prefrontal amygdala disconnect},\n volume = {17},\n year = {2007}\n}\n'}","[{'authorId': '2250619', 'name': 'S. Yoo'}, {'authorId': '1816334', 'name': 'N. Gujar'}, {'authorId': '2067770790', 'name': 'Peter Hu'}, {'authorId': '1603168041', 'name': 'F. Jolesz'}, {'authorId': '2341798', 'name': 'M. Walker'}]"
1615,8b3fff6b4f2d21b217dc5cdbe7487cd7303e847a,Investigating Human Perceptions of Trust in Robots for Safe HRI in Home Environments,"In an era in which robots take a part in our lives in daily living activities, humans have to trust robots in home environments. We aim to create guidelines that allow humans to trust robots to be able to look after their well-being by adopting human-like behaviours. We want to study a Human-Robot Interaction (HRI) to assess whether a certain degree of transparency in the robots actions, the use of social behaviours and natural communications can affect humans' sense of trust and companionship towards the robots. However, trust can change over time due to different factors, e.g. due to perceiving erroneous robot behaviors. We believe that the magnitude and the timing of the error during an interaction may have different impacts resulting in different scales of loss of trust and of restoring lost trust.",2017.0,15.0,38.0,False,,{'name': 'Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction'},"{'bibtex': '@Article{Rossi2017InvestigatingHP,\n author = {Alessandra Rossi and K. Dautenhahn and K. Koay and J. Saunders},\n journal = {Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction},\n title = {Investigating Human Perceptions of Trust in Robots for Safe HRI in Home Environments},\n year = {2017}\n}\n'}","[{'authorId': '48369504', 'name': 'Alessandra Rossi'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '1749179', 'name': 'K. Koay'}, {'authorId': '49163673', 'name': 'J. Saunders'}]"
1616,8b43a0a905745e7c1ae24c10129b6c51e1c676d6,Dancing the night away: controlling a virtual karaoke dancer by multimodal expressive cues,"In this article, we propose an approach of nonverbal interaction with virtual agents to control agents' behavioral expressivity by extracting and combining acoustic and gestural features. The goal for this approach is twofold, (i) expressing individual features like situated arousal and personal style and (ii) transmitting this information in an immersive 3D environment by suitable means.",2008.0,15.0,8.0,False,,{'pages': '1249-1252'},"{'bibtex': '@Inproceedings{Rehm2008DancingTN,\n author = {M. Rehm and Thurid Vogt and M. Wissner and Nikolaus Bee},\n pages = {1249-1252},\n title = {Dancing the night away: controlling a virtual karaoke dancer by multimodal expressive cues},\n year = {2008}\n}\n'}","[{'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '30169286', 'name': 'Thurid Vogt'}, {'authorId': '2754538', 'name': 'M. Wissner'}, {'authorId': '1790555', 'name': 'Nikolaus Bee'}]"
1617,8b66b793a8eb59bf5defafa017a5f70e867cc89b,Handbook of Research Methods in Social and Personality Psychology: Inducing and Measuring Emotion and Affect,"This chapter describes the use of field research for development of psychological theory. Field research helps identify which phenomena are most psychologically and behaviorally consequential. The chapter focuses on the kinds of theoretical insights afforded by research in field settings. It explains what one means by field research as opposed to laboratory research, and discusses advantages that come from finding and testing ideas in the field. Observational methods can be put to many important uses in field settings. The chapter examines the experimental research in the field that is explicitly designed for the purpose of comparison and causal inference. It explores the range of theoretical goals that can be accomplished with field research. The chapter outlines the strengths and weaknesses of various field research techniques and best practices of each one. It concludes with practical suggestions and reasons for researchers at various stages of experience to engage in field research.",2014.0,196.0,33.0,False,,"{'volume': '', 'pages': '220-252', 'name': ''}","{'bibtex': '@Inproceedings{Quigley2014HandbookOR,\n author = {K. Quigley and Kristen A. Lindquist and L. F. Barrett},\n pages = {220-252},\n title = {Handbook of Research Methods in Social and Personality Psychology: Inducing and Measuring Emotion and Affect},\n year = {2014}\n}\n'}","[{'authorId': '3460242', 'name': 'K. Quigley'}, {'authorId': '2593387', 'name': 'Kristen A. Lindquist'}, {'authorId': '1731779', 'name': 'L. F. Barrett'}]"
1618,8bb51f40236fd06406f22b31fcacb381539c3bf9,BDI Agents: From Theory to Practice,"The study of computational agents capable of rational behaviour has received a great deal of attention in recent years. Theoretical formalizations of such agents and their implementations have proceeded in parallel with little or no connection between them. Tkis paper explores a particular type of rational agent, a BeliefDesire-Intention (BDI) agent. The primary aim of this paper is to integrate (a) the theoretical foundations of BDI agents from both a quantitative decision-theoretic perspective and a symbolic reasoning perspective; (b) the implementations of BDI agents from an ideal theoretical perspective and a more practical perspective; and (c) the building of large-scale applications based on BDI agents. In particular, an air-trafflc management application will be described from both a theoretical and an implementation perspective.",1995.0,40.0,3415.0,False,,{'pages': '312-319'},"{'bibtex': '@Inproceedings{Rao1995BDIAF,\n author = {Anand Srinivasa Rao and M. Georgeff},\n pages = {312-319},\n title = {BDI Agents: From Theory to Practice},\n year = {1995}\n}\n'}","[{'authorId': '145946928', 'name': 'Anand Srinivasa Rao'}, {'authorId': '1694809', 'name': 'M. Georgeff'}]"
1620,8bd45ce46f5780a64ebe265eaea230e930c9fc5b,Empathic Touch by Relational Agents,"We describe a series of experiments with an agent designed to model human conversational touch-capable of physically touching users in synchrony with speech and other nonverbal communicative behavior-and its use in expressing empathy to users in distress. The agent is composed of an animated human face that is displayed on a monitor affixed to the top of a human mannequin, with touch conveyed by an air bladder that squeezes a user's hand. We demonstrate that when touch is used alone, hand squeeze pressure and number of squeezes are associated with user perceptions of affect arousal conveyed by an agent, while number of squeezes and squeeze duration are associated with affect valence. We also show that, when affect-relevant cues are present in facial display, speech prosody, and touch used simultaneously by the agent, facial display dominates user perceptions of affect valence, and facial display and prosody are associated with affect arousal, while touch had little effect. Finally, we show that when touch is used in the context of an empathic, comforting interaction (but without the manipulation of affect cues in other modalities), it can lead to better perceptions of relationship with the agent, but only for users who are comfortable being touched by other people.",2010.0,58.0,91.0,False,,"{'volume': '1', 'pages': '60-71', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Bickmore2010EmpathicTB,\n author = {T. Bickmore and Rukmal Fernando and Lazlo Ring and Daniel Schulman},\n journal = {IEEE Transactions on Affective Computing},\n pages = {60-71},\n title = {Empathic Touch by Relational Agents},\n volume = {1},\n year = {2010}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '1941416', 'name': 'Rukmal Fernando'}, {'authorId': '2880118', 'name': 'Lazlo Ring'}, {'authorId': '50247170', 'name': 'Daniel Schulman'}]"
1621,8bdd11e637e682a2dbea2c4617574cb01e2bad39,Continuing the bifurcation of affect and cognition, ,1996.0,0.0,927.0,False,,"{'volume': '26', 'pages': '89', 'name': 'Curriculum Inquiry'}","{'bibtex': '@Article{Roth1996ContinuingTB,\n author = {Jeffrey Roth and S. Damico and Fred M. Newmann},\n journal = {Curriculum Inquiry},\n pages = {89},\n title = {Continuing the bifurcation of affect and cognition},\n volume = {26},\n year = {1996}\n}\n'}","[{'authorId': '143980334', 'name': 'Jeffrey Roth'}, {'authorId': '82896601', 'name': 'S. Damico'}, {'authorId': '69437654', 'name': 'Fred M. Newmann'}]"
1622,8c0dc29f2f97fb00ac8800f59036da005023dd30,"Emotion, Memory, and Attention in the Taboo Stroop Paradigm","This study tested the binding hypothesis: that emotional reactions trigger binding mechanisms that link an emotional event to salient contextual features such as event location, a frequently recalled aspect of naturally occurring flashbulb memories. Our emotional events were taboo words in a Stroop color-naming task, and event location was manipulated by presenting the words in different task-irrelevant screen locations. Seventy-two participants named the font color of taboo and neutral words, with instructions to ignore word meaning; in one condition, several words were location consistent (i.e., always occupied the same screen location), whereas in another condition, several colors were location consistent. Then, in a surprise recognition memory test, participants recalled the locations of location-consistent words or colors. Although attention enhanced overall location memory for colors (the attended dimension during color naming), emotion (taboo vs. neutral words) enhanced location memory for words but not colors. These results support the binding hypothesis but contradict the hypothesis that emotional events induce imagelike memories more often than nonemotional events.",2005.0,36.0,164.0,False,,"{'volume': '16', 'pages': '25 - 32', 'name': 'Psychological Science'}","{'bibtex': '@Article{MacKay2005EmotionMA,\n author = {D. G. MacKay and Marat V. Ahmetzanov},\n journal = {Psychological Science},\n pages = {25 - 32},\n title = {Emotion, Memory, and Attention in the Taboo Stroop Paradigm},\n volume = {16},\n year = {2005}\n}\n'}","[{'authorId': '143917492', 'name': 'D. G. MacKay'}, {'authorId': '4069327', 'name': 'Marat V. Ahmetzanov'}]"
1623,8c1e46c901ae51434897138344c437ec6d7a55fc,An intelligent mobile vehicle navigator based on fuzzy logic and reinforcement learning,"In this paper, an alternative training approach to the EEM-based training method is presented and a fuzzy reactive navigation architecture is described. The new training method is 270 times faster in learning speed; and is only 4% of the learning cost of the EEM method. It also has very reliable convergence of learning; very high number of learned rules (98.8%); and high adaptability. Using the rule base learned from the new method, the proposed fuzzy reactive navigator fuses the obstacle avoidance behaviour and goal seeking behaviour to determine its control actions, where adaptability is achieved with the aid of an environment evaluator. A comparison of this navigator using the rule bases obtained from the new training method and the EEM method, shows that the new navigator guarantees a solution and its solution is more acceptable.",1999.0,20.0,90.0,True,"{'url': 'http://hub.hku.hk/bitstream/10722/42817/1/45788.pdf', 'status': None}","{'volume': '29 2', 'pages': '\n          314-21\n        ', 'name': 'IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society'}","{'bibtex': '@Article{Yung1999AnIM,\n author = {Nelson H C Yung and C. Ye},\n journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},\n pages = {\n          314-21\n        },\n title = {An intelligent mobile vehicle navigator based on fuzzy logic and reinforcement learning},\n volume = {29 2},\n year = {1999}\n}\n'}","[{'authorId': '2251398230', 'name': 'Nelson H C Yung'}, {'authorId': '1694177', 'name': 'C. Ye'}]"
1624,8c25f4ec8df7874c64a72dfe2324888c9c6a01d2,Uncovering Human-to-Human Physical Interactions that Underlie Emotional and Affective Touch Communication,"Couples often communicate their emotions, e.g., love or sadness, through physical expressions of touch. Prior efforts have used visual observation to distinguish emotional touch communications by certain gestures tied to one’s hand contact, velocity and position. The work herein describes an automated approach to eliciting the essential features of these gestures. First, a tracking system records the timing and location of contact interactions in 3-D between a toucher’s hand and a receiver’s forearm. Second, data post-processing algorithms extract dependent measures, derived from prior visual observation, tied to the intensity and velocity of the toucher’s hand, as well as areas, durations and parts of the hand in contact. Third, behavioral data were obtained from five couples who sought to convey a variety of emotional word cues. We found that certain combinations of six dependent measures well distinguish the touch communications. For example, a typical sadness expression invokes more contact, evolves more slowly, and impresses less deeply into the forearm than a typical attention expression. Furthermore, cluster analysis indicates 2-5 distinct expression strategies are common per word being communicated. Specifying the essential features of touch communications can guide haptic devices in reproducing naturalistic interactions.",2019.0,20.0,38.0,True,,"{'pages': '407-412', 'name': '2019 IEEE World Haptics Conference (WHC)'}","{'bibtex': '@Article{Hauser2019UncoveringHP,\n author = {Steven C. Hauser and S. McIntyre and A. Israr and H. Olausson and G. J. Gerling},\n journal = {2019 IEEE World Haptics Conference (WHC)},\n pages = {407-412},\n title = {Uncovering Human-to-Human Physical Interactions that Underlie Emotional and Affective Touch Communication},\n year = {2019}\n}\n'}","[{'authorId': '50514195', 'name': 'Steven C. Hauser'}, {'authorId': '152197729', 'name': 'S. McIntyre'}, {'authorId': '1769549', 'name': 'A. Israr'}, {'authorId': '144819271', 'name': 'H. Olausson'}, {'authorId': '145856041', 'name': 'G. J. Gerling'}]"
1625,8c318a290c3b2ad067057c1a1537d6e8fad9b99b,Symbolic vs. acoustics-based style control for expressive unit selection,"The present paper addresses the issue of flexibility in expressive unit selection speech synthesis by using different style selection techniques. We select units from a mixed-style unit selection database, using either forced style switching, no control, symbolic target cost, or acoustic target cost as a style selection criterion. We assess the effect of selection technique, feature weight and relative weight of target vs. join costs on a set of objective measures for style specificity and smoothness.",2010.0,21.0,15.0,False,,{'pages': '114-119'},"{'bibtex': '@Inproceedings{Steiner2010SymbolicVA,\n author = {I. Steiner and M. Schröder and Marcela Charfuelan and A. Klepp},\n pages = {114-119},\n title = {Symbolic vs. acoustics-based style control for expressive unit selection},\n year = {2010}\n}\n'}","[{'authorId': '2652243', 'name': 'I. Steiner'}, {'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '2191162', 'name': 'Marcela Charfuelan'}, {'authorId': '2817823', 'name': 'A. Klepp'}]"
1626,8c53674d18328f453e3131ad9229e1ab51d4e977,Oud worden,,2016.0,0.0,1.0,False,,"{'volume': '48', 'pages': '35', 'name': 'TvV Tijdschrift voor Verzorgenden'}","{'bibtex': '@Article{Anne-Mei2016OudW,\n author = {Anne-Mei},\n journal = {TvV Tijdschrift voor Verzorgenden},\n pages = {35},\n title = {Oud worden},\n volume = {48},\n year = {2016}\n}\n'}","[{'authorId': '1450274569', 'name': 'Anne-Mei'}]"
1627,8c62297d4c299f201be3c6b877fe81f1bd4f5e3d,Psychometric properties of the PTSD Checklist (PCL).,,1996.0,4.0,3849.0,False,,"{'volume': '34 8', 'pages': '\n          669-73\n        ', 'name': 'Behaviour research and therapy'}","{'bibtex': '@Article{Blanchard1996PsychometricPO,\n author = {E. Blanchard and Jacqueline Jones-Alexander and T. C. Buckley and C. Forneris},\n journal = {Behaviour research and therapy},\n pages = {\n          669-73\n        },\n title = {Psychometric properties of the PTSD Checklist (PCL).},\n volume = {34 8},\n year = {1996}\n}\n'}","[{'authorId': '2060460', 'name': 'E. Blanchard'}, {'authorId': '1398931204', 'name': 'Jacqueline Jones-Alexander'}, {'authorId': '4751979', 'name': 'T. C. Buckley'}, {'authorId': '6574143', 'name': 'C. Forneris'}]"
1628,8c666bbda4037c4cfb6f93e36feb5fdd857e35ad,AVATAR: Contribution to Human-Computer interaction processes through the adaptation of semi-personalized virtual agents,"In this article a process of animation of 3D models is proposed to transform them into virtual agents or avatars with the possibility of being used in Human-Computer interaction processes. The resulting virtual agents have been adapted as tools that serve as a starting point for the development of real-time interaction algorithms. The characteristics of the generated tools allows to deepen in techniques of machine learning and artificial intelligence, endowing to the virtual agents of movements with natural and real characteristics. It is possible to use them as puppets, capturing the movements of a person and transferring them to the animation; it is also possible to program specific sequences whose interaction processes are completely determined. Finally, the idea of developing algorithms involving artificial intelligence combined with human intelligence to improve interaction processes is proposed.",2018.0,17.0,6.0,False,,"{'pages': '1-4', 'name': '2018 IEEE Biennial Congress of Argentina (ARGENCON)'}","{'bibtex': '@Article{Guerrero-Vásquez2018AVATARCT,\n author = {L. F. Guerrero-Vásquez and Dennys X. Landy-Rivera and J. Bravo-Torres and M. López-Nores and Renato Castro-Serrano and P. E. Vintimilla-Tapia},\n journal = {2018 IEEE Biennial Congress of Argentina (ARGENCON)},\n pages = {1-4},\n title = {AVATAR: Contribution to Human-Computer interaction processes through the adaptation of semi-personalized virtual agents},\n year = {2018}\n}\n'}","[{'authorId': '1384430360', 'name': 'L. F. Guerrero-Vásquez'}, {'authorId': '1411468635', 'name': 'Dennys X. Landy-Rivera'}, {'authorId': '1398154358', 'name': 'J. Bravo-Torres'}, {'authorId': '1403802069', 'name': 'M. López-Nores'}, {'authorId': '1410642144', 'name': 'Renato Castro-Serrano'}, {'authorId': '1410303772', 'name': 'P. E. Vintimilla-Tapia'}]"
1629,8c783aaa01a756f50ea8c2fe6d13795398a6c043,To Mix or Not to Mix Synthetic Speech and Human Speech? Contrasting Impact on Judge-Rated Task Performance versus Self-Rated Performance and Attitudinal Responses,,2003.0,17.0,40.0,False,,"{'volume': '6', 'pages': '123-131', 'name': 'International Journal of Speech Technology'}","{'bibtex': '@Article{Gong2003ToMO,\n author = {Li Gong and J. Lai},\n journal = {International Journal of Speech Technology},\n pages = {123-131},\n title = {To Mix or Not to Mix Synthetic Speech and Human Speech? Contrasting Impact on Judge-Rated Task Performance versus Self-Rated Performance and Attitudinal Responses},\n volume = {6},\n year = {2003}\n}\n'}","[{'authorId': '2056813456', 'name': 'Li Gong'}, {'authorId': '3853032', 'name': 'J. Lai'}]"
1630,8c82a2efbcd615bd8ac590156c51dc1b91ba945b,A Study in Users' Physiological Response to an Empathic Interface Agent,"This paper presents a novel method for evaluating the impact of animated interface agents with affective and empathic behavior. While previous studies relied on questionnaires in order to assess the user's overall experience with the interface agent, we will analyze users' physiological response (skin conductance and electromyography), which allows us to estimate affect-related user experiences on a moment-by-moment basis without interfering with the primary interaction task. As an interaction scenario, a card game has been implemented where the user plays against a virtual opponent. The findings of our study indicate that within a competitive gaming scenario, (i) the absence of the agent's display of negative emotions is conceived as arousing or stress-inducing, and (ii) the valence of users' emotional response is congruent with the valence of the emotion expressed by the agent. Our results for skin conductance could also be reproduced by assuming a local rather than a global baseline.",2006.0,45.0,47.0,True,"{'url': 'http://www.miv.t.u-tokyo.ac.jp/papers/helmut-HumanoidRobotics06.pdf', 'status': None}","{'volume': '3', 'pages': '371-391', 'name': 'Int. J. Humanoid Robotics'}","{'bibtex': ""@Article{Prendinger2006ASI,\n author = {H. Prendinger and Christian Becker and M. Ishizuka},\n journal = {Int. J. Humanoid Robotics},\n pages = {371-391},\n title = {A Study in Users' Physiological Response to an Empathic Interface Agent},\n volume = {3},\n year = {2006}\n}\n""}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '2068695177', 'name': 'Christian Becker'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
1631,8c932cb26eab781127fae8a31dcf3b7ceb574e6a,Exposure to virtual social interactions in the treatment of social anxiety disorder: A randomized controlled trial.,,2016.0,51.0,150.0,True,"{'url': 'https://pure.uva.nl/ws/files/2689117/172016_502505.pdf', 'status': None}","{'volume': '77', 'pages': '\n          147-56\n        ', 'name': 'Behaviour research and therapy'}","{'bibtex': '@Article{Kampmann2016ExposureTV,\n author = {Isabel L. Kampmann and P. Emmelkamp and Dwi Hartanto and Willem-Paul Brinkman and B. Zijlstra and N. Morina},\n journal = {Behaviour research and therapy},\n pages = {\n          147-56\n        },\n title = {Exposure to virtual social interactions in the treatment of social anxiety disorder: A randomized controlled trial.},\n volume = {77},\n year = {2016}\n}\n'}","[{'authorId': '2116343', 'name': 'Isabel L. Kampmann'}, {'authorId': '2282500', 'name': 'P. Emmelkamp'}, {'authorId': '2068702206', 'name': 'Dwi Hartanto'}, {'authorId': '145495942', 'name': 'Willem-Paul Brinkman'}, {'authorId': '4506237', 'name': 'B. Zijlstra'}, {'authorId': '145500304', 'name': 'N. Morina'}]"
1632,8cf0841ca5b89f51fc48f5e5b3cd2d6af956f1ff,Emotional agents at the square lattice,"We introduce and investigate by numerical simulations a number of models of emotional agents at the square lattice. Our models describe the most general features of emotions such as the spontaneous emotional arousal, emotional relaxation, and transfers of emotions between different agents. Group emotions in the considered models are periodically fluctuating between two opposite valency levels and as result the mean value of such group emotions is zero. The oscillations amplitude depends strongly on probability ps of the individual spontaneous arousal. For small values of relaxation times tau we observed a stochastic resonance, i.e. the signal to noise ratio SNR is maximal for a non-zero ps parameter. The amplitude increases with the probability p of local affective interactions while the mean oscillations period increases with the relaxation time tau and is only weakly dependent on other system parameters. Presence of emotional antenna can enhance positive or negative emotions and for the optimal transition probability the antenna can change agents emotions at longer distances. The stochastic resonance was also observed for the influence of emotions on task execution efficiency.",2010.0,26.0,12.0,True,,"{'volume': '', 'name': 'arXiv: Physics and Society'}","{'bibtex': '@Article{Czaplicka2010EmotionalAA,\n author = {Agnieszka Czaplicka and A. Chmiel and J. Hołyst},\n journal = {arXiv: Physics and Society},\n title = {Emotional agents at the square lattice},\n year = {2010}\n}\n'}","[{'authorId': '1708031', 'name': 'Agnieszka Czaplicka'}, {'authorId': '143788693', 'name': 'A. Chmiel'}, {'authorId': '35433346', 'name': 'J. Hołyst'}]"
1633,8cf0c072eeaec310aff806bdb7a7931b81e9ed99,End-to-End Multimodal Emotion Recognition Using Deep Neural Networks,"Automatic affect recognition is a challenging task due to the various modalities emotions can be expressed with. Applications can be found in many domains including multimedia retrieval and human–computer interaction. In recent years, deep neural networks have been used with great success in determining emotional states. Inspired by this success, we propose an emotion recognition system using auditory and visual modalities. To capture the emotional content for various styles of speaking, robust features need to be extracted. To this purpose, we utilize a convolutional neural network (CNN) to extract features from the speech, while for the visual modality a deep residual network of 50 layers is used. In addition to the importance of feature extraction, a machine learning algorithm needs also to be insensitive to outliers while being able to model the context. To tackle this problem, long short-term memory networks are utilized. The system is then trained in an end-to-end fashion where—by also taking advantage of the correlations of each of the streams—we manage to significantly outperform, in terms of concordance correlation coefficient, traditional approaches based on auditory and visual handcrafted features for the prediction of spontaneous and natural emotions on the RECOLA database of the AVEC 2016 research challenge on emotion recognition.",2017.0,53.0,449.0,True,"{'url': 'https://research.gold.ac.uk/22284/1/end-end-multimodal.pdf', 'status': None}","{'volume': '11', 'pages': '1301-1309', 'name': 'IEEE Journal of Selected Topics in Signal Processing'}","{'bibtex': '@Article{Tzirakis2017EndtoEndME,\n author = {Panagiotis Tzirakis and George Trigeorgis and M. Nicolaou and Björn Schuller and S. Zafeiriou},\n journal = {IEEE Journal of Selected Topics in Signal Processing},\n pages = {1301-1309},\n title = {End-to-End Multimodal Emotion Recognition Using Deep Neural Networks},\n volume = {11},\n year = {2017}\n}\n'}","[{'authorId': '2829366', 'name': 'Panagiotis Tzirakis'}, {'authorId': '2814229', 'name': 'George Trigeorgis'}, {'authorId': '1752913', 'name': 'M. Nicolaou'}, {'authorId': '145411696', 'name': 'Björn Schuller'}, {'authorId': '1776444', 'name': 'S. Zafeiriou'}]"
1634,8d11a0d6f0477c8f176ffe84addf524060559b19,"Glances, glares, and glowering: how should a virtual human express emotion through gaze?",,2009.0,32.0,28.0,False,,"{'volume': '20', 'pages': '50-69', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Lance2009GlancesGA,\n author = {Brent Lance and S. Marsella},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {50-69},\n title = {Glances, glares, and glowering: how should a virtual human express emotion through gaze?},\n volume = {20},\n year = {2009}\n}\n'}","[{'authorId': '145417478', 'name': 'Brent Lance'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
1635,8d1ad01630963e10749c827cfc9f9265e9adb66a,Game-Based Learning Application for Children with Autism Spectrum Disorder using Participatory Design,"This paper aimed to devise a means to design game-based learning and develop an application game for children with autism spectrum disorder (ASD) using the participatory design (PD) method. A total of 15 participants from Khaneye Mehre Autism School in Tehran, Iran, were involved in this study. The engagement participatory sessions supplied the necessary information to facilitate the design process and understand the children’s preference between the different design stimuli in individuals as informants by allowing them to be part of design activities. In addition, some value practices and design methods informed by relevant PD projects in the healthcare and public sectors were discussed such as an effective role of designers require adequate communication skills from participants. Based on the findings, this study maintains that PD increases the chance that the result of a design process represents the values for future works.",2021.0,46.0,1.0,False,,{'name': 'International Journal of Academic Research in Progressive Education and Development'},"{'bibtex': '@Article{Dehkordi2021GameBasedLA,\n author = {Sara Reisi Dehkordi and Marina Ismail and Norizan Mat Diah},\n journal = {International Journal of Academic Research in Progressive Education and Development},\n title = {Game-Based Learning Application for Children with Autism Spectrum Disorder using Participatory Design},\n year = {2021}\n}\n'}","[{'authorId': '30609012', 'name': 'Sara Reisi Dehkordi'}, {'authorId': '16909046', 'name': 'Marina Ismail'}, {'authorId': '30703011', 'name': 'Norizan Mat Diah'}]"
1636,8d28d9c1b8efdc804f16c595027d23084f4eb675,Personality in Adulthood: A Five-Factor Theory Perspective,Contents: Facts and Theories of Adult Development. A Trait Approach to Personality. Measuring Personality. The Search for Growth or Decline in Personality. Cross-Cultural Perspectives on Personality and Aging. The Course of Personality Development in the Individual. Stability Reconsidered: Qualifications and Rival Hypotheses. A Different View: Ego Psychologies and Projective Methods. Adult Development as Seen through the Personal Interview. A Five-Factor Theory of Personality. The Influences of Personality on the Life Course.,2005.0,0.0,1965.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{McCrae2005PersonalityIA,\n author = {R. McCrae and P. Costa},\n title = {Personality in Adulthood: A Five-Factor Theory Perspective},\n year = {2005}\n}\n'}","[{'authorId': '6206591', 'name': 'R. McCrae'}, {'authorId': '2281038', 'name': 'P. Costa'}]"
1637,8d4b356db6eaf8bff66de9a3be87e5f0ed6da67e,"An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data",,2010.0,21.0,528.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BRM.42.1.188.pdf', 'status': None}","{'volume': '42', 'pages': '188-204', 'name': 'Behavior Research Methods'}","{'bibtex': '@Article{Nyström2010AnAA,\n author = {M. Nyström and K. Holmqvist},\n journal = {Behavior Research Methods},\n pages = {188-204},\n title = {An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data},\n volume = {42},\n year = {2010}\n}\n'}","[{'authorId': '2226198', 'name': 'M. Nyström'}, {'authorId': '3165327', 'name': 'K. Holmqvist'}]"
1638,8d4b84a0931b9916b9e19aec6b667f3a2c139fd8,Almost human: Anthropomorphism increases trust resilience in cognitive agents.,"We interact daily with computers that appear and behave like humans. Some researchers propose that people apply the same social norms to computers as they do to humans, suggesting that social psychological knowledge can be applied to our interactions with computers. In contrast, theories of human–automation interaction postulate that humans respond to machines in unique and specific ways. We believe that anthropomorphism—the degree to which an agent exhibits human characteristics—is the critical variable that may resolve this apparent contradiction across the formation, violation, and repair stages of trust. Three experiments were designed to examine these opposing viewpoints by varying the appearance and behavior of automated agents. Participants received advice that deteriorated gradually in reliability from a computer, avatar, or human agent. Our results showed (a) that anthropomorphic agents were associated with greater trust resilience, a higher resistance to breakdowns in trust; (b) that these effects were magnified by greater uncertainty; and c) that incorporating human-like trust repair behavior largely erased differences between the agents. Automation anthropomorphism is therefore a critical variable that should be carefully incorporated into any general theory of human–agent trust as well as novel automation design.",2016.0,132.0,327.0,True,,"{'volume': '22 3', 'pages': '\n          331-49\n        ', 'name': 'Journal of experimental psychology. Applied'}","{'bibtex': '@Article{Visser2016AlmostHA,\n author = {E. D. de Visser and Samuel S. Monfort and Ryan McKendrick and Melissa A. B. Smith and Patrick McKnight and F. Krueger and R. Parasuraman},\n journal = {Journal of experimental psychology. Applied},\n pages = {\n          331-49\n        },\n title = {Almost human: Anthropomorphism increases trust resilience in cognitive agents.},\n volume = {22 3},\n year = {2016}\n}\n'}","[{'authorId': '113889522', 'name': 'E. D. de Visser'}, {'authorId': '34330513', 'name': 'Samuel S. Monfort'}, {'authorId': '2402701', 'name': 'Ryan McKendrick'}, {'authorId': '1410179766', 'name': 'Melissa A. B. Smith'}, {'authorId': '2095598398', 'name': 'Patrick McKnight'}, {'authorId': '144714297', 'name': 'F. Krueger'}, {'authorId': '3264674', 'name': 'R. Parasuraman'}]"
1639,8d5013258fccc78615e47b8ab5f81812b989ac4a,Mining Sequential Patterns: Generalizations and Performance Improvements,,1996.0,14.0,3177.0,False,,{'pages': '3-17'},"{'bibtex': '@Inproceedings{Srikant1996MiningSP,\n author = {R. Srikant and R. Agrawal},\n pages = {3-17},\n title = {Mining Sequential Patterns: Generalizations and Performance Improvements},\n year = {1996}\n}\n'}","[{'authorId': '34641476', 'name': 'R. Srikant'}, {'authorId': '144947410', 'name': 'R. Agrawal'}]"
1640,8d71646a3d2658c78a7a7982f7bbbcff7981fc45,A domain-independent framework for modeling emotion,,2004.0,122.0,802.0,False,,"{'volume': '5', 'pages': '269-306', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Gratch2004ADF,\n author = {J. Gratch and S. Marsella},\n journal = {Cognitive Systems Research},\n pages = {269-306},\n title = {A domain-independent framework for modeling emotion},\n volume = {5},\n year = {2004}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
1646,8d7aacba92dcf2be1f5e711bc1238ab1eb6fc390,"""Discovering emotion influence patterns in online social network conversations"" by Suin Kim, JinYeong Bak, and Alice Oh, with Ching-man Au Yeung as coordinator","Conversational partners influence each others' emotions and topics. Using a large dataset of Twitter conversations and an unsupervised machine learning technique, we discover patterns of emotion influence in naturally occurring conversations. We describe our computational framework for automatically classifying emotions, analyzing the emotional transitions, and discovering emotion influence patterns. We found that conversational partners usually express the same emotion (emotion contagion), but when they do not, one of the conversational partners tends to respond with a positive emotion. Also, tweets containing sympathy, apology, and complaint are significant emotion influencers. One of the interesting findings is that expressing a desired emotion is the best strategy to alter partner's emotion.",2012.0,11.0,10.0,False,,"{'volume': '2012', 'pages': '1 - 6', 'name': 'ACM SIGWEB Newsletter'}","{'bibtex': '@Article{Kim2012DiscoveringEI,\n author = {Suin Kim and Jinyeong Bak and Alice H. Oh},\n journal = {ACM SIGWEB Newsletter},\n pages = {1 - 6},\n title = {""Discovering emotion influence patterns in online social network conversations"" by Suin Kim, JinYeong Bak, and Alice Oh, with Ching-man Au Yeung as coordinator},\n volume = {2012},\n year = {2012}\n}\n'}","[{'authorId': '2844832', 'name': 'Suin Kim'}, {'authorId': '72761736', 'name': 'Jinyeong Bak'}, {'authorId': '2463290', 'name': 'Alice H. Oh'}]"
1647,8d7b4c6e3193abe833418f52094cf5f27eb3da78,STORYTELLING FOR INCLUSION,"Storytelling accompanies the evolution of the human race, and bears witness to both its identity and culture. For a long time, it has represented a sort of “oral encyclopedia” which, through narrative, has passed down from generation to generation traditions, customs and knowledge (Halverson, 1992). The role that storytelling played, even before the discovery of writing, in the diffusion of knowledge, in the construction of interpersonal relationships and in the birth of new societies, is well known. Without doubt writing is the earliest “technology” invented by man, through which culture and knowledge have been passed down over time, after having been transmitted orally for a long time. According to Barthes and Duisit (1975), in fact, storytelling begins with the same story of the human race, almost as if to represent an ontogenetically distinctive trait of the species, which unites homo sapiens with the homo digitalis of today’s society (Montag & Diefenbach, 2018). Other authors (Kenyon et al., 1996) argue that men and women not only have stories to tell, but that they are the stories they tell. Storytelling, therefore, always reinterprets in a new way and with different tools a natural propensity of human beings to tell about themselves, to build memories capable of projecting the past into the future.",2020.0,28.0,2.0,False,,,"{'bibtex': '@Inproceedings{Capperucci2020STORYTELLINGFI,\n author = {Davide Capperucci},\n title = {STORYTELLING FOR INCLUSION},\n year = {2020}\n}\n'}","[{'authorId': '100833814', 'name': 'Davide Capperucci'}]"
1648,8d95d83766a658f96740e8d6d3657baebf881032,The markovchain Package: A Package for Easily Handling Discrete Markov Chains in R,"The markovchain package aims to ll a gap within the R framework providing S4 classes and methods for easily handling discrete time Markov chains, homogeneous and simple inhomogeneous ones. The S4 classes for handling and analysing discrete time Markov chains are presented, as well as functions and method for performing probabilistic and statistical analysis. Finally, some examples in which the package’s functions are applied to Economics, Finance and Natural Sciences topics are shown.",2013.0,64.0,63.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Spedicato2013TheMP,\n author = {G. Spedicato and M. Signorelli},\n title = {The markovchain Package: A Package for Easily Handling Discrete Markov Chains in R},\n year = {2013}\n}\n'}","[{'authorId': '49956982', 'name': 'G. Spedicato'}, {'authorId': '3433315', 'name': 'M. Signorelli'}]"
1649,8db3f00721e99b7bd44d7089d39641ae4b971bf3,Affect Dysregulation and Disorders of the Self,"Allan Schore has for some 15 years written about the processes underlying affect regulation in normal and abnormal self-development and attachment. His best known book entitled Affect Regulation and the Origin of the Self: The Neurobiology of Emotional Development, published in 1994, was the first coherent attempt to integrate the then recent findings of neurobiology with clinical observations in children and adults and brought down barriers that had impeded the understanding of the self and its disorders. In the present volume, Schore incorporates the vast amount of data from neurosciences since 1994 and presents the reader with a truly compelling theoretical synthesis of this literature. 
 
In part I, there are 4 chapters on developmental affective neuroscience. They deal with the contribution experience expectant vs. experience dependent phenomena make to the development of affect regulation. The former are primarily gene dependent (e.g., the CNS of a newborn is equipped to function well in infants who live within a reasonably safe environment and are exposed to gradual rather than violent changes) while the latter are dependent on the care taking practices the child is exposed to. One example cited is the affective transmissions in mutual gaze transactions between infants and their mothers. These affective parental responses are the first means by which mothers can provide a model of affect modulation to their infants (e.g., mother senses when her baby is becoming overstimulated and will respond by decreasing her own stimulation, leading to calming the infant). Such soothing behaviors will secondarily effect the maturation of the orbitofrontal cortex and strengthen its regulatory abilities. Attachment behavior is likewise based on the reciprocal activation of the couple’s endogenous opiate systems but also regulates the dopamine levels in the infant’s brain. Schore brings these and other interdisciplinary findings together by citing the available evidence and at times even presenting colored PET or fMRI scans to make his point. 
 
In part II, 5 chapters deal with developmental neuropsychiatric data and their relevance on development of the right brain, secure attachment relationships and on symptoms of PTSD, borderline and antisocial personality disorders. Here again, Schore cites studies that explain important psychological processes through neuropsychiatric data. For example, he cites evidence that in the context of face-to-face interactions, mothers trigger production of corticotropin releasing factor (CRF) in their infants. The CRF, in turn raises the concentration of noradrenaline, increasing general energy metabolism but also controls endorphin and ACTH. production, leading to an elated state in the infant. 
 
When it comes to PTSD and other well-defined psychiatric disorders, the overall picture becomes more complicated. For example, Schore claims that PTSD is related to the inability of the right prefrontal cortex to sufficiently modulate amygdala (i.e., aggressive) functions. The fact that this also occurs in children with a disorganized disoriented insecure attachment pattern is then seen as proof that this particular early maternal caretaking pattern contributes to later dissociative psychopathology. One could counter that proposition by pointing out that elevated cortisol levels are important for overall stress management – but that prenatally elevated levels, especially in the third trimester of pregnancy, have been found to be especially pathogenic as they effect the developing brain at its most critical time. However, high cortisol levels can be caused by a variety of conditions. Intra-uterine growth retardation (IUGR) is a common condition associated in children born with ‘small gestational age’ (SGA). It is innately stressful for the infant, hence associated with elevated prenatal cortisol levels that are not associated to later maternal attachment patterns. Aggressive behavior disorders are also described as a consequence of a right brain system impaired for regulating aggressive affective states. Here it is said to be the low arousal state characteristic for antisocial and aggressive individuals that such individuals try to increase back to optimal or normal levels by seeking stimulation. While this may be one pathway leading to aggressive behavior disorders, there are authors such as Tremblay and colleagues in Montreal who claim that all young children are highly aggressive and must “unlearn” this behavior in the process of development. Those who do not or cannot do so will make up our clinical population. 
 
In summary, the present volume of Allan Schore provides the reader with a provocative and stimulating theoretical synthesis of multi-disciplinary work that relates affect regulation to the development of the self and its deviations. Schore’s writing style is almost poetic and transforms potentially dry data into an exciting story of discovery and multidisciplinary dependency. He also suggests, at least indirectly, preventive measures that can address the problem of violence and other dysfunctions of the developing self in children through optimal early social-emotional experiences. I highly recommend this volume to researchers and clinicians.",2006.0,0.0,550.0,False,,"{'volume': '15', 'pages': '100-101', 'name': ""Journal de l'Académie canadienne de psychiatrie de l'enfant et de l'adolescent""}","{'bibtex': ""@Article{Minde2006AffectDA,\n author = {K. Minde},\n journal = {Journal de l'Académie canadienne de psychiatrie de l'enfant et de l'adolescent},\n pages = {100-101},\n title = {Affect Dysregulation and Disorders of the Self},\n volume = {15},\n year = {2006}\n}\n""}","[{'authorId': '48017979', 'name': 'K. Minde'}]"
1650,8db7bb4fcad6b6cb8fc348a7879397ae0bffe726,An exploratory study of how pre-kindergarten children use the interactive multimedia technology: implications for multimedia software design,,1996.0,0.0,47.0,False,,"{'volume': '7', 'pages': '71-92', 'name': 'Journal of Computing in Childhood Education archive'}","{'bibtex': '@Article{Liu1996AnES,\n author = {Min Liu},\n journal = {Journal of Computing in Childhood Education archive},\n pages = {71-92},\n title = {An exploratory study of how pre-kindergarten children use the interactive multimedia technology: implications for multimedia software design},\n volume = {7},\n year = {1996}\n}\n'}","[{'authorId': '71103094', 'name': 'Min Liu'}]"
1651,8e1f18632ae699ef049559a1f22c21813b27dc56,Gesture Synthesis in a Real-World ECA,,2004.0,5.0,4.0,False,,{'pages': '319-322'},"{'bibtex': '@Inproceedings{Olivier2004GestureSI,\n author = {P. Olivier},\n pages = {319-322},\n title = {Gesture Synthesis in a Real-World ECA},\n year = {2004}\n}\n'}","[{'authorId': '145171812', 'name': 'P. Olivier'}]"
1652,8e218630f62acb0178a250aa16aa3b33593d9e72,The functional architecture of human empathy.,"Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.",2004.0,307.0,2514.0,False,,"{'volume': '3 2', 'pages': '\n          71-100\n        ', 'name': 'Behavioral and cognitive neuroscience reviews'}","{'bibtex': '@Article{Decety2004TheFA,\n author = {J. Decety and P. Jackson},\n journal = {Behavioral and cognitive neuroscience reviews},\n pages = {\n          71-100\n        },\n title = {The functional architecture of human empathy.},\n volume = {3 2},\n year = {2004}\n}\n'}","[{'authorId': '3235030', 'name': 'J. Decety'}, {'authorId': '6079112', 'name': 'P. Jackson'}]"
1653,8e22ec85bc06686e5b6c4f0db0e2d27ef98e95f1,The development of empathy in twins.,"This study examined empathy in 94 monozygotic (MZ) and 90 dizygotic (DZ) twin pairs during the 2nd year of life. Children's reactions to simulations of distress in others were videotaped in home and laboratory settings. Some components of concern for others increased with age between 14 and 20 months for both MZ and DZ twins. Girls scored higher than boys on most of these observational measures. The different components (e.g., emotional concern, prosocial acts, and cognitive exploration) showed substantial coherence and low but significant stability over time. There was modest evidence for heritability of empathy, particularly for the affective component. Maternal reports of prosocial orientations indicated both genetic and environmental influences",1992.0,39.0,465.0,False,,"{'volume': '28', 'pages': '1038-1047', 'name': 'Developmental Psychology'}","{'bibtex': '@Article{Zahn-Waxler1992TheDO,\n author = {C. Zahn-Waxler and Joann L. Robinson and R. Emde},\n journal = {Developmental Psychology},\n pages = {1038-1047},\n title = {The development of empathy in twins.},\n volume = {28},\n year = {1992}\n}\n'}","[{'authorId': '1398158374', 'name': 'C. Zahn-Waxler'}, {'authorId': '145084432', 'name': 'Joann L. Robinson'}, {'authorId': '4828311', 'name': 'R. Emde'}]"
1654,8e5bc818596440d44dc6b6e2c75500f8bf3d8b81,HAPA: Harvester and Pedagogical Agents in E-learning Environments,"In the field of e-learning and tutoring systems two categories of soft- ware agents are of the special interest: harvester and pedagogical agents. This paper proposes a novel e-learning system that successfully combines both of these agent categories and introduces two distinct sub-types of pedagogical agents helpful and misleading. Whereas helpful agents provide the correct guidance for the given prob- lem, misleading agents try to guide the learning process in the wrong direction by offering false hints and inadequate solutions. The rationale behind this approach is to motivate students not to trust the agent's instructions blindly, but to employ critical thinking. Consequently, students will be put in a ""softly stressed"" environment in or- der to prepare them for real working environments in their future work in companies. Nevertheless students themselves will decide on the correct solution to the problem in question.",2015.0,19.0,10.0,True,"{'url': 'https://univagora.ro/jour/index.php/ijccc/article/download/1753/493', 'status': None}","{'volume': '10', 'pages': '200-210', 'name': 'Int. J. Comput. Commun. Control'}","{'bibtex': '@Article{Ivanović2015HAPAHA,\n author = {M. Ivanović and Dejan Mitrovic and Z. Budimac and Ljubomir Jerinic and C. Bǎdicǎ},\n journal = {Int. J. Comput. Commun. Control},\n pages = {200-210},\n title = {HAPA: Harvester and Pedagogical Agents in E-learning Environments},\n volume = {10},\n year = {2015}\n}\n'}","[{'authorId': '144395551', 'name': 'M. Ivanović'}, {'authorId': '34664252', 'name': 'Dejan Mitrovic'}, {'authorId': '1712090', 'name': 'Z. Budimac'}, {'authorId': '1827143', 'name': 'Ljubomir Jerinic'}, {'authorId': '1740341', 'name': 'C. Bǎdicǎ'}]"
1655,8e5d7405ece81f0ac9fcb4574e53bf0c827e9ad7,Interpersonal emotion regulation.,"Contemporary emotion regulation research emphasizes intrapersonal processes such as cognitive reappraisal and expressive suppression, but people experiencing affect commonly choose not to go it alone. Instead, individuals often turn to others for help in shaping their affective lives. How and under what circumstances does such interpersonal regulation modulate emotional experience? Although scientists have examined allied phenomena such as social sharing, empathy, social support, and prosocial behavior for decades, there have been surprisingly few attempts to integrate these data into a single conceptual framework of interpersonal regulation. Here we propose such a framework. We first map a ""space"" differentiating classes of interpersonal regulation according to whether an individual uses an interpersonal regulatory episode to alter their own or another person's emotion. We then identify 2 types of processes--response-dependent and response-independent--that could support interpersonal regulation. This framework classifies an array of processes through which interpersonal contact fulfills regulatory goals. More broadly, it organizes diffuse, heretofore independent data on ""pieces"" of interpersonal regulation, and identifies growth points for this young and exciting research domain.",2013.0,105.0,672.0,False,,"{'volume': '13 5', 'pages': '\n          803-10\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Zaki2013InterpersonalER,\n author = {Jamil Zaki and W. C. Williams},\n journal = {Emotion},\n pages = {\n          803-10\n        },\n title = {Interpersonal emotion regulation.},\n volume = {13 5},\n year = {2013}\n}\n'}","[{'authorId': '2268731', 'name': 'Jamil Zaki'}, {'authorId': '2055993791', 'name': 'W. C. Williams'}]"
1657,8e84a4033494d51c100d7736090ee18e2899bb75,"Facial asymmetry during emotional expression: Gender, valence, and measurement technique",,1998.0,53.0,108.0,False,,"{'volume': '36', 'pages': '1209-1215', 'name': 'Neuropsychologia'}","{'bibtex': '@Article{Borod1998FacialAD,\n author = {J. Borod and E. Koff and Sandra Yecker and C. Santschi and J. Schmidt},\n journal = {Neuropsychologia},\n pages = {1209-1215},\n title = {Facial asymmetry during emotional expression: Gender, valence, and measurement technique},\n volume = {36},\n year = {1998}\n}\n'}","[{'authorId': '3149424', 'name': 'J. Borod'}, {'authorId': '5126201', 'name': 'E. Koff'}, {'authorId': '4914778', 'name': 'Sandra Yecker'}, {'authorId': '38990539', 'name': 'C. Santschi'}, {'authorId': '2113420700', 'name': 'J. Schmidt'}]"
1658,8e9f3511c1b9bb9bc8d9573df1085c402de87ab6,Let's talk! Socially intelligent agents for language conversation training,"This paper promotes socially intelligent animated agents for the pedagogical task of English conversation training for native speakers of Japanese. As a novel feature, social role awareness is introduced to animated conversational agents, that are by non-strong affective reasoners, but otherwise often lack the social competence observed in humans. In particular, humans may easily adjust their behavior depending on their respective role in a social setting, whereas their synthetic pendants tend to be driven mostly by emotions and personality. Our main contribution is the incorporation of a ""social filter program"" to mental models of animated agents. This program may qualify an agent's expression of its emotional state by the social contest, thereby enhancing the agent's believability as a conversational partner. Our implemented system is web-based and demonstrates socially aware animated agents in a virtual coffee shop environment. An experiment with our conversation system shows that users consider socially aware agents as more natural than agents that violate conventional practices.",2001.0,52.0,57.0,True,"{'url': 'http://research.nii.ac.jp/~prendinger/papers/helmut-ieee-smc01.pdf', 'status': None}","{'volume': '31', 'pages': '465-471', 'name': 'IEEE Trans. Syst. Man Cybern. Part A'}","{'bibtex': ""@Article{Prendinger2001LetsTS,\n author = {H. Prendinger and M. Ishizuka},\n journal = {IEEE Trans. Syst. Man Cybern. Part A},\n pages = {465-471},\n title = {Let's talk! Socially intelligent agents for language conversation training},\n volume = {31},\n year = {2001}\n}\n""}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
1659,8ea96dd631a74655461b3c95580c8a18c11daf0c,Hand and Mind: What Gestures Reveal about Thought,"What is the relation between gestures and speech? In terms of symbolic forms, of course, the spontaneous and unwitting gestures we make while talking differ sharply from spoken language itself. Whereas spoken language is linear, segmented, standardized, and arbitrary, gestures are global, synthetic, idiosyncratic, and imagistic. In Hand and Mind, David McNeill presents a bold theory of the essential unity of speech and the gestures that accompany it. This long-awaited, provocative study argues that the unity of gestures and language far exceeds the surface level of speech noted by previous researchers and in fact also includes the semantic and pragmatic levels of language. In effect, the whole concept of language must be altered to take into account the nonsegmented, instantaneous, and holistic images conveyed by gestures. McNeill and his colleagues carefully devised a standard methodology for examining the speech and gesture behavior of individuals engaged in narrative discourse. A research subject is shown a cartoon like the 1950 Canary Row--a classic Sylvester and Tweedy Bird caper that features Sylvester climbing up a downspout, swallowing a bowling ball and slamming into a brick wall. After watching the cartoon, the subject is videotaped recounting the story from memory to a listener who has not seen the cartoon. Painstaking analysis of the videotapes revealed that although the research subjects--children as well as adults, some neurologically impaired--represented a wide variety of linguistic groupings, the gestures of people speaking English and a half dozen other languages manifest the same principles. Relying on data from more than ten years of research, McNeill shows thatgestures do not simply form a part of what is said and meant but have an impact on thought itself. He persuasively argues that because gestures directly transfer mental images to visible forms, conveying ideas that language cannot always express, we must examine language and gesture",1992.0,0.0,2038.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{McNeill1992HandAM,\n author = {D. McNeill},\n title = {Hand and Mind: What Gestures Reveal about Thought},\n year = {1992}\n}\n'}","[{'authorId': '145493778', 'name': 'D. McNeill'}]"
1660,8eb1d7ec4a3a6459cd9c6b57b2ed7a714d8821a8,The Virtual reality electrical substation field trip: Exploring student perceptions and cognitive learning,"COVID19 has disrupted many higher education's learning experiences, including those related to work integrated learning. This included the cancelling of the annual electrical engineering field trip to a local electrical substation. Field trips provides students an opportunity to connect their classroom learning with industry relevant engaging experiences. While virtual reality (VR) alternatives to electrical substations have been implemented and researched, the focus has been on the innovation and not on the educational benefits. The impact on learning is not well documented and understood. To address this gap an experimental study is conducted on fifty electrical engineering students at the University of Wollongong to determine if a VR replica of an electrical substation can provide an equal or better learning and student experience compared to traditional methods. A successful finding would provide confidence to implement such alternatives for situations that include: addressing COVID disruptions; for students that miss the field trip; and for providers that don't have the funds or resources to visit a substation. It was found that the VR substation simulation provided a comparable student experience and stronger cognitive learning benefits than traditional methods. Further research is needed to explore learning impact beyond the cognitive domain.",2021.0,32.0,5.0,True,,{'name': 'STEM Education'},"{'bibtex': '@Article{Memik2021TheVR,\n author = {Erdem Memik and S. Nikolic},\n journal = {STEM Education},\n title = {The Virtual reality electrical substation field trip: Exploring student perceptions and cognitive learning},\n year = {2021}\n}\n'}","[{'authorId': '2090245328', 'name': 'Erdem Memik'}, {'authorId': '33511946', 'name': 'S. Nikolic'}]"
1661,8eda29168c49a7b18b45b024c152becda4410215,Social cognition in schizophrenia: recommendations from the measurement and treatment research to improve cognition in schizophrenia new approaches conference.,"This article summarizes the discussion from a breakout group at the National Institute of Mental Health-Measurement and Treatment Research to Improve Cognition in Schizophrenia New Approaches Conference on social cognition in schizophrenia. During this discussion, the reasons for the recent growth of research on social cognition in schizophrenia were examined. The discussion group established consensus on several points, including the importance of viewing social cognition from interdisciplinary perspectives (including outcomes research, social psychology, cognitive psychology, cognitive neuroscience, and animal models) and the need for clearer definition of terms. There was also general agreement that social cognition is a valuable construct for understanding the nature and disability of schizophrenia. One of the objectives of this group was to generate recommendations for subsequent human and animal studies, and these research agendas are summarized in this report.",2005.0,60.0,452.0,True,"{'url': 'https://academic.oup.com/schizophreniabulletin/article-pdf/31/4/882/5308850/sbi049.pdf', 'status': None}","{'volume': '31 4', 'pages': '\n          882-7\n        ', 'name': 'Schizophrenia bulletin'}","{'bibtex': '@Article{Green2005SocialCI,\n author = {Michael F. Green and B. Olivier and J. Crawley and D. Penn and S. Silverstein},\n journal = {Schizophrenia bulletin},\n pages = {\n          882-7\n        },\n title = {Social cognition in schizophrenia: recommendations from the measurement and treatment research to improve cognition in schizophrenia new approaches conference.},\n volume = {31 4},\n year = {2005}\n}\n'}","[{'authorId': '2237562932', 'name': 'Michael F. Green'}, {'authorId': '71878805', 'name': 'B. Olivier'}, {'authorId': '3208524', 'name': 'J. Crawley'}, {'authorId': '2451983', 'name': 'D. Penn'}, {'authorId': '48582269', 'name': 'S. Silverstein'}]"
1662,8eed8a4154239d39cd58afef67673d3488c9c2e9,Emotional mimicry: why and when we mimic emotions,"The goal of this review was to provide a brief overview of recent developments in the domain of emotional mimicry research. We argue that emotional signals are intrinsically meaningful within a social relationship, which is crucial for understanding the functionality and boundary conditions of emotional mimicry. On the basis of a review of the literature on facial mimicry of emotion displays, we conclude that the classic matched motor hypothesis does not hold for emotional mimicry. We alternatively propose a contextual view of emotional mimicry, which states that emotional mimicry depends on the social context: we only mimic emotional signals that are interpreted to promote affiliation goals and not necessarily what we see. As a further consequence, we are less likely to mimic strangers and we do not mimic people we do not like nor emotions that signal antagonism.",2014.0,72.0,234.0,False,,"{'volume': '8', 'pages': '45-57', 'name': 'Social and Personality Psychology Compass'}","{'bibtex': '@Article{Hess2014EmotionalMW,\n author = {U. Hess and A. Fischer},\n journal = {Social and Personality Psychology Compass},\n pages = {45-57},\n title = {Emotional mimicry: why and when we mimic emotions},\n volume = {8},\n year = {2014}\n}\n'}","[{'authorId': '3067657', 'name': 'U. Hess'}, {'authorId': '7444483', 'name': 'A. Fischer'}]"
1663,8eef62972d27bd54e9744cda44aa3938a732221a,Functional grouping and cortical–subcortical interactions in emotion: A meta-analysis of neuroimaging studies,,2008.0,370.0,1019.0,True,"{'url': 'https://europepmc.org/articles/pmc2752702?pdf=render', 'status': None}","{'volume': '42', 'pages': '998-1031', 'name': 'NeuroImage'}","{'bibtex': '@Article{Kober2008FunctionalGA,\n author = {H. Kober and L. F. Barrett and Joshua W. Joseph and E. Bliss-Moreau and Kristen A. Lindquist and T. Wager},\n journal = {NeuroImage},\n pages = {998-1031},\n title = {Functional grouping and cortical–subcortical interactions in emotion: A meta-analysis of neuroimaging studies},\n volume = {42},\n year = {2008}\n}\n'}","[{'authorId': '1693653', 'name': 'H. Kober'}, {'authorId': '1731779', 'name': 'L. F. Barrett'}, {'authorId': '2052441460', 'name': 'Joshua W. Joseph'}, {'authorId': '1398003816', 'name': 'E. Bliss-Moreau'}, {'authorId': '2593387', 'name': 'Kristen A. Lindquist'}, {'authorId': '2549424', 'name': 'T. Wager'}]"
1664,8ef763cb4f13f8dc9d4376b5ad8f377331e8572d,Deep Convolutional Neural Networks for Large-scale Speech Tasks,,2015.0,33.0,444.0,False,,"{'volume': '64', 'pages': '\n          39-48\n        ', 'name': 'Neural networks : the official journal of the International Neural Network Society'}","{'bibtex': '@Article{Sainath2015DeepCN,\n author = {Tara N. Sainath and Brian Kingsbury and G. Saon and H. Soltau and Abdel-rahman Mohamed and George E. Dahl and B. Ramabhadran},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          39-48\n        },\n title = {Deep Convolutional Neural Networks for Large-scale Speech Tasks},\n volume = {64},\n year = {2015}\n}\n'}","[{'authorId': '1784851', 'name': 'Tara N. Sainath'}, {'authorId': '144707379', 'name': 'Brian Kingsbury'}, {'authorId': '1698208', 'name': 'G. Saon'}, {'authorId': '38940652', 'name': 'H. Soltau'}, {'authorId': '40360972', 'name': 'Abdel-rahman Mohamed'}, {'authorId': '35188630', 'name': 'George E. Dahl'}, {'authorId': '1720857', 'name': 'B. Ramabhadran'}]"
1665,8efa621359c3f5491f278e20915550502e3a224c,A taxonomy of machine learning applications for virtual power plants and home/building energy management systems,,2022.0,156.0,20.0,True,,{'name': 'Automation in Construction'},"{'bibtex': '@Article{Sierla2022ATO,\n author = {S. Sierla and M. Pourakbari‐Kasmaei and V. Vyatkin},\n journal = {Automation in Construction},\n title = {A taxonomy of machine learning applications for virtual power plants and home/building energy management systems},\n year = {2022}\n}\n'}","[{'authorId': '1777045', 'name': 'S. Sierla'}, {'authorId': '1403699330', 'name': 'M. Pourakbari‐Kasmaei'}, {'authorId': '144958974', 'name': 'V. Vyatkin'}]"
1666,8f089b968032e11b2d50c1b3c7404433241227e6,Self-attachment : A self-administrable intervention for chronic anxiety and depression ∗,"There has been increasing evidence to suggest that the root cause of much mental illness lies in a sub-optimal capacity for affect regulation. Cognition and emotion are intricately linked and cognitive deficits, which are characteristic of many psychiatric conditions, are often driven by affect dysregulation, which itself can usually be traced back to sub-optimal childhood development as supported by Attachment Theory. Individuals with insecure attachment types in their childhoods are prone to a variety of mental illness, whereas a secure attachment type in childhood provides a secure base in life. We therefore propose a holistic approach to tackle chronic anxiety and depression, typical of Axis II clinical disorders, which is informed by the development of the infant brain in social interaction with its primary care-givers. We formulate, in a self-administrable way, the protocols governing the interaction of a securely attached child with its primary care-givers that produce the capacity for affect regulation in the child. We posit that these protocols construct, by neuroplasticity and long term potentiation, new optimal neural pathways in the brains of adults with insecure childhood attachment that suffer from mental disorder. This procedure is called self-attachment and aims to help the individuals to create their own attachment objects in the form of their adult self looking after their inner child.",2017.0,34.0,6.0,False,,,"{'bibtex': '@Inproceedings{Edalat2017SelfattachmentA,\n author = {A. Edalat},\n title = {Self-attachment : A self-administrable intervention for chronic anxiety and depression ∗},\n year = {2017}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}]"
1667,8f12d0e8f154501e43932cb249446a922a3d5cd4,Emotion Capture: Emotionally Expressive Characters for Games,"It has been shown that humans are sensitive to the portrayal of emotions for virtual characters. However, previous work in this area has often examined this sensitivity using extreme examples of facial or body animation. Less is known about how attuned people are at recognizing emotions as they are expressed during conversational communication. In order to determine whether body or facial motion is a better indicator for emotional expression for game characters, we conduct a perceptual experiment using synchronized full-body and facial motion-capture data. We find that people can recognize emotions from either modality alone, but combining facial and body motion is preferable in order to create more expressive characters.",2013.0,25.0,31.0,False,,{'name': 'Proceedings of Motion on Games'},"{'bibtex': '@Article{Ennis2013EmotionCE,\n author = {Cathy Ennis and Ludovic Hoyet and A. Egges and R. Mcdonnell},\n journal = {Proceedings of Motion on Games},\n title = {Emotion Capture: Emotionally Expressive Characters for Games},\n year = {2013}\n}\n'}","[{'authorId': '31894925', 'name': 'Cathy Ennis'}, {'authorId': '1869571', 'name': 'Ludovic Hoyet'}, {'authorId': '2479558', 'name': 'A. Egges'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
1669,8f14c00079c601a95b7b0403e42653dedbc4e6c2,Deep Bi-Directional LSTM Network for Query Intent Detection,,2018.0,2.0,24.0,True,,"{'volume': '143', 'pages': '939-946', 'name': 'Procedia Computer Science'}","{'bibtex': '@Article{Sreelakshmi2018DeepBL,\n author = {K. Sreelakshmi and P. C. Rafeeque and S. Sreetha and E. S. Gayathri},\n journal = {Procedia Computer Science},\n pages = {939-946},\n title = {Deep Bi-Directional LSTM Network for Query Intent Detection},\n volume = {143},\n year = {2018}\n}\n'}","[{'authorId': '2065597068', 'name': 'K. Sreelakshmi'}, {'authorId': '9328378', 'name': 'P. C. Rafeeque'}, {'authorId': '2102687511', 'name': 'S. Sreetha'}, {'authorId': '2082825798', 'name': 'E. S. Gayathri'}]"
1670,8f311992038db87b7fe2f750f272c948d00d35ce,"Warmth, Competence, Believability and Virtual Agents",,2010.0,25.0,38.0,False,,{'pages': '272-285'},"{'bibtex': '@Inproceedings{Niewiadomski2010WarmthCB,\n author = {Radoslaw Niewiadomski and Virginie Demeure and C. Pelachaud},\n pages = {272-285},\n title = {Warmth, Competence, Believability and Virtual Agents},\n year = {2010}\n}\n'}","[{'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '2539387', 'name': 'Virginie Demeure'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1671,8f7c3e8dc7aef0a7b9ad70911ffc4d181349273e,Same situation--different emotions: how appraisals shape our emotions.,"Appraisal theories of emotion hold that it is the way a person interprets a situation--rather than the situation itself--that gives rise to one emotion rather than another emotion (or no emotion at all). Unfortunately, most prior tests of this foundational hypothesis have simultaneously varied situations and appraisals, making an evaluation of this assumption difficult. In the present study, participants responded to a standardized laboratory situation with a variety of different emotions. Appraisals predicted the intensity of individual emotions across participants. In addition, subgroups of participants with similar emotional response profiles made comparable appraisals. Together, these findings suggest that appraisals may be necessary and sufficient to determine different emotional reactions toward a particular situation.",2007.0,45.0,333.0,False,,"{'volume': '7 3', 'pages': '\n          592-600\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Siemer2007SameSE,\n author = {M. Siemer and I. Mauss and J. Gross},\n journal = {Emotion},\n pages = {\n          592-600\n        },\n title = {Same situation--different emotions: how appraisals shape our emotions.},\n volume = {7 3},\n year = {2007}\n}\n'}","[{'authorId': '4125928', 'name': 'M. Siemer'}, {'authorId': '2172628', 'name': 'I. Mauss'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
1672,8fa322274600d7500c235ef4b96e9e553c0293ee,An Emotion Contagion Simulation Model for Crowd Events,,2013.0,0.0,17.0,False,,"{'volume': '50', 'pages': '2578', 'name': 'Journal of Computer Research and Development'}","{'bibtex': '@Article{Zhen2013AnEC,\n author = {Liu Zhen and Jin Wei and Huang Peng and Chai Yanjie},\n journal = {Journal of Computer Research and Development},\n pages = {2578},\n title = {An Emotion Contagion Simulation Model for Crowd Events},\n volume = {50},\n year = {2013}\n}\n'}","[{'authorId': '2059085302', 'name': 'Liu Zhen'}, {'authorId': '2111523862', 'name': 'Jin Wei'}, {'authorId': '2140198344', 'name': 'Huang Peng'}, {'authorId': '104114672', 'name': 'Chai Yanjie'}]"
1673,8fc354164f6f80beac3696e389d5bba741b6b698,Theodor Lipps and the concept of empathy: 1851-1914.,,2008.0,0.0,60.0,False,,"{'volume': '165 10', 'pages': '\n          1261\n        ', 'name': 'The American journal of psychiatry'}","{'bibtex': '@Article{Montag2008TheodorLA,\n author = {C. Montag and J. Gallinat and A. Heinz},\n journal = {The American journal of psychiatry},\n pages = {\n          1261\n        },\n title = {Theodor Lipps and the concept of empathy: 1851-1914.},\n volume = {165 10},\n year = {2008}\n}\n'}","[{'authorId': '2720403', 'name': 'C. Montag'}, {'authorId': '2248997', 'name': 'J. Gallinat'}, {'authorId': '50665590', 'name': 'A. Heinz'}]"
1674,8ffe2d688a041f9caa3e9cfa0432704003011ae1,Economic and Social Perspectives of Immigrant Children in Germany,"Overall, children in Germany live in households with below average incomes; therefore social policies that address the vulnerable position of Germany’s children are necessary. These policies should cover targeted financial transfers as well as improvements in day care provision for children. With respect to selected non-monetary as well as monetary indicators our empirical analyses show significant differences in current living conditions between native born German children and those born to immigrants of German descent and foreign origin persons. Education is a key indicator for future economic and social perspectives. In principle, there is no formal ""discrimination"" of immigrant children by the German school system. However, low educational attainment levels are still being transferred from one immigrant generation to the next. The net result is that children of immigrants are not able to close the educational gap between themselves and their native German counterparts. The probable long-term consequence will be a large number of poorly qualified persons in the work force, who are much more likely to face severe labor market problems and as such will be a problem for the German economy as a whole for many years to come.",2001.0,26.0,53.0,True,"{'url': 'https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fdocs.iza.org%2Fdp301.pdf;h=repec:iza:izadps:dp301', 'status': None}",{'name': 'Public Economics eJournal'},"{'bibtex': '@Article{Frick2001EconomicAS,\n author = {J. Frick and Gert G. Wagner},\n journal = {Public Economics eJournal},\n title = {Economic and Social Perspectives of Immigrant Children in Germany},\n year = {2001}\n}\n'}","[{'authorId': '37211748', 'name': 'J. Frick'}, {'authorId': '2088678541', 'name': 'Gert G. Wagner'}]"
1675,90171eabf908b7517b668158d116405acb574a77,How arousal modulates memory: Disentangling the effects of attention and retention,,2004.0,72.0,342.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/CABN.4.3.294.pdf', 'status': None}","{'volume': '4', 'pages': '294-306', 'name': 'Cognitive, Affective, & Behavioral Neuroscience'}","{'bibtex': '@Article{Sharot2004HowAM,\n author = {T. Sharot and E. Phelps},\n journal = {Cognitive, Affective, & Behavioral Neuroscience},\n pages = {294-306},\n title = {How arousal modulates memory: Disentangling the effects of attention and retention},\n volume = {4},\n year = {2004}\n}\n'}","[{'authorId': '5586879', 'name': 'T. Sharot'}, {'authorId': '2471431', 'name': 'E. Phelps'}]"
1676,903ec87f1eb8759520feecaf4a719608fa761e58,Slot-Gated Modeling for Joint Slot Filling and Intent Prediction,"Attention-based recurrent neural network models for joint intent detection and slot filling have achieved the state-of-the-art performance, while they have independent attention weights. Considering that slot and intent have the strong relationship, this paper proposes a slot gate that focuses on learning the relationship between intent and slot attention vectors in order to obtain better semantic frame results by the global optimization. The experiments show that our proposed model significantly improves sentence-level semantic frame accuracy with 4.2% and 1.9% relative improvement compared to the attentional model on benchmark ATIS and Snips datasets respectively",2018.0,13.0,393.0,True,"{'url': 'https://www.aclweb.org/anthology/N18-2118.pdf', 'status': None}",{'pages': '753-757'},"{'bibtex': '@Inproceedings{Goo2018SlotGatedMF,\n author = {Chih-Wen Goo and Guang-Lai Gao and Yun-Kai Hsu and Chih-Li Huo and Tsung-Chieh Chen and Keng-Wei Hsu and Yun-Nung (Vivian) Chen},\n pages = {753-757},\n title = {Slot-Gated Modeling for Joint Slot Filling and Intent Prediction},\n year = {2018}\n}\n'}","[{'authorId': '46178179', 'name': 'Chih-Wen Goo'}, {'authorId': '30725803', 'name': 'Guang-Lai Gao'}, {'authorId': '3176770', 'name': 'Yun-Kai Hsu'}, {'authorId': '2818470', 'name': 'Chih-Li Huo'}, {'authorId': '2110505230', 'name': 'Tsung-Chieh Chen'}, {'authorId': '31294636', 'name': 'Keng-Wei Hsu'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}]"
1677,903f775ed97cb26ad9998eeb44a9a2269af20221,Inside Out,"Confusion is an emotion that is likely to occur while learning complex information. This emotion can be beneficial to learners in that it can foster engagement, leading to deeper understanding. However, if learners fail to resolve confusion, its effect can be detrimental to learning. Such detrimental learning experiences are particularly concerning within digital learning environments (DLEs), where a teacher is not physically present to monitor learner engagement and adapt the learning experience accordingly. However, with better information about a learner’s emotion and behavior, it is possible to improve the design of interactive DLEs (IDLEs) not only in promoting productive confusion but also in preventing overwhelming confusion. This article reviews different methodological approaches for detecting confusion, such as self-report and behavioral and physiological measures, and discusses their implications within the theoretical framework of a zone of optimal confusion. The specificities of several methodologies and their potential application in IDLEs are discussed.",2017.0,96.0,45.0,True,"{'url': 'https://opus.lib.uts.edu.au/bitstream/10453/124968/4/Inside_Out_preprint.pdf', 'status': None}","{'volume': '55', 'pages': '526 - 551', 'name': 'Journal of Educational Computing Research'}","{'bibtex': '@Article{Arguel2017InsideO,\n author = {A. Arguel and Lori Lockyer and O. Lipp and J. Lodge and G. Kennedy},\n journal = {Journal of Educational Computing Research},\n pages = {526 - 551},\n title = {Inside Out},\n volume = {55},\n year = {2017}\n}\n'}","[{'authorId': '2896194', 'name': 'A. Arguel'}, {'authorId': '2843881', 'name': 'Lori Lockyer'}, {'authorId': '143621789', 'name': 'O. Lipp'}, {'authorId': '46515199', 'name': 'J. Lodge'}, {'authorId': '2896323', 'name': 'G. Kennedy'}]"
1678,90939730f7fb66d1abfb218a4848b1914aa67ac2,Developmental differences in children’s interpersonal emotion regulation,,2016.0,78.0,14.0,True,"{'url': 'http://hira.hope.ac.uk/id/eprint/1678/1/Lopez-Perez%2C%20Wilson%2C%20Dellaria%2C%20%26%20Gummerum%2C%202016.pdf', 'status': None}","{'volume': '40', 'pages': '767 - 780', 'name': 'Motivation and Emotion'}","{'bibtex': '@Article{López-Pérez2016DevelopmentalDI,\n author = {B. López-Pérez and Ellie L. Wilson and Giulia Dellaria and M. Gummerum},\n journal = {Motivation and Emotion},\n pages = {767 - 780},\n title = {Developmental differences in children’s interpersonal emotion regulation},\n volume = {40},\n year = {2016}\n}\n'}","[{'authorId': '1402994497', 'name': 'B. López-Pérez'}, {'authorId': '6614376', 'name': 'Ellie L. Wilson'}, {'authorId': '6316463', 'name': 'Giulia Dellaria'}, {'authorId': '4734400', 'name': 'M. Gummerum'}]"
1679,90c5b176532d09309951d84fef8dc7be19fe959c,"Emotion regulation, emotion recognition, and empathy in adolescents with anorexia nervosa",,2019.0,55.0,25.0,False,,"{'pages': '1 - 10', 'name': 'Eating and Weight Disorders - Studies on Anorexia, Bulimia and Obesity'}","{'bibtex': '@Article{Nalbant2019EmotionRE,\n author = {Kevser Nalbant and Bilge Merve Kalaycı and D. Akdemir and Sinem Akgül and N. Kanbur},\n journal = {Eating and Weight Disorders - Studies on Anorexia, Bulimia and Obesity},\n pages = {1 - 10},\n title = {Emotion regulation, emotion recognition, and empathy in adolescents with anorexia nervosa},\n year = {2019}\n}\n'}","[{'authorId': '11730843', 'name': 'Kevser Nalbant'}, {'authorId': '50878908', 'name': 'Bilge Merve Kalaycı'}, {'authorId': '4240280', 'name': 'D. Akdemir'}, {'authorId': '6263479', 'name': 'Sinem Akgül'}, {'authorId': '4101233', 'name': 'N. Kanbur'}]"
1680,90db6006ddcb063af6fd42c70c7e7f91bbe61301,An Agent-Based Intervention to Assist Drivers Under Stereotype Threat: Effects of In-Vehicle Agents' Attributional Error Feedback,"For members of a group negatively stereotyped in a domain, making mistakes can aggravate the influence of stereotype threat because negative stereotypes often blame target individuals and attribute the outcome to their lack of ability. Virtual agents offering real-time error feedback may influence performance under stereotype threat by shaping the performers' attributional perception of errors they commit. We explored this possibility with female drivers, considering the prevalence of the ""women-are-bad-drivers"" stereotype. Specifically, we investigated how in-vehicle voice agents offering error feedback based on responsibility attribution (internal vs. external) and outcome attribution (ability vs. effort) influence female drivers' performance under stereotype threat. In addressing this question, we conducted an experiment in a virtual driving simulation environment that provided moment-to-moment error feedback messages. Participants performed a challenging driving task and made mistakes preprogrammed to occur. Results showed that the agent's error feedback with outcome attribution moderated the stereotype threat effect on driving performance. Participants under stereotype threat had a smaller number of collisions when the errors were attributed to effort than to ability. In addition, outcome attribution feedback moderated the effect of responsibility attribution on driving performance. Implications of these findings are discussed.",2016.0,41.0,3.0,False,,"{'volume': '19 10', 'pages': '\n          615-620\n        ', 'name': 'Cyberpsychology, behavior and social networking'}","{'bibtex': ""@Article{Joo2016AnAI,\n author = {Yeon Kyoung Joo and Roselyn J. Lee-Won},\n journal = {Cyberpsychology, behavior and social networking},\n pages = {\n          615-620\n        },\n title = {An Agent-Based Intervention to Assist Drivers Under Stereotype Threat: Effects of In-Vehicle Agents' Attributional Error Feedback},\n volume = {19 10},\n year = {2016}\n}\n""}","[{'authorId': '3136128', 'name': 'Yeon Kyoung Joo'}, {'authorId': '1401571040', 'name': 'Roselyn J. Lee-Won'}]"
1681,90edb80e8687b1ee18883c8795aa1e5767afe581,Special Track on Affective Computing,"This special track will serve as a forum to unite researchers from the interdisciplinary arena that encompasses computer science, engineering, HCI, psychology, and education to exchange ideas, frameworks, methods, and tools relating to affective computing. Although the last decade has been ripe with theory and applications relevant to AC, these advances are accompanied by a new set of challenges. By providing a framework to discuss and evaluate novel research, we hope to leverage recent advances to speed-up future research in this area.",2011.0,0.0,1498.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{D'Mello2011SpecialTO,\n author = {Sidney K. D'Mello and Rafael A. Calvo},\n title = {Special Track on Affective Computing},\n year = {2011}\n}\n""}","[{'authorId': '2200019872', 'name': ""Sidney K. D'Mello""}, {'authorId': '2264152559', 'name': 'Rafael A. Calvo'}]"
1682,910bfa42d0c43117735b2307356d1145957a0f99,Création et validation d’une version française du questionnaire AttrakDiff pour l’évaluation de l’expérience utilisateur des systèmes interactifs,,2015.0,68.0,77.0,False,,"{'volume': '65', 'pages': '239-252', 'name': 'European Review of Applied Psychology-revue Europeenne De Psychologie Appliquee'}","{'bibtex': '@Article{Lallemand2015CréationEV,\n author = {C. Lallemand and Vincent Koenig and G. Gronier and Romain Martin},\n journal = {European Review of Applied Psychology-revue Europeenne De Psychologie Appliquee},\n pages = {239-252},\n title = {Création et validation d’une version française du questionnaire AttrakDiff pour l’évaluation de l’expérience utilisateur des systèmes interactifs},\n volume = {65},\n year = {2015}\n}\n'}","[{'authorId': '2081134241', 'name': 'C. Lallemand'}, {'authorId': '2073604354', 'name': 'Vincent Koenig'}, {'authorId': '2034260', 'name': 'G. Gronier'}, {'authorId': '46776514', 'name': 'Romain Martin'}]"
1683,9125fc9a8e2748a4b92db8f133238a599de5fbb3,Category Processing and the human likeness dimension of the Uncanny Valley Hypothesis: Eye-Tracking Data,"The Uncanny Valley Hypothesis (Mori, 1970) predicts that perceptual difficulty distinguishing between a humanlike object (e.g., lifelike prosthetic hand, mannequin) and its human counterpart evokes negative affect. Research has focused on affect, with inconsistent results, but little is known about how objects along the hypothesis’ dimension of human likeness (DHL) are actually perceived. This study used morph continua based on human and highly realistic computer-generated (avatar) faces to represent the DHL. Total number and dwell time of fixations to facial features were recorded while participants (N = 60) judged avatar versus human category membership of the faces in a forced choice categorization task. Fixation and dwell data confirmed the face feature hierarchy (eyes, nose, and mouth in this order of importance) across the DHL. There were no further findings for fixation. A change in the relative importance of these features was found for dwell time, with greater preferential processing of eyes and mouth of categorically ambiguous faces compared with unambiguous avatar faces. There were no significant differences between ambiguous and human faces. These findings applied for men and women, though women generally dwelled more on the eyes to the disadvantage of the nose. The mouth was unaffected by gender. In summary, the relative importance of facial features changed on the DHL’s non-human side as a function of categorization ambiguity. This change was indicated by dwell time only, suggesting greater depth of perceptual processing of the eyes and mouth of ambiguous faces compared with these features in unambiguous avatar faces.",2013.0,116.0,61.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00108/pdf', 'status': None}","{'volume': '4', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Cheetham2013CategoryPA,\n author = {M. Cheetham and I. Pavlović and Nicola Jordan and Pascal Suter and L. Jancke},\n journal = {Frontiers in Psychology},\n title = {Category Processing and the human likeness dimension of the Uncanny Valley Hypothesis: Eye-Tracking Data},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '3442607', 'name': 'M. Cheetham'}, {'authorId': '144678539', 'name': 'I. Pavlović'}, {'authorId': '2058668434', 'name': 'Nicola Jordan'}, {'authorId': '40529088', 'name': 'Pascal Suter'}, {'authorId': '5703561', 'name': 'L. Jancke'}]"
1684,913c210a76ebd42f32f1587ffedf58a4d4e589b7,Empathy: Its ultimate and proximate bases.,"There is disagreement in the literature about the exact nature of the phenomenon of empathy. There are emotional, cognitive, and conditioning views, applying in varying degrees across species. An adequate description of the ultimate and proximate mechanism can integrate these views. Proximately, the perception of an object's state activates the subject's corresponding representations, which in turn activate somatic and autonomic responses. This mechanism supports basic behaviors (e.g., alarm, social facilitation, vicariousness of emotions, mother-infant responsiveness, and the modeling of competitors and predators) that are crucial for the reproductive success of animals living in groups. The Perception-Action Model (PAM), together with an understanding of how representations change with experience, can explain the major empirical effects in the literature (similarity, familiarity, past experience, explicit teaching, and salience). It can also predict a variety of empathy disorders. The interaction between the PAM and prefrontal functioning can also explain different levels of empathy across species and age groups. This view can advance our evolutionary understanding of empathy beyond inclusive fitness and reciprocal altruism and can explain different levels of empathy across individuals, species, stages of development, and situations.",2001.0,680.0,3386.0,True,"{'url': 'http://www.baillement.com/texte-empathy.pdf', 'status': None}","{'volume': '25 1', 'pages': '\n          1-20; discussion 20-71\n        ', 'name': 'The Behavioral and brain sciences'}","{'bibtex': '@Article{Preston2001EmpathyIU,\n author = {S. Preston and F. D. de Waal},\n journal = {The Behavioral and brain sciences},\n pages = {\n          1-20; discussion 20-71\n        },\n title = {Empathy: Its ultimate and proximate bases.},\n volume = {25 1},\n year = {2001}\n}\n'}","[{'authorId': '5011255', 'name': 'S. Preston'}, {'authorId': '3533326', 'name': 'F. D. de Waal'}]"
1685,913ea1c8295893d0a54e3703ed5571122afeb445,The Fundamentals of Kansei Engineering and a Methodological Problem: Human Internal Information and Empathy,"Researches in Biometrics (B. M.) and Kansei engineering (K. E.) commonly utilize biological or physiological data as their major means. Therefore, it seems plausible to expect meaningful cooperation between B. M. and K. E. Aiming at exploring a possibility to materialize such an expectation, in the 1st part of the paper, we first discuss some fundamental issues of K. E. including the characteristic of K.E. as well as the definition of the term Kansei itself. In the 2nd part of the paper, the issue of human internal information such as emotions which reside the inside of human body, and hence, are unmeasurable from the outside are discussed as a basic problem lying over both B. M. and K.E. In particular, problems how to acquire human internal information are discussed through several examples.",2013.0,12.0,2.0,False,,"{'pages': '332-335', 'name': '2013 International Conference on Biometrics and Kansei Engineering'}","{'bibtex': '@Article{Nagashima2013TheFO,\n author = {T. Nagashima},\n journal = {2013 International Conference on Biometrics and Kansei Engineering},\n pages = {332-335},\n title = {The Fundamentals of Kansei Engineering and a Methodological Problem: Human Internal Information and Empathy},\n year = {2013}\n}\n'}","[{'authorId': '3163017', 'name': 'T. Nagashima'}]"
1686,9147fffbcdd4c0f0a651c91e038d9b3e7df4fc21,Cross-Lagged Panel Analysis,"Cross-lagged panel analysis is an analytical strategy used to describe reciprocal relationships, or directional influences, between variables over time. Cross-lagged panel models (CLPM), also referred to as cross-lagged path models and cross-lagged regression models, are estimated using panel data, or longitudinal data where each observation or person is recorded at multiple points in time. The models are considered ""crossed"" because they estimate relationships from one variable to another and vice-versa. They are considered ""lagged"" because they estimate relationships between variables across different time points. Taken together, cross-lagged panel models estimate the directional influence variables have on each other over time. The primary goal of cross-lagged panel models is to examine the causal influences between variables. In essence, cross-lagged panel analysis compares the relationship between variable X at Time 1 and variable Y at Time 2 with the relationship between variable Y at Time 1 and X at Time 2. It is widely used to examine the stability and relationships between variables over time to better understand how variables influence each other over time. This entry discusses cross-lagged panel analysis, an analytical strategy used in longitudinal communication research. It describes its rationales and origins in research. It also describes modern path-analytic approaches to cross-lagged panel analysis. Finally, this entry discusses some important assumptions and issues with cross-lagged panel analysis.",2016.0,5.0,165.0,False,,,"{'bibtex': '@Inproceedings{Kearney2016CrossLaggedPA,\n author = {M. Kearney},\n title = {Cross-Lagged Panel Analysis},\n year = {2016}\n}\n'}","[{'authorId': '2011035', 'name': 'M. Kearney'}]"
1687,9174c318999aeea2b1dd30ebfbef0b600ac80d69,Embodying self-compassion within virtual reality and its effects on patients with depression,"Background Self-criticism is a ubiquitous feature of psychopathology and can be combatted by increasing levels of self-compassion. However, some patients are resistant to self-compassion. Aims To investigate whether the effects of self-identification with virtual bodies within immersive virtual reality could be exploited to increase self-compassion in patients with depression. Method We developed an 8-minute scenario in which 15 patients practised delivering compassion in one virtual body and then experienced receiving it from themselves in another virtual body. Results In an open trial, three repetitions of this scenario led to significant reductions in depression severity and self-criticism, as well as to a significant increase in self-compassion, from baseline to 4-week follow-up. Four patients showed clinically significant improvement. Conclusions The results indicate that interventions using immersive virtual reality may have considerable clinical potential and that further development of these methods preparatory to a controlled trial is now warranted. Declaration of interest None. Copyright and usage © The Royal College of Psychiatrists 2016. This is an open access article distributed under the terms of the Creative Commons Attribution (CC BY) licence.",2016.0,40.0,185.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/1A1217651159D085145A7999CFFFF772/S2056472400001186a.pdf/div-class-title-embodying-self-compassion-within-virtual-reality-and-its-effects-on-patients-with-depression-div.pdf', 'status': None}","{'volume': '2', 'pages': '74 - 80', 'name': 'BJPsych open'}","{'bibtex': '@Article{Falconer2016EmbodyingSW,\n author = {Caroline J. Falconer and Aitor Rovira and John A. King and P. Gilbert and Angus Antley and P. Fearon and N. Ralph and M. Slater and C. Brewin},\n journal = {BJPsych open},\n pages = {74 - 80},\n title = {Embodying self-compassion within virtual reality and its effects on patients with depression},\n volume = {2},\n year = {2016}\n}\n'}","[{'authorId': '36318701', 'name': 'Caroline J. Falconer'}, {'authorId': '2338435', 'name': 'Aitor Rovira'}, {'authorId': '32572883', 'name': 'John A. King'}, {'authorId': '145962984', 'name': 'P. Gilbert'}, {'authorId': '1705895', 'name': 'Angus Antley'}, {'authorId': '5188198', 'name': 'P. Fearon'}, {'authorId': '38454124', 'name': 'N. Ralph'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '5126407', 'name': 'C. Brewin'}]"
1689,91d7d6af4a78bea87ff0d86c2f995aef0d337e86,Literacy and Schooling.,,1987.0,0.0,140.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bloome1987LiteracyAS,\n author = {D. Bloome},\n title = {Literacy and Schooling.},\n year = {1987}\n}\n'}","[{'authorId': '83088087', 'name': 'D. Bloome'}]"
1690,920d960c7ff897fce29f8e828537bf440b3b4f6e,Cognitive Agent-based Computing-I: A Unified Framework for Modeling Complex Adaptive Systems using Agent-based & Complex Network-based Methods,"Complex Systems are made up of numerous interacting sub-components. Non-linear interactions of these components or agents give rise to emergent behavior observable at the global scale. Agent-based modeling and simulation is a proven paradigm which has previously been used for effective computational modeling of complex systems in various domains. Because of its popular use across different scientific domains, research in agent-based modeling has primarily been vertical in nature. The goal of this manuscript is to provide a single hands-on guide to developing cognitive agent-based models for the exploration of emergence across various types of complex systems. We present practical ideas and examples for researchers and practitioners for the building of agent-based models using a horizontal approach - applications are demonstrated in a number of exciting domains as diverse as wireless sensors networks, peer-to-peer networks, complex social systems, research networks, epidemiological HIV",2012.0,0.0,45.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Niazi2012CognitiveAC,\n author = {M. Niazi and A. Hussain},\n title = {Cognitive Agent-based Computing-I: A Unified Framework for Modeling Complex Adaptive Systems using Agent-based & Complex Network-based Methods},\n year = {2012}\n}\n'}","[{'authorId': '1795560', 'name': 'M. Niazi'}, {'authorId': '144664815', 'name': 'A. Hussain'}]"
1691,927300650e23d0dd63342dd72d7ebcb300e9d807,EEG-Based Emotion Recognition via Neural Architecture Search,"With the flourishing development of deep learning (DL) and the convolution neural network (CNN), electroencephalogram-based (EEG) emotion recognition is occupying an increasingly crucial part in the field of brain-computer interface (BCI). However, currently employed architectures have mostly been designed manually by human experts, which is a time-consuming and labor-intensive process. In this paper, we proposed a novel neural architecture search (NAS) framework based on reinforcement learning (RL) for EEG-based emotion recognition, which can automatically design network architectures. The proposed NAS mainly contains three parts: search strategy, search space, and evaluation strategy. During the search process, a recurrent network (RNN) controller is used to select the optimal network structure in the search space. We trained the controller with RL to maximize the expected reward of the generated models on a validation set and force parameter sharing among the models. We evaluated the performance of NAS on the DEAP and DREAMER dataset. On the DEAP dataset, the average accuracies reached 97.94%, 97.74%, and 97.82% on arousal, valence, and dominance respectively. On the DREAMER dataset, average accuracies reached 96.62%, 96.29% and 96.61% on arousal, valence, and dominance, respectively. The experimental results demonstrated that the proposed NAS outperforms the state-of-the-art CNN-based methods.",2023.0,64.0,21.0,False,,"{'volume': '14', 'pages': '957-968', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Li2023EEGBasedER,\n author = {Chang Li and Zhong-Xia Zhang and Rencheng Song and Juan Cheng and Yu Liu and Xun Chen},\n journal = {IEEE Transactions on Affective Computing},\n pages = {957-968},\n title = {EEG-Based Emotion Recognition via Neural Architecture Search},\n volume = {14},\n year = {2023}\n}\n'}","[{'authorId': '2145420832', 'name': 'Chang Li'}, {'authorId': '2118749579', 'name': 'Zhong-Xia Zhang'}, {'authorId': '1430708893', 'name': 'Rencheng Song'}, {'authorId': '46754596', 'name': 'Juan Cheng'}, {'authorId': '2146399587', 'name': 'Yu Liu'}, {'authorId': '2144213500', 'name': 'Xun Chen'}]"
1692,92777f9a04ca5d55bfbdc409132d94be57d42417,Towards Bi-directional Dancing Interaction,,2006.0,20.0,37.0,False,,{'pages': '1-12'},"{'bibtex': '@Inproceedings{Reidsma2006TowardsBD,\n author = {D. Reidsma and H. V. Welbergen and R. Poppe and Pieter Bos and A. Nijholt},\n pages = {1-12},\n title = {Towards Bi-directional Dancing Interaction},\n year = {2006}\n}\n'}","[{'authorId': '2997504', 'name': 'D. Reidsma'}, {'authorId': '3251916', 'name': 'H. V. Welbergen'}, {'authorId': '1754666', 'name': 'R. Poppe'}, {'authorId': '2074422254', 'name': 'Pieter Bos'}, {'authorId': '144483472', 'name': 'A. Nijholt'}]"
1693,9295d40353cbe4c56bbcf813abefb028b4a5ed65,Lip movement synthesis from speech based on hidden Markov models,"Speech intelligibility can be improved by adding lip image and facial image to speech signal. Thus the lip image synthesis plays an important role to realize a natural human-like face of computer agents. Moreover the synthesized lip movement images can compensate lack of auditory information for hearing impaired people. We propose a novel lip movement synthesis method based on mapping from input speech based on Hidden Markov Model (HMM). This paper compares the HMM-based method and a conventional method using vector quantization (VQ). In the experiment, error and time differential error between synthesized lip movement images and original ones are used for evaluation. The result shows that the error of the HMM based method is 8.7% smaller than that of the VQ-based method. Moreover, the HMM-based method reduces time differential error by 32% than the VQ's. The result also shows that the errors are mostly caused by phoneme /h/ and /Q/. Since lip shapes of those phonemes are strongly dependent on succeeding phoneme, the context dependent synthesis on the HMM-based method is applied to reduce the error. The improved HMM-based method realizes reduction of the error (differential error) by 10.5% (11%) compared with the original HMM-based method.",1998.0,23.0,136.0,False,,"{'pages': '154-159', 'name': 'Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition'}","{'bibtex': '@Article{Yamamoto1998LipMS,\n author = {E. Yamamoto and Satoshi Nakamura and K. Shikano},\n journal = {Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition},\n pages = {154-159},\n title = {Lip movement synthesis from speech based on hidden Markov models},\n year = {1998}\n}\n'}","[{'authorId': '2290237', 'name': 'E. Yamamoto'}, {'authorId': '145223960', 'name': 'Satoshi Nakamura'}, {'authorId': '9243990', 'name': 'K. Shikano'}]"
1694,92b648eabe5a9d95fa2389b4a93472322d43309d,"Testing the relationship between mimicry, trust and rapport in virtual reality conversations",,2016.0,68.0,49.0,True,"{'url': 'https://www.nature.com/articles/srep35295.pdf', 'status': None}","{'volume': '6', 'name': 'Scientific Reports'}","{'bibtex': '@Article{Hale2016TestingTR,\n author = {Joanna Hale and A. Hamilton},\n journal = {Scientific Reports},\n title = {Testing the relationship between mimicry, trust and rapport in virtual reality conversations},\n volume = {6},\n year = {2016}\n}\n'}","[{'authorId': '153068102', 'name': 'Joanna Hale'}, {'authorId': '145213359', 'name': 'A. Hamilton'}]"
1695,92b701bec2a86d0c3f5655e8e9116e87608f5341,Embodied conversational interface agents,"More than another friendly face, Rea knows how to have a conversation with living, breathing human users with a wink, a nod, and a sidelong glance. A nimals and humans all manifest social qualities and skills. Dogs recognize dominance and submission , stand corrected by their superiors, demonstrate consistent personalities, and so forth. On the other hand, only humans communicate through language and carry on conversations with one another. The skills involved in human conversation have developed in such a way as to exploit all the special characteristics of the human body. We make complex repre-sentational gestures with our prehensile hands, gaze away and toward one another out of the corners of our centrally set eyes, and use the pitch and melody of our flexible voices to emphasize and clarify what we are saying. Perhaps because conversation is so defining of humanness and human interaction, the metaphor of face-to-face conversation has been applied to human-computer interface design for quite some time. One of the early arguments for the utility of this metaphor pointed to the application of the features of face-to-face conversation in human-computer interaction, including mixed initiative, nonverbal communication , sense of presence, and the rules involved in transferring control [9]. However, although these features have gained widespread recognition, human-computer conversation has only recently become more than a metaphor. That is, only recently have human-computer interface designers taken the metaphor seriously enough to attempt to design a computer that could hold up its end of the conversation with a human user. Here, I describe some of the features of human-human conversation being implemented in this new genre of embodied conversational agent, exploring a notable embodied conversational agent—named Rea—based on these features. Because conversation is such a primary skill for humans and learned so early in life (practiced, in fact, between infants and their mothers taking turns cooing and burbling EMBODIED CONVERSATIONAL INTERFACE AGENTS",2000.0,16.0,358.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/332051.332075', 'status': None}","{'volume': '43', 'pages': '70-78', 'name': 'Commun. ACM'}","{'bibtex': '@Article{Cassell2000EmbodiedCI,\n author = {Justine Cassell},\n journal = {Commun. ACM},\n pages = {70-78},\n title = {Embodied conversational interface agents},\n volume = {43},\n year = {2000}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}]"
1696,92bed1ffb5d5eb17a5d45d0e8f784c46caaa693c,AutoTutor: A tutor with dialogue in natural language,,2004.0,83.0,477.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03195563.pdf', 'status': None}","{'volume': '36', 'pages': '180-192', 'name': 'Behavior Research Methods, Instruments, & Computers'}","{'bibtex': '@Article{Graesser2004AutoTutorAT,\n author = {A. Graesser and Shulan Lu and G. T. Jackson and Heather H. Mitchell and M. Ventura and A. Olney and M. Louwerse},\n journal = {Behavior Research Methods, Instruments, & Computers},\n pages = {180-192},\n title = {AutoTutor: A tutor with dialogue in natural language},\n volume = {36},\n year = {2004}\n}\n'}","[{'authorId': '1769251', 'name': 'A. Graesser'}, {'authorId': '2772086', 'name': 'Shulan Lu'}, {'authorId': '144874959', 'name': 'G. T. Jackson'}, {'authorId': '40490729', 'name': 'Heather H. Mitchell'}, {'authorId': '2056465739', 'name': 'M. Ventura'}, {'authorId': '1731622', 'name': 'A. Olney'}, {'authorId': '2073332', 'name': 'M. Louwerse'}]"
1697,92cccacbfcdd9f4ba9783070cc57705d56683a2c,Automated emotion recognition based on higher order statistics and deep learning algorithm,,2020.0,50.0,107.0,False,,"{'volume': '58', 'pages': '101867', 'name': 'Biomed. Signal Process. Control.'}","{'bibtex': '@Article{Sharma2020AutomatedER,\n author = {Rahul Sharma and R. B. Pachori and P. Sircar},\n journal = {Biomed. Signal Process. Control.},\n pages = {101867},\n title = {Automated emotion recognition based on higher order statistics and deep learning algorithm},\n volume = {58},\n year = {2020}\n}\n'}","[{'authorId': '2111334485', 'name': 'Rahul Sharma'}, {'authorId': '2812708', 'name': 'R. B. Pachori'}, {'authorId': '2579226', 'name': 'P. Sircar'}]"
1698,92dfe7e03f007a4cbfb1af57b79e31660ad7525f,Happy faces considered trustworthy irrespective of perceiver's mood: Challenges to the mood congruency effect,,2014.0,48.0,12.0,False,,"{'volume': '47', 'pages': '85-93', 'name': 'Comput. Secur.'}","{'bibtex': ""@Article{Dong2014HappyFC,\n author = {Yan Dong and Yongna Li and Tingting Sun},\n journal = {Comput. Secur.},\n pages = {85-93},\n title = {Happy faces considered trustworthy irrespective of perceiver's mood: Challenges to the mood congruency effect},\n volume = {47},\n year = {2014}\n}\n""}","[{'authorId': '2153514729', 'name': 'Yan Dong'}, {'authorId': '2950532', 'name': 'Yongna Li'}, {'authorId': '2113205902', 'name': 'Tingting Sun'}]"
1700,92ed769ba5558b7ff4acb2531bdb764b347790ba,Measuring Agreement on Set-valued Items (MASI) for Semantic and Pragmatic Annotation,"Annotation projects dealing with complex semantic or pragmatic phenomena face the dilemma of creating annotation schemes that oversimplify the phenomena, or that capture distinctions conventional reliability metrics cannot measure adequately. The solution to the dilemma is to develop metrics that quantify the decisions that annotators are asked to make. This paper discusses MASI, distance metric for comparing sets, and illustrates its use in quantifying the reliability of a specific dataset. Annotations of Summary Content Units (SCUs) generate models referred to as pyramids which can be used to evaluate unseen human summaries or machine summaries. The paper presents reliability results for five pairs of pyramids created for document sets from the 2003 Document Understanding Conference (DUC). The annotators worked independently of each other. Differences between application of MASI to pyramid annotation and its previous application to co-reference annotation are discussed. In addition, it is argued that a paradigmatic reliability study should relate measures of inter-annotator agreement to independent assessments, such as significance tests of the annotated variables with respect to other phenomena. In effect, what counts as sufficiently reliable intera-annotator agreement depends on the use the annotated data will be put to.",2006.0,16.0,166.0,False,,{'pages': '831-836'},"{'bibtex': '@Inproceedings{Passonneau2006MeasuringAO,\n author = {R. Passonneau},\n pages = {831-836},\n title = {Measuring Agreement on Set-valued Items (MASI) for Semantic and Pragmatic Annotation},\n year = {2006}\n}\n'}","[{'authorId': '1703046', 'name': 'R. Passonneau'}]"
1701,92f02267d94025091507343d48fb89efdd6cd198,Digital Game-Based Learning,"This special issue of Computers in the Schools focuses on digital game-based learning. Gaming has grown in popularity and become a deﬁning characteristic of young learners. Digital games, initially designed for the mass market with few educational connections, have gained increasing interests from educators and researchers. The articles featured in this issue will add to the body of knowledge that argues that digital games, when used effectively in instruction, can improve student learning through increased motivation and engagement. The articles in this issue also explore elements of game design that can increase effectiveness of games in the classroom. This special issue addresses using gaming as part of instruction with a variety of learners and within various learning contexts, including both K–12 education and higher education. This special issue consists of six outstanding articles, which provide readers with examples of game-based learning in practice, as well as discussion of game features that optimize learning opportunities. Selen Turkay and colleagues provide a teacher-oriented literature review addressing theoretical perspectives and game-design issues for educators to consider. Michael Martin and Yuzhong Shen share the results of their study regarding the effects of particular aspects of game design on learning outcomes. Judy Perry and Eric Klopfer’s study explores ubiquitous and causal learning games that help inform us of the educational effectiveness of speciﬁc game elements. Min Lun Wu, Kari Richards, and Guan Kung Saw’s investigation uses a massive multiplayer role-playing game to support second-language learning that yielded interesting ﬁndings on the interaction between motivation and game-based learning. Min Liu and colleagues further explore this interaction by explaining student motivation as a function of the engaging, interactive environment that is experienced through digital-learning games. In keeping",2014.0,0.0,1652.0,False,,"{'volume': '31', 'pages': '1 - 1', 'name': 'Computers in the Schools'}","{'bibtex': '@Article{Sadera2014DigitalGL,\n author = {W. Sadera and Qing Li and Liyan Song and Leping Liu},\n journal = {Computers in the Schools},\n pages = {1 - 1},\n title = {Digital Game-Based Learning},\n volume = {31},\n year = {2014}\n}\n'}","[{'authorId': '70043317', 'name': 'W. Sadera'}, {'authorId': '50444218', 'name': 'Qing Li'}, {'authorId': '144157724', 'name': 'Liyan Song'}, {'authorId': '35183985', 'name': 'Leping Liu'}]"
1702,92f33180db3a2c98cc2bde77d3bfa8b329be4692,Computer-assisted authoring of interactive narratives,"This paper explores new authoring paradigms and computer-assisted authoring tools for free-form interactive narratives. We present a new design formalism, Interactive Behavior Trees (IBT's), which decouples the monitoring of user input, the narrative, and how the user may influence the story outcome. We introduce automation tools for IBT's, to help the author detect and automatically resolve inconsistencies in the authored narrative, or conflicting user interactions that may hinder story progression. We compare IBT's to traditional story graph representations and show that our formalism better scales with the number of story arcs, and the degree and granularity of user input. The authoring time is further reduced with the help of automation, and errors are completely avoided. Our approach enables content creators to easily author complex, branching narratives with multiple story arcs in a modular, extensible fashion while empowering players with the agency to freely interact with the characters in the story and the world they inhabit.",2015.0,27.0,50.0,False,,{'name': 'Proceedings of the 19th Symposium on Interactive 3D Graphics and Games'},"{'bibtex': '@Article{Kapadia2015ComputerassistedAO,\n author = {Mubbasir Kapadia and Jessica Falk and Fabio Zünd and Marcel Marti and R. Sumner and M. Gross},\n journal = {Proceedings of the 19th Symposium on Interactive 3D Graphics and Games},\n title = {Computer-assisted authoring of interactive narratives},\n year = {2015}\n}\n'}","[{'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '144973887', 'name': 'Jessica Falk'}, {'authorId': '3071164', 'name': 'Fabio Zünd'}, {'authorId': '145658471', 'name': 'Marcel Marti'}, {'authorId': '1693475', 'name': 'R. Sumner'}, {'authorId': '2257153235', 'name': 'M. Gross'}]"
1703,931ec58dfb5b1928622274fdc5041c71f0e16d00,TARGET ARTICLE: Immersive Virtual Environment Technology as a Methodological Tool for Social Psychology,"Historically, at least 3 methodological problems have dogged experimental social psychology: the experimental control-mundane realism trade-off, lack of replication, and unrepresentative sampling. We argue that immersive virtual environment technology (IVET) can help ameliorate, if not solve, these methodological problems and, thus, holds promise as a new social psychological research tool. In this article, we first present an overview of IVET and review IVET-based research within psychology and other fields. Next, we propose a general model of social influence within immersive virtual environments and present some preliminary findings regarding its utility for social psychology. Finally, we present a new paradigm for experimental social psychology that may enable researchers to unravel the very fabric of social interaction.",2002.0,103.0,919.0,False,,"{'volume': '13', 'pages': '103 - 124', 'name': 'Psychological Inquiry'}","{'bibtex': '@Article{Blascovich2002TARGETAI,\n author = {J. Blascovich and J. Loomis and A. Beall and Kimberly R. Swinth and Crystal L. Hoyt and J. Bailenson},\n journal = {Psychological Inquiry},\n pages = {103 - 124},\n title = {TARGET ARTICLE: Immersive Virtual Environment Technology as a Methodological Tool for Social Psychology},\n volume = {13},\n year = {2002}\n}\n'}","[{'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '2386187', 'name': 'J. Loomis'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2396884', 'name': 'Kimberly R. Swinth'}, {'authorId': '32047738', 'name': 'Crystal L. Hoyt'}, {'authorId': '1737161', 'name': 'J. Bailenson'}]"
1705,932b227ec4baade553307e8ed2f07f058c6b2b5a,Spontaneous Facial Mimicry is Modulated by Joint Attention and Autistic Traits,"Joint attention (JA) and spontaneous facial mimicry (SFM) are fundamental processes in social interactions, and they are closely related to empathic abilities. When tested independently, both of these processes have been usually observed to be atypical in individuals with autism spectrum conditions (ASC). However, it is not known how these processes interact with each other in relation to autistic traits. This study addresses this question by testing the impact of JA on SFM of happy faces using a truly interactive paradigm. Sixty‐two neurotypical participants engaged in gaze‐based social interaction with an anthropomorphic, gaze‐contingent virtual agent. The agent either established JA by initiating eye contact or looked away, before looking at an object and expressing happiness or disgust. Eye tracking was used to make the agent's gaze behavior and facial actions contingent to the participants' gaze. SFM of happy expressions was measured by Electromyography (EMG) recording over the Zygomaticus Major muscle. Results showed that JA augments SFM in individuals with low compared with high autistic traits. These findings are in line with reports of reduced impact of JA on action imitation in individuals with ASC. Moreover, they suggest that investigating atypical interactions between empathic processes, instead of testing these processes individually, might be crucial to understanding the nature of social deficits in autism. Autism Res 2016, 9: 781–789. © 2015 The Authors Autism Research published by Wiley Periodicals, Inc. on behalf of International Society for Autism Research",2015.0,67.0,27.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aur.1573', 'status': None}","{'volume': '9', 'pages': '781 - 789', 'name': 'Autism Research'}","{'bibtex': '@Article{Neufeld2015SpontaneousFM,\n author = {J. Neufeld and C. Ioannou and S. Korb and L. Schilbach and B. Chakrabarti},\n journal = {Autism Research},\n pages = {781 - 789},\n title = {Spontaneous Facial Mimicry is Modulated by Joint Attention and Autistic Traits},\n volume = {9},\n year = {2015}\n}\n'}","[{'authorId': '50377075', 'name': 'J. Neufeld'}, {'authorId': '3093585', 'name': 'C. Ioannou'}, {'authorId': '15684638', 'name': 'S. Korb'}, {'authorId': '2127424', 'name': 'L. Schilbach'}, {'authorId': '3102450', 'name': 'B. Chakrabarti'}]"
1706,933d590085dda29d1a09b3f2f16a9829388a3213,Understanding and Improving Treatment Adherence in Patients with Psychotic Disorders: A Review and a Proposed Intervention,"Non-adherence to treatment of patients with psychotic disorders is related to higher rates of relapse, hospitalization, and suicide. Important predictors of non-adherence include poor social structure, cognitive deficits, negative medication attitude, side effects, depression, a sealing-over recovery style, feelings of stigmatization, denial of treatment need, and lack of insight. Attempts to improve adherence have shown that psychoeducation alone is not fully effective, and that motivational interviewing, behavioral strategies, and linking a patient s personal goals to treatment may increase adherence. Based on the empirical data reviewed, we formed four clusters of possible causes of non-adherence, each of which can be targeted by a specific module of our developed Treatment Adherence Therapy (TAT). These four modules are: self-enhancement, motivational interviewing, medication dosage trials, and behavioral training. An individual patient may benefit from one or more of these modules; and thus the contents of TAT vary in accordance with individual causes of non-adherence. Basically, TAT aims to help patients work out what they want regarding treatment and then support them in following this through. TAT will be investigated in a multicenter randomized clinical trial in the Netherlands, starting March 2006.",2006.0,58.0,29.0,False,,"{'volume': '2', 'pages': '487-494', 'name': 'Current Psychiatry Reviews'}","{'bibtex': '@Article{Staring2006UnderstandingAI,\n author = {A. Staring and C. Mulder and M. Gaag and J. Selten and A. Loonen and M. Hengeveld},\n journal = {Current Psychiatry Reviews},\n pages = {487-494},\n title = {Understanding and Improving Treatment Adherence in Patients with Psychotic Disorders: A Review and a Proposed Intervention},\n volume = {2},\n year = {2006}\n}\n'}","[{'authorId': '5628900', 'name': 'A. Staring'}, {'authorId': '4372174', 'name': 'C. Mulder'}, {'authorId': '145958551', 'name': 'M. Gaag'}, {'authorId': '48944283', 'name': 'J. Selten'}, {'authorId': '33615601', 'name': 'A. Loonen'}, {'authorId': '1994652', 'name': 'M. Hengeveld'}]"
1707,938658b6d86b74be6a22741a1ca24fded5c2bbf4,Creating Interactive Virtual Humans: Some Assembly Required,"Discusses some of the key issues that must be addressed in creating virtual humans, or androids. As a first step, we overview the issues and available tools in three key areas of virtual human research: face-to-face conversation, emotions and personality, and human figure animation. Assembling a virtual human is still a daunting task, but the building blocks are getting bigger and better every day.",2002.0,53.0,423.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/b93d950e-cc64-47d9-a063-d4f2c3e9d45d/download', 'status': None}","{'volume': '17', 'pages': '54-63', 'name': 'IEEE Intell. Syst.'}","{'bibtex': '@Article{Gratch2002CreatingIV,\n author = {J. Gratch and J. Rickel and E. André and Justine Cassell and E. Petajan and N. Badler},\n journal = {IEEE Intell. Syst.},\n pages = {54-63},\n title = {Creating Interactive Virtual Humans: Some Assembly Required},\n volume = {17},\n year = {2002}\n}\n'}","[{'authorId': '69014762', 'name': 'J. Gratch'}, {'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '2920582', 'name': 'E. Petajan'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
1710,93b0dc0311845a5b649c9f9764a3f55392291204,Virtual reality applications toward medical field,,2020.0,82.0,85.0,True,"{'url': 'http://cegh.net/article/S2213398419304294/pdf', 'status': None}",{'name': 'Clinical Epidemiology and Global Health'},"{'bibtex': '@Article{Javaid2020VirtualRA,\n author = {M. Javaid and Abid Haleem},\n journal = {Clinical Epidemiology and Global Health},\n title = {Virtual reality applications toward medical field},\n year = {2020}\n}\n'}","[{'authorId': '49884103', 'name': 'M. Javaid'}, {'authorId': '38272234', 'name': 'Abid Haleem'}]"
1711,93dcf21519bf58e135e66fef5376376d6e2af371,Cognitive mechanisms for responding to mimicry from others,,2016.0,187.0,51.0,True,"{'url': 'https://discovery.ucl.ac.uk/id/eprint/1480501/1/Hamilton-A__haleHamilton_NBR_2016.pdf', 'status': None}","{'volume': '63', 'pages': '106-123', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Hale2016CognitiveMF,\n author = {Joanna Hale and A. Hamilton},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {106-123},\n title = {Cognitive mechanisms for responding to mimicry from others},\n volume = {63},\n year = {2016}\n}\n'}","[{'authorId': '153068102', 'name': 'Joanna Hale'}, {'authorId': '145213359', 'name': 'A. Hamilton'}]"
1712,9401a600bf069852d9df1c2fb4d9f969b5e8df0e,Does the contingency of agents' nonverbal feedback affect users' social anxiety?,"We explored the association between users' social anxiety and the interactional fidelity of an agent (also referred to as a virtual human), specifically addressing whether the contingency of agents' nonverbal feedback affects the relationship between users' social anxiety and their feelings of rapport, performance, or judgment on interaction partners. This subject was examined across four experimental conditions where participants interacted with three different types of agents and a real human. The three types of agents included the Non-Contingent Agent, the Responsive Agent (opposite to the Non-Contingent Agent), and the Mediated Agent (controlled by a real human). The results indicated that people having greater social anxiety would feel less rapport and show worse performance while feeling more embarrassment if they experience the untimely feedback of the Non-Contingent Agent. The results also showed people having more anxiety would trust real humans less as their interaction partners. We discuss the implication of this relationship between social anxiety in a human subject and the interactional fidelity of an agent on the design of virtual characters for social skills training and therapy.",2008.0,29.0,49.0,False,,{'pages': '120-127'},"{'bibtex': ""@Inproceedings{Kang2008DoesTC,\n author = {Sin-Hwa Kang and J. Gratch and Ning Wang and J. Watt},\n pages = {120-127},\n title = {Does the contingency of agents' nonverbal feedback affect users' social anxiety?},\n year = {2008}\n}\n""}","[{'authorId': '34728215', 'name': 'Sin-Hwa Kang'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '24279134', 'name': 'J. Watt'}]"
1713,9435fa2f5fa49d5193e775ff46dfcf4dd081756a,First Impressions: Users' Judgments of Virtual Agents' Personality and Interpersonal Attitude in First Encounters,,2012.0,41.0,96.0,True,"{'url': 'https://ris.utwente.nl/ws/files/5294483/cafaro.pdf', 'status': None}",{'pages': '67-80'},"{'bibtex': ""@Inproceedings{Cafaro2012FirstIU,\n author = {Angelo Cafaro and H. Vilhjálmsson and T. Bickmore and D. Heylen and K. R. Jóhannsdóttir and Gunnar Steinn Valgarðsson},\n pages = {67-80},\n title = {First Impressions: Users' Judgments of Virtual Agents' Personality and Interpersonal Attitude in First Encounters},\n year = {2012}\n}\n""}","[{'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '1678537', 'name': 'D. Heylen'}, {'authorId': '145538307', 'name': 'K. R. Jóhannsdóttir'}, {'authorId': '2242296', 'name': 'Gunnar Steinn Valgarðsson'}]"
1715,944a54f54b156ffced95c0ea0bb47b35ee1a62d1,Online modeling for realtime facial animation,"We present a new algorithm for realtime face tracking on commodity RGB-D sensing devices. Our method requires no user-specific training or calibration, or any other form of manual assistance, thus enabling a range of new applications in performance-based facial animation and virtual interaction at the consumer level. The key novelty of our approach is an optimization algorithm that jointly solves for a detailed 3D expression model of the user and the corresponding dynamic tracking parameters. Realtime performance and robust computations are facilitated by a novel subspace parameterization of the dynamic facial expression space. We provide a detailed evaluation that shows that our approach significantly simplifies the performance capture workflow, while achieving accurate facial tracking for realtime applications.",2013.0,32.0,277.0,True,"{'url': 'https://infoscience.epfl.ch/record/189496/files/paper.pdf', 'status': None}","{'volume': '32', 'pages': '1 - 10', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Bouaziz2013OnlineMF,\n author = {Sofien Bouaziz and Yangang Wang and M. Pauly},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 10},\n title = {Online modeling for realtime facial animation},\n volume = {32},\n year = {2013}\n}\n'}","[{'authorId': '35119991', 'name': 'Sofien Bouaziz'}, {'authorId': '47906224', 'name': 'Yangang Wang'}, {'authorId': '143674021', 'name': 'M. Pauly'}]"
1716,9471f2a81d707028bcfc83d3d1c97f89e4fc8051,PICA: Proactive Intelligent Conversational Agent for Interactive Narratives,"A narrative relies on the imperfect knowledge of the user to create interactions between the characters that are ultimately used as a plot device to drive the narrative. This motivates our exploration of ways to encode this information, provides means for a user to both query and influence the knowledge, and guides the user based on a model of their experience. We developed PICA: a proactive intelligent conversational agent for interactive narratives that can guide users through such experiences. The underlying knowledge base is designed using a sub-symbolic architecture, which encodes belief models for multiple users and autonomous agents in addition to the actual story knowledge. We also developed a discourse module using Behavior Trees to intuitively design the proactive and reactive capabilities of PICA. We compare our approach to neural networks and symbolic knowledge bases and demonstrate its functionality.",2018.0,40.0,10.0,False,,{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Falk2018PICAPI,\n author = {Jessica Falk and Steven Poulakos and Mubbasir Kapadia and R. Sumner},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {PICA: Proactive Intelligent Conversational Agent for Interactive Narratives},\n year = {2018}\n}\n'}","[{'authorId': '144973887', 'name': 'Jessica Falk'}, {'authorId': '2634383', 'name': 'Steven Poulakos'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '1693475', 'name': 'R. Sumner'}]"
1717,9481b33f73c41e74da91197a5057cf1c0d5d087b,"Multiband multislice GE‐EPI at 7 tesla, with 16‐fold acceleration using partial parallel imaging with application to high spatial and temporal whole‐brain fMRI","Parallel imaging in the form of multiband radiofrequency excitation, together with reduced k‐space coverage in the phase‐encode direction, was applied to human gradient echo functional MRI at 7 T for increased volumetric coverage and concurrent high spatial and temporal resolution. Echo planar imaging with simultaneous acquisition of four coronal slices separated by 44mm and simultaneous 4‐fold phase‐encoding undersampling, resulting in 16‐fold acceleration and up to 16‐fold maximal aliasing, was investigated. Task/stimulus‐induced signal changes and temporal signal behavior under basal conditions were comparable for multiband and standard single‐band excitation and longer pulse repetition times. Robust, whole‐brain functional mapping at 7 T, with 2 × 2 × 2mm3 (pulse repetition time 1.25 sec) and 1 × 1 × 2mm3 (pulse repetition time 1.5 sec) resolutions, covering fields of view of 256 × 256 × 176mm3 and 192 × 172 × 176mm3, respectively, was demonstrated with current gradient performance. Magn Reson Med 63:1144–1153, 2010. © 2010 Wiley‐Liss, Inc.",2010.0,31.0,1288.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.22361', 'status': None}","{'volume': '63', 'name': 'Magnetic Resonance in Medicine'}","{'bibtex': '@Article{Moeller2010MultibandMG,\n author = {S. Moeller and E. Yacoub and C. Olman and E. Auerbach and J. Strupp and N. Harel and K. Uğurbil},\n journal = {Magnetic Resonance in Medicine},\n title = {Multiband multislice GE‐EPI at 7 tesla, with 16‐fold acceleration using partial parallel imaging with application to high spatial and temporal whole‐brain fMRI},\n volume = {63},\n year = {2010}\n}\n'}","[{'authorId': '3292782', 'name': 'S. Moeller'}, {'authorId': '1761064', 'name': 'E. Yacoub'}, {'authorId': '2063170', 'name': 'C. Olman'}, {'authorId': '2176539', 'name': 'E. Auerbach'}, {'authorId': '48666414', 'name': 'J. Strupp'}, {'authorId': '1782015', 'name': 'N. Harel'}, {'authorId': '1804349', 'name': 'K. Uğurbil'}]"
1718,9496417be3154a73c87d464d11cae49f1fd2ccd5,"What is empathy, and can empathy be taught?","Empathy is a commonly used, but poorly understood, concept. It is often confused with related concepts such as sympathy, pity, identification, and self-transposal. The purposes of this article are to clearly distinguish empathy from related terms and to suggest that the act of empathizing cannot be taught. According to Edith Stein, a German phenomenologist, empathy can be facilitated. It also can be interrupted and blocked, but it cannot be forced to occur. What makes empathy unique, according to Stein, is that it happens to us; it is indirectly given to us, ""nonprimordially."" When empathy occurs, we find ourselves experiencing it, rather than directly causing it to happen. This is the characteristic that makes the act of empathy unteachable. Instead, promoting attitudes and behaviors such as self-awareness, nonjudgmental positive regard for others, good listening skills, and self-confidence are suggested as important in the development of clinicians who will demonstrate an empathic willingness.",1990.0,5.0,125.0,True,"{'url': 'https://academic.oup.com/ptj/article-pdf/70/11/707/10759208/ptj0707.pdf', 'status': None}","{'volume': '70 11', 'pages': '\n          707-11; discussion 712-5\n        ', 'name': 'Physical therapy'}","{'bibtex': '@Article{Davis1990WhatIE,\n author = {C. Davis},\n journal = {Physical therapy},\n pages = {\n          707-11; discussion 712-5\n        },\n title = {What is empathy, and can empathy be taught?},\n volume = {70 11},\n year = {1990}\n}\n'}","[{'authorId': '113430662', 'name': 'C. Davis'}]"
1719,94a93babe070e6f84e5728ba64a43ce003104cfa,FAtiMA Toolkit - Toward an effective and accessible tool for the development of intelligent virtual agents and social robots,"More than a decade has passed since the development of FearNot!, an application designed to help children deal with bullying through role-playing with virtual characters. It was also the application that led to the creation of FAtiMA, an affective agent architecture for creating autonomous characters that can evoke empathic responses. In this paper, we describe FAtiMA Toolkit, a collection of open-source tools that is designed to help researchers, game developers and roboticists incorporate a computational model of emotion and decision-making in their work. The toolkit was developed with the goal of making FAtiMA more accessible, easier to incorporate into different projects and more flexible in its capabilities for human-agent interaction, based upon the experience gathered over the years across different virtual environments and human-robot interaction scenarios. As a result, this work makes several different contributions to the field of Agent-Based Architectures. More precisely, FAtiMA Toolkit's library based design allows developers to easily integrate it with other frameworks, its meta-cognitive model affords different internal reasoners and affective components and its explicit dialogue structure gives control to the author even within highly complex scenarios. To demonstrate the use of FAtiMA Toolkit, several different use cases where the toolkit was successfully applied are described and discussed.",2021.0,54.0,8.0,False,,"{'name': 'ArXiv', 'volume': 'abs/2103.03020'}","{'bibtex': '@Article{Mascarenhas2021FAtiMAT,\n author = {S. Mascarenhas and Manuel Guimarães and P. A. Santos and João Dias and R. Prada and Ana Paiva},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {FAtiMA Toolkit - Toward an effective and accessible tool for the development of intelligent virtual agents and social robots},\n volume = {abs/2103.03020},\n year = {2021}\n}\n'}","[{'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '28004507', 'name': 'Manuel Guimarães'}, {'authorId': '145255182', 'name': 'P. A. Santos'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
1720,94ba19382a5d5968af889c870a783fa09c94ed70,Cognitive and social action,"This monograph addresses the worlds of social science theory and artificial intelligence (AI). The book examines the interaction of individual cognitive factors and social influence on human action and discusses the implications for developments in artificial intelligence. This book is intended for graduate and research level artificial intelligence and social science theory (including sociology, economics, psychology).",1995.0,0.0,623.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Conte1995CognitiveAS,\n author = {R. Conte and C. Castelfranchi},\n title = {Cognitive and social action},\n year = {1995}\n}\n'}","[{'authorId': '49323336', 'name': 'R. Conte'}, {'authorId': '1755446', 'name': 'C. Castelfranchi'}]"
1721,94ba7821609310682ed5a84c50c377d29f197c58,Building Interactive Virtual Humans for Training Environments,"There is a great need in the Joint Forces to have human to human interpersonal training for skills such as negotiation, leadership, interviewing and cultural training. Virtual environments can be incredible training tools if used properly and used for the correct training application. Virtual environments have already been very successful in training Warfighters how to operate vehicles and weapons systems. At the Institute for Creative Technologies (ICT) we have been exploring a new question: can virtual environments be used to train Warfighters in interpersonal skills such as negotiation, tactical questioning and leadership that are so critical for success in the contemporary operating environment? Using embodied conversational agents to create this type of training system has been one of the goals of the Virtual Humans project at the institute. ICT has a great deal of experience building complex, integrated and immersive training systems that address the human factor needs for training experiences. This paper will address the research, technology and value of developing virtual humans for training environments. This research includes speech recognition, natural language understanding & generation, dialogue management, cognitive agents, emotion modeling, question response managers, speech generation and non-verbal behavior. Also addressed will be the diverse set of training environments we have developed for the system, from single computer laptops to multi-computer immersive displays to real and virtual integrated environments. This paper will also discuss the problems, issues and solutions we encountered while building these systems. The paper will recount subject testing we have performed in these environments and results we have obtained from users. Finally the future of this type of Virtual Humans technology and training applications will be discussed.",2007.0,38.0,138.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Kenny2007BuildingIV,\n author = {Patrick G. Kenny and Arno Hartholt and J. Gratch and W. Swartout and David Traum and S. Marsella and D. Piepol},\n title = {Building Interactive Virtual Humans for Training Environments},\n year = {2007}\n}\n'}","[{'authorId': '3181776', 'name': 'Patrick G. Kenny'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1684040', 'name': 'W. Swartout'}, {'authorId': '2251500479', 'name': 'David Traum'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '1794931', 'name': 'D. Piepol'}]"
1722,94f65e53740b20f4527043dfee1cac606002a246,"Gesture in Spatial Cognition: Expressing, Communicating, and Thinking About Spatial Information","Do hand gestures play a role in spatial cognition? This paper reviews literature addressing the roles of gestures in (1) expressing spatial information, (2) communicating about spatial information, and (3) thinking about spatial information. Speakers tend to produce gestures when they produce linguistic units that contain spatial information, and they gesture more when talking about spatial topics than when talking about abstract or verbal ones. Thus, gestures are commonly used to express spatial information. Speakers use gestures more in situations when those gestures could contribute to communication, suggesting that they intend those gestures to communicate. Further, gestures influence addressees' comprehension of the speech they accompany, and addressees also detect information that is conveyed uniquely in gestures. Thus, gestures contribute to effective communication of spatial information. Gestures also play multiple roles in thinking about spatial information. There is evidence that gestures activate lexical and spatial representations, promote a focus on spatial information, and facilitate the packaging of spatial information in speech. Finally, some of the observed variation across tasks in gesture production is associated with task differences in demands on spatial cognitive processes, and individual differences in gesture production are associated with individual differences in spatial and verbal abilities. In sum, gestures appear to play multiple roles in spatial cognition. Central challenges for future research include: (1) better specification of the mental representations that give rise to gestures, (2) deeper understanding of the mechanisms by which gestures play a role in spatial thinking, and (3) greater knowledge of the sources of task and individual differences in gesture production.",2005.0,63.0,296.0,False,,"{'volume': '5', 'pages': '307 - 331', 'name': 'Spatial Cognition & Computation'}","{'bibtex': '@Article{Alibali2005GestureIS,\n author = {M. Alibali},\n journal = {Spatial Cognition & Computation},\n pages = {307 - 331},\n title = {Gesture in Spatial Cognition: Expressing, Communicating, and Thinking About Spatial Information},\n volume = {5},\n year = {2005}\n}\n'}","[{'authorId': '3177547', 'name': 'M. Alibali'}]"
1723,94f9869ec0b2294449755d87b20ccda67d789a82,Using ubiquitous games in an English listening and speaking course: Impact on learning outcomes and motivation,,2010.0,44.0,526.0,False,,"{'volume': '55', 'pages': '630-643', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Liu2010UsingUG,\n author = {Tsung-Yu Liu and Yu-Ling Chu},\n journal = {Comput. Educ.},\n pages = {630-643},\n title = {Using ubiquitous games in an English listening and speaking course: Impact on learning outcomes and motivation},\n volume = {55},\n year = {2010}\n}\n'}","[{'authorId': '2955636', 'name': 'Tsung-Yu Liu'}, {'authorId': '7239678', 'name': 'Yu-Ling Chu'}]"
1724,9559856a5ad1e590508492d159c030d0b9a86652,“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention,,2011.0,110.0,82.0,True,"{'url': 'http://sure.sunderland.ac.uk/id/eprint/1211/1/Fear_Not.pdf', 'status': None}","{'volume': '26', 'pages': '21-44', 'name': 'European Journal of Psychology of Education'}","{'bibtex': '@Article{Vannini2011FearNotAC,\n author = {Natalie Vannini and Sibylle Enz and Maria Sapouna and D. Wolke and Scott Watson and Sarah N. Woods and K. Dautenhahn and L. Hall and A. Paiva and E. André and R. Aylett and W. Schneider},\n journal = {European Journal of Psychology of Education},\n pages = {21-44},\n title = {“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention},\n volume = {26},\n year = {2011}\n}\n'}","[{'authorId': '2433163', 'name': 'Natalie Vannini'}, {'authorId': '1871494', 'name': 'Sibylle Enz'}, {'authorId': '4061979', 'name': 'Maria Sapouna'}, {'authorId': '2770059', 'name': 'D. Wolke'}, {'authorId': '2055786828', 'name': 'Scott Watson'}, {'authorId': '2773308', 'name': 'Sarah N. Woods'}, {'authorId': '1724361', 'name': 'K. Dautenhahn'}, {'authorId': '144160845', 'name': 'L. Hall'}, {'authorId': '2052450001', 'name': 'A. Paiva'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '1422027739', 'name': 'W. Schneider'}]"
1725,955a3afa2e6c6255b325497cfbab3bd97ed013aa,Emotion Recognition Based on Weighted Fusion Strategy of Multichannel Physiological Signals,"Emotion recognition is an important pattern recognition problem that has inspired researchers for several areas. Various data from humans for emotion recognition have been developed, including visual, audio, and physiological signals data. This paper proposes a decision-level weight fusion strategy for emotion recognition in multichannel physiological signals. Firstly, we selected four kinds of physiological signals, including Electroencephalography (EEG), Electrocardiogram (ECG), Respiration Amplitude (RA), and Galvanic Skin Response (GSR). And various analysis domains have been used in physiological emotion features extraction. Secondly, we adopt feedback strategy for weight definition, according to recognition rate of each emotion of each physiological signal based on Support Vector Machine (SVM) classifier independently. Finally, we introduce weight in decision level by linear fusing weight matrix with classification result of each SVM classifier. The experiments on the MAHNOB-HCI database show the highest accuracy. The results also provide evidence and suggest a way for further developing a more specialized emotion recognition system based on multichannel data using weight fusion strategy.",2018.0,34.0,40.0,True,"{'url': 'http://downloads.hindawi.com/journals/cin/2018/5296523.pdf', 'status': None}","{'volume': '2018', 'name': 'Computational Intelligence and Neuroscience'}","{'bibtex': '@Article{Wei2018EmotionRB,\n author = {Wei Wei and Q. Jia and Yongli Feng and Gang Chen},\n journal = {Computational Intelligence and Neuroscience},\n title = {Emotion Recognition Based on Weighted Fusion Strategy of Multichannel Physiological Signals},\n volume = {2018},\n year = {2018}\n}\n'}","[{'authorId': '2149193058', 'name': 'Wei Wei'}, {'authorId': '2301733', 'name': 'Q. Jia'}, {'authorId': '9196677', 'name': 'Yongli Feng'}, {'authorId': '72111341', 'name': 'Gang Chen'}]"
1726,956382ee75f05f1b1403f60d5ae1ebe8f407ebee,A Computational Model of Empathy: Empirical Evaluation,"Empathy can be defined as the ability to perceive and understand others' emotional states. Neuropsychological evidence has shown that humans empathize with each other to different degrees depending on factors such as their mood, personality, and social relationships. Although artificial agents have been endowed with features such as affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such features as factors that can modulate their empathic behavior. In this paper, we present and discuss the results of an empirical evaluation of a computational model of empathy which allows a virtual human to exhibit different degrees of empathy. Our model is supported by psychological models of empathy and is applied and evaluated in the context of a conversational agent scenario.",2013.0,16.0,31.0,False,,"{'pages': '1-6', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Boukricha2013ACM,\n author = {Hana Boukricha and I. Wachsmuth and M. N. Carminati and P. Knoeferle},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {1-6},\n title = {A Computational Model of Empathy: Empirical Evaluation},\n year = {2013}\n}\n'}","[{'authorId': '3262504', 'name': 'Hana Boukricha'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}, {'authorId': '35078906', 'name': 'M. N. Carminati'}, {'authorId': '7267206', 'name': 'P. Knoeferle'}]"
1727,9576d1573688a05e45ad30e783e7d0c10a10d6d9,Measuring emotion: the Self-Assessment Manikin and the Semantic Differential.,,1994.0,30.0,7810.0,False,,"{'volume': '25 1', 'pages': '\n          49-59\n        ', 'name': 'Journal of behavior therapy and experimental psychiatry'}","{'bibtex': '@Article{Bradley1994MeasuringET,\n author = {M. Bradley and P. Lang},\n journal = {Journal of behavior therapy and experimental psychiatry},\n pages = {\n          49-59\n        },\n title = {Measuring emotion: the Self-Assessment Manikin and the Semantic Differential.},\n volume = {25 1},\n year = {1994}\n}\n'}","[{'authorId': '2007419', 'name': 'M. Bradley'}, {'authorId': '143853826', 'name': 'P. Lang'}]"
1728,959291d5fddcf6d445bca68c1c726a3c7a381f17,A formal model of emotions for an empathic rational dialog agent,,2012.0,67.0,63.0,False,,"{'volume': '24', 'pages': '410-440', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Ochs2012AFM,\n author = {M. Ochs and D. Sadek and C. Pelachaud},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {410-440},\n title = {A formal model of emotions for an empathic rational dialog agent},\n volume = {24},\n year = {2012}\n}\n'}","[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1766725', 'name': 'D. Sadek'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1729,95a2b1b7093cf4d5910ad322bb5d1d4f7c5611a2,Dynamic Documents with R and knitr,"Suitable for both beginners and advanced users, this book shows you how to write reports in simple languages such as Markdown. The reports range from homework, projects, exams, books, blogs, and web pages to any documents related to statistical graphics, computing, and data analysis. While familiarity with LaTeX and HTML is helpful, the book requires no prior experience with advanced programs or languages. For beginners, the text provides enough features to get started on basic applications. For power users, the last several chapters enable an understanding of the extensibility of the knitr package.",2015.0,16.0,610.0,True,"{'url': 'https://www.jstatsoft.org/index.php/jss/article/view/v056b02/v56b02.pdf', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Xie2015DynamicDW,\n author = {Yihui Xie},\n title = {Dynamic Documents with R and knitr},\n year = {2015}\n}\n'}","[{'authorId': '49291169', 'name': 'Yihui Xie'}]"
1730,95ae7a29bc023c5092fb9fa42e669ac23ad01ce7,Human-to-Human Interaction Using Virtual Agent Posing as Another Person,"Opportunities for online distance education have greatly expanded in recent years, and agent-based interactions in virtual spaces have attracted attention in this context. In this talk, I will discuss the various educational possibilities of using virtual spaces and agents, by presenting examples from several studies. I will also introduce our own development of systems using game-based learning and a game-based story generation system that automatically generates scripts in real time on the basis of players’ emotions and actions. Finally, I will discuss persuasive technology that systems can use to influence human behavior, along with impressions and applications of facial expressions and gestures, which are expressions of agents, and I will discuss what can happen when a virtual agent interacts with other users in a virtual space.",2023.0,10.0,0.0,True,"{'url': 'https://alife-robotics.co.jp/members2023/icarob/data/html/data/PS/PS1.pdf', 'status': 'BRONZE'}",{'name': 'Proceedings of International Conference on Artificial Life and Robotics'},"{'bibtex': '@Article{Sumi2023HumantoHumanIU,\n author = {Kaoru Sumi},\n booktitle = {Proceedings of International Conference on Artificial Life and Robotics},\n journal = {Proceedings of International Conference on Artificial Life and Robotics},\n title = {Human-to-Human Interaction Using Virtual Agent Posing as Another Person},\n year = {2023}\n}\n'}","[{'authorId': '145441214', 'name': 'Kaoru Sumi'}]"
1731,95b803d07c37e8349bd7b1318367d8237c76cbc0,Audio-driven facial animation by joint end-to-end learning of pose and emotion,"We present a machine learning technique for driving 3D facial animation by audio input in real time and with low latency. Our deep neural network learns a mapping from input waveforms to the 3D vertex coordinates of a face model, and simultaneously discovers a compact, latent code that disambiguates the variations in facial expression that cannot be explained by the audio alone. During inference, the latent code can be used as an intuitive control for the emotional state of the face puppet. We train our network with 3--5 minutes of high-quality animation data obtained using traditional, vision-based performance capture methods. Even though our primary goal is to model the speaking style of a single actor, our model yields reasonable results even when driven with audio from other speakers with different gender, accent, or language, as we demonstrate with a user study. The results are applicable to in-game dialogue, low-cost localization, virtual reality avatars, and telepresence.",2017.0,53.0,305.0,False,,"{'volume': '36', 'pages': '1 - 12', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Karras2017AudiodrivenFA,\n author = {Tero Karras and Timo Aila and S. Laine and Antti Herva and J. Lehtinen},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 12},\n title = {Audio-driven facial animation by joint end-to-end learning of pose and emotion},\n volume = {36},\n year = {2017}\n}\n'}","[{'authorId': '2976930', 'name': 'Tero Karras'}, {'authorId': '1761103', 'name': 'Timo Aila'}, {'authorId': '36436218', 'name': 'S. Laine'}, {'authorId': '3468872', 'name': 'Antti Herva'}, {'authorId': '49244945', 'name': 'J. Lehtinen'}]"
1732,960e0dd0cc0968c72cca2cea09f4a3013e7f65af,Virtual reality exposure therapy for anxiety and related disorders: A meta-analysis of randomized controlled trials.,,2019.0,70.0,419.0,False,,"{'volume': '61', 'pages': '\n          27-36\n        ', 'name': 'Journal of anxiety disorders'}","{'bibtex': '@Article{Carl2019VirtualRE,\n author = {Emily Carl and Aliza T. Stein and Andrew Levihn-Coon and Jamie R. Pogue and B. Rothbaum and P. Emmelkamp and G. Asmundson and P. Carlbring and Mark B. Powers},\n journal = {Journal of anxiety disorders},\n pages = {\n          27-36\n        },\n title = {Virtual reality exposure therapy for anxiety and related disorders: A meta-analysis of randomized controlled trials.},\n volume = {61},\n year = {2019}\n}\n'}","[{'authorId': '50816622', 'name': 'Emily Carl'}, {'authorId': '51256809', 'name': 'Aliza T. Stein'}, {'authorId': '1469026892', 'name': 'Andrew Levihn-Coon'}, {'authorId': '82937375', 'name': 'Jamie R. Pogue'}, {'authorId': '1382321016', 'name': 'B. Rothbaum'}, {'authorId': '2282500', 'name': 'P. Emmelkamp'}, {'authorId': '1943781409', 'name': 'G. Asmundson'}, {'authorId': '2538572', 'name': 'P. Carlbring'}, {'authorId': '3052779', 'name': 'Mark B. Powers'}]"
1733,961e2908c80c6f1e09fb12e1390def4be5db4d93,VR-Based Conversation Training Program for Patients with Schizophrenia: A Preliminary Clinical Trial,"Schizophrenia is a devastating mental illness and is characterized by hallucinations and delusions as well as social skills deficits. Generally, social skills training designed to help patients develop social skills includes role-playing, but this form of training has typical shortcomings, which are largely due to a trainer's difficulties to project emotion. Virtual reality (VR)-based techniques have the potential to solve these difficulties, because they provide a computer-generated but realistic three-dimensional world and humanlike avatars that can provide emotional stimuli. In this paper, we report on a method of implementing virtual environments (VEs) in order to train people with schizophrenia to develop conversational skills in specific situations, which could overcome the shortcomings of or complement conventional role-playing techniques. The paper reports the efficacy of the proposed approach in a preliminary clinical trial with 10 patients with schizophrenia.",2007.0,18.0,64.0,False,,"{'volume': '10 4', 'pages': '\n          567-74\n        ', 'name': 'Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society'}","{'bibtex': '@Article{Ku2007VRBasedCT,\n author = {J. Ku and Kiwan Han and Hyung Lee and H. Jang and K. Kim and Sung Hyouk Park and Jae-Jin Kim and Chan-Hyung Kim and I. Kim and Sun I. Kim},\n journal = {Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society},\n pages = {\n          567-74\n        },\n title = {VR-Based Conversation Training Program for Patients with Schizophrenia: A Preliminary Clinical Trial},\n volume = {10 4},\n year = {2007}\n}\n'}","[{'authorId': '143720898', 'name': 'J. Ku'}, {'authorId': '2148824601', 'name': 'Kiwan Han'}, {'authorId': '2110210855', 'name': 'Hyung Lee'}, {'authorId': '3287618', 'name': 'H. Jang'}, {'authorId': '1973742', 'name': 'K. Kim'}, {'authorId': '2237307', 'name': 'Sung Hyouk Park'}, {'authorId': '2145449477', 'name': 'Jae-Jin Kim'}, {'authorId': '2897323', 'name': 'Chan-Hyung Kim'}, {'authorId': '2219074220', 'name': 'I. Kim'}, {'authorId': '1455996091', 'name': 'Sun I. Kim'}]"
1734,962cf4ead989b6d5620497a018988d5776158cc5,Multi-user Robot Impression with a Virtual Agent and Features Modification According to Real-time Emotion from Physiological Signals,"Communication robots are now getting popular. In particular, partner robots, which can perform personal services, are in high demand. However, they can be prohibitively expensive. Therefore, we considered a multi-user robot with a virtual agent service which could satisfy user demands. But, several issues need to be solved in order to achieve this purpose. Firstly, there is no general service platform for such robots. Secondly, even if we use the multi-user robot by executing the virtual agent service, the physical shape, and other characteristics of the multi-user robot sometimes creates a strong impression on users. Therefore, we proposed a virtual agent service platform, and the robot features modification for a multi-user robot. The robot can autonomously adjust its position according to each user’s physiological signals, which based on emotion in real-time. We presented a preliminary evaluation to determine whether the proposed method could improve users’ robot experience even for the users who are not familiar with the robot at all.",2020.0,16.0,0.0,False,,"{'name': '2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)', 'pages': '1006-1012'}","{'bibtex': '@Article{Suzuki2020MultiuserRI,\n author = {Shoudai Suzuki and M. N. Anuardi and Peeraya Sripian and N. Matsuhira and Midori Sugaya},\n booktitle = {IEEE International Symposium on Robot and Human Interactive Communication},\n journal = {2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},\n pages = {1006-1012},\n title = {Multi-user Robot Impression with a Virtual Agent and Features Modification According to Real-time Emotion from Physiological Signals},\n year = {2020}\n}\n'}","[{'authorId': '1995826585', 'name': 'Shoudai Suzuki'}, {'authorId': '2679060', 'name': 'M. N. Anuardi'}, {'authorId': '2042016', 'name': 'Peeraya Sripian'}, {'authorId': '3299510', 'name': 'N. Matsuhira'}, {'authorId': '145094033', 'name': 'Midori Sugaya'}]"
1735,96421c506cd1027552d8040b858948bc351bc973,Psychometric evaluation of Simulator Sickness Questionnaire and its variants as a measure of cybersickness in consumer virtual environments.,,2019.0,71.0,98.0,False,,"{'volume': '82', 'pages': '\n          102958\n        ', 'name': 'Applied ergonomics'}","{'bibtex': '@Article{Sevinç2019PsychometricEO,\n author = {V. Sevinç and M. Berkman},\n journal = {Applied ergonomics},\n pages = {\n          102958\n        },\n title = {Psychometric evaluation of Simulator Sickness Questionnaire and its variants as a measure of cybersickness in consumer virtual environments.},\n volume = {82},\n year = {2019}\n}\n'}","[{'authorId': '90935194', 'name': 'V. Sevinç'}, {'authorId': '75109453', 'name': 'M. Berkman'}]"
1736,9645b941e3db4bc017cc2d80ee6315fe95650dc1,Emotional contagion between user and product recommendation virtual agent,"The notion of Emotional contagion is a phenomenon in which a human emotion infects others. Various studies have been done to cause emotional contagion between a human and a robot or an anthropomorphic agent in HRI research fields. However, few studies have been done to compare different kinds of agents in order to find important properties in emotional contagion in human-agent interaction (HAI). In this research, we conducted an experiment to determine which properties cause this phenomenon between anthropomorphic agents and users. We prepared two kinds of agents. One is a cartoon-like agent, and the other is a concrete agent. The cartoon-like agent smiled exaggeratedly, and the concrete agent smiled modestly. As a result, we found that the concrete agent was more effective than the cartoon-like agent at emotional contagion. This result suggests a model for designing more trustworthy and familiar agents and robots.",2016.0,16.0,4.0,False,,"{'name': '2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)', 'pages': '1172-1176'}","{'bibtex': '@Article{Matsui2016EmotionalCB,\n author = {T. Matsui and S. Yamada},\n booktitle = {IEEE International Symposium on Robot and Human Interactive Communication},\n journal = {2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},\n pages = {1172-1176},\n title = {Emotional contagion between user and product recommendation virtual agent},\n year = {2016}\n}\n'}","[{'authorId': '49201495', 'name': 'T. Matsui'}, {'authorId': '1679243', 'name': 'S. Yamada'}]"
1737,967f32841955b72f358190436baa5510839d9ab3,A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins,.,,9.0,5557.0,False,,,"{'bibtex': '@Misc{None,\n author = {Sagl B Needle and Asd Christus and D. Wuksch},\n title = {A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins}\n}\n'}","[{'authorId': '2223654620', 'name': 'Sagl B Needle'}, {'authorId': '2223656870', 'name': 'Asd Christus'}, {'authorId': '2223654618', 'name': 'D. Wuksch'}]"
1738,96a762cdead5b85474f4287bc96e8f2dc52fc873,Artificial neuro fuzzy logic system for detecting human emotions,,2012.0,41.0,56.0,True,,"{'volume': '3', 'pages': '1-13', 'name': 'Human-centric Computing and Information Sciences'}","{'bibtex': '@Article{Malkawi2012ArtificialNF,\n author = {M. Malkawi and Omayya Murad},\n journal = {Human-centric Computing and Information Sciences},\n pages = {1-13},\n title = {Artificial neuro fuzzy logic system for detecting human emotions},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '50544160', 'name': 'M. Malkawi'}, {'authorId': '5806627', 'name': 'Omayya Murad'}]"
1739,96b3b2b6814593159122d5c6590d50a51d4f338e,Seeing More Than Human: Autism and Anthropomorphic Theory of Mind,"Theory of mind (ToM) is defined as the process of taking another’s perspective. Anthropomorphism can be seen as the extension of ToM to non-human entities. This review examines the literature concerning ToM and anthropomorphism in relation to individuals with Autism Spectrum Disorder (ASD), specifically addressing the questions of how and why those on the spectrum both show an increased interest for anthropomorphism and may even show improved ToM abilities when judging the mental states of anthropomorphic characters. This review highlights that while individuals with ASD traditionally show deficits on a wide range of ToM tests, such as recognizing facial emotions, such ToM deficits may be ameliorated if the stimuli presented is cartoon or animal-like rather than in human form. Individuals with ASD show a greater interest in anthropomorphic characters and process the features of these characters using methods typically reserved for human stimuli. Personal accounts of individuals with ASD also suggest they may identify more closely with animals than other humans. It is shown how the social motivations hypothesized to underlie the anthropomorphizing of non-human targets may lead those on the spectrum to seek social connections and therefore gain ToM experience and expertise amongst unlikely sources.",2018.0,186.0,42.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00528/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Atherton2018SeeingMT,\n author = {Gray Atherton and Liam B. Cross},\n journal = {Frontiers in Psychology},\n title = {Seeing More Than Human: Autism and Anthropomorphic Theory of Mind},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '143639742', 'name': 'Gray Atherton'}, {'authorId': '143784184', 'name': 'Liam B. Cross'}]"
1740,96c1401e7b1fe0b539f8a2fe4ba4183f9e9812f8,The virtual little albert experiment: Creating conditioned emotion response in virtual agents,"Agent designers typically specify how an agent should interpret stimuli it receives. Designers also provide the agent with a list of actions from which the agent chooses a response based on the stimulation. We present a system where the agent's response to new stimuli is based solely on its memory and emotional state with no predefined response suggested other than for unconditioned stimuli like getting burned or, in this case, hearing a scary noise. We then let unspecified emotion emerge within the agent for newly encountered stimuli by association with these unconditioned stimuli. We use our agent to recreate a virtual version of the Little Albert Experiment, and were able to reproduce a form of conditioned emotion response without directing the agent's perception, appraisal or response.",2015.0,24.0,2.0,False,,"{'name': '2015 IEEE Games Entertainment Media Conference (GEM)', 'pages': '1-8'}","{'bibtex': '@Article{Patrick2015TheVL,\n author = {Alexander Patrick and Curtis L Gittens and M. Katchabaw},\n booktitle = {IEEE Games Entertainment Media Conference},\n journal = {2015 IEEE Games Entertainment Media Conference (GEM)},\n pages = {1-8},\n title = {The virtual little albert experiment: Creating conditioned emotion response in virtual agents},\n year = {2015}\n}\n'}","[{'authorId': '2060687559', 'name': 'Alexander Patrick'}, {'authorId': '2813638', 'name': 'Curtis L Gittens'}, {'authorId': '1793961', 'name': 'M. Katchabaw'}]"
1741,96c4c5293681138997d2659a80d177acd8220aa4,Empathy: A Social Psychological Approach,"This multidimensional approach brings together cognitive, sociobiological and behavioural perspectives providing students with a thorough, vet balanced and well-synthesised presentation of contemporary empathy research. The author approaches the topic in two ways: 1. through empirical work which is examined in a variety of empathy-related areas, clearly recognising the theoretical context; 2. through an organisational model which puts the smaller pieces into one, more coherent whole.",1994.0,1.0,2227.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Davis1994EmpathyAS,\n author = {Mark H. Davis},\n title = {Empathy: A Social Psychological Approach},\n year = {1994}\n}\n'}","[{'authorId': '47994338', 'name': 'Mark H. Davis'}]"
1742,96d04974f796ee1b80d4988ff5cd3b25efeaab4d,Appraisal considered as a process of multilevel sequential checking.,,2001.0,0.0,1635.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Scherer2001AppraisalCA,\n author = {K. Scherer},\n title = {Appraisal considered as a process of multilevel sequential checking.},\n year = {2001}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}]"
1743,96ee1e388a823aa0ef5bd98032e7443d69dc5115,"Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later",,2015.0,0.0,14.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s40593-015-0065-9.pdf', 'status': None}","{'volume': '26', 'pages': '25 - 36', 'name': 'International Journal of Artificial Intelligence in Education'}","{'bibtex': '@Article{Johnson2015FacetoFaceIW,\n author = {W. Johnson and James C. Lester},\n journal = {International Journal of Artificial Intelligence in Education},\n pages = {25 - 36},\n title = {Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later},\n volume = {26},\n year = {2015}\n}\n'}","[{'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
1744,970a5047a7b0a119f17b96297269301134524a27,GameTeen: New Tools for Evaluating and Training Emotional Regulation Strategies,"The aim of this paper is to describe GameTeen, a novel instrument for the assessment and training of Emotional Regulation (ER) strategies in adolescent population. These new tools are based on the use of 3D serious games that can be played under different settings. The evolution of ER strategies will be monitored in two ways depending on the setting where the tool is presented. Firstly, in the laboratory, physiological signals and facial expressions of participants will be recorded. Secondly, in real life settings, ecological momentary assessment tools will be used to obtain answers from the subjects using their mobile phone. The goal is to obtain more attractive and reliable tools to evaluate and train ER strategies.",2012.0,7.0,6.0,False,,"{'volume': '181', 'pages': '\n          334-8\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Rodríguez2012GameTeenNT,\n author = {Alejandro Rodríguez and B. Rey and M. Alcañiz and R. Baños and J. Guixeres and Maja Wrzesien and M. Martínez and D. Pérez and P. Rasal and Elena Parra},\n journal = {Studies in health technology and informatics},\n pages = {\n          334-8\n        },\n title = {GameTeen: New Tools for Evaluating and Training Emotional Regulation Strategies},\n volume = {181},\n year = {2012}\n}\n'}","[{'authorId': '2110469674', 'name': 'Alejandro Rodríguez'}, {'authorId': '144255441', 'name': 'B. Rey'}, {'authorId': '144485391', 'name': 'M. Alcañiz'}, {'authorId': '145562686', 'name': 'R. Baños'}, {'authorId': '3077120', 'name': 'J. Guixeres'}, {'authorId': '1807427', 'name': 'Maja Wrzesien'}, {'authorId': '144081629', 'name': 'M. Martínez'}, {'authorId': '2054088869', 'name': 'D. Pérez'}, {'authorId': '145206410', 'name': 'P. Rasal'}, {'authorId': '145135774', 'name': 'Elena Parra'}]"
1745,970aa7c680bd34cf9c0abc8df4dcbd31b24465a3,Neural correlates underlying change in state self-esteem,,2018.0,64.0,20.0,True,"{'url': 'https://www.nature.com/articles/s41598-018-20074-0.pdf', 'status': None}","{'volume': '8', 'name': 'Scientific Reports'}","{'bibtex': '@Article{Kawamichi2018NeuralCU,\n author = {H. Kawamichi and Sho K. Sugawara and Yuki H. Hamano and R. Kitada and E. Nakagawa and T. Kochiyama and N. Sadato},\n journal = {Scientific Reports},\n title = {Neural correlates underlying change in state self-esteem},\n volume = {8},\n year = {2018}\n}\n'}","[{'authorId': '2201191', 'name': 'H. Kawamichi'}, {'authorId': '25569909', 'name': 'Sho K. Sugawara'}, {'authorId': '47509042', 'name': 'Yuki H. Hamano'}, {'authorId': '3236294', 'name': 'R. Kitada'}, {'authorId': '38381724', 'name': 'E. Nakagawa'}, {'authorId': '1757663', 'name': 'T. Kochiyama'}, {'authorId': '1843699', 'name': 'N. Sadato'}]"
1746,97117e18cb9351e39ab18b7a8ebd34511bba8240,Conceptions of sex role. Some cross-cultural and longitudinal perspectives.,,1973.0,13.0,796.0,False,,"{'volume': '28 6', 'pages': '\n          512-26\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Block1973ConceptionsOS,\n author = {J. Block},\n journal = {The American psychologist},\n pages = {\n          512-26\n        },\n title = {Conceptions of sex role. Some cross-cultural and longitudinal perspectives.},\n volume = {28 6},\n year = {1973}\n}\n'}","[{'authorId': '81246914', 'name': 'J. Block'}]"
1747,97484d486832a6eef3f9c309c2819f168515773f,Impact of Technology,"Overview The heathcare academic literature seems to be saturated with articles on technology. The articles in this section are intended to be representative, covering a wide range of topics relating to the impact of technology on the healthcare system. Most articles assume that the overall impact is positive and focus on how to assess technology as it changes or what to do in light of its rapid and continuing advancement. Although these articles indicate overwhelming belief that technology’s impact is one of potentially great benefit, different levels of caution accompany this positive assessment.",2008.0,13.0,61.0,False,,"{'volume': '', 'pages': '389-394', 'name': ''}","{'bibtex': '@Inproceedings{Surry2008ImpactOT,\n author = {D. Surry},\n pages = {389-394},\n title = {Impact of Technology},\n year = {2008}\n}\n'}","[{'authorId': '37927655', 'name': 'D. Surry'}]"
1748,97510e2048af0c6c510aed405091514946c4eb13,"The moderator-mediator variable distinction in social psychological research: conceptual, strategic, and statistical considerations.","In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.",1986.0,54.0,83748.0,True,"{'url': 'http://www.public.asu.edu/%7Edavidpm/classes/psy536/Baron.pdf', 'status': None}","{'volume': '51 6', 'pages': '\n          1173-82\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Baron1986TheMV,\n author = {R. M. Baron and D. Kenny},\n journal = {Journal of personality and social psychology},\n pages = {\n          1173-82\n        },\n title = {The moderator-mediator variable distinction in social psychological research: conceptual, strategic, and statistical considerations.},\n volume = {51 6},\n year = {1986}\n}\n'}","[{'authorId': '114028501', 'name': 'R. M. Baron'}, {'authorId': '2060895', 'name': 'D. Kenny'}]"
1749,975884b5c5ce5616f87c8090d80e40cef541bc23,Patient adherence in the treatment of depression,"Background Non-adherence with antidepressant treatment is very common. Increasing adherence to pharmacological treatment may affect response rate. Aims To review and summarise quantitative evidence on factors associated with adherence and of adherence-enhancing interventions. Method A systematic review of computerised databases was carried out to identify quantitative studies of adherence in depression. Papers retained addressed unipolar depression and considered adherence as the primary end-point. Results Of studies published between 1973 and 1999, 32 met the review criteria: epidemiological descriptive studies (n=14): non-random comparisons of control and intervention groups (n=3); randomised interventions (n=14); and meta-analysis (n=1). Patient education and medication clinics were the interventions most commonly tested, combined with a variety of other interventions. Conclusions The studies did not give consistent indications of which interventions may be effective. Carefully designed clinical trials are needed to clarify the effect of single and combined interventions.",2002.0,44.0,295.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D1E0018DE9F9FB948E13B668FA8B817C/S0007125000270803a.pdf/div-class-title-patient-adherence-in-the-treatment-of-depression-div.pdf', 'status': None}","{'volume': '180', 'pages': '104 - 109', 'name': 'British Journal of Psychiatry'}","{'bibtex': '@Article{Pampallona2002PatientAI,\n author = {S. Pampallona and P. Bollini and G. Tibaldi and B. Kupelnick and C. Munizza},\n journal = {British Journal of Psychiatry},\n pages = {104 - 109},\n title = {Patient adherence in the treatment of depression},\n volume = {180},\n year = {2002}\n}\n'}","[{'authorId': '4641834', 'name': 'S. Pampallona'}, {'authorId': '2521914', 'name': 'P. Bollini'}, {'authorId': '4468378', 'name': 'G. Tibaldi'}, {'authorId': '4769619', 'name': 'B. Kupelnick'}, {'authorId': '5516335', 'name': 'C. Munizza'}]"
1750,97947d10a2e4d79a34c5996bf9f8e2b1fc47f427,Creativity and negotiation research: the integrative potential,"Purpose – The purpose of this article is to outline ways in which the large body of empirical work on creativity can meaningfully inform negotiation. In doing so, two general streams of creativity research and their implications for negotiation theory and empirical analysis are considered. Negotiation pundits advise that negotiators should engage in creative problem-solving to craft integrative agreements, and it is widely believed by both negotiation theorists and practitioners that “out-of-the-box” thinking and creative idea generation are necessary for win–win negotiation. Although practitioners have strongly encouraged parties to engage in creative problem-solving, there are remarkably few empirical investigations of creative thinking, brainstorming and other idea-generation methods in negotiation. Design/methodology/approach – First, creativity as a trait is considered and the relationship between individual differences in creativity and negotiation performance is examined. Then, creative thinking as...",2014.0,133.0,15.0,False,,"{'volume': '25', 'pages': '359-386', 'name': 'International Journal of Conflict Management'}","{'bibtex': '@Article{Wilson2014CreativityAN,\n author = {E. Wilson and Leigh Thompson},\n journal = {International Journal of Conflict Management},\n pages = {359-386},\n title = {Creativity and negotiation research: the integrative potential},\n volume = {25},\n year = {2014}\n}\n'}","[{'authorId': '145495014', 'name': 'E. Wilson'}, {'authorId': '50405579', 'name': 'Leigh Thompson'}]"
1751,97a5f812142511d02c6cec9f036a691783dcc202,Virtual peers as partners in storytelling and literacy learning,"Abstract  Literacy learning — learning how to read and write — begins long before children enter school. One of the key skills to reading and writing is the ability to represent thoughts symbolically and share them in language with an audience who may not necessarily share the same temporal and spatial context. Children learn and practice these important language skills everyday, telling stories with the peers and adults around them. In particular, storytelling in the context of peer collaboration provides a key environment for children to learn language skills important for literacy. In light of this, an embodied conversational agent, Sam, who tells stories collaboratively with children was designed. Sam looks like a peer for pre-school children, but tells stories in a developmentally advanced way, modelling narrative skills important for literacy. Results demonstrated that children who played with the virtual peer told stories that more closely resembled the virtual peer's linguistically advanced stories: using more quoted speech and temporal and spatial expressions. In addition, children listened to Sam's stories carefully, assisting her and suggesting improvements. The potential benefits of having technology play a social role in young children's literacy learning is discussed.",2003.0,50.0,260.0,False,,"{'volume': '19', 'pages': '195-208', 'name': 'J. Comput. Assist. Learn.'}","{'bibtex': '@Article{Ryokai2003VirtualPA,\n author = {Kimiko Ryokai and C. Boulanger and Justine Cassell},\n journal = {J. Comput. Assist. Learn.},\n pages = {195-208},\n title = {Virtual peers as partners in storytelling and literacy learning},\n volume = {19},\n year = {2003}\n}\n'}","[{'authorId': '2455971', 'name': 'Kimiko Ryokai'}, {'authorId': '2230970', 'name': 'C. Boulanger'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
1752,97bcea32979ed602fd404448a4e4cedad4171d79,Impact of Personality on Nonverbal Behavior Generation,"To realize natural-looking virtual agents, one key technical challenge is to automatically generate nonverbal behaviors from spoken language. Since nonverbal behavior varies depending on personality, it is important to generate these nonverbal behaviors to match the expected personality of a virtual agent. In this work, we study how personality traits relate to the process of generating individual nonverbal behaviors from the whole body, including the head, eye gaze, arms, and posture. To study this, we first created a dialogue corpus including transcripts, a broad range of labelled nonverbal behaviors, and the Big Five personality scores of participants in dyad interactions. We constructed models that can predict each nonverbal behavior label given as an input language representation from the participants' spoken sentences. Our experimental results show that personality can help improve the prediction of nonverbal behaviors.",2020.0,61.0,9.0,False,,{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Ishii2020ImpactOP,\n author = {Ryo Ishii and Chaitanya Ahuja and Y. Nakano and Louis-Philippe Morency},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Impact of Personality on Nonverbal Behavior Generation},\n year = {2020}\n}\n'}","[{'authorId': '1736448', 'name': 'Ryo Ishii'}, {'authorId': '118242121', 'name': 'Chaitanya Ahuja'}, {'authorId': '1718158', 'name': 'Y. Nakano'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
1753,97cf5e8e117f758e08c81fbe2af17b9fe8e1f408,The FML-APML language,"In this paper we present a new version of the APML (Affective Presentation Markup Language, [?]) representation language, called FML-APML. This new version encompasses the tags of APML as well as other tags related, for example, to world references and emotional state. The presented language has been developed in the Greta framework [?]. Greta is an ECA (Embodied Conversational Agent) that starting from a representation of its communicative intention, plans the verbal (speech) and nonverbal signals (facial expressions, head movements, gestures) in order to convey it. We use the FML-APML language to model the agent’s communicative intention.",2008.0,0.0,20.0,False,,,"{'bibtex': '@Inproceedings{Mancini2008TheFL,\n author = {M. Mancini and C. Pelachaud},\n title = {The FML-APML language},\n year = {2008}\n}\n'}","[{'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1754,97d665a781947ad74f10f9e05888ba931df5b820,Effects of direct and averted gaze on the perception of facially communicated emotion.,"Research has largely neglected the effects of gaze direction cues on the perception of facial expressions of emotion. It was hypothesized that when gaze direction matches the underlying behavioral intent (approach-avoidance) communicated by an emotional expression, the perception of that emotion would be enhanced (i.e., shared signal hypothesis). Specifically, the authors expected that (a) direct gaze would enhance the perception of approach-oriented emotions (anger and joy) and (b) averted eye gaze would enhance the perception of avoidance-oriented emotions (fear and sadness). Three studies supported this hypothesis. Study 1 examined emotional trait attributions made to neutral faces. Study 2 examined ratings of ambiguous facial blends of anger and fear. Study 3 examined the influence of gaze on the perception of highly prototypical expressions.",2005.0,65.0,566.0,False,,"{'volume': '5 1', 'pages': '\n          3-11\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Adams2005EffectsOD,\n author = {R. B. Adams and R. Kleck},\n journal = {Emotion},\n pages = {\n          3-11\n        },\n title = {Effects of direct and averted gaze on the perception of facially communicated emotion.},\n volume = {5 1},\n year = {2005}\n}\n'}","[{'authorId': '2075454382', 'name': 'R. B. Adams'}, {'authorId': '4170904', 'name': 'R. Kleck'}]"
1755,97dd654e0985e35ad4be14841bcb70fde7300f46,Differential Evolution: A Practical Approach to Global Optimization,"Problems demanding globally optimal solutions are ubiquitous, yet many are intractable when they involve constrained functions having many local optima and interacting, mixed-type variables.The differential evolution (DE) algorithm is a practical approach to global numerical optimization which is easy to understand, simple to implement, reliable, and fast. Packed with illustrations, computer code, new insights, and practical advice, this volume explores DE in both principle and practice. It is a valuable resource for professionals needing a proven optimizer and for students wanting an evolutionary perspective on global numerical optimization.",2014.0,0.0,6118.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Price2014DifferentialEA,\n author = {K. Price and R. Storn and J. Lampinen},\n title = {Differential Evolution: A Practical Approach to Global Optimization},\n year = {2014}\n}\n'}","[{'authorId': '30516941', 'name': 'K. Price'}, {'authorId': '2389722', 'name': 'R. Storn'}, {'authorId': '1680702', 'name': 'J. Lampinen'}]"
1756,97e6b062671cd18bdc8d4c0800afdca397335e2a,On the Identification of Speakers by Voice,"The effect of several factors upon voice identification was examined. These factors were: the size of the class of possible voices, the duration of the speech signal, the frequency range of the speech signal, voicing vs nonvoicing speech characteristics, and the simultaneous presentation of several voices. One of the most effective factors for speaker identification was the duration of the speech signal. Duration, as such, appears to be important, however, only insofar as it admits a smaller or larger statistical sampling of the speaker's speech repertoire.",1954.0,0.0,168.0,False,,"{'volume': '26', 'pages': '403-406', 'name': 'Journal of the Acoustical Society of America'}","{'bibtex': '@Article{Pollack1954OnTI,\n author = {I. Pollack and J. Pickett and W. H. Sumby},\n journal = {Journal of the Acoustical Society of America},\n pages = {403-406},\n title = {On the Identification of Speakers by Voice},\n volume = {26},\n year = {1954}\n}\n'}","[{'authorId': '70611381', 'name': 'I. Pollack'}, {'authorId': '144583875', 'name': 'J. Pickett'}, {'authorId': '16719494', 'name': 'W. H. Sumby'}]"
1757,97efafdb4a3942ab3efba53ded7413199f79c054,Reinforcement Learning: An Introduction,,2005.0,,,,,,,[]
1758,97fc82faf465f28db5ca3fca58315a3e98f47130,A Theory of Affective Communication: On the Phenomenological Foundations of Perspective Taking,,2018.0,56.0,3.0,False,,"{'volume': '41', 'pages': '623-641', 'name': 'Human Studies'}","{'bibtex': '@Article{Julmi2018ATO,\n author = {C. Julmi},\n journal = {Human Studies},\n pages = {623-641},\n title = {A Theory of Affective Communication: On the Phenomenological Foundations of Perspective Taking},\n volume = {41},\n year = {2018}\n}\n'}","[{'authorId': '2081091091', 'name': 'C. Julmi'}]"
1759,97fc86fd169215c1c0dea5274eaabba56d537736,Aging and Attentional Biases for Emotional Faces,"We examined age differences in attention to and memory for faces expressing sadness, anger, and happiness. Participants saw a pair of faces, one emotional and one neutral, and then a dot probe that appeared in the location of one of the faces. In two experiments, older adults responded faster to the dot if it was presented on the same side as a neutral face than if it was presented on the same side as a negative face. Younger adults did not exhibit this attentional bias. Interactions of age and valence were also found for memory for the faces, with older adults remembering positive better than negative faces. These findings reveal that in their initial attention, older adults avoid negative information. This attentional bias is consistent with older adults' generally better emotional well-being and their tendency to remember negative less well than positive information.",2003.0,37.0,771.0,True,"{'url': 'https://escholarship.org/content/qt8n37k31f/qt8n37k31f.pdf?t=lnpvgw', 'status': None}","{'volume': '14', 'pages': '409 - 415', 'name': 'Psychological Science'}","{'bibtex': '@Article{Mather2003AgingAA,\n author = {M. Mather and L. Carstensen},\n journal = {Psychological Science},\n pages = {409 - 415},\n title = {Aging and Attentional Biases for Emotional Faces},\n volume = {14},\n year = {2003}\n}\n'}","[{'authorId': '2145954', 'name': 'M. Mather'}, {'authorId': '5994816', 'name': 'L. Carstensen'}]"
1760,980dc62e4a1724b7f5dbc649dda8e08011e6bac1,Enhancing Conversational Agents with Empathic Abilities,"Conversational agents are getting increasingly popular and find applications in health and customer services. Conversations in these fields are often emotionally charged. It is, therefore, necessary to handle the conversation with some degree of empathy to be effective. In this work, we leverage advances in the field of natural language processing to create a dialogue system that can convincingly generate empathic responses to text-based messages. To improve the system's ability to converse with empathy, we train the language model on empathic conversations and inject additional emotional information in the response generation. We propose two chatbots: a benchmark bot and an empathic bot. Additionally, we implement an emotion classifier that allows us to predict the emotional state of text-based messages. We evaluate both chatbots in quantitative studies and compare them with human responses in qualitative studies involving human judges. Our evaluation shows that our empathic chatbot outperforms the benchmark bot and even the human-generated responses in terms of perceived empathy. Additionally, we achieve state-of-the-art results in terms of response quality using transformer-based language models. Finally we report that we can double the initial performance of the emotion classifier using undersampling techniques, yielding a final F1-score of 0.81 in six basic emotions.",2021.0,31.0,11.0,False,,{'name': 'Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Casas2021EnhancingCA,\n author = {Jacky Casas and Timo Spring and Karl Daher and E. Mugellini and Omar Abou Khaled and P. Cudré-Mauroux},\n journal = {Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents},\n title = {Enhancing Conversational Agents with Empathic Abilities},\n year = {2021}\n}\n'}","[{'authorId': '144558519', 'name': 'Jacky Casas'}, {'authorId': '50817194', 'name': 'Timo Spring'}, {'authorId': '1396363912', 'name': 'Karl Daher'}, {'authorId': '1802011', 'name': 'E. Mugellini'}, {'authorId': '72699451', 'name': 'Omar Abou Khaled'}, {'authorId': '1393644275', 'name': 'P. Cudré-Mauroux'}]"
1761,9819b600a828a57e1cde047bbe710d3446b30da5,Recurrent neural network based language model,"A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition",2010.0,17.0,5549.0,False,,{'pages': '1045-1048'},"{'bibtex': '@Inproceedings{Mikolov2010RecurrentNN,\n author = {Tomas Mikolov and M. Karafiát and L. Burget and J. Černocký and S. Khudanpur},\n pages = {1045-1048},\n title = {Recurrent neural network based language model},\n year = {2010}\n}\n'}","[{'authorId': '2047446108', 'name': 'Tomas Mikolov'}, {'authorId': '2245567', 'name': 'M. Karafiát'}, {'authorId': '1816892', 'name': 'L. Burget'}, {'authorId': '1899242', 'name': 'J. Černocký'}, {'authorId': '2803071', 'name': 'S. Khudanpur'}]"
1762,983d36220b46a910489fc026ceb91b5857f4694d,A meta-analysis of emotion perception and functional outcomes in schizophrenia,,2012.0,72.0,161.0,True,"{'url': 'https://europepmc.org/articles/pmc3351501?pdf=render', 'status': None}","{'volume': '137', 'pages': '203-211', 'name': 'Schizophrenia Research'}","{'bibtex': '@Article{Irani2012AMO,\n author = {F. Irani and Sarah C. Seligman and Vidyulata Kamath and C. Kohler and R. Gur},\n journal = {Schizophrenia Research},\n pages = {203-211},\n title = {A meta-analysis of emotion perception and functional outcomes in schizophrenia},\n volume = {137},\n year = {2012}\n}\n'}","[{'authorId': '143787470', 'name': 'F. Irani'}, {'authorId': '32858030', 'name': 'Sarah C. Seligman'}, {'authorId': '143801344', 'name': 'Vidyulata Kamath'}, {'authorId': '31936404', 'name': 'C. Kohler'}, {'authorId': '144762538', 'name': 'R. Gur'}]"
1763,983de9e5c43e827bcf1733fd0bf90afd0d866d24,An EEG-Based Brain Computer Interface for Emotion Recognition and Its Application in Patients with Disorder of Consciousness,"Recognizing human emotions based on electroencephalogram (EEG) signals has received a great deal of attentions. Most of the existing studies focused on offline analysis, and real-time emotion recognition using a brain computer interface (BCI) approach remains to be further investigated. In this paper, we proposed an EEG-based BCI system for emotion recognition. Specifically, two classes of video clips that represented positive and negative emotions were presented to the subjects one by one, while the EEG data were collected and processed simultaneously, and instant feedback was provided after each clip. Ten healthy subjects participated in the experiment and achieved a high average online accuracy of 91.5 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math><alternatives><mml:math><mml:mo>±</mml:mo></mml:math><inline-graphic xlink:href=""li-ieq1-2901456.gif""/></alternatives></inline-formula> 6.34 percent. The experimental results demonstrated that the subjects emotions had been sufficiently evoked and efficiently recognized by our system. Clinically, patients with disorder of consciousness (DOC), such as coma, vegetative state, minimally conscious state and emergence minimally conscious state, suffer from motor impairment and generally cannot provide adequate emotion expressions. Consequently, doctors have difficulty in detecting the emotional states of these patients. Therefore, we applied our emotion recognition BCI system to patients with DOC. Eight DOC patients participated in our experiment, and three of them achieved significant online accuracy. The experimental results show that the proposed BCI system could be a promising tool to detect the emotional states of patients with DOC.",2019.0,55.0,80.0,True,,"{'volume': '12', 'pages': '832-842', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Huang2019AnEB,\n author = {Haiyun Huang and Qiuyou Xie and Jiahui Pan and Yanbin He and Zhenfu Wen and Ronghao Yu and Yuanqing Li},\n journal = {IEEE Transactions on Affective Computing},\n pages = {832-842},\n title = {An EEG-Based Brain Computer Interface for Emotion Recognition and Its Application in Patients with Disorder of Consciousness},\n volume = {12},\n year = {2019}\n}\n'}","[{'authorId': '48185937', 'name': 'Haiyun Huang'}, {'authorId': '116519490', 'name': 'Qiuyou Xie'}, {'authorId': '7588999', 'name': 'Jiahui Pan'}, {'authorId': '3351554', 'name': 'Yanbin He'}, {'authorId': '2258024', 'name': 'Zhenfu Wen'}, {'authorId': '6646835', 'name': 'Ronghao Yu'}, {'authorId': '48514757', 'name': 'Yuanqing Li'}]"
1764,9850a6de42fcfaecac73f189318c4c3be49ae707,Human-Robot Personal Space Evaluated with Biological Information Emotion Estimation Method,,2018.0,0.0,2.0,False,,{'pages': '157-167'},"{'bibtex': '@Inproceedings{Someya2018HumanRobotPS,\n author = {Yiriko Someya and Y. Tobe and Reiji Yoshida and N. Matsuhira and Midori Sugaya},\n pages = {157-167},\n title = {Human-Robot Personal Space Evaluated with Biological Information Emotion Estimation Method},\n year = {2018}\n}\n'}","[{'authorId': '51118766', 'name': 'Yiriko Someya'}, {'authorId': '3187057', 'name': 'Y. Tobe'}, {'authorId': '46784763', 'name': 'Reiji Yoshida'}, {'authorId': '3299510', 'name': 'N. Matsuhira'}, {'authorId': '145094033', 'name': 'Midori Sugaya'}]"
1765,9853f122750431a4eda76af110747cb179b8f163,Do pedagogical agents make a difference to student motivation and learning,,2011.0,84.0,237.0,False,,"{'volume': '6', 'pages': '27-54', 'name': 'Educational Research Review'}","{'bibtex': '@Article{Heidig2011DoPA,\n author = {Steffi Heidig and G. Clarebout},\n journal = {Educational Research Review},\n pages = {27-54},\n title = {Do pedagogical agents make a difference to student motivation and learning},\n volume = {6},\n year = {2011}\n}\n'}","[{'authorId': '2650933', 'name': 'Steffi Heidig'}, {'authorId': '1795235', 'name': 'G. Clarebout'}]"
1766,9856dcd4ca7ecc94fc7b7e65a457e727880332dc,Subject independent emotion recognition from EEG using VMD and deep learning,,2019.0,49.0,104.0,True,,"{'volume': '34', 'pages': '1730-1738', 'name': 'J. King Saud Univ. Comput. Inf. Sci.'}","{'bibtex': '@Article{Pandey2019SubjectIE,\n author = {Pallavi Pandey and K. R. Seeja},\n journal = {J. King Saud Univ. Comput. Inf. Sci.},\n pages = {1730-1738},\n title = {Subject independent emotion recognition from EEG using VMD and deep learning},\n volume = {34},\n year = {2019}\n}\n'}","[{'authorId': '50162090', 'name': 'Pallavi Pandey'}, {'authorId': '2622519', 'name': 'K. R. Seeja'}]"
1767,985f050927d62e329c865526636fbc85421672e5,Analysis of Heavy Metal Sources in the Soil of Riverbanks Across an Urbanization Gradient,"Regional soil quality issues arising from rapid urbanization have received extensive attention. The riverbank that runs through a city is representative of urbanization gradient transformation. Thirty soil samples in the Yangtze River Delta urban agglomeration were collected and analyzed for the concentrations of seven analytes. Correlation, principle component analysis, cluster analysis and GeoDetector models suggested that the four groups (Cr-Ni-Cu, Cu-Zn-As-Sb, Cd and Pb) shared the same sources in the core urban region; five groups (Cr-Ni-Cu-Zn, As, Cd, Sb and Pb) in the suburbs and three groups (Cr-Ni, Cu-Zn-Cd-Sb-Pb and As) in the exurbs. GeoDetector methods not only validated the results of the three other methods, but also provided more possible impact factors. Besides the direct influences, the interaction effects among factors were quantified. Interactive combination with strong nonlinear increment changed from between-two-weak factors in the central region to between-strong-and-weak factors in the suburbs. In the exurbs, the stronger interaction effects were observed between strong and weak factors. Therefore, the GeoDetector model, which provided more detailed information of artificial sources could be used as a tool for identifying the potential factors of toxic elements and offering scientific basis for the development of subsequent pollution reduction strategies.",2018.0,53.0,29.0,True,"{'url': 'https://www.mdpi.com/1660-4601/15/10/2175/pdf?version=1538656071', 'status': None}","{'volume': '15', 'name': 'International Journal of Environmental Research and Public Health'}","{'bibtex': '@Article{Zuo2018AnalysisOH,\n author = {S. Zuo and Shaoqing Dai and Yaying Li and Jianfeng Tang and Y. Ren},\n journal = {International Journal of Environmental Research and Public Health},\n title = {Analysis of Heavy Metal Sources in the Soil of Riverbanks Across an Urbanization Gradient},\n volume = {15},\n year = {2018}\n}\n'}","[{'authorId': '38033299', 'name': 'S. Zuo'}, {'authorId': '41031443', 'name': 'Shaoqing Dai'}, {'authorId': '4516308', 'name': 'Yaying Li'}, {'authorId': '46741007', 'name': 'Jianfeng Tang'}, {'authorId': '102246858', 'name': 'Y. Ren'}]"
1768,9861fd9cf5dab60617180791b66c128c4e83c677,Making sense of agentic objects and teleoperation: In-the-moment and reflective perspectives,"Agentic objects are those entities that are perceived and responded to in-the-moment as if they were agentic despite the likely reflective perception that they are not agentic at all. They include autonomous robots, but also simpler systems like automatic doors, trashcans, and staplers - anything that seems to possess agency. It is well known that low-level spatiotemporal information elicits in-the-moment responses that are interpreted as perceiving mentalism [8, 17], but people reflectively believe that there is a distinction between human and non-human agents. How are we to make sense of these agentic objects?",2009.0,20.0,31.0,False,,"{'pages': '239-240', 'name': '2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Takayama2009MakingSO,\n author = {L. Takayama},\n journal = {2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {239-240},\n title = {Making sense of agentic objects and teleoperation: In-the-moment and reflective perspectives},\n year = {2009}\n}\n'}","[{'authorId': '1753156', 'name': 'L. Takayama'}]"
1769,986972cd62940e95aeba1cb1ccd6d33d124348de,"Embodiment and Interaction Guidelines for Designing Credible, Trustworthy Embodied Conversational Agents",,2003.0,63.0,45.0,False,,{'pages': '301-309'},"{'bibtex': '@Inproceedings{Cowell2003EmbodimentAI,\n author = {A. Cowell and K. Stanney},\n pages = {301-309},\n title = {Embodiment and Interaction Guidelines for Designing Credible, Trustworthy Embodied Conversational Agents},\n year = {2003}\n}\n'}","[{'authorId': '7234960', 'name': 'A. Cowell'}, {'authorId': '1701555', 'name': 'K. Stanney'}]"
1770,986ddae314f3c76771a10be08f499b95bb2ca17b,"Animal Faux Pas: Two Legs Good Four Legs Bad for Theory of Mind, but Not in the Broad Autism Spectrum","Abstract Research shows that the general population varies with regard to both autistic traits and theory of mind (ToM) ability. Other work has shown that autistic individuals may not underperform on ToM tests when the agent of evaluation is anthropomorphic rather than typically human. Two studies examined the relation between ToM and autistic trait profiles in over 650 adults using either the standard Faux Pas Recognition Test (FPT) or an anthropomorphized version of the FPT (FPTa). Results showed that autistic trait profiles were related to faux pas detection ability in the FPT but not the FPTa. Furthermore, while those with the broad autism phenotype scored significantly worse than those who were typically developed on the FPT, scores did not significantly differ on the FPTa. These findings add to a growing body of work suggesting that ToM ability is not at a global deficit in those on the autistic spectrum, but may relate to the mindreading of specifically human agents.",2019.0,64.0,14.0,True,"{'url': 'https://wlv.openrepository.com/bitstream/2436/622219/1/Animal%20Faux%20Pas.pdf', 'status': None}","{'volume': '180', 'pages': '81 - 95', 'name': 'The Journal of Genetic Psychology'}","{'bibtex': '@Article{Atherton2019AnimalFP,\n author = {Gray Atherton and Liam B. Cross},\n journal = {The Journal of Genetic Psychology},\n pages = {81 - 95},\n title = {Animal Faux Pas: Two Legs Good Four Legs Bad for Theory of Mind, but Not in the Broad Autism Spectrum},\n volume = {180},\n year = {2019}\n}\n'}","[{'authorId': '143639742', 'name': 'Gray Atherton'}, {'authorId': '143784184', 'name': 'Liam B. Cross'}]"
1771,989e70bc024c595f8cd91be6d4fe72e834975a3f,EMOCASH: An Intelligent Virtual-Agent Based Multiplayer Online Serious Game for Promoting Money and Emotion Recognition Skills in Egyptian Children with Autism,org,2023.0,75.0,0.0,True,"{'url': 'http://thesai.org/Downloads/Volume14No4/Paper_14-EMOCASH_An_Intelligent_Virtual_Agent_Based_Multiplayer.pdf', 'status': 'GOLD'}",{'name': 'International Journal of Advanced Computer Science and Applications'},"{'bibtex': '@Article{El-Sattar2023EMOCASHAI,\n author = {H. A. El-Sattar},\n booktitle = {International Journal of Advanced Computer Science and Applications},\n journal = {International Journal of Advanced Computer Science and Applications},\n title = {EMOCASH: An Intelligent Virtual-Agent Based Multiplayer Online Serious Game for Promoting Money and Emotion Recognition Skills in Egyptian Children with Autism},\n year = {2023}\n}\n'}","[{'authorId': '41154832', 'name': 'H. A. El-Sattar'}]"
1772,98a067775710886ee7d24f123b7a09116415ab2e,"The German Text-to-Speech Synthesis System MARY: A Tool for Research, Development and Teaching",,2003.0,43.0,512.0,False,,"{'volume': '6', 'pages': '365-377', 'name': 'International Journal of Speech Technology'}","{'bibtex': '@Article{Schröder2003TheGT,\n author = {M. Schröder and Jürgen Trouvain},\n journal = {International Journal of Speech Technology},\n pages = {365-377},\n title = {The German Text-to-Speech Synthesis System MARY: A Tool for Research, Development and Teaching},\n volume = {6},\n year = {2003}\n}\n'}","[{'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '1944105', 'name': 'Jürgen Trouvain'}]"
1773,98ab45160269f7c1545f7924f989d5da1895e9a5,The Uncanny Valley [From the Field],"More than 40 years ago, Masahiro Mori, a robotics professor at the Tokyo Institute of Technology, wrote an essay [1] on how he envisioned people's reactions to robots that looked and acted almost like a human. In particular, he hypothesized that a person's response to a humanlike robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance. This descent into eeriness is known as the uncanny valley. The essay appeared in an obscure Japanese journal called Energy in 1970, and in subsequent years, it received almost no attention. However, more recently, the concept of the uncanny valley has rapidly attracted interest in robotics and other scientific circles as well as in popular culture. Some researchers have explored its implications for human-robot interaction and computer-graphics animation, whereas others have investigated its biological and social roots. Now interest in the uncanny valley should only intensify, as technology evolves and researchers build robots that look human. Although copies of Mori's essay have circulated among researchers, a complete version hasn't been widely available. The following is the first publication of an English translation that has been authorized and reviewed by Mori. (See “Turning Point” in this issue for an interview with Mori.).",2012.0,0.0,1528.0,False,,"{'volume': '19', 'pages': '98-100', 'name': 'IEEE Robotics Autom. Mag.'}","{'bibtex': '@Article{Mori2012TheUV,\n author = {M. Mori and K. Macdorman and Norri Kageki},\n journal = {IEEE Robotics Autom. Mag.},\n pages = {98-100},\n title = {The Uncanny Valley [From the Field]},\n volume = {19},\n year = {2012}\n}\n'}","[{'authorId': '46861004', 'name': 'M. Mori'}, {'authorId': '1690354', 'name': 'K. Macdorman'}, {'authorId': '1956705', 'name': 'Norri Kageki'}]"
1775,98c0064ae479d840ecea4e3017912827f5857263,"Afraid to Be There? Evaluating the Relation Between Presence, Self-Reported Anxiety, and Heart Rate in a Virtual Public Speaking Task","The link between anxiety and presence in a virtual environment (VE) is still a subject of an unresolved debate, with little empirical research to support theoretical claims. Thus, the current study analyzed presence, self-reported anxiety, and a physiological parameter (heart rate [HR]) in a sample of 30 high anxious and 35 low anxious participants. Both groups delivered a 5 minute speech in a virtual lecture hall. Results indicate no mediating influences of presence on group differences in self-reported state anxiety during the speech, but point toward negative correlations between state anxiety and the iGroup Presence Questionnaire (IPQ) scales ""sense of being there"" and ""realism."" Furthermore, HR was found to be unrelated to self-reported presence. Only the IPQ scale ""spatial presence"" showed a marginally significant influence on group differences in state anxiety. The present results support the assumption that presence and anxiety are logically distinct, meaning that presence does not directly influence the intensity of an emotion felt in a VE. Rather, it constitutes a precondition for an emotion to be at all elicited by a VE. Also, HR has proven to be no adequate substitute measure for presence, since it only assesses anxiety not presence. It may, however, mediate the interplay between trait anxiety and state anxiety. Possible implications of the current findings are discussed alongside the problem of using presence questionnaires that seem to be prone to subjective bias (i.e., participants confusing presence and emotion).",2014.0,23.0,50.0,False,,"{'volume': '17 5', 'pages': '\n          310-6\n        ', 'name': 'Cyberpsychology, behavior and social networking'}","{'bibtex': '@Article{Felnhofer2014AfraidTB,\n author = {A. Felnhofer and O. Kothgassner and T. Hetterle and Leon Beutl and H. Hlavacs and I. Kryspin-Exner},\n journal = {Cyberpsychology, behavior and social networking},\n pages = {\n          310-6\n        },\n title = {Afraid to Be There? Evaluating the Relation Between Presence, Self-Reported Anxiety, and Heart Rate in a Virtual Public Speaking Task},\n volume = {17 5},\n year = {2014}\n}\n'}","[{'authorId': '2144008', 'name': 'A. Felnhofer'}, {'authorId': '3136916', 'name': 'O. Kothgassner'}, {'authorId': '3172310', 'name': 'T. Hetterle'}, {'authorId': '2373231', 'name': 'Leon Beutl'}, {'authorId': '1743771', 'name': 'H. Hlavacs'}, {'authorId': '1398005104', 'name': 'I. Kryspin-Exner'}]"
1776,98e4c30c04572e66281dc87a361be3617cf1e2e7,Towards a quantitative approach for comparing crowds,"In this paper, we propose a new model to quantitatively compare global flow characteristics of two crowds. The proposed approach explores a 4‐D histogram that contains information on the local velocity (speed and orientation) of each spatial position, and the comparison is made using histogram distances. The 4‐D histogram also allows the comparison of specific characteristics, such as distribution of orientations only, speed only, relative spatial occupancy only, and combinations of such features. Experimental results indicate that the proposed quantitative metric correlates with visual inspection. Copyright © 2012 John Wiley & Sons, Ltd.",2012.0,27.0,31.0,False,,"{'volume': '23', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Musse2012TowardsAQ,\n author = {S. Musse and V. Cassol and C. Jung},\n journal = {Computer Animation and Virtual Worlds},\n title = {Towards a quantitative approach for comparing crowds},\n volume = {23},\n year = {2012}\n}\n'}","[{'authorId': '1679516', 'name': 'S. Musse'}, {'authorId': '2676680', 'name': 'V. Cassol'}, {'authorId': '2870402', 'name': 'C. Jung'}]"
1777,98e95bff96a44995ac2fd2e5ac86945c04bce5ab,"Incubation, insight, and creative problem solving: a unified theory and a connectionist model.","This article proposes a unified framework for understanding creative problem solving, namely, the explicit-implicit interaction theory. This new theory of creative problem solving constitutes an attempt at providing a more unified explanation of relevant phenomena (in part by reinterpreting/integrating various fragmentary existing theories of incubation and insight). The explicit-implicit interaction theory relies mainly on 5 basic principles, namely, (a) the coexistence of and the difference between explicit and implicit knowledge, (b) the simultaneous involvement of implicit and explicit processes in most tasks, (c) the redundant representation of explicit and implicit knowledge, (d) the integration of the results of explicit and implicit processing, and (e) the iterative (and possibly bidirectional) processing. A computational implementation of the theory is developed based on the CLARION cognitive architecture and applied to the simulation of relevant human data. This work represents an initial step in the development of process-based theories of creativity encompassing incubation, insight, and various other related phenomena.",2010.0,144.0,325.0,True,"{'url': 'http://www.cogsci.rpi.edu/~rsun/folder-files/helie-sun-psycrev2010-f.pdf', 'status': None}","{'volume': '117 3', 'pages': '\n          994-1024\n        ', 'name': 'Psychological review'}","{'bibtex': '@Article{Hélie2010IncubationIA,\n author = {S. Hélie and R. Sun},\n journal = {Psychological review},\n pages = {\n          994-1024\n        },\n title = {Incubation, insight, and creative problem solving: a unified theory and a connectionist model.},\n volume = {117 3},\n year = {2010}\n}\n'}","[{'authorId': '1772825', 'name': 'S. Hélie'}, {'authorId': '145966408', 'name': 'R. Sun'}]"
1778,98efeaa4ff4dcef080006b945b5e075c4f2ec9cb,Micro-Simulation Model for Assessing the Risk of Vehicle–Pedestrian Road Accidents,"Data on traffic accidents clearly point to road black spots, where the accident rate is always high. However, road safety research is still far from understanding why these particular places on a road are risky. The reason is the lack of sufficient knowledge on how pedestrians and drivers interact when facing a potentially dangerous traffic situation, and the lack of an integrated framework that relates the data on human behavior to real-world traffic situations. We attempt to tackle this problem by developing SAFEPED, a multi-agent microscopic three-dimensional (3D) simulation of vehicle and pedestrian dynamics at a black spot. SAFEPED is a test platform for evaluating experimentally estimated drivers’ and pedestrians’ behavioral rules, and estimating accident risks in different traffic situations. It aims to analyze the design of existing and future black spots and to assess alternative architectural and environmental solutions in order to identify maximally efficient safety countermeasures.",2015.0,44.0,34.0,False,,"{'volume': '19', 'pages': '63 - 77', 'name': 'Journal of Intelligent Transportation Systems'}","{'bibtex': '@Article{Waizman2015MicroSimulationMF,\n author = {Gennady Waizman and S. Shoval and I. Benenson},\n journal = {Journal of Intelligent Transportation Systems},\n pages = {63 - 77},\n title = {Micro-Simulation Model for Assessing the Risk of Vehicle–Pedestrian Road Accidents},\n volume = {19},\n year = {2015}\n}\n'}","[{'authorId': '2104372', 'name': 'Gennady Waizman'}, {'authorId': '25700979', 'name': 'S. Shoval'}, {'authorId': '2174376', 'name': 'I. Benenson'}]"
1779,990832672adfe02ea3af49c48f4d83bbf2a57a15,Using animated vehicles with real emotional faces to improve emotion recognition in Chinese children with autism spectrum disorder,The objective of the present study was to conduct an intervention study which aimed to improve emotion recognition for Chinese children with ASD by using animated vehicles with real emotional faces. A total of 21 children participated in the current study; participants consisted of 14 children (2 girls) with a formal diagnosis of ASD and 7 typically developing children. Participants were measured on emotional vocabulary and situation-facial expression matching before and after the intervention. Results indicated that the intervention significantly improved ASD children’s emotion recognition compared to their pre-intervention scores. Our findings suggest that this emotional recognition intervention using animated vehicles (i.e. The Transporters) is an effective early intervention for Chinese children with ASD.,2018.0,6.0,10.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0200375&type=printable', 'status': None}","{'volume': '13', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Yan2018UsingAV,\n author = {Yuhong Yan and Chuanshi Liu and Lin Ye and Yangyang Liu},\n journal = {PLoS ONE},\n title = {Using animated vehicles with real emotional faces to improve emotion recognition in Chinese children with autism spectrum disorder},\n volume = {13},\n year = {2018}\n}\n'}","[{'authorId': '2115359760', 'name': 'Yuhong Yan'}, {'authorId': '152598617', 'name': 'Chuanshi Liu'}, {'authorId': '2111920655', 'name': 'Lin Ye'}, {'authorId': '47909953', 'name': 'Yangyang Liu'}]"
1780,990f3512851cd5f8c48dea3583503419b6273b9f,Learning To Read And Write : Developmentally Appropriate Practices For Young Children,"naeyc Copyright © 1998. All rights reserved. National Association for the Education of Young Children. In Young Children, July 1998, 53 (4): 30–46. 1509 16th Street, N.W., Washington, DC 20036-1426 ● 202-232-8777 ● 800-424-2460 ● FAX: 202-328-1846 Learning to read and write is critical to a child’s success in school and later in life. One of the best predictors of whether a child will function competently in school and go on to contribute actively in our increasingly literate society is the level to which the child progresses in reading and writing. Although reading and writing abilities continue to develop throughout the life span, the early childhood years—from birth through age eight—are the most important period for literacy development. It is for this reason that the International Reading Association (IRA) and the National Association for the Education of Young Children (NAEYC) joined together to formulate a position statement regarding early literacy development. The statement consists of a set of principles and recommendations for teaching practices and public policy. The primary purpose of this position statement is to provide guidance to teachers of young children in schools and early childhood programs (including child care centers, preschools, and family child care homes) serving children from birth through age eight. By and large, the principles and practices suggested here also will be of interest to any adults who are in a position to influence a young child’s learning and development—parents, grandparents, older siblings, tutors, and other community members. Teachers work in schools or programs regulated by administrative policies as well as available resources. Therefore secondary audiences for this position statement are school principals and program administrators whose roles are critical in establishing a supportive climate for sound, developmentally appropriate teaching practices; and policymakers whose decisions determine whether adequate resources are available for high-quality early childhood education. A great deal is known about how young children learn to read and write and how they can be helped toward literacy during the first five years of life. A great deal is known also about how to help children once compulsory schooling begins, whether in kindergarten or the primary grades. Based on a thorough review of the research, this document reflects the commitment of two major professional organizations to the goal of helping children learn to read well enough by the end of third grade so that they can read to learn in all curriculum areas. IRA and NAEYC are committed not only to helping young children learn to read and write but also to fostering and sustaining their interest and disposition to read and write for their own enjoyment, information, and communication. First, the statement summarizes the current issues that are the impetus for this position; then it reviews what is known from research on young children’s literacy development. This review of research as well as the collective wisdom and experience of IRA and NAEYC members provides the basis for a position statement about what constitutes developmentally appropriate practice in early literacy over the period of bir th through age eight. The position concludes with recommendations for teaching practices and policies.",2000.0,113.0,543.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Neuman2000LearningTR,\n author = {S. Neuman and C. Copple and S. Bredekamp},\n title = {Learning To Read And Write : Developmentally Appropriate Practices For Young Children},\n year = {2000}\n}\n'}","[{'authorId': '34577644', 'name': 'S. Neuman'}, {'authorId': '39976956', 'name': 'C. Copple'}, {'authorId': '12616777', 'name': 'S. Bredekamp'}]"
1781,9944b7170b19b5c8ede595d657db260bccae8729,Verification & Validation of Agent Based Simulations using the VOMAS (Virtual Overlay Multi-agent System) Approach,"Agent Based Models are very popular in a number of different areas. For example, they have been used in a range of domains ranging from modeling of tumor growth, immune systems, molecules to models of social networks, crowds and computer and mobile self-organizing networks. One reason for their success is their intuitiveness and similarity to human cognition. However, with this power of abstraction, in spite of being easily applicable to such a wide number of domains, it is hard to validate agent-based models. In addition, building valid and credible simulations is not just a challenging task but also a crucial exercise to ensure that what we are modeling is, at some level of abstraction, a model of our conceptual system; the system that we have in mind. In this paper, we address this important area of validation of agent based models by presenting a novel technique which has broad applicability and can be applied to all kinds of agent-based models. We present a framework, where a virtual overlay multi-agent system can be used to validate simulation models. In addition, since agent-based models have been typically growing, in parallel, in multiple domains, to cater for all of these, we present a new single validation technique applicable to all agent based models. Our technique, which allows for the validation of agent based simulations uses VOMAS: a Virtual Overlay Multi-agent System. This overlay multi-agent system can comprise various types of agents, which form an overlay on top of the agent based simulation model that needs to be validated. Other than being able to watch and log, each of these agents contains clearly defined constraints, which, if violated, can be logged in real time. To demonstrate its effectiveness, we show its broad applicability in a wide variety of simulation models ranging from social sciences to computer networks in spatial and non-spatial conceptual models.",2009.0,31.0,51.0,False,,"{'volume': 'abs/1708.02361', 'name': 'ArXiv'}","{'bibtex': '@Article{Niazi2009VerificationV,\n author = {M. Niazi and A. Hussain and M. Kolberg},\n journal = {ArXiv},\n title = {Verification & Validation of Agent Based Simulations using the VOMAS (Virtual Overlay Multi-agent System) Approach},\n volume = {abs/1708.02361},\n year = {2009}\n}\n'}","[{'authorId': '1795560', 'name': 'M. Niazi'}, {'authorId': '144664815', 'name': 'A. Hussain'}, {'authorId': '1796567', 'name': 'M. Kolberg'}]"
1782,9945e206bf033a40306dc3f6f100292290cc7154,Interventions to improve medication adherence in schizophrenia.,"OBJECTIVE
Although nonadherence with the antipsychotic medication regimen is a common barrier to the effective treatment for schizophrenia, knowledge is limited about how to improve medication adherence. This systematic literature review examined psychosocial interventions for improving medication adherence, focusing on promising initiatives, reasonable standards for conducting research in this area, and implications for clinical practice.


METHOD
Studies were identified by computerized searches of MEDLINE and PsychLIT for the years between 1980 and 2000 and by manual searches of relevant bibliographies and conference proceedings. Key articles were summarized.


RESULTS
Thirteen (33%) of 39 identified studies reported significant intervention effects. Although interventions and family therapy programs relying on psychoeducation were common in clinical practice, they were typically ineffective. Concrete problem solving or motivational techniques were common features of successful programs. Interventions targeted specifically to problems of nonadherence were more likely to be effective (55%) than were more broadly based treatment interventions (26%). One-half (four of eight) of the successful interventions not specifically focused on nonadherence involved an array of supportive and rehabilitative community-based services.


CONCLUSIONS
Psychoeducational interventions without accompanying behavioral components and supportive services are not likely to be effective in improving medication adherence in schizophrenia. Models of community care such as assertive community treatment and interventions based on principles of motivational interviewing are promising. Providing patients with concrete instructions and problem-solving strategies, such as reminders, self-monitoring tools, cues, and reinforcements, is useful. Problems in adherence are recurring, and booster sessions are needed to reinforce and consolidate gains.",2002.0,60.0,540.0,False,,"{'volume': '159 10', 'pages': '\n          1653-64\n        ', 'name': 'The American journal of psychiatry'}","{'bibtex': '@Article{Zygmunt2002InterventionsTI,\n author = {A. Zygmunt and M. Olfson and C. Boyer and D. Mechanic},\n journal = {The American journal of psychiatry},\n pages = {\n          1653-64\n        },\n title = {Interventions to improve medication adherence in schizophrenia.},\n volume = {159 10},\n year = {2002}\n}\n'}","[{'authorId': '46920194', 'name': 'A. Zygmunt'}, {'authorId': '6647030', 'name': 'M. Olfson'}, {'authorId': '24632261', 'name': 'C. Boyer'}, {'authorId': '32845644', 'name': 'D. Mechanic'}]"
1783,9997d0379f52c786a61e9306ca406c77f9bcfaf2,Recognising subtle emotional expressions: The role of facial movements,"Two studies investigated the importance of dynamic temporal characteristic information in facilitating the recognition of subtle expressions of emotion. In Experiment 1 there were three conditions, dynamic moving sequences that showed the expression emerging from neutral to a subtle emotion, a dynamic presentation containing nine static stills from the dynamic moving sequences (ran together to encapsulate a moving sequence) and a First–Last condition containing only the first (neutral) and last (subtle emotion) stills. The results showed recognition was significantly better for the dynamic moving sequences than both the Dynamic-9 and First–Last conditions. Experiments 2a and 2b then changed the dynamics of the moving sequences by speeding up, slowing down or disrupting the rhythm of the motion sequences. These manipulations significantly reduced recognition, and it was concluded that in addition to the perception of change, recognition is facilitated by the characteristic muscular movements associated with the portrayal of each emotion.",2008.0,20.0,84.0,False,,"{'volume': '22', 'pages': '1569 - 1587', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Bould2008RecognisingSE,\n author = {E. Bould and Neil Morris and B. Wink},\n journal = {Cognition and Emotion},\n pages = {1569 - 1587},\n title = {Recognising subtle emotional expressions: The role of facial movements},\n volume = {22},\n year = {2008}\n}\n'}","[{'authorId': '4195232', 'name': 'E. Bould'}, {'authorId': '47939572', 'name': 'Neil Morris'}, {'authorId': '30306572', 'name': 'B. Wink'}]"
1784,99bf8ac8c131291d771923d861b188510194615e,Facial Action Coding System,"The Facial Action Coding System (FACS) is a widely used protocol for recognizing and labelling facial expression by describing the movement of muscles of the face. FACS is used to objectively measure the frequency and intensity of facial expressions without assigning any emotional meaning to those muscle movements. Instead FACS breaks down facial expressions into their smallest discriminable movements called Action Units. Each Action Unit creates a distinct change in facial appearance, such as an eyebrow lift or nose wrinkle. FACS coders can identify the Action Units which are present on the face when viewing still images or videos. Psychological research has used FACS to examine a variety of research questions including social-emotional development, neuropsychiatric disorders, and deception. In the course of this report we provide an overview of FACS and the Action Units, its reliability as a measure, and how it has been applied in some key areas of psychological research.",2015.0,11.0,1509.0,False,,,"{'bibtex': '@Inproceedings{Prince2015FacialAC,\n author = {E. Prince and Katherine B. Martin and D. Messinger},\n title = {Facial Action Coding System},\n year = {2015}\n}\n'}","[{'authorId': '32173841', 'name': 'E. Prince'}, {'authorId': '39710065', 'name': 'Katherine B. Martin'}, {'authorId': '1874236', 'name': 'D. Messinger'}]"
1787,99d2dd2eecadaa926d9828bb6ec8049fa5a04f6e,Dehumanizing the Lowest of the Low,"Traditionally, prejudice has been conceptualized as simple animosity. The stereotype content model (SCM) shows that some prejudice is worse. The SCM previously demonstrated separate stereotype dimensions of warmth (low-high) and competence (low-high), identifying four distinct out-group clusters. The SCM predicts that only extreme out-groups, groups that are both stereotypically hostile and stereotypically incompetent (low warmth, low competence), such as addicts and the homeless, will be dehumanized. Prior studies show that the medial prefrontal cortex (mPFC) is necessary for social cognition. Functional magnetic resonance imaging provided data for examining brain activations in 10 participants viewing 48 photographs of social groups and 12 participants viewing objects; each picture dependably represented one SCM quadrant. Analyses revealed mPFC activation to all social groups except extreme (low-low) out-groups, who especially activated insula and amygdala, a pattern consistent with disgust, the emotion predicted by the SCM. No objects, though rated with the same emotions, activated the mPFC. This neural evidence supports the prediction that extreme out-groups may be perceived as less than human, or dehumanized.",2006.0,42.0,915.0,False,,"{'volume': '17', 'pages': '847 - 853', 'name': 'Psychological Science'}","{'bibtex': '@Article{Harris2006DehumanizingTL,\n author = {L. Harris and S. Fiske},\n journal = {Psychological Science},\n pages = {847 - 853},\n title = {Dehumanizing the Lowest of the Low},\n volume = {17},\n year = {2006}\n}\n'}","[{'authorId': '3705092', 'name': 'L. Harris'}, {'authorId': '1885803', 'name': 'S. Fiske'}]"
1788,99f037a157abc3aa7c75ba16be04bdf5208d1966,Theory,,1934.0,286.0,1846.0,False,,"{'volume': '20', 'pages': '50 - 50', 'name': 'Music Educators Journal'}","{'bibtex': '@Article{Lambach1934Theory,\n author = {Daniel Lambach and M. Bayer and Felix S. Bethke and Matteo Dressler and Véronique Dudouet},\n journal = {Music Educators Journal},\n pages = {50 - 50},\n title = {Theory},\n volume = {20},\n year = {1934}\n}\n'}","[{'authorId': '2022295313', 'name': 'Daniel Lambach'}, {'authorId': '145222753', 'name': 'M. Bayer'}, {'authorId': '2083410135', 'name': 'Felix S. Bethke'}, {'authorId': '121629413', 'name': 'Matteo Dressler'}, {'authorId': '103554374', 'name': 'Véronique Dudouet'}]"
1789,9a043c08d8cfe58d26bf04cb01a60c069dbba9bd,Impact of Expressive Wrinkles on Perception of a Virtual Character's Facial Expressions of Emotions,,2009.0,46.0,59.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-00783596/file/SAM_LCPI_092009_BUISINE.pdf', 'status': None}",{'pages': '201-214'},"{'bibtex': ""@Inproceedings{Courgeon2009ImpactOE,\n author = {M. Courgeon and S. Buisine and Jean-Claude Martin},\n pages = {201-214},\n title = {Impact of Expressive Wrinkles on Perception of a Virtual Character's Facial Expressions of Emotions},\n year = {2009}\n}\n""}","[{'authorId': '3237926', 'name': 'M. Courgeon'}, {'authorId': '1742939', 'name': 'S. Buisine'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}]"
1790,9a1a73d67042a1f60c18b84cb2f607a529bad2fe,Better Bootstrap Confidence Intervals,"Abstract We consider the problem of setting approximate confidence intervals for a single parameter θ in a multiparameter family. The standard approximate intervals based on maximum likelihood theory, , can be quite misleading. In practice, tricks based on transformations, bias corrections, and so forth, are often used to improve their accuracy. The bootstrap confidence intervals discussed in this article automatically incorporate such tricks without requiring the statistician to think them through for each new application, at the price of a considerable increase in computational effort. The new intervals incorporate an improvement over previously suggested methods, which results in second-order correctness in a wide variety of problems. In addition to parametric families, bootstrap intervals are also developed for nonparametric situations.",1987.0,21.0,3237.0,True,"{'url': 'http://www.dtic.mil/dtic/tr/fulltext/u2/a150798.pdf', 'status': None}","{'volume': '82', 'pages': '171-185', 'name': 'Journal of the American Statistical Association'}","{'bibtex': '@Article{Efron1987BetterBC,\n author = {B. Efron},\n journal = {Journal of the American Statistical Association},\n pages = {171-185},\n title = {Better Bootstrap Confidence Intervals},\n volume = {82},\n year = {1987}\n}\n'}","[{'authorId': '2550392', 'name': 'B. Efron'}]"
1791,9a2c9d67924271afc8c8f123decac1f98f151e1a,Thoughts on the relations between emotion and cognition.,"This paper argues that thought is a necessary condition of emotion. It therefore opposes the •stance taken by Zajonc, which reflects two widespread misunderstandings about what is meant by cognitive processes in emotion: (a) that a cognitive appraisal of the significance of an encounter for one's well-being must occur in fixed stages through the information processing of initially meaningless inputs from the environment; and (b) that such an appraisal is necessarily deliberate, rational, and conscious. Some of the phylogenetic and ontogenetic implications of a cognitive theory of emotion are also discussed briefly. Recent years have seen a major change in the way psychologists view emotion—the rediscovery that emotions are products of cognitive processes. The emotional response is elicited by an evaluative perception in lower animals, and in humans by a complex 'cognitive appraisal of the significance of events for one's well-being. Although there are many other issues concerning the relations between emotion and cognition, my comments will focus on the role of thought in the emotional response. I will refer often to Zajonc's (1980) challenge to the assumption that cognition occurs prior to emotion. I use his views to illustrate widespread misunderstandings of what it means to speak of cognition as a causal antecedent of emotion; I also use his views as a point of departure for rny argument that cognitive activity is a necessary as well as sufficient condition of emotion. Do Emotions Require Cognitive Mediation? My own position on this question is a variant of a family of theories of emotion centered on the concept of cognitive appraisal. Campos and Sternberg (1981) state, for example, that ""The recent history of the study of emotion has been dominated by approaches stressing cognitive factors. In theories of adult emotional response, cognitive appraisal now functions as the central construct"" (p. 273). Its role is, to mediate the relationship between the person and the environment. The appraisal process gives rise to a particular emotion with greater or lesser intensity depending on how the relationship is evaluated with respect to the person's well-being. Cognitive appraisal means that the way one interprets one's plight at any given moment is crucial to the emotional response. Cognition and emotion are usually fused in nature (Folkman, Schaefer, & Lazarus, 1979), although they can be dissociated in certain unusual or abnormal states. For example, cognitive coping processes (cf. Lazarus, 1981) such as isolation and intellectualization (or detachment), which are aimed at regulating feelings, can create a dissociation between thoughts and feelings. Moreover, attack can occur without anger, and avoidance without fear. These latter conditions are also instances in which the usual link between thought and feeling has been loosened or broken. Yet such separations are less often a rule of living and more often a product of coping under special circumstances. The full experience of emotion (as opposed to sham rage, for example) normally includes three fused components: thoughts, action impulses, and somatic disturbances. When these components are dissociated we are left with something other than what we mean by a true emotional state. Our theories of emotion must reflect the normal fusion, and separating thoughts, action impulses, and so^ matic disturbances except under certain specifiable conditions (as was done in the old days of faculty psychology—which treated cognition, emotion, and motivation as independent entities) distorts rather than clarifies the structure of the mind (cf. Lazarus, Coyne, & Folkman, 1982). One bit of fallout from the above analysis is the implication, often derived from statements of cognitive theory, that cognitive appraisal is a necessary I wish to thank my research colleague, Susan Folkman, and my secretary, Carol Carr, for providing substantial editorial advice on this article. I appreciate their skill and judgment. Requests for reprints should be sent to Richard S. Lazarus, Department of Psychology, University of California, Berkeley, 4105 Tolman Hall, Berkeley, California 94720. Vol. 37, No. 9, 1019-1024 Copyright 1982 by the American Psychological Association, Inc. AMERICAN PSYCHOLOGIST • SEPTEMBER 1982 • 1019 0003-066X/82/3709-1019$00.75 I as well as sufficient condition of emotion. Such a position has been criticized trenchantly by Zajonc (1980). He writes that affect is erroneously regarded in contemporary psychological theory as postcognitive, occurring only after extensive cognitive operations have taken place, and that in actuality affective judgments are fairly independent of, and even precede, the perceptual and cognitive activities on which they are said to depend. Zajonc argues that not only can affect occur without extensive perceptual and cognitive encoding—and even before—but that affect and cognition are controlled by separate and partially independent neural systems (see also Tomkins, 1981). Zajonc thus seems to be saying two things contrary to what I have argued: first, that the proposed directionality in which cognition determines affect is wrorig and that the actual direction is affect to cognition; and second, that cognition and affect should be regarded as relatively independent subsystems rather than as fused and highly interdependent. Building his argument, Zajonc cites a stanza of poetry from e. e. cummings (1973): since feeling is first who pays any attention to the syntax of things will never wholly kiss you. (p. 160) He also cites Wundt's (1907) concept of affective primacy, and Bartlett (1932), Ittelson (1973), Osgood (1962), and Premack (1976) as having adopted the view that feelings come first. He states, for example: . < In fact, it is entirely possible that the very first stage of the organism's reaction to stimuli and the very first elements in retrieval are affective. It is further possible that we can like something or be afraid of it before we know precisely what it is and perhaps even without knowing what it is. (p. 154) The most serious mistake in Zajonc's analysis lies in his approach to cognition, which is characteristic of much of present-day cognitive psychology. In this approach information and meaning stem from the conception of mind as an analogue to a computer (Shannon & Weaver, 1962), a view illustrated also by the work of Newell and Simon (1961) and Weiner (I960). This conception has been rebutted by Dreyfus (1972), Polanyi (1958, 1966), and others, although the rebuttal has not affected the mainstream of cognitive psychology. The mainstream stance is that meanings for decision and action are built up from essentially meaningless stimulus display elements or bits and that systematic scanning of this display generates information. Thus, human cognition, like the operations of a computer, proceeds by serially receiving, registering, encoding, storing for the shortor longrun, and ""retrieving meaningless bits—a transformation to meaning that is called ""information processing."" Meanings and their associated emotions, or hot cognitions as Abelson (1963) referred to them, are built through such processing. As Erdelyi (1974) and others (e.g., Neisser, 1967) have suggested, however, emotion can influence the process at any of its stages. With this in mind, it is not surprising that Zajonc might be troubled by the implication that emotion lies at the end of a tortuous cognitive chain of information processing, and therefore find it necessary to suggest an independent system making possible rapid, nonreflective emotional reactions. As many have argued (Folkman et al., 1979; Wrubel, Benner, & Lazarus, 1981), humans are meaning-oriented, meaning-creating creatures who constantly evaluate events from the perspective of their well-being and react emotionally to some of these evaluations. Zajonc is therefore correct in asserting that meanings are immediately inherent in emotionally laden transactions without lengthy or sequential processing, but for the wrong reasons. In my view, the concept of meaning defined by the traditional information processing approach subscribed to by Zajonc has a perfectly reasonable-—and better—alternative. We do not always have to await revelation from information processing to unravel the environmental code. As was argued in the New Look movement in perception, personal factors such as beliefs, expectations, and motives or commitments influence attention and appraisal at the very outset of any encounter. Concern with individual differences leads inevitably to concern with personal meanings and to the factors that shape such meanings. We actively select and shape experience and in some degree mold it to our own requirements (see also Rychlak, 1981). Information processing as an exclusive model of cognition is insufficiently concerned with the person as a source of meaning. The history of debate about the phenomenon of subception is instructive (see Eriksen, 1956, 1960, 1962; Lazarus, 1956; Lazarus & McCleary, 1951). In a controversial experiment, McCleary and I showed that by associating a set of nonsense syllables to the threat of a painful electric shock, subjects would later react with a galvanic skin response selectively to the shock-associated syllables, even when they had misperceived and misreported, them. We referred to this phenomenon as ""autonomic discrimination without awareness,"" or ""sub1020 • SEPTEMBER 1982 • AMERICAN PSYCHOLOGIST ception,"" arguing that subjects somehow sensed the threat without consciously recognizing the syllables. The debate sparked by this interpretation touched on many complex issues, but it mainly centered on a claim by Bricker and Chapanis (1953) and Eriksen (1956, 1960, 1962) that even though the subjects had misreported what had been flashed on the screen, they probably had registered perceptually some of the structural elements of the syllables and had, in effect, reacted automatica",1982.0,38.0,1439.0,False,,"{'volume': '37', 'pages': '1019-1024', 'name': 'American Psychologist'}","{'bibtex': '@Article{Lazarus1982ThoughtsOT,\n author = {R. Lazarus},\n journal = {American Psychologist},\n pages = {1019-1024},\n title = {Thoughts on the relations between emotion and cognition.},\n volume = {37},\n year = {1982}\n}\n'}","[{'authorId': '5628684', 'name': 'R. Lazarus'}]"
1792,9a2e9a3a0a59463c9dff6ad26710632b1105ace3,Emotion regulation and memory: the cognitive costs of keeping one's cool.,"An emerging literature has begun to document the affective consequences of emotion regulation. Little is known, however, about whether emotion regulation also has cognitive consequences. A process model of emotion suggests that expressive suppression should reduce memory for emotional events but that reappraisal should not. Three studies tested this hypothesis. Study 1 experimentally manipulated expressive suppression during film viewing, showing that suppression led to poorer memory for the details of the film. Study 2 manipulated expressive suppression and reappraisal during slide viewing. Only suppression led to poorer slide memory. Study 3 examined individual differences in typical expressive suppression and reappraisal and found that suppression was associated with poorer self-reported and objective memory but that reappraisal was not. Together, these studies suggest that the cognitive costs of keeping one's cool may vary according to how this is done.",2000.0,83.0,1405.0,False,,"{'volume': '79 3', 'pages': '\n          410-24\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': ""@Article{Richards2000EmotionRA,\n author = {J. Richards and J. Gross},\n journal = {Journal of personality and social psychology},\n pages = {\n          410-24\n        },\n title = {Emotion regulation and memory: the cognitive costs of keeping one's cool.},\n volume = {79 3},\n year = {2000}\n}\n""}","[{'authorId': '46307979', 'name': 'J. Richards'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
1793,9a3907ee9c0103f8773baec92d2c4b6596d1b825,The variance of the overlap of geometrical figures with reference to a bombing problem.,,1947.0,0.0,72.0,False,,"{'volume': '34 1-2', 'pages': '\n          1-17\n        ', 'name': 'Biometrika'}","{'bibtex': '@Article{Garwood1947TheVO,\n author = {F. Garwood},\n journal = {Biometrika},\n pages = {\n          1-17\n        },\n title = {The variance of the overlap of geometrical figures with reference to a bombing problem.},\n volume = {34 1-2},\n year = {1947}\n}\n'}","[{'authorId': '31974606', 'name': 'F. Garwood'}]"
1794,9a3c1927a727d72b42baaba175ca8c85e7c8f657,Recurrent Neural Networks,,2019.0,131.0,261.0,False,,{'name': 'Deep Learning for NLP and Speech Recognition'},"{'bibtex': '@Article{Bustreo2019RecurrentNN,\n author = {Matteo Bustreo and C. Beltrán-González and Vittorio Murino and Filmato Camozzi},\n journal = {Deep Learning for NLP and Speech Recognition},\n title = {Recurrent Neural Networks},\n year = {2019}\n}\n'}","[{'authorId': '2814633', 'name': 'Matteo Bustreo'}, {'authorId': '1401645184', 'name': 'C. Beltrán-González'}, {'authorId': '1727204', 'name': 'Vittorio Murino'}, {'authorId': '2232635679', 'name': 'Filmato Camozzi'}]"
1795,9a4deea347aa995941f2f69e2d59936af19af42d,The Sigma Cognitive Architecture and System: Towards Functionally Elegant Grand Unification,"Abstract Sigma (Σ) is a cognitive architecture and system whose development is driven by a combination of four desiderata: grand unification, generic cognition, functional elegance, and sufficient efficiency. Work towards these desiderata is guided by the graphical architecture hypothesis, that key to progress on them is combining what has been learned from over three decades’ worth of separate work on cognitive architectures and graphical models. In this article, these four desiderata are motivated and explained, and then combined with the graphical architecture hypothesis to yield a rationale for the development of Sigma. The current state of the cognitive architecture is then introduced in detail, along with the graphical architecture that sits below it and implements it. Progress in extending Sigma beyond these architectures and towards a full cognitive system is then detailed in terms of both a systematic set of higher level cognitive idioms that have been developed and several virtual humans that are built from combinations of these idioms. Sigma as a whole is then analyzed in terms of how well the progress to date satisfies the desiderata. This article thus provides the first full motivation, presentation and analysis of Sigma, along with a diversity of more specific results that have been generated during its development.",2016.0,119.0,71.0,True,"{'url': 'https://content.sciendo.com/downloadpdf/journals/jagi/7/1/article-p1.pdf', 'status': None}","{'volume': '7', 'pages': '1 - 103', 'name': 'Journal of Artificial General Intelligence'}","{'bibtex': '@Article{Rosenbloom2016TheSC,\n author = {P. Rosenbloom and A. Demski and Volkan Ustun},\n journal = {Journal of Artificial General Intelligence},\n pages = {1 - 103},\n title = {The Sigma Cognitive Architecture and System: Towards Functionally Elegant Grand Unification},\n volume = {7},\n year = {2016}\n}\n'}","[{'authorId': '1749322', 'name': 'P. Rosenbloom'}, {'authorId': '2756886', 'name': 'A. Demski'}, {'authorId': '2345304', 'name': 'Volkan Ustun'}]"
1796,9a713904f83e73e9468f36a446421d5858ec84c4,Exposure Therapy for Anxiety Disorders,,2011.0,79.0,21.0,False,,"{'volume': '', 'pages': '186-191', 'name': ''}","{'bibtex': '@Inproceedings{Kaplan2011ExposureTF,\n author = {J. S. Kaplan and D. Tolin},\n pages = {186-191},\n title = {Exposure Therapy for Anxiety Disorders},\n year = {2011}\n}\n'}","[{'authorId': '8116987', 'name': 'J. S. Kaplan'}, {'authorId': '3008032', 'name': 'D. Tolin'}]"
1797,9a78bb57695d3fa20b486ab11ebb675a1a4fcedb,Estrategias para mejorar la adherencia terapéutica en patologías crónicas,,2005.0,0.0,34.0,False,,"{'volume': '29', 'pages': '8-17', 'name': ''}","{'bibtex': '@Inproceedings{Sánchez2005EstrategiasPM,\n author = {R. O. Sánchez},\n pages = {8-17},\n title = {Estrategias para mejorar la adherencia terapéutica en patologías crónicas},\n volume = {29},\n year = {2005}\n}\n'}","[{'authorId': '66522030', 'name': 'R. O. Sánchez'}]"
1798,9a7cef438ad13d9f919ff07eb3c005d64908aa6a,Assessing children's interpersonal emotion regulation with virtual agents: The serious game Emodiscovery,,2018.0,42.0,19.0,True,"{'url': 'https://pearl.plymouth.ac.uk/bitstream/10026.1/12290/1/CAE-D-17-00895R1.pdf', 'status': 'GREEN'}","{'name': 'Comput. Educ.', 'pages': '1-12', 'volume': '123'}","{'bibtex': ""@Article{Pacella2018AssessingCI,\n author = {D. Pacella and B. López-Pérez},\n booktitle = {Comput. Educ.},\n journal = {Comput. Educ.},\n pages = {1-12},\n title = {Assessing children's interpersonal emotion regulation with virtual agents: The serious game Emodiscovery},\n volume = {123},\n year = {2018}\n}\n""}","[{'authorId': '34290637', 'name': 'D. Pacella'}, {'authorId': '1402994497', 'name': 'B. López-Pérez'}]"
1799,9a8661522f60b5b040eb08a54a0d26a81eaee2ec,The Effect of Realistic Appearance of Virtual Characters in Immersive Environments - Does the Character's Personality Play a Role?,"Virtual characters that appear almost photo-realistic have been shown to induce negative responses from viewers in traditional media, such as film and video games. This effect, described as the uncanny valley, is the reason why realism is often avoided when the aim is to create an appealing virtual character. In Virtual Reality, there have been few attempts to investigate this phenomenon and the implications of rendering virtual characters with high levels of realism on user enjoyment. In this paper, we conducted a large-scale experiment on over one thousand members of the public in order to gather information on how virtual characters are perceived in interactive virtual reality games. We were particularly interested in whether different render styles (realistic, cartoon, etc.) would directly influence appeal, or if a character's personality was the most important indicator of appeal. We used a number of perceptual metrics such as subjective ratings, proximity, and attribution bias in order to test our hypothesis. Our main result shows that affinity towards virtual characters is a complex interaction between the character's appearance and personality, and that realism is in fact a positive choice for virtual characters in virtual reality.",2018.0,47.0,86.0,True,"{'url': 'http://www.tara.tcd.ie/bitstream/2262/82526/1/08267290.pdf', 'status': None}","{'volume': '24', 'pages': '1681-1690', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': ""@Article{Zibrek2018TheEO,\n author = {Katja Zibrek and Elena Kokkinara and R. Mcdonnell},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {1681-1690},\n title = {The Effect of Realistic Appearance of Virtual Characters in Immersive Environments - Does the Character's Personality Play a Role?},\n volume = {24},\n year = {2018}\n}\n""}","[{'authorId': '1710384', 'name': 'Katja Zibrek'}, {'authorId': '2540057', 'name': 'Elena Kokkinara'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
1800,9a9c83b55c1356a7eca08e22da7bf2c97e70772c,Evaluation of Multimodal Behaviour of Embodied Agents,,2004.0,27.0,45.0,False,,{'pages': '217-238'},"{'bibtex': '@Inproceedings{Buisine2004EvaluationOM,\n author = {S. Buisine and S. Abrilian and Jean-Claude Martin},\n pages = {217-238},\n title = {Evaluation of Multimodal Behaviour of Embodied Agents},\n year = {2004}\n}\n'}","[{'authorId': '1742939', 'name': 'S. Buisine'}, {'authorId': '2094223', 'name': 'S. Abrilian'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}]"
1801,9aac1ccd5479a895009fa512ea2f8e49fcd91367,College Student Suicide in the United States: 1990-1991 Through 2003-2004,"Suggestions that there is a growing epidemic of suicide among college students in the United States are false. The National Survey of Counseling Center Directors reports 1,404 student suicides over a 14-year period and an adjusted suicide rate of 6.5, half the rate of the general US population (12.6 for all races) during this period when matched for gender and age. Counseling centers appear effective in treating suicidal students, for although the suicide rate for students who were currently or previously clients at campus counseling centers is 3 times the rate of other students, student clients have 18 times the risk of suicide compared to students in general. Identifying and referring students at elevated risk for suicide could further reduce the crude and relative rate of student suicide. However, even programs that do this only moderately well may require substantial increases in counseling staffing.",2006.0,51.0,153.0,False,,"{'volume': '54', 'pages': '341 - 352', 'name': 'Journal of American College Health'}","{'bibtex': '@Article{Schwartz2006CollegeSS,\n author = {A. J. Schwartz},\n journal = {Journal of American College Health},\n pages = {341 - 352},\n title = {College Student Suicide in the United States: 1990-1991 Through 2003-2004},\n volume = {54},\n year = {2006}\n}\n'}","[{'authorId': '2150134248', 'name': 'A. J. Schwartz'}]"
1802,9aadfa00377eea2b3c1a7607e372963efee248e6,Emotion Recognition Method for Call/Contact Centre Systems,"Nowadays, one of the important aspects of research on call/contact centre (CC) systems is how to automate their operations. Process automation is influenced by the continuous development in the implementation of virtual assistants. The effectiveness of virtual assistants depends on numerous factors. One of the most important is correctly recognizing the intent of clients conversing with the machine. Recognizing intentions is not an easy process, as often the client’s actual intentions can only be correctly identified after considering the client’s emotional state. When it comes to human–machine communication, the ability of a virtual assistant to recognize the client’s emotional state would greatly improve its effectiveness. This paper proposes a new method for recognizing interlocutors’ emotions dedicated directly to contact centre systems. The developed method provides opportunities to determine emotional states in text and voice channels. It provides opportunities to explore both the client’s and the agent’s emotional states. Information about agents’ emotions can be used to build their behavioural profiles, which is also applicable in contact centres. In addition, the paper explored the possibility of emotion assessment based on automatic transcriptions of recordings, which also positively affected emotion recognition performance in the voice channel. The research used actual conversations that took place during the operation of a large, commercial contact centre. The proposed solution makes it possible to recognize the emotions of customers contacting the hotline and agents handling these calls. Using this information in practical applications can increase the efficiency of agents’ work, efficiency of bots used in CC and increase customer satisfaction.",2022.0,0.0,2.0,True,"{'url': 'https://www.mdpi.com/2076-3417/12/21/10951/pdf?version=1667883008', 'status': 'GOLD'}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Płaza2022EmotionRM,\n author = {Mirosław Płaza and R. Kazala and Z. Koruba and Marcin Kozlowski and Malgorzata Lucinska and Kamil Sitek and Jarosław Spyrka},\n booktitle = {Applied Sciences},\n journal = {Applied Sciences},\n title = {Emotion Recognition Method for Call/Contact Centre Systems},\n year = {2022}\n}\n'}","[{'authorId': '2176832114', 'name': 'Mirosław Płaza'}, {'authorId': '20702131', 'name': 'R. Kazala'}, {'authorId': '3487326', 'name': 'Z. Koruba'}, {'authorId': '30411283', 'name': 'Marcin Kozlowski'}, {'authorId': '1883034', 'name': 'Malgorzata Lucinska'}, {'authorId': '2189620851', 'name': 'Kamil Sitek'}, {'authorId': '2189646228', 'name': 'Jarosław Spyrka'}]"
1803,9ace2bcdb0ff4468b160d0d96f9926359abb0a1f,The Relationship between Teacher Support and Students' Academic Emotions: A Meta-Analysis,"This meta-analysis examines the association between teacher support and students' academic emotions [both positive academic emotions (PAEs) and negative academic emotions (NAEs)] and explores how student characteristics moderate these relationships. We identified 65 primary studies with 58,368 students. The results provided strong evidence linking teacher support and students' academic emotions. Furthermore, students' culture, age, and gender moderated these links. The correlation between teacher support and PAEs was stronger for Western European and American students than for East Asian students, while the correlation between teacher support and NAEs was stronger for East Asian students than for Western European and American students. Also, the correlation between teacher support and PAEs was strong among university students and weaker among middle school students, compared to other students. The correlation between teacher support and NAEs was stronger for middle school students and for female students, compared to other students.",2018.0,95.0,162.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2017.02288/pdf', 'status': None}","{'volume': '8', 'name': 'Frontiers in Psychology'}","{'bibtex': ""@Article{Lei2018TheRB,\n author = {H. Lei and Yunhuo Cui and M. Chiu},\n journal = {Frontiers in Psychology},\n title = {The Relationship between Teacher Support and Students' Academic Emotions: A Meta-Analysis},\n volume = {8},\n year = {2018}\n}\n""}","[{'authorId': '145454468', 'name': 'H. Lei'}, {'authorId': '12389717', 'name': 'Yunhuo Cui'}, {'authorId': '1778619', 'name': 'M. Chiu'}]"
1804,9af51c13872b8f48b361bb194a4615052c4093b9,Are facial expressions of emotion produced by categorical affect programs or dynamically driven by appraisal?,"The different assumptions made by discrete and componential emotion theories about the nature of the facial expression of emotion and the underlying mechanisms are reviewed. Explicit and implicit predictions are derived from each model. It is argued that experimental expression-production paradigms rather than recognition studies are required to critically test these differential predictions. Data from a large-scale actor portrayal study are reported to demonstrate the utility of this approach. The frequencies with which 12 professional actors use major facial muscle actions individually and in combination to express 14 major emotions show little evidence for emotion-specific prototypical affect programs. Rather, the results encourage empirical investigation of componential emotion model predictions of dynamic configurations of appraisal-driven adaptive facial actions.",2007.0,87.0,269.0,False,,"{'volume': '7 1', 'pages': '\n          113-130\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Scherer2007AreFE,\n author = {K. Scherer and H. Ellgring},\n journal = {Emotion},\n pages = {\n          113-130\n        },\n title = {Are facial expressions of emotion produced by categorical affect programs or dynamically driven by appraisal?},\n volume = {7 1},\n year = {2007}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '5068013', 'name': 'H. Ellgring'}]"
1805,9afd4b558f4abb367f066cd66f0908b24bdd6b54,Facial affect processing in social anxiety: Tasks and stimuli,,2010.0,75.0,73.0,False,,"{'volume': '193', 'pages': '1-6', 'name': 'Journal of Neuroscience Methods'}","{'bibtex': '@Article{MACHADO-DE-SOUSA2010FacialAP,\n author = {J. P. MACHADO-DE-SOUSA and K. C. Arrais and N. T. Alves and M. H. Chagas and C. Meneses-Gaya and J. Crippa and J. Hallak},\n journal = {Journal of Neuroscience Methods},\n pages = {1-6},\n title = {Facial affect processing in social anxiety: Tasks and stimuli},\n volume = {193},\n year = {2010}\n}\n'}","[{'authorId': '1393620392', 'name': 'J. P. MACHADO-DE-SOUSA'}, {'authorId': '6197833', 'name': 'K. C. Arrais'}, {'authorId': '39169435', 'name': 'N. T. Alves'}, {'authorId': '4930772', 'name': 'M. H. Chagas'}, {'authorId': '1397945674', 'name': 'C. Meneses-Gaya'}, {'authorId': '37049737', 'name': 'J. Crippa'}, {'authorId': '3844705', 'name': 'J. Hallak'}]"
1806,9b035b1bdf28dd0c947dc8fcec715e5aca3360b7,Personal Space: An Evaluative and Orienting Overview.,,1978.0,143.0,241.0,False,,"{'volume': '85', 'pages': '117-134', 'name': 'Psychological Bulletin'}","{'bibtex': '@Article{Hayduk1978PersonalSA,\n author = {L. Hayduk},\n journal = {Psychological Bulletin},\n pages = {117-134},\n title = {Personal Space: An Evaluative and Orienting Overview.},\n volume = {85},\n year = {1978}\n}\n'}","[{'authorId': '4672023', 'name': 'L. Hayduk'}]"
1807,9b2b19ce3b078a475c0f9c0b4bdfc16cce7a6129,Virtual Humans That Touch Back: Enhancing Nonverbal Communication with Virtual Humans through Bidirectional Touch,"Touch is a powerful component of human communication, yet has been largely absent in communication between humans and virtual humans (VHs). This paper expands on recent work which allowed unidirectional touch from human to VH, by evaluating bidirectional touch as a new channel for nonverbal communication. A VH augmented with a haptic interface is able to touch her interaction partner using a pseudo-haptic touch or an active-haptic touch from a co-located mechanical arm. Within the context of a simulated doctor-patient interaction, two user studies (n = 54) investigate how touch can be used by both human and VH to communicate. Results show that human-to-VH touch is used for the same communication purposes as human-to-human touch, and that VH-to-human touch (pseudo-haptic and active-haptic) allows the VH to communicate with its human interaction partner. The enhanced nonverbal communication provided by bidirectional touch has the potential to solve difficult problems in VH research, such as disambiguating user speech, enforcing social norms, and achieving rapport with VHs.",2009.0,16.0,29.0,False,,"{'pages': '175-178', 'name': '2009 IEEE Virtual Reality Conference'}","{'bibtex': '@Article{Kotranza2009VirtualHT,\n author = {Aaron Kotranza and Benjamin C. Lok and C. Pugh and D. Lind},\n journal = {2009 IEEE Virtual Reality Conference},\n pages = {175-178},\n title = {Virtual Humans That Touch Back: Enhancing Nonverbal Communication with Virtual Humans through Bidirectional Touch},\n year = {2009}\n}\n'}","[{'authorId': '2007211', 'name': 'Aaron Kotranza'}, {'authorId': '1708157', 'name': 'Benjamin C. Lok'}, {'authorId': '2575546', 'name': 'C. Pugh'}, {'authorId': '1400444374', 'name': 'D. Lind'}]"
1808,9b77131efc055b70a1bc8352752c8a34939c1191,"Recognizing Emotion in Virtual Agent, Synthetic Human, and Human Facial Expressions","A growing interest in the HCI community is the design and development of embodied agents in virtual environments. For virtual environments where social interaction is needed, an agent's facial expression may communicate emotive state to users both young and old. However, younger and older adults differ in how they label human facial expressions (Ruffman et al., 2008). Such possible age-related differences in labeling virtual agent expressions may impact the user's social experience in a virtual environment. The purpose of the current research was to investigate age-related differences in emotion recognition of several on-screen characters of varying degrees of human-likeness. Participants performed a recognition task with three characters demonstrating four basic emotions or neutral. The results indicated age-related differences for all character types. Older adults commonly mislabeled the human and synthetic human emotions of anger, fear, sadness, and neutral. For the virtual agent face, older adults commonly mislabeled the emotions of anger, fear, happiness, and neutral.",2010.0,12.0,10.0,False,,"{'name': 'Proceedings of the Human Factors and Ergonomics Society Annual Meeting', 'pages': '2388 - 2392', 'volume': '54'}","{'bibtex': '@Article{Beer2010RecognizingEI,\n author = {Jenay M. Beer and A. D. Fisk and W. Rogers},\n journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},\n pages = {2388 - 2392},\n title = {Recognizing Emotion in Virtual Agent, Synthetic Human, and Human Facial Expressions},\n volume = {54},\n year = {2010}\n}\n'}","[{'authorId': '1809740', 'name': 'Jenay M. Beer'}, {'authorId': '1689705', 'name': 'A. D. Fisk'}, {'authorId': '145912604', 'name': 'W. Rogers'}]"
1809,9bb28869d9808b12273c42229c2d1aa564e5bac8,A circumplex model of affect.,,1980.0,56.0,13178.0,False,,"{'volume': '39', 'pages': '1161-1178', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Russell1980ACM,\n author = {J. Russell},\n journal = {Journal of Personality and Social Psychology},\n pages = {1161-1178},\n title = {A circumplex model of affect.},\n volume = {39},\n year = {1980}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}]"
1817,9bc0d495ada08a5dddd0861a1f74dbd75122a5af,Implementing Expressive Gesture Synthesis for Embodied Conversational Agents,,2005.0,21.0,247.0,False,,{'pages': '188-199'},"{'bibtex': '@Inproceedings{Hartmann2005ImplementingEG,\n author = {Bjoern Hartmann and M. Mancini and C. Pelachaud},\n pages = {188-199},\n title = {Implementing Expressive Gesture Synthesis for Embodied Conversational Agents},\n year = {2005}\n}\n'}","[{'authorId': '28226629', 'name': 'Bjoern Hartmann'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
1818,9bc780c0c9e8e4dba0533f10a0068f8476cf9b24,Dynamic preferences in multi-criteria reinforcement learning,"The current framework of reinforcement learning is based on maximizing the expected returns based on scalar rewards. But in many real world situations, tradeoffs must be made among multiple objectives. Moreover, the agent's preferences between different objectives may vary with time. In this paper, we consider the problem of learning in the presence of time-varying preferences among multiple objectives, using numeric weights to represent their importance. We propose a method that allows us to store a finite number of policies, choose an appropriate policy for any weight vector and improve upon it. The idea is that although there are infinitely many weight vectors, they may be well-covered by a small number of optimal policies. We show this empirically in two domains: a version of the Buridan's ass problem and network routing.",2005.0,23.0,141.0,False,,{'name': 'Proceedings of the 22nd international conference on Machine learning'},"{'bibtex': '@Article{Natarajan2005DynamicPI,\n author = {Sriraam Natarajan and Prasad Tadepalli},\n journal = {Proceedings of the 22nd international conference on Machine learning},\n title = {Dynamic preferences in multi-criteria reinforcement learning},\n year = {2005}\n}\n'}","[{'authorId': '145986014', 'name': 'Sriraam Natarajan'}, {'authorId': '1729906', 'name': 'Prasad Tadepalli'}]"
1819,9bd36d63aac878782184217d73e1fda9b2603bb5,"Subjective Ratings of Robot Video Clips for Human Likeness , Familiarity , and Eeriness : An Exploration of the Uncanny Valley","Masahiro Mori observed that as robots come to look more humanlike, they seem more familiar, until a point is reached at which subtle deviations from human norms cause them to look creepy. He referred to this dip in familiarity and corresponding surge in strangeness as the uncanny valley. The eerie sensation associated with a mismatch between human expectations and a robot’s behavior provides a useful source of feedback to improve the cognitive models implemented in the robot. Is the uncanny valley a necessary property of near-humanlike forms? This paper contributes to ongoing work in understanding the nature and causes of the uncanny valley by means of an experiment: 56 participants were asked to rate 13 robots and 1 human, shown in video clips, on a very mechanical (1) to very humanlike (9) scale, a very strange (1) to very familiar (9) scale, and a not eerie (0) to extremely eerie (10) scale. Contrary to earlier studies with morphs [MacDorman and Ishiguro, 2006], plots of average and median values for ratings on these scales do not reveal a single U-shaped valley as predicted by Mori’s uncanny valley hypothesis [1970], although his hypothesis allows for some variation owing to movement. Robots rated similarly on the mechanical versus humanlike scale can be rated quite differently on the strange versus familiar or the eeriness scales. The results indicate that the perceived human likeness of a robot is not the only factor determining the perceived familiarity, strangeness, or eeriness of the robot. This suggests that other factors could be manipulated to vary the familiarity, strangeness, or eeriness of a robot independently of its human likeness. Introduction To build robots that at least superficially approach human likeness is leading to insights in human perception and face-to-face interaction. These android robots possess the physical presence that simulated characters lack, yet can be more perfectly controlled than any human actor, to isolate the factor under study. Even in experiments in which the android’s responses are identical, we can observe how human responses vary according to their beliefs. For example, Japanese participants showed the same modesty with their eyes by averting gaze downward when interacting with an android as when interacting with a human interlocutor if they believed the android were under human control by telepresence [MacDorman et al., 2005]. In addition, androids provide an ideal testing ground for theories from the social and cognitive sciences because competing models can be implemented in an android and then tested by letting the android interact with industrial robot humanoid robot",2006.0,8.0,242.0,False,,,"{'bibtex': '@Inproceedings{Macdorman2006SubjectiveRO,\n author = {K. Macdorman},\n title = {Subjective Ratings of Robot Video Clips for Human Likeness , Familiarity , and Eeriness : An Exploration of the Uncanny Valley},\n year = {2006}\n}\n'}","[{'authorId': '1690354', 'name': 'K. Macdorman'}]"
1820,9bddf85953ae8276b728b70950f0cdc0503e5cd3,Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior,"Virtual humans are embodied software agents that should not only be realistic looking but also have natural and realistic behaviors. Traditional virtual human systems learn these interaction behaviors by observing how individuals respond in face-to-face situations (i.e., dir ect interaction). In contrast, this paper introduces a novel methodological approach called paras ocial consensus sampling (PCS) which allows multiple individuals to vicariously experience the same situation to gain insight on the typical (i.e., consensus view) of human responses in social interaction. This approach can help tease a part what is idiosyncratic from what is essential and help reveal the strength of cues that elicit social responses. Our PCS approach has several advantages over traditional methods: (1) it integrates data from multiple independent listeners interacting with the same speaker, (2) it associates probability of how likely feedback will be given over time, (3) it can be used as a prior to analyze and understand the face-to-face interaction data, (4) it facilitates much quicker and cheaper data collection. In this paper, we apply our PCS approach to learn a predictive model of listener backchannel feedback. Our experiments demonstrate that a virtual human driven by our PCS approach creates significantly more rapport and is perceived as more believable than the virtual human driven by face-to-face interaction data.",2010.0,28.0,59.0,False,,{'pages': '1265-1272'},"{'bibtex': '@Inproceedings{Huang2010ParasocialCS,\n author = {Lixing Huang and Louis-Philippe Morency and J. Gratch},\n pages = {1265-1272},\n title = {Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior},\n year = {2010}\n}\n'}","[{'authorId': '2110799090', 'name': 'Lixing Huang'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
1821,9be875c4202a52cd3fce2f20b9bb419989197fdd,"The Effect of the Agency and Anthropomorphism on Users' Sense of Telepresence, Copresence, and Social Presence in Virtual Environments","We report on an experiment that examined the influence of anthropomorphism and perceived agency on presence, copresence, and social presence in a virtual environment. The experiment varied the level of anthropomorphism of the image of interactants: high anthropomorphism, low anthropomorphism, or no image. Perceived agency was manipulated by telling the participants that the image was either an avatar controlled by a human, or an agent controlled by a computer. The results support the prediction that people respond socially to both human and computer-controlled entities, and that the existence of a virtual image increases tele-presence. Participants interacting with the less-anthropomorphic image reported more copresence and social presence than those interacting with partners represented by either no image at all or by a highly anthropomorphic image of the other, indicating that the more anthropomorphic images set up higher expectations that lead to reduced presence when these expectations were not met.",2003.0,67.0,873.0,False,,"{'volume': '12', 'pages': '481-494', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': ""@Article{Nowak2003TheEO,\n author = {Kristine L. Nowak and F. Biocca},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {481-494},\n title = {The Effect of the Agency and Anthropomorphism on Users' Sense of Telepresence, Copresence, and Social Presence in Virtual Environments},\n volume = {12},\n year = {2003}\n}\n""}","[{'authorId': '40372043', 'name': 'Kristine L. Nowak'}, {'authorId': '1726689', 'name': 'F. Biocca'}]"
1824,9bfd7c5c87dcad98b17b16ba1f3b01e549b8b3d5,Autonomous Agents: Characterization and Requirements,"A fresh assessment of what autonomous agents are or may aspire to be is presented in the paper. We dismiss the traditional dichotomy between reactive and symbolic architectures. A classiication in terms of the amount of knowledge embedded in the system is made, instead, running from regulatory to planning to adaptive agents. Regulatory agents are implementable as control systems or automata, and represent the ideal case in which the agent has all the knowledge it needs. We nd that each type of agent is best suited for a particular kind of behavior. The diierent kinds of behavior form a hierarchy in terms of frequency of occurrence and response time, and do not gracefully reduce to each other. This suggests implementing agents as hierarchies of simpler agents, each specialized in the kind of behavior it implements. In this scheme, agents at one level act through agents at the next lower level. We introduce the concept of drive to address the issue of where an agent's goals come from. A discussion is made of common pitfalls and suggestions for the design of planning agents. Finally, a parallel architecture that embodies many of the ideas presented is sketched and discussed. This architecture solves the two major problems present in Georgee's earlier architecture, PRS: strictly sequential execution, and inability to learn.",1991.0,17.0,55.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Brustoloni1991AutonomousAC,\n author = {J. Brustoloni},\n title = {Autonomous Agents: Characterization and Requirements},\n year = {1991}\n}\n'}","[{'authorId': '1763484', 'name': 'J. Brustoloni'}]"
1825,9c0bedf98c4fa51676669cc509b0d97e4c7c5fd0,Communicative Listener Feedback in Human-Agent Interaction: Artificial Speakers Need to Be Attentive and Adaptive,"In human dialogue, listener feedback is a pervasive phenomenon that serves important functions in the coordination of the conversation, both in regulating its flow, as well as in creating and ensuring understanding between interlocutors. This make feedback an interesting mechanism for conversational human-agent interaction. In this paper we describe computational models for an attentive speaker' agent is able to (1) interpret the feedback behaviour of its human interlocutors by probabilistically attributing listening-related mental states to them; (2) incrementally adapt its ongoing language and behaviour generation to their needs; and (3) elicit feedback from them when needed. We present a semi-autonomous interaction study, in which we compare such an attentive speaker agent with agents that either do not adapt their behaviour to their listeners' needs, or employ highly explicit ways of ensuring understanding. The results show that human interlocutors interacting with the attentive speaker agent provided significantly more listener feedback, felt that the agent was attentive to, and adaptive to their feedback, attested the agent a desire to be understood, and rated it more helpful in resolving difficulties in their understanding.",2018.0,45.0,25.0,False,,{'pages': '1213-1221'},"{'bibtex': '@Inproceedings{Buschmeier2018CommunicativeLF,\n author = {Hendrik Buschmeier and S. Kopp},\n pages = {1213-1221},\n title = {Communicative Listener Feedback in Human-Agent Interaction: Artificial Speakers Need to Be Attentive and Adaptive},\n year = {2018}\n}\n'}","[{'authorId': '2849488', 'name': 'Hendrik Buschmeier'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
1826,9c14dc8a394f22c65775dbfe762c450a5bd7173f,Psychological Construction in the OCC Model of Emotion,"This article presents six ideas about the construction of emotion: (a) Emotions are more readily distinguished by the situations they signify than by patterns of bodily responses; (b) emotions emerge from, rather than cause, emotional thoughts, feelings, and expressions; (c) the impact of emotions is constrained by the nature of the situations they represent; (d) in the OCC account (the model proposed by Ortony, Clore, and Collins in 1988), appraisals are psychological aspects of situations that distinguish one emotion from another, rather than triggers that elicit emotions; (e) analyses of the affective lexicon indicate that emotion words refer to internal mental states focused on affect; (f) the modularity of emotion, long sought in biology and behavior, exists as mental schemas for interpreting human experience in story, song, drama, and conversation.",2013.0,40.0,172.0,True,"{'url': 'https://europepmc.org/articles/pmc4243519?pdf=render', 'status': None}","{'volume': '5', 'pages': '335 - 343', 'name': 'Emotion Review'}","{'bibtex': '@Article{Clore2013PsychologicalCI,\n author = {G. Clore and A. Ortony},\n journal = {Emotion Review},\n pages = {335 - 343},\n title = {Psychological Construction in the OCC Model of Emotion},\n volume = {5},\n year = {2013}\n}\n'}","[{'authorId': '31458494', 'name': 'G. Clore'}, {'authorId': '1802934', 'name': 'A. Ortony'}]"
1827,9c1ddc2a368768fa73fa4d3e0dd02eadf9578a39,User-State Sensing for Virtual Health Agents and TeleHealth Applications,"Nonverbal behaviors play a crucial role in shaping outcomes in face-to-face clinical interactions. Experienced clinicians use nonverbals to foster rapport and ""read"" their clients to inform diagnoses. The rise of telemedicine and virtual health agents creates new opportunities, but it also strips away much of this nonverbal channel. Recent advances in low-cost computer vision and sensing technologies have the potential to address this challenge by learning to recognize nonverbal cues from large datasets of clinical interactions. These techniques can enhance both telemedicine and the emerging technology of virtual health agents. This article describes our current research in addressing these challenges in the domain of PTSD and depression screening for U.S. Veterans. We describe our general approach and report on our initial contribution: the creation of a large dataset of clinical interview data that facilitates the training of user-state sensing technology.",2013.0,31.0,30.0,False,,"{'volume': '184', 'pages': '\n          151-7\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Gratch2013UserStateSF,\n author = {J. Gratch and Louis-Philippe Morency and Stefan Scherer and Giota Stratou and Jill Boberg and S. Koenig and Todd Adamson and A. Rizzo},\n journal = {Studies in health technology and informatics},\n pages = {\n          151-7\n        },\n title = {User-State Sensing for Virtual Health Agents and TeleHealth Applications},\n volume = {184},\n year = {2013}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '6349590', 'name': 'Jill Boberg'}, {'authorId': '39471600', 'name': 'S. Koenig'}, {'authorId': '49651370', 'name': 'Todd Adamson'}, {'authorId': '29861580', 'name': 'A. Rizzo'}]"
1828,9c2f2fe4cbf7c30362f2818392b464e539b5aaca,The Chameleon Effect as Social Glue: Evidence for the Evolutionary Significance of Nonconscious Mimicry,,2003.0,77.0,934.0,False,,"{'volume': '27', 'pages': '145-162', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Lakin2003TheCE,\n author = {Jessica L. Lakin and V. Jefferis and C. M. Cheng and T. Chartrand},\n journal = {Journal of Nonverbal Behavior},\n pages = {145-162},\n title = {The Chameleon Effect as Social Glue: Evidence for the Evolutionary Significance of Nonconscious Mimicry},\n volume = {27},\n year = {2003}\n}\n'}","[{'authorId': '5622454', 'name': 'Jessica L. Lakin'}, {'authorId': '5486548', 'name': 'V. Jefferis'}, {'authorId': '2193145799', 'name': 'C. M. Cheng'}, {'authorId': '6026289', 'name': 'T. Chartrand'}]"
1829,9c4230f57112ee254dfe80e4fb3b1eaa9a76aba6,"The Effect of Behavioral Realism and Form Realism of Real-Time Avatar Faces on Verbal Disclosure, Nonverbal Disclosure, Emotion Recognition, and Copresence in Dyadic Interaction","The realism of avatars in terms of behavior and form is critical to the development of collaborative virtual environments. In the study we utilized state of the art, real-time face tracking technology to track and render facial expressions unobtrusively in a desktop CVE. Participants in dyads interacted with each other via either a video-conference (high behavioral realism and high form realism), voice only (low behavioral realism and low form realism), or an emotibox that rendered the dimensions of facial expressions abstractly in terms of color, shape, and orientation on a rectangular polygon (high behavioral realism and low form realism). Verbal and non-verbal self-disclosure were lowest in the videoconference condition while self-reported copresence and success of transmission and identification of emotions were lowest in the emotibox condition. Previous work demonstrates that avatar realism increases copresence while decreasing self-disclosure. We discuss the possibility of a hybrid realism solution that maintains high copresence without lowering self-disclosure, and the benefits of such an avatar on applications such as distance learning and therapy.",2006.0,42.0,349.0,False,,"{'volume': '15', 'pages': '359-372', 'name': 'PRESENCE: Teleoperators and Virtual Environments'}","{'bibtex': '@Article{Bailenson2006TheEO,\n author = {J. Bailenson and N. Yee and D. Merget and Ralph Schroeder},\n journal = {PRESENCE: Teleoperators and Virtual Environments},\n pages = {359-372},\n title = {The Effect of Behavioral Realism and Form Realism of Real-Time Avatar Faces on Verbal Disclosure, Nonverbal Disclosure, Emotion Recognition, and Copresence in Dyadic Interaction},\n volume = {15},\n year = {2006}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '38811484', 'name': 'N. Yee'}, {'authorId': '3044182', 'name': 'D. Merget'}, {'authorId': '144194373', 'name': 'Ralph Schroeder'}]"
1830,9c4a953ed2cfc999eef0901d43097f9d2933005c,Cost-Sensitive Learning and the Class Imbalance Problem,Cost-Sensitive Learning is a type of learning in data mining that takes the misclassification costs (and possibly other types of cost) into consideration. The goal of this type of learning is to minimize the total cost. The key difference between cost-sensitive learning and cost-insensitive learning is that cost-sensitive learning treats the different misclassifications differently. Costinsensitive learning does not take the misclassification costs into consideration. The goal of this type of learning is to pursue a high accuracy of classifying examples into a set of known classes.,2008.0,16.0,257.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ling2008CostSensitiveLA,\n author = {C. Ling and V. Sheng},\n title = {Cost-Sensitive Learning and the Class Imbalance Problem},\n year = {2008}\n}\n'}","[{'authorId': '1688204', 'name': 'C. Ling'}, {'authorId': '2858764', 'name': 'V. Sheng'}]"
1831,9c6d9244be3f4628a4b7fa31def3452aa02f20d2,Group Rapport: Posture Sharing as a Nonverbal Indicator,"Systematic observation and a questionnaire format were used to investigate the relationship between posture sharing and self-report indications of rapport in a group situation-college seminar classrooms. A pattern of significant positive correlations revealed that the greater the amount of mirroring and congruent postures evidenced by students vis-à-vis the teacher, the higher the ratings of involvement. Conversely, a significant negative relationship was found between amount of incongruent posture display and reports of interest. Implications of the findings for group dynamics and environmental design are discussed.",1976.0,11.0,220.0,False,,"{'volume': '1', 'pages': '328 - 333', 'name': 'Group & Organization Management'}","{'bibtex': '@Article{LaFrance1976GroupRP,\n author = {M. LaFrance and Maida Broadbent},\n journal = {Group & Organization Management},\n pages = {328 - 333},\n title = {Group Rapport: Posture Sharing as a Nonverbal Indicator},\n volume = {1},\n year = {1976}\n}\n'}","[{'authorId': '37544705', 'name': 'M. LaFrance'}, {'authorId': '113109009', 'name': 'Maida Broadbent'}]"
1832,9c9e452376340e26faadfd4af300aab2cc53621a,Integrating information from speech and physiological signals to achieve emotional sensitivity,"Recently, there has been a significant amount of work on the recognition of emotions from speech and biosignals. Most approaches to emotion recognition so far concentrate on a single modality and do not take advantage of the fact that an integrated multimodal analysis may help to resolve ambiguities and compensate for errors. In this paper, we describe various methods for fusing physiological and voice data at the feature-level and the decision-level as well as a hybrid integration scheme. The results of the integrated recognition approach are then compared with the individual recognition results from each modality.",2005.0,19.0,63.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/47270/Integrating Information from Speech and Physiological Signals to Achieve.pdf', 'status': None}",{'pages': '809-812'},"{'bibtex': '@Inproceedings{Kim2005IntegratingIF,\n author = {Jonghwa Kim and E. André and M. Rehm and Thurid Vogt and J. Wagner},\n pages = {809-812},\n title = {Integrating information from speech and physiological signals to achieve emotional sensitivity},\n year = {2005}\n}\n'}","[{'authorId': '11384820', 'name': 'Jonghwa Kim'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '39957689', 'name': 'M. Rehm'}, {'authorId': '30169286', 'name': 'Thurid Vogt'}, {'authorId': '6164138', 'name': 'J. Wagner'}]"
1833,9ca1602c57cea8fe8a1a3fe512acae6d8cfca11c,Beyond the basic emotions: what should affective computing compute?,"One of the primary goals of Affective Computing (AC) is to develop computer interfaces that automatically detect and respond to users' emotions. Despite significant progress, ""basic emotions"" (e.g., anger, disgust, sadness) have been emphasized in AC at the expense of other non-basic emotions. The present paper questions this emphasis by analyzing data from five studies that systematically tracked both basic and non-basic emotions. The results indicate that engagement, boredom, confusion, and frustration (all non-basic emotions) occurred at five times the rate of basic emotions after generalizing across tasks, interfaces, and methodologies. Implications of these findings for AC are discussed",2013.0,26.0,89.0,False,,"{'name': ""CHI '13 Extended Abstracts on Human Factors in Computing Systems""}","{'bibtex': ""@Article{D’Mello2013BeyondTB,\n author = {S. D’Mello and R. Calvo},\n journal = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},\n title = {Beyond the basic emotions: what should affective computing compute?},\n year = {2013}\n}\n""}","[{'authorId': '1383996606', 'name': 'S. D’Mello'}, {'authorId': '144792845', 'name': 'R. Calvo'}]"
1834,9ca8d729ea640b9367cc7e91b853ee8ed8e75a32,Virtual Rapport 2.0,,2011.0,36.0,156.0,False,,{'pages': '68-79'},"{'bibtex': '@Inproceedings{Huang2011VirtualR2,\n author = {Lixing Huang and Louis-Philippe Morency and Jonathan Gratch},\n pages = {68-79},\n title = {Virtual Rapport 2.0},\n year = {2011}\n}\n'}","[{'authorId': '2110799084', 'name': 'Lixing Huang'}, {'authorId': '2065275646', 'name': 'Louis-Philippe Morency'}, {'authorId': '2064713461', 'name': 'Jonathan Gratch'}]"
1836,9d164c20015a447bc8b7875c82822bb7342f3f92,Automatic vehicle classification system with range sensors,,2001.0,24.0,58.0,False,,"{'volume': '9', 'pages': '231-247', 'name': 'Transportation Research Part C-emerging Technologies'}","{'bibtex': '@Article{Harlow2001AutomaticVC,\n author = {C. Harlow and Shiquan Peng},\n journal = {Transportation Research Part C-emerging Technologies},\n pages = {231-247},\n title = {Automatic vehicle classification system with range sensors},\n volume = {9},\n year = {2001}\n}\n'}","[{'authorId': '2289828', 'name': 'C. Harlow'}, {'authorId': '2072712874', 'name': 'Shiquan Peng'}]"
1837,9d50b997c502ad87cc2a6f8980c4e0d0482a1fd0,A Telemonitoring Tool based on Serious Games Addressing Money Management Skills for People with Intellectual Disability,"This article presents a telemonitoring tool based on computer games, aimed at money management skill improvement for people with Intellectual Disabilities (ID). The presented tool is divided into two parts: on one hand, some training activities related to payments and currency discrimination based on Serious Games are proposed to the user using a multitouch device. On the other hand, the psychologists and specialist who work with them, can access to the Serious Games results using an online application in order to evaluate their evolution. The results are measured according to the number of errors they have during the proposed activities, the time they need to complete them and the score. The article show the results of an experiment made with a clinical sample of 12 users with ID between 12 and 15 years, taking into account that all of them are capable of correct oral communication and they do not have severe physical coordination problems. Only two users completed all the games without errors. Males obtained a mean of 28.25 errors, whereas females obtained a mean of 17.75. The results show significant difference between the selection of games 1, 2 or 3, because all of them prefer the game 1 related with “Payments” probably because it permits more interaction using the multitouch device. The authors also made a qualitative evaluation and the results have been very promising and satisfactory.",2014.0,58.0,31.0,True,"{'url': 'https://www.mdpi.com/1660-4601/11/3/2361/pdf?version=1403142363', 'status': None}","{'volume': '11', 'pages': '2361 - 2380', 'name': 'International Journal of Environmental Research and Public Health'}","{'bibtex': '@Article{Lopez-Basterretxea2014ATT,\n author = {Asier Lopez-Basterretxea and A. Méndez-Zorrilla and B. Garcia-Zapirain},\n journal = {International Journal of Environmental Research and Public Health},\n pages = {2361 - 2380},\n title = {A Telemonitoring Tool based on Serious Games Addressing Money Management Skills for People with Intellectual Disability},\n volume = {11},\n year = {2014}\n}\n'}","[{'authorId': '1402098919', 'name': 'Asier Lopez-Basterretxea'}, {'authorId': '1402098961', 'name': 'A. Méndez-Zorrilla'}, {'authorId': '1401698332', 'name': 'B. Garcia-Zapirain'}]"
1838,9d93af9029429a1916d692059ee213026b782d37,Insight Vs. Desensitization in Psychotherapy: An Experiment in Anxiety Reduction,"We may not be able to make you love reading, but insight vs desensitization in psychotherapy an experiment in anxiety reduction will lead you to love reading starting from now. Book is the window to open the new world. The world that you want is in the better stage and level. World will always guide you to even the prestige stage of the life. You know, this is some of how reading will give you the kindness. In this case, more books you read more knowledge you know, but it can mean also the bore is full.",1966.0,0.0,389.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Paul1966InsightVD,\n author = {G. L. Paul},\n title = {Insight Vs. Desensitization in Psychotherapy: An Experiment in Anxiety Reduction},\n year = {1966}\n}\n'}","[{'authorId': '73520605', 'name': 'G. L. Paul'}]"
1839,9d952862420dcd3e1d17d5e551eaa124ee1021eb,Agent-Based Modelling of the Emergence of Collective States Based on Contagion of Individual States in Groups,,2011.0,46.0,16.0,True,"{'url': 'http://www.cs.vu.nl/%7Ewai/Papers/TCCI10contagion.pdf', 'status': None}","{'volume': '3', 'pages': '152-179', 'name': 'Trans. Comput. Collect. Intell.'}","{'bibtex': '@Article{Hoogendoorn2011AgentBasedMO,\n author = {M. Hoogendoorn and Jan Treur and C. N. V. D. Wal and A. V. Wissen},\n journal = {Trans. Comput. Collect. Intell.},\n pages = {152-179},\n title = {Agent-Based Modelling of the Emergence of Collective States Based on Contagion of Individual States in Groups},\n volume = {3},\n year = {2011}\n}\n'}","[{'authorId': '144074133', 'name': 'M. Hoogendoorn'}, {'authorId': '1726343', 'name': 'Jan Treur'}, {'authorId': '1881843', 'name': 'C. N. V. D. Wal'}, {'authorId': '1809908', 'name': 'A. V. Wissen'}]"
1840,9dd45c22cd7fd84d616de698dbdd96fa343ec2db,Mathematical formulations of Hebbian learning,,2002.0,52.0,391.0,True,"{'url': 'https://infoscience.epfl.ch/record/97808/files/HEBB-BCY.pdf', 'status': None}","{'volume': '87', 'pages': '404-415', 'name': 'Biological Cybernetics'}","{'bibtex': '@Article{Gerstner2002MathematicalFO,\n author = {W. Gerstner and W. M. Kistler},\n journal = {Biological Cybernetics},\n pages = {404-415},\n title = {Mathematical formulations of Hebbian learning},\n volume = {87},\n year = {2002}\n}\n'}","[{'authorId': '1708945', 'name': 'W. Gerstner'}, {'authorId': '34847772', 'name': 'W. M. Kistler'}]"
1841,9dd9101cdb97a1b613f6168c1c77444c39b1fa81,Towards Autism Screening through Emotion-guided Eye Gaze Response,"Individuals with Autism Spectrum Disorder (ASD) are known to have significantly limited social interaction abilities, which are often manifested in different non-verbal cues of communication such as facial expression, atypical eye gaze response. While prior works leveraged the role of pupil response for screening ASD, limited works have been carried out to find the influence of emotion stimuli on pupil response for ASD screening. We, in this paper, design, develop, and evaluate a light-weight LSTM (Long-short Term Memory) model that captures pupil responses (pupil diameter, fixation duration, and fixation location) based on the social interaction with a virtual agent and detects ASD sessions based on short interactions. Our findings demonstrate that all the pupil responses vary significantly in the ASD sessions in response to the different emotion (angry, happy, neutral) stimuli applied. These findings reinforce the ASD screening with an average accuracy of 77%, while the accuracy improves further (>80%) with respect to angry and happy emotion stimuli.",2021.0,24.0,1.0,False,,"{'name': '2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)', 'pages': '820-823'}","{'bibtex': '@Article{Ghosh2021TowardsAS,\n author = {Surjya Ghosh and T. Guha},\n booktitle = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society},\n journal = {2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)},\n pages = {820-823},\n title = {Towards Autism Screening through Emotion-guided Eye Gaze Response},\n year = {2021}\n}\n'}","[{'authorId': '40598977', 'name': 'Surjya Ghosh'}, {'authorId': '1720741', 'name': 'T. Guha'}]"
1842,9dd9e154c79176b7df5f1e52e5d534089b302f1d,Differential attentional guidance by unattended faces expressing positive and negative emotion,,2001.0,45.0,601.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03194519.pdf', 'status': None}","{'volume': '63', 'pages': '1004-1013', 'name': 'Perception & Psychophysics'}","{'bibtex': '@Article{Eastwood2001DifferentialAG,\n author = {J. Eastwood and D. Smilek and P. Merikle},\n journal = {Perception & Psychophysics},\n pages = {1004-1013},\n title = {Differential attentional guidance by unattended faces expressing positive and negative emotion},\n volume = {63},\n year = {2001}\n}\n'}","[{'authorId': '3641490', 'name': 'J. Eastwood'}, {'authorId': '2562337', 'name': 'D. Smilek'}, {'authorId': '5367295', 'name': 'P. Merikle'}]"
1843,9ddd1b65e133de101c0100e90e0588c075d6fba8,The role of co-regulation for the development of social-emotional competence,"Regulating emotions volitionally requires the inhibition and modification of an elicited emotional action readiness and includes phases of reflection, planning and self-regulation. The proposed internalization model of reflective emotion regulation argues that caregivers’ co-regulation of emotionally challenging events plays a constitutive role for the development of 4- to 6-year-olds’ reflective emotion regulation. The model specifies the gradual shift from co- to self-regulation by focusing on two important ways how caregivers structure emotionally challenging interactions: Through emotion talk, caregivers promote the development of preschoolers’ emotional awareness. Once established, they support children in establishing a repertoire of effective emotion regulation strategies and they guide preschoolers’ emerging skills to generate, evaluate, and select from alternative appraisals or behavioral responses.",2016.0,87.0,23.0,False,,"{'volume': '2', 'pages': '17-32', 'name': ''}","{'bibtex': '@Inproceedings{Silkenbeumer2016TheRO,\n author = {Judith Rebecca Silkenbeumer and Eva-Maria Schiller and Manfred Holodynski and Joscha Kärtner},\n pages = {17-32},\n title = {The role of co-regulation for the development of social-emotional competence},\n volume = {2},\n year = {2016}\n}\n'}","[{'authorId': '115964516', 'name': 'Judith Rebecca Silkenbeumer'}, {'authorId': '2052760391', 'name': 'Eva-Maria Schiller'}, {'authorId': '6051757', 'name': 'Manfred Holodynski'}, {'authorId': '4185170', 'name': 'Joscha Kärtner'}]"
1844,9dfcec6f6fe0645d13c1c2618eb500cd30287ae5,E-learners Kansei experience towards expert-like virtual agent: A case study,"The rapid growth of Internet users and diverse Web 5.0 technologies has made the research scholars and educators to think of intelligent tools such as; expert-like virtual agents as an effective e-learning tool. The success of an e-learning tool relies primarily on the level of acceptance of the tool by the e-learners and their state of emotion while using the tool. Therefore, addressing e-learner's emotional competences is important to understand the implicit emotion of the young minds. In this context, virtual agents are expected to play the role of instructors in a virtual learning environment. This paper aims to study the affective design of the Virtual Agent in terms of attractiveness and realism that adopts Kansei Engineering, an emerging technology used to explore and validate the emotion structure defined as a complex state of feelings that can result in the changes of human behaviour and thoughts of e-learners. Adding on, the paper also highlights and validates the six universal emotions such as anger, happiness, surprise, disgust, sadness and fear. The findings suggest that the most attractive and realistic virtual agents have higher Kansei value. Some implications of the findings in relation to expert-like virtual agent design and Kansei are discussed in this paper.",2014.0,28.0,1.0,False,,"{'name': '2014 3rd International Conference on User Science and Engineering (i-USEr)', 'pages': '36-41'}","{'bibtex': '@Conference{Ramachandiran2014ElearnersKE,\n author = {C. R. Ramachandiran and N. Jomhari},\n booktitle = {International Conference on User Science and Engineering},\n journal = {2014 3rd International Conference on User Science and Engineering (i-USEr)},\n pages = {36-41},\n title = {E-learners Kansei experience towards expert-like virtual agent: A case study},\n year = {2014}\n}\n'}","[{'authorId': '9157318', 'name': 'C. R. Ramachandiran'}, {'authorId': '2191058', 'name': 'N. Jomhari'}]"
1845,9e0197052e4d35d0a8d81bb2cd37721753270f1c,Dynamics of emotional contagion in dense pedestrian crowds,,2020.0,30.0,16.0,False,,"{'volume': '384', 'pages': '126080', 'name': 'Physics Letters A'}","{'bibtex': '@Article{Xu2020DynamicsOE,\n author = {Tengfei Xu and Dongdong Shi and Juan Chen and Tao Li and P. Lin and Jian Ma},\n journal = {Physics Letters A},\n pages = {126080},\n title = {Dynamics of emotional contagion in dense pedestrian crowds},\n volume = {384},\n year = {2020}\n}\n'}","[{'authorId': '2118717268', 'name': 'Tengfei Xu'}, {'authorId': '2064971197', 'name': 'Dongdong Shi'}, {'authorId': '2108324508', 'name': 'Juan Chen'}, {'authorId': '2149199538', 'name': 'Tao Li'}, {'authorId': '2087501138', 'name': 'P. Lin'}, {'authorId': '119597887', 'name': 'Jian Ma'}]"
1846,9e2a69d52cbd91e6d2bb242d13412fa3920f9baa,"Behind the Robot’s Smiles and Frowns: In Social Context, People Do Not Mirror Android’s Expressions But React to Their Informational Value","Facial actions are key elements of non-verbal behavior. Perceivers’ reactions to others’ facial expressions often represent a match or mirroring (e.g., they smile to a smile). However, the information conveyed by an expression depends on context. Thus, when shown by an opponent, a smile conveys bad news and evokes frowning. The availability of anthropomorphic agents capable of facial actions raises the question of how people respond to such agents in social context. We explored this issue in a study where participants played a strategic game with or against a facially expressive android. Electromyography (EMG) recorded participants’ reactions over zygomaticus muscle (smiling) and corrugator muscle (frowning). We found that participants’ facial responses to android’s expressions reflect their informational value, rather than a direct match. Overall, participants smiled more, and frowned less, when winning than losing. Critically, participants’ responses to the game outcome were similar regardless of whether it was conveyed via the android’s smile or frown. Furthermore, the outcome had greater impact on people’s facial reactions when it was conveyed through android’s face than a computer screen. These findings demonstrate that facial actions of artificial agents impact human facial responding. They also suggest a sophistication in human-robot communication that highlights the signaling value of facial expressions.",2018.0,58.0,11.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnbot.2018.00014/pdf', 'status': None}","{'volume': '12', 'name': 'Frontiers in Neurorobotics'}","{'bibtex': '@Article{Hofree2018BehindTR,\n author = {Galit Hofree and P. Ruvolo and Audrey Reinert and M. Bartlett and P. Winkielman},\n journal = {Frontiers in Neurorobotics},\n title = {Behind the Robot’s Smiles and Frowns: In Social Context, People Do Not Mirror Android’s Expressions But React to Their Informational Value},\n volume = {12},\n year = {2018}\n}\n'}","[{'authorId': '3092566', 'name': 'Galit Hofree'}, {'authorId': '12114845', 'name': 'P. Ruvolo'}, {'authorId': '2073397460', 'name': 'Audrey Reinert'}, {'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '3122131', 'name': 'P. Winkielman'}]"
1847,9e3bc0c0294d02201466ac1883ec9a6e5b1707c2,Touch increases autonomic coupling between romantic partners,"Interpersonal touch is of paramount importance in human social bonding and close relationships, allowing a unique channel for affect communication. So far the effect of touch on human physiology has been studied at an individual level. The present study aims at extending the study of affective touch from isolated individuals to truly interacting dyads. We have designed an ecological paradigm where romantic partners interact only via touch and we manipulate their empathic states. Simultaneously, we collected their autonomic activity (skin conductance, pulse, respiration). Fourteen couples participated to the experiment. We found that interpersonal touch increased coupling of electrodermal activity between the interacting partners, regardless the intensity and valence of the emotion felt. In addition, physical touch induced strong and reliable changes in physiological states within individuals. These results support an instrumental role of interpersonal touch for affective support in close relationships. Furthermore, they suggest that touch alone allows the emergence of a somatovisceral resonance between interacting individuals, which in turn is likely to form the prerequisites for emotional contagion and empathy.",2014.0,56.0,107.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnbeh.2014.00095/pdf', 'status': None}","{'volume': '8', 'name': 'Frontiers in Behavioral Neuroscience'}","{'bibtex': '@Article{Chatel-Goldman2014TouchIA,\n author = {Jonas Chatel-Goldman and M. Congedo and C. Jutten and J. Schwartz},\n journal = {Frontiers in Behavioral Neuroscience},\n title = {Touch increases autonomic coupling between romantic partners},\n volume = {8},\n year = {2014}\n}\n'}","[{'authorId': '1401848361', 'name': 'Jonas Chatel-Goldman'}, {'authorId': '3276441', 'name': 'M. Congedo'}, {'authorId': '1696508', 'name': 'C. Jutten'}, {'authorId': '33803854', 'name': 'J. Schwartz'}]"
1848,9e46beca6fbf17d83ae85ce380f7a69106026522,Emotional virtual agent for mobile devices,"The increasing amount of computational capacity of mobile devices allowed the development of real time multimodal applications. This kind of systems use to employ virtual agents for improving the communication between services and users. In this work, we present an agent-based application that allows multimodal and emotional interaction with the users through different channels: visual, oral and written. The system has been assessed with real users in order to verify the virtual character's ability to express emotions.",2015.0,0.0,0.0,False,,{'name': 'Proceedings of the XVI International Conference on Human Computer Interaction'},"{'bibtex': '@Book{Baldassarri2015EmotionalVA,\n author = {S. Baldassarri and E. Cerezo},\n booktitle = {Interacción},\n journal = {Proceedings of the XVI International Conference on Human Computer Interaction},\n title = {Emotional virtual agent for mobile devices},\n year = {2015}\n}\n'}","[{'authorId': '1787072', 'name': 'S. Baldassarri'}, {'authorId': '144046205', 'name': 'E. Cerezo'}]"
1849,9e5b55d37ea21c26d5027e29cc4602a8382d3384,Reporting Mental Health Symptoms: Breaking Down Barriers to Care with Virtual Human Interviewers,"A common barrier to healthcare for psychiatric conditions is the stigma associated with these disorders. Perceived stigma prevents many from reporting their symptoms. Stigma is a particularly pervasive problem among military service members, preventing them from reporting symptoms of combat-related conditions like posttraumatic stress disorder (PTSD). However, research shows increased reporting by service members when anonymous assessments are used. For example, service members report more symptoms of PTSD when they anonymously answer the Post-Deployment Health Assessment (PDHA) symptom checklist compared to the official PDHA, which is identifiable and linked to their military records. To investigate the factors that influence reporting of psychological symptoms by service members, we used a transformative technology: automated virtual humans that interview people about their symptoms. Such virtual human interviewers allow simultaneous use of two techniques for eliciting disclosure that would otherwise be incompatible; they afford anonymity while also building rapport. We examined whether virtual human interviewers could increase disclosure of mental health symptoms among active-duty service members that just returned from a year-long deployment in Afghanistan. Service members reported more symptoms during a conversation with a virtual human interviewer than on the official PDHA. They also reported more to a virtual human interviewer than on an anonymized PDHA. A second, larger sample of active-duty and former service members found a similar effect that approached statistical significance. Because respondents in both studies shared more with virtual human interviewers than an anonymized PDHA -even though both conditions control for stigma and ramifications for service members’ military records- virtual human interviewers that build rapport may provide a superior option to encourage reporting.",2017.0,71.0,164.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2017.00051/pdf', 'status': None}","{'volume': '4', 'pages': '51', 'name': 'Frontiers Robotics AI'}","{'bibtex': '@Article{Lucas2017ReportingMH,\n author = {Gale M. Lucas and A. Rizzo and J. Gratch and Stefan Scherer and Giota Stratou and Jill Boberg and Louis-Philippe Morency},\n journal = {Frontiers Robotics AI},\n pages = {51},\n title = {Reporting Mental Health Symptoms: Breaking Down Barriers to Care with Virtual Human Interviewers},\n volume = {4},\n year = {2017}\n}\n'}","[{'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '6349590', 'name': 'Jill Boberg'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
1850,9e7c6355f3a50cf5aa3c2a1e4d5db56d289b14a4,Beyond mind-reading: multi-voxel pattern analysis of fMRI data,,2006.0,57.0,2225.0,False,,"{'volume': '10', 'pages': '424-430', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Norman2006BeyondMM,\n author = {K. Norman and Sean M. Polyn and Greg Detre and J. Haxby},\n journal = {Trends in Cognitive Sciences},\n pages = {424-430},\n title = {Beyond mind-reading: multi-voxel pattern analysis of fMRI data},\n volume = {10},\n year = {2006}\n}\n'}","[{'authorId': '1780319', 'name': 'K. Norman'}, {'authorId': '2872825', 'name': 'Sean M. Polyn'}, {'authorId': '2096648', 'name': 'Greg Detre'}, {'authorId': '2327323', 'name': 'J. Haxby'}]"
1851,9e865ddf1ddccc49b39c795c09aa02a0392dab2d,Pupil adaptation corresponds to quantitative measures of autism traits in children,,2017.0,56.0,27.0,True,"{'url': 'https://www.nature.com/articles/s41598-017-06829-1.pdf', 'status': None}","{'volume': '7', 'name': 'Scientific Reports'}","{'bibtex': '@Article{DiCriscio2017PupilAC,\n author = {A. S. DiCriscio and V. Troiani},\n journal = {Scientific Reports},\n title = {Pupil adaptation corresponds to quantitative measures of autism traits in children},\n volume = {7},\n year = {2017}\n}\n'}","[{'authorId': '9059336', 'name': 'A. S. DiCriscio'}, {'authorId': '2562268', 'name': 'V. Troiani'}]"
1852,9ea647f3a27ccbfab3006228ab54dfe8122745ac,Empathy in Social Agents,"Empathy is seen as the capacity to perceive, understand and experience others' emotions. This notion is often considered as one of the major elements in social interactions between humans. As such, when creating social agents, that are believable and able to engage users in social interactions, empathy needs to be addressed. Indeed, for the past few years, many researchers have been looking at this problem, not only in trying to find ways to perceive the user's emotions, but also to adapt to them, and react in an empathic way. This paper provides a small overview of this new challenging area of research, by analyzing empathy in the social relations established between humans and social agents, and providing a concrete model for the creation of empathic social agents.",2011.0,12.0,35.0,True,"{'url': 'https://ijvr.eu/article/download/2794/8852', 'status': None}","{'volume': '10', 'pages': '1-4', 'name': 'Int. J. Virtual Real.'}","{'bibtex': '@Article{Paiva2011EmpathyIS,\n author = {Ana Paiva},\n journal = {Int. J. Virtual Real.},\n pages = {1-4},\n title = {Empathy in Social Agents},\n volume = {10},\n year = {2011}\n}\n'}","[{'authorId': '145136631', 'name': 'Ana Paiva'}]"
1853,9ea80fd6ce6ad3e12e43338802d26443ce126f9f,"The emulation theory of representation: Motor control, imagery, and perception","The emulation theory of representation is developed and explored as a framework that can revealingly synthesize a wide variety of representational functions of the brain. The framework is based on constructs from control theory (forward models) and signal processing (Kalman filters). The idea is that in addition to simply engaging with the body and environment, the brain constructs neural circuits that act as models of the body and environment. During overt sensorimotor engagement, these models are driven by efference copies in parallel with the body and environment, in order to provide expectations of the sensory feedback, and to enhance and process sensory information. These models can also be run off-line in order to produce imagery, estimate outcomes of different actions, and evaluate and develop motor plans. The framework is initially developed within the context of motor control, where it has been shown that inner models running in parallel with the body can reduce the effects of feedback delay problems. The same mechanisms can account for motor imagery as the off-line driving of the emulator via efference copies. The framework is extended to account for visual imagery as the off-line driving of an emulator of the motor-visual loop. I also show how such systems can provide for amodal spatial imagery. Perception, including visual perception, results from such models being used to form expectations of, and to interpret, sensory input. I close by briefly outlining other cognitive functions that might also be synthesized within this framework, including reasoning, theory of mind phenomena, and language.",2004.0,337.0,1176.0,True,"{'url': 'http://www.cs.ucsd.edu/classes/fa07/cse87-b/papers/grush-em.pdf', 'status': None}","{'volume': '27', 'pages': '377 - 396', 'name': 'Behavioral and Brain Sciences'}","{'bibtex': '@Article{Grush2004TheET,\n author = {R. Grush},\n journal = {Behavioral and Brain Sciences},\n pages = {377 - 396},\n title = {The emulation theory of representation: Motor control, imagery, and perception},\n volume = {27},\n year = {2004}\n}\n'}","[{'authorId': '3107833', 'name': 'R. Grush'}]"
1854,9eb485c8eac410c6a9a704ee2f7d98ab95cb07ce,Using Linguistic Cues for the Automatic Recognition of Personality in Conversation and Text,"It is well known that utterances convey a great deal of information about the speaker in addition to their semantic content. One such type of information consists of cues to the speaker's personality traits, the most fundamental dimension of variation between humans. Recent work explores the automatic detection of other types of pragmatic variation in text and conversation, such as emotion, deception, speaker charisma, dominance, point of view, subjectivity, opinion and sentiment. Personality affects these other aspects of linguistic production, and thus personality recognition may be useful for these tasks, in addition to many other potential applications. However, to date, there is little work on the automatic recognition of personality traits. This article reports experimental results for recognition of all Big Five personality traits, in both conversation and text, utilising both self and observer ratings of personality. While other work reports classification results, we experiment with classification, regression and ranking models. For each model, we analyse the effect of different feature sets on accuracy. Results show that for some traits, any type of statistical model performs significantly better than the baseline, but ranking models perform best overall. We also present an experiment suggesting that ranking models are more accurate than multi-class classifiers for modelling personality. In addition, recognition models trained on observed personality perform better than models trained using self-reports, and the optimal feature set depends on the personality trait. A qualitative analysis of the learned models confirms previous findings linking language and personality, while revealing many new linguistic markers.",2007.0,94.0,894.0,True,"{'url': 'https://jair.org/index.php/jair/article/download/10520/25197', 'status': None}","{'volume': '30', 'pages': '457-500', 'name': 'J. Artif. Intell. Res.'}","{'bibtex': '@Article{Mairesse2007UsingLC,\n author = {François Mairesse and M. Walker and M. Mehl and Roger K. Moore},\n journal = {J. Artif. Intell. Res.},\n pages = {457-500},\n title = {Using Linguistic Cues for the Automatic Recognition of Personality in Conversation and Text},\n volume = {30},\n year = {2007}\n}\n'}","[{'authorId': '1769183', 'name': 'François Mairesse'}, {'authorId': '2234088162', 'name': 'M. Walker'}, {'authorId': '1760412', 'name': 'M. Mehl'}, {'authorId': '145914568', 'name': 'Roger K. Moore'}]"
1855,9ed50b34b8264750d5377f83cbe271a5bb335bc1,Design Evaluation of a Simulation for Teacher Education,"Recent calls to improve the quality of education in schools have drawn attention to the importance of teachers’ preparation for work in classroom settings. Although the practicum has long been the traditional means for pre-service teachers to learn and practice classroom teaching, it does not always offer student teachers the time, safe practice experiences, repetition, or extensive feedback needed for them to gain adequate knowledge, skills, and confidence. Well-designed simulations can augment the practicum and address these gaps. This study evaluated the design of simSchool (v.1), an online simulation for pre-service teachers, using student teachers’ ratings of selected factors, including realism, appropriateness of content and curriculum, appropriateness for target users, and user interaction. Based on these ratings, the study identified strengths and weaknesses, and suggested improvements for the software. Participant ratings varied considerably but indicated that certain aspects of the simulation, such as its educational value, classroom challenges, and simulated student characteristics, were moderately well received. However, user interface navigation and the range and realism of simulated teacher–student interactions should be improved.",2015.0,57.0,42.0,True,,"{'volume': '5', 'name': 'SAGE Open'}","{'bibtex': '@Article{Badiee2015DesignEO,\n author = {Farnaz Badiee and D. Kaufman},\n journal = {SAGE Open},\n title = {Design Evaluation of a Simulation for Teacher Education},\n volume = {5},\n year = {2015}\n}\n'}","[{'authorId': '112854120', 'name': 'Farnaz Badiee'}, {'authorId': '47330994', 'name': 'D. Kaufman'}]"
1856,9ed64e27f458a361b0d2adbbac3b1c3e7711d79c,The Role of Velocity in Affect Discrimination,"The Role of Velocity in Affect Discrimination Helena M. Paterson (helena@psy.gla.ac.uk) Glasgow, G12 8QB Frank E. Pollick (frank@psy.gla.ac.uk) Department of Psychology, 58 Hillhead Street, Glasgow, G12 8QB Anthony J. Sanford (tony@psy.gla.ac.uk) Department of Psychology, 58 Hillhead Street, Glasgow, G12 8QB Abstract Two experiments are described that examine the role of speed in the categorisation of affective biological motion displays. For the first experiment movements were recorded for 10 affects and the point-light animations of them were shown to participants in a recognition task. The resultant confusion matrices were analysed using the ALSCAL multi-dimensional scaling procedure and produced a 2-dimensional psychological space. The psychological space for discrimination was similar to that from recent models of experienced affect in that the first dimension corresponded to the activation dimension from these models. A strong correlation between the movement speed and the activation dimension confirmed the finding. From these results it would appear that the mapping between stimulus properties and representation of activation in affect is a fairly direct one. For the second experiment more sad, angry and neutral movements were collected. New movements of different duration, but identical spatial displacement were made using an interpolation algorithm. Observers viewed the movements as point light displays and heir task was to rate intensity of affect. Results from this experiment indicate speed plays a major role in modulating the intensity of activation in perceived affect. Introduction Humans can easily tell each other apart and interpret subtle differences in behaviour that communicates intentions, identity and emotions easily. Cues from facial features are used for much of this recognition, however, highly impoverished stimuli - such as point- light displays - convey sufficient information for the recognition of such person properties (Barclay, Cutting & Kozlowski, 1978, Cutting & Kozlowski, 1977; Dittrich, Troscianko, Lea & Morgan, 1986; Hill & Pollick, 2000; Kozlowski & Cutting, 1978; Mather & Murdoch, 1994; Runeson & Frykholm, 1981; Runeson & Frykholm, 1983; Walk & Homan, 1984). The cues that convey this information in biological motion are of primary interest to us and using point light displays of human arm movements, we have concentrated on the recognition of emotion from biological motion. In exploring the way in which humans recognise affect, it is possible not only to look at the accuracy with which an affect is recognised, but also at the structure of the representation of affect. A number of models for the structure of experienced affect have been suggested that resemble each other in a number of factors (Russell, 1980; Watson and Tellegen, 1985; Thayer, 1989, Larsen and Diener; 1992; Feldman, Barrett and Russell, 1999). The similarities between these models are that the structure of affect is a two- dimensional and continuous structure. This structure is referred to as a circumplex model (Feldman, Barrett and Russell, 1999). The two dimensions of the circumplex models are bipolar and independent. One dimension represents valence (for instance hedonic tone, pleasant – unpleasant) and the other, arousal or activation (arousal – sleep/ activated – deactivated). The models are also continuous, with affects falling on a circle, centred on the origin of the psychological space defined by the two dimensions. Although these models were established as representing one’s own experience of affect, there is recent evident to suggest that experience and perception interact when observing another person’s actions (Decety and Grezes, 1999; Rizzolatti, Fadiga, Gallese and Foggassi, 1996). Additionally biological motion relies on both specialised bottom-up processes of motion detection (Mather, Radford and West, 1992; Neri, Morrone and Burr, 1998) and interactions between these and top-down processes (Shiffrar and Freyd, 1990, 1993; Thornton, Pinto and Shiffrar, 1998). In the case of affect perception such a top-down process may well originate from the influence of an internal structure of affect. It seems reasonable, therefore, to further explore the possible relationship between perception and structure of affect. There is also, currently, little research that concentrates specifically at the recognition of emotion",2001.0,25.0,67.0,False,,"{'volume': '23', 'name': ''}","{'bibtex': '@Inproceedings{Paterson2001TheRO,\n author = {H. Paterson and F. Pollick and A. Sanford},\n title = {The Role of Velocity in Affect Discrimination},\n volume = {23},\n year = {2001}\n}\n'}","[{'authorId': '47877778', 'name': 'H. Paterson'}, {'authorId': '2819854', 'name': 'F. Pollick'}, {'authorId': '2213526', 'name': 'A. Sanford'}]"
1857,9edf74cfa5d65e198832242d7362727fda68f34d,American Association of State Highway and Transportation Officials. Highway Drainage Guidelines American Association of State Highway and Transportation Officials. LRFD Bridge Design Specifications,"The annual meeting of the AASHTO Subcommittee on Design, Task Force on Geometric Design was held in Charleston, South Carolina during the period July 13 through July 16, 2003. The purpose of the meeting was to review several documents undergoing revision, review the proposed revisions to the superelevation discussion in the Green Book, consider future research, and other administrative matters of concern to the Task Force Membership.",2000.0,3.0,2361.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Little2000AmericanAO,\n author = {Bryan E. Little and T. A. Mize and R. J. Bailey},\n title = {American Association of State Highway and Transportation Officials. Highway Drainage Guidelines American Association of State Highway and Transportation Officials. LRFD Bridge Design Specifications},\n year = {2000}\n}\n'}","[{'authorId': '94698724', 'name': 'Bryan E. Little'}, {'authorId': '94945302', 'name': 'T. A. Mize'}, {'authorId': '36691104', 'name': 'R. J. Bailey'}]"
1858,9ef698ea3e28aea9d65642e662f864053553a68d,"APML, a Markup Language for Believable Behavior Generation",,2004.0,31.0,283.0,False,,{'pages': '65-86'},"{'bibtex': '@Inproceedings{Carolis2004APMLAM,\n author = {B. D. Carolis and C. Pelachaud and I. Poggi and Mark Steedman},\n pages = {65-86},\n title = {APML, a Markup Language for Believable Behavior Generation},\n year = {2004}\n}\n'}","[{'authorId': '1739256', 'name': 'B. D. Carolis'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1802126', 'name': 'I. Poggi'}, {'authorId': '145332819', 'name': 'Mark Steedman'}]"
1860,9f367a7ea95814d827bf4859129868c8e4a5e1c1,Retail salespeople's mimicry of customers: Effects on consumer behavior,,2011.0,52.0,74.0,False,,"{'volume': '18', 'pages': '381-388', 'name': 'Journal of Retailing and Consumer Services'}","{'bibtex': ""@Article{Jacob2011RetailSM,\n author = {Céline Jacob and N. Guéguen and Angélique Martin and Gaëlle Boulbry},\n journal = {Journal of Retailing and Consumer Services},\n pages = {381-388},\n title = {Retail salespeople's mimicry of customers: Effects on consumer behavior},\n volume = {18},\n year = {2011}\n}\n""}","[{'authorId': '10125477', 'name': 'Céline Jacob'}, {'authorId': '1892904', 'name': 'N. Guéguen'}, {'authorId': '4889270', 'name': 'Angélique Martin'}, {'authorId': '2084060441', 'name': 'Gaëlle Boulbry'}]"
1861,9f3ce188893ce94f58e5a0eda3722bad404e7caa,Introduction of the need model for humanoid robots to generate active behavior,"The authors have been developing human-like head robots in order to develop new head mechanisms and functions for a humanoid robot that has the ability to communicate naturally with a human by expressing human-like emotion. We believe that in the future, it will be necessary for personal robots to generate active behavior to interact bilaterally between human and robot. Therefore, we developed an emotion expression humanoid robot WE-4R (Waseda eye no.4 refined) in 2003. The need model consisting of the ""appetite,"" the ""need for security"" and the ""need for exploration"" was introduced to the mental model for humanoid robots. We also defined the ""need matrix"" and introduced the ""equations of need"" to describe the robot needs. Robots with the need model can generate and express active behavior according to their need. This paper describes the need model that is implemented in the emotion expression humanoid robot WE-4R.",2003.0,10.0,35.0,False,,"{'volume': '2', 'pages': '1400-1406 vol.2', 'name': 'Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453)'}","{'bibtex': '@Article{Miwa2003IntroductionOT,\n author = {H. Miwa and K. Itoh and D. Ito and H. Takanobu and A. Takanishi},\n journal = {Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453)},\n pages = {1400-1406 vol.2},\n title = {Introduction of the need model for humanoid robots to generate active behavior},\n volume = {2},\n year = {2003}\n}\n'}","[{'authorId': '2065285579', 'name': 'H. Miwa'}, {'authorId': '46677342', 'name': 'K. Itoh'}, {'authorId': '2057391878', 'name': 'D. Ito'}, {'authorId': '1678499', 'name': 'H. Takanobu'}, {'authorId': '1737432', 'name': 'A. Takanishi'}]"
1862,9f5ac049fe4aa8274f76a9ee1dbf9d135158e0c4,Expression of Emotion as Part of the Work Role,"Research in organizational behavior focuses on expressed and felt emotions as indicators of employee health and satisfaction. In contrast, less conceptual and empirical work addresses the display of feelings as part of the job. This paper proposes a conceptual framework to guide theory development and research about the causes, qualities, and consequences of emotions that are expressed to fulfill role expectations.",1987.0,40.0,1456.0,False,,"{'volume': '12', 'pages': '23-37', 'name': 'Academy of Management Review'}","{'bibtex': '@Article{Rafaeli1987ExpressionOE,\n author = {A. Rafaeli and R. I. Sutton},\n journal = {Academy of Management Review},\n pages = {23-37},\n title = {Expression of Emotion as Part of the Work Role},\n volume = {12},\n year = {1987}\n}\n'}","[{'authorId': '2539868', 'name': 'A. Rafaeli'}, {'authorId': '3169834', 'name': 'R. I. Sutton'}]"
1863,9f86366feecbcfdf6c5be165fcf38c679164cc89,Machine Learning and the Profession of Medicine.,"This Viewpoint discusses the opportunities and ethical implications of using machine learning technologies, which can rapidly collect and learn from large amounts of personal data, to provide individalized patient care.",2016.0,6.0,304.0,False,,"{'volume': '315 6', 'pages': '\n          551-2\n        ', 'name': 'JAMA'}","{'bibtex': '@Article{Darcy2016MachineLA,\n author = {Alison M Darcy and A. Louie and L. Roberts},\n journal = {JAMA},\n pages = {\n          551-2\n        },\n title = {Machine Learning and the Profession of Medicine.},\n volume = {315 6},\n year = {2016}\n}\n'}","[{'authorId': '6120000', 'name': 'Alison M Darcy'}, {'authorId': '7172935', 'name': 'A. Louie'}, {'authorId': '34934943', 'name': 'L. Roberts'}]"
1864,9f88ce3ee9a8b1aaebbe51306602ba0895b82979,"The State-Trait Anxiety Inventory, Trait version: structure and content re-examined.",,1998.0,20.0,615.0,True,,"{'volume': '36 7-8', 'pages': '\n          777-88\n        ', 'name': 'Behaviour research and therapy'}","{'bibtex': '@Article{Bieling1998TheSA,\n author = {Peter J. Bieling and Martin M. Antony and Martin M. Antony and R. Swinson},\n journal = {Behaviour research and therapy},\n pages = {\n          777-88\n        },\n title = {The State-Trait Anxiety Inventory, Trait version: structure and content re-examined.},\n volume = {36 7-8},\n year = {1998}\n}\n'}","[{'authorId': '2239042739', 'name': 'Peter J. Bieling'}, {'authorId': '2239042892', 'name': 'Martin M. Antony'}, {'authorId': '2239042892', 'name': 'Martin M. Antony'}, {'authorId': '6796306', 'name': 'R. Swinson'}]"
1865,9f9bd3cfcf5850d738015eb60241456eeacb2919,Is it time to revise the diagnostic criteria for apathy in brain disorders? The 2018 international consensus group,,2018.0,40.0,188.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5A3A2F39C4A322DCCAD6B044B4AF5CB1/S0924933800008774a.pdf/div-class-title-is-it-time-to-revise-the-diagnostic-criteria-for-apathy-in-brain-disorders-the-2018-international-consensus-group-div.pdf', 'status': None}","{'volume': '54', 'pages': '71 - 76', 'name': 'European Psychiatry'}","{'bibtex': '@Article{Robert2018IsIT,\n author = {P. Robert and K. Lanctôt and L. Agüera-Ortiz and P. Aalten and François Brémond and M. Defrancesco and C. Hanon and R. David and B. Dubois and K. Dujardin and M. Husain and A. König and R. Levy and V. Mantua and D. Meulien and Daniel W. Miller and H. Moebius and J. Rasmussen and G. Robert and M. Ruthirakuhan and F. Stella and J. Yesavage and Radia Zeghari and V. Manera},\n journal = {European Psychiatry},\n pages = {71 - 76},\n title = {Is it time to revise the diagnostic criteria for apathy in brain disorders? The 2018 international consensus group},\n volume = {54},\n year = {2018}\n}\n'}","[{'authorId': '153196760', 'name': 'P. Robert'}, {'authorId': '4797664', 'name': 'K. Lanctôt'}, {'authorId': '114185955', 'name': 'L. Agüera-Ortiz'}, {'authorId': '3160020', 'name': 'P. Aalten'}, {'authorId': '2166562522', 'name': 'François Brémond'}, {'authorId': '4238269', 'name': 'M. Defrancesco'}, {'authorId': '2080994290', 'name': 'C. Hanon'}, {'authorId': '145768419', 'name': 'R. David'}, {'authorId': '2114244374', 'name': 'B. Dubois'}, {'authorId': '21834198', 'name': 'K. Dujardin'}, {'authorId': '2099406843', 'name': 'M. Husain'}, {'authorId': '144632221', 'name': 'A. König'}, {'authorId': '145293730', 'name': 'R. Levy'}, {'authorId': '5634092', 'name': 'V. Mantua'}, {'authorId': '7912759', 'name': 'D. Meulien'}, {'authorId': '2115908421', 'name': 'Daniel W. Miller'}, {'authorId': '117054199', 'name': 'H. Moebius'}, {'authorId': '5802006', 'name': 'J. Rasmussen'}, {'authorId': '49561639', 'name': 'G. Robert'}, {'authorId': '7747482', 'name': 'M. Ruthirakuhan'}, {'authorId': '143837246', 'name': 'F. Stella'}, {'authorId': '2235415', 'name': 'J. Yesavage'}, {'authorId': '51186373', 'name': 'Radia Zeghari'}, {'authorId': '4192721', 'name': 'V. Manera'}]"
1866,9fbffcff3fb9b90e092fabd9bf9d6786f3d22f23,Processing of observed pupil size modulates perception of sadness and predicts empathy.,"Facial autonomic responses may contribute to emotional communication and reveal individual affective style. In this study, the authors examined how observed pupillary size modulates processing of facial expression, extending the finding that incidentally perceived pupils influence ratings of sadness but not those of happy, angry, or neutral facial expressions. Healthy subjects rated the valence and arousal of photographs depicting facial muscular expressions of sadness, surprise, fear, and disgust. Pupil sizes within the stimuli were experimentally manipulated. Subjects themselves were scored with an empathy questionnaire. Diminishing pupil size linearly enhanced intensity and valence judgments of sad expressions (but not fear, surprise, or disgust). At debriefing, subjects were unaware of differences in pupil size across stimuli. These observations complement an earlier study showing that pupil size directly influences processing of sadness but not other basic emotional facial expressions. Furthermore, across subjects, the degree to which pupil size influenced sadness processing correlated with individual differences in empathy score. Together, these data demonstrate a central role of sadness processing in empathetic emotion and highlight the salience of implicit autonomic signals in affective communication.",2007.0,37.0,85.0,False,,"{'volume': '7 4', 'pages': '\n          724-9\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Harrison2007ProcessingOO,\n author = {Neil A Harrison and C. E. Wilson and Hugo D Critchley and A. Harrison},\n journal = {Emotion},\n pages = {\n          724-9\n        },\n title = {Processing of observed pupil size modulates perception of sadness and predicts empathy.},\n volume = {7 4},\n year = {2007}\n}\n'}","[{'authorId': '2247127725', 'name': 'Neil A Harrison'}, {'authorId': '2249717128', 'name': 'C. E. Wilson'}, {'authorId': '2247122717', 'name': 'Hugo D Critchley'}, {'authorId': '2247128150', 'name': 'A. Harrison'}]"
1867,9fd351c71b8dabd09f131d9ee01807674a91c381,The Motivational and Metacognitive Control in CLARION,"This article presents an overview of a relatively recent cognitive architecture, and its internal control structures, that is, its motivational and metacognitive mechanisms. The chapter starts with a look at some general ideas underlying this cognitive architecture and the relevance of these ideas to cognitive modeling of agents. It then presents a sketch of some details of the architecture and their uses in cognitive modeling of specific tasks.",2005.0,38.0,25.0,False,,,"{'bibtex': '@Inproceedings{Sun2005TheMA,\n author = {R. Sun},\n title = {The Motivational and Metacognitive Control in CLARION},\n year = {2005}\n}\n'}","[{'authorId': '145966408', 'name': 'R. Sun'}]"
1868,9fd65c80408595cdcd347041d25f7dd36210f013,A new approach to architecture of human-computer interaction,"Human Computer Interaction is a discipline concerned with the design, evaluation and implementation of interactive computing systems for human use and with the study of the major phenomena surrounding them. There is an extensive literature concerning the human computer interaction. This paper reviews and classifies the existing architectures. Moreover, the paper proposes some new approaches to the architectures of human computer interaction.",2017.0,19.0,5.0,False,,"{'pages': '1-4', 'name': '2017 IEEE 4th International Conference on Smart Instrumentation, Measurement and Application (ICSIMA)'}","{'bibtex': '@Article{Ghanbari2017ANA,\n author = {Amir Mohammad Ghanbari and Shamsollah Ghanbari and Y. Norouzi},\n journal = {2017 IEEE 4th International Conference on Smart Instrumentation, Measurement and Application (ICSIMA)},\n pages = {1-4},\n title = {A new approach to architecture of human-computer interaction},\n year = {2017}\n}\n'}","[{'authorId': '2068442025', 'name': 'Amir Mohammad Ghanbari'}, {'authorId': '2617969', 'name': 'Shamsollah Ghanbari'}, {'authorId': '2108184', 'name': 'Y. Norouzi'}]"
1869,9fdc872bcf20c3515aff1130fe574f1a132a9e24,Intelligent virtual humans with autonomy and personality: State-of-the-art,,2007.0,189.0,84.0,False,,"{'volume': '1', 'pages': '3-15', 'name': 'Intell. Decis. Technol.'}","{'bibtex': '@Article{Kasap2007IntelligentVH,\n author = {Zerrin Kasap and N. Magnenat-Thalmann},\n journal = {Intell. Decis. Technol.},\n pages = {3-15},\n title = {Intelligent virtual humans with autonomy and personality: State-of-the-art},\n volume = {1},\n year = {2007}\n}\n'}","[{'authorId': '2671891', 'name': 'Zerrin Kasap'}, {'authorId': '1387241200', 'name': 'N. Magnenat-Thalmann'}]"
1872,9fdde358066f0e9ad7c9c6872e06a7cf6cd3b654,Correcting psychophysiological measures for individual differences in range.,,1966.0,2.0,253.0,False,,"{'volume': '66 6', 'pages': '\n          481-4\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Dt1966CorrectingPM,\n author = {Lykken Dt and Richard Rose and B. Luther and M. Maley},\n journal = {Psychological bulletin},\n pages = {\n          481-4\n        },\n title = {Correcting psychophysiological measures for individual differences in range.},\n volume = {66 6},\n year = {1966}\n}\n'}","[{'authorId': '117992260', 'name': 'Lykken Dt'}, {'authorId': '2227993146', 'name': 'Richard Rose'}, {'authorId': '101868644', 'name': 'B. Luther'}, {'authorId': '143935798', 'name': 'M. Maley'}]"
1873,a0234d30dfd26a8c0c75fc631c291df6f82a1400,Designing for Workplace Reflection: A Chat and Voice-Based Conversational Agent,"Conversational agents stand to play an important role in supporting behavior change and well-being in many domains. With users able to interact with conversational agents through both text and voice, understanding how designing for these channels supports behavior change is important. To begin answering this question, we designed a conversational agent for the workplace that supports workers' activity journaling and self-learning through reflection. Our agent, named Robota, combines chat-based communication as a Slack Bot and voice interaction through a personal device using a custom Amazon Alexa Skill. Through a 3-week controlled deployment, we examine how voice-based and chat-based interaction affect workers' reflection and support self-learning. We demonstrate that, while many current technical limitations exist, adding dedicated mobile voice interaction separate from the already busy chat modality may further enable users to step back and reflect on their work. We conclude with discussion of the implications of our findings to design of workplace self-tracking systems specifically and to behavior-change systems in general.",2018.0,80.0,76.0,False,,{'name': 'Proceedings of the 2018 Designing Interactive Systems Conference'},"{'bibtex': '@Article{Kocielnik2018DesigningFW,\n author = {Rafal Kocielnik and Daniel Avrahami and Jennifer Marlow and Di Lu and Gary Hsieh},\n journal = {Proceedings of the 2018 Designing Interactive Systems Conference},\n title = {Designing for Workplace Reflection: A Chat and Voice-Based Conversational Agent},\n year = {2018}\n}\n'}","[{'authorId': '3299344', 'name': 'Rafal Kocielnik'}, {'authorId': '2667384', 'name': 'Daniel Avrahami'}, {'authorId': '144841404', 'name': 'Jennifer Marlow'}, {'authorId': '2087234532', 'name': 'Di Lu'}, {'authorId': '1786841', 'name': 'Gary Hsieh'}]"
1874,a03242b258194bff2e60200ec90608257f2ccc24,Believable Social and Emotional Agents.,"Abstract : One of the key steps in creating quality interactive drama is the ability to create quality interactive characters (or believable agents). Two important aspects of such characters will be that they appear emotional and that they can engage in social interactions. My basic approach to these problems has been to use a broad agent architecture and minimal amounts of modeling of other agent in the environment. This approach is based on an understanding of the artistic nature of the problem. To enable agent-builders (artists) to create emotional agents, I provide a general framework for building emotional agents, default emotion-processing rules, and discussion about how to create quality, emotional characters. My framework gets a lot of its power from being part of a broad agent architecture. The concept is simple: the agent will be emotionally richer if there are more things to have emotions about and more ways to express them. This reliance on breadth has also meant that I have been able to create simple emotion models that rely on perception and motivation instead of deep modeling of other agents and complex cognitive processing. To enable agent builders to create social behaviors for believable agents, I have designed a methodology that provides heuristics for incorporating personality into social behaviors and suggests how to model other agents in the environment. I propose an approach to modeling other agents that calls for limiting the amount of modeling of other agents to that which is sufficient to create the desired behavior. Using this technique, I have been able to build robust social behaviors that use surprisingly little representation. I have used this methodology to build a number of social behaviors, like negotiation and making friends. I have built three simulations containing seven agents to drive and test this work.",1996.0,129.0,488.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bates1996BelievableSA,\n author = {J. Bates and Jaime Carbonell and Reid G. Simmons and A. Sloman and W. Scott and Neal Reilly},\n title = {Believable Social and Emotional Agents.},\n year = {1996}\n}\n'}","[{'authorId': '145207410', 'name': 'J. Bates'}, {'authorId': '2228592956', 'name': 'Jaime Carbonell'}, {'authorId': '2054613750', 'name': 'Reid G. Simmons'}, {'authorId': '145788442', 'name': 'A. Sloman'}, {'authorId': '2053266146', 'name': 'W. Scott'}, {'authorId': '2229738965', 'name': 'Neal Reilly'}]"
1877,a0650855634a156db81a01dcdceff931e9f1ac04,The Soar Cognitive Architecture,"In development for thirty years, Soar is a general cognitive architecture that integrates knowledge-intensive reasoning, reactive execution, hierarchical reasoning, planning, and learning from experience, with the goal of creating a general computational system that has the same cognitive abilities as humans. In contrast, most AI systems are designed to solve only one type of problem, such as playing chess, searching the Internet, or scheduling aircraft departures. Soar is both a software system for agent development and a theory of what computational structures are necessary to support human-level agents. Over the years, both software system and theory have evolved. This book offers the definitive presentation of Soar from theoretical and practical perspectives, providing comprehensive descriptions of fundamental aspects and new components. The current version of Soar features major extensions, adding reinforcement learning, semantic memory, episodic memory, mental imagery, and an appraisal-based model of emotion. This book describes details of Soar's component memories and processes and offers demonstrations of individual components, components working in combination, and real-world applications. Beyond these functional considerations, the book also proposes requirements for general cognitive architectures and explicitly evaluates how well Soar meets those requirements.",2012.0,27.0,896.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Laird2012TheSC,\n author = {J. Laird},\n title = {The Soar Cognitive Architecture},\n year = {2012}\n}\n'}","[{'authorId': '1715438', 'name': 'J. Laird'}]"
1879,a0b7b6d5c582cf75cd5ff0b7caf456468c452d31,Interactive engagement with embodied agents: an empirically validated framework,"This paper presents an empirically tested theoretical framework to explain user engagement and end‐user satisfaction with interactive agents. Such a framework is not only important from a scientific point of view; application designers may find a set of dos and don'ts that help them create more satisfying embodied agents in different task domains and social settings. From a multidisciplinary perspective, we have conducted a series of experiments to verify underlying mechanisms in the processes of interacting and engaging with embodied agents in various task domains. Our results show that the most commonly held views are not always tenable; sometimes other factors provide better explanations for liking an embodied agent or end‐user satisfaction. For example, it is not realism but rather affordances and ethics that are key for understanding user responses, and a beautiful design is not always the most preferable. From our results, guidelines for designers and future research are reflected upon. Copyright © 2009 John Wiley & Sons, Ltd.",2009.0,25.0,31.0,False,,"{'volume': '20', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Vugt2009InteractiveEW,\n author = {H. C. V. Vugt and J. Hoorn and E. Konijn},\n journal = {Computer Animation and Virtual Worlds},\n title = {Interactive engagement with embodied agents: an empirically validated framework},\n volume = {20},\n year = {2009}\n}\n'}","[{'authorId': '1823909', 'name': 'H. C. V. Vugt'}, {'authorId': '71825175', 'name': 'J. Hoorn'}, {'authorId': '3132010', 'name': 'E. Konijn'}]"
1881,a0c356da5a913c2290dac051b28a420ede632868,Multimodal Sentiment Analysis: Addressing Key Issues and Setting Up the Baselines,"We compile baselines, along with dataset split, for multimodal sentiment analysis. In this paper, we explore three different deep-learning-based architectures for multimodal sentiment classification, each improving upon the previous. Further, we evaluate these architectures with multiple datasets with fixed train/test partition. We also discuss some major issues, frequently ignored in multimodal sentiment analysis research, e.g., the role of speaker-exclusive models, the importance of different modalities, and generalizability. This framework illustrates the different facets of analysis to be considered while performing multimodal sentiment analysis and, hence, serves as a new benchmark for future research in this emerging field.",2018.0,25.0,147.0,True,"{'url': 'https://dr.ntu.edu.sg/bitstream/10356/143239/2/Multimodal%20Sentiment%20Analysis_Addressing%20Key%20Issues%20and%20Setting%20Up%20the%20Baselines.pdf', 'status': None}","{'volume': '33', 'pages': '17-25', 'name': 'IEEE Intelligent Systems'}","{'bibtex': '@Article{Poria2018MultimodalSA,\n author = {Soujanya Poria and Navonil Majumder and Devamanyu Hazarika and E. Cambria and A. Hussain and Alexander Gelbukh},\n journal = {IEEE Intelligent Systems},\n pages = {17-25},\n title = {Multimodal Sentiment Analysis: Addressing Key Issues and Setting Up the Baselines},\n volume = {33},\n year = {2018}\n}\n'}","[{'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '145125161', 'name': 'A. Hussain'}, {'authorId': '1747784', 'name': 'Alexander Gelbukh'}]"
1883,a0cc94417d5cb36051ac4c0b35c7cae6340f44fc,Application of Virtual Travel for Alzheimer's Disease,"Negative emotions such as anxiety, frustration, or apathy can have an impact on the brain capability in terms of memory and cognitive functions. This is particularly visible in Alzheimer’s disease where the participants can have a deterioration of their brain connections which are often the cause of the disorders detected in Alzheimer's participants. It seems important to reduce these symptoms to allow better access to memory and cognitive abilities. Immersion in Virtual Reality is a means of providing the participant with a sense of presence in an environment that isolates them from external factors that can induce negative emotions. The virtual travel is a method that can mobilize the attention of the subject and revive their interest and curiosity. We present here, an experiment in which a participant is immersed in a virtual train using a virtual headset and EEG device to measure the brain signals. To measure the impact of this train on the memory and cognitive functions, some cognitive tasks have been included before and after the travel. Experiments have been done on participants with mild cognitive disorder. Preliminary results show an increase of memory functions and in certain cases of cognitive functions, while negative emotions are reduced.",2020.0,35.0,6.0,False,,{'pages': '52-60'},"{'bibtex': ""@Inproceedings{Abdessalem2020ApplicationOV,\n author = {H. Abdessalem and A. Byrns and M. Cuesta and V. Manera and P. Robert and M. Bruneau and S. Belleville and C. Frasson},\n pages = {52-60},\n title = {Application of Virtual Travel for Alzheimer's Disease},\n year = {2020}\n}\n""}","[{'authorId': '28987363', 'name': 'H. Abdessalem'}, {'authorId': '68990793', 'name': 'A. Byrns'}, {'authorId': '47258254', 'name': 'M. Cuesta'}, {'authorId': '4192721', 'name': 'V. Manera'}, {'authorId': '134599701', 'name': 'P. Robert'}, {'authorId': '34277926', 'name': 'M. Bruneau'}, {'authorId': '145580293', 'name': 'S. Belleville'}, {'authorId': '1788058', 'name': 'C. Frasson'}]"
1884,a0d63a2f8181ec66e22df7f9d270d0bb2d0dc263,Cumplimiento terapéutico: ¿qué conocemos de España?,,2001.0,60.0,49.0,True,,"{'volume': '27', 'pages': '559-568', 'name': 'Atencion Primaria'}","{'bibtex': '@Article{García2001CumplimientoT,\n author = {A. I. R. García},\n journal = {Atencion Primaria},\n pages = {559-568},\n title = {Cumplimiento terapéutico: ¿qué conocemos de España?},\n volume = {27},\n year = {2001}\n}\n'}","[{'authorId': '2107575170', 'name': 'A. I. R. García'}]"
1885,a1249e045a8db977ee827a8c4e2af7c3195b10d7,A causal role for the precuneus in network-wide theta and gamma oscillatory activity during complex memory retrieval,"Complex memory of personal events is thought to depend on coordinated reinstatement of cortical representations by the medial temporal lobes (MTL). MTL-cortical theta and gamma coupling is believed to mediate such coordination, but which cortical structures are critical for retrieval and how they influence oscillatory coupling is unclear. We used magnetoencephalography (MEG) combined with continuous theta burst stimulation (cTBS) to (i) clarify the roles of theta and gamma oscillations in network-wide communication during naturalistic memory retrieval, and (ii) understand the causal relationship between cortical network nodes and oscillatory communication. Retrieval was associated with MTL-posterior neocortical theta phase coupling and theta-gamma phase-amplitude coupling relative to a rest period. Precuneus cTBS altered MTL-neocortical communication by modulating theta and gamma oscillatory coupling. These findings provide a mechanistic account for MTL-cortical communication and demonstrate that the precuneus is a critical cortical node of oscillatory activity, coordinating cross-regional interactions that drive remembering.",2019.0,73.0,49.0,True,,"{'volume': '8', 'name': 'eLife'}","{'bibtex': '@Article{Hebscher2019ACR,\n author = {Melissa Hebscher and Jed A. Meltzer and A. Gilboa},\n journal = {eLife},\n title = {A causal role for the precuneus in network-wide theta and gamma oscillatory activity during complex memory retrieval},\n volume = {8},\n year = {2019}\n}\n'}","[{'authorId': '5784462', 'name': 'Melissa Hebscher'}, {'authorId': '1957052', 'name': 'Jed A. Meltzer'}, {'authorId': '2220346', 'name': 'A. Gilboa'}]"
1886,a18945b87fba66ac6e5418cad0fa55acb4c183ba,AI technologies for education: Recent research & future directions,,2021.0,81.0,94.0,True,,"{'volume': '2', 'pages': '100025', 'name': 'Comput. Educ. Artif. Intell.'}","{'bibtex': '@Article{Zhang2021AITF,\n author = {Ke Zhang and A. Aslan},\n journal = {Comput. Educ. Artif. Intell.},\n pages = {100025},\n title = {AI technologies for education: Recent research & future directions},\n volume = {2},\n year = {2021}\n}\n'}","[{'authorId': '2119058387', 'name': 'Ke Zhang'}, {'authorId': '2121951192', 'name': 'A. Aslan'}]"
1887,a1c5ac62bbdbe8cbb28fd14e895a3807de15a653,Do Variations in Agency Indirectly Affect Behavior with Others? An Analysis of Gaze Behavior,"In a group setting, it is possible for attributes of one group member to indirectly affect how other group members are perceived. In this paper, we explore whether one group member's agency (e.g. if they are real or virtual) can indirectly affect behavior with other group members. We also consider whether variations in the agency of a group member directly affects behavior with that group member. To do so, we examined gaze behavior during a team training exercise, in which sixty-nine nurses worked with a surgeon and an anesthesiologist to prepare a simulated patient for surgery. The agency of the surgeon and the anesthesiologist were varied between conditions. Nurses' gaze behavior was coded using videos of their interactions. Agency was observed to directly affect behavior, such that participants spent more time gazing at virtual teammates than human teammates. However, participants continued to obey polite gaze norms with virtual teammates. In contrast, agency was not observed to indirectly affect gaze behavior. The presence of a second human did not affect participants' gaze behavior with virtual teammates.",2016.0,31.0,7.0,False,,"{'volume': '22', 'pages': '1336-1345', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Robb2016DoVI,\n author = {Andrew C. Robb and A. Kleinsmith and Andrew Cordar and C. White and S. Lampotang and A. Wendling and Benjamin C. Lok},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {1336-1345},\n title = {Do Variations in Agency Indirectly Affect Behavior with Others? An Analysis of Gaze Behavior},\n volume = {22},\n year = {2016}\n}\n'}","[{'authorId': '78886496', 'name': 'Andrew C. Robb'}, {'authorId': '2870739', 'name': 'A. Kleinsmith'}, {'authorId': '2127223', 'name': 'Andrew Cordar'}, {'authorId': '4535740', 'name': 'C. White'}, {'authorId': '1705856', 'name': 'S. Lampotang'}, {'authorId': '2639010', 'name': 'A. Wendling'}, {'authorId': '1708157', 'name': 'Benjamin C. Lok'}]"
1888,a229b9c59347124e3bf3738a65acb04ed5b0cd35,Advanced Emotion Analytics of Virtual Group Meetings involving Intelligent Virtual Agents,"In this paper, we present our first prototype of a virtual group meeting emotion analytics tool based on both real human participants and virtual agents. The analysis starts with the detection of facial expressions of every participant using Facial Action Units (FACS), and calculates an aggregated summary of the group's emotional states throughout the duration of the meeting. We infer the inten-sities of the following primary emotional states: happy, surprised, angry, sad, disgusted, fearful by using the known AU combinations. Additionally, an AI algorithm was trained and tested on the DAiSEE dataset to infer the following secondary emotional states: engaged, bored, confused and frustrated. We present this tool in the context of an online classroom scenario in which the teacher can receive an anonymized aggregated emotion analytics of his/ her student group after their lecture calculated for the entire duration of the lecture. We finally asked 21 participants to rate the usability of this tool.",2022.0,0.0,2.0,False,,"{'name': '2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)', 'pages': '344-350'}","{'bibtex': '@Article{Joshi2022AdvancedEA,\n author = {Nidhi Joshi and Niklas Beecken and Hawa Bah and Frank Steinicke and Juliane Degner},\n booktitle = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},\n journal = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},\n pages = {344-350},\n title = {Advanced Emotion Analytics of Virtual Group Meetings involving Intelligent Virtual Agents},\n year = {2022}\n}\n'}","[{'authorId': '2162962781', 'name': 'Nidhi Joshi'}, {'authorId': '2162971367', 'name': 'Niklas Beecken'}, {'authorId': '2162969649', 'name': 'Hawa Bah'}, {'authorId': '32374164', 'name': 'Frank Steinicke'}, {'authorId': '4749648', 'name': 'Juliane Degner'}]"
1889,a2428eb9531abfbb463934163b68ac7de223bf91,A Virtual Conversational Agent for Teens with Autism: Experimental Results and Design Lessons,"We present the design of an online social skills development interface for teenagers with autism spectrum disorder (ASD), who often lack access to social skills training. The interface is intended to enable private conversation practice anywhere, anytime using a browser. Users converse informally with an on-screen persona, receiving feedback on nonverbal cues in real-time, and summary feedback. The prototype was developed in consultation with an expert UX designer, two psychologists, and a pediatrician. Using the data from 47 individuals, feedback and dialogue generation were automated using the hidden Markov model and a schema-driven dialogue manager capable of handling multi-topic conversations. We conducted a study with nine high-functioning ASD teenagers, and through thematic analysis of post-experiment interviews, identified several key design considerations, notably: 1) Users should be fully briefed at the outset about the purpose and limitations of the system, to avoid unrealistic expectations. 2) An interface should incorporate positive acknowledgment of behavior change. 3) Realistic appearance of a virtual agent and responsiveness are important in engaging users. 4) Conversation personalization, for instance in prompting laconic users for more input and reciprocal questions, would help the teenagers engage for longer terms and increase the system's utility.",2018.0,78.0,35.0,False,,"{'volume': 'abs/1811.03046', 'name': 'ArXiv'}","{'bibtex': '@Article{Ali2018AVC,\n author = {M. R. Ali and Zahra Rasazi and A. Mamun and Raina Langevin and Reza Rawassizadeh and Lenhart K. Schubert and Ehsan Hoque},\n journal = {ArXiv},\n title = {A Virtual Conversational Agent for Teens with Autism: Experimental Results and Design Lessons},\n volume = {abs/1811.03046},\n year = {2018}\n}\n'}","[{'authorId': '22858671', 'name': 'M. R. Ali'}, {'authorId': '51905143', 'name': 'Zahra Rasazi'}, {'authorId': '50059663', 'name': 'A. Mamun'}, {'authorId': '51900408', 'name': 'Raina Langevin'}, {'authorId': '3154478', 'name': 'Reza Rawassizadeh'}, {'authorId': '2404386', 'name': 'Lenhart K. Schubert'}, {'authorId': '144619896', 'name': 'Ehsan Hoque'}]"
1890,a2517bfcbea08e93c6880cad5c6ae90c6190358e,Usability investigation of an educational mobile application for individuals with intellectual disabilities,,2019.0,41.0,15.0,False,,"{'volume': '', 'pages': '1-14', 'name': 'Universal Access in the Information Society'}","{'bibtex': '@Article{Yeni2019UsabilityIO,\n author = {Sabiha Yeni and K. Cagiltay and N. Karasu},\n journal = {Universal Access in the Information Society},\n pages = {1-14},\n title = {Usability investigation of an educational mobile application for individuals with intellectual disabilities},\n year = {2019}\n}\n'}","[{'authorId': '29846641', 'name': 'Sabiha Yeni'}, {'authorId': '2001830', 'name': 'K. Cagiltay'}, {'authorId': '2089264127', 'name': 'N. Karasu'}]"
1891,a2721c95d1cd65bfc1492a4e5ca73be219d93bc4,EmotionML - An Upcoming Standard for Representing Emotions and Related States,,2011.0,23.0,62.0,False,,{'pages': '316-325'},"{'bibtex': '@Inproceedings{Schröder2011EmotionMLA,\n author = {M. Schröder and P. Baggia and F. Burkhardt and C. Pelachaud and Christian Peter and E. Zovato},\n pages = {316-325},\n title = {EmotionML - An Upcoming Standard for Representing Emotions and Related States},\n year = {2011}\n}\n'}","[{'authorId': '144951065', 'name': 'M. Schröder'}, {'authorId': '2349051', 'name': 'P. Baggia'}, {'authorId': '1763455', 'name': 'F. Burkhardt'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2061240446', 'name': 'Christian Peter'}, {'authorId': '2213115', 'name': 'E. Zovato'}]"
1892,a29f96a968a58d5dcd8eb4cfed07d4707f83fa6e,GAMYGDALA: An Emotion Engine for Games,"In this paper we present GAMYGDALA, an emotional appraisal engine that enables game developers to easily add emotions to their Non-Player Characters (NPC). Our approach proposes a solution that is positioned between event coding of affect, where individual events have predetermined annotated emotional consequences for NPCs, and a full blown cognitive appraisal model. Instead, for an NPC that needs emotions the game developer defines goals and annotates game events with a relation to these goals. Based on this input, GAMYGDALA produces an emotion for that NPC according to the well-known OCC model. In this paper we provide evidence for the following: GAMYGDALA provides black-box Game-AI independent emotion support, is efficient for large numbers of NPCs, and is psychologically grounded.",2014.0,45.0,68.0,True,"{'url': 'http://mmi.tudelft.nl/%7Ejoostb/files/Popescu_Broekens_Someren_2013.pdf', 'status': None}","{'volume': '5', 'pages': '32-44', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Popescu2014GAMYGDALAAE,\n author = {Alexandru Popescu and J. Broekens and M. Someren},\n journal = {IEEE Transactions on Affective Computing},\n pages = {32-44},\n title = {GAMYGDALA: An Emotion Engine for Games},\n volume = {5},\n year = {2014}\n}\n'}","[{'authorId': '144155622', 'name': 'Alexandru Popescu'}, {'authorId': '1735303', 'name': 'J. Broekens'}, {'authorId': '1733088', 'name': 'M. Someren'}]"
1893,a2b0ac0e7329fe1b5e9692cc535cfd53b18b0982,DANCE MOVEMENT THERAPY IMPROVES EMOTIONAL RESPONSES AND MODULATES NEUROHORMONES IN ADOLESCENTS WITH MILD DEPRESSION,"This study assessed the profiles of psychological health and changes in neurohormones of adolescents with mild depression after 12 weeks of dance movement therapy (DMT). Forty middle school seniors (mean age: 16 years old) volunteered to participate in this study and were randomly assigned into either a dance movement group (n = 20) or a control group (n = 20). All subscale scores of psychological distress and global scores decreased significantly after the 12 weeks in the DMT group. Plasma serotonin concentration increased and dopamine concentration decreased in the DMT group. These results suggest that DMT may stabilize the sympathetic nervous system. In conclusion, DMT may be effective in beneficially modulating concentrations of serotonin and dopamine, and in improving psychological distress in adolescents with mild depression.",2005.0,17.0,243.0,False,,"{'volume': '115', 'pages': '1711 - 1720', 'name': 'International Journal of Neuroscience'}","{'bibtex': '@Article{Jeong2005DANCEMT,\n author = {Young-Ja Jeong and S. Hong and Myeong Soo Lee and Min-Cheol Park and Yong-Kyu. Kim and Chae-Moon Suh},\n journal = {International Journal of Neuroscience},\n pages = {1711 - 1720},\n title = {DANCE MOVEMENT THERAPY IMPROVES EMOTIONAL RESPONSES AND MODULATES NEUROHORMONES IN ADOLESCENTS WITH MILD DEPRESSION},\n volume = {115},\n year = {2005}\n}\n'}","[{'authorId': '6241785', 'name': 'Young-Ja Jeong'}, {'authorId': '2151797703', 'name': 'S. Hong'}, {'authorId': '152522673', 'name': 'Myeong Soo Lee'}, {'authorId': '49360403', 'name': 'Min-Cheol Park'}, {'authorId': '51033371', 'name': 'Yong-Kyu. Kim'}, {'authorId': '5768258', 'name': 'Chae-Moon Suh'}]"
1894,a2ba548810431fbfc0db43b537dda71ccdf45dc2,Virtual human animation based on movement observation and cognitive behavior models,"Automatically animating virtual humans with actions that reflect real human motions is still a challenge. We present a framework for animation that is based on utilizing empirical and validated data from movement observation and cognitive psychology. To illustrate these, we demonstrate a mapping from effort motion factors onto expressive arm movements, and from cognitive data to autonomous attention behaviors. We conclude with a discussion on the implications of this approach for the future of real time virtual human animation.",1999.0,44.0,59.0,True,"{'url': 'https://repository.upenn.edu/cgi/viewcontent.cgi?article=1010&context=hms', 'status': None}","{'pages': '128-137', 'name': 'Proceedings Computer Animation 1999'}","{'bibtex': '@Article{Badler1999VirtualHA,\n author = {N. Badler and D. Chi and Sonu Chopra-Khullar},\n journal = {Proceedings Computer Animation 1999},\n pages = {128-137},\n title = {Virtual human animation based on movement observation and cognitive behavior models},\n year = {1999}\n}\n'}","[{'authorId': '1699200', 'name': 'N. Badler'}, {'authorId': '36224552', 'name': 'D. Chi'}, {'authorId': '1405537339', 'name': 'Sonu Chopra-Khullar'}]"
1895,a2bb3e1c2b8ffd0d0bc44e19cec233f14708bf30,A Framework for Conflict Resolution in Multi-Agent Systems,,2013.0,20.0,11.0,False,,{'pages': '195-204'},"{'bibtex': '@Inproceedings{Basheer2013AFF,\n author = {G. S. Basheer and M. S. Ahmad and Alicia Y. C. Tang},\n pages = {195-204},\n title = {A Framework for Conflict Resolution in Multi-Agent Systems},\n year = {2013}\n}\n'}","[{'authorId': '2090128', 'name': 'G. S. Basheer'}, {'authorId': '1693745', 'name': 'M. S. Ahmad'}, {'authorId': '145838167', 'name': 'Alicia Y. C. Tang'}]"
1896,a2e31c895b1652b2d8b3b5eb4240494d96051fc4,Acute stress recovery through listening to Melomics relaxing music: A randomized controlled trial,"ABSTRACT Daily life entails having to cope with many stressful situations. Although stress-related reactions could sometimes provoke impairments in physiological processes due to the frequency of exposure or the stress burden of the event, physiological recovery after coping with stressors is highly implied in the aversive consequences of stress. To analyze the effects of listening to relaxing music (generated by the Melomics computer system) on the cardiovascular recovery and subjective feelings of anxiety after undergoing an acute-stress episode, a double-blind randomized controlled trial was conducted in healthy adults (N = 24; M = 23.05 years, SD = 2.97). Participants reported their levels of psychiatric symptomatology and anxiety and were then exposed to a stress induction protocol. Afterward, they underwent a period of recovery where they would be exposed to either a relaxing music track or silence, depending on a random assignation. Heart-derived functioning and self-reported anxiety were monitored throughout the study stages. All the participants showed stress-related reactions throughout the study stages, as it was shown for the study outcomes. Regarding the effect of listening to music, participants who listened to relaxing music during the recovery stage showed higher levels of sample entropy than controls, highlighting a large effect size on this difference (η2partial = .59). Relaxing music promotes more adaptive emotional regulation after coping with an acutely stressful event. This study aims to shed light on the actual effects of music interventions, and encourage the use of music-based interventions on health services.",2017.0,76.0,30.0,False,,"{'volume': '26', 'pages': '124 - 141', 'name': 'Nordic Journal of Music Therapy'}","{'bibtex': '@Article{Torre-Luque2017AcuteSR,\n author = {A. de la Torre-Luque and R. Caparros-Gonzalez and T. Bastard and Francisco Vico and G. Buela-Casal},\n journal = {Nordic Journal of Music Therapy},\n pages = {124 - 141},\n title = {Acute stress recovery through listening to Melomics relaxing music: A randomized controlled trial},\n volume = {26},\n year = {2017}\n}\n'}","[{'authorId': '1400017870', 'name': 'A. de la Torre-Luque'}, {'authorId': '1401783389', 'name': 'R. Caparros-Gonzalez'}, {'authorId': '118955281', 'name': 'T. Bastard'}, {'authorId': '144955542', 'name': 'Francisco Vico'}, {'authorId': '1403560826', 'name': 'G. Buela-Casal'}]"
1897,a2e4b7c46420ad36fe69ed2be39437b918a19e0a,"Attributing Emotion to Static Body Postures: Recognition Accuracy, Confusions, and Viewpoint Dependence",,2004.0,50.0,591.0,False,,"{'volume': '28', 'pages': '117-139', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Coulson2004AttributingET,\n author = {Mark C. Coulson},\n journal = {Journal of Nonverbal Behavior},\n pages = {117-139},\n title = {Attributing Emotion to Static Body Postures: Recognition Accuracy, Confusions, and Viewpoint Dependence},\n volume = {28},\n year = {2004}\n}\n'}","[{'authorId': '144037531', 'name': 'Mark C. Coulson'}]"
1898,a2ec66b68bdc119443a3b07448f4fab3258f314a,Understanding and using the implicit association test: I. An improved scoring algorithm.,"In reporting Implicit Association Test (IAT) results, researchers have most often used scoring conventions described in the first publication of the IAT (A.G. Greenwald, D.E. McGhee, & J.L.K. Schwartz, 1998). Demonstration IATs available on the Internet have produced large data sets that were used in the current article to evaluate alternative scoring procedures. Candidate new algorithms were examined in terms of their (a) correlations with parallel self-report measures, (b) resistance to an artifact associated with speed of responding, (c) internal consistency, (d) sensitivity to known influences on IAT measures, and (e) resistance to known procedural influences. The best-performing measure incorporates data from the IAT's practice trials, uses a metric that is calibrated by each respondent's latency variability, and includes a latency penalty for errors. This new algorithm strongly outperforms the earlier (conventional) procedure.",2003.0,36.0,5292.0,True,"{'url': 'https://psyarxiv.com/acgxd/download', 'status': None}","{'volume': '85 2', 'pages': '\n          197-216\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Greenwald2003UnderstandingAU,\n author = {A. Greenwald and Brian A. Nosek and M. Banaji},\n journal = {Journal of personality and social psychology},\n pages = {\n          197-216\n        },\n title = {Understanding and using the implicit association test: I. An improved scoring algorithm.},\n volume = {85 2},\n year = {2003}\n}\n'}","[{'authorId': '3864246', 'name': 'A. Greenwald'}, {'authorId': '2862527', 'name': 'Brian A. Nosek'}, {'authorId': '1968771', 'name': 'M. Banaji'}]"
1899,a2f4631f973344505555707006dce597c2f696d4,Consistent Dynamic-Group Emotions for Virtual Agents,"The use of computational models of emotion in virtual agents enhances the realism of these agents in a variety of domains, including virtual reality training and entertainment computing. We consider these two domains as prototypical for Multi-emotional-Agent- Systems (MeASs), which are the focus of this paper. MeASs typically include groups of agents organised into clusters, for example a special-force unit. While each agent in such a group has its own emotional model, resulting in realistic individual emotional behaviour, the group as a whole can show unrealistic emotional behaviour. Currently there is no method to enforce emotional consistency of a cluster of agents while allowing agents to have individual emotions. Our approach introduces an emotionalstate component that is a separate step in the computational model of emotion used by individual agents. The introduction of this emotional-state component enables multiple architectures for group emotions. We evaluate these architectures and conclude that several enable consistent integration of individual emotions and group emotions. We believe that our research enables agent- and scenario designers to benefit from the individual realism a computational model of emotion brings to virtual agents, without losing group consistency. Furthermore, by choosing one architecture versus another, designers can trade-off quality of the group emotion for computational performance.",2005.0,10.0,4.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Broekens2005ConsistentDE,\n author = {J. Broekens and Niels Netten and D. DeGroot},\n title = {Consistent Dynamic-Group Emotions for Virtual Agents},\n year = {2005}\n}\n'}","[{'authorId': '1735303', 'name': 'J. Broekens'}, {'authorId': '1840656', 'name': 'Niels Netten'}, {'authorId': '145678408', 'name': 'D. DeGroot'}]"
1900,a2f48b96f17938f9522b6d0a2baeea5b872a2e9b,"The Culture of Time and Space, 1880–1918 by Stephen Kern (review)",Introduction 1. The Nature of Time 2. The Past 3. The Present 4. The Future 5. Speed 6. The Nature of Space 7. Form 8. Distance 9. Direction 10. Temporality of the July Crisis 11. The Cubist War Conclusion Notes Index,1984.0,0.0,837.0,False,,"{'volume': '26', 'pages': '882 - 884', 'name': 'Technology and Culture'}","{'bibtex': '@Article{Theerman1984TheCO,\n author = {P. Theerman},\n journal = {Technology and Culture},\n pages = {882 - 884},\n title = {The Culture of Time and Space, 1880–1918 by Stephen Kern (review)},\n volume = {26},\n year = {1984}\n}\n'}","[{'authorId': '7407199', 'name': 'P. Theerman'}]"
1901,a303aebc0be81f1865ae4e6ae2470c9b17924052,A platform for affective agent research,"Accurately interpreting and expressing affect is fundamental to empathetic relationships. A platform for sensing and interpreting several aspects of users’ nonverbal affective information and responding through an expressive agent has been developed. The platform includes integration of multi-modal affective sensors with a real time inference engine, a behavior engine, and a 3d scriptable expressive humanoid agent within a graphical virtual environment. Currently the sensors include a pressure-sensitive mouse, a BlueTooth wireless skin conductivity sensor, a TekScan pressure sensor on a chair, and a stereo head tracking system as well as an IBM Blue Eyes infrared-sensitive camera. These sensors feed into custom algorithms for analysis of individual channels of information, such as postural and facial expressions, which in turn are combined with additional channels of information to make an inference about the user’s affective state. The system further synchronizes this sensor data with the agent behaviors and with video of the user and his or her on-screen activity. This platform is seen as a generalpurpose tool applicable to research in several areas, including how to design an affective learning companion, and how to further basic understanding of empathy and emotion contagion in human-agent interaction. 1. ACM classification keywords Agent architectures, Agent programming languages and environments, Sensors, Emotion, Affective user interface, Agent and intelligent systems, E-Learning and education, children, Pedagogical agents.",2004.0,56.0,71.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Burleson2004APF,\n author = {W. Burleson and Rosalind W. Picard and K. Perlin and J. Lippincott},\n title = {A platform for affective agent research},\n year = {2004}\n}\n'}","[{'authorId': '14741670', 'name': 'W. Burleson'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}, {'authorId': '2307214', 'name': 'K. Perlin'}, {'authorId': '144695084', 'name': 'J. Lippincott'}]"
1902,a306fffc1854bd958b2e86e7085e45ae693e6388,The Persona Effect: How Substantial Is It?,,1998.0,20.0,285.0,False,,{'pages': '53-66'},"{'bibtex': '@Inproceedings{Mulken1998ThePE,\n author = {Susanne van Mulken and E. André and Jochen Müller},\n pages = {53-66},\n title = {The Persona Effect: How Substantial Is It?},\n year = {1998}\n}\n'}","[{'authorId': '2106252', 'name': 'Susanne van Mulken'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '2110564814', 'name': 'Jochen Müller'}]"
1903,a33a06ddc762fb855b6954c08d5aca603080b011,Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset,"One challenge for dialogue agents is recognizing feelings in the conversation partner and replying accordingly, a key communicative skill. While it is straightforward for humans to recognize and acknowledge others’ feelings in a conversation, this is a significant challenge for AI systems due to the paucity of suitable publicly-available datasets for training and evaluation. This work proposes a new benchmark for empathetic dialogue generation and EmpatheticDialogues, a novel dataset of 25k conversations grounded in emotional situations. Our experiments indicate that dialogue models that use our dataset are perceived to be more empathetic by human evaluators, compared to models merely trained on large-scale Internet conversation data. We also present empirical comparisons of dialogue model adaptations for empathetic responding, leveraging existing models or datasets without requiring lengthy re-training of the full model.",2018.0,69.0,603.0,True,"{'url': 'https://arxiv.org/pdf/1811.00207', 'status': None}",{'pages': '5370-5381'},"{'bibtex': '@Inproceedings{Rashkin2018TowardsEO,\n author = {Hannah Rashkin and Eric Michael Smith and Margaret Li and Y-Lan Boureau},\n pages = {5370-5381},\n title = {Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset},\n year = {2018}\n}\n'}","[{'authorId': '2516777', 'name': 'Hannah Rashkin'}, {'authorId': '51324296', 'name': 'Eric Michael Smith'}, {'authorId': '6649233', 'name': 'Margaret Li'}, {'authorId': '90841478', 'name': 'Y-Lan Boureau'}]"
1904,a354854c71d60a4490c42ae47464fbb9807d02bf,"The Big Five Trait taxonomy: History, measurement, and theoretical perspectives.","2 Taxonomy is always a contentious issue because the world does not come to us in neat little packages (S. Personality has been conceptualized from a variety of theoretical perspectives, and at various levels of Each of these levels has made unique contributions to our understanding of individual differences in behavior and experience. However, the number of personality traits, and scales designed to measure them, escalated without an end in sight (Goldberg, 1971). Researchers, as well as practitioners in the field of personality assessment, were faced with a bewildering array of personality scales from which to choose, with little guidance and no overall rationale at hand. What made matters worse was that scales with the same name often measure concepts that are not the same, and scales with different names often measure concepts that are quite similar. Although diversity and scientific pluralism are useful, the systematic accumulation of findings and the communication among researchers became difficult amidst the Babel of concepts and scales. Many personality researchers had hoped that they might devise the structure that would transform the Babel into a community speaking a common language. However, such an integration was not to be achieved by any one researcher or by any one theoretical perspective. As Allport once put it, "" each assessor has his own pet units and uses a pet battery of diagnostic devices "" (1958, p. 258). What personality psychology needed was a descriptive model, or taxonomy, of its subject matter. One of the central goals of scientific taxonomies is the definition of overarching domains within which large numbers of specific instances can be understood in a simplified way. Thus, in personality psychology, a taxonomy would permit researchers to study specified domains of personality characteristics, rather than examining separately the thousands of particular attributes that make human beings individual and unique. Moreover, a generally accepted taxonomy would greatly facilitate the accumulation and communication of empirical findings by offering a standard vocabulary, or nomenclature. After decades of research, the field is approaching consensus on a general taxonomy of personality traits, the "" Big Five "" personality dimensions. These dimensions do not represent a particular theoretical perspective but were derived from analyses of the natural-language terms people use to describe themselves 3 and others. Rather than replacing all previous systems, the Big Five taxonomy serves an integrative function because it can represent the various and diverse systems of personality …",1999.0,179.0,8586.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{John1999TheBF,\n author = {O. John and S. Srivastava},\n title = {The Big Five Trait taxonomy: History, measurement, and theoretical perspectives.},\n year = {1999}\n}\n'}","[{'authorId': '2254103', 'name': 'O. John'}, {'authorId': '50040921', 'name': 'S. Srivastava'}]"
1905,a35c404d7c8bb77ea5c3de3e22f70f4a13fc4450,Helper agent: designing an assistant for human-human interaction in a virtual meeting space,"This paper introduces a new application area for agents in the computer interface: the support of human-human interaction. We discuss an interface agent prototype that is designed to support human-human communication in virtual environments. The prototype interacts with users strategically during conversation, spending most of its time listening. The prototype mimics a party host, trying to find a safe common topic for guests whose conversation has lagged. We performed an experimental evaluation of the prototype's ability to assist in cross-cultural conversations. We designed the prototype to introduce safe or unsafe topics to conversation pairs, through a series of questions and suggestions. The agent made positive contributions to participants' experience of the conversation, influenced their perception of each other and of each others' national group, and even seemed to effect their style of behavior. We discuss the implications of our research for the design of social agents to support human-human interaction.",2000.0,15.0,187.0,False,,{'name': 'Proceedings of the SIGCHI conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Isbister2000HelperAD,\n author = {K. Isbister and Hideyuki Nakanishi and T. Ishida and C. Nass},\n journal = {Proceedings of the SIGCHI conference on Human Factors in Computing Systems},\n title = {Helper agent: designing an assistant for human-human interaction in a virtual meeting space},\n year = {2000}\n}\n'}","[{'authorId': '1740889', 'name': 'K. Isbister'}, {'authorId': '2268916', 'name': 'Hideyuki Nakanishi'}, {'authorId': '143807934', 'name': 'T. Ishida'}, {'authorId': '2029850', 'name': 'C. Nass'}]"
1906,a3688ebcce02bbafa87e3f644841d7d78172fc08,Constants across cultures in the face and emotion.,"This study addresses the question of whether any facial expressions of emotion are universal. Recent studies showing that members of literate cultures associated the same emotion concepts with the same facial behaviors could not demonstrate that at least some facial expressions of emotion are universal; the cultures compared had all been exposed to some of the same mass media presentations of facial expression, and these may have taught the people in each culture to recognize the unique facial expressions of other cultures. To show that members of a preliterate culture who had minimal exposure to literate cultures would associate the same emotion concepts with the same facial behaviors as do members of Western and Eastern literate cultures, data were gathered in New Guinea by telling subjects a story, showing them a set of three faces, and asking them to select the face which showed the emotion appropriate to the story. The results provide evidence in support of the hypothesis that the association between particular facial muscular patterns and discrete emotions is universal.",1971.0,28.0,4490.0,False,,"{'volume': '17 2', 'pages': '\n          124-9\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Ekman1971ConstantsAC,\n author = {P. Ekman and W. Friesen},\n journal = {Journal of personality and social psychology},\n pages = {\n          124-9\n        },\n title = {Constants across cultures in the face and emotion.},\n volume = {17 2},\n year = {1971}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '1388284460', 'name': 'W. Friesen'}]"
1908,a36ad82ed7d1365286e2179ef248a1782f8846e4,Emotions as metarepresentational states of mind: Naturalizing the belief–desire theory of emotion,,2009.0,122.0,171.0,False,,"{'volume': '10', 'pages': '6-20', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Reisenzein2009EmotionsAM,\n author = {R. Reisenzein},\n journal = {Cognitive Systems Research},\n pages = {6-20},\n title = {Emotions as metarepresentational states of mind: Naturalizing the belief–desire theory of emotion},\n volume = {10},\n year = {2009}\n}\n'}","[{'authorId': '3213879', 'name': 'R. Reisenzein'}]"
1909,a3ad2d9faf0129ebc56c6902493a91bb964a82c4,Crime and punishment?,,1992.0,0.0,463.0,False,,"{'volume': '64 6', 'pages': '\n          405-6\n        ', 'name': 'Delaware medical journal'}","{'bibtex': '@Article{Martz1992CrimeAP,\n author = {E. Martz},\n journal = {Delaware medical journal},\n pages = {\n          405-6\n        },\n title = {Crime and punishment?},\n volume = {64 6},\n year = {1992}\n}\n'}","[{'authorId': '2515172', 'name': 'E. Martz'}]"
1910,a3dc3353c5c916a865eb3477f739cc21142430fd,Real Time Face Detection and Facial Expression Recognition: Development and Applications to Human Computer Interaction.,"Computer animated agents and robots bring a social dimension to human computer interaction and force us to think in new ways about how computers could be used in daily life. Face to face communication is a real-time process operating at a a time scale in the order of 40 milliseconds. The level of uncertainty at this time scale is considerable, making it necessary for humans and machines to rely on sensory rich perceptual primitives rather than slow symbolic inference processes. In this paper we present progress on one such perceptual primitive. The system automatically detects frontal faces in the video stream and codes them with respect to 7 dimensions in real time: neutral, anger, disgust, fear, joy, sadness, surprise. The face finder employs a cascade of feature detectors trained with boosting techniques [15, 2]. The expression recognizer receives image patches located by the face detector. A Gabor representation of the patch is formed and then processed by a bank of SVM classifiers. A novel combination of Adaboost and SVM's enhances performance. The system was tested on the Cohn-Kanade dataset of posed facial expressions [6]. The generalization performance to new subjects for a 7- way forced choice correct. Most interestingly the outputs of the classifier change smoothly as a function of time, providing a potentially valuable representation to code facial expression dynamics in a fully automatic and unobtrusive manner. The system has been deployed on a wide variety of platforms including Sony's Aibo pet robot, ATR's RoboVie, and CU animator, and is currently being evaluated for applications including automatic reading tutors, assessment of human-robot interaction.",2003.0,19.0,567.0,True,"{'url': 'http://mplab.ucsd.edu/~movellan/mypapers/BartlettCVPR2003.pdf', 'status': None}","{'volume': '5', 'pages': '53-53', 'name': '2003 Conference on Computer Vision and Pattern Recognition Workshop'}","{'bibtex': '@Article{Bartlett2003RealTF,\n author = {M. Bartlett and G. Littlewort and Ian R. Fasel and J. Movellan},\n journal = {2003 Conference on Computer Vision and Pattern Recognition Workshop},\n pages = {53-53},\n title = {Real Time Face Detection and Facial Expression Recognition: Development and Applications to Human Computer Interaction.},\n volume = {5},\n year = {2003}\n}\n'}","[{'authorId': '2218905', 'name': 'M. Bartlett'}, {'authorId': '46548046', 'name': 'G. Littlewort'}, {'authorId': '2039025', 'name': 'Ian R. Fasel'}, {'authorId': '1741200', 'name': 'J. Movellan'}]"
1911,a3e43b8a86dfe91167f8cfa5d0ef84078291cddb,Cognitive Agent-Based Computing-I: a Unified Framework for Modeling Complex Adaptive Systems Using Agent-Based & Complex Network-Based Methods (SpringerBriefs in Cognitive Computation) by Muaz A Niazi and Amir Hussain,,2013.0,0.0,9.0,False,,"{'volume': '16', 'name': 'J. Artif. Soc. Soc. Simul.'}","{'bibtex': '@Article{Bragin2013CognitiveAC,\n author = {John Bragin},\n journal = {J. Artif. Soc. Soc. Simul.},\n title = {Cognitive Agent-Based Computing-I: a Unified Framework for Modeling Complex Adaptive Systems Using Agent-Based & Complex Network-Based Methods (SpringerBriefs in Cognitive Computation) by Muaz A Niazi and Amir Hussain},\n volume = {16},\n year = {2013}\n}\n'}","[{'authorId': '2957203', 'name': 'John Bragin'}]"
1912,a3f817c62b38d908bcd7c22f19226f57b751b6e0,Coordination of communication: effects of shared visual context on collaborative work,"We outline some of the benefits of shared visual information for collaborative repair tasks and report on a study comparing collaborative performance on a manual task by workers and helpers who are located side-by-side or connected via audio-video or audio-only links. Results show that the dyads complete the task more quickly and accurately when helpers are co-located than when they are connected via an audio link. However, they didn't achieve similar efficiency gains when they communicated through an audio/video link. These results demonstrate the value of a shared visual work space, but raise questions about the adequacy of current video communication technology for implementing it.",2000.0,23.0,361.0,False,,{'pages': '21-30'},"{'bibtex': '@Inproceedings{Fussell2000CoordinationOC,\n author = {Susan R. Fussell and R. Kraut and J. Siegel},\n pages = {21-30},\n title = {Coordination of communication: effects of shared visual context on collaborative work},\n year = {2000}\n}\n'}","[{'authorId': '1692772', 'name': 'Susan R. Fussell'}, {'authorId': '1702853', 'name': 'R. Kraut'}, {'authorId': '143760899', 'name': 'J. Siegel'}]"
1913,a408a9ba5c11c466ebb79794de9bfdfd4ff0e892,Emotional Contagion,,1993.0,0.0,1035.0,False,,"{'volume': '2', 'pages': '100 - 96', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Hatfield1993EmotionalC,\n author = {E. Hatfield and J. Cacioppo and Richard L. Rapson},\n journal = {Current Directions in Psychological Science},\n pages = {100 - 96},\n title = {Emotional Contagion},\n volume = {2},\n year = {1993}\n}\n'}","[{'authorId': '48279878', 'name': 'E. Hatfield'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}, {'authorId': '8611261', 'name': 'Richard L. Rapson'}]"
1915,a413a892efc95dc20a5366938cdc8521dbb9657a,Removal of Artifacts from EEG Signals: A Review,"Electroencephalogram (EEG) plays an important role in identifying brain activity and behavior. However, the recorded electrical activity always be contaminated with artifacts and then affect the analysis of EEG signal. Hence, it is essential to develop methods to effectively detect and extract the clean EEG data during encephalogram recordings. Several methods have been proposed to remove artifacts, but the research on artifact removal continues to be an open problem. This paper tends to review the current artifact removal of various contaminations. We first discuss the characteristics of EEG data and the types of different artifacts. Then, a general overview of the state-of-the-art methods and their detail analysis are presented. Lastly, a comparative analysis is provided for choosing a suitable methods according to particular application.",2019.0,128.0,403.0,True,"{'url': 'https://www.mdpi.com/1424-8220/19/5/987/pdf?version=1551160890', 'status': None}","{'volume': '19', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Jiang2019RemovalOA,\n author = {Xiao Jiang and Guibin Bian and Zean Tian},\n journal = {Sensors (Basel, Switzerland)},\n title = {Removal of Artifacts from EEG Signals: A Review},\n volume = {19},\n year = {2019}\n}\n'}","[{'authorId': '2144811563', 'name': 'Xiao Jiang'}, {'authorId': '2058633', 'name': 'Guibin Bian'}, {'authorId': '2069521267', 'name': 'Zean Tian'}]"
1916,a420672b66ff5e0ade50243c4a5ae74ddeb7b352,"Interpersonal Distance During Real-Time Social Interaction: Insights From Subjective Experience, Behavior, and Physiology","Physical distance is a prominent feature in face-to-face social interactions and allows regulating social encounters. Close interpersonal distance (IPD) increases emotional responses during interaction and has been related to avoidance behavior in social anxiety. However, a systematic investigation of the effects of IPD on subjective experience combined with measures of physiological arousal and behavioral responses during real-time social interaction has been missing. Virtual Reality allows for a controlled manipulation of IPD while maintaining naturalistic social encounters. The present study investigates IPD in social interaction using a novel paradigm in Virtual Reality. Thirty-six participants approached virtual agents and engaged in short interactions. IPD was varied between 3.5 and 1 m by manipulating the distance at which agents reacted to the participant's approach. Closer distances were rated as more arousing, less pleasant, and less natural than longer distances and this effect was significantly modulated by social anxiety scores. Skin conductance responses were also increased at short distances compared to longer distances. Finally, an interaction of IPD and social anxiety was observed for avoidance behavior, measured as participants' backward motion during interaction, with stronger avoidance related to close distances and high values of social anxiety. These results highlight the influence of IPD on experience, physiological response, and behavior during social interaction. The interaction of social anxiety and IPD suggests including the manipulation of IPD in behavioral tests in Virtual Reality as a promising tool for the treatment of social anxiety disorder.",2020.0,46.0,25.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00561/pdf', 'status': None}","{'volume': '11', 'name': 'Frontiers in Psychiatry'}","{'bibtex': '@Article{Kroczek2020InterpersonalDD,\n author = {Leon O. H. Kroczek and Michael Pfaller and B. Lange and Mathias Müller and A. Mühlberger},\n journal = {Frontiers in Psychiatry},\n title = {Interpersonal Distance During Real-Time Social Interaction: Insights From Subjective Experience, Behavior, and Physiology},\n volume = {11},\n year = {2020}\n}\n'}","[{'authorId': '30692915', 'name': 'Leon O. H. Kroczek'}, {'authorId': '2053795228', 'name': 'Michael Pfaller'}, {'authorId': '1471458840', 'name': 'B. Lange'}, {'authorId': '2116236276', 'name': 'Mathias Müller'}, {'authorId': '1684604', 'name': 'A. Mühlberger'}]"
1917,a4269ee19a49ec9cf7343a4a8a187a9caceab6a4,Tactical Language and Culture Training Systems: Using Artificial Intelligence to Teach Foreign Languages and Cultures,"The Tactical Language and Culture Training System (TLCTS) helps people quickly acquire communicative skills in foreign languages and cultures. More than 20,000 learners worldwide have used TLCTS courses. TLCTS utilizes artificial intelligence technologies in multiple ways: during the authoring process, and at run time to process learner speech, interpret learner actions, control the response of non-player characters, and evaluate and assess learner performance and proficiency. This paper describes the architecture of TLCTS and the artificial intelligence technologies that it employs, and presents results from multiple evaluation studies that demonstrate the benefits of learning foreign language and culture using this approach.",2008.0,14.0,120.0,False,,{'pages': '1632-1639'},"{'bibtex': '@Inproceedings{Johnson2008TacticalLA,\n author = {W. Johnson and A. Valente},\n pages = {1632-1639},\n title = {Tactical Language and Culture Training Systems: Using Artificial Intelligence to Teach Foreign Languages and Cultures},\n year = {2008}\n}\n'}","[{'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '2713763', 'name': 'A. Valente'}]"
1918,a430dabab264b8b70d3c26f9307c85ce8ebd094b,The analysis of embodied communicative feedback in multimodal corpora: a prerequisite for behavior simulation,,2007.0,20.0,37.0,False,,"{'volume': '41', 'pages': '255-272', 'name': 'Language Resources and Evaluation'}","{'bibtex': '@Article{Allwood2007TheAO,\n author = {J. Allwood and S. Kopp and K. Grammer and E. Ahlsén and E. Oberzaucher and Markus Koppensteiner},\n journal = {Language Resources and Evaluation},\n pages = {255-272},\n title = {The analysis of embodied communicative feedback in multimodal corpora: a prerequisite for behavior simulation},\n volume = {41},\n year = {2007}\n}\n'}","[{'authorId': '145860194', 'name': 'J. Allwood'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1850299', 'name': 'K. Grammer'}, {'authorId': '3074458', 'name': 'E. Ahlsén'}, {'authorId': '3065152', 'name': 'E. Oberzaucher'}, {'authorId': '1852082', 'name': 'Markus Koppensteiner'}]"
1919,a44d4efd142deff118e4a2c00c6d47174cb6de41,Mapping learning and game mechanics for serious games analysis,"Although there is a consensus on the instructional potential of Serious Games (SGs), there is still a lack of methodologies and tools not only for design but also to support analysis and assessment. Filling this gap is one of the main aims of the Games and Learning Alliance (http://www.galanoe.eu) European Network of Excellence on Serious Games, which has a focus upon pedagogy-driven SGs. This paper relies on the assumption that the fundamental aspect of SG design consists in the translation of learning goals/practices into mechanical element of gameplay, serving to an instructional purpose beside that of play and fun. This paper proposes the Learning Mechanics–Game Mechanics (LM-GM) model, which supports SG analysis and design by allowing reflection on the various pedagogical and game elements in an SG. The LM-GM model includes a set of pre-defined game mechanics and pedagogical elements that we have abstracted from literature on game studies and learning theories. 
 
Designers and analysts can exploit these mechanics to draw the LM-GM map for a game, so as to identify and highlight its main pedagogical and entertainment features, and their interrelations. The tool may also be useful for teachers to evaluate the effectiveness of a given game and better understand how to implement it in educational settings. A case study is reported to illustrate the framework's support in determining how gameplay and pedagogy intertwine in an SG. Finally, the paper presents the results of two comparative user tests demonstrating the advantages of the proposed model with respect to a similar state-of-the-art framework.",2015.0,70.0,584.0,True,"{'url': 'https://researchrepository.murdoch.edu.au/id/eprint/25898/1/mapping-for-serious-games-analysis.pdf', 'status': None}","{'volume': '46', 'pages': '391-411', 'name': 'Br. J. Educ. Technol.'}","{'bibtex': '@Article{Arnab2015MappingLA,\n author = {S. Arnab and T. Lim and M. Carvalho and F. Bellotti and S. Freitas and S. Louchart and N. Suttie and Riccardo Berta and A. D. Gloria},\n journal = {Br. J. Educ. Technol.},\n pages = {391-411},\n title = {Mapping learning and game mechanics for serious games analysis},\n volume = {46},\n year = {2015}\n}\n'}","[{'authorId': '3237267', 'name': 'S. Arnab'}, {'authorId': '145841951', 'name': 'T. Lim'}, {'authorId': '145137412', 'name': 'M. Carvalho'}, {'authorId': '1693322', 'name': 'F. Bellotti'}, {'authorId': '145700052', 'name': 'S. Freitas'}, {'authorId': '2910576', 'name': 'S. Louchart'}, {'authorId': '3181393', 'name': 'N. Suttie'}, {'authorId': '143892518', 'name': 'Riccardo Berta'}, {'authorId': '1696279', 'name': 'A. D. Gloria'}]"
1920,a462ab5e68412f81d7c1947bb8baefa10ff63266,Usage of Social Stories in Encouraging Social Interaction of Children with Autism Spectrum Disorder,Social story is a very popular intervention and used widely as a social learning tool for children with autism spectrum disorder (ASD). The purpose of this research was to investigate the usage of social stories in encouraging social interaction of children with ASD. The subjects for this study were 4 learners with ASD between the ages of 5 to 8 who were attending school in an inclusive setting. A single case experiment with A-B-A-B design was used for all 4 subjects. Three of the subjects showed great improvement in their ability to make friends. Improvement was also seen in their communication based on visual obeservation to the targeted behavior chart whereas 1 subject only showed very little improvement. The findings of this study suggest that the usage of social stories in improving the social interaction of children with ASD has a positive impact.,2017.0,27.0,13.0,True,"{'url': 'https://journal2.um.ac.id/index.php/icsar/article/download/340/595', 'status': None}","{'volume': '1', 'pages': '91-97', 'name': ''}","{'bibtex': '@Inproceedings{Balakrishnan2017UsageOS,\n author = {S. Balakrishnan and Aliza Alias},\n pages = {91-97},\n title = {Usage of Social Stories in Encouraging Social Interaction of Children with Autism Spectrum Disorder},\n volume = {1},\n year = {2017}\n}\n'}","[{'authorId': '2071649452', 'name': 'S. Balakrishnan'}, {'authorId': '113747877', 'name': 'Aliza Alias'}]"
1921,a499b8e33d43e6cda7d9fa705a8afc25cbf84b6c,A framework for interpersonal attitude and non-verbal communication in improvisational visual media production,"Computer generated characters are now commonplace 
in television and film. In some media productions like the Matrix™ they feature as frequently as the real cast. A visual media that is being explored by the research community is that of real-time improvisational theatre using virtual characters. This is a non-trivial problem with many research challenges; this paper starts to address one, which is the automatic generation of appropriate non-verbal 
communication between characters based on their personality and relationship to one another. We focus on our of model interpersonal attitude used for generating expressive postures and eye gaze in computer animated characters. Our model consists of two principle dimensions, affiliation and status. It takes into account the relationships between the attitudes of two characters and allows for a large degree of variation between characters, both in how they react to other characters’ behaviour and in the ways in which they express attitude.",2004.0,32.0,39.0,False,,"{'volume': '', 'pages': '203-210', 'name': ''}","{'bibtex': '@Inproceedings{Ballin2004AFF,\n author = {D. Ballin and M. Gillies and Barry Crabtree and D. Ballin and M. Gillies and I. B. Crabtree},\n pages = {203-210},\n title = {A framework for interpersonal attitude and non-verbal communication in improvisational visual media production},\n year = {2004}\n}\n'}","[{'authorId': '1945636', 'name': 'D. Ballin'}, {'authorId': '2246989429', 'name': 'M. Gillies'}, {'authorId': '2246988927', 'name': 'Barry Crabtree'}, {'authorId': '1945636', 'name': 'D. Ballin'}, {'authorId': '2246989429', 'name': 'M. Gillies'}, {'authorId': '145279822', 'name': 'I. B. Crabtree'}]"
1922,a4aa02c837958fc841a730f5d3377cc93266d090,Foundations of intelligent tutoring systems,"Contents: H.L. Burns, C.G. Capps, Foundations of Intelligent Tutoring Systems: An Introduction. J.R. Anderson, The Expert Module. K. VanLehn, Student Modeling. H.M. Halff, Curriculum and Instruction in Automated Tutors. R.C. Burton, The Environment Module of Intelligent Tutoring Systems. J.R. Miller, The Role of Human-Computer Interaction in Intelligent Tutoring Systems. W.B. Johnson, Pragmatic Considerations in Research, Development, and Implementation of Intelligent Tutoring Systems. D. Littman, E. Soloway, Evaluating ITSs: The Cognitive Science Perspective. J.J. Richardson, Directions for Research and Applications. Appendix I: Selected Intelligent Tutoring Systems. Glossary of ITS Terms.",1988.0,0.0,511.0,False,,"{'pages': 'I-XII, 1-280'}","{'bibtex': '@Inproceedings{Polson1988FoundationsOI,\n author = {M. Polson and J. J. Richardson},\n pages = {I-XII, 1-280},\n title = {Foundations of intelligent tutoring systems},\n year = {1988}\n}\n'}","[{'authorId': '33104574', 'name': 'M. Polson'}, {'authorId': '2150298442', 'name': 'J. J. Richardson'}]"
1923,a4d3a13f325fbd6dc6306fab2e263776c2c94572,Conversations between self and self as Sigmund Freud—A virtual body ownership paradigm for self counselling,,2015.0,58.0,156.0,True,"{'url': 'https://www.nature.com/articles/srep13899.pdf', 'status': None}","{'volume': '5', 'name': 'Scientific Reports'}","{'bibtex': '@Article{Osimo2015ConversationsBS,\n author = {S. Osimo and Rodrigo Pizarro and B. Spanlang and M. Slater},\n journal = {Scientific Reports},\n title = {Conversations between self and self as Sigmund Freud—A virtual body ownership paradigm for self counselling},\n volume = {5},\n year = {2015}\n}\n'}","[{'authorId': '46829922', 'name': 'S. Osimo'}, {'authorId': '145661678', 'name': 'Rodrigo Pizarro'}, {'authorId': '2891686', 'name': 'B. Spanlang'}, {'authorId': '144931212', 'name': 'M. Slater'}]"
1924,a4f7d3a3da4b26ed6fb436326d44af12653ed86e,Interpersonal emotion regulation as a mechanism of social support in depression.,,2011.0,226.0,291.0,False,,"{'volume': '31 8', 'pages': '\n          1276-90\n        ', 'name': 'Clinical psychology review'}","{'bibtex': '@Article{Marroquín2011InterpersonalER,\n author = {B. Marroquín},\n journal = {Clinical psychology review},\n pages = {\n          1276-90\n        },\n title = {Interpersonal emotion regulation as a mechanism of social support in depression.},\n volume = {31 8},\n year = {2011}\n}\n'}","[{'authorId': '6643983', 'name': 'B. Marroquín'}]"
1925,a4fbf9b384057d17c31ee0ad15f1d9f02897e9df,Facial expression recognition across the adult life span,,2003.0,43.0,371.0,False,,"{'volume': '41', 'pages': '195-202', 'name': 'Neuropsychologia'}","{'bibtex': '@Article{Calder2003FacialER,\n author = {A. Calder and Jill Keane and T. Manly and R. Sprengelmeyer and S. Scott and I. Nimmo-Smith and A. Young},\n journal = {Neuropsychologia},\n pages = {195-202},\n title = {Facial expression recognition across the adult life span},\n volume = {41},\n year = {2003}\n}\n'}","[{'authorId': '2825775', 'name': 'A. Calder'}, {'authorId': '40020056', 'name': 'Jill Keane'}, {'authorId': '2788672', 'name': 'T. Manly'}, {'authorId': '5139809', 'name': 'R. Sprengelmeyer'}, {'authorId': '144781145', 'name': 'S. Scott'}, {'authorId': '1401859312', 'name': 'I. Nimmo-Smith'}, {'authorId': '2423497', 'name': 'A. Young'}]"
1926,a4ffbc202c5c5ae2221dd9c2949b9b5935adb5cc,Experimental psychology: A manual of laboratory practice.,,,0.0,87.0,False,,"{'volume': '8', 'pages': '403-406', 'name': 'Psychological Review'}","{'bibtex': '@Misc{None,\n author = {C. Seashore},\n journal = {Psychological Review},\n pages = {403-406},\n title = {Experimental psychology: A manual of laboratory practice.},\n volume = {8}\n}\n'}","[{'authorId': '3555773', 'name': 'C. Seashore'}]"
1927,a5291a0e2b5d44f93cf2f3c6ef35bf8e18a28bf4,Multi-emotion Recognition and Dialogue Manager for VR-based Self-attachment Therapy,"Despite increase in mental health awareness, there is still a large portion of people not receiving treatment. There are various side effects associated with drugs and not everyone has access to therapy, whether due to cost or availability. Self-administrable therapies allow for greater ease of access and as such, a novel virtual reality based self-attachment therapy is currently being developed. One of its main goals is for the user to develop a bond and reparent a child avatar representing one’s childhood self. To do so efficiently, the emotions, felt by the user when discussing their childhood, should be transferred to this child avatar. This project aims to train an emotion recognition model to allow the detection of multiple emotions. In addition, it aims to implement the self-attachment theory scenario to manage the dialogue between a user and a virtual therapist. The two parts of the project are to be integrated within the proposed virtual reality application. The devised multimodal and multi-emotion recognition model trained on CMUMOSEI dataset, achieves state-of-the-art results on happiness detection and competitive results for other emotions. The scenario was implemented using FAtiMA toolkit and together with the emotion recognition model was successfully integrated within the virtual reality application.",2020.0,79.0,1.0,False,,,"{'bibtex': '@Inproceedings{Edalat2020MultiemotionRA,\n author = {A. Edalat and Georgios Rizos},\n title = {Multi-emotion Recognition and Dialogue Manager for VR-based Self-attachment Therapy},\n year = {2020}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}, {'authorId': '40185455', 'name': 'Georgios Rizos'}]"
1928,a52a1e3c4b74dc74f445f5113d4f701a05c496ad,Human-Computer Interaction in Healthcare: How to Support Patients during Their Wrist Rehabilitation,"The increasing use of IT/Informatics within the healthcare context is more and more helpful for both medical doctors and patients in all the surgical specialities. In this paper, we propose a low-cost system exploiting a haptic interface aided by a glove sensorized on the wrist allowing the identification of the wrist orientation for supporting patients during their wrist rehabilitation.",2016.0,15.0,19.0,False,,"{'pages': '325-328', 'name': '2016 IEEE Tenth International Conference on Semantic Computing (ICSC)'}","{'bibtex': '@Article{D’Auria2016HumanComputerII,\n author = {D. D’Auria and Fabio Persia and B. Siciliano},\n journal = {2016 IEEE Tenth International Conference on Semantic Computing (ICSC)},\n pages = {325-328},\n title = {Human-Computer Interaction in Healthcare: How to Support Patients during Their Wrist Rehabilitation},\n year = {2016}\n}\n'}","[{'authorId': '1398994076', 'name': 'D. D’Auria'}, {'authorId': '1721021', 'name': 'Fabio Persia'}, {'authorId': '1783131', 'name': 'B. Siciliano'}]"
1929,a54f5795def74a346d3e221147035caea24c42be,Affect recognition for interactive companions: challenges and design in real world scenarios,,2009.0,48.0,98.0,False,,"{'volume': '3', 'pages': '89-98', 'name': 'Journal on Multimodal User Interfaces'}","{'bibtex': '@Article{Castellano2009AffectRF,\n author = {Ginevra Castellano and Iolanda Leite and André Pereira and C. Martinho and Ana Paiva and P. McOwan},\n journal = {Journal on Multimodal User Interfaces},\n pages = {89-98},\n title = {Affect recognition for interactive companions: challenges and\xa0design in real world scenarios},\n volume = {3},\n year = {2009}\n}\n'}","[{'authorId': '39540970', 'name': 'Ginevra Castellano'}, {'authorId': '39799707', 'name': 'Iolanda Leite'}, {'authorId': '11845717', 'name': 'André Pereira'}, {'authorId': '145813496', 'name': 'C. Martinho'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '2803283', 'name': 'P. McOwan'}]"
1930,a55c126b31e265314b2d502f5928588b4a52ef0d,"Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant.","What is the structure of emotion? Emotion is too broad a class of events to be a single scientific category, and no one structure suffices. As an illustration, core affect is distinguished from prototypical emotional episode. Core affect refers to consciously accessible elemental processes of pleasure and activation, has many causes, and is always present. Its structure involves two bipolar dimensions. Prototypical emotional episode refers to a complex process that unfolds over time, involves causally connected subevents (antecedent; appraisal; physiological, affective, and cognitive changes; behavioral response; self-categorization), has one perceived cause, and is rare. Its structure involves categories (anger, fear, shame, jealousy, etc.) vertically organized as a fuzzy hierarchy and horizontally organized as part of a circumplex.",1999.0,131.0,2583.0,False,,"{'volume': '76 5', 'pages': '\n          805-19\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Russell1999CoreAP,\n author = {J. Russell and L. F. Barrett},\n journal = {Journal of personality and social psychology},\n pages = {\n          805-19\n        },\n title = {Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant.},\n volume = {76 5},\n year = {1999}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '1731779', 'name': 'L. F. Barrett'}]"
1931,a568ab075435ab3e59b7ea3eda70dcf78d82f742,Modeling and evaluating empathy in embodied companion agents,,2007.0,41.0,154.0,False,,"{'volume': '65', 'pages': '348-360', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{McQuiggan2007ModelingAE,\n author = {Scott W. McQuiggan and James C. Lester},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {348-360},\n title = {Modeling and evaluating empathy in embodied companion agents},\n volume = {65},\n year = {2007}\n}\n'}","[{'authorId': '2779835', 'name': 'Scott W. McQuiggan'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
1932,a56e71f4fec7ad97e00989902ec9c77ed1a708a7,Recognizing emotion from dance movement: comparison of spectator recognition and automated techniques,,2003.0,14.0,419.0,False,,"{'volume': '59', 'pages': '213-225', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Camurri2003RecognizingEF,\n author = {A. Camurri and Ingrid Lagerlöf and G. Volpe},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {213-225},\n title = {Recognizing emotion from dance movement: comparison of spectator recognition and automated techniques},\n volume = {59},\n year = {2003}\n}\n'}","[{'authorId': '3141704', 'name': 'A. Camurri'}, {'authorId': '1846900', 'name': 'Ingrid Lagerlöf'}, {'authorId': '145558735', 'name': 'G. Volpe'}]"
1933,a585300d7369839ba73999835f4a40a412f1ee9f,Towards Emotionally Expressive Virtual Human Agents to Foster L2 Production: Insights from a Preliminary Woz Experiment,"In second-language communication, emotional feedbacks play a preponderant role in instilling positive emotions and thereby facilitating the production of the target language by second-language learners. In contrast, facial expressions help convey emotion, intent, and sometimes even desired actions more effectively. Additionally, according to the facial feedback hypothesis, a major component of several contemporary theories of emotion, facial expressions can regulate emotional behavior and experience. The aim of this study was to determine whether and to what extent emotional expressions reproduced by virtual agents could provide empathetic support to second-language learners during communication tasks. To do so, using the Facial Coding Action System, we implemented a prototype virtual agent that can display a collection of nonverbal feedbacks, including Ekman’ six basic universal emotions and gazing and nodding behaviors. Then, we designed a Wizard of Oz experiment in which second-language learners were assigned independent speaking tasks with a virtual agent. In this paper, we outline our proposed method and report on an initial experimental evaluation which validated the meaningfulness of our approach. Moreover, we present our next steps for improving the system and validating its usefulness through large-scale experiments.",2022.0,41.0,0.0,True,"{'url': 'https://www.mdpi.com/2414-4088/6/9/77/pdf?version=1662626176', 'status': 'GOLD'}","{'name': 'Multimodal Technol. Interact.', 'pages': '77', 'volume': '6'}","{'bibtex': '@Article{Ayedoun2022TowardsEE,\n author = {Emmanuel Ayedoun and Masataka Tokumaru},\n booktitle = {Multimodal Technologies and Interaction},\n journal = {Multimodal Technol. Interact.},\n pages = {77},\n title = {Towards Emotionally Expressive Virtual Human Agents to Foster L2 Production: Insights from a Preliminary Woz Experiment},\n volume = {6},\n year = {2022}\n}\n'}","[{'authorId': '3350062', 'name': 'Emmanuel Ayedoun'}, {'authorId': '1980261', 'name': 'Masataka Tokumaru'}]"
1934,a5b4f139473e58ab836e4ce9923bdbf6381a6fac,DBT Skills Training: Manual,I. An Introduction to DBT Skills Training 1. Rationale for Dialectical Behavior Therapy Skills Training 2. Planning to Conduct DBT Skills Training 3. Structuring Skills Training Sessions 4. Skills Training Treatment Targets and Procedures 5. Application of Fundamental DBT Strategies in Behavioral Skills Training Part I Appendices II. Teaching Notes for DBT Skills Modules 6. General Skills: Orientation and Analyzing Behavior 7. Mindfulness Skills 8. Interpersonal Effectiveness Skills 9. Emotion Regulation Skills 10. Distress Tolerance Skills Index,2014.0,0.0,564.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Linehan2014DBTST,\n author = {M. Linehan},\n title = {DBT Skills Training: Manual},\n year = {2014}\n}\n'}","[{'authorId': '5574109', 'name': 'M. Linehan'}]"
1935,a5d2af2a518e2c74761bdc3d976657ac48c9d2f8,Façade: An Experiment in Building a Fully-Realized Interactive Drama,"Contemporary games are making significant strides towards offering complex, immersive experiences for players. We can now explore sprawling 3D virtual environments populated by beautifully rendered characters and objects with autonomous behavior, engage in highly visceral action-oriented experiences offering a variety of missions with multiple solutions, and interact in ever-expanding online worlds teeming with physically customizable player avatars.",2003.0,46.0,625.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mateas2003FacadeAE,\n author = {Michael Mateas and A. Stern},\n title = {Façade: An Experiment in Building a Fully-Realized Interactive Drama},\n year = {2003}\n}\n'}","[{'authorId': '114402462', 'name': 'Michael Mateas'}, {'authorId': '143727207', 'name': 'A. Stern'}]"
1937,a5d522b7d62dbd8ea338c9d34c338ab5cdc436a6,Evaluating a Computational Model of Emotion,,2005.0,61.0,171.0,False,,"{'volume': '11', 'pages': '23-43', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Gratch2005EvaluatingAC,\n author = {J. Gratch and S. Marsella},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {23-43},\n title = {Evaluating a Computational Model of Emotion},\n volume = {11},\n year = {2005}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
1939,a6077fa80467e741bdbbfdcc29003aeefe174179,Modeling crowd emotion from emergent event video,"In emergency situation, mass panic often causes more causalities than the disaster itself. The crowd emotional model could be used to simulate how crowd behavior in emergency scenarios and be helpful for developing crowd evacuation plans in emergency situations. However, existing crowd emotional models usually set model parameters in an empirical manner and are not validated by real cases. In this paper, a crowd emotional model is proposed to simulate the crowd movement in outdoor emergency situations. First of all, the crowd entropy and the movement difference are proposed to describe the emotional impact of the crowd scene on the agents. The perception of vision and hearing are considered, and the calculation formulas of the agent's emotional intensity and crowd emotional contagion are proposed. By calculating individual trajectories in the real video, the cumulative differences between the movements of the real crowd and the corresponding virtual crowd are analyzed. At last, a multi‐parameter optimization method is implemented by the differential evolution algorithm. To verify the parameters in models, three videos which are generated from three real cases, including explosion attack, shooting incident, and crowd disturbance are selected for experimental verification. The results showed that the proposed model could be a feasible method for optimizing parameters to simulate the emergency scenario.",2021.0,36.0,2.0,False,,"{'name': 'Computer Animation and Virtual Worlds', 'volume': '32'}","{'bibtex': '@Article{Zhuo2021ModelingCE,\n author = {Lin Zhuo and Zhen Liu and Tingting Liu and Chih-Chieh Hung and Yanjie Chai},\n booktitle = {Comput. Animat. Virtual Worlds},\n journal = {Computer Animation and Virtual Worlds},\n title = {Modeling crowd emotion from emergent event video},\n volume = {32},\n year = {2021}\n}\n'}","[{'authorId': '2089956568', 'name': 'Lin Zhuo'}, {'authorId': '2109341502', 'name': 'Zhen Liu'}, {'authorId': '91436120', 'name': 'Tingting Liu'}, {'authorId': '2059011525', 'name': 'Chih-Chieh Hung'}, {'authorId': '9398597', 'name': 'Yanjie Chai'}]"
1940,a60bdf04e4f67994f0a095a6fda70e3ace8accad,Hamlet on the Holodeck,,1997.0,0.0,528.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Murray1997HamletOT,\n author = {J. Murray},\n title = {Hamlet on the Holodeck},\n year = {1997}\n}\n'}","[{'authorId': '1715000', 'name': 'J. Murray'}]"
1941,a633ea2875fde8d5d21ebb96611b4d9fc098d605,Optimal feature selection based speech emotion recognition using two‐stream deep convolutional neural network,"Speech signal processing is an active area of research, the most dominant source of exchanging information among human beings, and the best way for human–computer interaction (HCI). Human behavior assessments and emotion recognition from a speech signal, such as speech emotion recognition (SER) is an emerging HCI area of exploration with various real time claims. The performance of an efficient SER system depends on feature learning, which include salient and discriminative information such as high‐level deep features. In this paper, we proposed a two‐stream deep convolutional neural network with an iterative neighborhood component analysis (INCA) to learn mutually spatial‐spectral features and select the most discriminative optimal features for the final prediction. Our model is composed of two channels, and each channel is associated with the convolutional neural network structure to extract cues from the oral signals. The first channel extracts feature from the spectral domain, and the second channel extracts features from the spatial domain, which are then fused and fed to the INCA to remove the severance and select the optimal features for the final model training. The joint refine features are passed from the fully connected network with a softmax classifier to yield the predictions of the different emotions. We trained our proposed system using three benchmarks, which included the EMO‐DB, SAVEE, and RAVDESS emotional speech corpora, and we tested the prediction performance to secure 95%, 82%, and 85% recognition rates. The performance of the system shows the effectiveness and significance of the proposed system.",2021.0,75.0,53.0,True,,"{'volume': '36', 'pages': '5116 - 5135', 'name': 'International Journal of Intelligent Systems'}","{'bibtex': '@Article{Mustaqeem2021OptimalFS,\n author = {Mustaqeem and Soonil Kwon},\n journal = {International Journal of Intelligent Systems},\n pages = {5116 - 5135},\n title = {Optimal feature selection based speech emotion recognition using two‐stream deep convolutional neural network},\n volume = {36},\n year = {2021}\n}\n'}","[{'authorId': '1478898295', 'name': 'Mustaqeem'}, {'authorId': '2111751120', 'name': 'Soonil Kwon'}]"
1942,a6401e102c03a441992b3e45f7b63eec09d4b89d,A Survey on Dialogue Systems: Recent Advances and New Frontiers,"Dialogue systems have attracted more and more attention. Recent advances on dialogue systems are overwhelmingly contributed by deep learning techniques, which have been employed to enhance a wide range of big data applications such as computer vision, natural language processing, and recommender systems. For dialogue systems, deep learning can leverage a massive amount of data to learn meaningful feature representations and response generation strategies, while requiring a minimum amount of hand-crafting. In this article, we give an overview to these recent advances on dialogue systems from various perspectives and discuss some possible research directions. In particular, we generally divide existing dialogue systems into task-oriented and nontask- oriented models, then detail how deep learning techniques help them with representative algorithms and finally discuss some appealing research directions that can bring the dialogue system research into a new frontier",2017.0,133.0,569.0,True,"{'url': 'https://arxiv.org/pdf/1711.01731', 'status': None}","{'volume': 'abs/1711.01731', 'name': 'ArXiv'}","{'bibtex': '@Article{Chen2017ASO,\n author = {Hongshen Chen and Xiaorui Liu and Dawei Yin and Jiliang Tang},\n journal = {ArXiv},\n title = {A Survey on Dialogue Systems: Recent Advances and New Frontiers},\n volume = {abs/1711.01731},\n year = {2017}\n}\n'}","[{'authorId': '2957953', 'name': 'Hongshen Chen'}, {'authorId': '1390612725', 'name': 'Xiaorui Liu'}, {'authorId': '50559722', 'name': 'Dawei Yin'}, {'authorId': '1736632', 'name': 'Jiliang Tang'}]"
1943,a64eeb6f564b5490f9544bd3524c781809238291,Modeling Effects of Behavior Moderators on Performance: Evaluation of the MAMID Methodology and Architecture,"The past five years have witnessed a growth of interest in modeling behavior moderators within cognitive architectures. Incorporating these effects within human behavior models driving training simulations is essential for producing more realistic simulated agent performance and improved training. We describe a methodology for modeling a broad range of interacting behavior moderators in terms of architecture parameters, and a cognitive architecture that implements this methodology. We then present results of an evaluation experiment that demonstrates the architecture’s ability to produce observable behavior differences resulting from distinct individual profiles. The demonstration illustrates distinct behaviors of three types of commanders (‘normal’, ‘anxious’, and ‘aggressive’) within a simulated Stability and Support Operations scenario.",2015.0,4.0,13.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hudlicka2015ModelingEO,\n author = {E. Hudlicka},\n title = {Modeling Effects of Behavior Moderators on Performance: Evaluation of the MAMID Methodology and Architecture},\n year = {2015}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
1944,a655bfdc6917c387aab364a7316c88f4a884409c,The Effects of Robot’s Facial Expressions on Children’s First Impressions of Trustworthiness,"Facial expressions of emotions influence the perception of robots in first encounters. People can judge trustworthiness, likability, and aggressiveness in a few milliseconds by simply observing other individuals’ faces. While first impressions have been extensively studied in adult-robot interaction, they have been addressed in child-robot interaction only rarely. This knowledge is crucial, as the first impression children build of robots might influence their willingness to interact with them over extended periods of time, for example in applications where robots play the role of companions or tutors. The present study focuses on investigating the effects of facial expressions of emotions on children’s perceptions of trust towards robots during first encounters. We constructed a set of facial expressions of happiness and anger varying in terms of intensity. We implemented these facial expressions onto a Furhat robot that was either male-like or female-like. 129 children were exposed to the robot’s expressions for a few seconds. We asked them to evaluate the robot in terms of trustworthiness, likability, and competence and investigated how emotion type, emotion intensity, and gender-likeness affected the perception of the robot. Results showed that a few seconds are enough for children to make a trait inference based on the robot’s emotion. We observed that emotion type, emotion intensity, and gender-likeness did not directly affect trust, but the perception of likability and competence of the robot served as facilitator to judge trustworthiness.",2020.0,39.0,24.0,True,"{'url': 'http://uu.diva-portal.org/smash/get/diva2:1513868/FULLTEXT02', 'status': None}","{'pages': '165-171', 'name': '2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)'}","{'bibtex': '@Article{Calvo-Barajas2020TheEO,\n author = {Natalia Calvo-Barajas and G. Perugia and Ginevra Castellano},\n journal = {2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},\n pages = {165-171},\n title = {The Effects of Robot’s Facial Expressions on Children’s First Impressions of Trustworthiness},\n year = {2020}\n}\n'}","[{'authorId': '2052028871', 'name': 'Natalia Calvo-Barajas'}, {'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
1945,a662d1af0f936c31072c2c1611687c624fd9414c,Linguistic modelling and language-processing technologies for Avatar-based sign language presentation,,2008.0,35.0,151.0,False,,"{'volume': '6', 'pages': '375-391', 'name': 'Universal Access in the Information Society'}","{'bibtex': '@Article{Elliott2008LinguisticMA,\n author = {R. Elliott and J. Glauert and R. Kennaway and I. Marshall and É. Sáfár},\n journal = {Universal Access in the Information Society},\n pages = {375-391},\n title = {Linguistic modelling and language-processing technologies for Avatar-based sign language presentation},\n volume = {6},\n year = {2008}\n}\n'}","[{'authorId': '33877256', 'name': 'R. Elliott'}, {'authorId': '1740734', 'name': 'J. Glauert'}, {'authorId': '7250309', 'name': 'R. Kennaway'}, {'authorId': '143818308', 'name': 'I. Marshall'}, {'authorId': '47569307', 'name': 'É. Sáfár'}]"
1946,a66a8783e249b1a253823023f3488a32e840d7ec,The impact of agent facial mimicry on social behavior in a prisoner's dilemma,"A long tradition of research suggests a relationship between emotional mimicry and pro-social behavior, but the nature of this relationship is unclear. Does mimicry cause rapport and cooperation, or merely reflect it? Virtual humans can provide unique insights into these social processes by allowing unprecedented levels of experimental control. In a 2 x 2 factorial design, we examined the impact of facial mimicry and counter-mimicry in the iterated prisoner's dilemma. Participants played with an agent that copied their smiles and frowns or one that showed the opposite pattern -- i.e., that frowned when they smiled. As people tend to smile more than frown, we independently manipulated the contingency of expressions to ensure any effects are due to mimicry alone, and not the overall positivity/negativity of the agent: i.e., participants saw either a reflection of their own expressions or saw the expressions shown to a previous participant. Results show that participants smiled significantly more when playing an agent that mimicked them. Results also show a complex association between smiling, feelings of rapport, and cooperation. We discuss the implications of these findings on virtual human systems and theories of cooperation.",2018.0,31.0,12.0,False,,{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': ""@Article{Hoegen2018TheIO,\n author = {Rens Hoegen and J. Schalk and Gale M. Lucas and J. Gratch},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {The impact of agent facial mimicry on social behavior in a prisoner's dilemma},\n year = {2018}\n}\n""}","[{'authorId': '2065815350', 'name': 'Rens Hoegen'}, {'authorId': '47871040', 'name': 'J. Schalk'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
1947,a68fff5d07699b33af739e88c59ff5b0dd4ee874,"The jackknife, the bootstrap, and other resampling plans","The Jackknife Estimate of Bias The Jackknife Estimate of Variance Bias of the Jackknife Variance Estimate The Bootstrap The Infinitesimal Jackknife The Delta Method and the Influence Function Cross-Validation, Jackknife and Bootstrap Balanced Repeated Replications (Half-Sampling) Random Subsampling Nonparametric Confidence Intervals.",1987.0,1.0,7228.0,True,"{'url': 'https://epubs.siam.org/doi/pdf/10.1137/1.9781611970319.fm', 'status': None}","{'volume': '', 'pages': '987', 'name': ''}","{'bibtex': '@Inproceedings{Efron1987TheJT,\n author = {B. Efron},\n pages = {987},\n title = {The jackknife, the bootstrap, and other resampling plans},\n year = {1987}\n}\n'}","[{'authorId': '2550392', 'name': 'B. Efron'}]"
1948,a6b124cf9654532c8af5f3dad697cec08f55b626,Facial emotion recognition in schizophrenia: intensity effects and error pattern.,"OBJECTIVE
The authors used color photographs of emotional and neutral expressions to investigate recognition patterns of five universal emotions in schizophrenia.


METHOD
Twenty-eight stable outpatients with schizophrenia (19 men and nine women) and 61 healthy subjects (29 men and 32 women) completed an emotion discrimination test that presented mild and extreme intensities of happy, sad, angry, fearful, disgusted, and neutral faces, balanced for gender and ethnicity. Analyses evaluated accuracy of identifying emotions as a function of intensity, diagnosis, and gender of poser and rater.


RESULTS
Patients performed worse than comparison subjects on recognition of all emotions and neutral faces combined, including mild and extreme expressions. For specific emotions, patients performed worse on recognition of fearful, disgusted, and neutral expressions. For all emotions except disgust, recognition of extreme intensity was better than recognition of mild intensity. However, patients showed less benefit from increased intensity for all emotions combined, and the difference was most pronounced for fear. Thus, patients were more impaired than healthy comparison subjects in identifying high-intensity expressions, even though this was an easier task than identifying low-intensity expressions. In the comparison of patterns of errors, patients and healthy subjects differed only in misattributions of neutral expressions; patients overattributed disgusted expressions and underattributed happy expressions.


CONCLUSIONS
Patients with schizophrenia were impaired in overall emotion recognition, particularly fear and disgust, and did not benefit from increased emotional intensity. Error patterns indicate that patients misidentified neutral cues as negatively valenced.",2003.0,40.0,752.0,False,,"{'volume': '160 10', 'pages': '\n          1768-74\n        ', 'name': 'The American journal of psychiatry'}","{'bibtex': '@Article{Kohler2003FacialER,\n author = {C. Kohler and T. Turner and W. Bilker and C. Brensinger and S. Siegel and S. Kanes and R. Gur and R. Gur},\n journal = {The American journal of psychiatry},\n pages = {\n          1768-74\n        },\n title = {Facial emotion recognition in schizophrenia: intensity effects and error pattern.},\n volume = {160 10},\n year = {2003}\n}\n'}","[{'authorId': '31936404', 'name': 'C. Kohler'}, {'authorId': '144898011', 'name': 'T. Turner'}, {'authorId': '3038423', 'name': 'W. Bilker'}, {'authorId': '2777419', 'name': 'C. Brensinger'}, {'authorId': '2213138', 'name': 'S. Siegel'}, {'authorId': '5394758', 'name': 'S. Kanes'}, {'authorId': '2406788', 'name': 'R. Gur'}, {'authorId': '144762538', 'name': 'R. Gur'}]"
1949,a6b136a13f0b3122ef62d687038b174eca74d1a3,Four systems for emotion activation: cognitive and noncognitive processes.,"The significant role of emotions in evolution and adaptation suggests that there must be more than 1 mechanism for generating them. Nevertheless, much of current emotion theory focuses on cognitive processes (appraisal, attribution, and construal) as the sole, or primary, means of eliciting emotions. As an alternative to this position, the present model describes 4 types of emotion-activating systems, 3 of which involve noncognitive information processing. From an evolutionary-developmental perspective, the systems maybe viewed as a loosely organized hierarchical arrangement, with neural systems, the simplest and most rapid, at the base and cognitive systems, the most complex and versatile, at the top. The emotion-activating systems operate under a number of constraints, including genetically influenced individual differences. The hierarchical organization of the systems for generating emotions provides an adaptive advantage.",1993.0,208.0,787.0,False,,"{'volume': '100 1', 'pages': '\n          68-90\n        ', 'name': 'Psychological review'}","{'bibtex': '@Article{Izard1993FourSF,\n author = {C. Izard},\n journal = {Psychological review},\n pages = {\n          68-90\n        },\n title = {Four systems for emotion activation: cognitive and noncognitive processes.},\n volume = {100 1},\n year = {1993}\n}\n'}","[{'authorId': '38430881', 'name': 'C. Izard'}]"
1950,a6bb5f963fd47831df1ccd587f84fb82d86ce62c,The Emotions,,1882.0,0.0,4622.0,False,,"{'volume': '29', 'pages': '318 - 318', 'name': ""Hall's Journal of Health""}","{'bibtex': ""@Article{Stainer1882TheE,\n author = {John Stainer},\n journal = {Hall's Journal of Health},\n pages = {318 - 318},\n title = {The Emotions},\n volume = {29},\n year = {1882}\n}\n""}","[{'authorId': '2262139257', 'name': 'John Stainer'}]"
1951,a6cb366736791bcccc5c8639de5a8f9636bf87e8,Adam: A Method for Stochastic Optimization,"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",2014.0,26.0,127688.0,False,,"{'volume': 'abs/1412.6980', 'name': 'CoRR'}","{'bibtex': '@Article{Kingma2014AdamAM,\n author = {Diederik P. Kingma and Jimmy Ba},\n journal = {CoRR},\n title = {Adam: A Method for Stochastic Optimization},\n volume = {abs/1412.6980},\n year = {2014}\n}\n'}","[{'authorId': '1726807', 'name': 'Diederik P. Kingma'}, {'authorId': '2503659', 'name': 'Jimmy Ba'}]"
1952,a6e6e3cd94d1cf481ff73eb3bcf885bec1ce442a,"Emotion regulation in interpersonal problems: the role of cognitive-emotional complexity, emotion regulation goals, and expressivity.","Young, middle-aged, and older adults' emotion regulation strategies in interpersonal problems were examined. Participants imagined themselves in anger- or sadness-eliciting situations with a close friend. Factor analyses of a new questionnaire supported a 4-factor model of emotion regulation strategies, including passivity, expressing emotions, seeking emotional information or support, and solving the problem. Results suggest that age differences in emotion regulation (such as older adults' increased endorsement of passive emotion regulation relative to young adults) are partially due to older adults' decreased ability to integrate emotion and cognition, increased prioritization of emotion regulation goals, and decreased tendency to express anger.",2008.0,45.0,111.0,False,,"{'volume': '23 1', 'pages': '\n          39-51\n        ', 'name': 'Psychology and aging'}","{'bibtex': '@Article{Coats2008EmotionRI,\n author = {A. H. Coats and F. Blanchard-Fields},\n journal = {Psychology and aging},\n pages = {\n          39-51\n        },\n title = {Emotion regulation in interpersonal problems: the role of cognitive-emotional complexity, emotion regulation goals, and expressivity.},\n volume = {23 1},\n year = {2008}\n}\n'}","[{'authorId': '5373056', 'name': 'A. H. Coats'}, {'authorId': '1401641948', 'name': 'F. Blanchard-Fields'}]"
1953,a701c66c3777e88e0cd58544ff40e4fb6e70cae5,Usability and acceptability assessment of an empathic virtual agent to prevent major depression,"In Human–Computer Interaction, the adaptation of the content and the way of how this content is communicated to the users in interactive sessions is a critical issue to promote the acceptability and usability of any computational system. We present a user‐adapted interactive platform to identify and provide an early intervention for symptoms of depression and suicide. In particular, we describe the work performed to assess users' system acceptability and usability. An empathic Virtual Agent is the main interface with the user, and it has been designed to generate the appropriate dialogues and emotions during the interactions according to the detected user's specific needs. This personalization is based on a dynamic user model nurtured with clinical, demographical and behavioural information. The evaluation was performed with 60 participants from the university community. The obtained results were promising, allowing the execution of a further clinical trial. The system's usability score was 75.7%, and the score of the user‐adapted content and the emotional responses of the Virtual Agent was 70.9%.",2016.0,33.0,29.0,True,"{'url': 'https://riunet.upv.es/bitstream/10251/81732/2/Manuscript_prevendep.pdf', 'status': 'GREEN'}","{'name': 'Expert Systems', 'pages': '297 - 312', 'volume': '33'}","{'bibtex': '@Article{Bresó2016UsabilityAA,\n author = {A. Bresó and J. Martínez-Miranda and C. Botella and R. Baños and J. M. García-Gómez},\n booktitle = {Expert Syst. J. Knowl. Eng.},\n journal = {Expert Systems},\n pages = {297 - 312},\n title = {Usability and acceptability assessment of an empathic virtual agent to prevent major depression},\n volume = {33},\n year = {2016}\n}\n'}","[{'authorId': '3352168', 'name': 'A. Bresó'}, {'authorId': '1398008961', 'name': 'J. Martínez-Miranda'}, {'authorId': '145945543', 'name': 'C. Botella'}, {'authorId': '145562686', 'name': 'R. Baños'}, {'authorId': '1388884721', 'name': 'J. M. García-Gómez'}]"
1954,a74fecf31b725457ea0fdb0b2acfe8a16e71bf30,Automated lip-sync: Background and techniques,"SUMMARY The problem of creating mouth animation synchronized to recorded speech is discussed. Review of a model of speech sound generation indicates that the automatic derivation of mouth movement from a speech soundtrack is a tractable problem. Several automatic lip-sync techniques are compared, and one method is described in detail. In this method a common speech synthesis method, linear prediction, is adapted to provide simple and accurate phoneme recognition. The recognized phonemes are associated with mouth positions to provide keyframes for computer animation of speech. Experience with this technique indicates that automatic lipsync can produce useful results.",1991.0,28.0,105.0,False,,"{'volume': '2', 'pages': '118-122', 'name': 'Comput. Animat. Virtual Worlds'}","{'bibtex': '@Article{Lewis1991AutomatedLB,\n author = {John Lewis},\n journal = {Comput. Animat. Virtual Worlds},\n pages = {118-122},\n title = {Automated lip-sync: Background and techniques},\n volume = {2},\n year = {1991}\n}\n'}","[{'authorId': '2116914412', 'name': 'John Lewis'}]"
1955,a7820a1327396ce448b8e65f0cdbdfbd005c2c76,Modeling motivations and emotions as a basis for intelligent behavior,"We report on an experiment to implement an autonomous creature situated in a two-dimensional world, that shows various learning and problem-solving capabilities, within the Society of Mind framework. This goal is approached from a developmental perspective, where phases in the experiment correspond broadly to cognitive stages in the development of an infant. This paper describes the first stage, the creature being a newborn whose behavior is strongly driven by motivational states—impulses to action based on bodily needs—and basic emotions—peripheral and cognitive responsestriggered by the recognition of a significant event. Physiological parameters are used to model both concepts, which are seen by analogy with control systems. Motivations drive behavior selection and organization based on the notions of arousal and satiation, and the exploitation principle. Emotions exert further control by sending “hormones” that may affect the intensity of the selected behavior, enable it, or prevent it. They also influence the attentional and perception mechanisms.",1997.0,18.0,351.0,False,,{'pages': '148-155'},"{'bibtex': '@Inproceedings{Cañamero1997ModelingMA,\n author = {Dolores Cañamero},\n pages = {148-155},\n title = {Modeling motivations and emotions as a basis for intelligent behavior},\n year = {1997}\n}\n'}","[{'authorId': '1719487', 'name': 'Dolores Cañamero'}]"
1956,a789638e61c6241cab757231f1ce234cb2b96a79,Emotion regulation: Conceptual foundations,,2007.0,79.0,3176.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gross2007EmotionRC,\n author = {J. Gross and Ross A. Thompson},\n title = {Emotion regulation: Conceptual foundations},\n year = {2007}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}, {'authorId': '2246294034', 'name': 'Ross A. Thompson'}]"
1957,a79d2fefeb292241d1612318c264e342b807684c,Is the wolf angry or... just hungry?,"In this paper we will discuss different types of control over synthetic characters in interactive stories. We will argue that, to attain a deeper and more engaging control, in certain conditions, users should be able to inspect, disclose, and modify the characters minds. To illustrate this idea, we will present a collaborative virtual environment called {\it Teatrix}, designed for children to build their own stories - fairy tales. In {\it Teatrix}, virtual actors play roles (such as: villain, hero, etc.) and may be controlled either by children or by the system. {\it Teatrix} allows children to go into the minds of the characters through a special tool named {\it “Hot Seating”}. {\it Teatrix} is already in use by children ages between 7 and 9 in the context of a Computer integrated Classroom (CiC) scenario installed in a school. The initial evaluations show that the use of the “Hot Seatin” tool is a fundamental element for children to feel in control of their characters and thus stay in character for their virtual performances.",2001.0,15.0,29.0,False,,{'pages': '370-376'},"{'bibtex': '@Inproceedings{Alexandre2001IsTW,\n author = {I. Alexandre and Ana Paiva and R. Prada},\n pages = {370-376},\n title = {Is the wolf angry or... just hungry?},\n year = {2001}\n}\n'}","[{'authorId': '3452275', 'name': 'I. Alexandre'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '143825592', 'name': 'R. Prada'}]"
1958,a7bb9a6327ad78764d8c8231e03b5738031c6142,Beliefs about the nonverbal expression of social power,,2005.0,43.0,269.0,False,,"{'volume': '29', 'pages': '105-123', 'name': 'Journal of Nonverbal Behavior'}","{'bibtex': '@Article{Carney2005BeliefsAT,\n author = {D. Carney and Judith A. Hall and Lavonia Smith Lebeau},\n journal = {Journal of Nonverbal Behavior},\n pages = {105-123},\n title = {Beliefs about the nonverbal expression of social power},\n volume = {29},\n year = {2005}\n}\n'}","[{'authorId': '38584363', 'name': 'D. Carney'}, {'authorId': '47355138', 'name': 'Judith A. Hall'}, {'authorId': '6475231', 'name': 'Lavonia Smith Lebeau'}]"
1959,a7c2015a2f40e3cbcc84a6dd7807e8e41934885f,Pedagogical Agent Gestures to Improve Learner Comprehension of Abstract Concepts in Hints,"In most Intelligent Tutoring Systems, the help messages hints are not very clear for students as they are only presented textually and have little connection with the task elements. This can lead to students' undesired behaviors, like gaming the system, associated with low performance. In this paper, the authors aim at evaluating if the gestures of an animated pedagogical agent to explain hints related to equation solving improves the students' understanding of these help messages. With this goal, they developed an animated pedagogical agent that uses gestures coupled with messages to explain hints in an algebra tutor. The authors performed a qualitative pilot study with four students to verify the impact of using gestures by the animated pedagogical agent on the comprehension of the hints, using two different versions of the system. The difference between these versions was the availability of gestures by the agent. The results showed that students understood the hints provided by the agent more correctly when they were coupled with agent's gesture. Furthermore, they also preferred using the tutor version with gestures.",2016.0,25.0,2.0,False,,"{'volume': '12', 'pages': '65-75', 'name': 'Int. J. Inf. Commun. Technol. Educ.'}","{'bibtex': '@Article{Martins2016PedagogicalAG,\n author = {Igor Martins and Felipe de Morais and Bruno Schaab and P. Jaques},\n journal = {Int. J. Inf. Commun. Technol. Educ.},\n pages = {65-75},\n title = {Pedagogical Agent Gestures to Improve Learner Comprehension of Abstract Concepts in Hints},\n volume = {12},\n year = {2016}\n}\n'}","[{'authorId': '2055147796', 'name': 'Igor Martins'}, {'authorId': '2072191453', 'name': 'Felipe de Morais'}, {'authorId': '2080539953', 'name': 'Bruno Schaab'}, {'authorId': '2179453', 'name': 'P. Jaques'}]"
1960,a7c248280200ba9b43c49076c761f0605083a0cd,Context-Aware Computing Applications,"This paper describes systems that examine and react to an individual's changing context. Such systems can promote and mediate people's interactions with devices, computers, and other people, and they can help navigate unfamiliar places. We believe that a limited amount of information covering a person's proximate environment is most important for this form of computing since the interesting part of the world around us is what we can see, hear, and touch. In this paper we define context-aware computing, and describe four catagories of context-aware applications: proximate selection, automatic contextual reconfiguration, contextual information and commands, and contex-triggered actions. Instances of these application types have been prototyped on the PARCTAB, a wireless, palm-sized computer.",1994.0,22.0,3895.0,False,,"{'pages': '85-90', 'name': '1994 First Workshop on Mobile Computing Systems and Applications'}","{'bibtex': '@Article{Schilit1994ContextAwareCA,\n author = {Bill N. Schilit and N. Adams and R. Want},\n journal = {1994 First Workshop on Mobile Computing Systems and Applications},\n pages = {85-90},\n title = {Context-Aware Computing Applications},\n year = {1994}\n}\n'}","[{'authorId': '1711856', 'name': 'Bill N. Schilit'}, {'authorId': '152926444', 'name': 'N. Adams'}, {'authorId': '1802351', 'name': 'R. Want'}]"
1961,a7cce524b3949a017e9b9a898b85034c566f3306,A multilayer personality model,"Virtual humans have been the focus of computer graphics research for several years now. The amalgamation of computer graphics and artificial intelligence has lead to the possibility of creating believable virtual personalities. The focus has shifted from modeling and animation towards imparting personalities to virtual humans. The aim is to create virtual humans that can interact spontaneously using a natural language, emotions and gestures. This paper discusses a system that allows the design of personality for emotional virtual human. We adopt the Five Factor Model (FFM) of personality from psychology studies. To realize the model, we use Bayesian Belief Network. We introduce a layered approach for modeling personality, moods and emotions. In order to demonstrate a virtual human with emotional personality, we integrate the system into a chat application. Thus, the system enables the developer to design and implement personalities and enables the user to interact with them.",2002.0,13.0,232.0,False,,{'pages': '107-115'},"{'bibtex': '@Inproceedings{Kshirsagar2002AMP,\n author = {S. Kshirsagar},\n pages = {107-115},\n title = {A multilayer personality model},\n year = {2002}\n}\n'}","[{'authorId': '144243072', 'name': 'S. Kshirsagar'}]"
1963,a7d93c24abf6e5b1e2789eccc6d5422a49b587f6,Effectiveness of social stories for children with autism: A comprehensive review,,2019.0,44.0,5.0,False,,{'name': 'Technology and Disability'},"{'bibtex': '@Article{Aldabas2019EffectivenessOS,\n author = {Rashed Aldabas},\n journal = {Technology and Disability},\n title = {Effectiveness of social stories for children with autism: A comprehensive review},\n year = {2019}\n}\n'}","[{'authorId': '73104970', 'name': 'Rashed Aldabas'}]"
1964,a7d96a2cdf7710b95342868f2b1fdb00223e7f4e,The Influence of Avatar Representation and Behavior on Communication in Social Immersive Virtual Environments,"Virtual reality applications have begun to offer great potential for communication in recent years. Creating an immersive virtual social environment that simulates a real social environment requires providing users with communication cues such as visual, verbal, and nonverbal cues to increase their sense of inhabiting the virtual world. In this work, we will investigate the influence of avatar representation and behavior on communication in an immersive, multiuser, same-place virtual environment by comparing three conditions of avatar representation: video see-through, scanned realistic avatar, and no-avatar representations. Subjective and objective measurements will be used to describe participants' observations and track their movement behavior to ascertain the effect of avatar representations on communication, based on personal presence, social presence, and trustworthiness.",2018.0,6.0,12.0,False,,"{'pages': '823-824', 'name': '2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)'}","{'bibtex': '@Article{Aseeri2018TheIO,\n author = {Sahar A. Aseeri and V. Interrante},\n journal = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},\n pages = {823-824},\n title = {The Influence of Avatar Representation and Behavior on Communication in Social Immersive Virtual Environments},\n year = {2018}\n}\n'}","[{'authorId': '2892331', 'name': 'Sahar A. Aseeri'}, {'authorId': '1785908', 'name': 'V. Interrante'}]"
1965,a7feb91dc40c2050c62b97aaccb107e989681121,Defining Presence,,2015.0,0.0,69.0,False,,{'pages': '13-34'},"{'bibtex': '@Inproceedings{Lombard2015DefiningP,\n author = {M. Lombard and Matthew T. Jones},\n pages = {13-34},\n title = {Defining Presence},\n year = {2015}\n}\n'}","[{'authorId': '37189009', 'name': 'M. Lombard'}, {'authorId': '2111036238', 'name': 'Matthew T. Jones'}]"
1966,a83d537259865df30f748e7dbc30b72ff0ea4731,More than mere mimicry? The influence of emotion on rapid facial reactions to faces.,"Within a second of seeing an emotional facial expression, people typically match that expression. These rapid facial reactions (RFRs), often termed mimicry, are implicated in emotional contagion, social perception, and embodied affect, yet ambiguity remains regarding the mechanism(s) involved. Two studies evaluated whether RFRs to faces are solely nonaffective motor responses or whether emotional processes are involved. Brow (corrugator, related to anger) and forehead (frontalis, related to fear) activity were recorded using facial electromyography (EMG) while undergraduates in two conditions (fear induction vs. neutral) viewed fear, anger, and neutral facial expressions. As predicted, fear induction increased fear expressions to angry faces within 1000 ms of exposure, demonstrating an emotional component of RFRs. This did not merely reflect increased fear from the induction, because responses to neutral faces were unaffected. Considering RFRs to be merely nonaffective automatic reactions is inaccurate. RFRs are not purely motor mimicry; emotion influences early facial responses to faces. The relevance of these data to emotional contagion, autism, and the mirror system-based perspectives on imitation is discussed.",2007.0,67.0,225.0,False,,"{'volume': '7 2', 'pages': '\n          447-57\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Moody2007MoreTM,\n author = {E. Moody and D. McIntosh and Laura J Mann and Kimberly R Weisser},\n journal = {Emotion},\n pages = {\n          447-57\n        },\n title = {More than mere mimicry? The influence of emotion on rapid facial reactions to faces.},\n volume = {7 2},\n year = {2007}\n}\n'}","[{'authorId': '48254408', 'name': 'E. Moody'}, {'authorId': '21464189', 'name': 'D. McIntosh'}, {'authorId': '2062750330', 'name': 'Laura J Mann'}, {'authorId': '40520042', 'name': 'Kimberly R Weisser'}]"
1967,a8546edc5732b971fefc302bacdf496b409e1880,Matching robot appearance and behavior to tasks to improve human-robot cooperation,"A robot's appearance and behavior provide cues to the robot's abilities and propensities. We hypothesize that an appropriate match between a robot's social cues and its task improve the people's acceptance of and cooperation with the robot. In an experiment, people systematically preferred robots for jobs when the robot's humanlikeness matched the sociability required in those jobs. In two other experiments, people complied more with a robot whose demeanor matched the seriousness of the task.",2003.0,28.0,773.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Matching_Robot_Appearance_and_Behavior_to_Tasks_to_Improve_Human-Robot_Cooperation/6470249/1/files/11898803.pdf', 'status': None}","{'pages': '55-60', 'name': 'The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.'}","{'bibtex': '@Article{Goetz2003MatchingRA,\n author = {Jennifer Goetz and Sara Kiesler and Aaron Powers},\n journal = {The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.},\n pages = {55-60},\n title = {Matching robot appearance and behavior to tasks to improve human-robot cooperation},\n year = {2003}\n}\n'}","[{'authorId': '40533864', 'name': 'Jennifer Goetz'}, {'authorId': '2070796426', 'name': 'Sara Kiesler'}, {'authorId': '2063989220', 'name': 'Aaron Powers'}]"
1968,a8705ab7b1471ff2d76af84b7b3540e38e4c83dd,An Accessible Toolkit for the Creation of Socio-EmotionalAgents,"FAtiMA Toolkit is a collection of open-source tools that is designed to facilitate the creation and use of cognitive agents with socioemotional skills. The toolkit was developed with a focus on accessibility so it could be used by both researchers and game developers. It provides a computational model of emotions that is based on the OCC appraisal theory as well as an explicit dialogue structure that is familiar to game developers while maintaining the flexibility of an approach based on autonomous agents. Among various use cases, the toolkit has been successfully applied by an external game studio in their development of two serious games.",2019.0,9.0,7.0,False,,{'pages': '2357-2359'},"{'bibtex': '@Inproceedings{Guimarães2019AnAT,\n author = {Manuel Guimarães and S. Mascarenhas and R. Prada and P. A. Santos and João Dias},\n pages = {2357-2359},\n title = {An Accessible Toolkit for the Creation of Socio-EmotionalAgents},\n year = {2019}\n}\n'}","[{'authorId': '28004507', 'name': 'Manuel Guimarães'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145255182', 'name': 'P. A. Santos'}, {'authorId': '2151066261', 'name': 'João Dias'}]"
1969,a889d242f3136db159bb5384d4dbc8b9c1f7cf71,A measure of emotional empathy.,,1972.0,14.0,2353.0,False,,"{'volume': '40 4', 'pages': '\n          525-43\n        ', 'name': 'Journal of personality'}","{'bibtex': '@Article{Mehrabian1972AMO,\n author = {A. Mehrabian and N. Epstein},\n journal = {Journal of personality},\n pages = {\n          525-43\n        },\n title = {A measure of emotional empathy.},\n volume = {40 4},\n year = {1972}\n}\n'}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}, {'authorId': '47060925', 'name': 'N. Epstein'}]"
1970,a8e8ddde3c2b8a92126e88e56272bcc7af75d40b,Relations between Big Five Traits and Fundamental Motives,"Relations were examined between configurations of Big Five Traits (Extraversion, Agreeableness, Conscientiousness, Neuroticism, Openness to Experience) and 16 fundamental motives (Social Contact, Curiosity, Honor, Power, Order, Idealism, Independence, Status, Vengeance, Romance, Family, Activity, Saving, Acceptance, Eating, Tranquility) in 138 university students (93 women, 45 men; M age = 20.3 yr., SD = 4.5). Big Five traits were measured with the NEO-PI–R and motives were measured with the Reiss Profile of Fundamental Goals and Motivation Sensitivities. The traits were significantly related with all the motives (adjusted R2 = .06 to .43) except Physical Activity. Four motives were related with only one trait and nine configurations of two or more traits were correlated with the remaining 11 motives. Total motive scores across all participants, an index of the strength of overall motivation, were positively correlated with Extraversion and Neuroticism and negatively with Agreeableness.",2004.0,13.0,90.0,False,,"{'volume': '95', 'pages': '795 - 802', 'name': 'Psychological Reports'}","{'bibtex': '@Article{Olson2004RelationsBB,\n author = {Kenneth Ray Olson and D. A. Weber},\n journal = {Psychological Reports},\n pages = {795 - 802},\n title = {Relations between Big Five Traits and Fundamental Motives},\n volume = {95},\n year = {2004}\n}\n'}","[{'authorId': '47400491', 'name': 'Kenneth Ray Olson'}, {'authorId': '2056850820', 'name': 'D. A. Weber'}]"
1971,a8ea40704911fa3e596cf2c0a4ee1399b3768cde,Virtual proxemics: Locomotion in the presence of obstacles in large immersive projection environments,"In this paper, we investigate obstacle avoidance behavior during real walking in a large immersive projection setup. We analyze the walking behavior of users when avoiding real and virtual static obstacles. In order to generalize our study, we consider both anthropomorphic and inanimate objects, each having his virtual and real counterpart. The results showed that users exhibit different locomotion behaviors in the presence of real and virtual obstacles, and in the presence of anthropomorphic and inanimate objects. Precisely, the results showed a decrease of walking speed as well as an increase of the clearance distance (i. e., the minimal distance between the walker and the obstacle) when facing virtual obstacles compared to real ones. Moreover, our results suggest that users act differently due to their perception of the obstacle: users keep more distance when the obstacle is anthropomorphic compared to an inanimate object and when the orientation of anthropomorphic obstacle is from the profile compared to a front position. We discuss implications on future large shared immersive projection spaces.",2015.0,21.0,90.0,True,"{'url': 'https://hal.inria.fr/hal-01149962/file/aobpl15.pdf', 'status': None}","{'pages': '75-80', 'name': '2015 IEEE Virtual Reality (VR)'}","{'bibtex': '@Article{Argelaguet2015VirtualPL,\n author = {F. Argelaguet and A. Olivier and G. Bruder and J. Pettré and A. Lécuyer},\n journal = {2015 IEEE Virtual Reality (VR)},\n pages = {75-80},\n title = {Virtual proxemics: Locomotion in the presence of obstacles in large immersive projection environments},\n year = {2015}\n}\n'}","[{'authorId': '1854224', 'name': 'F. Argelaguet'}, {'authorId': '1851306', 'name': 'A. Olivier'}, {'authorId': '34638348', 'name': 'G. Bruder'}, {'authorId': '2235773', 'name': 'J. Pettré'}, {'authorId': '1693899', 'name': 'A. Lécuyer'}]"
1972,a8f4bf67575c72bee34d806b4a98caaa25982bcf,The effectiveness of virtual reality for people with mild cognitive impairment or dementia: a meta-analysis,,2019.0,64.0,109.0,True,"{'url': 'https://bmcpsychiatry.biomedcentral.com/counter/pdf/10.1186/s12888-019-2180-x', 'status': None}","{'volume': '19', 'name': 'BMC Psychiatry'}","{'bibtex': '@Article{Kim2019TheEO,\n author = {O. Kim and Y. Pang and Jung-Hee Kim},\n journal = {BMC Psychiatry},\n title = {The effectiveness of virtual reality for people with mild cognitive impairment or dementia: a meta-analysis},\n volume = {19},\n year = {2019}\n}\n'}","[{'authorId': '143815380', 'name': 'O. Kim'}, {'authorId': '38957782', 'name': 'Y. Pang'}, {'authorId': '153188133', 'name': 'Jung-Hee Kim'}]"
1973,a9235c88b3d83a5c8b6519227bf29422ae020816,Children with Autism Fail to Orient to Naturally Occurring Social Stimuli,,1998.0,15.0,1069.0,False,,"{'volume': '28', 'pages': '479-485', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Dawson1998ChildrenWA,\n author = {G. Dawson and A. Meltzoff and J. Osterling and J. Rinaldi and Emily Brown},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {479-485},\n title = {Children with Autism Fail to Orient to Naturally Occurring Social Stimuli},\n volume = {28},\n year = {1998}\n}\n'}","[{'authorId': '145862897', 'name': 'G. Dawson'}, {'authorId': '3053914', 'name': 'A. Meltzoff'}, {'authorId': '4329421', 'name': 'J. Osterling'}, {'authorId': '31368850', 'name': 'J. Rinaldi'}, {'authorId': '2072719592', 'name': 'Emily Brown'}]"
1974,a94cce2a48521ed4e1ec6bdb87b6bbf8d6fac505,An interactive virtual audience platform for public speaking training,We have developed an interactive virtual audience platform for public speaking training. Users' public speaking behavior is automatically analyzed using audiovisual sensors. The virtual characters display indirect feedback depending on user's behavior descriptors correlated with public speaking performance. We used the system to collect a dataset of public speaking performances in different training conditions.,2014.0,5.0,32.0,False,,{'pages': '1657-1658'},"{'bibtex': '@Inproceedings{Chollet2014AnIV,\n author = {Mathieu Chollet and Giota Stratou and Ari Shapiro and Louis-Philippe Morency and Stefan Scherer},\n pages = {1657-1658},\n title = {An interactive virtual audience platform for public speaking training},\n year = {2014}\n}\n'}","[{'authorId': '40325099', 'name': 'Mathieu Chollet'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '145109163', 'name': 'Ari Shapiro'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}]"
1975,a963d05b9d4acd347ad528e7d098eb53d8f555a2,Systematic literature reviews in software engineering - A systematic literature review,,2009.0,50.0,2994.0,False,,"{'volume': '51', 'pages': '7-15', 'name': 'Inf. Softw. Technol.'}","{'bibtex': '@Article{Kitchenham2009SystematicLR,\n author = {B. Kitchenham and P. Brereton and D. Budgen and M. Turner and J. Bailey and S. Linkman},\n journal = {Inf. Softw. Technol.},\n pages = {7-15},\n title = {Systematic literature reviews in software engineering - A systematic literature review},\n volume = {51},\n year = {2009}\n}\n'}","[{'authorId': '145968635', 'name': 'B. Kitchenham'}, {'authorId': '145662410', 'name': 'P. Brereton'}, {'authorId': '1896276', 'name': 'D. Budgen'}, {'authorId': '145689630', 'name': 'M. Turner'}, {'authorId': '2067719224', 'name': 'J. Bailey'}, {'authorId': '1700115', 'name': 'S. Linkman'}]"
1976,a96746bf3d7f2ed4a2e2177ef801a55fe8c8c764,Automated cars: Queue discharge at signalized intersections with ‘Assured-Clear-Distance-Ahead’ driving strategies,,2016.0,46.0,40.0,False,,"{'volume': '62', 'pages': '35-54', 'name': 'Transportation Research Part C-emerging Technologies'}","{'bibtex': '@Article{Vine2016AutomatedCQ,\n author = {S. Vine and Xiaobo Liu and F. Zheng and J. Polak},\n journal = {Transportation Research Part C-emerging Technologies},\n pages = {35-54},\n title = {Automated cars: Queue discharge at signalized intersections with ‘Assured-Clear-Distance-Ahead’ driving strategies},\n volume = {62},\n year = {2016}\n}\n'}","[{'authorId': '35757964', 'name': 'S. Vine'}, {'authorId': '2109059532', 'name': 'Xiaobo Liu'}, {'authorId': '39815793', 'name': 'F. Zheng'}, {'authorId': '144325425', 'name': 'J. Polak'}]"
1977,a96ceb51dfc20eb8da42891b68a573b5c88021de,Cooperative customer navigation between robots outside and inside a retail shop—an implementation on the ubiquitous market platform,,2012.0,21.0,18.0,False,,"{'volume': '67', 'pages': '329-340', 'name': 'annals of telecommunications - annales des télécommunications'}","{'bibtex': '@Article{Kamei2012CooperativeCN,\n author = {Koji Kamei and Tetsushi Ikeda and M. Shiomi and Hiroyuki Kidokoro and A. Utsumi and K. Shinozawa and T. Miyashita and N. Hagita},\n journal = {annals of telecommunications - annales des télécommunications},\n pages = {329-340},\n title = {Cooperative customer navigation between robots outside and inside a retail shop—an implementation on the ubiquitous market platform},\n volume = {67},\n year = {2012}\n}\n'}","[{'authorId': '38746416', 'name': 'Koji Kamei'}, {'authorId': '3326975', 'name': 'Tetsushi Ikeda'}, {'authorId': '34656564', 'name': 'M. Shiomi'}, {'authorId': '2064478755', 'name': 'Hiroyuki Kidokoro'}, {'authorId': '1785513', 'name': 'A. Utsumi'}, {'authorId': '3290442', 'name': 'K. Shinozawa'}, {'authorId': '47281633', 'name': 'T. Miyashita'}, {'authorId': '1781078', 'name': 'N. Hagita'}]"
1978,a9adbab6dae28c23a205786c725a988649d155ef,Empathic neural responses are modulated by the perceived fairness of others,,2006.0,34.0,1590.0,True,"{'url': 'https://pure.mpg.de/pubman/item/item_2614250_3/component/file_2621849/RD_Empathic_2006.pdf', 'status': None}","{'volume': '439', 'pages': '466-469', 'name': 'Nature'}","{'bibtex': '@Article{Singer2006EmpathicNR,\n author = {T. Singer and B. Seymour and J. O’Doherty and K. Stephan and R. Dolan and C. Frith},\n journal = {Nature},\n pages = {466-469},\n title = {Empathic neural responses are modulated by the perceived fairness of others},\n volume = {439},\n year = {2006}\n}\n'}","[{'authorId': '47272511', 'name': 'T. Singer'}, {'authorId': '145324953', 'name': 'B. Seymour'}, {'authorId': '101096038', 'name': 'J. O’Doherty'}, {'authorId': '1715046', 'name': 'K. Stephan'}, {'authorId': '2231343', 'name': 'R. Dolan'}, {'authorId': '144155759', 'name': 'C. Frith'}]"
1979,a9f2f40605644a56822e69068a3967eebc7227f5,Automatic Nonverbal Behavior Indicators of Depression and PTSD: Exploring Gender Differences,"In this paper, we show that gender plays an important role in the automatic assessment of psychological conditions such as depression and post-traumatic stress disorder (PTSD). We identify a directly interpretable and intuitive set of predictive indicators, selected from three general categories of nonverbal behaviors: affect, expression variability and motor variability. For the analysis, we introduce a semi-structured virtual human interview dataset which includes 53 video recorded interactions. Our experiments on automatic classification of psychological conditions show that a gender-dependent approach significantly improves the performance over a gender agnostic one.",2013.0,31.0,66.0,False,,"{'pages': '147-152', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Stratou2013AutomaticNB,\n author = {Giota Stratou and Stefan Scherer and J. Gratch and Louis-Philippe Morency},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {147-152},\n title = {Automatic Nonverbal Behavior Indicators of Depression and PTSD: Exploring Gender Differences},\n year = {2013}\n}\n'}","[{'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
1980,aa124a389ab617eedcbd4d33a718e2c1213e25ee,Social VR: How Personal Space is Affected by Virtual Agents' Emotions,"Personal space (PS), the flexible protective zone maintained around oneself, is a key element of everyday social interactions. It, e.g., affects people's interpersonal distance and is thus largely involved when navigating through social environments. However, the PS is regulated dynamically, its size depends on numerous social and personal characteristics and its violation evokes different levels of discomfort and physiological arousal. Thus, gaining more insight into this phenomenon is important. We contribute to the PS investigations by presenting the results of a controlled experiment in a CAVE, focusing on German males in the age of 18 to 30 years. The PS preferences of 27 participants have been sampled while they were approached by either a single embodied, computer-controlled virtual agent (VA) or by a group of three VAs. In order to investigate the influence of a VA's emotions, we altered their facial expression between angry and happy. Our results indicate that the emotion as well as the number of VAs approaching influence the PS: larger distances are chosen to angry VAs compared to happy ones; single VAs are allowed closer compared to the group. Thus, our study is a foundation for social and behavioral studies investigating PS preferences.",2018.0,48.0,50.0,False,,"{'pages': '199-206', 'name': '2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)'}","{'bibtex': ""@Article{Bönsch2018SocialVH,\n author = {A. Bönsch and Sina Radke and H. Overath and L. Asche and J. Wendt and Tom Vierjahn and U. Habel and T. Kuhlen},\n journal = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},\n pages = {199-206},\n title = {Social VR: How Personal Space is Affected by Virtual Agents' Emotions},\n year = {2018}\n}\n""}","[{'authorId': '3249697', 'name': 'A. Bönsch'}, {'authorId': '145880611', 'name': 'Sina Radke'}, {'authorId': '47973447', 'name': 'H. Overath'}, {'authorId': '51243025', 'name': 'L. Asche'}, {'authorId': '39812907', 'name': 'J. Wendt'}, {'authorId': '2824434', 'name': 'Tom Vierjahn'}, {'authorId': '2782974', 'name': 'U. Habel'}, {'authorId': '144483066', 'name': 'T. Kuhlen'}]"
1981,aa1a1db36963841b54fae0213fb90c2144236a71,A Persuasion Dialogue Game based on Commitments and Arguments,"In this paper we propose a new persuasion dialogue game for agent communication. We show how this dialogue game is modeled by a framework based on social commitments and arguments. Called Commitment and Argument Network (CAN), this framework allows us to model communication dynamics in terms of actions that agents apply to commitments and in terms of argumentation relations. This dialogue game is specified by indicating its entry conditions, its dynamics and its exit conditions. In order to solve the problem of the acceptance of arguments, the protocol integrates the concept of agents' trustworthiness in its specification.",2004.0,44.0,7.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bentahar2004APD,\n author = {J. Bentahar and B. Moulin and B. Chaib-draa and Steven R. W. Foy},\n title = {A Persuasion Dialogue Game based on Commitments and Arguments},\n year = {2004}\n}\n'}","[{'authorId': '1812107', 'name': 'J. Bentahar'}, {'authorId': '1727720', 'name': 'B. Moulin'}, {'authorId': '1399443272', 'name': 'B. Chaib-draa'}, {'authorId': '34680332', 'name': 'Steven R. W. Foy'}]"
1982,aa3c4d6799638836d2a20673fb910d64180a6da4,FarmChat: A Conversational Agent to Answer Farmer Queries,"Farmers constitute 54.6% of the Indian population, but earn only 13.9% of the national GDP. This gross mismatch can be alleviated by improving farmers' access to information and expert advice (e.g., knowing which seeds to sow and how to treat pests can significantly impact yield). In this paper, we report our experience of designing a conversational agent, called FarmChat, to meet the information needs of farmers in rural India. We conducted an evaluative study with 34 farmers near Ranchi in India, focusing on assessing the usability of the system, acceptability of the information provided, and understanding the user population's unique preferences, needs, and challenges in using the technology. We performed a comparative study with two different modalities: audio-only and audio+text. Our results provide a detailed understanding on how literacy level, digital literacy, and other factors impact users' preferences for the interaction modality. We found that a conversational agent has the potential to effectively meet the information needs of farmers at scale. More broadly, our results could inform future work on designing conversational agents for user populations with limited literacy and technology experience.",2018.0,54.0,70.0,False,,"{'volume': '2', 'pages': '170:1-170:22', 'name': 'Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.'}","{'bibtex': '@Article{Jain2018FarmChatAC,\n author = {Mohit Jain and Pratyush Kumar and Ishita Bhansali and Q. Liao and K. Truong and Shwetak N. Patel},\n journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},\n pages = {170:1-170:22},\n title = {FarmChat: A Conversational Agent to Answer Farmer Queries},\n volume = {2},\n year = {2018}\n}\n'}","[{'authorId': '2089551047', 'name': 'Mohit Jain'}, {'authorId': '38724234', 'name': 'Pratyush Kumar'}, {'authorId': '66101406', 'name': 'Ishita Bhansali'}, {'authorId': '144921048', 'name': 'Q. Liao'}, {'authorId': '1752847', 'name': 'K. Truong'}, {'authorId': '1701358', 'name': 'Shwetak N. Patel'}]"
1983,aa4d4785ce7426d6bf05954ede6493994b79f04e,The UPPS model of impulsivity in the abuse of Information and Communication Technologies (ICT).,"The UPPS model of impulsivity has recently been proposed, has been widely applied to substance abuse and is one of those recommended in the context of Research Domain Criteria, RDoC. However, its application to the abuse of information and communication technologies (ICTs) has been very limited. In the present work, a sample of n=748 (67% females) was recruited through the Internet, and the reduced version of the UPPS-P was administered, in addition to the MULTICAGE-TIC and the Prefrontal Symptoms Inventory (PSI-20). The psychometric properties of UPPS-P were satisfactory in terms of internal consistency (0.87 > ω > 0.75) and structural validity. Impulsivity measured by UPPS-P correlated with all MULTICAGE-TIC scales, although with a very small effect size, and with greater magnitude with prefrontal dysfunction symptoms. The impulsivity dimension most related to ICT abuse was Urgency (0.3 > r > 0.2). A structural analysis of all the variables was carried out, with impulsivity appearing as a product of the prefrontal malfunction that predicted, through Positive Urgency, the abuse of ICTs. Impulsivity does not seem to be the central nucleus of ICT abuse, but rather failures in the superior control of behavior, of which impulsivity would be a consequence, but not the most important. This makes it advisable to design cognitive rehabilitation interventions that improve the functioning of superior behavior control mechanisms in the prevention and treatment of ICT abuse.",2020.0,69.0,28.0,True,,"{'volume': '0 0', 'pages': '\n          1449\n        ', 'name': 'Adicciones'}","{'bibtex': '@Article{Pérez2020TheUM,\n author = {E. P. Pedrero Pérez and Sara Morales Alonso and Vanesa Gallardo Arriero and Laura Blázquez Rollón and Irene Folguera Expósito and J. M. Ruíz Sánchez de León},\n journal = {Adicciones},\n pages = {\n          1449\n        },\n title = {The UPPS model of impulsivity in the abuse of Information and Communication Technologies (ICT).},\n volume = {0 0},\n year = {2020}\n}\n'}","[{'authorId': '117514512', 'name': 'E. P. Pedrero Pérez'}, {'authorId': '117487197', 'name': 'Sara Morales Alonso'}, {'authorId': '2254240237', 'name': 'Vanesa Gallardo Arriero'}, {'authorId': '2254271378', 'name': 'Laura Blázquez Rollón'}, {'authorId': '2254280051', 'name': 'Irene Folguera Expósito'}, {'authorId': '115276196', 'name': 'J. M. Ruíz Sánchez de León'}]"
1984,aa6be519b394b44ab24c6ad964f8a2c6a9b23571,Consensus and Cooperation in Networked Multi-Agent Systems,"This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. We discuss the connections between consensus problems in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations",2007.0,118.0,9277.0,True,"{'url': 'http://thayer.dartmouth.edu/tr/reports/tr06-004.pdf', 'status': None}","{'volume': '95', 'pages': '215-233', 'name': 'Proceedings of the IEEE'}","{'bibtex': '@Article{Olfati-Saber2007ConsensusAC,\n author = {R. Olfati-Saber and J. Alex Fax and R. Murray},\n journal = {Proceedings of the IEEE},\n pages = {215-233},\n title = {Consensus and Cooperation in Networked Multi-Agent Systems},\n volume = {95},\n year = {2007}\n}\n'}","[{'authorId': '1394237404', 'name': 'R. Olfati-Saber'}, {'authorId': '2226866845', 'name': 'J. Alex Fax'}, {'authorId': '144696890', 'name': 'R. Murray'}]"
1985,aa6c3c0ee2883f90ec97f10e4491e3f02271d861,"Context Aware Joint Modeling of Domain Classification, Intent Detection and Slot Filling with Zero-Shot Intent Detection Approach",,2021.0,1.0,2.0,False,,{'pages': '582-595'},"{'bibtex': '@Inproceedings{Priya2021ContextAJ,\n author = {N. Priya and Abhisek Tiwari and S. Saha},\n pages = {582-595},\n title = {Context Aware Joint Modeling of Domain Classification, Intent Detection and Slot Filling with Zero-Shot Intent Detection Approach},\n year = {2021}\n}\n'}","[{'authorId': '2106126217', 'name': 'N. Priya'}, {'authorId': '2063522518', 'name': 'Abhisek Tiwari'}, {'authorId': '145470045', 'name': 'S. Saha'}]"
1986,aa88bf03209db2df8f0e30d30095e1c2449e930d,The effect of dynamics on identifying basic emotions from synthetic and natural faces,,2008.0,59.0,96.0,False,,"{'volume': '66', 'pages': '233-242', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Kätsyri2008TheEO,\n author = {J. Kätsyri and M. Sams},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {233-242},\n title = {The effect of dynamics on identifying basic emotions from synthetic and natural faces},\n volume = {66},\n year = {2008}\n}\n'}","[{'authorId': '48160993', 'name': 'J. Kätsyri'}, {'authorId': '2556968', 'name': 'M. Sams'}]"
1987,aa9e7ceb55cae5e8667a0ca19d226e00dd172afe,Show Me or Tell Me: Designing Avatars for Feedback,"Avatarscanbeemployedasamotivationaltool,forexample,allowingnon-verbalcommunicationthat can be close to human communication. We describe two lab studies where we presented participants with avatars that communicated verbally via text and visually via expressions. In the first study, participants rated five different categories of captions and corresponding avatars. Results showed that the most persuasive, consistent and trustworthy verbal feedback was given in a humanized form. The second study was an exhaustive forced choice experiment where participants chose the happiest avatar from a pair displayed. Results showed participants found visual avatars more expressive and easier to understand than their verbal counterparts, and that users respond differently when presented with negative or positive emotions. This paper contributes to a better understanding of how to design feedback for expressive avatars.",2015.0,42.0,19.0,False,,"{'volume': '27', 'pages': '458-469', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Scott2015ShowMO,\n author = {Michelle Scott and Lucas Pereira and Ian Oakley},\n journal = {Interact. Comput.},\n pages = {458-469},\n title = {Show Me or Tell Me: Designing Avatars for Feedback},\n volume = {27},\n year = {2015}\n}\n'}","[{'authorId': '2067726616', 'name': 'Michelle Scott'}, {'authorId': '145850235', 'name': 'Lucas Pereira'}, {'authorId': '145902847', 'name': 'Ian Oakley'}]"
1988,aaa695ca2b79985d66dbcabbbe792af423da58e4,The influence of mood on the intensity of emotional responses: Disentangling feeling and knowing,"The results of three experiments suggest that pre-existing mood increases the intensity of affectively congruent emotions while dampening the intensity of incongruent emotions independent of attributional knowledge. This result was obtained using a new method for inducing mood states unobtrusively and with minimal or no cognitive concomitants. The results of Experiment 1 revealed that for participants who were exposed to positive feedback a pre-existing positive mood led to stronger feelings of pride in comparison to negative mood. The results of Experiments 2 and 3 suggest that pre-existing mood directly influences the experience of subsequently elicited emotions independent of what one knows about the causes of this feeling. When participants were required to differentiate between the funniness of a cartoon and their subjective humour response, mood influenced only the latter judgement (Experiment 2). In Experiment 3, reminding participants of the mood induction resulted in a contrast effect in judging the funniness of a cartoon. However, the pre-existing mood continued to exert an assimilation effect on the overt mirth response. In conclusion, these results suggest that the feeling and knowledge component are partly independent bases of emotional responses.",2001.0,43.0,89.0,False,,"{'volume': '15', 'pages': '725 - 747', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Neumann2001TheIO,\n author = {Roland Neumann and Beate Seibt and F. Strack},\n journal = {Cognition and Emotion},\n pages = {725 - 747},\n title = {The influence of mood on the intensity of emotional responses: Disentangling feeling and knowing},\n volume = {15},\n year = {2001}\n}\n'}","[{'authorId': '47921749', 'name': 'Roland Neumann'}, {'authorId': '2848483', 'name': 'Beate Seibt'}, {'authorId': '4574442', 'name': 'F. Strack'}]"
1989,aadb364df890b00b16164ea161003e0039057c0d,Normative observations on neuropsychological test performances in old age.,"As part of a study of dementia, 162 normal volunteers in the age range of 65-84 years were given a battery of nine neuropsychological tests assessing temporal orientation, short-term memory, language functions, and visuoperceptive capacity. When compared to subjects less than 65 years of age, the groups showed little evidence of generalized decline in cognitive function before the age of 80 years. The 80-84 years subgroup showed a higher overall failure rate on the tests than the younger subgroups. Nevertheless, 70% of all subjects in the 80-84 years subgroup made no more than one failure on the nine tests. There were substantial differences among the tests in respect to their sensitivity to the effects of aging. The largest decline in performance was shown on tests of short-term visual memory, serial digit learning, and facial recognition. The other verbal, memory, and visuoperceptive tests were performed well up to the age of 80 years. The findings are interpreted as providing limited support for the hypothesis that normal aging does not necessarily involve a general decline in level of cognitive functioning. The clinical application of the tests that were sensitive or insensitive to the effects of aging is considered.",1981.0,20.0,217.0,False,,"{'volume': '3 1', 'pages': '\n          33-42\n        ', 'name': 'Journal of clinical neuropsychology'}","{'bibtex': '@Article{Benton1981NormativeOO,\n author = {A. Benton and P. Eslinger and A. Damasio},\n journal = {Journal of clinical neuropsychology},\n pages = {\n          33-42\n        },\n title = {Normative observations on neuropsychological test performances in old age.},\n volume = {3 1},\n year = {1981}\n}\n'}","[{'authorId': '2203961', 'name': 'A. Benton'}, {'authorId': '5231695', 'name': 'P. Eslinger'}, {'authorId': '2656777', 'name': 'A. Damasio'}]"
1990,aae78eafd6b1a653344c5e8e51a440f86e2658e6,The structural and functional connectivity of the amygdala: From normal emotion to pathological anxiety,,2011.0,130.0,766.0,True,"{'url': 'https://europepmc.org/articles/pmc3119771?pdf=render', 'status': None}","{'volume': '223', 'pages': '403-410', 'name': 'Behavioural Brain Research'}","{'bibtex': '@Article{Kim2011TheSA,\n author = {Justin Kim and R. Loucks and Amy L. Palmer and Annemarie C. Brown and Kimberly M. Solomon and shley N. Marchante and P. Whalen},\n journal = {Behavioural Brain Research},\n pages = {403-410},\n title = {The structural and functional connectivity of the amygdala: From normal emotion to pathological anxiety},\n volume = {223},\n year = {2011}\n}\n'}","[{'authorId': '2231651440', 'name': 'Justin Kim'}, {'authorId': '5421549', 'name': 'R. Loucks'}, {'authorId': '4879547', 'name': 'Amy L. Palmer'}, {'authorId': '6502685', 'name': 'Annemarie C. Brown'}, {'authorId': '1396511145', 'name': 'Kimberly M. Solomon'}, {'authorId': '2231277788', 'name': 'shley N. Marchante'}, {'authorId': '1869485', 'name': 'P. Whalen'}]"
1991,aaff3d3da7d8b18cc5d9f85d5b1af63ec174fe84,The Perception of Emotion in Artificial Agents,"Given recent technological developments in robotics, artificial intelligence, and virtual reality, it is perhaps unsurprising that the arrival of emotionally expressive and reactive artificial agents is imminent. However, if such agents are to become integrated into our social milieu, it is imperative to establish an understanding of whether and how humans perceive emotion in artificial agents. In this review, we incorporate recent findings from social robotics, virtual reality, psychology, and neuroscience to examine how people recognize and respond to emotions displayed by artificial agents. First, we review how people perceive emotions expressed by an artificial agent, such as facial and bodily expressions. Second, we evaluate the similarities and differences in the consequences of perceived emotions in artificial compared to human agents. Besides accurately recognizing the emotional state of an artificial agent, it is critical to understand how humans respond to those emotions. Does interacting with an angry robot induce the same responses in people as interacting with an angry person? Similarly, does watching a robot rejoice when it wins a game elicit similar feelings of elation in the human observer? Here, we provide an overview of the current state of emotion expression and perception during interactions with artificial agents, as well as a clear articulation of the challenges and guiding principles to be addressed as we move ever closer to truly emotional artificial agents.",2018.0,143.0,87.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/7274989/8567843/08341761.pdf', 'status': None}","{'volume': '10', 'pages': '852-864', 'name': 'IEEE Transactions on Cognitive and Developmental Systems'}","{'bibtex': '@Article{Hortensius2018ThePO,\n author = {R. Hortensius and Felix Hekele and Emily S. Cross},\n journal = {IEEE Transactions on Cognitive and Developmental Systems},\n pages = {852-864},\n title = {The Perception of Emotion in Artificial Agents},\n volume = {10},\n year = {2018}\n}\n'}","[{'authorId': '1974324', 'name': 'R. Hortensius'}, {'authorId': '118504855', 'name': 'Felix Hekele'}, {'authorId': '1850742', 'name': 'Emily S. Cross'}]"
1992,ab2148d4ccaa18f055af7560485f38be13e6cc34,Visual Information as a Conversational Resource in Collaborative Physical Tasks,"In this article we consider the ways in which visual information is used as a conversational resource in the accomplishment of collaborative physical tasks. We focus on the role of visual information in maintaining task awareness and in achieving mutual understanding in conversation. We first describe the theoretical framework we use to analyze the role of visual information in physical collaboration. Then, we present two experiments that vary the amount and quality of the visual information available to participants during a collaborative bicycle repair task. We examine the effects of this visual information on performance and on conversational strategies. We conclude with a general discussion of how situational awareness and conversational grounding are achieved in collaborative tasks and with some design considerations for systems to support remote collaborative repair.",2003.0,41.0,422.0,False,,"{'volume': '18', 'pages': '13 - 49', 'name': 'Human–Computer Interaction'}","{'bibtex': '@Article{Kraut2003VisualIA,\n author = {R. Kraut and Susan R. Fussell and J. Siegel},\n journal = {Human–Computer Interaction},\n pages = {13 - 49},\n title = {Visual Information as a Conversational Resource in Collaborative Physical Tasks},\n volume = {18},\n year = {2003}\n}\n'}","[{'authorId': '1702853', 'name': 'R. Kraut'}, {'authorId': '1692772', 'name': 'Susan R. Fussell'}, {'authorId': '143760899', 'name': 'J. Siegel'}]"
1993,ab3cd200735f3d11dcc980cf24e70320ce9d9a85,"Likert scales, levels of measurement and the “laws” of statistics",,2010.0,20.0,3340.0,False,,"{'volume': '15', 'pages': '625-632', 'name': 'Advances in Health Sciences Education'}","{'bibtex': '@Article{Norman2010LikertSL,\n author = {G. Norman},\n journal = {Advances in Health Sciences Education},\n pages = {625-632},\n title = {Likert scales, levels of measurement and the “laws” of statistics},\n volume = {15},\n year = {2010}\n}\n'}","[{'authorId': '144011340', 'name': 'G. Norman'}]"
1994,ab53140bf9a80fb72554ad797c5520eb09dd6f33,Industry 4.0,,2014.0,16.0,2073.0,False,,"{'volume': '6', 'pages': '239-242', 'name': 'Business & Information Systems Engineering'}","{'bibtex': '@Article{Lasi2014Industry4,\n author = {H. Lasi and Peter Fettke and H.-G. Kemper and T. Feld and M. Hoffmann},\n journal = {Business & Information Systems Engineering},\n pages = {239-242},\n title = {Industry 4.0},\n volume = {6},\n year = {2014}\n}\n'}","[{'authorId': '3165570', 'name': 'H. Lasi'}, {'authorId': '2209018', 'name': 'Peter Fettke'}, {'authorId': '120066866', 'name': 'H.-G. Kemper'}, {'authorId': '2839784', 'name': 'T. Feld'}, {'authorId': '77776939', 'name': 'M. Hoffmann'}]"
1995,ab53169405702e79e6823902f02aa412fb0a2fa0,From virtual community members to C2C e-commerce buyers: Trust in virtual communities and its effect on consumers' purchase intention,,2010.0,73.0,638.0,False,,"{'volume': '9', 'pages': '346-360', 'name': 'Electron. Commer. Res. Appl.'}","{'bibtex': ""@Article{Lu2010FromVC,\n author = {Yao-bin Lu and Ling Zhao and Bin Wang},\n journal = {Electron. Commer. Res. Appl.},\n pages = {346-360},\n title = {From virtual community members to C2C e-commerce buyers: Trust in virtual communities and its effect on consumers' purchase intention},\n volume = {9},\n year = {2010}\n}\n""}","[{'authorId': '144038070', 'name': 'Yao-bin Lu'}, {'authorId': '2254268814', 'name': 'Ling Zhao'}, {'authorId': None, 'name': 'Bin Wang'}]"
1996,ab807ca19061a122e98f4b35e68748ef2a299dfb,Individual differences multidemensional scaling of adjectives denoting feelings.,,1973.0,28.0,179.0,False,,"{'volume': '25 1', 'pages': '\n          50-7\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Bush1973IndividualDM,\n author = {L. E. Bush},\n journal = {Journal of personality and social psychology},\n pages = {\n          50-7\n        },\n title = {Individual differences multidemensional scaling of adjectives denoting feelings.},\n volume = {25 1},\n year = {1973}\n}\n'}","[{'authorId': '102473881', 'name': 'L. E. Bush'}]"
1997,ab936a19d3c1af9587db0e568627b83373c9b57d,Measuring Stress-Reducing Effects of Virtual Training Based on Subjective Response,,2012.0,19.0,13.0,True,"{'url': 'http://www.few.vu.nl/%7Ewai/Papers/ICONIP12stressexperiment.pdf', 'status': None}",{'pages': '322-330'},"{'bibtex': '@Inproceedings{Bosse2012MeasuringSE,\n author = {T. Bosse and C. Gerritsen and J. D. Man and Jan Treur},\n pages = {322-330},\n title = {Measuring Stress-Reducing Effects of Virtual Training Based on Subjective Response},\n year = {2012}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '144668050', 'name': 'C. Gerritsen'}, {'authorId': '144287490', 'name': 'J. D. Man'}, {'authorId': '1726343', 'name': 'Jan Treur'}]"
1998,abb2ed00e3255b80fcb3a84f6829d11c6843c736,Transformed Social Interaction: Decoupling Representation from Behavior and Form in Collaborative Virtual Environments,"Computer-mediated communication systems known as collaborative virtual environments (CVEs) allow geographically separated individuals to interact verbally and nonverbally in a shared virtual space in real time. We discuss a CVE-based research paradigm that transforms (i.e., filters and modifies) nonverbal behaviors during social interaction. Because the technology underlying CVEs allows a strategic decoupling of rendered behavior from the actual behavior of the interactants, conceptual and perceptual constraints inherent in face-to-face interaction need not apply. Decoupling algorithms can enhance or degrade facets of nonverbal behavior within CVEs, such that interactants can reap the benefits of nonverbal enhancement or suffer nonverbal degradation. Concepts underlying transformed social interaction (TSI), the ethics and implications of such a research paradigm, and data from a pilot study examining TSI are discussed.",2004.0,73.0,250.0,False,,"{'volume': '13', 'pages': '428-441', 'name': 'Presence: Teleoperators & Virtual Environments'}","{'bibtex': '@Article{Bailenson2004TransformedSI,\n author = {J. Bailenson and A. Beall and J. Loomis and J. Blascovich and M. Turk},\n journal = {Presence: Teleoperators & Virtual Environments},\n pages = {428-441},\n title = {Transformed Social Interaction: Decoupling Representation from Behavior and Form in Collaborative Virtual Environments},\n volume = {13},\n year = {2004}\n}\n'}","[{'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '40458739', 'name': 'A. Beall'}, {'authorId': '2386187', 'name': 'J. Loomis'}, {'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '144097660', 'name': 'M. Turk'}]"
1999,abc62b40e07e758e6ca013db2956a3f2d021dec1,"Where computers disappear, virtual humans appear",,2004.0,25.0,43.0,True,"{'url': 'https://ris.utwente.nl/ws/files/6499201/compgraph2004.pdf', 'status': None}","{'volume': '28', 'pages': '467-476', 'name': 'Comput. Graph.'}","{'bibtex': '@Article{Nijholt2004WhereCD,\n author = {A. Nijholt},\n journal = {Comput. Graph.},\n pages = {467-476},\n title = {Where computers disappear, virtual humans appear},\n volume = {28},\n year = {2004}\n}\n'}","[{'authorId': '144483472', 'name': 'A. Nijholt'}]"
2000,abd1c342495432171beb7ca8fd9551ef13cbd0ff,ImageNet classification with deep convolutional neural networks,"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",2012.0,44.0,103931.0,True,"{'url': 'http://dl.acm.org/ft_gateway.cfm?id=3065386&type=pdf', 'status': None}","{'volume': '60', 'pages': '84 - 90', 'name': 'Communications of the ACM'}","{'bibtex': '@Article{Krizhevsky2012ImageNetCW,\n author = {A. Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},\n journal = {Communications of the ACM},\n pages = {84 - 90},\n title = {ImageNet classification with deep convolutional neural networks},\n volume = {60},\n year = {2012}\n}\n'}","[{'authorId': '2064160', 'name': 'A. Krizhevsky'}, {'authorId': '1701686', 'name': 'Ilya Sutskever'}, {'authorId': '1695689', 'name': 'Geoffrey E. Hinton'}]"
2001,abd3db64cb99c139aabb25a8bfa2770ac86c0a92,SmartBody: behavior realization for embodied conversational agents,"Researchers demand much from their embodied conversational agents (ECAs), requiring them to be both life-like, as well as responsive to events in an interactive setting. We find that a flexible combination of animation approaches may be needed to satisfy these needs. In this paper we present SmartBody, an open source modular framework for animating ECAs in real time, based on the notion of hierarchically connected animation controllers. Controllers in SmartBody can employ arbitrary animation algorithms such as keyframe interpolation, motion capture or procedural animation. Controllers can also schedule or combine other controllers. We discuss our architecture in detail, including how we incorporate traditional approaches, and develop the notion of a controller as a reactive module within a generic framework, for realizing modular animation control. To illustrate the versatility of the architecture, we also discuss a range of applications that have used SmartBody successfully.",2008.0,29.0,301.0,False,,{'pages': '151-158'},"{'bibtex': '@Inproceedings{Thiébaux2008SmartBodyBR,\n author = {M. Thiébaux and S. Marsella and Andrew N. Marshall and Marcelo Kallmann},\n pages = {151-158},\n title = {SmartBody: behavior realization for embodied conversational agents},\n year = {2008}\n}\n'}","[{'authorId': '2096971', 'name': 'M. Thiébaux'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2979549', 'name': 'Andrew N. Marshall'}, {'authorId': '1682684', 'name': 'Marcelo Kallmann'}]"
2002,ac01073def1adc42be69ac26a804bfeba767d440,Physicians' characteristics influence patients' adherence to medical treatment: results from the Medical Outcomes Study.,"The influence of physicians' attributes and practice style on patients' adherence to treatment was examined in a 2-year longitudinal study of 186 physicians and their diabetes, hypertension, and heart disease patients. A physician-level analysis was conducted, controlling for baseline patient adherence rates and for patient characteristics predictive of adherence in previous analyses. General adherence and adherence to medication, exercise, and diet recommendations were examined. Baseline adherence rates were associated with adherence rates 2 years later. Other predictors were physician job satisfaction (general adherence), number of patients seen per week (medication), scheduling a follow-up appointment (medication), tendency to answer patients' questions (exercise), number of tests ordered (diet), seriousness of illness (diet), physician specialty (medication, diet), and patient health distress (medication, exercise).",1993.0,48.0,823.0,False,,"{'volume': '12 2', 'pages': '\n          93-102\n        ', 'name': 'Health psychology : official journal of the Division of Health Psychology, American Psychological Association'}","{'bibtex': ""@Article{Dimatteo1993PhysiciansCI,\n author = {M. Dimatteo and C. Sherbourne and Ron D. Hays and Lynn Ordway and R. Kravitz and E. McGlynn and S. Kaplan and W. Rogers},\n journal = {Health psychology : official journal of the Division of Health Psychology, American Psychological Association},\n pages = {\n          93-102\n        },\n title = {Physicians' characteristics influence patients' adherence to medical treatment: results from the Medical Outcomes Study.},\n volume = {12 2},\n year = {1993}\n}\n""}","[{'authorId': '3429434', 'name': 'M. Dimatteo'}, {'authorId': '3852593', 'name': 'C. Sherbourne'}, {'authorId': '2146153212', 'name': 'Ron D. Hays'}, {'authorId': '20488234', 'name': 'Lynn Ordway'}, {'authorId': '3231793', 'name': 'R. Kravitz'}, {'authorId': '2948642', 'name': 'E. McGlynn'}, {'authorId': '31456269', 'name': 'S. Kaplan'}, {'authorId': '144622201', 'name': 'W. Rogers'}]"
2003,ac31871243ed32763555de5ee8b4cf960395b67d,ESCAP: Towards the Design of an AI Architecture for a Virtual Counselor to Tackle Students' Exam Stress,"Exam stress is a common predicament faced by students of all age groups and cultures. Unfortunately, it has neither created much consternation in the society nor attracted much interest for serious research, perhaps due to its impulsive causal nature that disappears almost instantly after the exams are over. Stress in optimal level can stimulate students to achieve their personal best in their exams. However, one of the greatest threats to the well-being of students arises due to the fallout of excessive stress, which, if not addressed timely may not only lead to failure in exams, but result in serious debilitating consequences including insomnia, depression and even suicide. Our research aims to design a human computer interaction (HCI) interface using artificial intelligence (AI) techniques for modeling a virtual exam-stress counsellor ESCAP, an embodied conversational agent with facial animation, advice and intelligence of a professional psychologist to support undergraduate students in managing their exam stress.",2012.0,28.0,13.0,False,,"{'pages': '2981-2990', 'name': '2012 45th Hawaii International Conference on System Sciences'}","{'bibtex': ""@Article{Rudra2012ESCAPTT,\n author = {T. Rudra and Manning Li and M. Kavakli},\n journal = {2012 45th Hawaii International Conference on System Sciences},\n pages = {2981-2990},\n title = {ESCAP: Towards the Design of an AI Architecture for a Virtual Counselor to Tackle Students' Exam Stress},\n year = {2012}\n}\n""}","[{'authorId': '12156140', 'name': 'T. Rudra'}, {'authorId': '40217188', 'name': 'Manning Li'}, {'authorId': '3247112', 'name': 'M. Kavakli'}]"
2004,ac32109b5b91b4490295d31ef051ffb98a0003d8,Exogenous testosterone decreases men's personal distance in a social threat context,,2017.0,78.0,28.0,False,,"{'volume': '90', 'pages': '75-83', 'name': 'Hormones and Behavior'}","{'bibtex': ""@Article{Wagels2017ExogenousTD,\n author = {L. Wagels and Sina Radke and K. Goerlich and U. Habel and M. Votinov},\n journal = {Hormones and Behavior},\n pages = {75-83},\n title = {Exogenous testosterone decreases men's personal distance in a social threat context},\n volume = {90},\n year = {2017}\n}\n""}","[{'authorId': '6367374', 'name': 'L. Wagels'}, {'authorId': '145880611', 'name': 'Sina Radke'}, {'authorId': '2455354', 'name': 'K. Goerlich'}, {'authorId': '2782974', 'name': 'U. Habel'}, {'authorId': '3270733', 'name': 'M. Votinov'}]"
2005,ac338e286788dc790f13607bff607e0919beb378,"Effects of Eye Contact, Posture and Vocal Inflection upon Credibility and Comprehension.","In order to test whether constant eye contact, formal posture, and varied vocal inflection increase source credibility and listener comprehensiOn, 144 College students in an introductory speeck communication course were placed in groups of equal size that .listened to the same informative speech. The speaker presented to each group a different combination cf the independent variables, and, after the subjects were tested for their comprehension of the speech, they'rated the speaker's credibility.. Analysis of the effects of the three independent Veriableh led to the following conclusions: Eye .contact seeps to enhance both listener comprehension and speaker credibility, though inconsistencies""between'eye contact and vocal inflection may lower the speaker's believability; the speaker's posture has little effect on either-cadibility or comprehension; varied or limited vocal lefiection has no-significant effect""dpon the speaker's credibility, except for the likability factor of credibility; and differences invocal inflection do not _affect listener comprehension. Tables of 'the analyzed data illustrate the text. (RL)* .ABSTRACT",1976.0,4.0,21.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Beebe1976EffectsOE,\n author = {S. Beebe},\n title = {Effects of Eye Contact, Posture and Vocal Inflection upon Credibility and Comprehension.},\n year = {1976}\n}\n'}","[{'authorId': '69373932', 'name': 'S. Beebe'}]"
2006,ac6ec6a266df0d8245959319d55caa1c133adf7e,Emotional agents - state of the art and applications,"last decade, intensive research on emotional intelligence has advanced 
 significantly from its theoretical basis, analytical studies and processing 
 technology to exploratory applications in a wide range of real-life domains. 
 This paper brings new insights in the field of emotional, intelligent 
 software agents. The first part is devoted to an overview of the 
 state-of-the-art in emotional intelligence research with emphasis on 
 emotional agents. A wide range of applications in different areas like 
 modeling emotional agents, aspects of learning in emotional environments, 
 interactive emotional systems and so on are presented. After that we suggest 
 a systematic order of research steps with the idea of proposing an adequate 
 framework for several possible real-life applications of emotional agents. We 
 recognize that it is necessary to apply specific methods for dynamic data 
 analysis in order to identify and discover new knowledge from available 
 emotional information and data sets. The last part of the paper discusses 
 research activities for designing an agent-based architecture, in which 
 agents are capable of reasoning about and displaying some kind of emotions 
 based on emotions detected in human speech, as well as online documents. 
 [Projekat Ministarstva nauke Republike Srbije, br. OI174023: Intelligent 
 techniques and their integration into wide-spectrum decision support]",2015.0,89.0,21.0,True,"{'url': 'http://www.doiserbia.nb.rs/ft.aspx?id=1820-02141500047I', 'status': None}","{'volume': '12', 'pages': '1121-1148', 'name': 'Comput. Sci. Inf. Syst.'}","{'bibtex': '@Article{Ivanović2015EmotionalA,\n author = {M. Ivanović and Z. Budimac and Miloš Radovanović and V. Kurbalija and Weihui Dai and C. Bǎdicǎ and M. Colhon and S. Ninkovic and Dejan Mitrovic},\n journal = {Comput. Sci. Inf. Syst.},\n pages = {1121-1148},\n title = {Emotional agents - state of the art and applications},\n volume = {12},\n year = {2015}\n}\n'}","[{'authorId': '144395551', 'name': 'M. Ivanović'}, {'authorId': '1712090', 'name': 'Z. Budimac'}, {'authorId': '143651750', 'name': 'Miloš Radovanović'}, {'authorId': '3113695', 'name': 'V. Kurbalija'}, {'authorId': '143742626', 'name': 'Weihui Dai'}, {'authorId': '1740341', 'name': 'C. Bǎdicǎ'}, {'authorId': '1789290', 'name': 'M. Colhon'}, {'authorId': '33627984', 'name': 'S. Ninkovic'}, {'authorId': '34664252', 'name': 'Dejan Mitrovic'}]"
2008,ac6f2191227b14d9cd29cd074fb6bf5c46d9ab0e,The intensity of facial expression is determined by underlying affective state and social situation.,"The present study concerned the influence ofthe presence of others on facial expressions of emotion. The proposition that facial expressive displays are better predicted by the social context than by emotional state (A. J. Fridlund, 1991) was tested in an experiment varying both the sociality of the context and the intensity of the emotion elicitor as well as the relationship between expressor and audience. The results indicate that the intensity of expressive displays cannot be satisfactorily predicted by either of these factors alone but is influenced by a complex interplay of all 3 factors.",1995.0,40.0,303.0,False,,"{'volume': '69', 'pages': '280-288', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Hess1995TheIO,\n author = {U. Hess and R. Banse and Arvid Kappas},\n journal = {Journal of Personality and Social Psychology},\n pages = {280-288},\n title = {The intensity of facial expression is determined by underlying affective state and social situation.},\n volume = {69},\n year = {1995}\n}\n'}","[{'authorId': '3067657', 'name': 'U. Hess'}, {'authorId': '47161796', 'name': 'R. Banse'}, {'authorId': '1742554', 'name': 'Arvid Kappas'}]"
2009,ac8d1ebe57fb6c3875f372747450459aa2ef1b51,Preschool and School Readiness of Children of Immigrants,"Objective. In this article, we use data from the Early Childhood Longitudinal Survey—Kindergarten Cohort to analyze the links between preschool attendance and the school readiness of children of immigrants. 
 
Methods. Using data from the Early Childhood Longitudinal Survey—Kindergarten Cohort, we estimate multivariate regression models for the effects of preschool on school readiness for children of immigrants and children of natives. 
 
Results. We find that children whose mothers were born outside the United States are less likely to be enrolled in school or center-based preschool programs than other children. We find that preschool attendance raises reading and math scores as much for children of immigrants as it does for other children. Attending preschool also raises the English-language proficiency of children of immigrants. Although not the main focus of our study, we examined the effects of Head Start, and found that this program improves children's English proficiency, with especially large effects for children of immigrants whose mothers have less than a high school education; in this latter group, Head Start also improved math scores. 
 
Conclusions. Given that preschool benefits children of immigrants as much as it does children of natives and given that children of immigrants are less likely to be enrolled, our findings strongly suggest that enrolling more children of immigrants in preschool would help reduce inequality in skills at school entry.",2006.0,19.0,308.0,False,,"{'volume': '87', 'pages': '1241-1262', 'name': 'Social Science Quarterly'}","{'bibtex': '@Article{Magnuson2006PreschoolAS,\n author = {Katherine A. Magnuson and C. Lahaie and J. Waldfogel},\n journal = {Social Science Quarterly},\n pages = {1241-1262},\n title = {Preschool and School Readiness of Children of Immigrants},\n volume = {87},\n year = {2006}\n}\n'}","[{'authorId': '115016308', 'name': 'Katherine A. Magnuson'}, {'authorId': '116111218', 'name': 'C. Lahaie'}, {'authorId': '153689159', 'name': 'J. Waldfogel'}]"
2010,ac95022a873613b5e2f99bbc3505b88060183c7f,Emotional State Recognition with EEG Signals Using Subject Independent Approach,,2018.0,19.0,35.0,False,,{'pages': '117-124'},"{'bibtex': '@Inproceedings{Pandey2018EmotionalSR,\n author = {Pallavi Pandey and K. R. Seeja},\n pages = {117-124},\n title = {Emotional State Recognition with EEG Signals Using Subject Independent Approach},\n year = {2018}\n}\n'}","[{'authorId': '50162090', 'name': 'Pallavi Pandey'}, {'authorId': '2622519', 'name': 'K. R. Seeja'}]"
2011,ac9b4fd8fed454f2b22b8cdd5c5cde92c90f7ebd,Improvisational interaction : a framework for structural exploration of media,"Whenever we use computers to interact with media, our experience is that of direct control, and the goal of our interactions is either artifact-production (the editor paradigm) or passive exploration (the browser paradigm). This thesis proposes an alternative: a model of media interaction based on the ideas of non-idiomatic improvisation that encourages active exploration of media and its structures. We argue that in order to facilitate this kind of exploration, (1) computational tools must actively participate in the creative process and (2) the interaction framework must allow structural exploration of media. This leads to our main claim: improvisation should be considered a valid and appropriate paradigm for media interaction. To this extent, we present a Cognitive Model of Improvisational Action (CMIA) that integrates element-centric and process-centric (structural) modes of control into a single framework for media exploration. This model allows participants to switch their attention between compositional elements and structural processes. The model is argued to be particularly powerful in leading us to novel spaces for media creation and consumption. We follow by presenting the Emonic Environment (Implementation), an interactive system built on the principles of CMIA. We conclude by describing two studies (Scenarios & Experiments) that analyze the ways in which Emonic Environment affects how people interact and think about their interactions with digital media. These studies illustrate the potential of CMIA as a paradigm for interaction between humans and machines. Thesis Supervisor: Glorianna Davenport Title: Principal Research Associate, Media Fabrics, Program in Media Arts and Science, MIT",2006.0,75.0,111.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Nemirovsky2006ImprovisationalI,\n author = {Paul Nemirovsky},\n title = {Improvisational interaction : a framework for structural exploration of media},\n year = {2006}\n}\n'}","[{'authorId': '2265532399', 'name': 'Paul Nemirovsky'}]"
2012,acae71006c0a8c3193f99b89ddf23e4d319a3d3c,An interactive VR platform with emotion recognition for self-attachment intervention,"INTRODUCTION: Self-attachment is a new self-administrable psychotherapeutic intervention based on creating an a ﬀ ectional bond between the user and their childhood-self using their childhood photos to develop the capacity for a ﬀ ect self-regulation. Technological advances, such as virtual reality (VR), can enhance the procedure of this intervention and make it scalable. METHODS: We have developed a user-friendly, interactive VR platform for self-attachment featuring a virtual assistant and a customised child avatar that resembles the user in their childhood. The virtual agent interacts with the user and using an emotion recognition algorithm can provide suggestions for the user to undertake an appropriate self-attachment sub-protocol. Furthermore, the platform allows user interaction with the child avatar, such as embracing the avatar. RESULTS: We show by a small preliminary trial that such a VR experience can be realistic, leading to a positive emotion change in the user.",2021.0,58.0,4.0,True,"{'url': 'http://eudl.eu/pdf/10.4108/eai.14-9-2021.170951', 'status': 'GOLD'}","{'name': 'EAI Endorsed Trans. Pervasive Health Technol.', 'pages': 'e5', 'volume': '7'}","{'bibtex': '@Article{Polydorou2021AnIV,\n author = {Neophytos Polydorou and A. Edalat},\n booktitle = {EAI Endorsed Transactions on Pervasive Health and Technology},\n journal = {EAI Endorsed Trans. Pervasive Health Technol.},\n pages = {e5},\n title = {An interactive VR platform with emotion recognition for self-attachment intervention},\n volume = {7},\n year = {2021}\n}\n'}","[{'authorId': '2133722561', 'name': 'Neophytos Polydorou'}, {'authorId': '1694989', 'name': 'A. Edalat'}]"
2013,acc55d8e5fb9c4d1fce6a12101fbd68add372a55,A Review of Emotion Recognition Using Physiological Signals,"Emotion recognition based on physiological signals has been a hot topic and applied in many areas such as safe driving, health care and social security. In this paper, we present a comprehensive review on physiological signal-based emotion recognition, including emotion models, emotion elicitation methods, the published emotional physiological datasets, features, classifiers, and the whole framework for emotion recognition based on the physiological signals. A summary and comparation among the recent studies has been conducted, which reveals the current existing problems and the future work has been discussed.",2018.0,151.0,484.0,True,"{'url': 'https://www.mdpi.com/1424-8220/18/7/2074/pdf?version=1530280392', 'status': None}","{'volume': '18', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Shu2018ARO,\n author = {Lin Shu and Jinyan Xie and Mingyue Yang and Ziyi Li and Zhenqi Li and D. Liao and Xiangmin Xu and Xinyi Yang},\n journal = {Sensors (Basel, Switzerland)},\n title = {A Review of Emotion Recognition Using Physiological Signals},\n volume = {18},\n year = {2018}\n}\n'}","[{'authorId': '144308894', 'name': 'Lin Shu'}, {'authorId': '2216566593', 'name': 'Jinyan Xie'}, {'authorId': '2186950329', 'name': 'Mingyue Yang'}, {'authorId': '2118274805', 'name': 'Ziyi Li'}, {'authorId': '2109633844', 'name': 'Zhenqi Li'}, {'authorId': '2066494685', 'name': 'D. Liao'}, {'authorId': '9303726', 'name': 'Xiangmin Xu'}, {'authorId': '2150442453', 'name': 'Xinyi Yang'}]"
2014,acc90c2f727736958f01c16137b5c80680d6cb7e,Attention Theory And Practice,"Thank you very much for reading attention theory and practice. Maybe you have knowledge that, people have search hundreds times for their chosen readings like this attention theory and practice, but end up in harmful downloads. Rather than enjoying a good book with a cup of coffee in the afternoon, instead they are facing with some harmful virus inside their laptop. attention theory and practice is available in our digital library an online access to it is set as public so you can download it instantly. Our books collection hosts in multiple countries, allowing you to get the most less latency time to download any of our books like this one. Kindly say, the attention theory and practice is universally compatible with any devices to read.",2016.0,0.0,65.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Boehm2016AttentionTA,\n author = {U. Boehm},\n title = {Attention Theory And Practice},\n year = {2016}\n}\n'}","[{'authorId': '21149652', 'name': 'U. Boehm'}]"
2015,ad05058642323229833623b3c9bd427c040b6f30,Inferring search behaviors using partially observable markov model with duration (POMD),"This paper presents Partially Observable Markov model with Duration (POMD), a statistical method that addresses the challenge of understanding sophisticated user behaviors from the search log in which some user actions, such as reading and skipping search results, cannot be observed and recorded. POMD utilizes not only the positional but also the temporal information of the clicks in the log. In this work, we treat the user engagements with a search engine as a Markov process, and model the unobservable engagements as hidden states. POMD differs from the traditional hidden Markov model (HMM) in that not all the hidden state transitions emit observable events, and that the duration of staying in each state is explicitly factored into the core statistical model. To address the training and decoding issues emerged as the results of the variations, we propose an iterative two-stage training algorithm and a greedy segmental decoding algorithm respectively. We validate the proposed algorithm with two sets of experiments. First, we show that the search behavioral patterns inferred by POMD match well with those reported in the eye tracking experiments. Secondly, through a series of A/B comparison experiments, we demonstrate that POMD can distinguish the ranking qualities of different search engine configurations much better than the patterns inferred by the model proposed in the previous work. Both of the experimental results suggest that POMD can provide a statistical and quantitative way to understand the sophisticated search behaviors by simply mining the search logs.",2011.0,22.0,22.0,False,,{'pages': '415-424'},"{'bibtex': '@Inproceedings{He2011InferringSB,\n author = {Yin He and Kuansan Wang},\n pages = {415-424},\n title = {Inferring search behaviors using partially observable markov model with duration (POMD)},\n year = {2011}\n}\n'}","[{'authorId': '2118917602', 'name': 'Yin He'}, {'authorId': '1748169', 'name': 'Kuansan Wang'}]"
2016,ad07b99615407b4bf5c0967571d6bd8b9f969ff7,Empathy and Moral Development: Implications for caring and Justice.,"Empathy and Moral Development represents the life’s work of Professor Hoffman, integrating over 30 years of research with information and ideas gleaned from the psychological and social development theories of the last century. Starting with biblical concepts of sin and guilt and drawing on the germinal theories of historical figures such as Rousseau, Freud and Piaget, the author also discusses Kohlberg’s theory and modifications by later followers. 
 
The first chapter begins with a brief overview of the previous and current theories and the historical sources for the book, giving clear definitions and outlining the theory to follow. Each of the seven sections of the book expands on important key concepts introduced earlier. There are frequent references to and review of the previously discussed material. The first section of the book explains the “innocent bystander” model that has been used for decades to explore human moral development. Concepts from animal arousal and behavior models are linked with human infant research on early affective and cognitive development. The research quoted is illustrative and extensive. The section ends with a discussion of the differences between empathy, guilt, sympathy and injustice. Parts Two and Three introduce the concept of guilt and how parental discipline interacts with a child’s cognitive skills to guide moral development. This first half of the book could have been expanded further through the use of more examples and further exploration of how genetics and innate brain processes contribute to the development of empathy. Hoffman also seemed to emphasize the psychosocial aspects over the behavioral cognitive and genetic aspects, but it is a good review of the field to date. 
 
The second half of the book is very interesting. The examples given are more current, complete and involved. The author shines as he discusses his integration of existing theory and research into a comprehensive model. He sketches a brief picture of different types of guilt, and a theoretical hierarchy. He expands on his assertion that both parental discipline and peer interaction are necessary for the development of guilt and morality. His collected statistics on parental discipline and its effects on children’s moral development are impressive. He explains why empathy can operate in some situations and can be overwhelmed in others, even when the individuals involved are highly empathic (i.e. therapist burnout). Numerous examples are given of how guilt and empathy are motivators for human action, especially prosocial and “altruistic” actions. In light of the events of September 11, 2001, Hoffman’s concepts explain much of the individual and social group actions which followed. 
 
Section Four of the book asks the question “Is Empathy Enough” to explain moral action. Types of bias which may affect empathy and moral action are examined. Empathy’s self-destructive and self-limiting qualities are explored and integrated in Darwinian fashion. Hoffman states that a morality based on empathy alone would not be fair in large mixed or larger human groups and would lead to bias and conflict. To live together peaceably, Hoffman insists that empathy must be embedded in moral principles, the subject of the fifth part of the book. Hoffman shows how empathy (affect) becomes linked or bonded to moral principles (of cognitive and social origin) as the person develops. The synthesis is used powerfully to explain the perpetuation of social attributes of caring and justice in western society. Useful definitions of key concepts in justice research are included. 
 
Parts six and seven of the book are the slimmest and cover culture, wherein issues of the universal applicability of the key concepts are examined, and intervention, which hopefully can someday be expanded into its own volume. A few directions in designing empathic training for use in young offenders and other children at risk are given, but not in the kind of depth currently desperately needed in the field. 
 
The book is well organized in its scant 300 pages and set up as a graduate course. It is an easy book from which to learn. It would make an ideal text and makes for a brilliant discussion overall, as it presents the author’s theory that will, no doubt, form the basis for future research and intervention in this area.",2003.0,0.0,1859.0,False,,"{'volume': '12', 'pages': '46-47', 'name': ''}","{'bibtex': '@Inproceedings{Vogt2003EmpathyAM,\n author = {Lori Ann Vogt},\n pages = {46-47},\n title = {Empathy and Moral Development: Implications for caring and Justice.},\n volume = {12},\n year = {2003}\n}\n'}","[{'authorId': '115702696', 'name': 'Lori Ann Vogt'}]"
2018,ad4e281293237bdb8efbbd639ac823536815f42b,An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest,,2006.0,64.0,9762.0,False,,"{'volume': '31', 'pages': '968-980', 'name': 'NeuroImage'}","{'bibtex': '@Article{Desikan2006AnAL,\n author = {R. Desikan and F. Ségonne and B. Fischl and B. Quinn and B. Dickerson and D. Blacker and R. Buckner and A. Dale and R. P. Maguire and B. Hyman and M. Albert and R. Killiany},\n journal = {NeuroImage},\n pages = {968-980},\n title = {An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest},\n volume = {31},\n year = {2006}\n}\n'}","[{'authorId': '143727348', 'name': 'R. Desikan'}, {'authorId': '2945611', 'name': 'F. Ségonne'}, {'authorId': '145815766', 'name': 'B. Fischl'}, {'authorId': '34838229', 'name': 'B. Quinn'}, {'authorId': '1769416', 'name': 'B. Dickerson'}, {'authorId': '2971502', 'name': 'D. Blacker'}, {'authorId': '1761695', 'name': 'R. Buckner'}, {'authorId': '143619169', 'name': 'A. Dale'}, {'authorId': '144079633', 'name': 'R. P. Maguire'}, {'authorId': '2349067', 'name': 'B. Hyman'}, {'authorId': '35047388', 'name': 'M. Albert'}, {'authorId': '2029704', 'name': 'R. Killiany'}]"
2019,ad6de2d9a36f851da4bef2c9f576a24ac502920a,Revisiting the uncanny valley theory: Developing and validating an alternative to the Godspeed indices,,2010.0,55.0,355.0,False,,"{'volume': '26', 'pages': '1508-1518', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Ho2010RevisitingTU,\n author = {Chin-Chang Ho and K. Macdorman},\n journal = {Comput. Hum. Behav.},\n pages = {1508-1518},\n title = {Revisiting the uncanny valley theory: Developing and validating an alternative to the Godspeed indices},\n volume = {26},\n year = {2010}\n}\n'}","[{'authorId': '2472620', 'name': 'Chin-Chang Ho'}, {'authorId': '1690354', 'name': 'K. Macdorman'}]"
2020,ad72b65ab67ebe502e27b16932ffafd9a69d61ca,Towards a Common Framework for Multimodal Generation: The Behavior Markup Language,,2006.0,20.0,464.0,False,,{'pages': '205-217'},"{'bibtex': '@Inproceedings{Kopp2006TowardsAC,\n author = {S. Kopp and Brigitte Krenn and S. Marsella and Andrew N. Marshall and C. Pelachaud and Hannes Pirker and K. Thórisson and H. Vilhjálmsson},\n pages = {205-217},\n title = {Towards a Common Framework for Multimodal Generation: The Behavior Markup Language},\n year = {2006}\n}\n'}","[{'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '3313648', 'name': 'Brigitte Krenn'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2979549', 'name': 'Andrew N. Marshall'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1696134', 'name': 'Hannes Pirker'}, {'authorId': '1727838', 'name': 'K. Thórisson'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}]"
2024,ada9f2200bee952427dc4bb35a77dcc83716b932,Performance Evaluation of a Novel Vehicle Collision Avoidance Lane Change Algorithm,,2016.0,19.0,16.0,False,,"{'volume': '', 'pages': '103-116', 'name': ''}","{'bibtex': '@Inproceedings{Samiee2016PerformanceEO,\n author = {S. Samiee and S. Azadi and R. Kazemi and A. Eichberger and Branko Rogic and Michael Semmer},\n pages = {103-116},\n title = {Performance Evaluation of a Novel Vehicle Collision Avoidance Lane Change Algorithm},\n year = {2016}\n}\n'}","[{'authorId': '24323972', 'name': 'S. Samiee'}, {'authorId': '1966095', 'name': 'S. Azadi'}, {'authorId': '143700987', 'name': 'R. Kazemi'}, {'authorId': '3434981', 'name': 'A. Eichberger'}, {'authorId': '70018068', 'name': 'Branko Rogic'}, {'authorId': '69842764', 'name': 'Michael Semmer'}]"
2025,adbb20378727b892a1705425c8df6efec423c5ab,Patterns of cognitive appraisal in emotion.,"There has long been interest in describing emotional experience in terms of underlying dimensions, but traditionally only two dimensions, pleasantness and arousal, have been reliably found. The reasons for these findings are reviewed, and integrating this review with two recent theories of emotions (Roseman, 1984; Scherer, 1982), we propose eight cognitive appraisal dimensions to differentiate emotional experience. In an investigation of this model, subjects recalled past experiences associated with each of 15 emotions, and rated them along the proposed dimensions. Six orthogonal dimensions, pleasantness, anticipated effort, certainty, attentional activity, self-other responsibility/control, and situational control, were recovered, and the emotions varied systematically along each of these dimensions, indicating a strong relation between the appraisal of one's circumstances and one's emotional state. The patterns of appraisal for the different emotions, and the role of each of the dimensions in differentiating emotional experience are discussed.",1985.0,53.0,3623.0,False,,"{'volume': '48 4', 'pages': '\n          813-38\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Smith1985PatternsOC,\n author = {Craig A. Smith and P. Ellsworth},\n journal = {Journal of personality and social psychology},\n pages = {\n          813-38\n        },\n title = {Patterns of cognitive appraisal in emotion.},\n volume = {48 4},\n year = {1985}\n}\n'}","[{'authorId': '2110202993', 'name': 'Craig A. Smith'}, {'authorId': '4367292', 'name': 'P. Ellsworth'}]"
2026,add99bb7a404accb3de776f6554901e83db8cbf3,A Meta-Analysis on the Relationship between Self-Reported Presence and Anxiety in Virtual Reality Exposure Therapy for Anxiety Disorders,"In virtual reality exposure therapy (VRET) for anxiety disorders, sense of presence in the virtual environment is considered the principal mechanism that enables anxiety to be felt. Existing studies on the relation between sense of presence and level of anxiety, however, have yielded mixed results on the correlation between the two. In this meta-analysis, we reviewed publications on VRET for anxiety that included self-reported presence and anxiety. The comprehensive search of the literature identified 33 publications with a total of 1196 participants. The correlation between self-reported sense of presence and anxiety was extracted and meta-analyzed. Potential moderators such as technology characteristics, sample characteristics including age, gender and clinical status, disorder characteristics and study design characteristics such as measurements were also examined. The random effects analysis showed a medium effect size for the correlation between sense of presence and anxiety (r = .28; 95% CI: 0.18–0.38). Moderation analyses revealed that the effect size of the correlation differed across different anxiety disorders, with a large effect size for fear of animals (r = .50; 95% CI: 0.30–0.66) and a no to small effect size for social anxiety disorder (r = .001; 95% CI: −0.19–0.19). Further, the correlation between anxiety and presence was stronger in studies with participants who met criteria for an anxiety disorder than in studies with a non-clinical population. Trackers with six degrees of freedom and displays with a larger field of view resulted in higher effect sizes, compared to trackers with three degrees of freedom and displays with a smaller field of view. In addition, no difference in effect size was found for the type of presence measurement and the type of anxiety measurement. This meta-analysis confirms the positive relation between sense of presence and anxiety and demonstrates that this relation can be affected by various moderating factors.",2014.0,93.0,149.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0096144&type=printable', 'status': None}","{'volume': '9', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Ling2014AMO,\n author = {Y. Ling and H. Nefs and N. Morina and I. Heynderickx and Willem-Paul Brinkman},\n journal = {PLoS ONE},\n title = {A Meta-Analysis on the Relationship between Self-Reported Presence and Anxiety in Virtual Reality Exposure Therapy for Anxiety Disorders},\n volume = {9},\n year = {2014}\n}\n'}","[{'authorId': '2055564023', 'name': 'Y. Ling'}, {'authorId': '2353999', 'name': 'H. Nefs'}, {'authorId': '145500304', 'name': 'N. Morina'}, {'authorId': '145412643', 'name': 'I. Heynderickx'}, {'authorId': '145495942', 'name': 'Willem-Paul Brinkman'}]"
2028,adf583eab0acddd2d536a141c04c10a944a42e08,The Inclusive Classroom: The Effects of Color on Learning and Behavior,"Color impacts student behavior within the physical learning environment. Due to the move toward including students with disabilities in the general education classroom, functional color applications are critical. This article reviews and analyzes existing literature and empirical evidence related to use of color in the classroom for students of all abilities. The three major areas reviewed were (1) the inclusive classroom for students with disabilities, (2) color theory, and (3) the physiological and psychological aspects of color. The results show that color is important in designing functional learning spaces. The results of this analysis may benefit educators, parents, and design professionals in designing beneficial learning environments for all students.",2011.0,38.0,65.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gaines2011TheIC,\n author = {K. Gaines and Z. Curry},\n title = {The Inclusive Classroom: The Effects of Color on Learning and Behavior},\n year = {2011}\n}\n'}","[{'authorId': '48442388', 'name': 'K. Gaines'}, {'authorId': '73231253', 'name': 'Z. Curry'}]"
2029,ae02cd14f9bd54cfbb3c1c481cf9408f78134a2c,Emotion recognition in human-computer interaction,,2005.0,34.0,2192.0,False,,"{'volume': '18 4', 'pages': '\n          389-405\n        ', 'name': 'Neural networks : the official journal of the International Neural Network Society'}","{'bibtex': '@Article{Fragopanagos2005EmotionRI,\n author = {N. Fragopanagos and John G. Taylor},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          389-405\n        },\n title = {Emotion recognition in human-computer interaction},\n volume = {18 4},\n year = {2005}\n}\n'}","[{'authorId': '2321683', 'name': 'N. Fragopanagos'}, {'authorId': '2110316079', 'name': 'John G. Taylor'}]"
2030,ae5bc4f3469cd6b9edfd712cb516c857b0c2cf1a,WASABI: Affect simulation for agents with believable interactivity,"Preface The research reported in this thesis is the result of the creative and communicative environment I enjoyed during the last eight years in the Artificial Intelligence Group at the University of Bielefeld. Over the years the members of this group discussed even the most far-reaching ideas with me and without their professional and personal support this work would not have been possible. First and foremost, I am most grateful to my advisor Ipke Wachsmuth for trusting in my hidden abilities from the very beginning. With his idea to let me investigate the fascinating problem of emotion simulation for our virtual human MAX, he gave me the chance to experience the "" world of science "" to which I am now addicted. I would like to thank all members of the AI Group, including for reminding me from time to time that the emotion simulation cannot be applied to every problem of Computer Science. Special thanks go to Stefan Kopp for his long-standing technical and ideational support as my colleague and friend. I am also indebted to Helmut Prendinger for supervising me during three-month in 2005 as a Pre-doctoral fellow of the Japan Society for the Promotion of Science in Tokyo, Japan, and supporting me ever since. Further special thanks go to Klaus Scherer, who agreed to be the second reviewer of this thesis and found the time to share my fascination for this challenging research. I am also grateful to Roger Giles and Nick Thomas for proofreading parts of the manuscript and to for insightful discussions and advices. Finally, I owe many thanks to my family, especially to my mother Dorothea, my brother Jörg, and my son Jonas. But most importantly, without the love and practical as well as "" mental "" support of my wife Yoko, finishing this thesis would have been close to impossible— thank you so much for your love and encouragement.",2008.0,206.0,108.0,False,,{'pages': '1-188'},"{'bibtex': '@Inproceedings{Becker-Asano2008WASABIAS,\n author = {C. Becker-Asano},\n pages = {1-188},\n title = {WASABI: Affect simulation for agents with believable interactivity},\n year = {2008}\n}\n'}","[{'authorId': '1403827243', 'name': 'C. Becker-Asano'}]"
2032,ae61a4e0a774a0771ee66fa8a5469fd3f03df977,Sharing Concerns: Interpersonal Worry Regulation in Romantic Couples,"Two dyadic studies investigated interpersonal worry regulation in heterosexual relationships. In Study 1, we video-recorded 40 romantic couples discussing shared concerns. Male partners’ worry positively predicted female partners’ interpersonal calming attempts, and negatively predicted female partners’ interpersonal alerting attempts (i.e., attempts to make their partners appreciate the seriousness of concerns). Video-cued recall data also indicated that changes in partner A’s worry over time positively predicted partner B’s motivation to reduce partner A’s worry, and that this effect was stronger when B was the female partner. Study 2 was a dyadic survey of 100 couples. Individual differences in partner A’s negative affect were positive predictors of partner B’s interpersonal calming, and individual differences in partner A’s expressive suppression were negative predictors of partner B’s interpersonal calming. Further, individual differences in male partners’ expressivity were significant positive predictors of female partners’ interpersonal calming, and individual differences in male partners’ reappraisal were significant positive predictors of female partners’ interpersonal alerting. These findings suggest that interpersonal worry regulation relates to partners’ expression and intrapersonal regulation of worry, but not equally for men and women.",2016.0,50.0,48.0,True,,"{'volume': '16', 'pages': '449 - 458', 'name': 'Emotion (Washington, D.C.)'}","{'bibtex': '@Article{Parkinson2016SharingCI,\n author = {B. Parkinson and G. Simons and Karen Niven},\n journal = {Emotion (Washington, D.C.)},\n pages = {449 - 458},\n title = {Sharing Concerns: Interpersonal Worry Regulation in Romantic Couples},\n volume = {16},\n year = {2016}\n}\n'}","[{'authorId': '144603514', 'name': 'B. Parkinson'}, {'authorId': '48350755', 'name': 'G. Simons'}, {'authorId': '145276844', 'name': 'Karen Niven'}]"
2033,ae67674c6431140e0779786e61526bb5e3b0dec1,Eye Communication in a Conversational 3D Synthetic Agent,"Our goal is to create an ‘intelligent’ 3D agent able to send complex, ‘natural’ messages to users and, in the future, to converse with them. We look at the relationship between the agent's communicative intentions and the way that these intentions are expressed into verbal and nonverbal messages. In this paper, we concentrate on the study and generation of coordinated linguistic and gaze communicative acts. In this view we analyse gaze signals according to their functional meaning rather than to their physical actions. We propose a formalism where a communicative act is represented by two elements: a meaning (that corresponds to a set of goals and beliefs that the agent has the purpose to transmit to the interlocutor) and a signal, that is the nonverbal expression of that meaning. We also outline a methodology to generate messages that coordinate verbal with nonverbal signals.",2000.0,33.0,138.0,False,,"{'volume': '13', 'pages': '169-182', 'name': 'AI Commun.'}","{'bibtex': '@Article{Poggi2000EyeCI,\n author = {I. Poggi and C. Pelachaud and F. D. Rosis},\n journal = {AI Commun.},\n pages = {169-182},\n title = {Eye Communication in a Conversational 3D Synthetic Agent},\n volume = {13},\n year = {2000}\n}\n'}","[{'authorId': '1802126', 'name': 'I. Poggi'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1807752', 'name': 'F. D. Rosis'}]"
2034,ae9257f3be9f815db8d72819332372ac59c1316b,Deciphering the Enigmatic Face,"Most studies investigating the recognition of facial expressions have focused on static displays of intense expressions. Consequently, researchers may have underestimated the importance of motion in deciphering the subtle expressions that permeate real-life situations. In two experiments, we examined the effect of motion on perception of subtle facial expressions and tested the hypotheses that motion improves affect judgment by (a) providing denser sampling of expressions, (b) providing dynamic information, (c) facilitating configural processing, and (d) enhancing the perception of change. Participants viewed faces depicting subtle facial expressions in four modes (single-static, multi-static, dynamic, and first-last). Experiment 1 demonstrated a robust effect of motion and suggested that this effect was due to the dynamic property of the expression. Experiment 2 showed that the beneficial effect of motion may be due more specifically to its role in perception of change. Together, these experiments demonstrated the importance of motion in identifying subtle facial expressions.",2005.0,39.0,441.0,False,,"{'volume': '16', 'pages': '403 - 410', 'name': 'Psychological Science'}","{'bibtex': '@Article{Ambadar2005DecipheringTE,\n author = {Z. Ambadar and J. Schooler and J. Cohn},\n journal = {Psychological Science},\n pages = {403 - 410},\n title = {Deciphering the Enigmatic Face},\n volume = {16},\n year = {2005}\n}\n'}","[{'authorId': '2059653', 'name': 'Z. Ambadar'}, {'authorId': '2809346', 'name': 'J. Schooler'}, {'authorId': '1737918', 'name': 'J. Cohn'}]"
2035,ae9928754cd3e21af4f2a894fde3e9e76e7149bd,Wechsler Adult Intelligence Scale-III,,2001.0,4.0,3546.0,False,,"{'volume': '', 'pages': '19-42', 'name': ''}","{'bibtex': '@Inproceedings{Ryan2001WechslerAI,\n author = {J. Ryan and S. Lopez},\n pages = {19-42},\n title = {Wechsler Adult Intelligence Scale-III},\n year = {2001}\n}\n'}","[{'authorId': '46511680', 'name': 'J. Ryan'}, {'authorId': '143931391', 'name': 'S. Lopez'}]"
2036,aead9832b48372ecb284af5bf471768c60f69e18,Looking at human-computer interface design: Effects of ethnicity in computer agents,,2007.0,49.0,67.0,False,,"{'volume': '19', 'pages': '512-523', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Pratt2007LookingAH,\n author = {Jean A. Pratt and K. Hauser and Zsolt Ugray and Olga V. Patterson},\n journal = {Interact. Comput.},\n pages = {512-523},\n title = {Looking at human-computer interface design: Effects of ethnicity in computer agents},\n volume = {19},\n year = {2007}\n}\n'}","[{'authorId': '2254205', 'name': 'Jean A. Pratt'}, {'authorId': '49817642', 'name': 'K. Hauser'}, {'authorId': '2164911', 'name': 'Zsolt Ugray'}, {'authorId': '2143207', 'name': 'Olga V. Patterson'}]"
2037,aec3f10357b843494b440151c6ec9ff21b0f6b35,Speed Dating with an Affective Virtual Agent - Developing a Testbed for Emotion Models,,2010.0,20.0,11.0,False,,{'pages': '91-103'},"{'bibtex': '@Article{Pontier2010SpeedDW,\n author = {M. Pontier and G. F. Siddiqui and J. Hoorn},\n booktitle = {International Conference on Intelligent Virtual Agents},\n pages = {91-103},\n title = {Speed Dating with an Affective Virtual Agent - Developing a Testbed for Emotion Models},\n year = {2010}\n}\n'}","[{'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}, {'authorId': '71825175', 'name': 'J. Hoorn'}]"
2038,aecbfd83f49a7cff9b1192b8156bc4b827f4b519,Assessing the validity of appraisal-based models of emotion,"We describe an empirical study comparing the accuracy of competing computational models of emotion in predicting human emotional responses in naturalistic emotion-eliciting situations. The results find clear differences in models' ability to forecast human emotional responses, and provide guidance on how to develop more accurate models of human emotion.",2009.0,28.0,57.0,False,,"{'pages': '1-8', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Gratch2009AssessingTV,\n author = {J. Gratch and S. Marsella and Ning Wang and B. Stankovic},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-8},\n title = {Assessing the validity of appraisal-based models of emotion},\n year = {2009}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '2074566879', 'name': 'B. Stankovic'}]"
2040,aed9fcf86629b624854ebaa3e21d856daeae1c1d,The Experience of Social Touch in Multi-User Virtual Reality,"We present user study results on virtual body contact experience in a two-user VR scenario, in which participants performed different touches with a research assistant. The interaction evoked different emotional reactions in perceived relaxation, happiness, desire, anxiety, disgust, and fear. Congruent to physical social touch, the evaluation of virtual body contact was modulated by intimacy, touch direction, and sex. Further, individual comfort with interpersonal touch was positively associated with perceived relaxation and happiness. We discuss the results regarding implications for follow-up studies and infer implications for the use of social touch in social VR applications.",2020.0,66.0,24.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3385956.3418944', 'status': None}",{'name': 'Proceedings of the 26th ACM Symposium on Virtual Reality Software and Technology'},"{'bibtex': '@Article{Sykownik2020TheEO,\n author = {Philipp Sykownik and M. Masuch},\n journal = {Proceedings of the 26th ACM Symposium on Virtual Reality Software and Technology},\n title = {The Experience of Social Touch in Multi-User Virtual Reality},\n year = {2020}\n}\n'}","[{'authorId': '35743461', 'name': 'Philipp Sykownik'}, {'authorId': '1716815', 'name': 'M. Masuch'}]"
2041,aee6d6b3282662b69a1020c95be725e0075428bd,Reinforcement Learning: An Introduction,,2005.0,0.0,12800.0,False,,"{'volume': '', 'name': 'IEEE Transactions on Neural Networks'}","{'bibtex': '@Article{Montague2005ReinforcementLA,\n author = {P. Montague},\n journal = {IEEE Transactions on Neural Networks},\n title = {Reinforcement Learning: An Introduction},\n year = {2005}\n}\n'}","[{'authorId': '144895942', 'name': 'P. Montague'}]"
2042,aeeea6eec2f063c006c13be865cec0c350244e5b,"Induced Disgust , Happiness and Surprise : an Addition to the MMI Facial Expression Database","We have acquired a set of audio-visual recordings of induced emotions. A collage of comedy clips and clips of disgusting content were shown to a number of participants, who displayed mostly expressions of disgust, happiness, and surprise in response. While displays of induced emotions may differ from those shown in everyday life in aspects such as the frequency with which they occur, they are regarded as highly naturalistic and spontaneous. We recorded 25 participants for approximately 5 minutes each. This collection of recordings has been added to the MMI Facial Expression Database, an online accessible, easily searchable resource that is freely available to the scientific community.",2010.0,16.0,429.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Valstar2010InducedD,\n author = {M. Valstar and M. Pantic},\n title = {Induced Disgust , Happiness and Surprise : an Addition to the MMI Facial Expression Database},\n year = {2010}\n}\n'}","[{'authorId': '1795528', 'name': 'M. Valstar'}, {'authorId': '145387780', 'name': 'M. Pantic'}]"
2043,af5a71cd9dcde6e19c7430c9ea8c0f3c42f9844f,Communication Behavior in Embodied Virtual Reality,"Embodied virtual reality faithfully renders users' movements onto an avatar in a virtual 3D environment, supporting nuanced nonverbal behavior alongside verbal communication. To investigate communication behavior within this medium, we had 30 dyads complete two tasks using a shared visual workspace: negotiating an apartment layout and placing model furniture on an apartment floor plan. Dyads completed both tasks under three different conditions: face-to-face, embodied VR with visible full-body avatars, and no embodiment VR, where the participants shared a virtual space, but had no visible avatars. Both subjective measures of users' experiences and detailed annotations of verbal and nonverbal behavior are used to understand how the media impact communication behavior. Embodied VR provides a high level of social presence with conversation patterns that are very similar to face-to-face interaction. In contrast, providing only the shared environment was generally found to be lonely and appears to lead to degraded communication.",2018.0,52.0,144.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3173574.3173863', 'status': None}",{'name': 'Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Smith2018CommunicationBI,\n author = {H. Smith and Michael Neff},\n journal = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},\n title = {Communication Behavior in Embodied Virtual Reality},\n year = {2018}\n}\n'}","[{'authorId': '2110645261', 'name': 'H. Smith'}, {'authorId': '143687087', 'name': 'Michael Neff'}]"
2044,af5c23b85edfb56bb0b29c2cef2c41a2bc0efc4c,Empathy,,1971.0,1.0,867.0,False,,"{'volume': '366', 'name': 'The Lancet'}","{'bibtex': '@Article{Hayward1971Empathy,\n author = {R. Hayward},\n journal = {The Lancet},\n title = {Empathy},\n volume = {366},\n year = {1971}\n}\n'}","[{'authorId': '35792669', 'name': 'R. Hayward'}]"
2045,af64a1e32d812fae7736fedd0212b5b2c602a4b3,A method for obtaining 3-dimensional facial expressions and its standardization for use in neurocognitive studies,,2002.0,15.0,609.0,False,,"{'volume': '115', 'pages': '137-143', 'name': 'Journal of Neuroscience Methods'}","{'bibtex': '@Article{Gur2002AMF,\n author = {R. Gur and R. Sára and Michiel Hagendoorn and Oren Marom and P. Hughett and Larry Macy and Travis Turner and R. Bajcsy and Aaron Posner and R. Gur},\n journal = {Journal of Neuroscience Methods},\n pages = {137-143},\n title = {A method for obtaining 3-dimensional facial expressions and its standardization for use in neurocognitive studies},\n volume = {115},\n year = {2002}\n}\n'}","[{'authorId': '144762538', 'name': 'R. Gur'}, {'authorId': '144953681', 'name': 'R. Sára'}, {'authorId': '49084583', 'name': 'Michiel Hagendoorn'}, {'authorId': '2115134677', 'name': 'Oren Marom'}, {'authorId': '2366678', 'name': 'P. Hughett'}, {'authorId': '2115138330', 'name': 'Larry Macy'}, {'authorId': '2114803325', 'name': 'Travis Turner'}, {'authorId': '1784213', 'name': 'R. Bajcsy'}, {'authorId': '103777597', 'name': 'Aaron Posner'}, {'authorId': '2406788', 'name': 'R. Gur'}]"
2046,af71c2aa8ee0b5888dbe339e8030aea4b1efb87c,THE DOER AND THE DEED Action as a Basis for Characterization in Narrative,"Like most other literary-critical terms, ""character,"" ""figure"" or ""person"" are polysemic and ambiguous. For the purpose of this essay, ""character"" or ""person"" in narrative will be understood as designating a human or human-like individual, existing in some possible world, and capable of fulfilling the argument position in the propositional form DO(X) - that is, a Narrative Agent (=NA), to whom inner states, mental properties (traits, features) or complexes of such properties (personality models) can be ascribed on the basis of textual data. This particular explication of the term has the advantage of capturing the reader's intuitive understanding of the term, while at the same time enabling a disciplined and explicit study of this phenomenon within narratology. The ascription of individual mental traits to an NA may be called ""characterization,"" and the ascription of complexes of traits ""character-building"" or ""portraiture."" The two activities are logically and substantively different. The first is the primary one and is based on inference drawn from individual acts of the NA, details of his looks and setting, etc. (see below). Character-building, on the other hand, comes later and involves several additional operations. These include the accumulation of a number of traits from several successive acts of the NA, setting, or formal patterns; a generalization concerning their extent in terms of narrative time; the classification or categorization of these traits; their interrelation in terms of a network or hierarchy of traits; a confrontation of traits belonging to successive acts in order to infer second order traits such as ""inconsistent""; and finally, an attempt to interrelate the traits or trait-clusters into a unified stable constellation (configuration, pattern, Gestalt, personality model) of some duration in terms of narrative time. Character-building consists of a succession of individual operations of characterization, together with second order activities of continual patterning and repatterning of the traits obtained in the first order operations, until a fairly coherent",1986.0,3.0,38.0,False,,"{'volume': '7', 'pages': '205', 'name': 'Poetics Today'}","{'bibtex': '@Article{Margolin1986THEDA,\n author = {Uri Margolin},\n journal = {Poetics Today},\n pages = {205},\n title = {THE DOER AND THE DEED Action as a Basis for Characterization in Narrative},\n volume = {7},\n year = {1986}\n}\n'}","[{'authorId': '113677166', 'name': 'Uri Margolin'}]"
2047,af7b3323c7f3b80c3da6c0be78a85475aad1354a,A review of empirical evidence on different uncanny valley hypotheses: support for perceptual mismatch as one road to the valley of eeriness,"The uncanny valley hypothesis, proposed already in the 1970s, suggests that almost but not fully humanlike artificial characters will trigger a profound sense of unease. This hypothesis has become widely acknowledged both in the popular media and scientific research. Surprisingly, empirical evidence for the hypothesis has remained inconsistent. In the present article, we reinterpret the original uncanny valley hypothesis and review empirical evidence for different theoretically motivated uncanny valley hypotheses. The uncanny valley could be understood as the naïve claim that any kind of human-likeness manipulation will lead to experienced negative affinity at close-to-realistic levels. More recent hypotheses have suggested that the uncanny valley would be caused by artificial–human categorization difficulty or by a perceptual mismatch between artificial and human features. Original formulation also suggested that movement would modulate the uncanny valley. The reviewed empirical literature failed to provide consistent support for the naïve uncanny valley hypothesis or the modulatory effects of movement. Results on the categorization difficulty hypothesis were still too scarce to allow drawing firm conclusions. In contrast, good support was found for the perceptual mismatch hypothesis. Taken together, the present review findings suggest that the uncanny valley exists only under specific conditions. More research is still needed to pinpoint the exact conditions under which the uncanny valley phenomenon manifests itself.",2015.0,83.0,281.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00390/pdf', 'status': None}","{'volume': '6', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Kätsyri2015ARO,\n author = {J. Kätsyri and Klaus Förger and Meeri Mäkäräinen and T. Takala},\n journal = {Frontiers in Psychology},\n title = {A review of empirical evidence on different uncanny valley hypotheses: support for perceptual mismatch as one road to the valley of eeriness},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '48160993', 'name': 'J. Kätsyri'}, {'authorId': '46618154', 'name': 'Klaus Förger'}, {'authorId': '2950835', 'name': 'Meeri Mäkäräinen'}, {'authorId': '1894905', 'name': 'T. Takala'}]"
2048,af8d3a41a0d809081b5d1eee2a8cf14601b14be0,"Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017",,2018.0,159.0,4988.0,True,"{'url': 'http://www.thelancet.com/article/S0140673618322797/pdf', 'status': None}","{'volume': '392', 'pages': '1789 - 1858', 'name': 'Lancet (London, England)'}","{'bibtex': '@Article{Abbastabar2018GlobalRA,\n author = {Spencer L Degu Kalkidan Hassen Solomon M Cristiana Nooshin James Abate Abate Abay Abbafati Abbasi Abbastabar  and S. James and D. Abate and K. H. Abate and Solomon M Abay and C. Abbafati and Nooshin Abbasi and H. Abbastabar and F. Abd-Allah and Jemal Abdela and A. Abdelalim and Ibrahim Abdollahpour and R. Abdulkader and Zegeye Abebe and S. Abera and Olifan Zewdie Abil and H. Abraha and L. Abu-Raddad and Niveen M E Abu-Rmeileh and Manfred Accrombessi and Dilaram Acharya and Pawan Acharya and Ilana N Ackerman and Abdullahi Adamu and O. Adebayo and V. Adekanmbi and O. Adetokunboh and Mina G. Adib and Jose C. Adsuar and K. Afanvi and Mohsen Afarideh and A. Afshin and Gina Agarwal and Kareha M Agesa and Rakesh Aggarwal and S. Aghayan and S. Agrawal and Alireza Ahmadi and Mehdi Ahmadi and H. Ahmadieh and M. Ahmed and Amani Nidhal Aichour and Ibtihel Aichour and Miloud Taki Eddine Aichour and Tomi F Akinyemiju and N. Akseer and Z. Al‐Aly and A. Al-Eyadhy and Hesham M Al-Mekhlafi and Rajaa Al-Raddadi and Fares Alahdab and K. Alam and Tahiya Alam and Alaa Alashi and S. Alavian and K. Alene and M. Alijanzadeh and R. Alizadeh-Navaei and S. Aljunid and A. Alkerwi and François Alla and Peter Allebeck and Mohamed M L Alouani and K. Altirkawi and N. Alvis-Guzmán and A. Amare and L. Aminde and W. Ammar and Y. Amoako and N. Anber and C. Andrei and S. Androudi and Megbaru Debalkie Animut and Mina Anjomshoa and Mustafa Geleto Ansha and C. Antonio and P. Anwari and J. Arabloo and Antonio Arauz and O. Aremu and F. Ariani and Bahroom Armoon and Johan Ärnlöv and Amit Arora and A. Artaman and K. Aryal and H. Asayesh and R. J. Asghar and Z. Ataro and Sachin R Atre and M. Ausloos and L. Ávila-Burgos and Euripide Avokpaho and A. Awasthi and B. A. Ayala Quintanilla and R. Ayer and P. Azzopardi and A. Babazadeh and Hamid Badali and A. Badawi and A. G. Bali and Katherine E Ballesteros and S. Ballew and Maciej Banach and J. Banoub and A. Banstola and A. Barać and Miguel A Barboza and S. Barker-Collo and T. Bärnighausen and L. Barrero and B. Baune and S. Bazargan-Hejazi and Neeraj Bedi and Ettore Beghi and Masoud Behzadifar and M. Behzadifar and Yannick Béjot and A. Belachew and Yihalem Abebe Belay and Michelle L. Bell and A. Bello and Isabela M Bensenor and Eduardo Bernabé and Robert S Bernstein and M. Beuran and Tina Beyranvand and N. Bhala and S. Bhattarai and Soumyadeep Bhaumik and Z. Bhutta and B. Biadgo and A. Bijani and B. Bikbov and V. Bilano and Nigus Bililign and M. B. Bin Sayeed and D. Bisanzio and B. Blacker and Fiona M. Blyth and I. Bou-Orm and S. Boufous and R. Bourne and Oliver J. Brady and Michael Brainin and L. C. Brant and A. Brazinova and N. Breitborde and Hermann Brenner and P. Briant and Andrew M Briggs and A. Briko and Gabrielle B Britton and T. Brugha and Rachelle Buchbinder and Reinhard Busse and Z. Butt and Lucero Cahuana-Hurtado and Jorge Cano and Rosario Cárdenas and J. Carrero and A. Carter and F. Carvalho and C. Castañeda-Orjuela and Jacqueline Castillo Rivas and Franz Castro and Ferrán Catalá-López and Kelly M. Cercy and Ester Cerin and Y. Chaiah and Alex R Chang and Hsing-Yi Chang and Jung-Chen Chang and F. Charlson and Aparajita Chattopadhyay and V. Chattu and Pankaj Chaturvedi and P. Chiang and Ken Lee Chin and Abdulaal Chitheer and J. Choi and Rajiv Chowdhury and H. Christensen and D. Christopher and F. Cicuttini and Liliana G. Ciobanu and Massimo Cirillo and R. M. Claro and D. Collado-Mateo and Cyrus Cooper and Josef Coresh and P. Cortesi and Monica Cortinovis and Megan Costa and Ewerton Cousin and M. Criqui and Elizabeth A. Cromwell and M. Cross and J. Crump and A. F. Dadi and L. Dandona and R. Dandona and Paul I Dargan and A. Daryani and R. Das Gupta and J. D. das Neves and T. Dasa and Gail Davey and A. Davis and D. Davițoiu and B. de Courten and Fernando Pio De La Hoz and Diego De Leo and Jan‐Walter De Neve and M. G. Degefa and L. Degenhardt and Selina Deiparine and R. Dellavalle and Gebre Teklemariam Demoz and Kebede Deribe and N. Dervenis and Don C. Des Jarlais and Getenet Dessie and Subhojit Dey and S. Dharmaratne and Mesfin Tadese Dinberu and M. Dirac and Shirin Djalalinia and L. Doan and K. Dokova and D. Doku and E. R. Dorsey and Kerrie E. Doyle and T. Driscoll and M. Dubey and E. Dubljanin and Eyasu Ejeta Duken and Bruce B. Duncan and A. Durães and H. Ebrahimi and S. Ebrahimpour and M. Echko and D. Edvardsson and A. Effiong and Joshua R Ehrlich and C. El Bcheraoui and M. El Sayed Zaki and Z. El-Khatib and H. Elkout and Iqbal Elyazar and A. Enayati and A. Endries and Benjamin Er and H. Erskine and B. Eshrati and S. Eskandarieh and Alireza Esteghamati and S. Esteghamati and H. Fakhim and Vahid Fallah Omrani and Mahbobeh Faramarzi and M. Fareed and F. Farhadi and Talha A Farid and C. Farinha and Andrea Farioli and Andre Faro and M. Farvid and F. Farzadfar and Valery L Feigin and Netsanet Fentahun and S. Fereshtehnejad and Eduarda Fernandes and Joao C Fernandes and A. Ferrari and Garumma Tolu Feyissa and I. Filip and Florian Fischer and C. Fitzmaurice and N. Foigt and Kyle Foreman and Jack T Fox and Tahvi D Frank and Takeshi Fukumoto and N. Fullman and Thomas Fürst and João M Furtado and Neal D Futran and S. Gall and M. Ganji and F. Gankpé and A. García-Basteiro and William M Gardner and A. Gebre and A. Gebremedhin and Teklu Gebrehiwo Gebremichael and Tilayie Feto Gelano and J. Geleijnse and R. Gènova-Maleras and Y. C. D. Geramo and P. Gething and Kebede Embaye Gezae and K. Ghadiri and Khalil Ghasemi Falavarjani and M. Ghasemi-Kasman and M. Ghimire and Rakesh Ghosh and Aloke G. Ghoshal and Simona Giampaoli and P. Gill and Tiffany K. Gill and I. Ginawi and G. Giussani and E. Gnedovskaya and Ellen M. Goldberg and Srinivas Goli and H. Gómez-Dantés and P. Gona and S. Gopalani and Taren M Gorman and A. Goulart and B. N. Goulart and A. Grada and Morgan E. Grams and Giuseppe Grosso and H. Gugnani and Yuming Guo and Prakash C Gupta and Rahul Gupta and R. Gupta and Tanush Gupta and Bishal Gyawali and J. Haagsma and Vladimir Hachinski and N. Hafezi-Nejad and Hassan Haghparast Bidgoli and Tekleberhan B Hagos and G. B. Hailu and Arvin Haj-Mirzaian and A. Haj-Mirzaian and R. Hamadeh and S. Hamidi and A. Handal and Graeme J. Hankey and Yuantao Hao and H. Harb and Sivadasanpillai Harikrishnan and J. Haro and M. Hasan and H. Hassankhani and H. Y. Hassen and Rasmus J Havmoeller and Caitlin N Hawley and Roderick J Hay and S. Hay and A. Hedayatizadeh-Omran and B. Heibati and D. Hendrie and A. Henok and C. Herteliu and S. Heydarpour and D. T. Hibstu and Huong Thanh Hoang and Hans W. Hoek and Howard J Hoffman and M. K. Hole and Enayatollah Homaie Rad and Praveen Hoogar and H. Hosgood and Seyed Mostafa Hosseini and M. Hosseinzadeh and M. Hostiuc and S. Hostiuc and Peter J. Hotez and D. Hoy and M. Hsairi and A. Htet and Guoqing Hu and John J Emmanuel Huang and Chantal K Huynh and K. Iburg and C. Ikeda and B. Ileanu and O S Ilesanmi and Usman Iqbal and S. Irvani and C. Irvine and Sheikh Mohammed Shariful Islam and F. Islami and K. Jacobsen and L. Jahangiry and N. Jahanmehr and Sudhir Kumar Jain and Mihajlo Jakovljevic and Mehdi Javanbakht and A. Jayatilleke and P. Jeemon and Ravi Prakash Jha and Vivekanand Jha and John S Ji and C. Johnson and J. Jonas and J. Jozwiak and Suresh Jungari and Mikk Jürisson and Zubair Kabir and R. Kadel and Amaha Kahsay and Rizwan Kalani and T. Kanchan and Manoochehr Karami and B. Karami Matin and André Karch and C. Karema and Narges Karimi and Seyed M. Karimi and A. Kasaeian and D. H. Kassa and G. Kassa and T. Kassa and N. Kassebaum and S. Katikireddi and Norito Kawakami and Ali Kazemi Karyani and Masoud Keighobadi and P. Keiyoro and L. Kemmer and Grant Rodgers Kemp and A. Kengne and Andre Keren and Yousef S. Khader and Behzad Khafaei and M. Khafaie and Alireza Khajavi and I. Khalil and E. Khan and M. Khan and Muhammad Ali Khan and Y. Khang and Mohammad Khazaei and Abdullah Khoja and A. Khosravi and Mohammad Hossein Khosravi and A. Kiadaliri and Daniel N. Kiirithio and Cho-il Kim and Daniel H. Kim and Pauline Kim and Young-Eun Kim and Y. Kim and R. Kimokoti and Y. Kinfu and A. Kisa and K. Kissimova-Skarbek and Mika Kivimäki and A. Knudsen and Jonathan M Kocarnik and S. Kochhar and Yoshihiro Kokubo and T. Kolola and Jacek A. Kopec and S. Kosen and Georgios A Kotsakis and P. Koul and Ai Koyanagi and M. Kravchenko and K. Krishan and Kristopher J. Krohn and B. Kuate Defo and B. Kucuk Bicer and G. Kumar and Manasi Kumar and H. Kyu and Deepesh P Lad and S. Lad and A. Lafranconi and R. Lalloo and T. Lallukka and Faris Lami and V. Lansingh and A. Latifi and Kathryn M. Lau and Jeffrey V. Lazarus and J. Leasher and J. R. Ledesma and P. H. Lee and J. Leigh and Janni Leung and Miriam Levi and S. Lewycka and Shanshan Li and Yichong Li and Yu Liao and Misgan Legesse Liben and Lee-Ling Lim and Stephen S. Lim and Shiwei Liu and R. Lodha and Katharine J Looker and A. D. Lopez and Stefan Lorkowski and P. Lotufo and Nicola Low and Rafael Lozano and T. Lucas and L. R. Lucchesi and R. Lunevicius and R. Lyons and Stefan Ma and Erlyn K Macarayan and Mark T Mackay and Fabiana Madotto and H. Magdy Abd El Razek and Muhammed Magdy Abd El Razek and Dhaval P. Maghavani and N. Mahotra and Hue Thi Mai and M. Majdan and Reza Majdzadeh and Azeem Majeed and R. Malekzadeh and Deborah Carvalho Malta and A. A. Mamun and Ana-Laura Manda and Helena Manguerra and Treh Manhertz and Mohammad Ali Mansournia and L. Mantovani and C. Mapoma and Joemer C. Maravilla and W. Marcenes and Ashley Marks and Francisco Rogerlândio Martins-Melo and Ira Martopullo and Winfried März and M. Marzan and T. Mashamba-Thompson and B. Massenburg and M. Mathur and Kunihiro Matsushita and P. Maulik and M. Mazidi and C. McAlinden and John J McGrath and M. McKee and M. Mehndiratta and Ravi Mehrotra and Kala M. Mehta and Varshil Mehta and Fabiola Mejía-Rodríguez and Tesfa Mekonen and A. Melese and M. Melku and Michele Meltzer and P. Memiah and Ziad A. Memish and W. Mendoza and D. T. Mengistu and G. Mengistu and George A. Mensah and S. T. Mereta and A. Meretoja and T. Meretoja and T. Meštrović and Naser Mohammad gholi Mezerji and Bartosz Miazgowski and T. Miazgowski and Anoushka I Millear and Ted R. Miller and Benjamin Miltz and G. Mini and M. Mirarefin and E. Mirrakhimov and A. Misganaw and Philip B Mitchell and H. Mitiku and B. Moazen and B. Mohajer and K. Mohammad and N. Mohammadifard and M. Mohammadnia-Afrouzi and Mohammed A Mohammed and S. Mohammed and F. Mohebi and Modhurima Moitra and A. Mokdad and M. Molokhia and L. Monasta and Y. Moodley and M. Moosazadeh and Ghobad Moradi and M. Moradi-Lakeh and Mehdi Moradinazar and P. Moraga and Lidia Morawska and Ilais Moreno Velásquez and J. Morgado-da-Costa and S. D. Morrison and M. Moschos and Seyyed Meysam Mousavi and K. B. Mruts and A. Muche and Kindie Fentahun Muchie and U. Mueller and O. Muhammed and Satinath Mukhopadhyay and Kate Muller and J. Mumford and Manoj V. Murhekar and Jonah Musa and K. I. Musa and Ghulam Mustafa and A. F. Nabhan and Chie Nagata and M. Naghavi and A. Naheed and A. Nahvijou and G. Naik and Nitish Naik and Farid Najafi and Luigi Naldi and Hae Sung Nam and V. Nangia and J. R. Nansseu and B. R. Nascimento and Gopalakrishnan Natarajan and N. Neamati and I. Negoi and R. Negoi and Subas Neupane and C. R. Newton and J. Ngunjiri and Anh Quynh Nguyen and Ha Thu Nguyen and Huong Lan Thi Nguyen and Huong Thanh Nguyen and L. H. Nguyen and Minh Nguyen and N. B. Nguyen and S. H. Nguyen and E. Nichols and D. N. A. Ningrum and M. Nixon and Nomonde Nolutshungu and Shuhei Nomura and O. Norheim and M. Noroozi and B. Norrving and J. J. Noubiap and H. Nouri and M. Nourollahpour Shiadeh and M. Nowroozi and E. Nsoesie and Peter S Nyasulu and Christopher M. Odell and R. Ofori-Asenso and F. Ogbo and In-Hwan Oh and O. Oladimeji and A. Olagunju and T. Olagunju and Pedro R Olivares and H. Olsen and B. Olusanya and K. Ong and S. Ong and Eyal Oren and Alberto Ortiz and E. Ota and Stanislav S. Otstavnov and Simon Øverland and M. Owolabi and M. P. A. and R. Pacella and Amir H. Pakpour and A. Pana and S. Panda‐Jonas and Andrea Parisi and Eun-Kee Park and Charles D H Parry and Shanti Patel and S. Pati and Snehal T. Patil and Ajay Patle and George C. Patton and V. R. Paturi and Katherine R Paulson and Neil Pearce and David M Pereira and N. Perico and Konrad Pesudovs and H. Pham and Michael Robert Phillips and D. Pigott and J. Pillay and M. Piradov and M. Pirsaheb and F. Pishgar and O. Plana-Ripoll and Dietrich Plass and S. Polinder and Svetlana Popova and Maarten J. Postma and A. Pourshams and H. Poustchi and D. Prabhakaran and Swayam Prakash and V. Prakash and Caroline A. Purcell and M. Purwar and Mostafa Qorbani and D. A. Quistberg and A. Radfar and Anwar Rafay and A. Rafiei and F. Rahim and Kazem Rahimi and A. Rahimi-Movaghar and V. Rahimi-Movaghar and Mahfuzar Rahman and Mohammad Hifz Ur Rahman and Muhammad Aziz Rahman and Sajjad Ur Rahman and R. Rai and Fatemeh Rajati and U. Ram and Prabhat Ranjan and A. Ranta and P. Rao and D. Rawaf and S. Rawaf and K. S. Reddy and R. Reiner and Nickolas Reinig and M. Reitsma and G. Remuzzi and Andre M. N. Renzaho and S. Resnikoff and S. Rezaei and M. S. Rezai and A. L. Ribeiro and Stephen R Robinson and L. Roever and L. Ronfani and G. Roshandel and Ali Rostami and Gregory A Roth and Ambuj Roy and Enrico Rubagotti and Perminder S. Sachdev and Nafis Sadat and B. Saddik and Ehsan Sadeghi and S. Saeedi Moghaddam and H. Safari and Y. Safari and R. Safari-Faramani and M. Safdarian and S. Safi and Saeid Safiri and Rajesh Sagar and A. Sahebkar and M. Sahraian and Haniye Sadat Sajadi and Nasir Salam and Joseph S. Salama and Payman Salamati and Komal Saleem and Zikria Saleem and Yahya Salimi and Joshua A. Salomon and S. Salvi and I. Salz and A. Samy and Juan R Sanabria and Y. Sang and D. Santomauro and I. Santos and João Vasco Santos and M. Šantrić Milićević and Bruno Piassi Sao Jose and M. Sardana and A. Sarker and N. Sarrafzadegan and B. Sartorius and S. Sarvi and B. Sathian and Maheswar Satpathy and Arundhati R Sawant and M. Sawhney and S. Saxena and Mete Saylan and Elke Schaeffner and M.I. Schmidt and I. Schneider and Ben Schöttker and D. Schwebel and Falk Schwendicke and James G Scott and M. Šekerija and S. Sepanlou and E. Serván-Mori and Seyedmojtaba Seyedmousavi and Hosein Shabaninejad and Azadeh Shafieesabet and M. Shahbazi and A. Shaheen and M. Shaikh and Mehran Shams-Beyranvand and M. Shamsi and M. Shamsizadeh and H. Sharafi and K. Sharafi and M. Sharif and M. Sharif-Alhoseini and Meenakshi Sharma and Rajesh Sharma and Jun She and Aziz Sheikh and Peilin Shi and Kenji Shibuya and M. Shigematsu and R. Shiri and R. Shirkoohi and K. Shishani and I. Shiue and F. Shokraneh and H. Shoman and M. Shrime and Si Si and S. Siabani and T. Siddiqi and I. Sigfusdottir and Rannveig Sigurvinsdottir and J. Silva and D. Silveira and N. Singam and Jasvinder A. Singh and Narinder Pal Singh and Virendra Singh and D. Sinha and Eirini Skiadaresi and E. Slepak and Karen Sliwa and David L Smith and Mari Smith and Adauto Martins Soares Filho and B. Sobaih and S. Sobhani and E. Sobngwi and S. Soneji and M. Soofi and Masoud Soosaraei and Reed J. D. Sorensen and Joan B Soriano and Ireneous N. Soyiri and L. Sposato and C. Sreeramareddy and V. Srinivasan and J. Stanaway and D. Stein and C. Steiner and Timothy J Steiner and Mark A Stokes and L. Stovner and Michelle L. Subart and A. Sudaryanto and M. Sufiyan and B. Sunguya and P. Sur and I. Sutradhar and Bryan L. Sykes and Dillon O Sylte and R. Tabarés-Seisdedos and S. Tadakamadla and B. T. Tadesse and Nikhil Tandon and S. Tassew and M. Tavakkoli and N. Taveira and Hugh R Taylor and Arash Tehrani-Banihashemi and Tigist Gashaw Tekalign and Shishay Wahdey Tekelemedhin and Merhawi Gebremedhin Tekle and H. Temesgen and M. Temsah and Omar Temsah and A. Terkawi and Mebrahtu Teweldemedhin and K. Thankappan and Nihal Thomas and B. Tilahun and Q. To and Marcello Tonelli and R. Topor-Madry and F. Topouzis and Anna E. Torre and M. Tortajada-Girbés and Mathilde Touvier and M. Tovani-Palone and J. Towbin and Bach Xuan Tran and Khanh B. Tran and C. Troeger and T. Truelsen and M. Tsilimbaris and Derrick Tsoi and Lorainne Tudor Car and E. Tuzcu and K. Ukwaja and Irfan Ullah and E. Undurraga and J. Unutzer and R. Updike and M. Usman and O. Uthman and M. Vaduganathan and A. Vaezi and P. Valdez and S. Varughese and T. Vasankari and N. Venketasubramanian and S. Villafaina and F. S. Violante and S. Vladimirov and V. Vlassov and S. Vollset and K. Vosoughi and I. Vujcic and Fasil Wagnew and Yasir Waheed and Stephen G Waller and Yafeng Wang and Yuan-Pang Wang and E. Weiderpass and Robert G Weintraub and Daniel J Weiss and Fitsum Weldegebreal and Kidu Gidey Weldegwergs and A. Werdecker and T. E. West and Harvey A. Whiteford and Justyna Widecka and T. Wijeratne and Lauren B. Wilner and Shadrach Wilson and Andrea S. Winkler and A. Wiyeh and C. S. Wiysonge and Charles D A Wolfe and Anthony D Woolf and Shouling Wu and Yun-Chun Wu and Grant M A Wyper and Denis Xavier and Gelin Xu and Simon R Yadgir and A. Yadollahpour and Seyed Hossein Yahyazadeh Jabbari and Tomohide Yamada and Lijing L. Yan and Yuichiro Yano and M. Yaseri and Y. J. Yasin and Alex Yeshaneh and Ebrahim M. Yimer and Paul Yip and E. Yisma and N. Yonemoto and Seok-Jun Yoon and M. Yotebieng and M. Younis and M. Yousefifard and Chuanhua Yu and V. Zadnik and Z. Zaidi and S. Zaman and M. Zamani and Z. Zare and A. Zeleke and Z. M. Zenebe and Kai Zhang and Zheng Zhao and Maigeng Zhou and S. Zodpey and Inbar Zucker and T. Vos and C. Murray},\n journal = {Lancet (London, England)},\n pages = {1789 - 1858},\n title = {Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017},\n volume = {392},\n year = {2018}\n}\n'}","[{'authorId': None, 'name': 'Spencer L Degu Kalkidan Hassen Solomon M Cristiana Nooshin James Abate Abate Abay Abbafati Abbasi Abbastabar '}, {'authorId': '50791451', 'name': 'S. James'}, {'authorId': '29530223', 'name': 'D. Abate'}, {'authorId': '3543310', 'name': 'K. H. Abate'}, {'authorId': '2253473877', 'name': 'Solomon M Abay'}, {'authorId': '8272851', 'name': 'C. Abbafati'}, {'authorId': '2236358461', 'name': 'Nooshin Abbasi'}, {'authorId': '3921695', 'name': 'H. Abbastabar'}, {'authorId': '1380173279', 'name': 'F. Abd-Allah'}, {'authorId': '16651307', 'name': 'Jemal Abdela'}, {'authorId': '8430656', 'name': 'A. Abdelalim'}, {'authorId': '2245810908', 'name': 'Ibrahim Abdollahpour'}, {'authorId': '3877692', 'name': 'R. Abdulkader'}, {'authorId': '8638890', 'name': 'Zegeye Abebe'}, {'authorId': '4473319', 'name': 'S. Abera'}, {'authorId': '51924425', 'name': 'Olifan Zewdie Abil'}, {'authorId': '22261520', 'name': 'H. Abraha'}, {'authorId': '1389737341', 'name': 'L. Abu-Raddad'}, {'authorId': '2245813477', 'name': 'Niveen M E Abu-Rmeileh'}, {'authorId': '5025795', 'name': 'Manfred Accrombessi'}, {'authorId': '2245812738', 'name': 'Dilaram Acharya'}, {'authorId': '2245811540', 'name': 'Pawan Acharya'}, {'authorId': '2257589958', 'name': 'Ilana N Ackerman'}, {'authorId': '152125837', 'name': 'Abdullahi Adamu'}, {'authorId': '12480889', 'name': 'O. Adebayo'}, {'authorId': '48041197', 'name': 'V. Adekanmbi'}, {'authorId': '8003495', 'name': 'O. Adetokunboh'}, {'authorId': '51877136', 'name': 'Mina G. Adib'}, {'authorId': '2191459031', 'name': 'Jose C. Adsuar'}, {'authorId': '5184272', 'name': 'K. Afanvi'}, {'authorId': '2238866218', 'name': 'Mohsen Afarideh'}, {'authorId': '6667488', 'name': 'A. Afshin'}, {'authorId': '2245811353', 'name': 'Gina Agarwal'}, {'authorId': '51929978', 'name': 'Kareha M Agesa'}, {'authorId': '2110049974', 'name': 'Rakesh Aggarwal'}, {'authorId': '14573009', 'name': 'S. Aghayan'}, {'authorId': '38031807', 'name': 'S. Agrawal'}, {'authorId': '2257551681', 'name': 'Alireza Ahmadi'}, {'authorId': '2058961704', 'name': 'Mehdi Ahmadi'}, {'authorId': '2037304', 'name': 'H. Ahmadieh'}, {'authorId': '48797032', 'name': 'M. Ahmed'}, {'authorId': '24312538', 'name': 'Amani Nidhal Aichour'}, {'authorId': '24284955', 'name': 'Ibtihel Aichour'}, {'authorId': '24290306', 'name': 'Miloud Taki Eddine Aichour'}, {'authorId': '2256515772', 'name': 'Tomi F Akinyemiju'}, {'authorId': '5841392', 'name': 'N. Akseer'}, {'authorId': '1382885412', 'name': 'Z. Al‐Aly'}, {'authorId': '7968190', 'name': 'A. Al-Eyadhy'}, {'authorId': '2178655519', 'name': 'Hesham M Al-Mekhlafi'}, {'authorId': '1404754550', 'name': 'Rajaa Al-Raddadi'}, {'authorId': '4466057', 'name': 'Fares Alahdab'}, {'authorId': '49584865', 'name': 'K. Alam'}, {'authorId': '4120272', 'name': 'Tahiya Alam'}, {'authorId': '2240625949', 'name': 'Alaa Alashi'}, {'authorId': '84296508', 'name': 'S. Alavian'}, {'authorId': '5808467', 'name': 'K. Alene'}, {'authorId': '8565153', 'name': 'M. Alijanzadeh'}, {'authorId': '1393628081', 'name': 'R. Alizadeh-Navaei'}, {'authorId': '3191034', 'name': 'S. Aljunid'}, {'authorId': '3515741', 'name': 'A. Alkerwi'}, {'authorId': '2245814213', 'name': 'François Alla'}, {'authorId': '2249387515', 'name': 'Peter Allebeck'}, {'authorId': '2257717361', 'name': 'Mohamed M L Alouani'}, {'authorId': '7506393', 'name': 'K. Altirkawi'}, {'authorId': '1382885100', 'name': 'N. Alvis-Guzmán'}, {'authorId': '8338000', 'name': 'A. Amare'}, {'authorId': '4045733', 'name': 'L. Aminde'}, {'authorId': '153304529', 'name': 'W. Ammar'}, {'authorId': '6786482', 'name': 'Y. Amoako'}, {'authorId': '5840271', 'name': 'N. Anber'}, {'authorId': '13730120', 'name': 'C. Andrei'}, {'authorId': '6354568', 'name': 'S. Androudi'}, {'authorId': '51881581', 'name': 'Megbaru Debalkie Animut'}, {'authorId': '5581219', 'name': 'Mina Anjomshoa'}, {'authorId': '23615626', 'name': 'Mustafa Geleto Ansha'}, {'authorId': '8408197', 'name': 'C. Antonio'}, {'authorId': '7345936', 'name': 'P. Anwari'}, {'authorId': '6239913', 'name': 'J. Arabloo'}, {'authorId': '2238104946', 'name': 'Antonio Arauz'}, {'authorId': '5685777', 'name': 'O. Aremu'}, {'authorId': '34816279', 'name': 'F. Ariani'}, {'authorId': '2257717270', 'name': 'Bahroom Armoon'}, {'authorId': '2237749014', 'name': 'Johan Ärnlöv'}, {'authorId': '2257638134', 'name': 'Amit Arora'}, {'authorId': '7411216', 'name': 'A. Artaman'}, {'authorId': '5386972', 'name': 'K. Aryal'}, {'authorId': '3961067', 'name': 'H. Asayesh'}, {'authorId': '2250999236', 'name': 'R. J. Asghar'}, {'authorId': '40370064', 'name': 'Z. Ataro'}, {'authorId': '2252861170', 'name': 'Sachin R Atre'}, {'authorId': '2151199248', 'name': 'M. Ausloos'}, {'authorId': '1390172488', 'name': 'L. Ávila-Burgos'}, {'authorId': '8554259', 'name': 'Euripide Avokpaho'}, {'authorId': '2534282', 'name': 'A. Awasthi'}, {'authorId': '8504503', 'name': 'B. A. Ayala Quintanilla'}, {'authorId': '34590275', 'name': 'R. Ayer'}, {'authorId': '3232220', 'name': 'P. Azzopardi'}, {'authorId': '10758721', 'name': 'A. Babazadeh'}, {'authorId': '2250939737', 'name': 'Hamid Badali'}, {'authorId': '145537648', 'name': 'A. Badawi'}, {'authorId': '51890105', 'name': 'A. G. Bali'}, {'authorId': '51296932', 'name': 'Katherine E Ballesteros'}, {'authorId': '5742561', 'name': 'S. Ballew'}, {'authorId': '2104898325', 'name': 'Maciej Banach'}, {'authorId': '15268455', 'name': 'J. Banoub'}, {'authorId': '3682904', 'name': 'A. Banstola'}, {'authorId': '31465432', 'name': 'A. Barać'}, {'authorId': '2240421235', 'name': 'Miguel A Barboza'}, {'authorId': '1387830552', 'name': 'S. Barker-Collo'}, {'authorId': '2247935442', 'name': 'T. Bärnighausen'}, {'authorId': '2440643', 'name': 'L. Barrero'}, {'authorId': '2131047254', 'name': 'B. Baune'}, {'authorId': '2152012', 'name': 'S. Bazargan-Hejazi'}, {'authorId': '4642370', 'name': 'Neeraj Bedi'}, {'authorId': '2238483712', 'name': 'Ettore Beghi'}, {'authorId': '4013616', 'name': 'Masoud Behzadifar'}, {'authorId': '3872319', 'name': 'M. Behzadifar'}, {'authorId': '2248360446', 'name': 'Yannick Béjot'}, {'authorId': '4815558', 'name': 'A. Belachew'}, {'authorId': '46182431', 'name': 'Yihalem Abebe Belay'}, {'authorId': '2247257692', 'name': 'Michelle L. Bell'}, {'authorId': '145905521', 'name': 'A. Bello'}, {'authorId': '2251962022', 'name': 'Isabela M Bensenor'}, {'authorId': '2242560536', 'name': 'Eduardo Bernabé'}, {'authorId': '2245812123', 'name': 'Robert S Bernstein'}, {'authorId': '4093701', 'name': 'M. Beuran'}, {'authorId': '51247778', 'name': 'Tina Beyranvand'}, {'authorId': '3644262', 'name': 'N. Bhala'}, {'authorId': '1379789528', 'name': 'S. Bhattarai'}, {'authorId': '2240445317', 'name': 'Soumyadeep Bhaumik'}, {'authorId': '13613845', 'name': 'Z. Bhutta'}, {'authorId': '5650512', 'name': 'B. Biadgo'}, {'authorId': '34174674', 'name': 'A. Bijani'}, {'authorId': '49692793', 'name': 'B. Bikbov'}, {'authorId': '47451359', 'name': 'V. Bilano'}, {'authorId': '9531358', 'name': 'Nigus Bililign'}, {'authorId': '8225952', 'name': 'M. B. Bin Sayeed'}, {'authorId': '6070916', 'name': 'D. Bisanzio'}, {'authorId': '50811830', 'name': 'B. Blacker'}, {'authorId': '2239447867', 'name': 'Fiona M. Blyth'}, {'authorId': '1399278399', 'name': 'I. Bou-Orm'}, {'authorId': '4759692', 'name': 'S. Boufous'}, {'authorId': '2066283190', 'name': 'R. Bourne'}, {'authorId': '2247289621', 'name': 'Oliver J. Brady'}, {'authorId': '2257109091', 'name': 'Michael Brainin'}, {'authorId': '2209343580', 'name': 'L. C. Brant'}, {'authorId': '4389878', 'name': 'A. Brazinova'}, {'authorId': '144376742', 'name': 'N. Breitborde'}, {'authorId': '2237664444', 'name': 'Hermann Brenner'}, {'authorId': '51915910', 'name': 'P. Briant'}, {'authorId': '2240636922', 'name': 'Andrew M Briggs'}, {'authorId': '46254218', 'name': 'A. Briko'}, {'authorId': '2245814677', 'name': 'Gabrielle B Britton'}, {'authorId': '48962604', 'name': 'T. Brugha'}, {'authorId': '2238868657', 'name': 'Rachelle Buchbinder'}, {'authorId': '2223390667', 'name': 'Reinhard Busse'}, {'authorId': '8444968', 'name': 'Z. Butt'}, {'authorId': '1398967834', 'name': 'Lucero Cahuana-Hurtado'}, {'authorId': '2249945163', 'name': 'Jorge Cano'}, {'authorId': '134626992', 'name': 'Rosario Cárdenas'}, {'authorId': '2245815118', 'name': 'J. Carrero'}, {'authorId': '8208882', 'name': 'A. Carter'}, {'authorId': '67266295', 'name': 'F. Carvalho'}, {'authorId': '1396794108', 'name': 'C. Castañeda-Orjuela'}, {'authorId': '115093311', 'name': 'Jacqueline Castillo Rivas'}, {'authorId': '40648067', 'name': 'Franz Castro'}, {'authorId': '2240430884', 'name': 'Ferrán Catalá-López'}, {'authorId': '47375203', 'name': 'Kelly M. Cercy'}, {'authorId': '2243759229', 'name': 'Ester Cerin'}, {'authorId': '51894656', 'name': 'Y. Chaiah'}, {'authorId': '2257541086', 'name': 'Alex R Chang'}, {'authorId': '2257948028', 'name': 'Hsing-Yi Chang'}, {'authorId': '48808996', 'name': 'Jung-Chen Chang'}, {'authorId': '6001547', 'name': 'F. Charlson'}, {'authorId': '2245811652', 'name': 'Aparajita Chattopadhyay'}, {'authorId': '3776828', 'name': 'V. Chattu'}, {'authorId': '2257597710', 'name': 'Pankaj Chaturvedi'}, {'authorId': '49170011', 'name': 'P. Chiang'}, {'authorId': '2256225900', 'name': 'Ken Lee Chin'}, {'authorId': '10227612', 'name': 'Abdulaal Chitheer'}, {'authorId': '88811832', 'name': 'J. Choi'}, {'authorId': '1759513', 'name': 'Rajiv Chowdhury'}, {'authorId': '153670186', 'name': 'H. Christensen'}, {'authorId': '145096723', 'name': 'D. Christopher'}, {'authorId': '2240064182', 'name': 'F. Cicuttini'}, {'authorId': '7947028', 'name': 'Liliana G. Ciobanu'}, {'authorId': '2053365784', 'name': 'Massimo Cirillo'}, {'authorId': '2256287257', 'name': 'R. M. Claro'}, {'authorId': '1397415315', 'name': 'D. Collado-Mateo'}, {'authorId': '2257490993', 'name': 'Cyrus Cooper'}, {'authorId': '2257584721', 'name': 'Josef Coresh'}, {'authorId': '2237996248', 'name': 'P. Cortesi'}, {'authorId': '3565510', 'name': 'Monica Cortinovis'}, {'authorId': '2249567071', 'name': 'Megan Costa'}, {'authorId': '46255582', 'name': 'Ewerton Cousin'}, {'authorId': '10029674', 'name': 'M. Criqui'}, {'authorId': '2257634564', 'name': 'Elizabeth A. Cromwell'}, {'authorId': '144919788', 'name': 'M. Cross'}, {'authorId': '3863653', 'name': 'J. Crump'}, {'authorId': '6224601', 'name': 'A. F. Dadi'}, {'authorId': '3624717', 'name': 'L. Dandona'}, {'authorId': '5666172', 'name': 'R. Dandona'}, {'authorId': '2257629849', 'name': 'Paul I Dargan'}, {'authorId': '4751403', 'name': 'A. Daryani'}, {'authorId': '46247361', 'name': 'R. Das Gupta'}, {'authorId': '2127509902', 'name': 'J. D. das Neves'}, {'authorId': '79649562', 'name': 'T. Dasa'}, {'authorId': '2248110059', 'name': 'Gail Davey'}, {'authorId': '40386300', 'name': 'A. Davis'}, {'authorId': '7267119', 'name': 'D. Davițoiu'}, {'authorId': '7829724', 'name': 'B. de Courten'}, {'authorId': '2245811969', 'name': 'Fernando Pio De La Hoz'}, {'authorId': '2245816469', 'name': 'Diego De Leo'}, {'authorId': '6728229', 'name': 'Jan‐Walter De Neve'}, {'authorId': '51881692', 'name': 'M. G. Degefa'}, {'authorId': '2251723584', 'name': 'L. Degenhardt'}, {'authorId': '51886975', 'name': 'Selina Deiparine'}, {'authorId': '2250837534', 'name': 'R. Dellavalle'}, {'authorId': '41158172', 'name': 'Gebre Teklemariam Demoz'}, {'authorId': '5928220', 'name': 'Kebede Deribe'}, {'authorId': '4161915', 'name': 'N. Dervenis'}, {'authorId': '2245811985', 'name': 'Don C. Des Jarlais'}, {'authorId': '5243540', 'name': 'Getenet Dessie'}, {'authorId': '4608017', 'name': 'Subhojit Dey'}, {'authorId': '3782043', 'name': 'S. Dharmaratne'}, {'authorId': '51887916', 'name': 'Mesfin Tadese Dinberu'}, {'authorId': '8860807', 'name': 'M. Dirac'}, {'authorId': '116681037', 'name': 'Shirin Djalalinia'}, {'authorId': '150186187', 'name': 'L. Doan'}, {'authorId': '1380379452', 'name': 'K. Dokova'}, {'authorId': '5062866', 'name': 'D. Doku'}, {'authorId': '2240443585', 'name': 'E. R. Dorsey'}, {'authorId': '2071438', 'name': 'Kerrie E. Doyle'}, {'authorId': '2245818043', 'name': 'T. Driscoll'}, {'authorId': '48115074', 'name': 'M. Dubey'}, {'authorId': '4375638', 'name': 'E. Dubljanin'}, {'authorId': '8542974', 'name': 'Eyasu Ejeta Duken'}, {'authorId': '2239649240', 'name': 'Bruce B. Duncan'}, {'authorId': '4518656', 'name': 'A. Durães'}, {'authorId': '3988495', 'name': 'H. Ebrahimi'}, {'authorId': '4997692', 'name': 'S. Ebrahimpour'}, {'authorId': '40900240', 'name': 'M. Echko'}, {'authorId': '3775564', 'name': 'D. Edvardsson'}, {'authorId': '1379789271', 'name': 'A. Effiong'}, {'authorId': '2257516013', 'name': 'Joshua R Ehrlich'}, {'authorId': '4660623', 'name': 'C. El Bcheraoui'}, {'authorId': '117084215', 'name': 'M. El Sayed Zaki'}, {'authorId': '1398967847', 'name': 'Z. El-Khatib'}, {'authorId': '4376805', 'name': 'H. Elkout'}, {'authorId': '2201045405', 'name': 'Iqbal Elyazar'}, {'authorId': '2080111091', 'name': 'A. Enayati'}, {'authorId': '7705540', 'name': 'A. Endries'}, {'authorId': '2245811672', 'name': 'Benjamin Er'}, {'authorId': '5971622', 'name': 'H. Erskine'}, {'authorId': '6237061', 'name': 'B. Eshrati'}, {'authorId': '4362142', 'name': 'S. Eskandarieh'}, {'authorId': '2237186735', 'name': 'Alireza Esteghamati'}, {'authorId': '5694096', 'name': 'S. Esteghamati'}, {'authorId': '145832132', 'name': 'H. Fakhim'}, {'authorId': '134833467', 'name': 'Vahid Fallah Omrani'}, {'authorId': '2245815034', 'name': 'Mahbobeh Faramarzi'}, {'authorId': '1404346347', 'name': 'M. Fareed'}, {'authorId': '2694161', 'name': 'F. Farhadi'}, {'authorId': '2245814106', 'name': 'Talha A Farid'}, {'authorId': '1717742', 'name': 'C. Farinha'}, {'authorId': '2257486520', 'name': 'Andrea Farioli'}, {'authorId': '79524205', 'name': 'Andre Faro'}, {'authorId': '4616927', 'name': 'M. Farvid'}, {'authorId': '5785969', 'name': 'F. Farzadfar'}, {'authorId': '2242798301', 'name': 'Valery L Feigin'}, {'authorId': '5494376', 'name': 'Netsanet Fentahun'}, {'authorId': '51879228', 'name': 'S. Fereshtehnejad'}, {'authorId': '2245815760', 'name': 'Eduarda Fernandes'}, {'authorId': '2257641143', 'name': 'Joao C Fernandes'}, {'authorId': '38334221', 'name': 'A. Ferrari'}, {'authorId': '79597694', 'name': 'Garumma Tolu Feyissa'}, {'authorId': '98591128', 'name': 'I. Filip'}, {'authorId': '2238725777', 'name': 'Florian Fischer'}, {'authorId': '4982486', 'name': 'C. Fitzmaurice'}, {'authorId': '7793834', 'name': 'N. Foigt'}, {'authorId': '116189314', 'name': 'Kyle Foreman'}, {'authorId': '1471137188', 'name': 'Jack T Fox'}, {'authorId': '47976495', 'name': 'Tahvi D Frank'}, {'authorId': '2238811388', 'name': 'Takeshi Fukumoto'}, {'authorId': '3756261', 'name': 'N. Fullman'}, {'authorId': '49324203', 'name': 'Thomas Fürst'}, {'authorId': '2245811391', 'name': 'João M Furtado'}, {'authorId': '2245812695', 'name': 'Neal D Futran'}, {'authorId': '48504286', 'name': 'S. Gall'}, {'authorId': '143740943', 'name': 'M. Ganji'}, {'authorId': '8461029', 'name': 'F. Gankpé'}, {'authorId': '1398465968', 'name': 'A. García-Basteiro'}, {'authorId': '2241479139', 'name': 'William M Gardner'}, {'authorId': '40997857', 'name': 'A. Gebre'}, {'authorId': '10053591', 'name': 'A. Gebremedhin'}, {'authorId': '51906589', 'name': 'Teklu Gebrehiwo Gebremichael'}, {'authorId': '35702695', 'name': 'Tilayie Feto Gelano'}, {'authorId': '6431370', 'name': 'J. Geleijnse'}, {'authorId': '120232099', 'name': 'R. Gènova-Maleras'}, {'authorId': '51928643', 'name': 'Y. C. D. Geramo'}, {'authorId': '1864915', 'name': 'P. Gething'}, {'authorId': '51921050', 'name': 'Kebede Embaye Gezae'}, {'authorId': '3536478', 'name': 'K. Ghadiri'}, {'authorId': '2245812912', 'name': 'Khalil Ghasemi Falavarjani'}, {'authorId': '1402636364', 'name': 'M. Ghasemi-Kasman'}, {'authorId': '2082765', 'name': 'M. Ghimire'}, {'authorId': '2245820192', 'name': 'Rakesh Ghosh'}, {'authorId': '2257723751', 'name': 'Aloke G. Ghoshal'}, {'authorId': '2246581958', 'name': 'Simona Giampaoli'}, {'authorId': '2242128849', 'name': 'P. Gill'}, {'authorId': '2238778077', 'name': 'Tiffany K. Gill'}, {'authorId': '50406834', 'name': 'I. Ginawi'}, {'authorId': '3640372', 'name': 'G. Giussani'}, {'authorId': '9025455', 'name': 'E. Gnedovskaya'}, {'authorId': '114738224', 'name': 'Ellen M. Goldberg'}, {'authorId': '27437418', 'name': 'Srinivas Goli'}, {'authorId': '77245465', 'name': 'H. Gómez-Dantés'}, {'authorId': '4539326', 'name': 'P. Gona'}, {'authorId': '5754239', 'name': 'S. Gopalani'}, {'authorId': '51921069', 'name': 'Taren M Gorman'}, {'authorId': '2241885078', 'name': 'A. Goulart'}, {'authorId': '33138629', 'name': 'B. N. Goulart'}, {'authorId': '11527043', 'name': 'A. Grada'}, {'authorId': '2243704950', 'name': 'Morgan E. Grams'}, {'authorId': '2257452162', 'name': 'Giuseppe Grosso'}, {'authorId': '5111667', 'name': 'H. Gugnani'}, {'authorId': '2247369687', 'name': 'Yuming Guo'}, {'authorId': '2258534306', 'name': 'Prakash C Gupta'}, {'authorId': '1617807983', 'name': 'Rahul Gupta'}, {'authorId': '2110344784', 'name': 'R. Gupta'}, {'authorId': '2245813904', 'name': 'Tanush Gupta'}, {'authorId': '2246441871', 'name': 'Bishal Gyawali'}, {'authorId': '2695200', 'name': 'J. Haagsma'}, {'authorId': '2240979710', 'name': 'Vladimir Hachinski'}, {'authorId': '1401624764', 'name': 'N. Hafezi-Nejad'}, {'authorId': '117482817', 'name': 'Hassan Haghparast Bidgoli'}, {'authorId': '2245815210', 'name': 'Tekleberhan B Hagos'}, {'authorId': '1865582', 'name': 'G. B. Hailu'}, {'authorId': '1401817213', 'name': 'Arvin Haj-Mirzaian'}, {'authorId': '1397932257', 'name': 'A. Haj-Mirzaian'}, {'authorId': '4734173', 'name': 'R. Hamadeh'}, {'authorId': '144110014', 'name': 'S. Hamidi'}, {'authorId': '5532090', 'name': 'A. Handal'}, {'authorId': '2237499321', 'name': 'Graeme J. Hankey'}, {'authorId': '2245965589', 'name': 'Yuantao Hao'}, {'authorId': '32288199', 'name': 'H. Harb'}, {'authorId': '2238319788', 'name': 'Sivadasanpillai Harikrishnan'}, {'authorId': '2067882521', 'name': 'J. Haro'}, {'authorId': '2078334945', 'name': 'M. Hasan'}, {'authorId': '6236514', 'name': 'H. Hassankhani'}, {'authorId': '14853114', 'name': 'H. Y. Hassen'}, {'authorId': '88664387', 'name': 'Rasmus J Havmoeller'}, {'authorId': '1404827955', 'name': 'Caitlin N Hawley'}, {'authorId': '2106961779', 'name': 'Roderick J Hay'}, {'authorId': '2088787', 'name': 'S. Hay'}, {'authorId': '102184805', 'name': 'A. Hedayatizadeh-Omran'}, {'authorId': '12994972', 'name': 'B. Heibati'}, {'authorId': '39608729', 'name': 'D. Hendrie'}, {'authorId': '10695533', 'name': 'A. Henok'}, {'authorId': '11045635', 'name': 'C. Herteliu'}, {'authorId': '10404591', 'name': 'S. Heydarpour'}, {'authorId': '22612052', 'name': 'D. T. Hibstu'}, {'authorId': '2257708894', 'name': 'Huong Thanh Hoang'}, {'authorId': '2242483409', 'name': 'Hans W. Hoek'}, {'authorId': '2111563784', 'name': 'Howard J Hoffman'}, {'authorId': '47082401', 'name': 'M. K. Hole'}, {'authorId': '4045220', 'name': 'Enayatollah Homaie Rad'}, {'authorId': '2135606874', 'name': 'Praveen Hoogar'}, {'authorId': '152796705', 'name': 'H. Hosgood'}, {'authorId': '2245905020', 'name': 'Seyed Mostafa Hosseini'}, {'authorId': '2138729058', 'name': 'M. Hosseinzadeh'}, {'authorId': '4297895', 'name': 'M. Hostiuc'}, {'authorId': '5769596', 'name': 'S. Hostiuc'}, {'authorId': '2243311118', 'name': 'Peter J. Hotez'}, {'authorId': '3166743', 'name': 'D. Hoy'}, {'authorId': '7236546', 'name': 'M. Hsairi'}, {'authorId': '3263282', 'name': 'A. Htet'}, {'authorId': '2246745623', 'name': 'Guoqing Hu'}, {'authorId': '2031795991', 'name': 'John J Emmanuel Huang'}, {'authorId': '1397305959', 'name': 'Chantal K Huynh'}, {'authorId': '6952820', 'name': 'K. Iburg'}, {'authorId': '46226106', 'name': 'C. Ikeda'}, {'authorId': '10286643', 'name': 'B. Ileanu'}, {'authorId': '3960883', 'name': 'O S Ilesanmi'}, {'authorId': '2066229537', 'name': 'Usman Iqbal'}, {'authorId': '46181760', 'name': 'S. Irvani'}, {'authorId': '40897204', 'name': 'C. Irvine'}, {'authorId': '2237975779', 'name': 'Sheikh Mohammed Shariful Islam'}, {'authorId': '5813941', 'name': 'F. Islami'}, {'authorId': '1810896', 'name': 'K. Jacobsen'}, {'authorId': '5055341', 'name': 'L. Jahangiry'}, {'authorId': '5427157', 'name': 'N. Jahanmehr'}, {'authorId': '2249741762', 'name': 'Sudhir Kumar Jain'}, {'authorId': '2148313071', 'name': 'Mihajlo Jakovljevic'}, {'authorId': '6188933', 'name': 'Mehdi Javanbakht'}, {'authorId': '34236843', 'name': 'A. Jayatilleke'}, {'authorId': '4103656', 'name': 'P. Jeemon'}, {'authorId': '2257487680', 'name': 'Ravi Prakash Jha'}, {'authorId': '2075161726', 'name': 'Vivekanand Jha'}, {'authorId': '2257460108', 'name': 'John S Ji'}, {'authorId': '2238118843', 'name': 'C. Johnson'}, {'authorId': '1851144', 'name': 'J. Jonas'}, {'authorId': '144494294', 'name': 'J. Jozwiak'}, {'authorId': '15721232', 'name': 'Suresh Jungari'}, {'authorId': '5652492', 'name': 'Mikk Jürisson'}, {'authorId': '2238866203', 'name': 'Zubair Kabir'}, {'authorId': '46565942', 'name': 'R. Kadel'}, {'authorId': '46260781', 'name': 'Amaha Kahsay'}, {'authorId': '48495225', 'name': 'Rizwan Kalani'}, {'authorId': '3381430', 'name': 'T. Kanchan'}, {'authorId': '2237964944', 'name': 'Manoochehr Karami'}, {'authorId': '5800517', 'name': 'B. Karami Matin'}, {'authorId': '2257494074', 'name': 'André Karch'}, {'authorId': '5808458', 'name': 'C. Karema'}, {'authorId': '2245817526', 'name': 'Narges Karimi'}, {'authorId': '11016464', 'name': 'Seyed M. Karimi'}, {'authorId': '82392523', 'name': 'A. Kasaeian'}, {'authorId': '46207022', 'name': 'D. H. Kassa'}, {'authorId': '2986070', 'name': 'G. Kassa'}, {'authorId': '46192488', 'name': 'T. Kassa'}, {'authorId': '6756736', 'name': 'N. Kassebaum'}, {'authorId': '3691127', 'name': 'S. Katikireddi'}, {'authorId': '2239975973', 'name': 'Norito Kawakami'}, {'authorId': '8266078', 'name': 'Ali Kazemi Karyani'}, {'authorId': '2257610109', 'name': 'Masoud Keighobadi'}, {'authorId': '144307689', 'name': 'P. Keiyoro'}, {'authorId': '5679487', 'name': 'L. Kemmer'}, {'authorId': '2245817907', 'name': 'Grant Rodgers Kemp'}, {'authorId': '2194601968', 'name': 'A. Kengne'}, {'authorId': '2245816038', 'name': 'Andre Keren'}, {'authorId': '2172234799', 'name': 'Yousef S. Khader'}, {'authorId': '51877672', 'name': 'Behzad Khafaei'}, {'authorId': '6169898', 'name': 'M. Khafaie'}, {'authorId': '2245817727', 'name': 'Alireza Khajavi'}, {'authorId': '46361321', 'name': 'I. Khalil'}, {'authorId': '33782404', 'name': 'E. Khan'}, {'authorId': '2152497008', 'name': 'M. Khan'}, {'authorId': '2246748934', 'name': 'Muhammad Ali Khan'}, {'authorId': '5181120', 'name': 'Y. Khang'}, {'authorId': '2245813336', 'name': 'Mohammad Khazaei'}, {'authorId': '3953479', 'name': 'Abdullah Khoja'}, {'authorId': '5145639', 'name': 'A. Khosravi'}, {'authorId': '1832574716', 'name': 'Mohammad Hossein Khosravi'}, {'authorId': '4582713', 'name': 'A. Kiadaliri'}, {'authorId': '46259246', 'name': 'Daniel N. Kiirithio'}, {'authorId': '2246788329', 'name': 'Cho-il Kim'}, {'authorId': '2111372935', 'name': 'Daniel H. Kim'}, {'authorId': '6567082', 'name': 'Pauline Kim'}, {'authorId': '2243895911', 'name': 'Young-Eun Kim'}, {'authorId': '90841871', 'name': 'Y. Kim'}, {'authorId': '3518889', 'name': 'R. Kimokoti'}, {'authorId': '4861657', 'name': 'Y. Kinfu'}, {'authorId': '46580287', 'name': 'A. Kisa'}, {'authorId': '1399769382', 'name': 'K. Kissimova-Skarbek'}, {'authorId': '2250941780', 'name': 'Mika Kivimäki'}, {'authorId': '3797208', 'name': 'A. Knudsen'}, {'authorId': '6436920', 'name': 'Jonathan M Kocarnik'}, {'authorId': '87991116', 'name': 'S. Kochhar'}, {'authorId': '2240443777', 'name': 'Yoshihiro Kokubo'}, {'authorId': '7997240', 'name': 'T. Kolola'}, {'authorId': '2250163614', 'name': 'Jacek A. Kopec'}, {'authorId': '152233784', 'name': 'S. Kosen'}, {'authorId': '2254310750', 'name': 'Georgios A Kotsakis'}, {'authorId': '5318184', 'name': 'P. Koul'}, {'authorId': '2188633440', 'name': 'Ai Koyanagi'}, {'authorId': '144389579', 'name': 'M. Kravchenko'}, {'authorId': '46434163', 'name': 'K. Krishan'}, {'authorId': '49573494', 'name': 'Kristopher J. Krohn'}, {'authorId': '6953990', 'name': 'B. Kuate Defo'}, {'authorId': '7862805', 'name': 'B. Kucuk Bicer'}, {'authorId': '2241655536', 'name': 'G. Kumar'}, {'authorId': '2246133102', 'name': 'Manasi Kumar'}, {'authorId': '3783694', 'name': 'H. Kyu'}, {'authorId': '2240058685', 'name': 'Deepesh P Lad'}, {'authorId': '51910568', 'name': 'S. Lad'}, {'authorId': '52238454', 'name': 'A. Lafranconi'}, {'authorId': '5577782', 'name': 'R. Lalloo'}, {'authorId': '5232086', 'name': 'T. Lallukka'}, {'authorId': '46998993', 'name': 'Faris Lami'}, {'authorId': '7330933', 'name': 'V. Lansingh'}, {'authorId': '144813820', 'name': 'A. Latifi'}, {'authorId': '144831322', 'name': 'Kathryn M. Lau'}, {'authorId': '2237967676', 'name': 'Jeffrey V. Lazarus'}, {'authorId': '8058936', 'name': 'J. Leasher'}, {'authorId': '52089781', 'name': 'J. R. Ledesma'}, {'authorId': '73155726', 'name': 'P. H. Lee'}, {'authorId': '11712726', 'name': 'J. Leigh'}, {'authorId': '2245814997', 'name': 'Janni Leung'}, {'authorId': '2238871443', 'name': 'Miriam Levi'}, {'authorId': '6677277', 'name': 'S. Lewycka'}, {'authorId': '2144504121', 'name': 'Shanshan Li'}, {'authorId': '2257957895', 'name': 'Yichong Li'}, {'authorId': '2246170367', 'name': 'Yu Liao'}, {'authorId': '8268491', 'name': 'Misgan Legesse Liben'}, {'authorId': '2245813743', 'name': 'Lee-Ling Lim'}, {'authorId': '2238204084', 'name': 'Stephen S. Lim'}, {'authorId': '2246228124', 'name': 'Shiwei Liu'}, {'authorId': '104126550', 'name': 'R. Lodha'}, {'authorId': '2239422192', 'name': 'Katharine J Looker'}, {'authorId': '2241213246', 'name': 'A. D. Lopez'}]"
2049,af9c9e1a6e9519d04403eed4050cd277c0e80160,Virtual humans for assisted health care,"There is a growing need for applications that can dynamically interact with aging populations to gather information, monitor their health care, provide information, or even act as companions. Virtual human agents or virtual characters offer a technology that can enable human users to overcome the confusing interfaces found in current human-computer interactions. These artificially intelligent virtual characters have speech recognition, natural language and vision that will allow human users to interact with their computers in a more natural way. Additionally, sensors may be used to monitor the environment for specific behaviors that can be fused into a virtual human system. As a result, the virtual human may respond to a patient or elderly person in a manner that will have a powerful affect on their living situation. This paper will describe the virtual human technology developed and some current applications that apply the technology to virtual patients for mental health diagnosis and clinician training. Additionally the paper will discuss possible ways in which the virtual humans may be utilized for assisted health care and for the integration of multi-modal input to enhance the virtual human system.",2008.0,13.0,60.0,True,"{'url': 'https://psychology.unt.edu/%7Etparsons/pdf/Parsons_Virtual%20Humans%20for%20Assisted%20Health%20Care.pdf', 'status': None}",{'pages': '6'},"{'bibtex': '@Inproceedings{Kenny2008VirtualHF,\n author = {Patrick G. Kenny and T. Parsons and J. Gratch and A. Rizzo},\n pages = {6},\n title = {Virtual humans for assisted health care},\n year = {2008}\n}\n'}","[{'authorId': '3181776', 'name': 'Patrick G. Kenny'}, {'authorId': '145842705', 'name': 'T. Parsons'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '29861580', 'name': 'A. Rizzo'}]"
2050,afd2e426df00d9bd4bf261581a3d0d21f36f6d7a,From a User-created Corpus of Virtual Agent's Non-verbal Behavior to a Computational Model of Interpersonal Attitudes,,2013.0,27.0,60.0,False,,{'pages': '263-274'},"{'bibtex': ""@Inproceedings{Ravenet2013FromAU,\n author = {Brian Ravenet and M. Ochs and C. Pelachaud},\n pages = {263-274},\n title = {From a User-created Corpus of Virtual Agent's Non-verbal Behavior to a Computational Model of Interpersonal Attitudes},\n year = {2013}\n}\n""}","[{'authorId': '1682486', 'name': 'Brian Ravenet'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2052,afd496c5a4c135206d12479961b373c6d1cb7ad3,On the Narrative Self,,2016.0,0.0,62.0,False,,"{'volume': '38', 'pages': '12-15', 'name': 'German Research'}","{'bibtex': '@Article{Axmacher2016OnTN,\n author = {N. Axmacher},\n journal = {German Research},\n pages = {12-15},\n title = {On the Narrative Self},\n volume = {38},\n year = {2016}\n}\n'}","[{'authorId': '2117280', 'name': 'N. Axmacher'}]"
2053,b00b08e486ee4b4f24ad4ebf2671626678af0a5a,Pedagogical agents as social models for engineering: The influence of agent appearance on female choice,"The current work examined the influence of pedagogical agents as social models to increase females' interest in engineering. Seventy-nine female undergraduate students rated pedagogical agents on a series of factors (e.g., most like themselves, most like an engineer, and most prefer to learn from). The agents were identical with the exception of differing by appearance/image in four aspects (age, gender, attractiveness, “coolness”). After selecting the agent from which they most preferred to learn, participants interacted with it for approximately 15 minutes and received a persuasive message about engineering. Results indicated that the women were more likely to choose a female, attractive, young, and cool agent as most like themselves and the one they most wanted to be like. However, they tended to select male, older, uncool agents as the most like engineers and tended to choose to learn about engineering from agents that were male and attractive, but uncool. Interacting with an agent had a positive impact on math-related beliefs. Specifically, the women reported more positive math and science related beliefs compared to their attitudes at the beginning of the semester and compared to a group of women who did not interact with an agent. Further, among the women who viewed an agent, the older version of the agent had a stronger positive influence on their math-related beliefs than the younger agent.",2005.0,14.0,67.0,False,,{'pages': '65-72'},"{'bibtex': '@Inproceedings{Baylor2005PedagogicalAA,\n author = {A. L. Baylor and E. Plant},\n pages = {65-72},\n title = {Pedagogical agents as social models for engineering: The influence of agent appearance on female choice},\n year = {2005}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}, {'authorId': '145202321', 'name': 'E. Plant'}]"
2054,b05c1cbe28ec875962cf19e4f4ff35c3cc1ed99c,Genetic Alterations in Pesticide Exposed Bolivian Farmers,"Background Pesticides are of concern in Bolivia because of increasing use. Frequent intoxications have been demonstrated due to use of very toxic pesticides, insufficient control of distribution and sale and little knowledge among farmers of protective measures and hygienic procedures. Method Questionnaires were applied and blood tests taken from 81 volunteers from La Paz County, of whom 48 were pesticide exposed farmers and 33 non-exposed controls. Sixty males and 21 females participated with a mean age of 37.3 years (range 17–76). Data of exposure and possible genetic damage were collected and evaluated by well known statistical methods, controlling for relevant confounders. To measure genetic damage chromosomal aberrations and the comet assay analysis were performed. Results Pesticide exposed farmers had a higher degree of genetic damage compared to the control group. The number of chromosomal aberrations increased with the intensity of pesticide exposure. Females had a lower number of chromosomal aberrations than males, and people living at altitudes above 2500 metres seemed to exhibit more DNA damage measured by the comet assay. Conclusions Bolivian farmers showed signs of genotoxic damage, probably related to exposure to pesticides. Due to the potentially negative long term health effects of genetic damage on reproduction and the development of cancer, preventive measures are recommended. Effective control with imports and sales, banning of the most toxic pesticides, education and information are possible measures, which could help preventing the negative effects of pesticides on human health and the environment.",2007.0,26.0,44.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/117727190700200017', 'status': None}","{'volume': '2', 'pages': '439 - 445', 'name': 'Biomarker Insights'}","{'bibtex': '@Article{Jørs2007GeneticAI,\n author = {E. Jørs and Ana Rosa Gonzáles and Maria Eugenia Ascarrunz and Noemi Tirado and Catharina Takahashi and Erika Lafuente and Raquel A Dos Santos and Natalia Bailon and Rafael Cervantes and Huici O and Jesper Bælum and Flemming Lander.},\n journal = {Biomarker Insights},\n pages = {439 - 445},\n title = {Genetic Alterations in Pesticide Exposed Bolivian Farmers},\n volume = {2},\n year = {2007}\n}\n'}","[{'authorId': '80031913', 'name': 'E. Jørs'}, {'authorId': '2247300844', 'name': 'Ana Rosa Gonzáles'}, {'authorId': '2247325504', 'name': 'Maria Eugenia Ascarrunz'}, {'authorId': '2247289997', 'name': 'Noemi Tirado'}, {'authorId': '2247309918', 'name': 'Catharina Takahashi'}, {'authorId': '2247290428', 'name': 'Erika Lafuente'}, {'authorId': '2247294611', 'name': 'Raquel A Dos Santos'}, {'authorId': '2247294057', 'name': 'Natalia Bailon'}, {'authorId': '2055888664', 'name': 'Rafael Cervantes'}, {'authorId': '2247309548', 'name': 'Huici O'}, {'authorId': '2247292265', 'name': 'Jesper Bælum'}, {'authorId': '2241640032', 'name': 'Flemming Lander.'}]"
2055,b072be95bd56c9c9fbf4b466da236d5f0fec9815,The spontaneous expression of pride and shame: Evidence for biologically innate nonverbal displays,"The present research examined whether the recognizable nonverbal expressions associated with pride and shame may be biologically innate behavioral responses to success and failure. Specifically, we tested whether sighted, blind, and congenitally blind individuals across cultures spontaneously display pride and shame behaviors in response to the same success and failure situations—victory and defeat at the Olympic or Paralympic Games. Results showed that sighted, blind, and congenitally blind individuals from >30 nations displayed the behaviors associated with the prototypical pride expression in response to success. Sighted, blind, and congenitally blind individuals from most cultures also displayed behaviors associated with shame in response to failure. However, culture moderated the shame response among sighted athletes: it was less pronounced among individuals from highly individualistic, self-expression-valuing cultures, primarily in North America and West Eurasia. Given that congenitally blind individuals across cultures showed the shame response to failure, findings overall are consistent with the suggestion that the behavioral expressions associated with both shame and pride are likely to be innate, but the shame display may be intentionally inhibited by some sighted individuals in accordance with cultural norms.",2008.0,58.0,431.0,True,"{'url': 'https://europepmc.org/articles/pmc2575323?pdf=render', 'status': None}","{'volume': '105', 'pages': '11655 - 11660', 'name': 'Proceedings of the National Academy of Sciences'}","{'bibtex': '@Article{Tracy2008TheSE,\n author = {J. Tracy and D. Matsumoto},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {11655 - 11660},\n title = {The spontaneous expression of pride and shame: Evidence for biologically innate nonverbal displays},\n volume = {105},\n year = {2008}\n}\n'}","[{'authorId': '37930132', 'name': 'J. Tracy'}, {'authorId': '145413880', 'name': 'D. Matsumoto'}]"
2056,b07e6104d909b6d81a2f382d6d2a0400dd430f97,Emotion-Regulation Choice,"Despite centuries of speculation about how to manage negative emotions, little is actually known about which emotion-regulation strategies people choose to use when confronted with negative situations of varying intensity. On the basis of a new process conception of emotion regulation, we hypothesized that in low-intensity negative situations, people would show a relative preference to choose to regulate emotions by engagement reappraisal, which allows emotional processing. However, we expected people in high-intensity negative situations to show a relative preference to choose to regulate emotions by disengagement distraction, which blocks emotional processing at an early stage before it gathers force. In three experiments, we created emotional contexts that varied in intensity, using either emotional pictures (Experiments 1 and 2) or unpredictable electric stimulation (Experiment 3). In response to these emotional contexts, participants chose between using either reappraisal or distraction as an emotion-regulation strategy. Results in all experiments supported our hypothesis. This pattern in the choice of emotion-regulation strategies has important implications for the understanding of healthy adaptation.",2011.0,25.0,1097.0,False,,"{'volume': '22', 'pages': '1391 - 1396', 'name': 'Psychological Science'}","{'bibtex': '@Article{Sheppes2011EmotionRegulationC,\n author = {G. Sheppes and S. Scheibe and G. Suri and J. Gross},\n journal = {Psychological Science},\n pages = {1391 - 1396},\n title = {Emotion-Regulation Choice},\n volume = {22},\n year = {2011}\n}\n'}","[{'authorId': '5236984', 'name': 'G. Sheppes'}, {'authorId': '5576156', 'name': 'S. Scheibe'}, {'authorId': '47763916', 'name': 'G. Suri'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
2057,b088a550a2841ee332ad8ca8a6398b3837916cb8,The study of emotion from the perspective of cognitive neuroscience,,2000.0,0.0,61.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lane2000TheSO,\n author = {R. Lane and L. Nadel and John J. B. Allen and A. Kaszniak},\n title = {The study of emotion from the perspective of cognitive neuroscience},\n year = {2000}\n}\n'}","[{'authorId': '50480971', 'name': 'R. Lane'}, {'authorId': '145890227', 'name': 'L. Nadel'}, {'authorId': '143897032', 'name': 'John J. B. Allen'}, {'authorId': '2310149', 'name': 'A. Kaszniak'}]"
2058,b08a998e86ec77ee2b88d0702469b169a8d51bf3,Exploring the Relationship between Modified Output and Working Memory Capacity.,"This study examines the relationship between learners’ production of modified output and their working memory (WM) capacity. The task-based interactions of 42 college-level, native English-speaking learners of Spanish as a foreign language were examined. A relationship was found between learners’ WM test scores and their tendency to modify output. Specifically, greater processing capacity was related to greater production of modified output during interaction.",2010.0,75.0,173.0,False,,"{'volume': '60', 'pages': '501-533', 'name': 'Language Learning'}","{'bibtex': '@Article{Mackey2010ExploringTR,\n author = {Alison Mackey and R. Adams and C. Stafford and Paula M. Winke},\n journal = {Language Learning},\n pages = {501-533},\n title = {Exploring the Relationship between Modified Output and Working Memory Capacity.},\n volume = {60},\n year = {2010}\n}\n'}","[{'authorId': '118340139', 'name': 'Alison Mackey'}, {'authorId': '48460302', 'name': 'R. Adams'}, {'authorId': '82135016', 'name': 'C. Stafford'}, {'authorId': '11063619', 'name': 'Paula M. Winke'}]"
2059,b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca,Robust Real-Time Face Detection,,2001.0,20.0,15955.0,False,,"{'volume': '57', 'pages': '137-154', 'name': 'International Journal of Computer Vision'}","{'bibtex': '@Article{Viola2001RobustRF,\n author = {Paul A. Viola and Michael J. Jones},\n journal = {International Journal of Computer Vision},\n pages = {137-154},\n title = {Robust Real-Time Face Detection},\n volume = {57},\n year = {2001}\n}\n'}","[{'authorId': '2247495712', 'name': 'Paul A. Viola'}, {'authorId': '145319478', 'name': 'Michael J. Jones'}]"
2060,b0a4b7c77f82893c7acd5fe3eea6c8f39ba4b1c6,Virtual humans elicit socially anxious interactants' verbal self‐disclosure,"We explored the relationship between interactants' social anxiety and the interactional fidelity of virtual humans. We specifically addressed whether the contingent non‐verbal feedback of virtual humans affects the association between interactants' social anxiety and their verbal self‐disclosure. This subject was investigated across three experimental conditions where participants interacted with real human videos and virtual humans in computer‐mediated interview interactions. The results demonstrated that socially anxious people revealed more information and greater intimate information about themselves when interacting with a virtual human when compared with real human video interaction, whereas less socially anxious people did not show this difference. We discuss the implication of this association between the interactional fidelity of virtual humans and social anxiety in a human interactant on the design of an embodied virtual agent for social skills' training and psychotherapy. Copyright © 2010 John Wiley & Sons, Ltd.",2010.0,34.0,16.0,False,,"{'volume': '21', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': ""@Article{Kang2010VirtualHE,\n author = {Sin-Hwa Kang and J. Gratch},\n journal = {Computer Animation and Virtual Worlds},\n title = {Virtual humans elicit socially anxious interactants' verbal self‐disclosure},\n volume = {21},\n year = {2010}\n}\n""}","[{'authorId': '34728215', 'name': 'Sin-Hwa Kang'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2061,b0aa882ed17230c6b478530c9758e74ead2dab15,"Interpersonal distance, body orientation, and touch: effects of culture, gender, and age.","Video recordings of naturally occurring interactions in England, France, the Netherlands, Italy, Greece, Scotland, and Ireland were coded and analyzed to examine the effects of culture, gender, and age on interpersonal distance, body orientation, and touch. Results partially supported expected differences between contact cultures of southern Europe and noncontact cultures of northern Europe with respect to touch. More touch was observed among Italian and Greek dyads than among English, French, and Dutch dyads. In addition, an interaction effect between age and gender for body orientation suggested opposite development trends for mixed-sex dyads and male dyads. Whereas mixed dyads tended to maintain less direct orientations as they aged, male dyads maintained more direct orientations.",1995.0,43.0,231.0,False,,"{'volume': '135 3', 'pages': '\n          281-97\n        ', 'name': 'The Journal of social psychology'}","{'bibtex': '@Article{Remland1995InterpersonalDB,\n author = {Martin S. Remland and T. Jones and Heidi Brinkman},\n journal = {The Journal of social psychology},\n pages = {\n          281-97\n        },\n title = {Interpersonal distance, body orientation, and touch: effects of culture, gender, and age.},\n volume = {135 3},\n year = {1995}\n}\n'}","[{'authorId': '3996616', 'name': 'Martin S. Remland'}, {'authorId': '31484405', 'name': 'T. Jones'}, {'authorId': '117783642', 'name': 'Heidi Brinkman'}]"
2062,b0ee222ae224a67039f85103a0166e12e4e416d6,Sharing the burden: The interpersonal regulation of emotional arousal in mother-daughter dyads.,"According to social baseline theory (Beckes & Coan, 2011), load sharing is a feature of close relationships whereby the burden of emotional distress is distributed across relationship partners. Load sharing varies by physical closeness and relationship quality. We investigated the effect of load sharing on emotional arousal via galvanic skin response, an indicator of sympathetic nervous system arousal, during a social stressor. Social stress was elicited in 66 adolescent girls (Mage = 15 years) using a spontaneous public-speaking task. Mother-daughter dyads reported their relationship quality, and physical closeness was manipulated by having mothers either touch or not touch their daughter's hand during the performance. We found evidence of load sharing among dyads who held hands, independent of relationship quality. However, without physical contact, load sharing was only evident among dyads with higher relationship quality. Thus, high relationship quality buffers against threat in a similar way to the physical comfort of a loved one.",2016.0,52.0,34.0,False,,"{'volume': '16 1', 'pages': '\n          83-93\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Lougheed2016SharingTB,\n author = {Jessica P. Lougheed and Peter Koval and Tom Hollenstein},\n journal = {Emotion},\n pages = {\n          83-93\n        },\n title = {Sharing the burden: The interpersonal regulation of emotional arousal in mother-daughter dyads.},\n volume = {16 1},\n year = {2016}\n}\n'}","[{'authorId': '3714961', 'name': 'Jessica P. Lougheed'}, {'authorId': '2140903', 'name': 'Peter Koval'}, {'authorId': '2329276', 'name': 'Tom Hollenstein'}]"
2063,b10560a6ee1c0f9d4de2387f68a59181a8749c61,Mixed agent/social dynamics for emotion computation,"Affective computing is the study and development of systems and devices that can recognise, interpret, process, and simulate human affects. In this context, computational modelling of emotion is a major challenge in order to design believable virtual humans. This factor has an impact on both the individual behaviour and the collective one. Recently, researchers have shown an increased interest in the emotion contagion phenomenon in order to model emerging group behaviour. 
 
Stemming from works on multi-agent systems environments, we propose an architecture to manage both internal and external emotion dynamics. Emotions evolve in function of three influences: punctual events, temporal dynamics and external influences. In an embodied agent approach, the first is the responsibility of the agent's mind, the second of the agent's body, and the third of the environment. This functional architecture is then adapted to a multi-agent architecture, adding a control responsibility to the agent body. Finally, we show the results of several experiments to examine the properties of the architecture and its efficiency by comparing it to a full agent approach.",2014.0,27.0,22.0,False,,{'pages': '645-652'},"{'bibtex': '@Article{Saunier2014MixedAD,\n author = {Julien Saunier and H. Jones},\n booktitle = {Adaptive Agents and Multi-Agent Systems},\n pages = {645-652},\n title = {Mixed agent/social dynamics for emotion computation},\n year = {2014}\n}\n'}","[{'authorId': '1708997', 'name': 'Julien Saunier'}, {'authorId': '31600786', 'name': 'H. Jones'}]"
2064,b14ff2a2f78cd3f410002976755580c169412bb9,This time with feeling: Integrated model of trait and state effects on cognition and behavior,"Both stable personality characteristics (traits) and transient emotions (states) influence cognition and behavior. In this paper, we describe a methodology for modeling these effects in terms of a set of parameters that control processing within a symbolic cognitive architecture. The underlying thesis of the approach is that the combined effects of these individual differences can be modeled by varying the architecture parameters that control both processing and the structure of knowledge within the architecture modules. We describe the architecture, provide operational definitions of representative trait and state influences in terms of the controlling parameters, and demonstrate how observed trait/state phenomena are modeled in the context of the current demonstration scenario: a peacekeeping training simulation.",2002.0,39.0,60.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/08339510290030417?needAccess=true', 'status': None}","{'volume': '16', 'pages': '611 - 641', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Hudlicka2002ThisTW,\n author = {E. Hudlicka},\n journal = {Applied Artificial Intelligence},\n pages = {611 - 641},\n title = {This time with feeling: Integrated model of trait and state effects on cognition and behavior},\n volume = {16},\n year = {2002}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
2065,b188db85abd8e1247f4c407bd20c176b829f0632,Electrodermal activity measurements for detection of emotional arousal,". In this article, we present a comprehensive measurement system to determine the level of user emotional arousal by the analysis of electrodermal activity (EDA). A number of EDA measurements were collected, while emotions were elicited using specially selected movie sequences. Data collected from 16 participants of the experiment, in conjunction with those from personal questionnaires, were used to determine a large number of 20 features of the EDA, to assess the emotional state of a user. Feature selection was performed using signal processing and analysis methods, while considering user declarations. The suitability of the designed system for detecting the level of emotional arousal was fully confirmed, throughout the number of experiments. The average classification accuracy for two classes of the least and the most stimulating movies varies within the range of 61‒72%.",2023.0,67.0,12.0,True,"{'url': 'http://journals.pan.pl/Content/113674/PDF/14_813-829_01032_Bpast.No.67-4_23.08.19_K.pdf', 'status': None}",{'name': 'Bulletin of the Polish Academy of Sciences Technical Sciences'},"{'bibtex': '@Article{Kołodziej2023ElectrodermalAM,\n author = {M. Kołodziej and P. Tarnowski and A. Majkowski and R. Rak},\n journal = {Bulletin of the Polish Academy of Sciences Technical Sciences},\n title = {Electrodermal activity measurements for detection of emotional arousal},\n year = {2023}\n}\n'}","[{'authorId': '2266678489', 'name': 'M. Kołodziej'}, {'authorId': '2518874', 'name': 'P. Tarnowski'}, {'authorId': '79693825', 'name': 'A. Majkowski'}, {'authorId': '35261781', 'name': 'R. Rak'}]"
2066,b19e8ceff5f2ed70ddb0a5cadc495777235dfd62,Service with a smile: Emotional contagion in the service encounter.,This study focuses on the antecedents and consequences of displayed emotion in organizations. I propose that customers “catch” the affect of employees through emotional contagion processes. Results...,2001.0,24.0,1353.0,False,,"{'volume': '44', 'pages': '1018-1027', 'name': 'Academy of Management Journal'}","{'bibtex': '@Article{Pugh2001ServiceWA,\n author = {S. Pugh},\n journal = {Academy of Management Journal},\n pages = {1018-1027},\n title = {Service with a smile: Emotional contagion in the service encounter.},\n volume = {44},\n year = {2001}\n}\n'}","[{'authorId': '145490003', 'name': 'S. Pugh'}]"
2067,b1afeacdae33129e84406ee2ed635fd81ae6efa7,Learning Speech-driven 3D Conversational Gestures from Video,"We propose the first approach to synthesize the synchronous 3D conversational body and hand gestures, as well as 3D face and head animations, of a virtual character from speech input. Our algorithm uses a CNN architecture that leverages the inherent correlation between facial expression and hand gestures. Synthesis of conversational body gestures is a multi-modal problem since many similar gestures can plausibly accompany the same input speech. To synthesize plausible body gestures in this setting, we train a Generative Adversarial Network (GAN) based model that measures the plausibility of the generated sequences of 3D body motion when paired with the input audio features. We also contribute a new corpus that contains more than 33 hours of annotated data from in-the-wild videos of talking people. To this end, we apply state-of-the-art monocular approaches for 3D body and hand pose estimation as well as 3D face performance capture to the video corpus. In this way, we can train on orders of magnitude more data than previous algorithms that resort to complex in-studio motion capture solutions, and thereby train more expressive synthesis algorithms. Our experiments and user study show the state-of-the-art quality of our speech-synthesized full 3D character animations.",2021.0,63.0,52.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3472306.3478335', 'status': None}",{'name': 'Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Habibie2021LearningS3,\n author = {I. Habibie and Weipeng Xu and Dushyant Mehta and Lingjie Liu and H. Seidel and Gerard Pons-Moll and Mohamed A. Elgharib and C. Theobalt},\n journal = {Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents},\n title = {Learning Speech-driven 3D Conversational Gestures from Video},\n year = {2021}\n}\n'}","[{'authorId': '3202217', 'name': 'I. Habibie'}, {'authorId': '9765909', 'name': 'Weipeng Xu'}, {'authorId': '39503308', 'name': 'Dushyant Mehta'}, {'authorId': '46458089', 'name': 'Lingjie Liu'}, {'authorId': '145156858', 'name': 'H. Seidel'}, {'authorId': '1403428213', 'name': 'Gerard Pons-Moll'}, {'authorId': '1854465', 'name': 'Mohamed A. Elgharib'}, {'authorId': '1680185', 'name': 'C. Theobalt'}]"
2068,b1be7d7d65f58ff6feaf641de95f92e004af2a76,Building genuine trust through interpersonal emotion management: A threat regulation model of trust and collaboration across boundaries,"I introduce the construct of threat regulation as an agentic interpersonal process for building and maintaining trust. I examine threat regulation as a specific dimension of interpersonal emotion management that fosters trust and effective cooperation by allowing individuals to understand and mitigate the harm that their counterparts associate with cooperating—in particular, harm from opportunism, identity damage, and neglect of their interests. To explicate the microprocesses of threat regulation, I draw on social cognitive theory, symbolic interactionism, and the psychology of emotion regulation.",2007.0,127.0,329.0,False,,"{'volume': '32', 'pages': '595-621', 'name': 'Academy of Management Review'}","{'bibtex': '@Article{Williams2007BuildingGT,\n author = {Michele Williams},\n journal = {Academy of Management Review},\n pages = {595-621},\n title = {Building genuine trust through interpersonal emotion management: A threat regulation model of trust and collaboration across boundaries},\n volume = {32},\n year = {2007}\n}\n'}","[{'authorId': '30792905', 'name': 'Michele Williams'}]"
2069,b1cf3570cca62a28dbaf36d078f2b58ca6acab0b,Cognitive Behavior Therapy,"Abstrack, This study aims to intervene in one of the students who is in Al-Azhar Gresik High School. The subject has obsessive compulsive behavior in the form of using a handbody on the sole of the foot repeatedly. Researchers provide interventions in the form of cognitive behavior therapy as interventions to reduce obsessive compulsive behavior, and to improve mental health in schools. This therapy aims to oppose wrong thoughts and emotions by presenting evidence that contradicts beliefs about the problem at hand. The method used in this research is qualitative with a case study approach. Subjects were female who were 16 years old and had obsessive compulsive behavior for 14 months. The cognitive behavior therapy procedure is first, the subject is asked for relaxation in the form of progressivrizkie muscle relaxation to learn to stretch and relax various muscle groups and learn to notice the difference between tension and relax. Second, cognitive restructuring, reducing the anxiety level of the subject caused by negative thoughts and replacing them with more positive thoughts, and. Third, exposure with response prevention, to overcome obsessive compulsive behavior. Where the subject is faced with a situation of having the belief that must perform the usual ritual behavior but the subject is prevented from doing the ritual. If the subject can prevent not doing the ritual and it turns out that something terrible did not happen, this can help in changing the subject's belief in compulsive behavior. The intervention consisted of eight sessions with two sessions a week and 60 minutes each for each session. The results of this study indicate that cognitive behavior therapy is effectively used to reduce the subject's obsessive compulsive behavior, which is shown by decreasing levels of anxiety, negative thinking and compulsive behavior.",2020.0,14.0,255.0,True,,{'name': 'Definitions'},"{'bibtex': '@Article{Chand2020CognitiveBT,\n author = {S. Chand and Daniel P. Kuckel and M. Huecker},\n journal = {Definitions},\n title = {Cognitive Behavior Therapy},\n year = {2020}\n}\n'}","[{'authorId': '48434738', 'name': 'S. Chand'}, {'authorId': '35361247', 'name': 'Daniel P. Kuckel'}, {'authorId': '66787992', 'name': 'M. Huecker'}]"
2070,b1e70a004867da1922e68fc977a8fb795422afb8,Vocal Synchrony of Robots Boosts Positive Affective Empathy,"Robots that can talk with humans play increasingly important roles in society. However, current conversation robots remain unskilled at eliciting empathic feelings in humans. To address this problem, we used a robot that speaks in a voice synchronized with human vocal prosody. We conducted an experiment in which human participants held positive conversations with the robot by reading scenarios under conditions with and without vocal synchronization. We assessed seven subjective responses related to affective empathy (e.g., emotional connection) and measured the physiological emotional responses using facial electromyography from the corrugator supercilii and zygomatic major muscles as well as the skin conductance level. The subjective ratings consistently revealed heightened empathic responses to the robot in the synchronization condition compared with that under the de-synchronizing condition. The physiological signals showed that more positive and stronger emotional arousal responses to the robot with synchronization. These findings suggest that robots that are able to vocally synchronize with humans can elicit empathic emotional responses.",2021.0,69.0,2.0,True,"{'url': 'https://www.mdpi.com/2076-3417/11/6/2502/pdf?version=1615520202', 'status': None}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Nishimura2021VocalSO,\n author = {Shogo Nishimura and Takuya Nakamura and Wataru Sato and M. Kanbara and Yuichiro Fujimoto and H. Kato and N. Hagita},\n journal = {Applied Sciences},\n title = {Vocal Synchrony of Robots Boosts Positive Affective Empathy},\n year = {2021}\n}\n'}","[{'authorId': '50154325', 'name': 'Shogo Nishimura'}, {'authorId': '2217259326', 'name': 'Takuya Nakamura'}, {'authorId': '2057374903', 'name': 'Wataru Sato'}, {'authorId': '1796418', 'name': 'M. Kanbara'}, {'authorId': '1981023', 'name': 'Yuichiro Fujimoto'}, {'authorId': '2262728792', 'name': 'H. Kato'}, {'authorId': '1781078', 'name': 'N. Hagita'}]"
2071,b1e75fb00c3da98c4a808c7fad0bbe1f9a861003,Convolutional neural networks for acoustic modeling of raw time signal in LVCSR,"In this paper we continue to investigate how the deep neural network (DNN) based acoustic models for automatic speech recognition can be trained without hand-crafted feature extraction. Previously, we have shown that a simple fully connected feedforward DNN performs surprisingly well when trained directly on the raw time signal. The analysis of the weights revealed that the DNN has learned a kind of short-time time-frequency decomposition of the speech signal. In conventional feature extraction pipelines this is done manually by means of a filter bank that is shared between the neighboring analysis windows. Following this idea, we show that the performance gap between DNNs trained on spliced hand-crafted features and DNNs trained on raw time signal can be strongly reduced by introducing 1D-convolutional layers. Thus, the DNN is forced to learn a short-time filter bank shared over a longer time span. This also allows us to interpret the weights of the second convolutional layer in the same way as 2D patches learned on critical band energies by typical convolutional neural networks. The evaluation is performed on an English LVCSR task. Trained on the raw time signal, the convolutional layers allow to reduce the WER on the test set from 25.5% to 23.4%, compared to an MFCC based result of 22.1% using fully connected layers. Index Terms: acoustic modeling, raw time signal, convolutional neural networks",2015.0,21.0,118.0,False,,{'pages': '26-30'},"{'bibtex': '@Inproceedings{Golik2015ConvolutionalNN,\n author = {Pavel Golik and Zoltán Tüske and R. Schlüter and H. Ney},\n pages = {26-30},\n title = {Convolutional neural networks for acoustic modeling of raw time signal in LVCSR},\n year = {2015}\n}\n'}","[{'authorId': '3207549', 'name': 'Pavel Golik'}, {'authorId': '1790221', 'name': 'Zoltán Tüske'}, {'authorId': '144490010', 'name': 'R. Schlüter'}, {'authorId': '145322333', 'name': 'H. Ney'}]"
2072,b219f0ddd236b446aa37244d947054a46dcbe555,Toward Virtual Humans,"This article describes the virtual humans developed as part of the Mission Rehearsal Exercise project, a virtual reality-based training system. This project is an ambitious exercise in integration, both in the sense of integrating technology with entertainment industry content, but also in that we have joined a number of component technologies that have not been integrated before. This integration has not only raised new research issues, but it has also suggested some new approaches to difficult problems. We describe the key capabilities of the virtual humans, including task representation and reasoning, natural language dialogue, and emotion reasoning, and show how these capabilities are integrated to provide more human-level intelligence than would otherwise be possible.",2006.0,45.0,264.0,False,,"{'volume': '27', 'pages': '96-108', 'name': 'AI Mag.'}","{'bibtex': '@Article{Swartout2006TowardVH,\n author = {W. Swartout and J. Gratch and R. Hill and E. Hovy and S. Marsella and J. Rickel and D. Traum},\n journal = {AI Mag.},\n pages = {96-108},\n title = {Toward Virtual Humans},\n volume = {27},\n year = {2006}\n}\n'}","[{'authorId': '1684040', 'name': 'W. Swartout'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1812270', 'name': 'R. Hill'}, {'authorId': '144547315', 'name': 'E. Hovy'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '144518646', 'name': 'D. Traum'}]"
2073,b255474d62f082fa97f50ea1174bf339522f6c99,Facial mimicry in its social setting,"In interpersonal encounters, individuals often exhibit changes in their own facial expressions in response to emotional expressions of another person. Such changes are often called facial mimicry. While this tendency first appeared to be an automatic tendency of the perceiver to show the same emotional expression as the sender, evidence is now accumulating that situation, person, and relationship jointly determine whether and for which emotions such congruent facial behavior is shown. We review the evidence regarding the moderating influence of such factors on facial mimicry with a focus on understanding the meaning of facial responses to emotional expressions in a particular constellation. From this, we derive recommendations for a research agenda with a stronger focus on the most common forms of encounters, actual interactions with known others, and on assessing potential mediators of facial mimicry. We conclude that facial mimicry is modulated by many factors: attention deployment and sensitivity, detection of valence, emotional feelings, and social motivations. We posit that these are the more proximal causes of changes in facial mimicry due to changes in its social setting.",2015.0,171.0,110.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01122/pdf', 'status': None}","{'volume': '6', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Seibt2015FacialMI,\n author = {Beate Seibt and A. Mühlberger and Katja U. Likowski and P. Weyers},\n journal = {Frontiers in Psychology},\n title = {Facial mimicry in its social setting},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '2848483', 'name': 'Beate Seibt'}, {'authorId': '1684604', 'name': 'A. Mühlberger'}, {'authorId': '4579242', 'name': 'Katja U. Likowski'}, {'authorId': '152592651', 'name': 'P. Weyers'}]"
2074,b272c7fa96e2737803fb2640d3893f3a1b9d7d8e,"The Repertoire of Nonverbal Behavior: Categories, Origins, Usage, and Coding","Ir we arc to understand fully any instance of a person's non-verbal behavior that is, any movement or position of the face and/or the bodywe must discover how that behavior became part of the penon's repertoire, the circumstances of its usc, and the rules which explain how the behavior contains or conveys information. We will call these three fundamental considerations ORIGIN, USAGE. and CODING. The interrelationships among and the differences within these three aspects of nonverbal behavior are extremely complex. The task of unraveling nonverbal behavior in these terms is enormously difficult; and it becomes impossible if we fail to consider the possibility of multiple categories of nonverbal behavior. The need to develop such a categorical scheme bas emerged from the results of our empirical studies over the past eight years, and has been crystallized by our two current research projects, the study of crosscultural differences in nonverbal behavior, and the study of nonverbal leakage of information during deceptive situations. We will briefly trace how some of the findings raised questions which led us to attempt to",1969.0,2.0,2939.0,False,,"{'volume': '1', 'pages': '49 - 98', 'name': 'Semiotica'}","{'bibtex': '@Article{Ekman1969TheRO,\n author = {P. Ekman and Wallace V. Friesen},\n journal = {Semiotica},\n pages = {49 - 98},\n title = {The Repertoire of Nonverbal Behavior: Categories, Origins, Usage, and Coding},\n volume = {1},\n year = {1969}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}]"
2075,b28be40d6f5780a3768882d2edf9f30847b73929,Virtual Patients for Clinical Therapist Skills Training,,2007.0,30.0,130.0,False,,{'pages': '197-210'},"{'bibtex': '@Inproceedings{Kenny2007VirtualPF,\n author = {Patrick G. Kenny and T. Parsons and J. Gratch and A. Leuski and A. Rizzo},\n pages = {197-210},\n title = {Virtual Patients for Clinical Therapist Skills Training},\n year = {2007}\n}\n'}","[{'authorId': '3181776', 'name': 'Patrick G. Kenny'}, {'authorId': '145842705', 'name': 'T. Parsons'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '3201827', 'name': 'A. Leuski'}, {'authorId': '29861580', 'name': 'A. Rizzo'}]"
2076,b2ade0036eb3de638d5f44cf9b1cda26e59bcc64,Universals and cultural variation in turn-taking in conversation,"Informal verbal interaction is the core matrix for human social life. A mechanism for coordinating this basic mode of interaction is a system of turn-taking that regulates who is to speak and when. Yet relatively little is known about how this system varies across cultures. The anthropological literature reports significant cultural differences in the timing of turn-taking in ordinary conversation. We test these claims and show that in fact there are striking universals in the underlying pattern of response latency in conversation. Using a worldwide sample of 10 languages drawn from traditional indigenous communities to major world languages, we show that all of the languages tested provide clear evidence for a general avoidance of overlapping talk and a minimization of silence between conversational turns. In addition, all of the languages show the same factors explaining within-language variation in speed of response. We do, however, find differences across the languages in the average gap between turns, within a range of 250 ms from the cross-language mean. We believe that a natural sensitivity to these tempo differences leads to a subjective perception of dramatic or even fundamental differences as offered in ethnographic reports of conversational style. Our empirical evidence suggests robust human universals in this domain, where local variations are quantitative only, pointing to a single shared infrastructure for language use with likely ethological foundations.",2009.0,49.0,1022.0,True,,"{'volume': '106', 'pages': '10587 - 10592', 'name': 'Proceedings of the National Academy of Sciences'}","{'bibtex': '@Article{Stivers2009UniversalsAC,\n author = {Tanya Stivers and N. Enfield and P. Brown and C. Englert and M. Hayashi and Trine Heinemann and G. Hoymann and F. Rossano and Jan Peter De Ruiter and Kyung-Eun Yoon and S. Levinson and P. Kay and K. Y},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {10587 - 10592},\n title = {Universals and cultural variation in turn-taking in conversation},\n volume = {106},\n year = {2009}\n}\n'}","[{'authorId': '50756211', 'name': 'Tanya Stivers'}, {'authorId': '3247678', 'name': 'N. Enfield'}, {'authorId': '144197022', 'name': 'P. Brown'}, {'authorId': '2849668', 'name': 'C. Englert'}, {'authorId': '48429944', 'name': 'M. Hayashi'}, {'authorId': '47636211', 'name': 'Trine Heinemann'}, {'authorId': '4860165', 'name': 'G. Hoymann'}, {'authorId': '6363461', 'name': 'F. Rossano'}, {'authorId': '2223686319', 'name': 'Jan Peter De Ruiter'}, {'authorId': '6105175', 'name': 'Kyung-Eun Yoon'}, {'authorId': '6488514', 'name': 'S. Levinson'}, {'authorId': '145463410', 'name': 'P. Kay'}, {'authorId': '2223984575', 'name': 'K. Y'}]"
2077,b2b1ecf267be0dcb454ae33fbd8545e8af88e23e,The Neurological Traces of Look-Alike Avatars,"We designed an observational study where participants (n = 17) were exposed to pictures and look-alike avatars pictures of themselves, a familiar friend or an unfamiliar person. By measuring participants’ brain activity with electroencephalography (EEG), we found face-recognition event related potentials (ERPs) in the visual cortex, around 200–250 ms, to be prominent for the different familiarity levels. A less positive component was found for self-recognized pictures (P200) than pictures of others, showing similar effects in both real faces and look-alike avatars. A rapid adaptation in the same component was found when comparing the neural processing of avatar faces vs. real faces, as if avatars in general were assimilated as real face representations over time. ERP results also showed that in the case of the self-avatar, the P200 component correlated with more complex conscious encodings of self-representation, i.e., the difference in voltage in the P200 between the self-avatar and the self-picture was reduced in participants that felt the avatar looked like them. This study is put into context within the literature of self-recognition and face recognition in the visual cortex. Additionally, the implications of these results on look-alike avatars are discussed both for future virtual reality (VR) and neuroscience studies.",2016.0,74.0,29.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnhum.2016.00392/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Human Neuroscience'}","{'bibtex': '@Article{González-Franco2016TheNT,\n author = {Mar González-Franco and Anna I. Bellido and K. J. Blom and M. Slater and A. Rodríguez-Fornells},\n journal = {Frontiers in Human Neuroscience},\n title = {The Neurological Traces of Look-Alike Avatars},\n volume = {10},\n year = {2016}\n}\n'}","[{'authorId': '1403064530', 'name': 'Mar González-Franco'}, {'authorId': '4413460', 'name': 'Anna I. Bellido'}, {'authorId': '34763211', 'name': 'K. J. Blom'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '1381777734', 'name': 'A. Rodríguez-Fornells'}]"
2078,b2c1d4cf07a397aaaaad2ef1db5899034bb6b1ea,Using Facial Micro-Expressions in Combination With EEG and Physiological Signals for Emotion Recognition,"Emotions are multimodal processes that play a crucial role in our everyday lives. Recognizing emotions is becoming more critical in a wide range of application domains such as healthcare, education, human-computer interaction, Virtual Reality, intelligent agents, entertainment, and more. Facial macro-expressions or intense facial expressions are the most common modalities in recognizing emotional states. However, since facial expressions can be voluntarily controlled, they may not accurately represent emotional states. Earlier studies have shown that facial micro-expressions are more reliable than facial macro-expressions for revealing emotions. They are subtle, involuntary movements responding to external stimuli that cannot be controlled. This paper proposes using facial micro-expressions combined with brain and physiological signals to more reliably detect underlying emotions. We describe our models for measuring arousal and valence levels from a combination of facial micro-expressions, Electroencephalography (EEG) signals, galvanic skin responses (GSR), and Photoplethysmography (PPG) signals. We then evaluate our model using the DEAP dataset and our own dataset based on a subject-independent approach. Lastly, we discuss our results, the limitations of our work, and how these limitations could be overcome. We also discuss future directions for using facial micro-expressions and physiological signals in emotion recognition.",2022.0,122.0,8.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2022.864047/pdf', 'status': 'GOLD'}","{'name': 'Frontiers in Psychology', 'volume': '13'}","{'bibtex': '@Article{Saffaryazdi2022UsingFM,\n author = {Nastaran Saffaryazdi and Syed Talal Wasim and Kuldeep Dileep and A. F. Nia and Suranga Nanayakkara and E. Broadbent and M. Billinghurst},\n booktitle = {Frontiers in Psychology},\n journal = {Frontiers in Psychology},\n title = {Using Facial Micro-Expressions in Combination With EEG and Physiological Signals for Emotion Recognition},\n volume = {13},\n year = {2022}\n}\n'}","[{'authorId': '1486414917', 'name': 'Nastaran Saffaryazdi'}, {'authorId': '2174126602', 'name': 'Syed Talal Wasim'}, {'authorId': '2174125419', 'name': 'Kuldeep Dileep'}, {'authorId': '40960929', 'name': 'A. F. Nia'}, {'authorId': '1486464114', 'name': 'Suranga Nanayakkara'}, {'authorId': '2056896949', 'name': 'E. Broadbent'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}]"
2079,b2c755445c3d5ccd2b1c315090da422a08e99145,Modelling emotion expression through agent oriented methodology,"This paper presents Modelling Emotion Expression through Agent Oriented Methodology. Considering emotions of the intended users in the software engineering can uncover new requirements to improve and more accepted the system. While emotion is paying much attention nowadays, there is lacking systematic way to model the emotion based system. Without the systematic approach, it is hard to debug, design and develop an emotion based system. Since the emotional requirement of people has not being fully investigated, the research outcome propose the emotion modelling as part of the complete set of agent-oriented modelling for virtual character in eLearning system, The contribution of this paper is to introduce agent oriented modelling to systematic model an emotion based solution for an eLearning system and instructional video design. With the emotion model, it can serve as a guide to design, redesign, and discuss the emotion elements among the software development team. This is important for better debugging and project management especially for emotion led system.",2019.0,24.0,2.0,True,"{'url': 'http://ijeecs.iaescore.com/index.php/IJEECS/article/download/19895/13077', 'status': 'HYBRID'}",{'name': 'Indonesian Journal of Electrical Engineering and Computer Science'},"{'bibtex': '@Article{Zulkifli2019ModellingEE,\n author = {S. Zulkifli and Cheah Wai Shiang and Nurfauza Jali and M. A. Khairuddin},\n booktitle = {Indonesian Journal of Electrical Engineering and Computer Science},\n journal = {Indonesian Journal of Electrical Engineering and Computer Science},\n title = {Modelling emotion expression through agent oriented methodology},\n year = {2019}\n}\n'}","[{'authorId': '1659202103', 'name': 'S. Zulkifli'}, {'authorId': '9340171', 'name': 'Cheah Wai Shiang'}, {'authorId': '9366035', 'name': 'Nurfauza Jali'}, {'authorId': '48920304', 'name': 'M. A. Khairuddin'}]"
2080,b2c90eddd3b4627361f407d7948d5c52e3043028,Multi-Modal Dialogue Policy Learning for Dynamic and Co-operative Goal Setting,"Developing an adequate and human-like virtual agent has been one of the primary applications of artificial intelligence. In the last few years, task-oriented dialogue systems have gained huge popularity because of their upsurging relevance and positive outcomes. In real-world, users may not always have a predefined and rigid task goal beforehand; they upgrade/downgrade/change their goal component dynamically depending upon their utility value and agent's serving capability. However, existing virtual agents fail to incorporate this dynamic behavior, leading to either unsuccessful task completion or an ungratified user experience. The paper presents an end to end multimodal dialogue system for dynamic and co-operative goal setting, which incorporates i) a multi-modal semantic state representation in policy learning to deal with multi-modal inputs, ii) a goal manager module in a traditional dialogue manager for handling dynamic and goal unavailability scenarios effectively, iii) an accumulative reward (task/persona/sentiment) for task success, personalized persuasion and user-adaptive behavior, respectively. The obtained experimental results and the comparisons with baselines firmly establish the need and efficacy of the proposed system.",2021.0,0.0,5.0,False,,"{'pages': '1-8', 'name': '2021 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Tiwari2021MultiModalDP,\n author = {Abhisek Tiwari and Tulika Saha and S. Saha and Shubhashis Sengupta and Anutosh Maitra and Roshni Ramnani and P. Bhattacharyya},\n journal = {2021 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {Multi-Modal Dialogue Policy Learning for Dynamic and Co-operative Goal Setting},\n year = {2021}\n}\n'}","[{'authorId': '2063522518', 'name': 'Abhisek Tiwari'}, {'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '2062808558', 'name': 'Shubhashis Sengupta'}, {'authorId': '40585053', 'name': 'Anutosh Maitra'}, {'authorId': '3040439', 'name': 'Roshni Ramnani'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
2081,b2ed95f7e68865630df15add0852d2e246cc09c3,The Elaboration Likelihood Model of Persuasion,,1986.0,266.0,9175.0,False,,{'pages': '123-205'},"{'bibtex': '@Inproceedings{Petty1986TheEL,\n author = {R. Petty and J. Cacioppo},\n pages = {123-205},\n title = {The Elaboration Likelihood Model of Persuasion},\n year = {1986}\n}\n'}","[{'authorId': '32761043', 'name': 'R. Petty'}, {'authorId': '2285765', 'name': 'J. Cacioppo'}]"
2082,b2fdee5ca0b364a056de8f8d749c88bd7c0086c6,"Game-Based Learning with Computers - Learning, Simulations, and Games",,2008.0,28.0,65.0,False,,"{'volume': '1', 'pages': '172-190', 'name': 'Trans. Edutainment'}","{'bibtex': '@Article{Martens2008GameBasedLW,\n author = {A. Martens and H. Diener and Steffen Malo},\n journal = {Trans. Edutainment},\n pages = {172-190},\n title = {Game-Based Learning with Computers - Learning, Simulations, and Games},\n volume = {1},\n year = {2008}\n}\n'}","[{'authorId': '144424885', 'name': 'A. Martens'}, {'authorId': '21322561', 'name': 'H. Diener'}, {'authorId': '2093490546', 'name': 'Steffen Malo'}]"
2083,b330974c5f50b7bba0da625d2688cdd425bab73f,[From theory to practice].,,1997.0,0.0,704.0,False,,"{'volume': '189', 'pages': '\n          XII\n        ', 'name': 'Soins. Psychiatrie'}","{'bibtex': '@Article{Perlemuter1997FromTT,\n author = {L. Perlemuter},\n journal = {Soins. Psychiatrie},\n pages = {\n          XII\n        },\n title = {[From theory to practice].},\n volume = {189},\n year = {1997}\n}\n'}","[{'authorId': '7257210', 'name': 'L. Perlemuter'}]"
2084,b351e23285facd1e4795836c349bc0d442488492,"A Transformer based Multi-task Model for Domain Classification, Intent Detection and Slot-Filling","With the ever increasing complexity of the user queries in a multi-domain based task-oriented dialogue system, it is imperative to facilitate robust Spoken Language Understanding (SLU) modules that perform multiple tasks in an unified way. In this paper, we present a novel multi-task approach for the joint modelling of three tasks together, namely, Domain Classification, Intent Detection and Slot-Filling. We hypothesize with the intuition that the cross dependencies of all these three tasks mutually help each other towards their representations and classifications which further simplify the SLU module in a multi-domain scenario. Towards this end, we propose a BERT language model based multi-task framework utilizing capsule networks and conditional random fields for addressing the classification and sequence labeling problems, respectively, for different tasks. Experimental results indicate that the proposed multi-task model outperformed several strong baselines and its single task counterparts on three benchmark datasets of different domains and attained state-of-the-art results on different tasks.",2021.0,37.0,2.0,False,,"{'pages': '1-8', 'name': '2021 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Saha2021ATB,\n author = {Tulika Saha and N. Priya and S. Saha and P. Bhattacharyya},\n journal = {2021 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {A Transformer based Multi-task Model for Domain Classification, Intent Detection and Slot-Filling},\n year = {2021}\n}\n'}","[{'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '2106126217', 'name': 'N. Priya'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
2085,b3b7b374eee3ea3c6fe35c1e7bdf9bf24c9456b0,A GENERAL PSYCHOEVOLUTIONARY THEORY OF EMOTION,,1980.0,26.0,1735.0,False,,"{'volume': '', 'pages': '3-33', 'name': ''}","{'bibtex': '@Inproceedings{Plutchik1980AGP,\n author = {R. Plutchik},\n pages = {3-33},\n title = {A GENERAL PSYCHOEVOLUTIONARY THEORY OF EMOTION},\n year = {1980}\n}\n'}","[{'authorId': '84527386', 'name': 'R. Plutchik'}]"
2086,b3bacb44ac820cb54a9e455eafe721edd1136e23,The Behavior of Organisms: An Experimental Analysis,"This is likewise one of the factors by obtaining the soft documents of this the behavior of organisms an experimental analysis by online. You might not require more times to spend to go to the books launch as well as search for them. In some cases, you likewise realize not discover the pronouncement the behavior of organisms an experimental analysis that you are looking for. It will utterly squander the time.",2016.0,0.0,1807.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Jones2016TheBO,\n author = {F. Nowell Jones and B. Skinner},\n title = {The Behavior of Organisms: An Experimental Analysis},\n year = {2016}\n}\n'}","[{'authorId': '2226851910', 'name': 'F. Nowell Jones'}, {'authorId': '113469609', 'name': 'B. Skinner'}]"
2087,b3f6067a627b2c8952536c52414fddf892d735c6,"Measurement Instruments for the Anthropomorphism, Animacy, Likeability, Perceived Intelligence, and Perceived Safety of Robots",,2009.0,82.0,2041.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s12369-008-0001-3.pdf', 'status': None}","{'volume': '1', 'pages': '71-81', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Bartneck2009MeasurementIF,\n author = {C. Bartneck and D. Kulić and E. Croft and Susana Zoghbi},\n journal = {International Journal of Social Robotics},\n pages = {71-81},\n title = {Measurement Instruments for the Anthropomorphism, Animacy, Likeability, Perceived Intelligence, and Perceived Safety of Robots},\n volume = {1},\n year = {2009}\n}\n'}","[{'authorId': '1728894', 'name': 'C. Bartneck'}, {'authorId': '1768765', 'name': 'D. Kulić'}, {'authorId': '1735428', 'name': 'E. Croft'}, {'authorId': '3348963', 'name': 'Susana Zoghbi'}]"
2088,b43f9b861cb3959fb3a4891ef58c24ed1f64e461,EMMA: An Emotion-Aware Wellbeing Chatbot,"The delivery of mental health interventions via ubiquitous devices has shown much promise. A conversational chatbot is a promising oracle for delivering appropriate just-in-time interventions. However, designing emotionally-aware agents, specially in this context, is under-explored. Furthermore, the feasibility of automating the delivery of just-in-time mHealth interventions via such an agent has not been fully studied. In this paper, we present the design and evaluation of EMMA (EMotion-Aware mHealth Agent) through a two-week long human-subject experiment with N=39 participants. EMMA provides emotionally appropriate micro-activities in an empathetic manner. We show that the system can be extended to detect a user's mood purely from smartphone sensor data. Our results show that our personalized machine learning model was perceived as likable via self-reports of emotion from users. Finally, we provide a set of guidelines for the design of emotion-aware bots for mHealth.",2018.0,52.0,55.0,True,"{'url': 'https://arxiv.org/pdf/1812.11423', 'status': None}","{'pages': '1-7', 'name': '2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)'}","{'bibtex': '@Article{Ghandeharioun2018EMMAAE,\n author = {Asma Ghandeharioun and Daniel J. McDuff and M. Czerwinski and Kael Rowan},\n journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {1-7},\n title = {EMMA: An Emotion-Aware Wellbeing Chatbot},\n year = {2018}\n}\n'}","[{'authorId': '2214185', 'name': 'Asma Ghandeharioun'}, {'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '1817251', 'name': 'M. Czerwinski'}, {'authorId': '36516124', 'name': 'Kael Rowan'}]"
2089,b46194ac5696379cfa920ff08cda8d7c4cb6579c,Augment to Prevent: Short-Text Data Augmentation in Deep Learning for Hate-Speech Classification,"In this paper, we address the issue of augmenting text data in supervised Natural Language Processing problems, exemplified by deep online hate speech classification. A great challenge in this domain is that although the presence of hate speech can be deleterious to the quality of service provided by social platforms, it still comprises only a tiny fraction of the content that can be found online, which can lead to performance deterioration due to majority class overfitting. To this end, we perform a thorough study on the application of deep learning to the hate speech detection problem: a) we propose three text-based data augmentation techniques aimed at reducing the degree of class imbalance and to maximise the amount of information we can extract from our limited resources and b) we apply them on a selection of top-performing deep architectures and hate speech databases in order to showcase their generalisation properties. The data augmentation techniques are based on a) synonym replacement based on word embedding vector closeness, b) warping of the word tokens along the padded sequence or c) class-conditional, recurrent neural language generation. Our proposed framework yields a significant increase in multi-class hate speech detection, outperforming the baseline in the largest online hate speech database by an absolute 5.7% increase in Macro-F1 score and 30% in hate speech class recall.",2019.0,50.0,78.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/71702/71702.pdf', 'status': None}",{'name': 'Proceedings of the 28th ACM International Conference on Information and Knowledge Management'},"{'bibtex': '@Article{Rizos2019AugmentTP,\n author = {Georgios Rizos and Konstantin Hemker and Björn Schuller},\n journal = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},\n title = {Augment to Prevent: Short-Text Data Augmentation in Deep Learning for Hate-Speech Classification},\n year = {2019}\n}\n'}","[{'authorId': '40185455', 'name': 'Georgios Rizos'}, {'authorId': '2121244573', 'name': 'Konstantin Hemker'}, {'authorId': '145411696', 'name': 'Björn Schuller'}]"
2090,b48f1a8a99a64346232e4ebb9e4105aeb62a81a2,Style‐Controllable Speech‐Driven Gesture Synthesis Using Normalising Flows,"Automatic synthesis of realistic gestures promises to transform the fields of animation, avatars and communicative agents. In off‐line applications, novel tools can alter the role of an animator to that of a director, who provides only high‐level input for the desired animation; a learned network then translates these instructions into an appropriate sequence of body poses. In interactive scenarios, systems for generating natural animations on the fly are key to achieving believable and relatable characters. In this paper we address some of the core issues towards these ends. By adapting a deep learning‐based motion synthesis method called MoGlow, we propose a new generative model for generating state‐of‐the‐art realistic speech‐driven gesticulation. Owing to the probabilistic nature of the approach, our model can produce a battery of different, yet plausible, gestures given the same input speech signal. Just like humans, this gives a rich natural variation of motion. We additionally demonstrate the ability to exert directorial control over the output style, such as gesture level, speed, symmetry and spacial extent. Such control can be leveraged to convey a desired character personality or mood. We achieve all this without any manual annotation of the data. User studies evaluating upper‐body gesticulation confirm that the generated motions are natural and well match the input speech. Our method scores above all prior systems and baselines on these measures, and comes close to the ratings of the original recorded motions. We furthermore find that we can accurately control gesticulation styles without unnecessarily compromising perceived naturalness. Finally, we also demonstrate an application of the same method to full‐body gesticulation, including the synthesis of stepping motion and stance.",2020.0,99.0,134.0,True,"{'url': 'http://kth.diva-portal.org/smash/get/diva2:1499133/FULLTEXT01', 'status': None}","{'volume': '39', 'name': 'Computer Graphics Forum'}","{'bibtex': '@Article{Alexanderson2020StyleControllableSG,\n author = {Simon Alexanderson and G. Henter and Taras Kucherenko and J. Beskow},\n journal = {Computer Graphics Forum},\n title = {Style‐Controllable Speech‐Driven Gesture Synthesis Using Normalising Flows},\n volume = {39},\n year = {2020}\n}\n'}","[{'authorId': '1717035', 'name': 'Simon Alexanderson'}, {'authorId': '2763884', 'name': 'G. Henter'}, {'authorId': '145372964', 'name': 'Taras Kucherenko'}, {'authorId': '1826819', 'name': 'J. Beskow'}]"
2091,b49e195843aa588e9deb9138e5d7d4a5c377e795,The Oxford Handbook of Affective Computing,"Affective Computing is a growing multidisciplinary field encompassing computer science, engineering, psychology, education, neuroscience, and many other disciplines. It explores how affective factors influence interactions between humans and technology, how affect sensing and affect generation techniques can inform our understanding of human affect, and on the design, implementation, and evaluation of systems that intricately involve affect at their core. The Oxford Handbook of Affective Computing will help both new and experienced researchers identify trends, concepts, methodologies, and applications in this burgeouning field. The volume features 41 chapters divided into five main sections: history and theory, detection, generation, methodologies, and applications. Section One begins with a look at the makings of AC and a historical review of the science of emotion. Chapters discuss the theoretical underpinnings of AC from an interdisciplinary perspective involving the affective, cognitive, social, media, and brain sciences. Section Two focuses on affect detection or affect recognition, which is one of the most commonly investigated areas in AC. Section Three examines aspects of affect generation including the synthesis of emotion and its expression via facial features, speech, postures and gestures. Cultural issues in affect generation are also discussed. Section Four features chapters on methodological issues in AC research, including data collection techniques, multimodal affect databases, emotion representation formats, crowdsourcing techniques, machine learning approaches, affect elicitation techniques, useful AC tools, and ethical issues in AC. Finally, Section Five highlights existing and future applications of AC in domains such as formal and informal learning, games, robotics, virtual reality, autism research, healthcare, cyberpsychology, music, deception, reflective writing, and cyberpsychology.With chapters authored by world leaders in each area, The Oxford Handbook of Affective Computing is suitable for use as a textbook in undergraduate or graduate courses in AC, and will serve as a valuable resource for students, researchers, and practitioners across the globe.",2014.0,0.0,336.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Calvo2014TheOH,\n author = {R. Calvo and S. D’Mello and J. Gratch and Arvid Kappas},\n title = {The Oxford Handbook of Affective Computing},\n year = {2014}\n}\n'}","[{'authorId': '144792845', 'name': 'R. Calvo'}, {'authorId': '1383996606', 'name': 'S. D’Mello'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1742554', 'name': 'Arvid Kappas'}]"
2093,b4a645ca958f1067594bb5c82aad322f2bbbe1a8,Cognitive Evaluations and Intuitive Appraisals: Can Emotion Models Handle Them Both?,,2011.0,48.0,14.0,False,,"{'volume': '', 'pages': '459-481', 'name': ''}","{'bibtex': '@Inproceedings{Rosis2011CognitiveEA,\n author = {F. D. Rosis and C. Castelfranchi and P. Goldie and V. Carofiglio},\n pages = {459-481},\n title = {Cognitive Evaluations and Intuitive Appraisals: Can Emotion Models Handle Them Both?},\n year = {2011}\n}\n'}","[{'authorId': '1807752', 'name': 'F. D. Rosis'}, {'authorId': '1755446', 'name': 'C. Castelfranchi'}, {'authorId': '49005891', 'name': 'P. Goldie'}, {'authorId': '1694255', 'name': 'V. Carofiglio'}]"
2094,b4a7398788d8cc76756692a8c218b62b58ba73fd,Modeling the Mechanisms of Emotion Effects on Cognition,"Emotions exert a profound influence on cognitive processes, both the fundamental processes mediating cognition, such as attention and memory, and higher-level processes including decision-making and learning. A number of emotion effects on cognition have been identified, but their mechanisms are not yet understood. In this paper I describe a methodology for modeling the effects of emotion on cognition, within a symbolic cognitive-affective architecture. The primary objective of the approach is to facilitate the construction of alternative mechanisms of observed emotion effects. The paper describes how the effects of anxiety are modeled and how alternative mechanisms of these effects can be explored.",2008.0,19.0,36.0,False,,{'pages': '82-86'},"{'bibtex': '@Inproceedings{Hudlicka2008ModelingTM,\n author = {E. Hudlicka},\n pages = {82-86},\n title = {Modeling the Mechanisms of Emotion Effects on Cognition},\n year = {2008}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
2095,b4dc56f66aa67bc92cbb7c2dd98e93055f1b4fb0,A 12-Point Circumplex Structure of Core Affect.,"Core Affect is a state accessible to consciousness as a single simple feeling (feeling good or bad, energized or enervated) that can vary from moment to moment and that is the heart of, but not the whole of, mood and emotion. In four correlational studies (Ns = 535, 190, 234, 395), a 12-Point Affect Circumplex (12-PAC) model of Core Affect was developed that is finer grained than previously available and that integrates major dimensional models of mood and emotion. Self-report scales in three response formats were cross-validated for Core Affect felt during current and remembered moments. A technique that places any external variable into the 12-PAC showed that 29 of 38 personality scales and 30 of 30 mood scales are significantly related to Core Affect, but not in a way that revealed its basic dimensions.",2011.0,119.0,437.0,False,,"{'volume': '11 4', 'pages': '\n          705-31\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Yik2011A1C,\n author = {Michelle Yik and J. Russell and J. H. Steiger},\n journal = {Emotion},\n pages = {\n          705-31\n        },\n title = {A 12-Point Circumplex Structure of Core Affect.},\n volume = {11 4},\n year = {2011}\n}\n'}","[{'authorId': '6618455', 'name': 'Michelle Yik'}, {'authorId': '46367714', 'name': 'J. Russell'}, {'authorId': '48654914', 'name': 'J. H. Steiger'}]"
2096,b4f481a36c49e356d5d8e9543bbcdbd62057764a,Internet-based mental health programs: a powerful tool in the rural medical kit.,"OBJECTIVE
To discuss, using two case examples, the potential utility of Internet-based depression information and automated therapy programs in rural regions.


DESIGN
Systematic review of evaluations of two Australian web-based mental health programs: MoodGYM and BluePages Depression Information.


SETTING
Community, school, university.


PARTICIPANTS
A total of 12 papers and reports derived from nine separate studies of MoodGYM and BluePages involving sample sizes ranging from 78 to 19 607 people.


OUTCOME MEASURES
Depressive symptoms, anxiety symptoms, dysfunctional thoughts, depression literacy, stigma, help seeking and cost-effectiveness.


RESULTS
Internet-based applications were effective in reducing depressive symptoms and stigmatising attitudes to depression and in improving depression literacy. School-based programs also showed promise in decreasing depressive symptoms.


CONCLUSIONS
Depression self-help and information programs can be delivered effectively by means of the Internet. As accessibility of face-to-face mental health services in rural areas is poor and as there is a strong culture of self-reliance and preference for self-managing health problems among rural residents, the Internet might offer an important platform for the delivery of help for depression in rural regions. Consideration should be given to developing programs tailored to rural settings and future research should evaluate the efficacy and effectiveness of such programs in rural settings.",2007.0,20.0,283.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1440-1584.2007.00859.x', 'status': None}","{'volume': '15 2', 'pages': '\n          81-7\n        ', 'name': 'The Australian journal of rural health'}","{'bibtex': '@Article{Griffiths2007InternetbasedMH,\n author = {K. Griffiths and H. Christensen},\n journal = {The Australian journal of rural health},\n pages = {\n          81-7\n        },\n title = {Internet-based mental health programs: a powerful tool in the rural medical kit.},\n volume = {15 2},\n year = {2007}\n}\n'}","[{'authorId': '4743339', 'name': 'K. Griffiths'}, {'authorId': '144174775', 'name': 'H. Christensen'}]"
2097,b4f7cb021d130ca7f8949d53b746d60b216ce14c,Dimensions of Mind Perception,"Participants compared the mental capacities of various human and nonhuman characters via online surveys. Factor analysis revealed two dimensions of mind perception, Experience (for example, capacity for hunger) and Agency (for example, capacity for self-control). The dimensions predicted different moral judgments but were both related to valuing of mind.",2007.0,12.0,1314.0,True,"{'url': 'http://www.bio-nica.info/Biblioteca/Gray2007MindPerception.pdf', 'status': None}","{'volume': '315', 'pages': '619 - 619', 'name': 'Science'}","{'bibtex': '@Article{Gray2007DimensionsOM,\n author = {H. Gray and Kurt Gray and D. Wegner},\n journal = {Science},\n pages = {619 - 619},\n title = {Dimensions of Mind Perception},\n volume = {315},\n year = {2007}\n}\n'}","[{'authorId': '2676083', 'name': 'H. Gray'}, {'authorId': '144470585', 'name': 'Kurt Gray'}, {'authorId': '1810430', 'name': 'D. Wegner'}]"
2098,b524d8050121296244b502181e72717f50d44335,Reflections on Mirror Therapy,"Background. Mirror visual feedback (MVF), a phenomenon where movement of one limb is perceived as movement of the other limb, has the capacity to alleviate phantom limb pain or promote motor recovery of the upper limbs after stroke. The tool has received great interest from health professionals; however, a clear understanding of the mechanisms underlying the neural recovery owing to MVF is lacking. Objective. We performed a systematic review to assess the effect of MVF on brain activation during a motor task. Methods. We searched PubMed, CINAHL, and EMBASE databases for neuroimaging studies investigating the effect of MVF on the brain. Key details for each study regarding participants, imaging methods, and results were extracted. Results. The database search yielded 347 article, of which we identified 33 suitable for inclusion. Compared with a control condition, MVF increases neural activity in areas involved with allocation of attention and cognitive control (dorsolateral prefrontal cortex, posterior cingulate cortex, S1 and S2, precuneus). Apart from activation in the superior temporal gyrus and premotor cortex, there is little evidence that MVF activates the mirror neuron system. MVF increases the excitability of the ipsilateral primary motor cortex (M1) that projects to the “untrained” hand/arm. There is also evidence for ipsilateral projections from the contralateral M1 to the untrained/affected hand as a consequence of training with MVF. Conclusion. MVF can exert a strong influence on the motor network, mainly through increased cognitive penetration in action control, though the variance in methodology and the lack of studies that shed light on the functional connectivity between areas still limit insight into the actual underlying mechanisms.",2015.0,88.0,158.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1545968314546134', 'status': None}","{'volume': '29', 'pages': '349 - 361', 'name': 'Neurorehabilitation and Neural Repair'}","{'bibtex': '@Article{Deconinck2015ReflectionsOM,\n author = {F. Deconinck and A. Smorenburg and A. Benham and A. Ledebt and M. Feltham and G. Savelsbergh},\n journal = {Neurorehabilitation and Neural Repair},\n pages = {349 - 361},\n title = {Reflections on Mirror Therapy},\n volume = {29},\n year = {2015}\n}\n'}","[{'authorId': '2741246', 'name': 'F. Deconinck'}, {'authorId': '3999271', 'name': 'A. Smorenburg'}, {'authorId': '2338075', 'name': 'A. Benham'}, {'authorId': '3688722', 'name': 'A. Ledebt'}, {'authorId': '5116312', 'name': 'M. Feltham'}, {'authorId': '3765596', 'name': 'G. Savelsbergh'}]"
2099,b52db024be11491393925344dee197f91b9b2221,Sign Languages & Language Universals: The Status of Order & Position in Grammar,,2013.0,21.0,29.0,False,,"{'volume': '91', 'pages': '101 - 160', 'name': 'Sign Language Studies'}","{'bibtex': '@Article{Bouchard2013SignL,\n author = {Denis Bouchard},\n journal = {Sign Language Studies},\n pages = {101 - 160},\n title = {Sign Languages & Language Universals: The Status of Order & Position in Grammar},\n volume = {91},\n year = {2013}\n}\n'}","[{'authorId': '49830492', 'name': 'Denis Bouchard'}]"
2100,b54bcfca3fddc26b8889739a247a25e445818149,"Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition","From the Publisher: 
This book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora.Methodology boxes are included in each chapter. Each chapter is built around one or more worked examples to demonstrate the main idea of the chapter. Covers the fundamental algorithms of various fields, whether originally proposed for spoken or written language to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation. Emphasis on web and other practical applications. Emphasis on scientific evaluation. Useful as a reference for professionals in any of the areas of speech and language processing.",2000.0,261.0,4066.0,False,,"{'pages': 'I-XXVI, 1-934'}","{'bibtex': '@Inproceedings{Jurafsky2000SpeechAL,\n author = {Dan Jurafsky and James H. Martin},\n pages = {I-XXVI, 1-934},\n title = {Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition},\n year = {2000}\n}\n'}","[{'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '10796472', 'name': 'James H. Martin'}]"
2101,b56ef5c71c3d8d44816e0eac2a0ba1383424896c,More accurate confidence intervals in exponential families,"SUMMARY Fisher's theory of maximum likelihood estimation routinely provides approximate confidence intervals for a parameter of interest 0, the standard intervals 0? Za5,s where 0 is the maximum likelihood estimator, 5' is an estimate of standard error based on differentiation of the log likelihood function, and Za is a normal percentile point. Recent work has produced systems of better approximate confidence intervals, which look more like exact intervals when exact intervals exist, and in general have coverage probabilities an order of magnitude more accurate than the standard intervals. This paper develops an efficient and dependable algorithm for calculating highly accurate approximate intervals on a routine basis, for parameters 0 defined in the framework of a multiparameter exponential family. The better intervals require only a few times as much computational effort as the standard intervals. A variety of numerical and theoretical arguments are used to show that the algorithm works well, and that the improvement over the standard intervals can be striking in realistic situations.",1992.0,12.0,104.0,False,,"{'volume': '79', 'pages': '231-245', 'name': 'Biometrika'}","{'bibtex': '@Article{DiCiccio1992MoreAC,\n author = {T. DiCiccio and B. Efron},\n journal = {Biometrika},\n pages = {231-245},\n title = {More accurate confidence intervals in exponential families},\n volume = {79},\n year = {1992}\n}\n'}","[{'authorId': '4824776', 'name': 'T. DiCiccio'}, {'authorId': '2550392', 'name': 'B. Efron'}]"
2102,b5880e5f19bfe89b51cbeeeaf60d39e6b9f36a41,Environment optimization for crowd evacuation,"The layout of a building, real or virtual, affects the flow patterns of its intended users. It is well established, for example, that the placement of pillars at proper locations can often facilitate pedestrian flow during the evacuation of a building. Such considerations are therefore important for architects, game level developers, and others whose domains involve agents navigating through buildings. In this paper, we take the first steps towards developing a simulation framework that can be used to study the optimal placement of architectural elements, such as pillars or doors, for the purposes of facilitating dense pedestrian flow during the evacuation of a building. In particular, we show that the steering algorithms used to model the local navigation abilities of the agents significantly affect the results, which motivates the need for a statistically valid approach and further study. Copyright © 2015 John Wiley & Sons, Ltd.",2015.0,37.0,41.0,False,,"{'volume': '26', 'pages': '377 - 386', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Berseth2015EnvironmentOF,\n author = {G. Berseth and Muhammad Usman and M. B. Haworth and Mubbasir Kapadia and P. Faloutsos},\n journal = {Computer Animation and Virtual Worlds},\n pages = {377 - 386},\n title = {Environment optimization for crowd evacuation},\n volume = {26},\n year = {2015}\n}\n'}","[{'authorId': '2994035', 'name': 'G. Berseth'}, {'authorId': '145274939', 'name': 'Muhammad Usman'}, {'authorId': '38590145', 'name': 'M. B. Haworth'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '1737527', 'name': 'P. Faloutsos'}]"
2103,b5ac51cef9564204b4dc615e3d5884d47bc23312,Applying Augmented Reality to E-Learning for Foreign Language Study and its Evaluation,"- Various studies have been undertaken to adapt Augmented Reality (AR) technology for use in education. We see AR as being suitable for creating an enjoyable learning experience (edutainment) for students. In this study, we developed an AR application based on the same content as conventional printed teaching material focusing on the field of foreign language study. The learning efficacy of the two media was assessed by comparing verification test results and monitoring brain activity during the learning process. The results show that there is no significant difference in test results between the two media. However, we found that the subjects’ brains were more active while studying the printed teaching materials than the AR teaching materials. We believe this shows that the proposed method of study is overall a more natural one and, when compared with traditional methods of study, has the potential to be less stressful for students.",2012.0,15.0,11.0,False,,,"{'bibtex': '@Inproceedings{Miyosawa2012ApplyingAR,\n author = {T. Miyosawa and Mayuko Akahane and Kentaro Hara and Kikunori Shinohara},\n title = {Applying Augmented Reality to E-Learning for Foreign Language Study and its Evaluation},\n year = {2012}\n}\n'}","[{'authorId': '2988760', 'name': 'T. Miyosawa'}, {'authorId': '98088518', 'name': 'Mayuko Akahane'}, {'authorId': '49706232', 'name': 'Kentaro Hara'}, {'authorId': '4765645', 'name': 'Kikunori Shinohara'}]"
2104,b5b6d87f663fcc56cd7319ea49d6baaa653ecaae,Facial expression and emotion,"Zusammenfassung Die menschliche Mimik ist einzigartig in ihrer Fähigkeit unseren Emotionen Ausdruck zu verleihen und diese anderen Menschen zu übermitteln. Die mimische Expression grundlegender Emotionen ist über verschiedene Kulturen hinweg sehr ähnlich und du weist auch Gemeinsamkeiten zu anderen Säugetieren auf. Dies deutet auf einen gemeinsamen genetischen Ursprung des Zusammenhangs von Mimik und Emotion. Neuere Untersuchungen zeigen aber auch kulturelle Einflüsse und Unterschiede. Die Erkennung von Emotionen aus der Mimik und auch der Prozess des mimischen Ausdrucks der eigenen Emotionen erfolgt in einem äußerst komplexen zerebralen Netzwerk. Aufgrund der Komplexität des zerebralen Verarbeitungssystems gibt es eine Vielzahl von neurologischen und psychiatrischen Erkrankungen, welche die Kopplung von Mimik und Emotionen erheblich stören können. Auch durch das Tragen von Masken wird unsere Fähigkeit zur Übermittlung und zum Erkennen von Emotionen über die Mimik eingeschränkt. Durch die Mimik lassen sich aber nicht nur „echte“ Emotionen ausdrücken, sondern auch gespielte. Damit eröffnet die Mimik die Möglichkeit sozial erwünschten Ausdruck vorzuspielen und auch Emotionen bewusst vorzutäuschen. Diese Täuschungen sind jedoch zumeist nicht perfekt und können von kurzfristigen Gesichtsbewegungen begleitet sein, die auf die tatsächlich vorhandenen Emotionen hinweisen (Mikroexpressionen). Diese Mikroexpressionen sind von nur sehr kurzer Dauer und vom Menschen häufig kaum wahrnehmbar, jedoch das ideale Anwendungsgebiet für computergestützte Analysen. Diese automatische Identifikation von Mikroexpressionen hat in den letzten Jahren nicht nur wissenschaftliche Aufmerksamkeit erfahren, sondern ihr Einsatz wird auch in sicherheitsrelevanten Bereichen getestet. Der vorliegende Artikel fasst den aktuellen Wissensstand von Mimik und Emotionen zusammen. ABSTRACT Human facial expressions are unique in their ability to express our emotions and communicate them to others. The mimic expression of basic emotions is very similar across different cultures and has also many features in common with other mammals. This suggests a common genetic origin of the association between facial expressions and emotion. However, recent studies also show cultural influences and differences. The recognition of emotions from facial expressions, as well as the process of expressing one’s emotions facially, occurs within an extremely complex cerebral network. Due to the complexity of the cerebral processing system, there are a variety of neurological and psychiatric disorders that can significantly disrupt the coupling of facial expressions and emotions. Wearing masks also limits our ability to convey and recognize emotions through facial expressions. Through facial expressions, however, not only “real” emotions can be expressed, but also acted ones. Thus, facial expressions open up the possibility of faking socially desired expressions and also of consciously faking emotions. However, these pretenses are mostly imperfect and can be accompanied by short-term facial movements that indicate the emotions that are actually present (microexpressions). These microexpressions are of very short duration and often barely perceptible by humans, but they are the ideal application area for computer-aided analysis. This automatic identification of microexpressions has not only received scientific attention in recent years, but its use is also being tested in security-related areas. This article summarizes the current state of knowledge of facial expressions and emotions.",2023.0,131.0,1350.0,True,"{'url': 'http://www.thieme-connect.de/products/ejournals/pdf/10.1055/a-2003-5687.pdf', 'status': None}","{'volume': '102', 'pages': 'S115 - S125', 'name': 'Laryngo- Rhino- Otologie'}","{'bibtex': '@Article{Klingner2023FacialEA,\n author = {C. Klingner and O. Guntinas-Lichius},\n journal = {Laryngo- Rhino- Otologie},\n pages = {S115 - S125},\n title = {Facial expression and emotion},\n volume = {102},\n year = {2023}\n}\n'}","[{'authorId': '47016130', 'name': 'C. Klingner'}, {'authorId': '2149403111', 'name': 'O. Guntinas-Lichius'}]"
2106,b5c6c7ea99fe35c55e83df53feb85e8e2953d001,"Eliciting mixed emotions: a meta-analysis comparing models, types, and measures","The idea that people can experience two oppositely valenced emotions has been controversial ever since early attempts to investigate the construct of mixed emotions. This meta-analysis examined the robustness with which mixed emotions have been elicited experimentally. A systematic literature search identified 63 experimental studies that instigated the experience of mixed emotions. Studies were distinguished according to the structure of the underlying affect model—dimensional or discrete—as well as according to the type of mixed emotions studied (e.g., happy-sad, fearful-happy, positive-negative). The meta-analysis using a random-effects model revealed a moderate to high effect size for the elicitation of mixed emotions (dIG+ = 0.77), which remained consistent regardless of the structure of the affect model, and across different types of mixed emotions. Several methodological and design moderators were tested. Studies using the minimum index (i.e., the minimum value between a pair of opposite valenced affects) resulted in smaller effect sizes, whereas subjective measures of mixed emotions increased the effect sizes. The presence of more women in the samples was also associated with larger effect sizes. The current study indicates that mixed emotions are a robust, measurable and non-artifactual experience. The results are discussed in terms of the implications for an affect system that has greater versatility and flexibility than previously thought.",2015.0,106.0,136.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00428/pdf', 'status': None}","{'volume': '6', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Berrios2015ElicitingME,\n author = {Raul Berrios and P. Totterdell and S. Kellett},\n journal = {Frontiers in Psychology},\n title = {Eliciting mixed emotions: a meta-analysis comparing models, types, and measures},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '6585586', 'name': 'Raul Berrios'}, {'authorId': '1993236', 'name': 'P. Totterdell'}, {'authorId': '5507248', 'name': 'S. Kellett'}]"
2107,b60c7f2ed3374b490cfac4471de1cdf7588d9cd4,Enhancing Social Believability of Virtual Agents using Social Power Dynamics,"Social Power, a pervasive feature in our daily life, has been proved to have a significant impact on Social Interaction; While the capability of maintaining a Social Interaction has an acknowledged role in Believability of Intelligent Virtual Agents (IVAs). In this paper, we argue that an ability of reasoning and planning in the presence of Social Power enhances Social Believability of IVAs, leading to more rational interactions. With this aim, we focus on theoretical issues of agent modeling aiming at increasing intelligence and therefore believability of NPCs or agents of game-like simulations or serious games. Thereby, we propose a model of social power inspired by a recently proposed model, SAPIENT, based on a well-known theory of Social Power proposed by French and Raven.",2018.0,26.0,6.0,False,,{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Hashemian2018EnhancingSB,\n author = {M. Hashemian and R. Prada and P. A. Santos and S. Mascarenhas},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {Enhancing Social Believability of Virtual Agents using Social Power Dynamics},\n year = {2018}\n}\n'}","[{'authorId': '2640328', 'name': 'M. Hashemian'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145255182', 'name': 'P. A. Santos'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}]"
2108,b629bba548337c3482aa39a25c82c2f9624866aa,"Children's engagement during digital game-based learning of reading: The effects of time, rewards, and challenge",,2014.0,50.0,183.0,False,,"{'volume': '71', 'pages': '237-246', 'name': 'Comput. Educ.'}","{'bibtex': ""@Article{Ronimus2014ChildrensED,\n author = {Miia Ronimus and J. Kujala and A. Tolvanen and H. Lyytinen},\n journal = {Comput. Educ.},\n pages = {237-246},\n title = {Children's engagement during digital game-based learning of reading: The effects of time, rewards, and challenge},\n volume = {71},\n year = {2014}\n}\n""}","[{'authorId': '2940002', 'name': 'Miia Ronimus'}, {'authorId': '2084127', 'name': 'J. Kujala'}, {'authorId': '2997867', 'name': 'A. Tolvanen'}, {'authorId': '39518098', 'name': 'H. Lyytinen'}]"
2109,b6536a8f688d6d712316e98fd38097a8a442709f,Social functions of emotion and emotion regulation,,2016.0,0.0,90.0,False,,"{'volume': '', 'pages': '424-439', 'name': ''}","{'bibtex': '@Inproceedings{Fischer2016SocialFO,\n author = {A. Fischer and A. Manstead},\n pages = {424-439},\n title = {Social functions of emotion and emotion regulation},\n year = {2016}\n}\n'}","[{'authorId': '7444483', 'name': 'A. Fischer'}, {'authorId': '92736978', 'name': 'A. Manstead'}]"
2110,b6586981b15d336bd34245c5b7bb8726f46b284f,EduRP: an Educational Resources Platform based on Opinion Mining and Semantic Web,": Educational platforms have become important tools for e-learning; nonetheless, finding the appropriate educational resources to use often represents a tedious task for learners. Opinions in the educational domain are important information for decision making; they allow teachers to improve the teaching process and enable students to decide on the best educational resources. The large amount of data that is daily generated on the Web makes it difficult, however, to analyze opinions manually. Multiple opinion mining approaches are being proposed as a solution to this problem; this research work introduces EduRP, an education platform that integrates opinion mining techniques and ontology-based user profiling techniques. We specifically propose an opinion mining approach for Spanish text which consists of three main steps: 1) collect opinions from the EduRP platform, 2) process the opinions to normalize the text, and 3) obtain the polarity of the opinions using a machine learning approach. We also propose a profile customization approach that uses Semantic Web technologies, specifically ontologies, to integrate socio-demographic data from different social networks and from the platform itself. Finally, we assess the performance of our system under precision, recall, and F-measure metrics, obtaining average values of 81.85%, 81.80% and 81.54, respectively.",2018.0,24.0,14.0,False,,"{'volume': '24', 'pages': '1515-1535', 'name': 'J. Univers. Comput. Sci.'}","{'bibtex': '@Article{Bustos-López2018EduRPAE,\n author = {Maritza Bustos-López and G. Alor-Hernández and J. L. Sánchez-Cervantes and María del Pilar Salas-Zárate and Mario Andrés Paredes-Valverde},\n journal = {J. Univers. Comput. Sci.},\n pages = {1515-1535},\n title = {EduRP: an Educational Resources Platform based on Opinion Mining and Semantic Web},\n volume = {24},\n year = {2018}\n}\n'}","[{'authorId': '1401236683', 'name': 'Maritza Bustos-López'}, {'authorId': '1397382854', 'name': 'G. Alor-Hernández'}, {'authorId': '1403484174', 'name': 'J. L. Sánchez-Cervantes'}, {'authorId': '1398978805', 'name': 'María del Pilar Salas-Zárate'}, {'authorId': '1398978803', 'name': 'Mario Andrés Paredes-Valverde'}]"
2111,b67c8a0ac3737c69eef925bb6bf5206e625760e6,Nonverbal behavior in clinician—patient interaction,,1995.0,177.0,276.0,False,,"{'volume': '4', 'pages': '21-37', 'name': 'Applied & Preventive Psychology'}","{'bibtex': '@Article{Hall1995NonverbalBI,\n author = {Judith A. Hall and J. Harrigan and R. Rosenthal},\n journal = {Applied & Preventive Psychology},\n pages = {21-37},\n title = {Nonverbal behavior in clinician—patient interaction},\n volume = {4},\n year = {1995}\n}\n'}","[{'authorId': '47355138', 'name': 'Judith A. Hall'}, {'authorId': '4011070', 'name': 'J. Harrigan'}, {'authorId': '67149081', 'name': 'R. Rosenthal'}]"
2112,b694cb24ec28fdc5fe07c857f8ec377169ece0ab,"The Empathy Quotient: An Investigation of Adults with Asperger Syndrome or High Functioning Autism, and Normal Sex Differences",,2004.0,61.0,3492.0,False,,"{'volume': '34', 'pages': '163-175', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Baron-Cohen2004TheEQ,\n author = {S. Baron-Cohen and S. Wheelwright},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {163-175},\n title = {The Empathy Quotient: An Investigation of Adults with Asperger Syndrome or High Functioning Autism, and Normal Sex Differences},\n volume = {34},\n year = {2004}\n}\n'}","[{'authorId': '1390019127', 'name': 'S. Baron-Cohen'}, {'authorId': '3159706', 'name': 'S. Wheelwright'}]"
2114,b69646bf2a11711e673e226e68f3bb059265944d,Animated Pedagogical Agents: An Opportunity to be Grasped?,"In open learning environments students are confronted with complex tasks. Learners have control over the environment and decide themselves over the use of support tools. However, research indicates that merely providing students with these tools does not result in their actual use. In this article possibilities of animated pedagogical agents to enhance the use of support tools are explored. First, a typology is constructed to describe and compare the different pedagogical agents from an instructional design perspective. Second currently available pedagogical agents are analyzed, and finally empirical research on pedagogical agents in educational settings is reviewed. The conclusion discusses future research perspectives. ********** The use of open learning environments is advocated when learning complex problem-solving skills (Jonassen, 1997). These environments are characterized by at least three features. First, students receive a complex task that has to be examined from different perspectives to generate a suitable solution (Spiro, Feltovich, Jacobson, & Coulson, 1991). Second, support tools are embedded in the environment. Their use may help to solve the problem by structuring the problem-solving process or by providing problem-solving tools. And third, learners are responsible for their own learning and decide, themselves, on the use of these supportive elements. In other words, there is a large amount of learner control (Hannafin, 1995). In spite of strong theoretical arguments in favor of open learning environments, research demonstrates that students in open learning environments do not optimally use accessible support tools (Clarebout, Elen, Lowyck, Van den Ende, & Lagana, 2000; Crooks, Klein, Jones, & Dwyer, 1996, Land, 2000). Students seem not always capable to make the appropriate choices (Clark, 1991; Large, 1996; Hill & Hannafin, 2001; Lee & Lehman, 1993; Shaw, Johnson, & Ganeshan, 1999). This has a negative impact on the effectiveness and efficiency of leaming in open learning environments. How to encourage learners to make more ample and deliberate use of support in open learning environments is therefore an important question from an instructional design perspective. Two developments seem especially relevant in this respect. The first one relates to the interaction between learner characteristics and support characteristics. Research within the aptitude-treatment-interaction tradition revealed strong interactions between individual learner characteristics and instructional interventions (Snow, 1986; Snow & Swanson, 1992). This also pertains to support devices. Clark (1991) demonstrated that both too much or not enough support may be detrimental to learning. A second development pertains to the delivery of support. Technological evolutions and especially the development of so called pedagogical agents may provide possibilities to individualize support and encourage learners to use it. Pedagogical agents are, by definition, animated characters designed to operate in an educational setting for supporting or facilitating learning (Shaw, et al., 1999). They can adapt their support to learning paths of students and provide students with nonverbal feedback (Gregoire, Zettlemoyer, & Lester, 1999; Johnson, Rickel, & Lester, 2000). Pedagogical agents have been primarily described and studied from a technological perspective (Johnson et al., 2000; Johnson, Rickel, Stiles, & Munro, 1997; Lester, Voerman, Towns, & Callaway, 1997, Graesser, Wiemer-Hastings, Wiemer-Hastings, & Kreuz, 1999). Nevertheless, studies with a more learning oriented perspective are beginning to emerge (e.g., Moreno & Mayer, 2000). To consider the use of pedagogical agents in instructional design endeavors and to study their role in encouraging students to use help functions, a common instructional typology is needed to describe these agents. …",2002.0,0.0,109.0,False,,"{'volume': '11', 'pages': '267-286', 'name': 'Journal of Educational Multimedia and Hypermedia'}","{'bibtex': '@Article{Clarebout2002AnimatedPA,\n author = {G. Clarebout and J. Elen and W. Johnson and Erin Shaw},\n journal = {Journal of Educational Multimedia and Hypermedia},\n pages = {267-286},\n title = {Animated Pedagogical Agents: An Opportunity to be Grasped?},\n volume = {11},\n year = {2002}\n}\n'}","[{'authorId': '1795235', 'name': 'G. Clarebout'}, {'authorId': '1783893', 'name': 'J. Elen'}, {'authorId': '145834585', 'name': 'W. Johnson'}, {'authorId': '143878462', 'name': 'Erin Shaw'}]"
2115,b6980ceff33c6e114a53fa69f5ad9d9430fdabe2,Analysis of personality measures in terms of basic dimensions of temperament.,,1980.0,36.0,82.0,False,,"{'volume': '38', 'pages': '492-503', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': ""@Article{Mehrabian1980AnalysisOP,\n author = {A. Mehrabian and E. O'reilly},\n journal = {Journal of Personality and Social Psychology},\n pages = {492-503},\n title = {Analysis of personality measures in terms of basic dimensions of temperament.},\n volume = {38},\n year = {1980}\n}\n""}","[{'authorId': '144102217', 'name': 'A. Mehrabian'}, {'authorId': '2072471638', 'name': ""E. O'reilly""}]"
2116,b6a266e2990aab3158a755607eba715757ab46d8,Why emotions should be integrated into conversational agents,"When building conversational agents that are to take part in social interaction with humans, an important question is whether psychological concepts like emotions or personality of the agents need to be incorporated. In this chapter we argue for the integration of an emotion system 
into a conversational agent to enable the simulation of having “own emotions”. We first clarify the concept of emotions and we discuss different approaches to modeling emotions and personality in artificial systems. Drawing on our work on the multimodal conversational agent Max, we present motives for the integration of emotions as integral parts of an agent’s cognitive architecture. Our approach combines different psychological emotion theories and distinguishes between primary and secondary emotions as originating from different levels of this architecture. Exemplary application scenarios are described to show how the agent’s believability can be increased by the integration of emotions. In a cooperative setting, Max 
is employed as a virtual interactive guide in a public computer museum, where his emotion module enhances his acceptance as a coequal conversational partner. We further quote an empirical study that yields evidence that the same emotion module supports the believability 
and lifelikeness of the agent in a competitive gaming scenario.",2007.0,60.0,73.0,False,,"{'volume': '', 'pages': '49-67', 'name': ''}","{'bibtex': '@Inproceedings{Becker2007WhyES,\n author = {Christian Becker and S. Kopp and I. Wachsmuth},\n pages = {49-67},\n title = {Why emotions should be integrated into conversational agents},\n year = {2007}\n}\n'}","[{'authorId': '2068695177', 'name': 'Christian Becker'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
2117,b6a7f03ba57bcdab85ffd89cbf9b9d44de1910ec,Improving Patient Adherence,"IN BRIEF Regimen adherence problems are common in individuals with diabetes, making
glycemic control difficult to attain. Because the risk of complications of
diabetes can be reduced by proper adherence, patient nonadherence to treatment
recommendations is often frustrating for diabetes health care professionals.
This article reviews the scope of the adherence problem and the factors
underlying it. The author discusses the concepts of compliance and adherence
and offers recommendations for improving adherence by adopting a more
collaborative model of care emphasizing patient autonomy and choice.",2006.0,38.0,528.0,True,"{'url': 'https://diabetesjournals.org/clinical/article-pdf/24/2/71/320696/0071.pdf', 'status': None}","{'volume': '24', 'pages': '71-77', 'name': 'Clinical Diabetes'}","{'bibtex': '@Article{Delamater2006ImprovingPA,\n author = {A. Delamater},\n journal = {Clinical Diabetes},\n pages = {71-77},\n title = {Improving Patient Adherence},\n volume = {24},\n year = {2006}\n}\n'}","[{'authorId': '4075697', 'name': 'A. Delamater'}]"
2118,b6b782cac09b34043cc7aafee17bcfb62dbd1a05,Gaze-Sensitive Virtual Reality Based Social Communication Platform for Individuals with Autism,"Autism spectrum disorder (ASD) is often characterized by core deficits in social communication and ability to understand others’ non-verbal emotional cues. This can be attributed to their atypical eye-gaze patterns along with reduced fixation towards communicator's face during social communication. With technological progress, Virtual Reality (VR) augmented with peripherals such as, eye tracker can offer a promising complementary assistive platform for presenting various social situations to this target group along with quantification of one's task performance and measurement of gaze-related indices. This paper presents the design of a VR-based social communication platform augmented with technologically-enhanced eye-tracking facility as a proof-of-concept application. We measured one's performance score along with real-time synchronized gaze-related indices while one interacted with VR-based social tasks having both context-relevant verbal and non-verbal components of social interaction. The results of a usability study carried out in the Indian sub-continent with eight pairs of individuals with ASD and typically-developing individuals showed the potential of our system to have implications on one's task performance and gaze-related indices in response to virtual peer's emotional expressions. The implication of emotions on gaze-related behavioral and physiological indices shows the potential of using gaze-related indices as bio-markers of one's anxiety during social communication.",2018.0,47.0,28.0,False,,"{'volume': '9', 'pages': '450-462', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Babu2018GazeSensitiveVR,\n author = {Pradeep Raj Krishnappa Babu and Poojan Oza and U. Lahiri},\n journal = {IEEE Transactions on Affective Computing},\n pages = {450-462},\n title = {Gaze-Sensitive Virtual Reality Based Social Communication Platform for Individuals with Autism},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '52161814', 'name': 'Pradeep Raj Krishnappa Babu'}, {'authorId': '144477698', 'name': 'Poojan Oza'}, {'authorId': '2393577', 'name': 'U. Lahiri'}]"
2119,b6c236d61c5b6f93087f7804d735141725484123,Best Practice Strategies for Effective Use of Questions as a Teaching Tool,"Questions have long been used as a teaching tool by teachers and preceptors to assess students’ knowledge, promote comprehension, and stimulate critical thinking. Well-crafted questions lead to new insights, generate discussion, and promote the comprehensive exploration of subject matter. Poorly constructed questions can stifle learning by creating confusion, intimidating students, and limiting creative thinking. Teachers most often ask lower-order, convergent questions that rely on students’ factual recall of prior knowledge rather than asking higher-order, divergent questions that promote deep thinking, requiring students to analyze and evaluate concepts. This review summarizes the taxonomy of questions, provides strategies for formulating effective questions, and explores practical considerations to enhance student engagement and promote critical thinking. These concepts can be applied in the classroom and in experiential learning environments.",2013.0,34.0,270.0,True,"{'url': 'https://www.ajpe.org/content/ajpe/77/7/155.full.pdf', 'status': None}","{'volume': '77', 'name': 'American Journal of Pharmaceutical Education'}","{'bibtex': '@Article{Tofade2013BestPS,\n author = {T. Tofade and Jamie N. Elsner and Stuart T Haines},\n journal = {American Journal of Pharmaceutical Education},\n title = {Best Practice Strategies for Effective Use of Questions as a Teaching Tool},\n volume = {77},\n year = {2013}\n}\n'}","[{'authorId': '11018594', 'name': 'T. Tofade'}, {'authorId': '2073888305', 'name': 'Jamie N. Elsner'}, {'authorId': '4304131', 'name': 'Stuart T Haines'}]"
2120,b75a3ff12044610d0f12d46b00ad0f60f09bc968,Student Designed Virtual Teacher Feedback,"Interactive virtual learning environments (VLEs) have significant potential to influence students' learning achievements. Characters in these VLEs can act as a virtual peers and teachers by providing empathic responses tailored to the affective state of the students. Designing appropriate dialogues and feedback will be important in achieving the desired outcomes such as increased engagement, motivation and achievement. In this paper we report our findings from a study with 19 girls in Year 8 and 9 at high school using the Omosa VLE. The study investigated student responses to the initial dialogues we designed to elicit their emotional state and provide support. Analysis of responses and alternative dialogues offered by the students revealed that the feedback provided by our characters was mostly acceptable, but further improvements should be made to include elements such as self-disclosure and more helpful dialogue.",2017.0,10.0,4.0,False,,{'pages': '26-30'},"{'bibtex': '@Inproceedings{Ranjbartabar2017StudentDV,\n author = {Hedieh Ranjbartabar and Deborah Richards},\n pages = {26-30},\n title = {Student Designed Virtual Teacher Feedback},\n year = {2017}\n}\n'}","[{'authorId': '2788668', 'name': 'Hedieh Ranjbartabar'}, {'authorId': '144037536', 'name': 'Deborah Richards'}]"
2121,b75cb25753c947224dd18ef4f2cdf91e493af2d2,Architecture of an Intelligent Training System based on Virtual Environments for Electricity Distribution Substations,"In the electrical domain, qualified electricians are required since it involves danger. Training has been based on classroom courses and practice in the real installations, but it takes a long time and is costly. We propose to complement traditional training with an intelligent training system based on virtual environments in such a way that a blended training model is composed. We are looking for adaptive and innovative training; therefore we are including the characteristics and states of the student to adapt the instruction. We are developing a system to teach novice student how an electrical substation works as well as its individual compounding equipment. The proposed architecture for the intelligent training system and the development progress of the virtual environment are presented.",2016.0,14.0,4.0,True,,"{'volume': '129', 'pages': '63-70', 'name': 'Res. Comput. Sci.'}","{'bibtex': '@Article{Hernández2016ArchitectureOA,\n author = {Y. Hernández and Miguel Pérez-Ramírez and William Ingram Ramírez and Eric Nava Ayala and Norma J. Ontiveros-Hernández},\n journal = {Res. Comput. Sci.},\n pages = {63-70},\n title = {Architecture of an Intelligent Training System based on Virtual Environments for Electricity Distribution Substations},\n volume = {129},\n year = {2016}\n}\n'}","[{'authorId': '145513668', 'name': 'Y. Hernández'}, {'authorId': '1401994903', 'name': 'Miguel Pérez-Ramírez'}, {'authorId': '1409237384', 'name': 'William Ingram Ramírez'}, {'authorId': '1410527312', 'name': 'Eric Nava Ayala'}, {'authorId': '1409001854', 'name': 'Norma J. Ontiveros-Hernández'}]"
2122,b774f3fc6b05a86d966365ba46a2c6ea9612bfce,Age differences in recognition of emotion in lexical stimuli and facial expressions.,"Age differences in emotion recognition from lexical stimuli and facial expressions were examined in a cross-sectional sample of adults aged 18 to 85 (N = 357). Emotion-specific response biases differed by age: Older adults were disproportionately more likely to incorrectly label lexical stimuli as happiness, sadness, and surprise and to incorrectly label facial stimuli as disgust and fear. After these biases were controlled, findings suggested that older adults were less accurate at identifying emotions than were young adults, but the pattern differed across emotions and task types. The lexical task showed stronger age differences than the facial task, and for lexical stimuli, age groups differed in accuracy for all emotional states except fear. For facial stimuli, in contrast, age groups differed only in accuracy for anger, disgust, fear, and happiness. Implications for age-related changes in different types of emotional processing are discussed.",2007.0,60.0,315.0,False,,"{'volume': '22 1', 'pages': '\n          147-59\n        ', 'name': 'Psychology and aging'}","{'bibtex': '@Article{Isaacowitz2007AgeDI,\n author = {D. Isaacowitz and C. Löckenhoff and R. Lane and R. Wright and L. Sechrest and R. Riedel and P. Costa},\n journal = {Psychology and aging},\n pages = {\n          147-59\n        },\n title = {Age differences in recognition of emotion in lexical stimuli and facial expressions.},\n volume = {22 1},\n year = {2007}\n}\n'}","[{'authorId': '1919851', 'name': 'D. Isaacowitz'}, {'authorId': '2538621', 'name': 'C. Löckenhoff'}, {'authorId': '50480971', 'name': 'R. Lane'}, {'authorId': '48466798', 'name': 'R. Wright'}, {'authorId': '1808389760', 'name': 'L. Sechrest'}, {'authorId': '46559560', 'name': 'R. Riedel'}, {'authorId': '2281038', 'name': 'P. Costa'}]"
2124,b77f4487be0a8285654553de443e44015d435961,A System Dynamics and Agent-Based Approach to Model Emotions in Collaborative Networks,,2017.0,55.0,9.0,True,"{'url': 'https://hal.inria.fr/hal-01629604/file/448071_1_En_3_Chapter.pdf', 'status': None}",{'pages': '29-43'},"{'bibtex': '@Inproceedings{Ferrada2017ASD,\n author = {Filipa Ferrada and L. Camarinha-Matos},\n pages = {29-43},\n title = {A System Dynamics and Agent-Based Approach to Model Emotions in Collaborative Networks},\n year = {2017}\n}\n'}","[{'authorId': '2834276', 'name': 'Filipa Ferrada'}, {'authorId': '1397341979', 'name': 'L. Camarinha-Matos'}]"
2125,b79e9ee1fa71af99f37079037cc22089195bb224,"Formal models of appraisal: Theory, specification, and computational model",,2008.0,41.0,64.0,False,,"{'volume': '9', 'pages': '173-197', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Broekens2008FormalMO,\n author = {J. Broekens and D. DeGroot and W. Kosters},\n journal = {Cognitive Systems Research},\n pages = {173-197},\n title = {Formal models of appraisal: Theory, specification, and computational model},\n volume = {9},\n year = {2008}\n}\n'}","[{'authorId': '1735303', 'name': 'J. Broekens'}, {'authorId': '145678408', 'name': 'D. DeGroot'}, {'authorId': '1680388', 'name': 'W. Kosters'}]"
2126,b7ced6ae7c3899e410852910c82b31d65a6cf565,Designing Emotions,,2011.0,25.0,244.0,False,,"{'volume': '25', 'pages': '205-211', 'name': 'KI - Künstliche Intelligenz'}","{'bibtex': '@Article{Kipp2011DesigningE,\n author = {Michael Kipp and Thomas Dackweiler and Patrick Gebhard},\n journal = {KI - Künstliche Intelligenz},\n pages = {205-211},\n title = {Designing Emotions},\n volume = {25},\n year = {2011}\n}\n'}","[{'authorId': '145616714', 'name': 'Michael Kipp'}, {'authorId': '1934427', 'name': 'Thomas Dackweiler'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}]"
2127,b7e3343ec10cc5cfc83e1a238c10ac08e5d393d8,Bodily expression of emotion,"The question whether body movements and body postures are indicative of specific emotions is a matter of debate. While some studies have found evidence for specific body movements accompanying specific emotions, others indicate that movement behavior (aside from facial expression) may be only indicative of the quantity (intensity) of emotion, but not of its quality. The study reported here is an attempt to demonstrate that body movements and postures to some degree are specific for certain emotions. A sample of 224 video takes, in which actors and actresses portrayed the emotions of elated joy, happiness, sadness, despair, fear, terror, cold anger, hot anger, disgust, contempt, shame, guilt, pride, and boredom via a scenario approach, was analyzed using coding schemata for the analysis of body movements and postures. Results indicate that some emotion-specific movement and posture characteristics seem to exist, but that for body movements differences between emotions can be partly explained by the dimension of activation. While encoder (actor) differences are rather pronounced with respect to specific movement and posture habits, these differences are largely independent from the emotion-specific differences found. The results are discussed with respect to emotion-specific discrete expression models in contrast to dimensional models of emotion encoding. Copyright © 1998 John Wiley & Sons, Ltd.",1998.0,33.0,473.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/%28SICI%291099-0992%281998110%2928%3A6%3C879%3A%3AAID-EJSP901%3E3.0.CO%3B2-W', 'status': None}","{'volume': '28', 'pages': '879-896', 'name': 'European Journal of Social Psychology'}","{'bibtex': '@Article{Wallbott1998BodilyEO,\n author = {H. Wallbott},\n journal = {European Journal of Social Psychology},\n pages = {879-896},\n title = {Bodily expression of emotion},\n volume = {28},\n year = {1998}\n}\n'}","[{'authorId': '4874112', 'name': 'H. Wallbott'}]"
2128,b7f2f04edd37b012e3c52ecf47af1c99e87127e1,Acoustic Word Embeddings for End-to-End Speech Synthesis,"The most recent end-to-end speech synthesis systems use phonemes as acoustic input tokens and ignore the information about which word the phonemes come from. However, many words have their specific prosody type, which may significantly affect the naturalness. Prior works have employed pre-trained linguistic word embeddings as TTS system input. However, since linguistic information is not directly relevant to how words are pronounced, TTS quality improvement of these systems is mild. In this paper, we propose a novel and effective way of jointly training acoustic phone and word embeddings for end-to-end TTS systems. Experiments on the LJSpeech dataset show that the acoustic word embeddings dramatically decrease both the training and validation loss in phone-level prosody prediction. Subjective evaluations on naturalness demonstrate that the incorporation of acoustic word embeddings can significantly outperform both pure phone-based system and the TTS system with pre-trained linguistic word embedding.",2021.0,23.0,3.0,True,"{'url': 'https://www.mdpi.com/2076-3417/11/19/9010/pdf?version=1632887255', 'status': None}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Shen2021AcousticWE,\n author = {Feiyu Shen and Chenpeng Du and K. Yu},\n journal = {Applied Sciences},\n title = {Acoustic Word Embeddings for End-to-End Speech Synthesis},\n year = {2021}\n}\n'}","[{'authorId': '2146848507', 'name': 'Feiyu Shen'}, {'authorId': '1658323286', 'name': 'Chenpeng Du'}, {'authorId': '47841301', 'name': 'K. Yu'}]"
2129,b7f49969204503a27bd369820b17fdd652d6a1ff,"Emotion: Theory, Research and Experience",,1982.0,0.0,1045.0,True,,"{'volume': '170', 'pages': '315-316', 'name': 'Journal of Nervous and Mental Disease'}","{'bibtex': '@Article{Hughes1982EmotionTR,\n author = {C. W. Hughes},\n journal = {Journal of Nervous and Mental Disease},\n pages = {315-316},\n title = {Emotion: Theory, Research and Experience},\n volume = {170},\n year = {1982}\n}\n'}","[{'authorId': '2056019545', 'name': 'C. W. Hughes'}]"
2130,b80d46e0fe2ed8392eb08273497723d1d112cd9b,Facial Expression Recognition for Intelligent Tutoring Systems in Remote Laboratories Platform,,2015.0,25.0,37.0,True,,"{'volume': '73', 'pages': '274-281', 'name': 'Procedia Computer Science'}","{'bibtex': '@Article{Khalfallah2015FacialER,\n author = {Jihen Khalfallah and J. Slama},\n journal = {Procedia Computer Science},\n pages = {274-281},\n title = {Facial Expression Recognition for Intelligent Tutoring Systems in Remote Laboratories Platform},\n volume = {73},\n year = {2015}\n}\n'}","[{'authorId': '70453290', 'name': 'Jihen Khalfallah'}, {'authorId': '7343974', 'name': 'J. Slama'}]"
2131,b826d6986cf8390bdd28b2be5cce91bf9471b770,Pancultural Aspects of the Human Conceptual Organization of Emotions,"This study investigated whether certain elementary properties of the human conceptual system for categorizing emotions are pancultural or are specific to particular languages and cultures. From similarity judgments provided by native speakers, multidimensional scalings of emotion-related words in Gujarati, Croatian, Japanese, Chinese, and English provided evidence of several pancultural properties. In all five languages, emotion-related words ,fell in roughly a circular order in a space definable by two dimensions: pleasure-displeasure and arousal-sleep. Similar results were obtained from unilingual and bilingual subjects.",1983.0,42.0,393.0,False,,"{'volume': '45', 'pages': '1281-1288', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Russell1983PanculturalAO,\n author = {J. Russell},\n journal = {Journal of Personality and Social Psychology},\n pages = {1281-1288},\n title = {Pancultural Aspects of the Human Conceptual Organization of Emotions},\n volume = {45},\n year = {1983}\n}\n'}","[{'authorId': '46367714', 'name': 'J. Russell'}]"
2132,b85464fc97560b8ab7ccc2324a4839082f2b2b54,Design and Evaluation of Embodied Conversational Agents: A Proposed Taxonomy,"workshop call demonstrates that our field is eager to move beyond first-generation generalist projects, toward a more mature practice. To do so, we seek to set up a common set of expectations and criteria for how to judge our work. In this paper, we propose some subclasses of embodied conversational character research and design, with criteria for describing and evaluating research and design advances in each. We suggest that researchers in this field could benefit from carefully identifying their own areas of expertise and contribution, and then looking for ways to collaborate on standards and share advances within these sub- areas. Presenting results, then, would require making clear the sub-areas addressed by the particular project, with evaluations appropriate to those areas included. We believe this approach can help the research community to clarify contributions, and more easily build a common base of knowledge.",2002.0,35.0,61.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Isbister2002DesignAE,\n author = {K. Isbister and Patrick Doyle},\n title = {Design and Evaluation of Embodied Conversational Agents: A Proposed Taxonomy},\n year = {2002}\n}\n'}","[{'authorId': '1740889', 'name': 'K. Isbister'}, {'authorId': '144164167', 'name': 'Patrick Doyle'}]"
2133,b86c402ed82b2e3f66fbd7c33964f157c9f97a94,Study on Deformation Rule of Personalized-Avatar for Producing Sense of Affinity,"In avatar-mediated communication, there is concern that the deference between user's and avatar's appearances detracts the sense of affinity. However, the personalized avatar did not produce the favorability against the expectation. In this study, a general deformation rule independent from the aspects of the model was discussed by comparing the sixteen cartoonish deformed portraits to the originals. An avatar personalize tool based on the averaged deformation proportions was developed. It was experimentally confirmed that the deformed-personalized avatars tend to produce the more sense",2011.0,0.0,6.0,False,,"{'volume': '13', 'pages': '243-254', 'name': ''}","{'bibtex': '@Inproceedings{Heike2011StudyOD,\n author = {Masayuki Heike and H. Kawasaki and Takahiro Tanaka and K. Fujita},\n pages = {243-254},\n title = {Study on Deformation Rule of Personalized-Avatar for Producing Sense of Affinity},\n volume = {13},\n year = {2011}\n}\n'}","[{'authorId': '48706380', 'name': 'Masayuki Heike'}, {'authorId': '1972507', 'name': 'H. Kawasaki'}, {'authorId': '49126074', 'name': 'Takahiro Tanaka'}, {'authorId': '1733141', 'name': 'K. Fujita'}]"
2134,b8a63ed6c02b5382930faa500ee6a891c0223e26,Congruency Matters - How Ambiguous Gender Cues Increase a Robot's Uncanniness,,2016.0,16.0,15.0,False,,{'pages': '402-412'},"{'bibtex': ""@Inproceedings{Paetzel2016CongruencyM,\n author = {Maike Paetzel and Christopher E. Peters and Ingela Nyström and Ginevra Castellano},\n pages = {402-412},\n title = {Congruency Matters - How Ambiguous Gender Cues Increase a Robot's Uncanniness},\n year = {2016}\n}\n""}","[{'authorId': '2710492', 'name': 'Maike Paetzel'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '1783613', 'name': 'Ingela Nyström'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
2135,b8b1c89aeff6bdf45046c726fae9421447f82b39,Society 5.0,,2018.0,0.0,160.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Salgues2018Society5,\n author = {Bruno Salgues},\n title = {Society 5.0},\n year = {2018}\n}\n'}","[{'authorId': '47750549', 'name': 'Bruno Salgues'}]"
2136,b8cac158a294c11981b22db33ed554bc6a53c6dc,The cognitive control of emotion,,2005.0,85.0,3977.0,False,,"{'volume': '9', 'pages': '242-249', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Ochsner2005TheCC,\n author = {K. Ochsner and J. Gross},\n journal = {Trends in Cognitive Sciences},\n pages = {242-249},\n title = {The cognitive control of emotion},\n volume = {9},\n year = {2005}\n}\n'}","[{'authorId': '2669604', 'name': 'K. Ochsner'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
2137,b8e24b41333477da99eafef1882e96ae3194b86b,MEMO—A Mobile Phone Depression Prevention Intervention for Adolescents: Development Process and Postprogram Findings on Acceptability From a Randomized Controlled Trial,"Background Prevention of the onset of depression in adolescence may prevent social dysfunction, teenage pregnancy, substance abuse, suicide, and mental health conditions in adulthood. New technologies allow delivery of prevention programs scalable to large and disparate populations. Objective To develop and test the novel mobile phone delivery of a depression prevention intervention for adolescents. We describe the development of the intervention and the results of participants’ self-reported satisfaction with the intervention. Methods The intervention was developed from 15 key messages derived from cognitive behavioral therapy (CBT). The program was fully automated and delivered in 2 mobile phone messages/day for 9 weeks, with a mixture of text, video, and cartoon messages and a mobile website. Delivery modalities were guided by social cognitive theory and marketing principles. The intervention was compared with an attention control program of the same number and types of messages on different topics. A double-blind randomized controlled trial was undertaken in high schools in Auckland, New Zealand, from June 2009 to April 2011. Results A total of 1348 students (13–17 years of age) volunteered to participate at group sessions in schools, and 855 were eventually randomly assigned to groups. Of these, 835 (97.7%) self-completed follow-up questionnaires at postprogram interviews on satisfaction, perceived usefulness, and adherence to the intervention. Over three-quarters of participants viewed at least half of the messages and 90.7% (379/418) in the intervention group reported they would refer the program to a friend. Intervention group participants said the intervention helped them to be more positive (279/418, 66.7%) and to get rid of negative thoughts (210/418, 50.2%)—significantly higher than proportions in the control group. Conclusions Key messages from CBT can be delivered by mobile phone, and young people report that these are helpful. Change in clinician-rated depression symptom scores from baseline to 12 months, yet to be completed, will provide evidence on the effectiveness of the intervention. If proven effective, this form of delivery may be useful in many countries lacking widespread mental health services but with extensive mobile phone coverage. ClinicalTrial Australia New Zealand Clinical Trials Registry (ACTRN): 12609000405213; http://www.anzctr.org.au/trial_view.aspx?ID=83667 (Archived by WebCite at http://www.webcitation.org/64aueRqOb)",2012.0,41.0,160.0,True,"{'url': 'https://www.jmir.org/2012/1/e13/PDF', 'status': None}","{'volume': '14', 'name': 'Journal of Medical Internet Research'}","{'bibtex': '@Article{Whittaker2012MEMOAMP,\n author = {R. Whittaker and Sally Merry and K. Stasiak and H. McDowell and I. Doherty and M. Shepherd and Enid Dorey and V. Parag and S. Ameratunga and A. Rodgers},\n journal = {Journal of Medical Internet Research},\n title = {MEMO—A Mobile Phone Depression Prevention Intervention for Adolescents: Development Process and Postprogram Findings on Acceptability From a Randomized Controlled Trial},\n volume = {14},\n year = {2012}\n}\n'}","[{'authorId': '144640160', 'name': 'R. Whittaker'}, {'authorId': '2139727774', 'name': 'Sally Merry'}, {'authorId': '2915861', 'name': 'K. Stasiak'}, {'authorId': '48854350', 'name': 'H. McDowell'}, {'authorId': '31950894', 'name': 'I. Doherty'}, {'authorId': '144400049', 'name': 'M. Shepherd'}, {'authorId': '37344033', 'name': 'Enid Dorey'}, {'authorId': '4289651', 'name': 'V. Parag'}, {'authorId': '5172363', 'name': 'S. Ameratunga'}, {'authorId': '145188451', 'name': 'A. Rodgers'}]"
2138,b8e698e8a7d968f3dba9040e2f5fafe7e5a2b095,What are emotions? And how can they be measured?,"Defining “emotion” is a notorious problem. Without consensual conceptualization and operationalization of exactly what phenomenon is to be studied, progress in theory and research is difficult to achieve and fruitless debates are likely to proliferate. A particularly unfortunate example is William James’s asking the question “What is an emotion?” when he really meant “feeling”, a misnomer that started a debate which is still ongoing, more than a century later. This contribution attempts to sensitize researchers in the social and behavioral sciences to the importance of definitional issues and their consequences for distinguishing related but fundamentally different affective processes, states, and traits. Links between scientific and folk concepts of emotion are explored and ways to measure emotion and its components are discussed.",2005.0,93.0,3456.0,False,,"{'volume': '44', 'pages': '695 - 729', 'name': 'Social Science Information'}","{'bibtex': '@Article{Scherer2005WhatAE,\n author = {K. Scherer},\n journal = {Social Science Information},\n pages = {695 - 729},\n title = {What are emotions? And how can they be measured?},\n volume = {44},\n year = {2005}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}]"
2139,b8f7eb74b9b35215005fc8da64ef6d2dc31aaceb,East Asian Young and Older Adult Perceptions of Emotional Faces From an Age- and Sex-Fair East Asian Facial Expression Database,"There is increasing interest in clarifying how different face emotion expressions are perceived by people from different cultures, of different ages and sex. However, scant availability of well-controlled emotional face stimuli from non-Western populations limit the evaluation of cultural differences in face emotion perception and how this might be modulated by age and sex differences. We present a database of East Asian face expression stimuli, enacted by young and older, male and female, Taiwanese using the Facial Action Coding System (FACS). Combined with a prior database, this present database consists of 90 identities with happy, sad, angry, fearful, disgusted, surprised and neutral expressions amounting to 628 photographs. Twenty young and 24 older East Asian raters scored the photographs for intensities of multiple-dimensions of emotions and induced affect. Multivariate analyses characterized the dimensionality of perceived emotions and quantified effects of age and sex. We also applied commercial software to extract computer-based metrics of emotions in photographs. Taiwanese raters perceived happy faces as one category, sad, angry, and disgusted expressions as one category, and fearful and surprised expressions as one category. Younger females were more sensitive to face emotions than younger males. Whereas, older males showed reduced face emotion sensitivity, older female sensitivity was similar or accentuated relative to young females. Commercial software dissociated six emotions according to the FACS demonstrating that defining visual features were present. Our findings show that East Asians perceive a different dimensionality of emotions than Western-based definitions in face recognition software, regardless of age and sex. Critically, stimuli with detailed cultural norms are indispensable in interpreting neural and behavioral responses involving human facial expression processing. To this end, we add to the tools, which are available upon request, for conducting such research.",2018.0,95.0,13.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02358/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Tu2018EastAY,\n author = {Yu-Zhen Tu and Dong-Wei Lin and Atsunobu Suzuki and J. Goh},\n journal = {Frontiers in Psychology},\n title = {East Asian Young and Older Adult Perceptions of Emotional Faces From an Age- and Sex-Fair East Asian Facial Expression Database},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '121894317', 'name': 'Yu-Zhen Tu'}, {'authorId': '2116443919', 'name': 'Dong-Wei Lin'}, {'authorId': '3147469', 'name': 'Atsunobu Suzuki'}, {'authorId': '1739475', 'name': 'J. Goh'}]"
2140,b9138cc6eea1322f817e2e4f06cf204d0c212f9e,Problems in Output and the Cognitive Processes They Generate: A Step Towards Second Language Learning,"L'A. veut montrer que, dans la production de la L2, le fait de prendre conscience d'un probleme linguistique peut amener les apprenants a modifier leur production. Ce faisant, ils sont obliges d'utiliser un mode de traitement plus syntaxique, qui apparait dans la comprehension. Ce qu'il advient entre la production originale et la production finale modifiee par la prise en compte du probleme, fait partie du processus d'acquisition d'une L2",1995.0,29.0,1453.0,False,,"{'volume': '16', 'pages': '371-391', 'name': 'Applied Linguistics'}","{'bibtex': '@Article{Swain1995ProblemsIO,\n author = {M. Swain and Sharon Lapkin},\n journal = {Applied Linguistics},\n pages = {371-391},\n title = {Problems in Output and the Cognitive Processes They Generate: A Step Towards Second Language Learning},\n volume = {16},\n year = {1995}\n}\n'}","[{'authorId': '2027127', 'name': 'M. Swain'}, {'authorId': '5965726', 'name': 'Sharon Lapkin'}]"
2141,b91db89ddd3a42918403aeb80788be682d24a3a8,Humans versus Computers: Impact of Emotion Expressions on People's Decision Making,"Recent research in perception and theory of mind reveals that people show different behavior and lower activation of brain regions associated with mentalizing (i.e., the inference of other's mental states) when engaged in decision making with computers, when compared to humans. These findings are important for affective computing because they suggest people's decisions might be influenced differently according to whether they believe emotional expressions shown in computers are being generated by algorithms or humans. To test this, we had people engage in a social dilemma (Experiment 1) or negotiation (Experiment 2) with virtual humans that were either perceived to be agents (i.e., controlled by computers) or avatars (i.e., controlled by humans). The results showed that such perceptions have a deep impact on people's decisions: in Experiment 1, people cooperated more with virtual humans that showed cooperative facial displays (e.g., joy after mutual cooperation) than competitive displays (e.g., joy when the participant was exploited) but, the effect was stronger with avatars (d = .601) than with agents (d = .360); in Experiment 2, people conceded more to angry than neutral virtual humans but, again, the effect was much stronger with avatars (d = 1.162) than with agents (d = .066). Participants also showed less anger towards avatars and formed more positive impressions of avatars when compared to agents.",2015.0,75.0,63.0,True,,"{'volume': '6', 'pages': '127-136', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': ""@Article{Melo2015HumansVC,\n author = {C. D. Melo and J. Gratch and P. Carnevale},\n journal = {IEEE Transactions on Affective Computing},\n pages = {127-136},\n title = {Humans versus Computers: Impact of Emotion Expressions on People's Decision Making},\n volume = {6},\n year = {2015}\n}\n""}","[{'authorId': '1977901', 'name': 'C. D. Melo'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '48755211', 'name': 'P. Carnevale'}]"
2142,b92e09bbe6e176e07a995a0aee510ddc3961ce04,Language from the Body: Iconicity and Metaphor in American Sign Language,1. A glimpse of the material 2. Motivation and linguistic theory 3. Iconicity defined and demonstrated 4. The analogue-building model of linguistic iconicity 5. Survey of iconicity in signed and spoken languages 6. Metaphor in American Sign Language: the double mapping 7. Many metaphors in a single sign 8. The vertical scale as source domain 9. Verb agreement paths in American Sign Language 10. Complex superposition of metaphors in an American Sign Language poem 11. The future of signed-language research Appendices References Index.,2001.0,0.0,469.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Taub2001LanguageFT,\n author = {S. Taub},\n title = {Language from the Body: Iconicity and Metaphor in American Sign Language},\n year = {2001}\n}\n'}","[{'authorId': '34649792', 'name': 'S. Taub'}]"
2143,b95b9c94864db735fcac1cd0aad2f335feaf2eb1,The Influence of Virtual Agents' Gender and Rapport on Enhancing Math Performance,"The Influence of Virtual Agents’ Gender and Rapport on Enhancing Math Performance Bilge Karacora 1 (bilge.karacora@stud.uni-due.de), Morteza Dehghani 2 (morteza@ict.usc.edu), Nicole Kramer-Mertens 1 (nicole.kraemer@uni-due.de), Jonathan Gratch 2 (gratch@ict.usc.edu) Department of Social Psychology, University of Duisburg-Essen, Forsthausweg 2, 47057 Duisburg, Germany Institute for Creative Technologies, University of Southern California, 12015 Waterfront Dr., Playa Vista, CA 90094-2536, USA Rapport has been shown as an effective way to create behavioral realism in virtual agents. In social psychology, rapport is described as the establishment of a positive relationship among interaction partners by rapidly detecting and responding to each other’s nonverbal behavior (Gratch et al., 2007a). This includes displaying behaviors that indicate positive emotions (such as head nods and smiles), showing mutual attentiveness (such as mutual gaze) and certain coordination behaviors (such as postural mimicry and synchronized movement) (Tickle-Degnan & Rosenthal, 1990). Niewiadomski et al. (2010) reports that when an agent displays appropriate and socially adapted emotional expressions, he is perceived as more human-like than an agent that shows human expressions which are inappropriate or not socially adapted. Garau et al. (2005) conducted a study showing that only participants who interacted with an agent that was responsive to their movements, experienced a sense of personal contact with the agent which influenced them to behave more socially considerate as opposed to interacting with a static or moving but unresponsive agent. This indicates that rapport is an important feature in order for the agent to be perceived as human-like and for any social effects, such as social facilitation, to occur. Previous research on social facilitation/inhibition illustrates how the presence of others affects an individuals’ task performance either positively or negatively (Guerin & Innes, 1982; Zanjonc, 1965; Sanders, Baron & Moore, 1978). Whether or not similar facilitation/inhibition effects occur in presence of virtual agents has been subject to several studies. Rickenberg and Reeves (2000) found that tasks are facilitated or inhibited by the “social” presence of a virtual agent. A study by Zanbaka et al. (2004) indicates that when asked to perform a task, participants reacted similarly to the presence of a virtual agent as they would have in the presence of another human. A follow-up study by Zanbaka et al. (2007) demonstrates that the presence of a virtual agent inhibits the performance of participants on a mathematical task. The limitation of this study was that the sample consisted of only female participants being confronted with an agent of matching gender. Hayes et al. (2010) found a similar decrease in performance with regard Abstract The purpose of the present research is to investigate whether virtual agents can help enhance participants’ performance, effort and motivation in mathematics. We hypothesize that a minimal amount behavioral realism induced by display of rapport is necessary for any social effects to occur in human- computer interaction. Further, we examine whether social facilitation effects occur depending on the gender of the participants and the interacting virtual agents. In a 2x2 between subjects design, participants interacted with a male or female virtual agent that either displayed rapport or no rapport. Our results confirm that gender plays a role when interacting with virtual agents that are capable of establishing rapport. Participants’ performance and effort were significantly enhanced when interacting with an agent of opposite gender that displayed rapport . Our results have implications on designing agents for education and training purposes. Keywords: social facilitation, STEM, rapport, virtual agents Introduction There is considerable interest in factors that enhance science and math performance. Recently, there has been an upsurge of interest in educational technology that exploits social and motivational factors that enhance math performance in general, and reduce gender inequality in particular (Kim, 2004; Baylor & Ryu, 2003). This work builds on the phenomena that people often treat computers as social actors. Therefore, psychological factors that improve people's performance in traditional face-to-face settings can be simulated by technologies in form of virtual learning companions or virtual instructors. In this paper, we seek to address two related goals. First, we aim to show that certain social psychological phenomena can enhance math performance in a human-computer setting. Specifically, we show that a form of social facilitation can improve performance on standardized math tests. Second, we seek to provide further evidence that people do treat computers as social actors and help elucidate the design principles that foster this effect. We specifically demonstrate that virtual agents must possess a minimum level of behavioral realism to achieve any social effects.",2012.0,22.0,21.0,False,,"{'volume': '34', 'name': 'Cognitive Science'}","{'bibtex': ""@Article{Karacora2012TheIO,\n author = {Bilge Karacora and Morteza Dehghani and Nicole Krämer-Mertens and J. Gratch},\n journal = {Cognitive Science},\n title = {The Influence of Virtual Agents' Gender and Rapport on Enhancing Math Performance},\n volume = {34},\n year = {2012}\n}\n""}","[{'authorId': '3364569', 'name': 'Bilge Karacora'}, {'authorId': '145707560', 'name': 'Morteza Dehghani'}, {'authorId': '1455003730', 'name': 'Nicole Krämer-Mertens'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2144,b9615876001c4312db057d7a1b13abb823cfdcfd,Patient adherence to medical treatment: a review of reviews,,2007.0,74.0,594.0,True,"{'url': 'https://bmchealthservres.biomedcentral.com/counter/pdf/10.1186/1472-6963-7-55', 'status': None}","{'volume': '7', 'pages': '55 - 55', 'name': 'BMC Health Services Research'}","{'bibtex': '@Article{Dulmen2007PatientAT,\n author = {S. van Dulmen and E. Sluijs and L. van Dijk and D. D. de Ridder and Rob Heerdink and J. Bensing},\n journal = {BMC Health Services Research},\n pages = {55 - 55},\n title = {Patient adherence to medical treatment: a review of reviews},\n volume = {7},\n year = {2007}\n}\n'}","[{'authorId': '3678586', 'name': 'S. van Dulmen'}, {'authorId': '2076676278', 'name': 'E. Sluijs'}, {'authorId': '88346223', 'name': 'L. van Dijk'}, {'authorId': '145100156', 'name': 'D. D. de Ridder'}, {'authorId': '4047732', 'name': 'Rob Heerdink'}, {'authorId': '3703011', 'name': 'J. Bensing'}]"
2145,b989c68b9a6f8bb1bb849cdc7594427d47720c85,The SEMAINE API: Towards a Standards-Based Framework for Building Emotion-Oriented Systems,"This paper presents the SEMAINE API, an open source framework for building emotion-oriented systems. By encouraging and simplifying the use of standard representation formats, the framework aims to contribute to interoperability and reuse of system components in the research community. By providing a Java and C++ wrapper around a message-oriented middleware, the API makes it easy to integrate components running on different operating systems and written in different programming languages. The SEMAINE system 1.0 is presented as an example of a full-scale system built on top of the SEMAINE API. Three small example systems are described in detail to illustrate how integration between existing and new components is realised with minimal effort.",2010.0,66.0,124.0,True,"{'url': 'https://downloads.hindawi.com/journals/ahci/2010/319406.pdf', 'status': None}","{'volume': '2010', 'pages': '319406:1-319406:21', 'name': 'Adv. Hum. Comput. Interact.'}","{'bibtex': '@Article{Schröder2010TheSA,\n author = {M. Schröder},\n journal = {Adv. Hum. Comput. Interact.},\n pages = {319406:1-319406:21},\n title = {The SEMAINE API: Towards a Standards-Based Framework for Building Emotion-Oriented Systems},\n volume = {2010},\n year = {2010}\n}\n'}","[{'authorId': '144951065', 'name': 'M. Schröder'}]"
2146,b9935d15008ca27ea17bda27764b769bb3c04588,"The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places [Book Review]",,1997.0,0.0,345.0,False,,"{'volume': '34', 'pages': '9-10', 'name': 'IEEE Spectrum'}","{'bibtex': '@Article{Martin1997TheME,\n author = {C.D. Martin},\n journal = {IEEE Spectrum},\n pages = {9-10},\n title = {The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places [Book Review]},\n volume = {34},\n year = {1997}\n}\n'}","[{'authorId': '30758386', 'name': 'C.D. Martin'}]"
2147,b9a6985d2a0fcd988b2538c89c95ad19ccd67a66,"From game design elements to gamefulness: defining ""gamification""","Recent years have seen a rapid proliferation of mass-market consumer software that takes inspiration from video games. Usually summarized as ""gamification"", this trend connects to a sizeable body of existing concepts and research in human-computer interaction and game studies, such as serious games, pervasive games, alternate reality games, or playful design. However, it is not clear how ""gamification"" relates to these, whether it denotes a novel phenomenon, and how to define it. Thus, in this paper we investigate ""gamification"" and the historical origins of the term in relation to precursors and similar concepts. It is suggested that ""gamified"" applications provide insight into novel, gameful phenomena complementary to playful phenomena. Based on our research, we propose a definition of ""gamification"" as the use of game design elements in non-game contexts.",2011.0,79.0,6365.0,False,,{'pages': '9-15'},"{'bibtex': '@Inproceedings{Deterding2011FromGD,\n author = {Sebastian Deterding and Dan Dixon and Rilla Khaled and L. Nacke},\n pages = {9-15},\n title = {From game design elements to gamefulness: defining ""gamification""},\n year = {2011}\n}\n'}","[{'authorId': '2127156', 'name': 'Sebastian Deterding'}, {'authorId': '49978761', 'name': 'Dan Dixon'}, {'authorId': '1711689', 'name': 'Rilla Khaled'}, {'authorId': '1953205', 'name': 'L. Nacke'}]"
2148,b9cd58409bb62aeb7d99e0bffd32492ea01f7541,Cultural Variance in the Interpersonal Effects of Anger in Negotiations,"The current research is the first investigation of how the effects of expressing discrete emotions in negotiations vary across cultures. In a hypothetical negotiation scenario (Study 1) and a computer-mediated negotiation simulation (Study 2), expressing anger (relative to not expressing anger) elicited larger concessions from European American negotiators, but smaller concessions from Asian and Asian American negotiators. A third study provided evidence that this effect is due to different cultural norms about the appropriateness of anger expressions in negotiations: When we explicitly manipulated anger expressions to be appropriate, Asian and Asian American negotiators made larger concessions to the angry opponent, and their concessions were as large as was typical for European American negotiators; when we explicitly manipulated anger expressions to be inappropriate, European American negotiators made smaller concessions to the angry opponent, and their concessions were as small as was typical for Asian and Asian American negotiators. Implications for current understanding of culture, emotions, and negotiations are discussed.",2010.0,44.0,116.0,False,,"{'volume': '21', 'pages': '882 - 889', 'name': 'Psychological Science'}","{'bibtex': '@Article{Adam2010CulturalVI,\n author = {Hajo Adam and Aiwa Shirako and William W Maddux},\n journal = {Psychological Science},\n pages = {882 - 889},\n title = {Cultural Variance in the Interpersonal Effects of Anger in Negotiations},\n volume = {21},\n year = {2010}\n}\n'}","[{'authorId': '3826921', 'name': 'Hajo Adam'}, {'authorId': '5732160', 'name': 'Aiwa Shirako'}, {'authorId': '5989771', 'name': 'William W Maddux'}]"
2149,b9d245563e5bca974b39b36730cc8431e0e130d2,Analysis and Predictive Modeling of Body Language Behavior in Dyadic Interactions From Multimodal Interlocutor Cues,"During dyadic interactions, participants adjust their behavior and give feedback continuously in response to the behavior of their interlocutors and the interaction context. In this paper, we study how a participant in a dyadic interaction adapts his/her body language to the behavior of the interlocutor, given the interaction goals and context. We apply a variety of psychology-inspired body language features to describe body motion and posture. We first examine the coordination between the dyad's behavior for two interaction stances: friendly and conflictive. The analysis empirically reveals the dyad's behavior coordination, and helps identify informative interlocutor features with respect to the participant's target body language features. The coordination patterns between the dyad's behavior are found to depend on the interaction stances assumed. We apply a Gaussian-Mixture-Model-based (GMM) statistical mapping in combination with a Fisher kernel framework for automatically predicting the body language of an interacting participant from the speech and gesture behavior of an interlocutor. The experimental results show that the Fisher kernel-based approach outperforms methods using only the GMM-based mapping, and using the support vector regression, in terms of correlation coefficient and RMSE. These results suggest a significant level of predictability of body language behavior from interlocutor cues.",2014.0,54.0,30.0,False,,"{'volume': '16', 'pages': '1766-1778', 'name': 'IEEE Transactions on Multimedia'}","{'bibtex': '@Article{Yang2014AnalysisAP,\n author = {Zhaojun Yang and A. Metallinou and Shrikanth S. Narayanan},\n journal = {IEEE Transactions on Multimedia},\n pages = {1766-1778},\n title = {Analysis and Predictive Modeling of Body Language Behavior in Dyadic Interactions From Multimodal Interlocutor Cues},\n volume = {16},\n year = {2014}\n}\n'}","[{'authorId': '3161887', 'name': 'Zhaojun Yang'}, {'authorId': '47851995', 'name': 'A. Metallinou'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
2150,b9d25e86ea5ede85bff1633618843b9226a2d919,Designing Relational Agents as Long Term Social Companions for Older Adults,,2012.0,27.0,150.0,True,"{'url': 'http://relationalagents.com/publications/IVA12.woz.pdf', 'status': None}",{'pages': '289-302'},"{'bibtex': '@Inproceedings{Vardoulakis2012DesigningRA,\n author = {L. Vardoulakis and Lazlo Ring and Barbara Barry and C. Sidner and T. Bickmore},\n pages = {289-302},\n title = {Designing Relational Agents as Long Term Social Companions for Older Adults},\n year = {2012}\n}\n'}","[{'authorId': '1787101', 'name': 'L. Vardoulakis'}, {'authorId': '2880118', 'name': 'Lazlo Ring'}, {'authorId': '150931679', 'name': 'Barbara Barry'}, {'authorId': '2668280', 'name': 'C. Sidner'}, {'authorId': '1690448', 'name': 'T. Bickmore'}]"
2152,b9e3ec64ace1c69e161a878d4272342e3db71f16,Generating Robotic Speech Prosody for Human Robot Interaction: A Preliminary Study,"The use of affective speech in robotic applications has increased in recent years, especially regarding the developments or studies of emotional prosody for a specific group of people. The current work proposes a prosody-based communication system that considers the limited parameters found in speech recognition for the elderly, for example. This work explored what types of voices were more effective for understanding presented information, and if the affects of robot voices reflected on the emotional states of listeners. By using functions of a small humanoid robot, two different experiments conducted to find out comprehension level and the affective reflection respectively. University students participated in both tests. The results showed that affective voices helped the users understand the information, as well as that they felt corresponding negative emotions in conversations with negative voices.",2021.0,45.0,6.0,True,"{'url': 'https://www.mdpi.com/2076-3417/11/8/3468/pdf?version=1618299621', 'status': None}","{'volume': '11', 'pages': '3468', 'name': 'Applied Sciences'}","{'bibtex': '@Article{Lee2021GeneratingRS,\n author = {Jaeryoung Lee},\n journal = {Applied Sciences},\n pages = {3468},\n title = {Generating Robotic Speech Prosody for Human Robot Interaction: A Preliminary Study},\n volume = {11},\n year = {2021}\n}\n'}","[{'authorId': '77537854', 'name': 'Jaeryoung Lee'}]"
2153,ba0f61a54fd4fc3aa3e0654e823719d21c0f2e89,Development of an empathy scale.,"The concept of empathy—the intellectual or imaginative apprehension of another's condition or state of mind— is central for understanding a broad range of social phenomena including, in particular, moral development. Within this latter context, an empathic disposition can be regarded as the capacity to adopt a broad moral perspective, that is, to take ""the moral point of view."" This paper discusses the development of a 64-item self-report measure of empathy, constructed by comparing the responses of groups with high- and low-rated empathy, using the combined MMPI-CPI item pool. After providing evidence concerning the scale's reliability and validity, an attempt is made to show its relevance for specifically moral conduct by relating empathy scale scores to real life indexes of socially appropriate behavior and to certain previously wellvalidated measures of personality. Some form of empathic disposition, roletaking ability, or social sensitivity is assumed by all approaches to personality which take the interpersonal situation as a major focus of concern. Accordingly, most writers in the role-theoretical tradition (Cottrell, 1942; Gough, 1948; Mead, 1934; Sarbin, 1968) have given careful attention to this aspect of social functioning. Mead, for example, has argued that role-taking ability is the key variable in social and moral development; extending this line of reasoning he equates the ""g"" factor in intelligence with social sensitivity, the origins of which can be found in the central nervous system. In a similar vein, Cottrell and Dymond (1949) also maintained that empathy is the basic process in all social interaction. Empathy, seen as an everyday manifestation of the disposition to adopt a broad moral",1969.0,23.0,1405.0,False,,"{'volume': '33 3', 'pages': '\n          307-16\n        ', 'name': 'Journal of consulting and clinical psychology'}","{'bibtex': '@Article{Hogan1969DevelopmentOA,\n author = {R. Hogan},\n journal = {Journal of consulting and clinical psychology},\n pages = {\n          307-16\n        },\n title = {Development of an empathy scale.},\n volume = {33 3},\n year = {1969}\n}\n'}","[{'authorId': '143977043', 'name': 'R. Hogan'}]"
2154,ba2e73a3f5f717ba36cb44fd572c2248cf169aee,Human Emotions: A Sociological Theory,"1. Human Emotions 2. Why did Humans Become so Emotional? 3. Social Structure, Culture, and Emotions 4. Emotional Arousal: Basic Principles 5. Transactional Needs and Emotional Arousal 6. Social Structure and Emotional Arousal 7. Culture and Emotional Arousal 8. Emotions and Social Change 9. The Theory Reviewed",2007.0,117.0,772.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Turner2007HumanEA,\n author = {J. Turner},\n title = {Human Emotions: A Sociological Theory},\n year = {2007}\n}\n'}","[{'authorId': '118688586', 'name': 'J. Turner'}]"
2155,ba30358d8eb578e12024ec1c62e2dcdd0273b0b6,A head-eye coordination model for animating gaze shifts of virtual characters,"We present a parametric, computational model of head-eye coordination that can be used in the animation of directed gaze shifts for virtual characters. The model is based on research in human neurophysiology. It incorporates control parameters that allow for adapting gaze shifts to the characteristics of the environment, the gaze targets, and the idiosyncratic behavioral attributes of the virtual character. A user study confirms that the model communicates gaze targets as effectively as real humans do, while being preferred subjectively to state-of-the-art models.",2012.0,24.0,23.0,False,,{'pages': '4:1-4:6'},"{'bibtex': '@Inproceedings{Andrist2012AHC,\n author = {Sean Andrist and T. Pejsa and Bilge Mutlu and Michael Gleicher},\n pages = {4:1-4:6},\n title = {A head-eye coordination model for animating gaze shifts of virtual characters},\n year = {2012}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '2633572', 'name': 'T. Pejsa'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}]"
2156,ba364694e7cc582ecd0134991e791492a98bffba,Psychological Foundations of Trust,"Trust lies at the foundation of nearly all major theories of interpersonal relationships. Despite its great theoretical importance, a limited amount of research has examined how and why trust develops, is maintained, and occasionally unravels in relationships. Following a brief overview of theoretical and empirical milestones in the interpersonal-trust literature, an integrative process model of trust in dyadic relationships is presented.",2007.0,21.0,431.0,False,,"{'volume': '16', 'pages': '264 - 268', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Simpson2007PsychologicalFO,\n author = {J. Simpson},\n journal = {Current Directions in Psychological Science},\n pages = {264 - 268},\n title = {Psychological Foundations of Trust},\n volume = {16},\n year = {2007}\n}\n'}","[{'authorId': '144652931', 'name': 'J. Simpson'}]"
2157,ba502e59fb58310a3e8f8889f02ed9e782e27c75,Facial emotional classification: from a discrete perspective to a continuous emotional space,,2013.0,44.0,25.0,False,,"{'volume': '16', 'pages': '41-54', 'name': 'Pattern Analysis and Applications'}","{'bibtex': '@Article{Hupont2013FacialEC,\n author = {I. Hupont and S. Baldassarri and E. Cerezo},\n journal = {Pattern Analysis and Applications},\n pages = {41-54},\n title = {Facial emotional classification: from a discrete perspective to a continuous emotional space},\n volume = {16},\n year = {2013}\n}\n'}","[{'authorId': '2321433', 'name': 'I. Hupont'}, {'authorId': '1787072', 'name': 'S. Baldassarri'}, {'authorId': '144046205', 'name': 'E. Cerezo'}]"
2158,ba69e1f3bc5cf8f0973d87e348ff9dfba18b7ea8,A Review on Automatic Facial Expression Recognition Systems Assisted by Multimodal Sensor Data,"Facial Expression Recognition (FER) can be widely applied to various research areas, such as mental diseases diagnosis and human social/physiological interaction detection. With the emerging advanced technologies in hardware and sensors, FER systems have been developed to support real-world application scenes, instead of laboratory environments. Although the laboratory-controlled FER systems achieve very high accuracy, around 97%, the technical transferring from the laboratory to real-world applications faces a great barrier of very low accuracy, approximately 50%. In this survey, we comprehensively discuss three significant challenges in the unconstrained real-world environments, such as illumination variation, head pose, and subject-dependence, which may not be resolved by only analysing images/videos in the FER system. We focus on those sensors that may provide extra information and help the FER systems to detect emotion in both static images and video sequences. We introduce three categories of sensors that may help improve the accuracy and reliability of an expression recognition system by tackling the challenges mentioned above in pure image/video processing. The first group is detailed-face sensors, which detect a small dynamic change of a face component, such as eye-trackers, which may help differentiate the background noise and the feature of faces. The second is non-visual sensors, such as audio, depth, and EEG sensors, which provide extra information in addition to visual dimension and improve the recognition reliability for example in illumination variation and position shift situation. The last is target-focused sensors, such as infrared thermal sensors, which can facilitate the FER systems to filter useless visual contents and may help resist illumination variation. Also, we discuss the methods of fusing different inputs obtained from multimodal sensors in an emotion system. We comparatively review the most prominent multimodal emotional expression recognition approaches and point out their advantages and limitations. We briefly introduce the benchmark data sets related to FER systems for each category of sensors and extend our survey to the open challenges and issues. Meanwhile, we design a framework of an expression recognition system, which uses multimodal sensor data (provided by the three categories of sensors) to provide complete information about emotions to assist the pure face image/video analysis. We theoretically analyse the feasibility and achievability of our new expression recognition system, especially for the use in the wild environment, and point out the future directions to design an efficient, emotional expression recognition system.",2019.0,128.0,121.0,True,"{'url': 'https://www.mdpi.com/1424-8220/19/8/1863/pdf?version=1556181562', 'status': None}","{'volume': '19', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Samadiani2019ARO,\n author = {N. Samadiani and Guangyan Huang and Borui Cai and Wei Luo and Chi-Hung Chi and Yong Xiang and Jing He},\n journal = {Sensors (Basel, Switzerland)},\n title = {A Review on Automatic Facial Expression Recognition Systems Assisted by Multimodal Sensor Data},\n volume = {19},\n year = {2019}\n}\n'}","[{'authorId': '30455934', 'name': 'N. Samadiani'}, {'authorId': '2074183', 'name': 'Guangyan Huang'}, {'authorId': '8811761', 'name': 'Borui Cai'}, {'authorId': '145951567', 'name': 'Wei Luo'}, {'authorId': '36452710', 'name': 'Chi-Hung Chi'}, {'authorId': '2068338805', 'name': 'Yong Xiang'}, {'authorId': '40446561', 'name': 'Jing He'}]"
2159,ba8459c5fa5be65cf1a520bd2d00e72592c71607,Towards Understanding Emotional Intelligence for Behavior Change Chatbots,"A natural conversational interface that allows longitudinal symptom tracking would be extremely valuable in health/wellness applications. However, the task of designing emotionally-aware agents for behavior change is still poorly understood. In this paper, we present the design and evaluation of an emotion-aware chatbot that conducts experience sampling in an empathetic manner. We evaluate it through a human-subject experiment with N=39 participants over the course of a week. Our results show that extraverts preferred the emotion-aware chatbot significantly more than introverts. Also, participants reported a higher percentage of positive mood reports when interacting with the empathetic bot. Finally, we provide guidelines for the design of emotion-aware chatbots for potential use in mHealth contexts.",2019.0,32.0,34.0,True,"{'url': 'https://arxiv.org/pdf/1907.10664', 'status': None}","{'pages': '8-14', 'name': '2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)'}","{'bibtex': '@Article{Ghandeharioun2019TowardsUE,\n author = {Asma Ghandeharioun and Daniel J. McDuff and M. Czerwinski and Kael Rowan},\n journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {8-14},\n title = {Towards Understanding Emotional Intelligence for Behavior Change Chatbots},\n year = {2019}\n}\n'}","[{'authorId': '2214185', 'name': 'Asma Ghandeharioun'}, {'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '1817251', 'name': 'M. Czerwinski'}, {'authorId': '36516124', 'name': 'Kael Rowan'}]"
2160,bada4e9dca0b3b63c8087deba3cf0356b8eea8a5,Emotions are expressed more intensely on the left side of the face.,"Pictures of human faces posing six distinct emotions (plus a neutral expression) and their mirror reversals were split down the midlines, and left-side and right-side composites were constructed. Subjects judged left-side composites as expressing emotions more intensely than right-side composites. The finding indicates hemispheric asymmetry in the control over emotional expression in the face.",1978.0,27.0,487.0,False,,"{'volume': '202 4366', 'pages': '\n          434-6\n        ', 'name': 'Science'}","{'bibtex': '@Article{Sackeim1978EmotionsAE,\n author = {H. Sackeim and R. Gur and M. C. Saucy},\n journal = {Science},\n pages = {\n          434-6\n        },\n title = {Emotions are expressed more intensely on the left side of the face.},\n volume = {202 4366},\n year = {1978}\n}\n'}","[{'authorId': '1788596', 'name': 'H. Sackeim'}, {'authorId': '144762538', 'name': 'R. Gur'}, {'authorId': '4415944', 'name': 'M. C. Saucy'}]"
2161,baedd244794e35e11712ba2241f64b9eec27e7e3,Emotions Recognition Using EEG Signals: A Survey,"Emotions have an important role in daily life, not only in human interaction, but also in decision-making processes, and in the perception of the world around us. Due to the recent interest shown by the research community in establishing emotional interactions between humans and computers, the identification of the emotional state of the former became a need. This can be achieved through multiple measures, such as subjective self-reports, autonomic and neurophysiological measurements. In the last years, Electroencephalography (EEG) received considerable attention from researchers, since it can provide a simple, cheap, portable, and ease-to-use solution for identifying emotions. In this paper, we present a survey of the neurophysiological research performed from 2009 to 2016, providing a comprehensive overview of the existing works in emotion recognition using EEG signals. We focus our analysis in the main aspects involved in the recognition process (e.g., subjects, features extracted, classifiers), and compare the works per them. From this analysis, we propose a set of good practice recommendations that researchers must follow to achieve reproducible, replicable, well-validated and high-quality results. We intend this survey to be useful for the research community working on emotion recognition through EEG signals, and in particular for those entering this field of research, since it offers a structured starting point.",2019.0,143.0,580.0,False,,"{'volume': '10', 'pages': '374-393', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Alarcão2019EmotionsRU,\n author = {Soraia M. Alarcão and M. J. Fonseca},\n journal = {IEEE Transactions on Affective Computing},\n pages = {374-393},\n title = {Emotions Recognition Using EEG Signals: A Survey},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '30485106', 'name': 'Soraia M. Alarcão'}, {'authorId': '2057537695', 'name': 'M. J. Fonseca'}]"
2162,baf65f9a9ca292d8115333a873d9e05ae2d4e6a3,Empathy: A Review of the Concept,"The inconsistent definition of empathy has had a negative impact on both research and practice. The aim of this article is to review and critically appraise a range of definitions of empathy and, through considered analysis, to develop a new conceptualisation. From the examination of 43 discrete definitions, 8 themes relating to the nature of empathy emerged: “distinguishing empathy from other concepts”; “cognitive or affective?”; “congruent or incongruent?”; “subject to other stimuli?”; “self/other distinction or merging?”; “trait or state influences?”; “has a behavioural outcome?”; and “automatic or controlled?” The relevance and validity of each theme is assessed and a new conceptualisation of empathy is offered. The benefits of employing a more consistent and complete definition of empathy are discussed.",2016.0,111.0,703.0,True,"{'url': 'http://nectar.northampton.ac.uk/17038/1/Cuff_etal_ER_2014_Empathy_a_review_of_the_concept.pdf', 'status': None}","{'volume': '8', 'pages': '144 - 153', 'name': 'Emotion Review'}","{'bibtex': '@Article{Cuff2016EmpathyAR,\n author = {B. Cuff and Sarah D. Brown and Laura K. Taylor and D. Howat},\n journal = {Emotion Review},\n pages = {144 - 153},\n title = {Empathy: A Review of the Concept},\n volume = {8},\n year = {2016}\n}\n'}","[{'authorId': '117787690', 'name': 'B. Cuff'}, {'authorId': '28835463', 'name': 'Sarah D. Brown'}, {'authorId': '3795722', 'name': 'Laura K. Taylor'}, {'authorId': '34906389', 'name': 'D. Howat'}]"
2163,baf822e8e772853e88170a37f1c3d32018adf7f1,The Emerging Field of Emotion Regulation: An Integrative Review,"The emerging field of emotion regulation studies how individuals influence which emotions they have, when they have them, and how they experience and express them. This review takes an evolutionary perspective and characterizes emotion in terms of response tendencies. Emotion regulation is defined and distinguished from coping, mood regulation, defense, and affect regulation. In the increasingly specialized discipline of psychology, the field of emotion regulation cuts across traditional boundaries and provides common ground. According to a process model of emotion regulation, emotion may be regulated at five points in the emotion generative process: (a) selection of the situation, (b) modification of the situation, (c) deployment of attention, (d) change of cognitions, and (e) modulation of responses. The field of emotion regulation promises new insights into age-old questions about how people manage their emotions.",1998.0,382.0,7258.0,False,,"{'volume': '2', 'pages': '271 - 299', 'name': 'Review of General Psychology'}","{'bibtex': '@Article{Gross1998TheEF,\n author = {J. Gross},\n journal = {Review of General Psychology},\n pages = {271 - 299},\n title = {The Emerging Field of Emotion Regulation: An Integrative Review},\n volume = {2},\n year = {1998}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}]"
2165,baf9e0badb6576f2bae6f1e03d6e04c652e9b94b,"Disturbed dreaming, posttraumatic stress disorder, and affect distress: a review and neurocognitive model.","Nightmares are common, occurring weekly in 4%-10% of the population, and are associated with female gender, younger age, increased stress, psychopathology, and dispositional traits. Nightmare pathogenesis remains unexplained, as do differences between nontraumatic and posttraumatic nightmares (for those with or without posttraumatic stress disorder) and relations with waking functioning. No models adequately explain nightmares nor have they been reconciled with recent developments in cognitive neuroscience, fear acquisition, and emotional memory. The authors review the recent literature and propose a conceptual framework for understanding a spectrum of dysphoric dreaming. Central to this is the notion that variations in nightmare prevalence, frequency, severity, and psychopathological comorbidity reflect the influence of both affect load, a consequence of daily variations in emotional pressure, and affect distress, a disposition to experience events with distressing, highly reactive emotions. In a cross-state, multilevel model of dream function and nightmare production, the authors integrate findings on emotional memory structures and the brain correlates of emotion.",2007.0,566.0,487.0,False,,"{'volume': '133 3', 'pages': '\n          482-528\n        ', 'name': 'Psychological bulletin'}","{'bibtex': '@Article{Levin2007DisturbedDP,\n author = {R. Levin and T. Nielsen},\n journal = {Psychological bulletin},\n pages = {\n          482-528\n        },\n title = {Disturbed dreaming, posttraumatic stress disorder, and affect distress: a review and neurocognitive model.},\n volume = {133 3},\n year = {2007}\n}\n'}","[{'authorId': '117883465', 'name': 'R. Levin'}, {'authorId': '144235536', 'name': 'T. Nielsen'}]"
2166,bafdff07880b4420e365bd23a003ccade3d4ccfa,A Storytelling Robot: Modeling and Evaluation of Human-like Gaze Behavior,"Engaging storytelling is a necessary skill for humanoid robots if they are to be used in education and entertainment applications. Storytelling requires that the humanoid robot be aware of its audience and able to direct its gaze in a natural way. In this paper, we explore how human gaze can be modeled and implemented on a humanoid robot to create a natural, human-like behavior for storytelling. Our gaze model integrates data collected from a human storyteller and a discourse structure model developed by Cassell and her colleagues for human-like conversational agents (1994). We used this model to direct the gaze of a humanoid robot, Honda's ASIMO, as he recited a Japanese fairy tale using a pre-recorded human voice. We assessed the efficacy of this gaze algorithm by manipulating the frequency of ASIMO's gaze between two participants and used pre and post questionnaires to assess whether participants evaluated the robot more positively and did better on a recall task when ASIMO looked at them more. We found that participants performed significantly better in recalling ASIMO's story when the robot looked at them more. Our results also showed significant differences in how men and women evaluated ASIMO based on the frequency of gaze they received from the robot. Our study adds to the growing evidence that there are many commonalities between human-human communication and human-robot communication",2006.0,34.0,367.0,False,,"{'pages': '518-523', 'name': '2006 6th IEEE-RAS International Conference on Humanoid Robots'}","{'bibtex': '@Article{Mutlu2006ASR,\n author = {Bilge Mutlu and J. Forlizzi and J. Hodgins},\n journal = {2006 6th IEEE-RAS International Conference on Humanoid Robots},\n pages = {518-523},\n title = {A Storytelling Robot: Modeling and Evaluation of Human-like Gaze Behavior},\n year = {2006}\n}\n'}","[{'authorId': '145656551', 'name': 'Bilge Mutlu'}, {'authorId': '145174228', 'name': 'J. Forlizzi'}, {'authorId': '1788773', 'name': 'J. Hodgins'}]"
2167,bb01a43c2fc553582e3c34ed5fc249670c849dd8,Establishing and maintaining long-term human-computer relationships,"This research investigates the meaning of “human-computer relationship” and presents techniques for constructing, maintaining, and evaluating such relationships, based on research in social psychology, sociolinguistics, communication and other social sciences. Contexts in which relationships are particularly important are described, together with specific benefits (like trust) and task outcomes (like improved learning) known to be associated with relationship quality. We especially consider the problem of designing for long-term interaction, and define relational agents as computational artifacts designed to establish and maintain long-term social-emotional relationships with their users. We construct the first such agent, and evaluate it in a controlled experiment with 101 users who were asked to interact daily with an exercise adoption system for a month. Compared to an equivalent task-oriented agent without any deliberate social-emotional or relationship-building skills, the relational agent was respected more, liked more, and trusted more, even after four weeks of interaction. Additionally, users expressed a significantly greater desire to continue working with the relational agent after the termination of the study. We conclude by discussing future directions for this research together with ethical and other ramifications of this work for HCI designers.",2005.0,111.0,1053.0,False,,"{'volume': '12', 'pages': '293-327', 'name': 'ACM Trans. Comput. Hum. Interact.'}","{'bibtex': '@Article{Bickmore2005EstablishingAM,\n author = {T. Bickmore and Rosalind W. Picard},\n journal = {ACM Trans. Comput. Hum. Interact.},\n pages = {293-327},\n title = {Establishing and maintaining long-term human-computer relationships},\n volume = {12},\n year = {2005}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
2170,bb3c547fcc02f89730517980cfcf9e5b462421ef,The effects of empathetic virtual characters on presence in narrative-centered learning environments,"Recent years have seen a growing interest in the role that narrative can play in learning. With the emergence of narrative-centered learning environments that engage students by drawing them into rich interactions with compelling characters, we have begun to see the significant potential offered by immersive story-based learning experiences. In this paper we describe two studies that investigate the impact of empathetic characters on student perceptions of presence. A study was initially conducted with middle school students, and was then replicated with high school students. The results indicate that, for both populations, employing empathetic characters in narrative-centered learning environments significantly increases student perceptions of presence. The studies also reveal that empathetic characters contribute to a heightened sense of student involvement and control in learning situations.",2008.0,47.0,73.0,True,"{'url': 'http://research.csc.ncsu.edu/intellimedia/papers/empathy-chi-2008.pdf', 'status': None}",{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{McQuiggan2008TheEO,\n author = {Scott W. McQuiggan and Jonathan P. Rowe and James C. Lester},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {The effects of empathetic virtual characters on presence in narrative-centered learning environments},\n year = {2008}\n}\n'}","[{'authorId': '2779835', 'name': 'Scott W. McQuiggan'}, {'authorId': '34971293', 'name': 'Jonathan P. Rowe'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
2171,bb4c4c2482e543dcb67708f3ad775f1e3fa2ab8f,Towards Understanding the Influence of a Virtual Agent ’ s Emotional Expression on Personal Space,"The concept of personal space is a key element of social interactions. As such, it is a recurring subject of investigations in the context of research on proxemics. Using virtual-reality-based experiments, we contribute to this area by evaluating the direct effects of emotional expressions of an approaching virtual agent on an individual’s behavioral and physiological responses. As a pilot study focusing on the emotion expressed solely by facial expressions gave promising results, we now present a study design to gain more insight.",2018.0,25.0,1.0,False,,,"{'bibtex': '@Inproceedings{Kuhlen2018TowardsUT,\n author = {T. Kuhlen and A. Bönsch and J. Wendt and H. Overath and Ö. Gürerk and C. Harbring and C. Grund and T. Kittsteiner and B. McFadyen and T. Iachini and Y. Coello and F. Frassinetti and V. Senese and M. Rinck and T. Rörtgen and D. Wigboldus and B. Spanlang and M. Slater and N. Thomas and C. Spence and T. Tavares and D. Mitchell},\n title = {Towards Understanding the Influence of a Virtual Agent ’ s Emotional Expression on Personal Space},\n year = {2018}\n}\n'}","[{'authorId': '144483066', 'name': 'T. Kuhlen'}, {'authorId': '3249697', 'name': 'A. Bönsch'}, {'authorId': '39812907', 'name': 'J. Wendt'}, {'authorId': '47973447', 'name': 'H. Overath'}, {'authorId': '66809640', 'name': 'Ö. Gürerk'}, {'authorId': '2536104', 'name': 'C. Harbring'}, {'authorId': '3354454', 'name': 'C. Grund'}, {'authorId': '2856539', 'name': 'T. Kittsteiner'}, {'authorId': '1862105', 'name': 'B. McFadyen'}, {'authorId': '1902889', 'name': 'T. Iachini'}, {'authorId': '3200187', 'name': 'Y. Coello'}, {'authorId': '2903600', 'name': 'F. Frassinetti'}, {'authorId': '1414692301', 'name': 'V. Senese'}, {'authorId': '2505736', 'name': 'M. Rinck'}, {'authorId': '113703375', 'name': 'T. Rörtgen'}, {'authorId': '39854264', 'name': 'D. Wigboldus'}, {'authorId': '2891686', 'name': 'B. Spanlang'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '2262597', 'name': 'N. Thomas'}, {'authorId': '46582609', 'name': 'C. Spence'}, {'authorId': '3500182', 'name': 'T. Tavares'}, {'authorId': '2928107', 'name': 'D. Mitchell'}]"
2172,bb7cd6f69c11d2b9bfde7ad1e9611f8a8a45bec8,Multi-modal emotion analysis from facial expressions and electroencephalogram,,2016.0,55.0,75.0,False,,"{'volume': '147', 'pages': '114-124', 'name': 'Comput. Vis. Image Underst.'}","{'bibtex': '@Article{Huang2016MultimodalEA,\n author = {Xiaohua Huang and J. Kortelainen and Guoying Zhao and Xiaobai Li and A. Moilanen and T. Seppänen and M. Pietikäinen},\n journal = {Comput. Vis. Image Underst.},\n pages = {114-124},\n title = {Multi-modal emotion analysis from facial expressions and electroencephalogram},\n volume = {147},\n year = {2016}\n}\n'}","[{'authorId': '47932625', 'name': 'Xiaohua Huang'}, {'authorId': '2911579', 'name': 'J. Kortelainen'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '1502872895', 'name': 'Xiaobai Li'}, {'authorId': '39056318', 'name': 'A. Moilanen'}, {'authorId': '48819369', 'name': 'T. Seppänen'}, {'authorId': '145962204', 'name': 'M. Pietikäinen'}]"
2173,bb83f808716f0c4f669378ef85b5289ca86f7640,Learning responsive robot behavior by imitation,"In this paper we present a new approach for learning responsive robot behavior by imitation of human interaction partners. Extending previous work on robot imitation learning, that has so far mostly concentrated on learning from demonstrations by a single actor, we simultaneously record the movements of two humans engaged in on-going interaction tasks and learn compact models of the interaction. Extracted interaction models can thereafter be used by a robot to engage in a similar interaction with a human partner. We present two algorithms for deriving interaction models from motion capture data as well as experimental results on a humanoid robot.",2013.0,24.0,41.0,True,"{'url': 'http://www.ias.informatik.tu-darmstadt.de/uploads/Publications/iros2013Heni.pdf', 'status': None}","{'pages': '3257-3264', 'name': '2013 IEEE/RSJ International Conference on Intelligent Robots and Systems'}","{'bibtex': '@Article{Amor2013LearningRR,\n author = {H. B. Amor and David Vogt and Marco Ewerton and Erik Berger and B. Jung and Jan Peters},\n journal = {2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},\n pages = {3257-3264},\n title = {Learning responsive robot behavior by imitation},\n year = {2013}\n}\n'}","[{'authorId': '2207330', 'name': 'H. B. Amor'}, {'authorId': '144325919', 'name': 'David Vogt'}, {'authorId': '3355680', 'name': 'Marco Ewerton'}, {'authorId': '46831251', 'name': 'Erik Berger'}, {'authorId': '144292204', 'name': 'B. Jung'}, {'authorId': '145197867', 'name': 'Jan Peters'}]"
2174,bb95f4bb91bffa9a3524b5e12519831be539d357,The Relationship of Emotion to Cognition: A Functional Approach to a Semantic Controversy,"Abstract We first review the main points in the dispute about whether emotion is primary and independent of cognition (Zajonc), or secondary and always dependent upon cognition (Lazarus), and suggest that the dispute is largely one of definition. Because definitional disputes seldom clarify substantive, theoretical points, we suggest a variety of questions regarding cognition-emotion interaction. To stimulate discussion of these issues, we propose a componential model in which emotions are seen to develop from simpler, reflex-like forms (“wired-in” sensory-motor processes) to complex cognitive-emotional patterns that result from the participation of at least two distinct levels of memory and information processing, a schematic and a conceptual level. These systems are typically activated by a continuous stimulus check process which evaluates five environment-organism attributes: novelty; pleasantness; goal conductiveness; coping potential; and consistency with social norms and self-relevant values. Questi...",1987.0,52.0,797.0,False,,"{'volume': '1', 'pages': '3-28', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Leventhal1987TheRO,\n author = {H. Leventhal and K. Scherer},\n journal = {Cognition & Emotion},\n pages = {3-28},\n title = {The Relationship of Emotion to Cognition: A Functional Approach to a Semantic Controversy},\n volume = {1},\n year = {1987}\n}\n'}","[{'authorId': '2059373265', 'name': 'H. Leventhal'}, {'authorId': '2462740', 'name': 'K. Scherer'}]"
2175,bbaae3188aed31df77272c9f30d2b8faaa407939,"Speech gesture generation from the trimodal context of text, audio, and speaker identity","For human-like agents, including virtual avatars and social robots, making proper gestures while speaking is crucial in human-agent interaction. Co-speech gestures enhance interaction experiences and make the agents look alive. However, it is difficult to generate human-like gestures due to the lack of understanding of how people gesture. Data-driven approaches attempt to learn gesticulation skills from human demonstrations, but the ambiguous and individual nature of gestures hinders learning. In this paper, we present an automatic gesture generation model that uses the multimodal context of speech text, audio, and speaker identity to reliably generate gestures. By incorporating a multimodal context and an adversarial training scheme, the proposed model outputs gestures that are human-like and that match with speech content and rhythm. We also introduce a new quantitative evaluation metric for gesture generation models. Experiments with the introduced metric and subjective human evaluation showed that the proposed gesture generation model is better than existing end-to-end generation models. We further confirm that our model is able to work with synthesized audio in a scenario where contexts are constrained, and show that different gesture styles can be generated for the same speech by specifying different speaker identities in the style embedding space that is learned from videos of various speakers. All the code and data is available at https://github.com/ai4r/Gesture-Generation-from-Trimodal-Context.",2020.0,70.0,147.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3414685.3417838', 'status': None}","{'volume': '39', 'pages': '1 - 16', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Yoon2020SpeechGG,\n author = {Youngwoo Yoon and Bok Cha and Joo-Haeng Lee and Minsu Jang and Jaeyeon Lee and Jaehong Kim and Geehyuk Lee},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 16},\n title = {Speech gesture generation from the trimodal context of text, audio, and speaker identity},\n volume = {39},\n year = {2020}\n}\n'}","[{'authorId': '145215929', 'name': 'Youngwoo Yoon'}, {'authorId': '2068564225', 'name': 'Bok Cha'}, {'authorId': '2200538568', 'name': 'Joo-Haeng Lee'}, {'authorId': '145416765', 'name': 'Minsu Jang'}, {'authorId': '2108383739', 'name': 'Jaeyeon Lee'}, {'authorId': '1684726', 'name': 'Jaehong Kim'}, {'authorId': '80502761', 'name': 'Geehyuk Lee'}]"
2176,bbb4858ded5c5e270883c8c105bc2b66cd4f4045,Rapid facial reactions to emotional facial expressions.,"This study explored how rapidly emotion specific facial muscle reactions were elicited when subjects were exposed to pictures of angry and happy facial expressions. In three separate experiments, it was found that distinctive facial electromyographic reactions, i.e., greater Zygomaticus major muscle activity in response to happy than to angry stimuli and greater Corrugator supercilii muscle activity in response to angry stimuli, were detectable after only 300-400 ms of exposure. These findings demonstrate that facial reactions are quickly elicited, indicating that expressive emotional reactions can be very rapidly manifested and are perhaps controlled by fast operating facial affect programs.",1998.0,0.0,429.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1467-9450.00054', 'status': None}","{'volume': '39 1', 'pages': '\n          39-45\n        ', 'name': 'Scandinavian journal of psychology'}","{'bibtex': '@Article{Dimberg1998RapidFR,\n author = {U. Dimberg and M. Thunberg},\n journal = {Scandinavian journal of psychology},\n pages = {\n          39-45\n        },\n title = {Rapid facial reactions to emotional facial expressions.},\n volume = {39 1},\n year = {1998}\n}\n'}","[{'authorId': '4583182', 'name': 'U. Dimberg'}, {'authorId': '3924673', 'name': 'M. Thunberg'}]"
2177,bbd2cf9a439dc19f455c9dff00b1e968c44e42af,"This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. IEEE TRANSACTIONS ON AFFECTIVE COMPUTING",,,0.0,575.0,False,,,"{'bibtex': '@Misc{None,\n title = {This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. IEEE TRANSACTIONS ON AFFECTIVE COMPUTING}\n}\n'}",[]
2178,bbe8b6e541c473bfe3f2e20aa009ab1e0dba3220,Why we interact: On the functional role of the striatum in the subjective experience of social interaction,,2014.0,100.0,122.0,True,"{'url': 'https://aura.abdn.ac.uk/bitstream/2164/3718/1/PfeifferEtAl_NeuroImage_Draft.pdf', 'status': None}","{'volume': '101', 'pages': '124-137', 'name': 'NeuroImage'}","{'bibtex': '@Article{Pfeiffer2014WhyWI,\n author = {U. Pfeiffer and L. Schilbach and Bert Timmermans and B. Kuzmanovic and A. Georgescu and G. Bente and K. Vogeley},\n journal = {NeuroImage},\n pages = {124-137},\n title = {Why we interact: On the functional role of the striatum in the subjective experience of social interaction},\n volume = {101},\n year = {2014}\n}\n'}","[{'authorId': '48230544', 'name': 'U. Pfeiffer'}, {'authorId': '2127424', 'name': 'L. Schilbach'}, {'authorId': '1918177', 'name': 'Bert Timmermans'}, {'authorId': '144082475', 'name': 'B. Kuzmanovic'}, {'authorId': '2989516', 'name': 'A. Georgescu'}, {'authorId': '2487649', 'name': 'G. Bente'}, {'authorId': '2051580', 'name': 'K. Vogeley'}]"
2179,bbf3bbab60960ab2ce53ec8d1b4ef87673268b92,The Dialogic Imagination: Four Essays,Acknowledgments A Note on Translation Introduction Epic and Novel From the Prehistory of Novelistic Discourse Forms of Time and of the Chronotope in the Novel Discourse in the Novel Glossary Index,1981.0,0.0,10665.0,False,,"{'volume': '5', 'pages': '172', 'name': 'Poetics Today'}","{'bibtex': '@Article{Ehre1981TheDI,\n author = {Milton Ehre and M. Bakhtin and M. Holquist and Caryl Emerson},\n journal = {Poetics Today},\n pages = {172},\n title = {The Dialogic Imagination: Four Essays},\n volume = {5},\n year = {1981}\n}\n'}","[{'authorId': '115990619', 'name': 'Milton Ehre'}, {'authorId': '116694342', 'name': 'M. Bakhtin'}, {'authorId': '4452651', 'name': 'M. Holquist'}, {'authorId': '108210680', 'name': 'Caryl Emerson'}]"
2180,bc02d4d0b04c19f62051a8b992369a8d38cba8bd,Validating the Search and Rescue Game Environment as a robot simulator by performing a simulated anomaly detection task,"This paper presents the results from experiments validating the physics and environmental accuracy of a new robot simulation environment, the search and rescue game environment (SARGE), which is the foundation for series of robot-operator training games. An ATRV-Jr. outfitted with a SICK laser, GPS, and compass was used both in the real-world and in a simulated environment modeled after the real-world testing location in a simulated anomaly detection task. The ARTV-Jr., controlled by the Distributed Field Robotics Architecture, navigated through a series of waypoints in the environment. The simulated ATRV-Jr. matched the actions of the real ATRV-Jr. in both velocity and path similarity within 0.08 m/s and 0.7 m respectively.",2008.0,13.0,12.0,False,,"{'pages': '2289-2295', 'name': '2008 IEEE/RSJ International Conference on Intelligent Robots and Systems'}","{'bibtex': '@Article{Craighead2008ValidatingTS,\n author = {J. Craighead and Rodrigo Gutierrez and J. Burke and R. Murphy},\n journal = {2008 IEEE/RSJ International Conference on Intelligent Robots and Systems},\n pages = {2289-2295},\n title = {Validating the Search and Rescue Game Environment as a robot simulator by performing a simulated anomaly detection task},\n year = {2008}\n}\n'}","[{'authorId': '38140175', 'name': 'J. Craighead'}, {'authorId': '145938456', 'name': 'Rodrigo Gutierrez'}, {'authorId': '34066787', 'name': 'J. Burke'}, {'authorId': '1789429', 'name': 'R. Murphy'}]"
2181,bc1745fb575dc9ca2d08bd334ba470515c862044,Environment Programming in CArtAgO,,2009.0,35.0,150.0,False,,{'pages': '259-288'},"{'bibtex': '@Inproceedings{Ricci2009EnvironmentPI,\n author = {A. Ricci and Michele Piunti and Mirko Viroli and Andrea Omicini},\n pages = {259-288},\n title = {Environment Programming in CArtAgO},\n year = {2009}\n}\n'}","[{'authorId': '144464279', 'name': 'A. Ricci'}, {'authorId': '1831718', 'name': 'Michele Piunti'}, {'authorId': '1728548', 'name': 'Mirko Viroli'}, {'authorId': '3119182', 'name': 'Andrea Omicini'}]"
2182,bc38f00bc19d6b43ad1e3b3737dd791c9cb782fc,Intelligent software,"INTRODUCTION Computers are as ubiquitous as automobiles and toasters, but exploiting their capabilities still seems to require the training of a supersonic test pilot. VCR displays blinking a constant 12 noon around the world testi~ to this conunclrum. As interactive television, palmtop diaries and “smart” credit cards proliferate, the gap between millions of untrained users and an equal number of sophisticated microprocessors will become even more sharply apparent. With people spending a growing proportion of their lives in front ctf computer screens--informing and entertaining one ancltier, exchanging correspondence, working, shopping and falling in love—some accommodation must be found between limited human attention spans and increasingly complex collections of software and data. ,",1997.0,4.0,121.0,False,,{'pages': '41-43'},"{'bibtex': '@Inproceedings{Maes1997IntelligentS,\n author = {P. Maes},\n pages = {41-43},\n title = {Intelligent software},\n year = {1997}\n}\n'}","[{'authorId': '1701876', 'name': 'P. Maes'}]"
2183,bc405796b2bef0219909592777ae52c5f07f34d7,Cross-Cultural Perception of Spanish Synthetic Expressive Voices Among Asians,"Nonverbal cues play a vital role in contributing to how emotions are perceived, especially by outgroups. In this study, a cross-cultural perception experiment of Spanish Synthetic Expressive Voices (SEV) was conducted to investigate the perception rate among different groups of Asians towards the SEV. Ten (10) subjects from each ethnic group namely Japanese, Chinese, Vietnamese, and Malaysians participated in this test. The subjects were required to listen to and categorize the SEV corpus which contains 260 utterances with 4 emotions (anger, happiness, sadness, and surprise) and the neutral speech in different intensities and durations. Overall, the results indicate that duration and intensity of speech plays a significant role in perception. This paper concludes that listeners’ perceptions are influenced by a speaker’s nonverbal expression and it is important that these features (duration and intensity of speech) are considered when modelling synthetic speech for artificial agents in real-time applications in a cross-cultural user environment.",2018.0,42.0,1.0,True,"{'url': 'https://www.mdpi.com/2076-3417/8/3/426/pdf?version=1520869895', 'status': None}","{'volume': '8', 'pages': '426', 'name': 'Applied Sciences'}","{'bibtex': '@Article{Naidu2018CrossCulturalPO,\n author = {Ganapreeta Renunathan Naidu and S. Lutfi and Amal Azazi and Jaime Lorenzo-Trueba and Juan Manuel Montero Martínez},\n journal = {Applied Sciences},\n pages = {426},\n title = {Cross-Cultural Perception of Spanish Synthetic Expressive Voices Among Asians},\n volume = {8},\n year = {2018}\n}\n'}","[{'authorId': '25586216', 'name': 'Ganapreeta Renunathan Naidu'}, {'authorId': '1775289', 'name': 'S. Lutfi'}, {'authorId': '2211368', 'name': 'Amal Azazi'}, {'authorId': '1388601149', 'name': 'Jaime Lorenzo-Trueba'}, {'authorId': '2109650475', 'name': 'Juan Manuel Montero Martínez'}]"
2184,bc595fd0f97ad98663d4d681746879fe9df06045,Crowd panic state detection using entropy of the distribution of enthalpy,,2019.0,29.0,25.0,False,,{'name': 'Physica A: Statistical Mechanics and its Applications'},"{'bibtex': '@Article{Zhang2019CrowdPS,\n author = {Xuguang Zhang and Xiaohu Shu and Zhen He},\n journal = {Physica A: Statistical Mechanics and its Applications},\n title = {Crowd panic state detection using entropy of the distribution of enthalpy},\n year = {2019}\n}\n'}","[{'authorId': '8443268', 'name': 'Xuguang Zhang'}, {'authorId': '107928381', 'name': 'Xiaohu Shu'}, {'authorId': '2116778579', 'name': 'Zhen He'}]"
2185,bc6dff14a130c57a91d5a21339c23471faf1d46f,Et al,"disasters. Plenum, 2001. 11. Haley R, Thomas L, Hom J. Is there a Gulf War Syndrome? Searching for syndromes by factor analysis of symptoms. JAMA 1997;277:215–22. 12. Fukuda K, Nisenbaum R, Stewart G, et al. Chronic multi-symptom illness affecting Air Force veterans of the Gulf War. JAMA 1998;280:981–8. 13. Ismail K, Everitt B, Blatchley N, et al. Is there a Gulf War Syndrome? Lancet 1999;353:179–82. 14. Shapiro S, Lasarev M, McCauley L. Factor analysis of Gulf War illness: what does it add to our understanding of possible health effects of deployment. Am J Epidemiol 2002;156:578–85. 15. Doebbeling B, Clarke W, Watson D, et al. Is there a Persian Gulf War Syndrome? Evidence from a large population-based survey of veterans and nondeployed controls. Am J Med 2000;108:695–704. 16. Knoke J, Smith T, Gray G, et al. Factor analysis of self reported symptoms: Does it identify a Gulf War Syndrome? Am J Epidemiol 2000;152:379–88. 17. Kang H, Mahan C, Lee K, et al. Evidence for a deployment-related Gulf War syndrome by factor analysis. Arch Environ Health 2002;57:61–8.",2008.0,33.0,68766.0,False,,"{'volume': '11', 'pages': '102 - 104', 'name': 'Evidence Based Mental Health'}","{'bibtex': '@Article{Cochat2008EtA,\n author = {P. Cochat and L. Vaucoret and J. Sarles},\n journal = {Evidence Based Mental Health},\n pages = {102 - 104},\n title = {Et al},\n volume = {11},\n year = {2008}\n}\n'}","[{'authorId': '2059358552', 'name': 'P. Cochat'}, {'authorId': '13267685', 'name': 'L. Vaucoret'}, {'authorId': '2097644863', 'name': 'J. Sarles'}]"
2186,bca2e6c3e1728cf856de492605631c49e562bcf0,"Approach, avoidance, and coping with stress.","The study of stress and coping points to two concepts central to an understanding of the response to trauma: approach and avoidance. This pair of concepts refers to two basic modes of coping with stress. Approach and avoidance are simply metaphors for cognitive and emotional activity that is oriented either toward or away from threat. An approach-avoidance model of coping is presented in the context of contemporary theoretical ap- proaches to coping. The research literature on coping ef- fectiveness, including evidence from our laboratory, is dis- cussed, and speculations are made about the implications for future research. The study of stress and coping has become quite popular in recent years, particularly in regard to traumatic life events. Although the area is broad and the coping process is complex, there is a striking coherence in much of the literature. This coherence is based on two concepts central to an understanding of coping with trauma: approach and avoidance. In its simplest form, this pair of concepts refers to two basic orientations toward stressful infor- mation, or two basic modes of coping with stress. Ap- proach and avoidance are shorthand terms for the cog- nitive and emotional activity that is oriented either toward or away from threat. In this article we will present the case for utilizing the concepts of approach and avoidance to provide a co- herent theoretical structure to our understanding of cop- ing with stress. Several different formulations of the ap- proach-avoidance dimension will be reviewed, followed by a brief review of the coping effectiveness literature. Several studies from our laboratory will be used to illus- trate the relationship between coping and outcome. Fi- nally, a general approach-avoidance model of coping will be presented, with suggestions for further research to cor- roborate or extend the theory. The study of coping with stress has been split into two areas: anticipation of future stressful events and re- covery from trauma. These areas have been kept re- markably distinct in both theory and research on coping. Although there are clearly important differences between the two cases, we have chosen not to emphasize this dis- tinction. For any given stress, anticipation and recovery are not always clearly separable; dealing with a trauma involves coming to terms with the event itself and with the threat of recurrence in the future. More important, Correspondence concerning this article should be sent to Susan",1986.0,35.0,1746.0,False,,"{'volume': '41 7', 'pages': '\n          813-9\n        ', 'name': 'The American psychologist'}","{'bibtex': '@Article{Roth1986ApproachAA,\n author = {S. Roth and L. Cohen},\n journal = {The American psychologist},\n pages = {\n          813-9\n        },\n title = {Approach, avoidance, and coping with stress.},\n volume = {41 7},\n year = {1986}\n}\n'}","[{'authorId': '152368844', 'name': 'S. Roth'}, {'authorId': '144994495', 'name': 'L. Cohen'}]"
2187,bca946bac5a5015291802e3e07c12236c60c3f3e,"Multimodal Sensing, Interpretation and Copying of Movements by a Virtual Agent",,2006.0,30.0,13.0,True,"{'url': 'http://www.image.ece.ntua.gr/papers/416.pdf', 'status': None}",{'pages': '164-174'},"{'bibtex': '@Inproceedings{Bevacqua2006MultimodalSI,\n author = {Elisabetta Bevacqua and A. Raouzaiou and Christopher E. Peters and G. Caridakis and K. Karpouzis and C. Pelachaud and M. Mancini},\n pages = {164-174},\n title = {Multimodal Sensing, Interpretation and Copying of Movements by a Virtual Agent},\n year = {2006}\n}\n'}","[{'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '3346592', 'name': 'A. Raouzaiou'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '2001300', 'name': 'G. Caridakis'}, {'authorId': '1715144', 'name': 'K. Karpouzis'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2169958', 'name': 'M. Mancini'}]"
2188,bcc92febdcb871ecb6e764d323e6ca58fe777a12,Emotion Regulation and Children's Socioemotional Competence.,,2006.0,0.0,65.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Eisenberg2006EmotionRA,\n author = {N. Eisenberg and R. Fabes},\n title = {Emotion Regulation and Children's Socioemotional Competence.},\n year = {2006}\n}\n""}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}, {'authorId': '1833039', 'name': 'R. Fabes'}]"
2189,bce809c25d22a601cb1e708a7ffb16dea58651fb,It feels real: physiological responses to a stressful virtual reality environment and its impact on working memory,"Background: Virtual reality (VR) is increasingly used to study and treat psychiatric disorders. Its fidelity depends in part on the extent to which the VR environment provides a convincing simulation, for example whether a putatively stressful VR situation actually produces a stress response. Methods: We studied the stress response in 28 healthy men exposed either to a stressor VR elevator (which simulated travelling up the outside of a tall building and culminated in the participant being asked to step off the elevator platform), or to a control elevator. We measured psychological and physiological (salivary cortisol and alpha-amylase, blood pressure, pulse, skin conductance) stress indices. We also measured subsequent performance on the N-back task because acute stress has been reported to impact on working memory. Results: Compared to participants in the control elevator, those in the external elevator had increases in skin conductance, pulse and subjective stress and anxiety ratings, altered heart rate variability, and a delayed rise in cortisol. N-back performance was unaffected. Conclusions: A putatively stressful VR elevator produces a physiological as well as a psychological stress response, supporting its use in the investigation and treatment of stress-related disorders, and its potential value as an experimental laboratory stressor.",2019.0,53.0,63.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/0269881119860156', 'status': None}","{'volume': '33', 'pages': '1264 - 1273', 'name': 'Journal of Psychopharmacology (Oxford, England)'}","{'bibtex': '@Article{Martens2019ItFR,\n author = {M. Martens and Angus Antley and D. Freeman and M. Slater and Paul J. Harrison and E. Tunbridge},\n journal = {Journal of Psychopharmacology (Oxford, England)},\n pages = {1264 - 1273},\n title = {It feels real: physiological responses to a stressful virtual reality environment and its impact on working memory},\n volume = {33},\n year = {2019}\n}\n'}","[{'authorId': '2057229443', 'name': 'M. Martens'}, {'authorId': '1705895', 'name': 'Angus Antley'}, {'authorId': '145331574', 'name': 'D. Freeman'}, {'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '40306765', 'name': 'Paul J. Harrison'}, {'authorId': '2661182', 'name': 'E. Tunbridge'}]"
2191,bcf1f1fb2fbceb6e4edb895c2ca6d1665c2aa62e,Using Visual Supports with Young Children with Autism Spectrum Disorder,"Isaac is learning ways to complete hisnightly bedtime routine; Omar is fol -lowing cues to control his disruptiveand impulsive behavior; Peter isbecoming more independent withlibrary routines; and Adriana hasbenefited from visual support withlearning hand-washing and toiletingroutines.Most of us use visual supports tonavigate our days (calendars, maps,watches, to-do lists—even high-techversions of these supports), so why notprovide similar supports to young chil -dren? We must particularly be sensi -tive to the needs of children who canbenefit greatly from them: young child-ren with autism spectrum disorder.There are many helpful kinds of visualsupports teachers can use in the class -room every day, modifying andenhancing them as children becomemore and more independent. Indeed,both parents and teachers have usedmany of these tools successfully with",2011.0,17.0,95.0,False,,"{'volume': '43', 'pages': '28 - 35', 'name': 'TEACHING Exceptional Children'}","{'bibtex': '@Article{Meadan2011UsingVS,\n author = {H. Meadan and M. Ostrosky and Brooke Triplett and Amanda Michna and Angel Fettig},\n journal = {TEACHING Exceptional Children},\n pages = {28 - 35},\n title = {Using Visual Supports with Young Children with Autism Spectrum Disorder},\n volume = {43},\n year = {2011}\n}\n'}","[{'authorId': '50265822', 'name': 'H. Meadan'}, {'authorId': '31843910', 'name': 'M. Ostrosky'}, {'authorId': '117520017', 'name': 'Brooke Triplett'}, {'authorId': '117898575', 'name': 'Amanda Michna'}, {'authorId': '37703791', 'name': 'Angel Fettig'}]"
2192,bd2986fbbc9465e8f55fa7f7d1beffa1505862f9,"The benefit of being physically present: A survey of experimental works comparing copresent robots, telepresent robots and virtual agents",,2015.0,76.0,392.0,False,,"{'volume': '77', 'pages': '23-37', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Li2015TheBO,\n author = {Jamy J. Li},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {23-37},\n title = {The benefit of being physically present: A survey of experimental works comparing copresent robots, telepresent robots and virtual agents},\n volume = {77},\n year = {2015}\n}\n'}","[{'authorId': '40557756', 'name': 'Jamy J. Li'}]"
2193,bd779b36941b5573aeacf8a77157b43fa1ace466,Emotion-based diversity crowd behavior simulation in public emergency,,2018.0,32.0,28.0,False,,"{'volume': '', 'pages': '1-15', 'name': 'The Visual Computer'}","{'bibtex': '@Article{Mao2018EmotionbasedDC,\n author = {Yan Mao and Zuning Li and Yongjian Li and Wu He},\n journal = {The Visual Computer},\n pages = {1-15},\n title = {Emotion-based diversity crowd behavior simulation in public emergency},\n year = {2018}\n}\n'}","[{'authorId': '1390848733', 'name': 'Yan Mao'}, {'authorId': '49970067', 'name': 'Zuning Li'}, {'authorId': '2110516274', 'name': 'Yongjian Li'}, {'authorId': '51125889', 'name': 'Wu He'}]"
2194,bdab45dfbd4e21b707dbf2503147d1eb99d183da,EmoStory: A Game-based System Supporting Children's Emotional Development,"Children's emotional skills are important for their success. However, children with Autism Spectrum Disorders have difficulties in understanding social contexts and recognizing and expressing facial expressions. In this paper, we present the design of EmoStory, a game-based interactive narratives system that supports children's emotional development. The system uses animation and emotional sounds to teach children six basic emotions and facial expressions in various social contexts, and also provides multi-level games for children to systematically practice the learnt skills. Through using facial expression recognition technique and designing animated visual cue for important facial movement features, the system helps children to practice facial expressions and provides them with explicit guides during the tasks.",2018.0,17.0,13.0,False,,{'name': 'Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': ""@Article{Fan2018EmoStoryAG,\n author = {Min Fan and Jianyu Fan and Sheng Jin and A. Antle and Philippe Pasquier},\n journal = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},\n title = {EmoStory: A Game-based System Supporting Children's Emotional Development},\n year = {2018}\n}\n""}","[{'authorId': '2054875601', 'name': 'Min Fan'}, {'authorId': '144069698', 'name': 'Jianyu Fan'}, {'authorId': '2108914487', 'name': 'Sheng Jin'}, {'authorId': '1693717', 'name': 'A. Antle'}, {'authorId': '144380634', 'name': 'Philippe Pasquier'}]"
2195,bdc192a3dac4f62a0ebc5dd824d36fcb0128a536,"The personal and national costs of mental health conditions: impacts on income, taxes, government support payments due to lost labour force participation",,2011.0,61.0,70.0,True,"{'url': 'https://bmcpsychiatry.biomedcentral.com/counter/pdf/10.1186/1471-244X-11-72', 'status': None}","{'volume': '11', 'pages': '72 - 72', 'name': 'BMC Psychiatry'}","{'bibtex': '@Article{Schofield2011ThePA,\n author = {D. Schofield and R. Shrestha and Richard Percival and M. Passey and E. Callander and S. Kelly},\n journal = {BMC Psychiatry},\n pages = {72 - 72},\n title = {The personal and national costs of mental health conditions: impacts on income, taxes, government support payments due to lost labour force participation},\n volume = {11},\n year = {2011}\n}\n'}","[{'authorId': '6244428', 'name': 'D. Schofield'}, {'authorId': '6441370', 'name': 'R. Shrestha'}, {'authorId': '2359876', 'name': 'Richard Percival'}, {'authorId': '5820454', 'name': 'M. Passey'}, {'authorId': '5170062', 'name': 'E. Callander'}, {'authorId': '5455965', 'name': 'S. Kelly'}]"
2196,bdc464624f572b9c5cfe0be420ee5b827c61107e,Emotion Regulation in Young Children with Autism Spectrum Disorders,,2016.0,44.0,135.0,False,,"{'volume': '47', 'pages': '68 - 79', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Berkovits2016EmotionRI,\n author = {Lauren D. Berkovits and A. Eisenhower and J. Blacher},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {68 - 79},\n title = {Emotion Regulation in Young Children with Autism Spectrum Disorders},\n volume = {47},\n year = {2016}\n}\n'}","[{'authorId': '39841151', 'name': 'Lauren D. Berkovits'}, {'authorId': '50171038', 'name': 'A. Eisenhower'}, {'authorId': '32569768', 'name': 'J. Blacher'}]"
2197,bdcc68811729510aec15f41d56aab8b200e6f372,Modeling Emotions and Other Motivations in Synthetic Agents,"We present Cathexis, a distributed, computational model which offers an alternative approach to model the dynamic nature of different affective phenomena, such as emotions, moods and temperaments, and provides a flexible way of modeling their influence on the behavior of synthetic autonomous agents. The model has been implemented as part of an extensible, object-oriented framework which provides enough functionality for agent developers to design emotional agents that can be used in a variety of applications including entertainment (e.g. synthetic agents for interactive drama, video games, etc.), education (e.g. Intelligent Tutoring Systems), and human-computer interfaces.",1997.0,28.0,365.0,False,,{'pages': '10-15'},"{'bibtex': '@Inproceedings{Velásquez1997ModelingEA,\n author = {J. Velásquez},\n pages = {10-15},\n title = {Modeling Emotions and Other Motivations in Synthetic Agents},\n year = {1997}\n}\n'}","[{'authorId': '2095517457', 'name': 'J. Velásquez'}]"
2198,bdddef9ced9f199c069a158f400bfb27857c58c1,How to Touch Humans: Guidelines for Social Agents and Robots That Can Touch,"Touch is an essential channel in interpersonal and affective communication, yet most social agents currently lack the capability to touch the user. In this paper we show the credibility of three premises that make the case that providing touch capability to social robots will increase their effectiveness in communicating emotions, building trust and achieving behavioral changes. The first premise is that humans can communicate distinct emotions through touch only, the second is that this is also possible through mediated (virtual) touch, and the third is that social agents can use the same mediated touch technology as effectively as humans. Based on a literature review, we also formulate ten design rules as guidance for the development of social agents that can touch. These rules concern parameters that regulate the meaning of touch cues like context and familiarity, the implicit and explicit meanings of touch, user characteristics, and parameters that can be communicated through affective touch.",2013.0,77.0,44.0,False,,"{'pages': '780-785', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Erp2013HowTT,\n author = {J. V. Erp and A. Toet},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {780-785},\n title = {How to Touch Humans: Guidelines for Social Agents and Robots That Can Touch},\n year = {2013}\n}\n'}","[{'authorId': '118775648', 'name': 'J. V. Erp'}, {'authorId': '1944545', 'name': 'A. Toet'}]"
2199,bdf19700fd64de2d5ed7dfde5e95c7d0965b87a8,A model of gaze for the purpose of emotional expression in virtual embodied agents,"Currently, state of the art virtual agents lack the ability to display emotion as seen in actual humans, or even in hand-animated characters. One reason for the emotional inexpressiveness of virtual agents is the lack of emotionally expressive gaze manner. For virtual agents to express emotion that observers can empathize with, they need to generate gaze - including eye, head, and torso movement - to arbitrary targets, while displaying arbitrary emotional states. Our previous work [18] describes the Gaze Warping Transformation, a method of generating emotionally expressive head and torso movement during gaze shifts that is derived from human movement data. Through an evaluation, it was shown that applying different transformations to the same gaze shift could modify the affective state perceived when the transformed gaze shift was viewed by a human observer. In this paper we propose a model of realistic, emotionally expressive gaze that builds upon the Gaze Warping Transformation by improving the transformation implementation, and by adding a model of eye movement drawn from the visual neuroscience literature. We describe how to generate a gaze to an arbitrary target, while displaying an arbitrary emotional behavior. Finally, we propose an evaluation to determine what emotions human observers will attribute to the generated gaze shifts. Once this work is completed, virtual agents will have access to a new channel for emotionally expressive behavior.",2008.0,42.0,44.0,False,,{'pages': '199-206'},"{'bibtex': '@Inproceedings{Lance2008AMO,\n author = {Brent Lance and S. Marsella},\n pages = {199-206},\n title = {A model of gaze for the purpose of emotional expression in virtual embodied agents},\n year = {2008}\n}\n'}","[{'authorId': '145417478', 'name': 'Brent Lance'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
2200,bdf77a44438f1f44f8abfc66076c658a303add74,Eurographics/ Acm Siggraph Symposium on Computer Animation (2007) Group Behavior from Video: a Data-driven Approach to Crowd Simulation,"Permission to make digital or hard copies of part or all of this wor k for per sonal or classr oom use is granted without fee provided that copies are not made or distributed for commer cial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this wor k owned by other s than ACM must be honored. Abstracting with cr edit is permitted. To copy other wise, to republish, to post on ser ver s, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM Abstract Crowd simulation techniques have frequently been used to animate a large group of virtual humans in computer graphics applications. We present a data-driven method of simulating a crowd of virtual humans that exhibit behaviors imitating real human crowds. To do so, we record the motion of a human crowd from an aerial view using a camcorder, extract the two-dimensional moving trajectories of each individual in the crowd, and then learn an agent model from observed trajectories. The agent model decides each agent's actions based on features of the environment and the motion of nearby agents in the crowd. Once the agent model is learned, we can simulate a virtual crowd that behaves similarly to the real crowd in the video. The versatility and flexibility of our approach is demonstrated through examples in which various characteristics of group behaviors are captured and reproduced in simulated crowds.",,16.0,310.0,False,,,"{'bibtex': '@Misc{None,\n author = {Dimitris N. Metaxas and J. Popović and Hoon Kang and Myung Geol Lee and Qyoun Choi and Jehee Hong and Lee},\n title = {Eurographics/ Acm Siggraph Symposium on Computer Animation (2007) Group Behavior from Video: a Data-driven Approach to Crowd Simulation}\n}\n'}","[{'authorId': '48351473', 'name': 'Dimitris N. Metaxas'}, {'authorId': '145492783', 'name': 'J. Popović'}, {'authorId': '2231643408', 'name': 'Hoon Kang'}, {'authorId': '2231648428', 'name': 'Myung Geol Lee'}, {'authorId': '2230811017', 'name': 'Qyoun Choi'}, {'authorId': '2231614594', 'name': 'Jehee Hong'}, {'authorId': '2230734554', 'name': 'Lee'}]"
2201,be0e29291ae7c887249fcb1fbd106b3790637497,Reasons for Emotions,,2007.0,0.0,29.0,False,,"{'volume': '', 'pages': '263-278', 'name': ''}","{'bibtex': '@Inproceedings{Hudlicka2007ReasonsFE,\n author = {E. Hudlicka},\n pages = {263-278},\n title = {Reasons for Emotions},\n year = {2007}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
2202,be1891dd9ec6aa78267ecc1649812274456a3783,"For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1985","A model of P300 amplitude is proposed that reduces the many hypothetical constructs invoked to explain variations in P300 amplitude to three dimensions: 1) Subjective Probability, 2) Stimulus Meaning, and 3) Information Transmission. Evidence is presented to support the assertion that variables on the subjective probability and stimulus meaning dimensions have independent and additive contributions to overall P300 amplitude. The amplitude contributions of both of these dimensions, however, are modulated by a multiplicative relation with the proportion of transmitted stimulus information. Within each dimension, the fundamental experimental variables and their interrelations are specified. An example is presented to show how, by using an additive factors method, the respective amplitude effects of the probability and stimulus meaning dimensions can be separated. Supporting data are presented to show that the proposed model provides a reasonable and testable framework in which to conceptualize P300 results.",1986.0,62.0,661.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1469-8986.1986.tb00649.x', 'status': None}","{'volume': '23', 'pages': '367-384', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Johnson1986ForDE,\n author = {Ray Johnson},\n journal = {Psychophysiology},\n pages = {367-384},\n title = {For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1985},\n volume = {23},\n year = {1986}\n}\n'}","[{'authorId': '145207176', 'name': 'Ray Johnson'}]"
2203,be26cdf0573bc8eee1119802e548dfaa2e401bdb,Overview of deep learning,"In recent years, deep learning has achieved great success in many fields, such as computer vision and natural language processing. Compared to traditional machine learning methods, deep learning has a strong learning ability and can make better use of datasets for feature extraction. Because of its practicability, deep learning becomes more and more popular for many researchers to do research works. In this paper, we mainly introduce some advanced neural networks of deep learning and their applications. Besides, we also discuss the limitations and prospects of deep learning.",2016.0,38.0,229.0,False,,"{'pages': '159-164', 'name': '2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)'}","{'bibtex': '@Article{Du2016OverviewOD,\n author = {Xuedan Du and Yinghao Cai and Shuo Wang and Leijie Zhang},\n journal = {2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)},\n pages = {159-164},\n title = {Overview of deep learning},\n year = {2016}\n}\n'}","[{'authorId': '31254825', 'name': 'Xuedan Du'}, {'authorId': '2230979', 'name': 'Yinghao Cai'}, {'authorId': '2117010531', 'name': 'Shuo Wang'}, {'authorId': '2107887550', 'name': 'Leijie Zhang'}]"
2204,be62ab5500883a5e02abcfd381b28b0267760508,Improving attendance at school,,2012.0,0.0,22.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Taylor2012ImprovingAA,\n author = {Charlie Taylor},\n title = {Improving attendance at school},\n year = {2012}\n}\n'}","[{'authorId': '51109300', 'name': 'Charlie Taylor'}]"
2205,be921ace702e263fa25e2d5adda6909d69fdb2b7,Reinforcement learning for passive dynamic walking robot,,2008.0,0.0,1.0,False,,"{'volume': '', 'name': 'Scopus'}","{'bibtex': '@Article{Mao2008ReinforcementLF,\n author = {Y. Mao and S. Li and J.-X. Wang and P. Jia and Zhenglin Yang and Zhengyue Qiu},\n journal = {Scopus},\n title = {Reinforcement learning for passive dynamic walking robot},\n year = {2008}\n}\n'}","[{'authorId': '2117694340', 'name': 'Y. Mao'}, {'authorId': '50341299', 'name': 'S. Li'}, {'authorId': '143628350', 'name': 'J.-X. Wang'}, {'authorId': '2463381', 'name': 'P. Jia'}, {'authorId': '2149234483', 'name': 'Zhenglin Yang'}, {'authorId': '98642924', 'name': 'Zhengyue Qiu'}]"
2206,be9a4798022f2785ba914bd3ed2227618cc761a4,Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters,"Successful collaboration relies on the coordination and alignment of communicative cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated production and detection of gaze cues - by which a virtual character can coordinate its gaze cues with those of its human user. We implement these mechanisms in a hybrid stochastic/heuristic model synthesized from data collected in human-human interactions. In three lab studies wherein a virtual character instructs participants in a sandwich-making task, we demonstrate how bidirectional gaze can lead to positive outcomes in error rate, completion time, and the agent's ability to produce quick, effective nonverbal references. The first study involved an on-screen agent and the participant wearing eye-tracking glasses. The second study demonstrates that these positive outcomes can be achieved using head-pose estimation in place of full eye tracking. The third study demonstrates that these effects also transfer into virtual-reality interactions.",2017.0,55.0,69.0,False,,{'name': 'Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Andrist2017LookingCB,\n author = {Sean Andrist and Michael Gleicher and Bilge Mutlu},\n journal = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},\n title = {Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters},\n year = {2017}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}, {'authorId': '1776507', 'name': 'Michael Gleicher'}, {'authorId': '145656551', 'name': 'Bilge Mutlu'}]"
2207,bea7191c719c0ce028c01697563a98aa669cafbb,"Time, touch, and compassion: effects on autonomic nervous system and well-being.",,2012.0,88.0,23.0,False,,"{'volume': '8 3', 'pages': '\n          177-84\n        ', 'name': 'Explore'}","{'bibtex': '@Article{Shaltout2012TimeTA,\n author = {H. Shaltout and J. Tooze and E. Rosenberger and K. Kemper},\n journal = {Explore},\n pages = {\n          177-84\n        },\n title = {Time, touch, and compassion: effects on autonomic nervous system and well-being.},\n volume = {8 3},\n year = {2012}\n}\n'}","[{'authorId': '6931797', 'name': 'H. Shaltout'}, {'authorId': '3683723', 'name': 'J. Tooze'}, {'authorId': '38400077', 'name': 'E. Rosenberger'}, {'authorId': '34030498', 'name': 'K. Kemper'}]"
2208,bebca9208e8d3c47f477bb349613e6a4e05b42c1,The Motivational and Metacognitive Control in CLARION,"This article presents an overview of a relatively recent cognitive architecture, and its internal control structures, that is, its motivational and metacognitive mechanisms. The chapter starts with a look at some general ideas underlying this cognitive architecture and the relevance of these ideas to cognitive modeling of agents. It then presents a sketch of some details of the architecture and their uses in cognitive modeling of specific tasks.",2007.0,25.0,33.0,False,,{'pages': '63-75'},"{'bibtex': '@Inproceedings{Sun2007TheMA,\n author = {R. Sun},\n pages = {63-75},\n title = {The Motivational and Metacognitive Control in CLARION},\n year = {2007}\n}\n'}","[{'authorId': '145966408', 'name': 'R. Sun'}]"
2209,bec00f4474bf4128bd19ba2c266a7b5ffcdb72a0,Autism/excel study,"Five high school students with ASD (autistic spectrum disorder) participating in the Excel/Autism study were able to demonstrate mastery of a set of Excel topics. The Excel curriculum covered approximately the same topics as are covered in the Excel portion of Computer Business Applications, a class for regular education students at Fox Chapel Area High School, a high school in suburban Pittsburgh. The students with ASD were provided with one-on-one tutoring support. Two of the five ASD participants self-initiated activities and engaged in generative thinking to a substantial degree over the course of the eight instructional sessions for which data was recorded. Two others demonstrated lesser amounts of this behavior, and one participant did not demonstrate any. The ASD experimental participants, as compared to a treatment group of three students with ASD who did not receive instruction in Excel, demonstrated improvement in a multi-step planning task which was significant.",2005.0,7.0,59.0,False,,{'pages': '136-141'},"{'bibtex': '@Inproceedings{Hart2005AutismexcelS,\n author = {M. Hart},\n pages = {136-141},\n title = {Autism/excel study},\n year = {2005}\n}\n'}","[{'authorId': '144973594', 'name': 'M. Hart'}]"
2210,bed413b4da1fd24e59e2c33ffd758ab140d52189,Tactical Language and Culture Training Systems: Using AI to Teach Foreign Languages and Cultures,"The Tactical Language and Culture Training System (TLCTS) helps people quickly acquire communicative skills in foreign languages and cultures. More than 40,000 learners worldwide have used TLCTS courses. TLCTS utilizes artificial intelligence technologies during the authoring process, and at run time to process learner speech, engage in dialog, and evaluate and assess learner performance. This paper describes the architecture of TLCTS and the artificial intelligence technologies that it employs, and presents results from multiple evaluation studies that demonstrate the benefits of learning foreign language and culture using this approach.",2009.0,14.0,111.0,True,"{'url': 'https://aaai.org/ojs/index.php/aimagazine/article/download/2240/2091', 'status': None}","{'volume': '30', 'pages': '72-83', 'name': 'AI Mag.'}","{'bibtex': '@Article{Johnson2009TacticalLA,\n author = {W. Johnson and A. Valente},\n journal = {AI Mag.},\n pages = {72-83},\n title = {Tactical Language and Culture Training Systems: Using AI to Teach Foreign Languages and Cultures},\n volume = {30},\n year = {2009}\n}\n'}","[{'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '2713763', 'name': 'A. Valente'}]"
2212,bed629bc6ed311418dc8b870a1ee2b79576066b2,DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition,"This paper presents our pioneering effort for emotion recognition in conversation (ERC) with pre-trained language models. Unlike regular documents, conversational utterances appear alternately from different parties and are usually organized as hierarchical structures in previous work. Such structures are not conducive to the application of pre-trained language models such as XLNet. To address this issue, we propose an all-in-one XLNet model, namely DialogXL, with enhanced memory to store longer historical context and dialog-aware self-attention to deal with the multi-party structures. Specifically, we first modify the recurrence mechanism of XLNet from segment-level to utterance-level in order to better model the conversational data. Second, we introduce dialog-aware self-attention in replacement of the vanilla self-attention in XLNet to capture useful intra- and inter-speaker dependencies. Extensive experiments are conducted on four ERC benchmarks with mainstream models presented for comparison. The experimental results show that the proposed model outperforms the baselines on all the datasets. Several other experiments such as ablation study and error analysis are also conducted and the results confirm the role of the critical modules of DialogXL.",2020.0,27.0,112.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/17625/17432', 'status': None}",{'pages': '13789-13797'},"{'bibtex': '@Inproceedings{Shen2020DialogXLAX,\n author = {Weizhou Shen and Junqing Chen and Xiaojun Quan and Zhixiang Xie},\n pages = {13789-13797},\n title = {DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition},\n year = {2020}\n}\n'}","[{'authorId': '74132442', 'name': 'Weizhou Shen'}, {'authorId': '2144130855', 'name': 'Junqing Chen'}, {'authorId': '38472218', 'name': 'Xiaojun Quan'}, {'authorId': '2114111909', 'name': 'Zhixiang Xie'}]"
2213,bed64dbbfcf4ab4260f3240e18d21750e83bc22e,Immersive Journalism: Immersive Virtual Reality for the First-Person Experience of News,"This paper introduces the concept and discusses the implications of immersive journalism, which is the production of news in a form in which people can gain first-person experiences of the events or situation described in news stories. The fundamental idea of immersive journalism is to allow the participant, typically represented as a digital avatar, to actually enter a virtually recreated scenario representing the news story. The sense of presence obtained through an immersive system (whether a Cave or head-tracked head-mounted displays [HMD] and online virtual worlds, such as video games and online virtual worlds) affords the participant unprecedented access to the sights and sounds, and possibly feelings and emotions, that accompany the news. This paper surveys current approaches to immersive journalism and the theoretical background supporting claims regarding avatar experience in immersive systems. We also provide a specific demonstration: giving participants the experience of being in an interrogation room in an offshore prison. By both describing current approaches and demonstrating an immersive journalism experience, we open a new avenue for research into how presence can be utilized in the field of news and nonfiction.",2010.0,35.0,351.0,True,"{'url': 'https://diposit.ub.edu/dspace/bitstream/2445/52803/1/631348.pdf', 'status': None}","{'volume': '19', 'pages': '291-301', 'name': 'PRESENCE: Teleoperators and Virtual Environments'}","{'bibtex': '@Article{Peña2010ImmersiveJI,\n author = {Nonny de la Peña and P. Weil and J. Llobera and Elias Giannopoulos and Ausiàs Pomés and B. Spanlang and D. Friedman and Maria V. Sanchez-Vives and M. Slater},\n journal = {PRESENCE: Teleoperators and Virtual Environments},\n pages = {291-301},\n title = {Immersive Journalism: Immersive Virtual Reality for the First-Person Experience of News},\n volume = {19},\n year = {2010}\n}\n'}","[{'authorId': '2913738', 'name': 'Nonny de la Peña'}, {'authorId': '40112757', 'name': 'P. Weil'}, {'authorId': '48334647', 'name': 'J. Llobera'}, {'authorId': '1855877', 'name': 'Elias Giannopoulos'}, {'authorId': '32246938', 'name': 'Ausiàs Pomés'}, {'authorId': '2891686', 'name': 'B. Spanlang'}, {'authorId': '144220013', 'name': 'D. Friedman'}, {'authorId': '1384107200', 'name': 'Maria V. Sanchez-Vives'}, {'authorId': '144931212', 'name': 'M. Slater'}]"
2214,bed7551bb0f97ff991b82d0aecedaa14a1ceca24,Factors predicting the use of technology: findings from the Center for Research and Education on Aging and Technology Enhancement (CREATE).,"The successful adoption of technology is becoming increasingly important to functional independence. The present article reports findings from the Center for Research and Education on Aging and Technology Enhancement (CREATE) on the use of technology among community-dwelling adults. The sample included 1,204 individuals ranging in age from 18-91 years. All participants completed a battery that included measures of demographic characteristics, self-rated health, experience with technology, attitudes toward computers, and component cognitive abilities. Findings indicate that the older adults were less likely than younger adults to use technology in general, computers, and the World Wide Web. The results also indicate that computer anxiety, fluid intelligence, and crystallized intelligence were important predictors of the use of technology. The relationship between age and adoption of technology was mediated by cognitive abilities, computer self-efficacy, and computer anxiety. These findings are discussed in terms of training strategies to promote technology adoption.",2006.0,71.0,1649.0,True,"{'url': 'https://europepmc.org/articles/pmc1524856?pdf=render', 'status': None}","{'volume': '21 2', 'pages': '\n          333-52\n        ', 'name': 'Psychology and aging'}","{'bibtex': '@Article{Czaja2006FactorsPT,\n author = {S. Czaja and N. Charness and A. D. Fisk and C. Hertzog and S. Nair and W. Rogers and J. Sharit},\n journal = {Psychology and aging},\n pages = {\n          333-52\n        },\n title = {Factors predicting the use of technology: findings from the Center for Research and Education on Aging and Technology Enhancement (CREATE).},\n volume = {21 2},\n year = {2006}\n}\n'}","[{'authorId': '1748503', 'name': 'S. Czaja'}, {'authorId': '7232085', 'name': 'N. Charness'}, {'authorId': '1689705', 'name': 'A. D. Fisk'}, {'authorId': '51895118', 'name': 'C. Hertzog'}, {'authorId': '2838714', 'name': 'S. Nair'}, {'authorId': '145912604', 'name': 'W. Rogers'}, {'authorId': '3238695', 'name': 'J. Sharit'}]"
2215,bf176c71dfaaba000f9f7605ecc532991bf4cca9,Multimedia interfaces for users with high functioning autism: An empirical investigation,,2008.0,31.0,133.0,False,,"{'volume': '66', 'pages': '628-639', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Grynszpan2008MultimediaIF,\n author = {O. Grynszpan and Jean-Claude Martin and J. Nadel},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {628-639},\n title = {Multimedia interfaces for users with high functioning autism: An empirical investigation},\n volume = {66},\n year = {2008}\n}\n'}","[{'authorId': '2791712', 'name': 'O. Grynszpan'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}, {'authorId': '2433022', 'name': 'J. Nadel'}]"
2216,bf4045307607f783ae8e22e805eed62c1c4e9b84,Principles of traditional animation applied to 3D computer animation,"This paper describes the basic principles of traditional 2D hand drawn animation and their application to 3D computer animation. After describing how these principles evolved, the individual principles are detailed, addressing their meanings in 2D hand drawn animation and their application to 3D computer animation. This should demonstrate the importance of these principles to quality 3D computer animation.",1987.0,28.0,709.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/37401.37407', 'status': None}",{'name': 'Proceedings of the 14th annual conference on Computer graphics and interactive techniques'},"{'bibtex': '@Article{Lasseter1987PrinciplesOT,\n author = {J. Lasseter},\n journal = {Proceedings of the 14th annual conference on Computer graphics and interactive techniques},\n title = {Principles of traditional animation applied to 3D computer animation},\n year = {1987}\n}\n'}","[{'authorId': '31781220', 'name': 'J. Lasseter'}]"
2217,bf8cadd5dc450f8e6d41dc95f3535c324401c508,Expression of the emotions in man,,1963.0,0.0,266.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Knapp1963ExpressionOT,\n author = {P. Knapp},\n title = {Expression of the emotions in man},\n year = {1963}\n}\n'}","[{'authorId': '70003799', 'name': 'P. Knapp'}]"
2218,bfa6eb0241c6968f178f00a35677fa3df30706a7,Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces,This paper explores how interaction with systems using touchless gestures can be made intuitive and natural. Analysis of 912 video clips of gesture production from a user study of 16 subjects communicating transitive actions (manipulation of objects with or without external tools) indicated that 1) dynamic pantomimic gestures where imagined tool/object is explicitly held are performed more intuitively and easily than gestures where a body part is used to represent the tool/object or compared to static hand poses and 2) gesturing while communicating the transitive action as how the user habitually performs the action (pantomimic action) is perceived to be easier and more natural than gesturing while communicating it as an instruction. These findings provide guidelines for the characteristics of gestures and user mental models one must consciously be concerned with when designing and implementing gesture vocabularies of touchless interaction.,2011.0,23.0,126.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Grandhi2011UnderstandingNA,\n author = {Sukeshini A. Grandhi and Gina Joue and I. Mittelberg},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces},\n year = {2011}\n}\n'}","[{'authorId': '2246337', 'name': 'Sukeshini A. Grandhi'}, {'authorId': '2988256', 'name': 'Gina Joue'}, {'authorId': '2076370', 'name': 'I. Mittelberg'}]"
2219,bfc96faaf8d52d5c96684dfc9ed7189596508018,Investigations into emotion regulation difficulties among adolescents and young adults with autism spectrum disorder: A qualitative study,"ABSTRACT Background Emotion regulation difficulties have been associated with depression and anxiety in typically developing individuals. However, until recently, the impact of emotion regulation difficulties for adolescents and young adults with autism spectrum disorder (ASD) has received little attention. We investigated emotion regulation difficulties from the perspective of those who would experience the sequelae. This included parents, teachers, and psychologists. Method Seven focus groups with parents, teachers, and psychologists, and 7 interviews with adolescents and young adults with ASD were conducted. Results Across the groups, participants discussed their triggers of distressing emotions, difficulties with emotional awareness, emotion regulation strategies, and the consequences of their distressing emotions. Both depression and anxiety were perceived as the most experienced distressing issues with the greatest consequences. Conclusions The implications of the themes revealed in the interviews and focus groups are discussed in light in previous literature and may help to inform future interventions.",2017.0,59.0,15.0,False,,"{'volume': '42', 'pages': '275 - 284', 'name': 'Journal of Intellectual & Developmental Disability'}","{'bibtex': '@Article{Santomauro2017InvestigationsIE,\n author = {D. Santomauro and J. Sheffield and K. Sofronoff},\n journal = {Journal of Intellectual & Developmental Disability},\n pages = {275 - 284},\n title = {Investigations into emotion regulation difficulties among adolescents and young adults with autism spectrum disorder: A qualitative study},\n volume = {42},\n year = {2017}\n}\n'}","[{'authorId': '6731644', 'name': 'D. Santomauro'}, {'authorId': '5316023', 'name': 'J. Sheffield'}, {'authorId': '4384768', 'name': 'K. Sofronoff'}]"
2220,bfd6b70fa91024a3ea9ba390f57fe903e42b5183,Can Virtual Human Build Rapport and Promote Learning?,"Research show that teacher's nonverbal immediacy can have a positive impact on student's cognitive learning and affect [3]. This paper investigates the effectiveness of nonverbal immediacy using a virtual human. The virtual human attempts to use immediacy feedback to create rapport with the learner. Results show that the virtual human established rapport with learners but did not help them achieve better learning results. The results also suggest that creating rapport is related to higher self-efficacy, and self-efficacy is related to better learning results.",2009.0,56.0,18.0,False,,{'pages': '737-739'},"{'bibtex': '@Inproceedings{Wang2009CanVH,\n author = {Ning Wang and J. Gratch},\n pages = {737-739},\n title = {Can Virtual Human Build Rapport and Promote Learning?},\n year = {2009}\n}\n'}","[{'authorId': '2152170419', 'name': 'Ning Wang'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2223,bfdbfe3bf703594b884ae69f505f94ce7e98141e,An argument for basic emotions,"Abstract Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each...",1992.0,94.0,7591.0,False,,"{'volume': '6', 'pages': '169-200', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Ekman1992AnAF,\n author = {P. Ekman},\n journal = {Cognition & Emotion},\n pages = {169-200},\n title = {An argument for basic emotions},\n volume = {6},\n year = {1992}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
2224,bff2e781c1b54f6d490fccf05b303291cf4655ec,Meta-Analysis of the Efficacy of Virtual Reality Exposure Therapy for Social Anxiety,"Abstract Social anxiety is a common, debilitating psychological problem. In the present study, two meta-analyses examined the efficacy of virtual reality exposure therapy for social anxiety. The first meta-analysis tested whether virtual reality exposure therapy reduces social anxiety more than a waitlist control condition. The results of the first meta-analysis, consisting of six studies and 233 participants, showed a significant overall effect size, indicating that virtual reality exposure therapy was effective in reducing social anxiety. The second meta-analysis tested whether the standard treatment for social anxiety, which includes in vivo or imaginal exposure, leads to greater effects than virtual reality exposure therapy. The second meta-analysis, consisting of seven studies and 340 total participants, showed essentially no difference in effect sizes between virtual reality exposure and in vivo or imaginal exposure. The results of the two meta-analyses support the use of virtual reality in the treatment of social anxiety.",2018.0,68.0,79.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/523AE3EAF14DD82FB614431421656FC5/S0813483918000153a.pdf/div-class-title-meta-analysis-of-the-efficacy-of-virtual-reality-exposure-therapy-for-social-anxiety-div.pdf', 'status': None}","{'volume': '35', 'pages': '152 - 166', 'name': 'Behaviour Change'}","{'bibtex': '@Article{Chesham2018MetaAnalysisOT,\n author = {Rachel K Chesham and J. Malouff and N. Schutte},\n journal = {Behaviour Change},\n pages = {152 - 166},\n title = {Meta-Analysis of the Efficacy of Virtual Reality Exposure Therapy for Social Anxiety},\n volume = {35},\n year = {2018}\n}\n'}","[{'authorId': '115557090', 'name': 'Rachel K Chesham'}, {'authorId': '5877808', 'name': 'J. Malouff'}, {'authorId': '5055848', 'name': 'N. Schutte'}]"
2225,bff9b22a96a49a35edd10f6a1cec04694cfdc79e,Towards Emotion-aided Multi-modal Dialogue Act Classification,"The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset- multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants.",2020.0,56.0,44.0,True,"{'url': 'https://www.aclweb.org/anthology/2020.acl-main.402.pdf', 'status': None}",{'pages': '4361-4372'},"{'bibtex': '@Inproceedings{Saha2020TowardsEM,\n author = {Tulika Saha and Aditya Patra and S. Saha and P. Bhattacharyya},\n pages = {4361-4372},\n title = {Towards Emotion-aided Multi-modal Dialogue Act Classification},\n year = {2020}\n}\n'}","[{'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '46561390', 'name': 'Aditya Patra'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
2226,c0292ef46a4bed4f8146a654983683a206295f1d,Photorealistic avatars to enhance the efficacy of Selfattachment psychotherapy,"We have designed, developed, and tested an Immersive virtual reality (VR) platform to practice the protocols of Self-attachment psychotherapy. We made use of customized photorealistic avatars for the implementation of both the high-end version (based on Facebook’s Oculus) and the low-end version (based on Google’s cardboard) of our platform. Under the Selfattachment therapeutic framework, the causes of mental disorders such as chronic anxiety and depression are traced back to the individual’s insecure attachment with their primary caregiver during childhood and their subsequent problems in affect regulation. The conventional approach (without VR) to Selfattachment requires that the individual uses their childhood photographs to recall their childhood memories and then imagine that the child that they were is present with them. They thus establish a compassionate relationship with their childhood self and then, using love songs and dancing, create an affectional bond with them. Their adult self subsequently role plays a good parent and interacts with their imagined childhood self to perform various developmental and re-parenting activities. The goal is to enhance their capacities for self-regulation of emotion, which can lead them into earning secure attachment. It is hypothesized that our immersive virtual reality platform – which enables the users to interact with their customized 3D photorealistic childhood avatar - offers either a better alternative or at least a complementary visual tool to the conventional imaginal approach to Self-attachment. The platform was developed in Unity 3D, a cross-platform game engine, and takes advantage of the itSeez3D Avatar SDK for generating a customized photorealistic 3D avatar head from a 2D childhood image of the user. The platform also offers facial and body animations for some of the basic emotional states such as Happy, Sad, Scared and Joyful and it allows modifications to the avatar body (height/ width) and clothing color. A study to compare the use of the avatar-based approach (VR) to Self-attachment with the conventional photo-based approach showed promising results. Almost 85% of the participants reported that their photorealistic childhood avatar in VR was more relatable than their childhood photos. Both low-end and high-end VR based approaches were unanimously reported to be more effective than the conventional imaginal approach. Participants reported that the high-end version of the VR platform was more realistic and immersive than the low-end mobile VR version.",2020.0,42.0,2.0,False,,"{'pages': '60-67', 'name': '2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)'}","{'bibtex': '@Article{Ghaznavi2020PhotorealisticAT,\n author = {I. Ghaznavi and Duncan Gillies and D. Nicholls and A. Edalat},\n journal = {2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},\n pages = {60-67},\n title = {Photorealistic avatars to enhance the efficacy of Selfattachment psychotherapy},\n year = {2020}\n}\n'}","[{'authorId': '2485535', 'name': 'I. Ghaznavi'}, {'authorId': '146493111', 'name': 'Duncan Gillies'}, {'authorId': '40054719', 'name': 'D. Nicholls'}, {'authorId': '1694989', 'name': 'A. Edalat'}]"
2227,c048797031d2fe53e4f8c9af8ce46952bed284cb,Emotion Regulation and Autism Spectrum Disorders: A Literature Review,,2017.0,21.0,3.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hurd2017EmotionRA,\n author = {Catherine R Hurd},\n title = {Emotion Regulation and Autism Spectrum Disorders: A Literature Review},\n year = {2017}\n}\n'}","[{'authorId': '114421967', 'name': 'Catherine R Hurd'}]"
2228,c05d2a7ed16e47f2ab2dd18435b7a0380b5041dd,Greta: a conversing socio-emotional agent,"To create socially aware virtual agents, we conduct research along two main research directions: 1) develop richer models of multimodal behaviors for the agent; 2) make the agent a more socially competent interlocutor.",2017.0,19.0,7.0,False,,{'name': 'Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents'},"{'bibtex': '@Article{Pelachaud2017GretaAC,\n author = {C. Pelachaud},\n journal = {Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents},\n title = {Greta: a conversing socio-emotional agent},\n year = {2017}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2229,c08b5a8338cdceae6d78b7108086e17d58c20b62,Younger and older users' recognition of virtual agent facial expressions,,2015.0,91.0,27.0,True,"{'url': 'https://europepmc.org/articles/pmc4331019?pdf=render', 'status': None}","{'volume': '75', 'pages': '\n          1-20\n        ', 'name': 'International journal of human-computer studies'}","{'bibtex': ""@Article{Beer2015YoungerAO,\n author = {Jenay M. Beer and Cory-Ann Smarr and A. D. Fisk and W. Rogers},\n journal = {International journal of human-computer studies},\n pages = {\n          1-20\n        },\n title = {Younger and older users' recognition of virtual agent facial expressions},\n volume = {75},\n year = {2015}\n}\n""}","[{'authorId': '1809740', 'name': 'Jenay M. Beer'}, {'authorId': '1963261', 'name': 'Cory-Ann Smarr'}, {'authorId': '1689705', 'name': 'A. D. Fisk'}, {'authorId': '145912604', 'name': 'W. Rogers'}]"
2231,c0d94c9c36c9ef2a850ae15303eef47dec4650a8,Experimental Methods for Inducing Basic Emotions: A Qualitative Review,"Experimental emotion inductions provide the strongest causal evidence of the effects of emotions on psychological and physiological outcomes. In the present qualitative review, we evaluated five common experimental emotion induction techniques: visual stimuli, music, autobiographical recall, situational procedures, and imagery. For each technique, we discuss the extent to which they induce six basic emotions: anger, disgust, surprise, happiness, fear, and sadness. For each emotion, we discuss the relative influences of the induction methods on subjective emotional experience and physiological responses (e.g., heart rate, blood pressure). Based on the literature reviewed, we make emotion-specific recommendations for induction methods to use in experiments.",2019.0,45.0,146.0,True,"{'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1754073917749016', 'status': None}","{'volume': '11', 'pages': '87 - 97', 'name': 'Emotion Review'}","{'bibtex': '@Article{Siedlecka2019ExperimentalMF,\n author = {E. Siedlecka and T. Denson},\n journal = {Emotion Review},\n pages = {87 - 97},\n title = {Experimental Methods for Inducing Basic Emotions: A Qualitative Review},\n volume = {11},\n year = {2019}\n}\n'}","[{'authorId': '5735685', 'name': 'E. Siedlecka'}, {'authorId': '2990169', 'name': 'T. Denson'}]"
2232,c0f2bdd626ce66f91e14a6af604f9a1f3355a6c1,Conversational Games‚ Belief Revision and Bayesian Networks,,1997.0,0.0,44.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Pulman1997ConversationalGB,\n author = {S. Pulman},\n title = {Conversational Games‚ Belief Revision and Bayesian Networks},\n year = {1997}\n}\n'}","[{'authorId': '50419262', 'name': 'S. Pulman'}]"
2233,c0f98b13fb62fcd49a389de541870d15bd3247be,Emotion and Adaptation,"Part I: BACKGROUND: About emotion Issues of research, classification and measurements Part II: THE COGNITIVE-MOTIVATIONAL-RELATIONAL THEORY: The person-environment relationship: motivation and coping Cognition and emotion Issues of causality Part III: INDIVIDUAL EMOTIONS: Goal incongruent (negative) emotions Goal congruent (positive) and problematic emotions Part IV: EMOTIONAL DEVELOPMENT: Individual development Social influence Part V: PRACTICAL APPLICATIONS: Emotions and health Implications for research, assessment, treatment and disease prevention References Index.",1991.0,0.0,5248.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lazarus1991EmotionAA,\n author = {R. Lazarus},\n title = {Emotion and Adaptation},\n year = {1991}\n}\n'}","[{'authorId': '5628684', 'name': 'R. Lazarus'}]"
2236,c1003dca00630d4d40fc5827ac2524fa5f31c9a8,What influences patients' medication adherence? Mental health nurse perspectives and a need for education and training.,"This paper explores the role of mental health nurses in medication adherence and their perspective of what influences patients' medication non-adherence. Forty-eight mental health nurses with active patient caseloads completed a comprehensive questionnaire assessing a number of variables related to medications, including whom they felt was primarily responsible for monitoring the side-effects of medication, their knowledge skills and confidence in dealing with medication adherence and their prior education and training in medication adherence strategies. Lack of patient insight was endorsed as the strongest influence on patient non-adherence. Over 84% of nurses indicated they did not have any prior education or training in medication adherence strategies. Implications of the findings for education and training and nurses' roles in supporting medication adherence are discussed.",2003.0,12.0,63.0,False,,"{'volume': '12 2', 'pages': '\n          148-52\n        ', 'name': 'International journal of mental health nursing'}","{'bibtex': ""@Article{Coombs2003WhatIP,\n author = {T. Coombs and F. Deane and Gordon Lambert and R. Griffiths},\n journal = {International journal of mental health nursing},\n pages = {\n          148-52\n        },\n title = {What influences patients' medication adherence? Mental health nurse perspectives and a need for education and training.},\n volume = {12 2},\n year = {2003}\n}\n""}","[{'authorId': '34812947', 'name': 'T. Coombs'}, {'authorId': '2882448', 'name': 'F. Deane'}, {'authorId': '152667497', 'name': 'Gordon Lambert'}, {'authorId': '143882489', 'name': 'R. Griffiths'}]"
2237,c10141ed6b04b5eea3da602e75e3ad1a08262ba1,Cognitive bias modification approaches to anxiety.,"Clinical anxiety disorders and elevated levels of anxiety vulnerability are characterized by cognitive biases, and this processing selectivity has been implicated in theoretical accounts of these conditions. We review research that has sought to evaluate the causal contributions such biases make to anxiety dysfunction and to therapeutically alleviate anxiety using cognitive-bias modification (CBM) procedures. After considering the purpose and nature of CBM methodologies, we show that variants designed to modify selective attention (CBM-A) or interpretation (CBM-I) have proven capable of reducing anxiety vulnerability and ameliorating dysfunctional anxiety. In addition to supporting the causal role of cognitive bias in anxiety vulnerability and dysfunction and illuminating the mechanisms that underpin such bias, the findings suggest that CBM procedures may have therapeutic promise within clinical settings. We discuss key issues within this burgeoning field of research and suggest future directions CBM research should take to maximize its theoretical and applied value.",2012.0,125.0,521.0,False,,"{'volume': '8', 'pages': '\n          189-217\n        ', 'name': 'Annual review of clinical psychology'}","{'bibtex': '@Article{MacLeod2012CognitiveBM,\n author = {C. MacLeod and A. Mathews},\n journal = {Annual review of clinical psychology},\n pages = {\n          189-217\n        },\n title = {Cognitive bias modification approaches to anxiety.},\n volume = {8},\n year = {2012}\n}\n'}","[{'authorId': '145934733', 'name': 'C. MacLeod'}, {'authorId': '1808296', 'name': 'A. Mathews'}]"
2238,c10d2d7d1fd68e6517a7360fdfca72b787405b67,Cross-cultural differences in recognizing affect from body posture,,2006.0,45.0,192.0,False,,"{'volume': '18', 'pages': '1371-1389', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Kleinsmith2006CrossculturalDI,\n author = {A. Kleinsmith and P. Ravindra De Silva and N. Bianchi-Berthouze},\n journal = {Interact. Comput.},\n pages = {1371-1389},\n title = {Cross-cultural differences in recognizing affect from body posture},\n volume = {18},\n year = {2006}\n}\n'}","[{'authorId': '2870739', 'name': 'A. Kleinsmith'}, {'authorId': '2223722359', 'name': 'P. Ravindra De Silva'}, {'authorId': '1398541310', 'name': 'N. Bianchi-Berthouze'}]"
2239,c113f8a477b2348b4b163a9a6fd420b8a826a435,Understanding the Psycho-Physiological Implications of Interaction With a Virtual Reality-Based System in Adolescents With Autism: A Feasibility Study,"Individuals with Autism are characterized by deficits in socialization and communication. In recent years several assistive technologies, e.g., Virtual Reality (VR), have been investigated to address the socialization deficits in these individuals. Presently available VR-based systems address various aspects of social communication in an isolated manner and without monitoring one's affective state such as, anxiety. However, in conventional observation-based therapy, a therapist adjusts the intervention paradigm by monitoring one's anxiety level. But, often these individuals have an inherent inability to explicitly express their anxiety thereby inducing limitations on conventional techniques. Physiological signals being continuously available and not directly impacted by these communication difficulties can be alternatively used as markers of one's anxiety level. In our research we aim at designing a Virtual-reality bAsed Social-communication Task (VAST) system that can address the various aspects of social communication, e.g., social context, subtle social cues, emotional expression, etc., in a cumulative and structured way. In addition, we augment this with a capability to use one's physiological signals as markers of one's anxiety level. In our preliminary feasibility study we investigate the potential of VAST to cause variations in one's performance and anxiety level that can be mapped from one's physiological indices.",2015.0,28.0,52.0,False,,"{'volume': '23', 'pages': '665-675', 'name': 'IEEE Transactions on Neural Systems and Rehabilitation Engineering'}","{'bibtex': '@Article{Kuriakose2015UnderstandingTP,\n author = {Selvia Kuriakose and U. Lahiri},\n journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},\n pages = {665-675},\n title = {Understanding the Psycho-Physiological Implications of Interaction With a Virtual Reality-Based System in Adolescents With Autism: A Feasibility Study},\n volume = {23},\n year = {2015}\n}\n'}","[{'authorId': '2388380', 'name': 'Selvia Kuriakose'}, {'authorId': '2393577', 'name': 'U. Lahiri'}]"
2240,c130cd3c5708df9034e4748742d944183b642595,Consistent Communication with Control,"We are seeking to outline a framework to create embodied agents with consistency both in terms of human actions and communications in general and individual humans in particular. Our goal is to drive this consistent behavior from internal or cognitive models of the agents. First, we describe channels of non-verbal communication and related research in embodied agents. We then describe cognitive processes that can be used to coordinate these channels of communication and create consistent behavior. Comments Postprint version. Presented at Workshop on Non-Verbal and Verbal Communicative Acts to Achieve Contextual Embodied Agents, Autonomous Agents 2001, 6 pages. This conference paper is available at ScholarlyCommons: http://repository.upenn.edu/hms/85 Consistent Communication with Control Jan M. Allbeck and Norman I. Badler Center for Human Modeling and Simulation University of Pennsylvania 200 S. 33rd St., Philadelphia, PA 19104-6389 allbeck@graphics.cis.upenn.edu",2001.0,30.0,15.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Allbeck2001ConsistentCW,\n author = {J. Allbeck and N. Badler},\n title = {Consistent Communication with Control},\n year = {2001}\n}\n'}","[{'authorId': '1855748', 'name': 'J. Allbeck'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
2241,c134bb64f1547baa693fd6593a8ae77bb5289b6a,Behavioral Neuroscience Methods Article,"setting that mirrors a real-life situation, but with, for example, the experimental design manipulating particular factors of interest in exposures of different groups of subjects to the experience. Here we argue that immersive virtual reality is especially interesting for the study of how people respond to violent incidents where a perpetrator attacks a victim. We are interested in the circumstances under which bystanders are likely to intervene in order to prevent harm to the victim. Immersive virtual reality provides an ecologically valid setting in which to study this issue while at the same time removing the problem of physical danger, and overcoming the many ethical issues involved in the study of violence. In the rest of this paper we fi rst briefl y review some of the literature relating to responses to violence in desktop based systems such as video games, before going on to describe what we mean by immersive virtual reality, and how this is profoundly different with respect to engaging people in realistic responses to virtual situations. Next we review one experiment where participants infl ict violence on virtual characters in immersive virtual reality, a reprise of the Stanley Milgram obedience experiments. Next we apply these ideas to new research that is using virtual reality to study bystander responses to violent incidents, and we describe some qualitative results from ongoing pilot studies. Finally we discuss recommendations for the use of virtual reality in the study of violence. Our experiments discussed in this paper have been approved by the UCL Research Ethics Committee.",,51.0,92.0,False,,,"{'bibtex': '@Misc{None,\n title = {Behavioral Neuroscience Methods Article}\n}\n'}",[]
2242,c151f144c2c0e8d3b176edaf2ce5369c7707bd31,Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health,"Mental illness is one of the most pressing public health issues of our time. While counseling and psychotherapy can be effective treatments, our knowledge about how to conduct successful counseling conversations has been limited due to lack of large-scale data with labeled outcomes of the conversations. In this paper, we present a large-scale, quantitative study on the discourse of text-message-based counseling conversations. We develop a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes. Applying techniques such as sequence-based conversation models, language model comparisons, message clustering, and psycholinguistics-inspired word frequency analyses, we discover actionable conversation strategies that are associated with better conversation outcomes.",2016.0,40.0,220.0,True,"{'url': 'http://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00111', 'status': None}","{'volume': '4', 'pages': '463 - 476', 'name': 'Transactions of the Association for Computational Linguistics'}","{'bibtex': '@Article{Althoff2016LargescaleAO,\n author = {Tim Althoff and Kevin Clark and J. Leskovec},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {463 - 476},\n title = {Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health},\n volume = {4},\n year = {2016}\n}\n'}","[{'authorId': '1745524', 'name': 'Tim Althoff'}, {'authorId': '144358401', 'name': 'Kevin Clark'}, {'authorId': '1702139', 'name': 'J. Leskovec'}]"
2243,c16f03480935ca2eb4cb55df1a06b071f32959f8,Mean value coordinates,,2003.0,17.0,1096.0,False,,"{'volume': '20', 'pages': '19-27', 'name': 'Comput. Aided Geom. Des.'}","{'bibtex': '@Article{Floater2003MeanVC,\n author = {M. Floater},\n journal = {Comput. Aided Geom. Des.},\n pages = {19-27},\n title = {Mean value coordinates},\n volume = {20},\n year = {2003}\n}\n'}","[{'authorId': '2548703', 'name': 'M. Floater'}]"
2244,c1ac0c8e52cad06a91c783606771ac320211a0a0,Cooperating with life-like interface agents,,1999.0,27.0,142.0,True,,"{'volume': '15', 'pages': '123-142', 'name': 'Computers in Human Behavior'}","{'bibtex': '@Article{Parise1999CooperatingWL,\n author = {Salvatore Parise and S. Kiesler and L. Sproull and Keith Waters},\n journal = {Computers in Human Behavior},\n pages = {123-142},\n title = {Cooperating with life-like interface agents},\n volume = {15},\n year = {1999}\n}\n'}","[{'authorId': '2622833', 'name': 'Salvatore Parise'}, {'authorId': '47198673', 'name': 'S. Kiesler'}, {'authorId': '2198165', 'name': 'L. Sproull'}, {'authorId': '150179849', 'name': 'Keith Waters'}]"
2245,c1e2274bcc01d860af5f8e6d8ceb75c836d9c058,Multilingual emotion classification using supervised learning: Comparative experiments,,2017.0,56.0,41.0,False,,"{'volume': '53', 'pages': '684-704', 'name': 'Inf. Process. Manag.'}","{'bibtex': '@Article{Becker2017MultilingualEC,\n author = {Karin Becker and V. Moreira and Aline G. L. dos Santos},\n journal = {Inf. Process. Manag.},\n pages = {684-704},\n title = {Multilingual emotion classification using supervised learning: Comparative experiments},\n volume = {53},\n year = {2017}\n}\n'}","[{'authorId': '49629811', 'name': 'Karin Becker'}, {'authorId': '35052246', 'name': 'V. Moreira'}, {'authorId': '144510739', 'name': 'Aline G. L. dos Santos'}]"
2246,c1f0eee9e0ef6052beb5e7e2b3aede2a4437bf52,Context-aware Natural Language Generation for Spoken Dialogue Systems,"Natural language generation (NLG) is an important component of question answering(QA) systems which has a significant impact on system quality. Most tranditional QA systems based on templates or rules tend to generate rigid and stylised responses without the natural variation of human language. Furthermore, such methods need an amount of work to generate the templates or rules. To address this problem, we propose a Context-Aware LSTM model for NLG. The model is completely driven by data without manual designed templates or rules. In addition, the context information, including the question to be answered, semantic values to be addressed in the response, and the dialogue act type during interaction, are well approached in the neural network model, which enables the model to produce variant and informative responses. The quantitative evaluation and human evaluation show that CA-LSTM obtains state-of-the-art performance.",2016.0,22.0,23.0,False,,{'pages': '2032-2041'},"{'bibtex': '@Inproceedings{Zhou2016ContextawareNL,\n author = {Hao Zhou and Minlie Huang and Xiaoyan Zhu},\n pages = {2032-2041},\n title = {Context-aware Natural Language Generation for Spoken Dialogue Systems},\n year = {2016}\n}\n'}","[{'authorId': '144751955', 'name': 'Hao Zhou'}, {'authorId': '1730108', 'name': 'Minlie Huang'}, {'authorId': '145213540', 'name': 'Xiaoyan Zhu'}]"
2247,c1faf90821d6d9c3a445d472c145f13c1e19143f,Conditioned emotional reactions,"If the theory advanced by Watson and Morgan (in 'Emotional Reactions and Psychological Experimentation,' American Journal of Psychology, April, 1917, Vol. 28, pp. 163-174) to the effect that in infancy the original emotional reaction patterns are few, consisting so far as observed of fear, rage and love, then there must be some simple method by means of which the range of stimuli which can call out these emotions and their compounds is greatly increased. Otherwise, complexity in adult response could not be accounted for. These authors without adequate experimental evidence advanced the view that this range was increased by means of conditioned reflex factors. It was suggested there that the early home life of the child furnishes a laboratory situation for establishing conditioned emotional responses. The present authors present their experimental findings of conditioned fear responses in a male infant beginning at 11 months of age. (PsycINFO Database Record (c) 2012 APA, all rights reserved)",1920.0,0.0,1743.0,True,"{'url': 'https://pure.mpg.de/pubman/item/item_2404117_3/component/file_2404116/Watsob_Rayner_1929_Conditioned.pdf', 'status': None}","{'volume': '3', 'pages': '1-14', 'name': 'Journal of Experimental Psychology'}","{'bibtex': '@Article{Watson1920ConditionedER,\n author = {J. Watson and R. Rayner},\n journal = {Journal of Experimental Psychology},\n pages = {1-14},\n title = {Conditioned emotional reactions},\n volume = {3},\n year = {1920}\n}\n'}","[{'authorId': '145762127', 'name': 'J. Watson'}, {'authorId': '144984026', 'name': 'R. Rayner'}]"
2248,c22c01aa1deff3ce97180fe697b243cda3d3b60f,"Research-Based Design of Pedagogical Agent Roles: a Review, Progress, and Recommendations",,2016.0,68.0,115.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s40593-015-0055-y.pdf', 'status': None}","{'volume': '26', 'pages': '160-169', 'name': 'International Journal of Artificial Intelligence in Education'}","{'bibtex': '@Article{Kim2016ResearchBasedDO,\n author = {Yanghee Kim and A. L. Baylor},\n journal = {International Journal of Artificial Intelligence in Education},\n pages = {160-169},\n title = {Research-Based Design of Pedagogical Agent Roles: a Review, Progress, and Recommendations},\n volume = {26},\n year = {2016}\n}\n'}","[{'authorId': '32964910', 'name': 'Yanghee Kim'}, {'authorId': '25550816', 'name': 'A. L. Baylor'}]"
2251,c25526ad368ac02386f028962d8a00f8e94f956a,A critique of cross-lagged correlation,"Comments that cross-lagged correlation (CLC) is not a useful procedure for the analysis of longitudinal panel data. In particular, the difference between CLCs is not a sound basis for causal inference. Demonstrations of the failure of CLC are based mainly on results for the 2-wave, 2-variable longit",1980.0,33.0,624.0,False,,"{'volume': '88', 'pages': '245-258', 'name': 'Psychological Bulletin'}","{'bibtex': '@Article{Rogosa1980ACO,\n author = {D. Rogosa},\n journal = {Psychological Bulletin},\n pages = {245-258},\n title = {A critique of cross-lagged correlation},\n volume = {88},\n year = {1980}\n}\n'}","[{'authorId': '32127380', 'name': 'D. Rogosa'}]"
2252,c2617b8b6632e8f3349e90bc37c2f2cc9a192190,What can head and facial movements convey about positive and negative affect?,"We investigated whether the dynamics of head and facial movements apart from specific facial expressions communicate affect in infants. Age-appropriate tasks were used to elicit positive and negative affect in 28 ethnically diverse 12-month-old infants. 3D head and facial movements were tracked from 2D video. Strong effects were found for both head and facial movements. For head movement, angular velocity and angular acceleration of pitch, yaw, and roll were higher during negative relative to positive affect. For facial movement, displacement, velocity, and acceleration also increased during negative relative to positive affect. Our results suggest that the dynamics of head and facial movements communicate affect at ages as young as 12 months. These findings deepen our understanding of emotion communication and provide a basis for studying individual differences in emotion in socio-emotional development.",2015.0,35.0,15.0,False,,"{'pages': '281-287', 'name': '2015 International Conference on Affective Computing and Intelligent Interaction (ACII)'}","{'bibtex': '@Article{Hammal2015WhatCH,\n author = {Z. Hammal and J. Cohn and C. Heike and M. Speltz},\n journal = {2015 International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {281-287},\n title = {What can head and facial movements convey about positive and negative affect?},\n year = {2015}\n}\n'}","[{'authorId': '1785007', 'name': 'Z. Hammal'}, {'authorId': '1737918', 'name': 'J. Cohn'}, {'authorId': '1811221', 'name': 'C. Heike'}, {'authorId': '2706570', 'name': 'M. Speltz'}]"
2253,c263083aa7d9e95e4be451b9c221162aa922bf4a,"Virtual Intimacy, this little something between us: A study about Human perception of intimate behaviors in Embodied Conversational Agents","Building a long-term relationship between human and virtual agent remains a challenge. This paper explores the influence of intimate behavioral cues and the impact of different interaction modalities (voice, text, gesture) on our perception of intimacy. We built a virtual Tourism Information (TI) counselor capable of intimate behaviors based on grounded theories of intimacy developed in psychology. We studied how external observers perceive the social behaviors of the agent during its interactions with a human tourist. Our originality is to evaluate the perception of social skills across the interaction. Our results show that nonverbal behaviors of the virtual agent reinforces the impact of verbal cues on human perception on virtual intimacy. Findings also suggest that textual medium of communication has a negative impact on the perception of virtual intimacy, whatever the level of animation and intimacy exhibited by the TI counselor.",2018.0,27.0,15.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-03195489/file/IVA2018%20%281%29.pdf', 'status': None}",{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Potdevin2018VirtualIT,\n author = {D. Potdevin and C. Clavel and N. Sabouret},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {Virtual Intimacy, this little something between us: A study about Human perception of intimate behaviors in Embodied Conversational Agents},\n year = {2018}\n}\n'}","[{'authorId': '51898243', 'name': 'D. Potdevin'}, {'authorId': '1724799', 'name': 'C. Clavel'}, {'authorId': '1731432', 'name': 'N. Sabouret'}]"
2254,c28bd8193f89554205c887443d7836130d48e244,Thespian: a decision-theoretic framework for interactive narratives,"With the rapid development of computer technology, a new form of media – interactive narrative has received increasing attention. Interactive narrative allows the user to participate in a dynamically unfolding story, by playing a character or by exerting directorial control. By allowing the user to interact, interactive narrative provides a richer and potentially more engaging experience than traditional narrative. Moreover, because different choices of the user lead to different paths through the story, the author of interactive narrative can tailor the experience for the user or user groups. 
The design of interactive narrative faces many challenges. The central challenge comes from the integration of interactivity into the narrative. Instead of presenting one well-crafted static story, the author has to design the characters' behaviors along many paths through the story in response to possible user interactions. The amount of work can easily overwhelm an author. 
In this thesis, I present a multi-agent approach to modeling and simulating interactive narrative, implemented as the Thespian framework. Thespian utilizes a two-layer runtime system to drive the characters' interactions with the user. At the base is a multi-agent system comprised of goal-oriented autonomous agents that realize the characters in the story. Above this layer is a proactive director agent that continuously monitors the progress of the story and directs the characters toward the author's plot design goals. In addition to the two-layer runtime system, Thespian contains offline authoring procedures to facilitate the author in configuring the characters. 
The evaluation of the Thespian framework has been performed at different levels. Various components within Thespian have been individually evaluated or validated. In addition, Thespian's generality in practice for authoring a range of stories has been demonstrated through its many applications in different domains.",2010.0,0.0,11.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Marsella2010ThespianAD,\n author = {S. Marsella and Mei Si},\n title = {Thespian: a decision-theoretic framework for interactive narratives},\n year = {2010}\n}\n'}","[{'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '33432486', 'name': 'Mei Si'}]"
2255,c2bcef09c15dc2b9df40630bf8af2ab387cec598,Emergency crowd simulation for outdoor environments,,2010.0,25.0,38.0,True,"{'url': 'http://repository.bilkent.edu.tr/bitstream/11693/22380/1/Emergency%20crowd%20simulation%20for%20outdoor%20environments.pdf', 'status': None}","{'volume': '34', 'pages': '136-144', 'name': 'Comput. Graph.'}","{'bibtex': '@Article{Oguz2010EmergencyCS,\n author = {O. Oguz and A. Akaydin and T. Yilmaz and U. Güdükbay},\n journal = {Comput. Graph.},\n pages = {136-144},\n title = {Emergency crowd simulation for outdoor environments},\n volume = {34},\n year = {2010}\n}\n'}","[{'authorId': '2264449', 'name': 'O. Oguz'}, {'authorId': '50495312', 'name': 'A. Akaydin'}, {'authorId': '2060192299', 'name': 'T. Yilmaz'}, {'authorId': '1746035', 'name': 'U. Güdükbay'}]"
2256,c2d4a6e4900ec0f096c87bb2b1272eeceaa584a6,Labeling images with a computer game,"We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.",2004.0,21.0,2472.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Ahn2004LabelingIW,\n author = {Luis von Ahn and Laura A. Dabbish},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Labeling images with a computer game},\n year = {2004}\n}\n'}","[{'authorId': '3328108', 'name': 'Luis von Ahn'}, {'authorId': '1784365', 'name': 'Laura A. Dabbish'}]"
2257,c2f441a578c1f2a5d147d3ac378454839a6cb217,Are there basic emotions?,"Ortony and Turner's (1990) arguments against those who adopt the view that there are basic emotions are challenged. The evidence on universals in expression and in physiology strongly suggests that there is a biological basis to the emotions that have been studied. Ortony and Turner's reviews of this literature are faulted, and their alternative theoretical explanations do not fit the evidence. The utility of the basic emotions approach is also shown in terms of the research it has generated.",1992.0,35.0,1804.0,False,,"{'volume': '99 3', 'pages': '\n          550-3\n        ', 'name': 'Psychological review'}","{'bibtex': '@Article{Ekman1992AreTB,\n author = {P. Ekman},\n journal = {Psychological review},\n pages = {\n          550-3\n        },\n title = {Are there basic emotions?},\n volume = {99 3},\n year = {1992}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
2260,c3073dc2bc514b8574c7be81cdf77b061e3b5c8a,Emotion recognition via facial expression and affective prosody in schizophrenia: a methodological review.,,2002.0,131.0,748.0,False,,"{'volume': '22 6', 'pages': '\n          789-832\n        ', 'name': 'Clinical psychology review'}","{'bibtex': '@Article{Edwards2002EmotionRV,\n author = {J. Edwards and H. Jackson and P. Pattison},\n journal = {Clinical psychology review},\n pages = {\n          789-832\n        },\n title = {Emotion recognition via facial expression and affective prosody in schizophrenia: a methodological review.},\n volume = {22 6},\n year = {2002}\n}\n'}","[{'authorId': '20389638', 'name': 'J. Edwards'}, {'authorId': '52580977', 'name': 'H. Jackson'}, {'authorId': '1694662', 'name': 'P. Pattison'}]"
2261,c3251e77adef7cb777c070e3cd0ce067ab17cce3,Virtual Rapport,,2006.0,28.0,252.0,False,,{'pages': '14-27'},"{'bibtex': '@Inproceedings{Gratch2006VirtualR,\n author = {Jonathan Gratch and Anya Okhmatovskaia and Francois Lamothe and Stacy Marsella and Mathieu Morales and Rick J. van der Werf and Louis-Philippe Morency},\n pages = {14-27},\n title = {Virtual Rapport},\n year = {2006}\n}\n'}","[{'authorId': '2064713461', 'name': 'Jonathan Gratch'}, {'authorId': '2079253023', 'name': 'Anya Okhmatovskaia'}, {'authorId': '2058678290', 'name': 'Francois Lamothe'}, {'authorId': '2066069570', 'name': 'Stacy Marsella'}, {'authorId': '2067580497', 'name': 'Mathieu Morales'}, {'authorId': '2097196392', 'name': 'Rick J. van der Werf'}, {'authorId': '2065275646', 'name': 'Louis-Philippe Morency'}]"
2264,c328d6681aa7b44fe0f3a7a2f40e591e347b68c5,Rapid perceptual integration of facial expression and emotional body language.,"In our natural world, a face is usually encountered not as an isolated object but as an integrated part of a whole body. The face and the body both normally contribute in conveying the emotional state of the individual. Here we show that observers judging a facial expression are strongly influenced by emotional body language. Photographs of fearful and angry faces and bodies were used to create face-body compound images, with either matched or mismatched emotional expressions. When face and body convey conflicting emotional information, judgment of facial expression is hampered and becomes biased toward the emotion expressed by the body. Electrical brain activity was recorded from the scalp while subjects attended to the face and judged its emotional expression. An enhancement of the occipital P1 component as early as 115 ms after presentation onset points to the existence of a rapid neural mechanism sensitive to the degree of agreement between simultaneously presented facial and bodily emotional expressions, even when the latter are unattended.",2005.0,56.0,644.0,True,"{'url': 'https://europepmc.org/articles/pmc1283446?pdf=render', 'status': None}","{'volume': '102 45', 'pages': '\n          16518-23\n        ', 'name': 'Proceedings of the National Academy of Sciences of the United States of America'}","{'bibtex': '@Article{Meeren2005RapidPI,\n author = {H. Meeren and Corné C R J van Heijnsbergen and B. de Gelder},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {\n          16518-23\n        },\n title = {Rapid perceptual integration of facial expression and emotional body language.},\n volume = {102 45},\n year = {2005}\n}\n'}","[{'authorId': '6702631', 'name': 'H. Meeren'}, {'authorId': '4002418', 'name': 'Corné C R J van Heijnsbergen'}, {'authorId': '4628064', 'name': 'B. de Gelder'}]"
2265,c338d8336f9fb8afa4a1d827ce4152180ee5bab1,Development of a Real-Time Emotion Recognition System Using Facial Expressions and EEG based on machine learning and deep neural network methods,,2020.0,33.0,102.0,True,,{'name': 'Informatics in Medicine Unlocked'},"{'bibtex': '@Article{Hassouneh2020DevelopmentOA,\n author = {Aya Hassouneh and A. Mutawa and M. Murugappan},\n journal = {Informatics in Medicine Unlocked},\n title = {Development of a Real-Time Emotion Recognition System Using Facial Expressions and EEG based on machine learning and deep neural network methods},\n year = {2020}\n}\n'}","[{'authorId': '1419352888', 'name': 'Aya Hassouneh'}, {'authorId': '145431335', 'name': 'A. Mutawa'}, {'authorId': '145164247', 'name': 'M. Murugappan'}]"
2266,c36fa9d48a49a19a40f1f21d14034c29c2ffd531,Driver Behavior Modeling Using Game Engine and Real Vehicle: A Learning-Based Approach,"As a good example of Advanced Driver-Assistance Systems (ADAS), Advisory Speed Assistance (ASA) helps improve driving safety and possibly energy efficiency by showing advisory speed to the driver of an intelligent vehicle. However, driver-based speed tracking errors often emerge, due to the perception and reaction delay, as well as imperfect vehicle control, degrading the effectiveness of ASA system. In this study, we propose a learning-based approach to modeling driver behavior, aiming to predict and compensate for the speed tracking errors in real time. Subject drivers are first classified into different types according to their driving behaviors using the k-nearest neighbors (k-NN) algorithm. A nonlinear autoregressive (NAR) neural network is then adopted to predict the speed tracking errors generated by each driver. A specific traffic scenario has been created in a Unity game engine-based driving simulator platform, where ASA system provides advisory driving speed to the driver via a head-up display (HUD). A human-in-the-loop simulation study is conducted by 17 volunteer drivers, revealing a 53% reduction in the speed error variance and a 3% reduction in the energy consumption with the compensation of the speed tracking errors. The results are further validated by a field implementation with a real passenger vehicle.",2020.0,44.0,45.0,False,,"{'volume': '5', 'pages': '738-749', 'name': 'IEEE Transactions on Intelligent Vehicles'}","{'bibtex': '@Article{Wang2020DriverBM,\n author = {Ziran Wang and Xishun Liao and Chao Wang and David Oswald and Guoyuan Wu and K. Boriboonsomsin and M. Barth and Kyungtae Han and Baekgyu Kim and Prashant Tiwari},\n journal = {IEEE Transactions on Intelligent Vehicles},\n pages = {738-749},\n title = {Driver Behavior Modeling Using Game Engine and Real Vehicle: A Learning-Based Approach},\n volume = {5},\n year = {2020}\n}\n'}","[{'authorId': '4141749', 'name': 'Ziran Wang'}, {'authorId': '1490892140', 'name': 'Xishun Liao'}, {'authorId': '2144448003', 'name': 'Chao Wang'}, {'authorId': '2055994840', 'name': 'David Oswald'}, {'authorId': '2222213', 'name': 'Guoyuan Wu'}, {'authorId': '2871648', 'name': 'K. Boriboonsomsin'}, {'authorId': '1773036', 'name': 'M. Barth'}, {'authorId': '152152987', 'name': 'Kyungtae Han'}, {'authorId': '1771227', 'name': 'Baekgyu Kim'}, {'authorId': '152688641', 'name': 'Prashant Tiwari'}]"
2267,c3e104240e03dda9cb5f2514f123e6ef0b30e942,Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning,"Emotion recognition has become an important field of research in Human Computer Interactions as we improve upon the techniques for modelling the various aspects of behaviour. With the advancement of technology our understanding of emotions are advancing, there is a growing need for automatic emotion recognition systems. One of the directions the research is heading is the use of Neural Networks which are adept at estimating complex functions that depend on a large number and diverse source of input data. In this paper we attempt to exploit this effectiveness of Neural networks to enable us to perform multimodal Emotion recognition on IEMOCAP dataset using data from Speech, Text, and Motion capture data from face expressions, rotation and hand movements. Prior research has concentrated on Emotion detection from Speech on the IEMOCAP dataset, but our approach is the first that uses the multiple modes of data offered by IEMOCAP for a more robust and accurate emotion detection.",2018.0,22.0,2.0,False,,"{'volume': 'abs/1804.05788', 'name': 'ArXiv'}","{'bibtex': '@Article{Tripathi2018MultiModalER,\n author = {Samarth Tripathi and H. Beigi},\n journal = {ArXiv},\n title = {Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning},\n volume = {abs/1804.05788},\n year = {2018}\n}\n'}","[{'authorId': '2265542260', 'name': 'Samarth Tripathi'}, {'authorId': '144396601', 'name': 'H. Beigi'}]"
2268,c3f372c32e721c861d51c0ff78542e01de9f1560,"Reprint of: Mahalanobis, P.C. (1936) ""On the Generalised Distance in Statistics.""",,2018.0,1.0,750.0,False,,"{'volume': '80', 'pages': '1 - 7', 'name': 'Sankhya A'}","{'bibtex': '@Article{None,\n journal = {Sankhya A},\n pages = {1 - 7},\n title = {Reprint of: Mahalanobis, P.C. (1936) ""On the Generalised Distance in Statistics.""},\n volume = {80},\n year = {2018}\n}\n'}",[]
2269,c405b80956885e08671e3ef92a57092211500504,"Children, Adolescents, and the Media","Communications research has come a long way since the 1954 Senate hearings that tried to determine if juvenile delinquency is linked to media violence. Unfortunately, the entertainment industry, the advertising industry, schools, parents, and the federal government have not followed suit. Media seem to be just as misunderstood now as they were 60 years ago. Many people simply don’t “buy” the idea that the media have any impact on child and adolescent health or behavior. And try as hard as we media researchers and public health advocates, we seem unable to do anything about it. To be scrupulously honest, part of the problem is probably ours—we have failed to effectively communicate our knowledge to everyone else. We are smart, but we are not that smart; and we have made mistakes. Only by examining those mistakes can we become more effective in the future.",2016.0,28.0,447.0,False,,"{'volume': '55', 'pages': '509 - 512', 'name': 'Clinical Pediatrics'}","{'bibtex': '@Article{Strasburger2016ChildrenAA,\n author = {V. Strasburger},\n journal = {Clinical Pediatrics},\n pages = {509 - 512},\n title = {Children, Adolescents, and the Media},\n volume = {55},\n year = {2016}\n}\n'}","[{'authorId': '6370151', 'name': 'V. Strasburger'}]"
2270,c432b9a9307212f85672bb3981fa0ef429928d24,Understanding and Predicting Bonding in Conversations Using Thin Slices of Facial Expressions and Body Language,,2016.0,22.0,35.0,True,"{'url': 'https://dspace.mit.edu/bitstream/1721.1/138086/2/understanding-predicting-bonding-CameraReady.pdf', 'status': None}",{'pages': '64-74'},"{'bibtex': '@Inproceedings{Jaques2016UnderstandingAP,\n author = {Natasha Jaques and Daniel J. McDuff and Y. Kim and Rosalind W. Picard},\n pages = {64-74},\n title = {Understanding and Predicting Bonding in Conversations Using Thin Slices of Facial Expressions and Body Language},\n year = {2016}\n}\n'}","[{'authorId': '3106683', 'name': 'Natasha Jaques'}, {'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '2117904670', 'name': 'Y. Kim'}, {'authorId': '1719389', 'name': 'Rosalind W. Picard'}]"
2271,c4688cf894ddc7b274aca0819f3386785e38f6f7,Understanding and sharing intentions: The origins of cultural cognition,"We propose that the crucial difference between human cognition and that of other species is the ability to participate with others in collaborative activities with shared goals and intentions: shared intentionality. Participation in such activities requires not only especially powerful forms of intention reading and cultural learning, but also a unique motivation to share psychological states with others and unique forms of cognitive representation for doing so. The result of participating in these activities is species-unique forms of cultural cognition and evolution, enabling everything from the creation and use of linguistic symbols to the construction of social norms and individual beliefs to the establishment of social institutions. In support of this proposal we argue and present evidence that great apes (and some children with autism) understand the basics of intentional action, but they still do not participate in activities involving joint intentions and attention (shared intentionality). Human children's skills of shared intentionality develop gradually during the first 14 months of life as two ontogenetic pathways intertwine: (1) the general ape line of understanding others as animate, goal-directed, and intentional agents; and (2) a species-unique motivation to share emotions, experience, and activities with other persons. The developmental outcome is children's ability to construct dialogic cognitive representations, which enable them to participate in earnest in the collectivity that is human cognition.",2005.0,475.0,3751.0,False,,"{'volume': '28', 'pages': '675 - 691', 'name': 'Behavioral and Brain Sciences'}","{'bibtex': '@Article{Tomasello2005UnderstandingAS,\n author = {M. Tomasello and M. Carpenter and J. Call and Tanya Behne and Henrike Moll},\n journal = {Behavioral and Brain Sciences},\n pages = {675 - 691},\n title = {Understanding and sharing intentions: The origins of cultural cognition},\n volume = {28},\n year = {2005}\n}\n'}","[{'authorId': '2534361', 'name': 'M. Tomasello'}, {'authorId': '5473468', 'name': 'M. Carpenter'}, {'authorId': '1945385', 'name': 'J. Call'}, {'authorId': '5073625', 'name': 'Tanya Behne'}, {'authorId': '47380094', 'name': 'Henrike Moll'}]"
2272,c51027f7e93ea54102130a8394f863c1a80a7918,A Personality Model based on Reiss Motivational Profile f or Autonomous Digital Actors,"The creation of a believable agent depends on several factors, one of the most important is personality. This paper presents a proposal for the development of a computational metaphor for autonomous digital actors that includes a personality component, in order to make their behavior individualized and coherent. Through the study of personality theories and their assessment instruments, we propose a model that considers personality, both in terms of its description and its dynamics. Using this model, it is expected that digital actors react in a coherent and individualized way to a given dramatic situation.",2012.0,15.0,2.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ramos2012APM,\n author = {Ricardo Filipe Pereira Ramos and Juliane Cristine and Koerber Reis},\n title = {A Personality Model based on Reiss Motivational Profile f or Autonomous Digital Actors},\n year = {2012}\n}\n'}","[{'authorId': '113583485', 'name': 'Ricardo Filipe Pereira Ramos'}, {'authorId': '115488349', 'name': 'Juliane Cristine'}, {'authorId': '115834192', 'name': 'Koerber Reis'}]"
2273,c52a8645c3dd08eeab89c4578db4dccc4a9e1ec5,Dynamic Facial Emotion Recognition Oriented to HCI Applications,"As part of a multimodal animated interface previously presented in [38], in this paper we describe a method for dynamic recognition of displayed facial emotions on low resolution streaming images. First, we address the detection of Action Units of the Facial Action Coding System upon Active Shape Models and Gabor filters. Normalized outputs of the Action Unit recognition step are then used as inputs for a neural network which is based on real cognitive systems architecture, and consists on a habituation network plus a competitive network. Both the competitive and the habituation layer use differential equations thus taking into account the dynamic information of facial expressions through time. Experimental results carried out on live video sequences and on the Cohn-Kanade face database show that the proposed method provides high recognition hit rates.",2015.0,47.0,16.0,True,"{'url': 'https://uvadoc.uva.es/bitstream/10324/21061/1/Dynamic-facial-emotion-recognition-preprint.pdf', 'status': None}","{'volume': '27', 'pages': '99-119', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Marcos2015DynamicFE,\n author = {Samuel Marcos and J. García-Bermejo and E. Casanova and Joaquín López},\n journal = {Interact. Comput.},\n pages = {99-119},\n title = {Dynamic Facial Emotion Recognition Oriented to HCI Applications},\n volume = {27},\n year = {2015}\n}\n'}","[{'authorId': '2021385', 'name': 'Samuel Marcos'}, {'authorId': '1399011929', 'name': 'J. García-Bermejo'}, {'authorId': '35499533', 'name': 'E. Casanova'}, {'authorId': '143815467', 'name': 'Joaquín López'}]"
2274,c539cba11a68789d9c12a2245ac6a5cc81b53e31,A Novel Integrated System of Visual Communication and Touch Technology for People with Disabilities,,2016.0,16.0,8.0,False,,{'pages': '509-518'},"{'bibtex': '@Inproceedings{Kerdvibulvech2016ANI,\n author = {C. Kerdvibulvech},\n pages = {509-518},\n title = {A Novel Integrated System of Visual Communication and Touch Technology for People with Disabilities},\n year = {2016}\n}\n'}","[{'authorId': '1824649', 'name': 'C. Kerdvibulvech'}]"
2275,c547e1f79e6039d05c5ae433a36612d7f8e4d3f5,STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving,,1971.0,21.0,6072.0,False,,"{'volume': '2', 'pages': '189-208', 'name': 'Artif. Intell.'}","{'bibtex': '@Article{Fikes1971STRIPSAN,\n author = {R. Fikes and N. Nilsson},\n journal = {Artif. Intell.},\n pages = {189-208},\n title = {STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving},\n volume = {2},\n year = {1971}\n}\n'}","[{'authorId': '1748956', 'name': 'R. Fikes'}, {'authorId': '144497046', 'name': 'N. Nilsson'}]"
2276,c54d39571ba78094aa8fe0f04dbc3fa6d23e41d6,Enhancing Emotion Recognition in Children with Autism Spectrum Conditions: An Intervention Using Animated Vehicles with Real Emotional Faces,,2010.0,74.0,415.0,False,,"{'volume': '40', 'pages': '269-279', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Golan2010EnhancingER,\n author = {O. Golan and E. Ashwin and Y. Granader and S. McClintock and K. Day and V. Leggett and S. Baron-Cohen},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {269-279},\n title = {Enhancing Emotion Recognition in Children with Autism Spectrum Conditions: An Intervention Using Animated Vehicles with Real Emotional Faces},\n volume = {40},\n year = {2010}\n}\n'}","[{'authorId': '2100443', 'name': 'O. Golan'}, {'authorId': '2759475', 'name': 'E. Ashwin'}, {'authorId': '5011339', 'name': 'Y. Granader'}, {'authorId': '4406821', 'name': 'S. McClintock'}, {'authorId': '2071486805', 'name': 'K. Day'}, {'authorId': '4408318', 'name': 'V. Leggett'}, {'authorId': '1390019127', 'name': 'S. Baron-Cohen'}]"
2277,c556ed80eb0453ba3001469f70e738bc541fc727,Video Gaming with Emotion-Expressive Virtual Rival Agent,,2019.0,0.0,0.0,False,,"{'name': '', 'pages': '79-80', 'volume': '119'}","{'bibtex': '@Inproceedings{Shinsuke2019VideoGW,\n author = {Kiyomoto Shinsuke and Takashio Kazunori},\n pages = {79-80},\n title = {Video Gaming with Emotion-Expressive Virtual Rival Agent},\n volume = {119},\n year = {2019}\n}\n'}","[{'authorId': '1583801483', 'name': 'Kiyomoto Shinsuke'}, {'authorId': '66161924', 'name': 'Takashio Kazunori'}]"
2278,c57f50d09b9b92a4d3725197ad5ae332d2db7cf6,Fast Emotion Recognition Based on Single Pulse PPG Signal with Convolutional Neural Network,"Physiological signals contain considerable information regarding emotions. This paper investigated the ability of photoplethysmogram (PPG) signals to recognize emotion, adopting a two-dimensional emotion model based on valence and arousal to represent human feelings. The main purpose was to recognize short term emotion using a single PPG signal pulse. We used a one-dimensional convolutional neural network (1D CNN) to extract PPG signal features to classify the valence and arousal. We split the PPG signal into a single 1.1 s pulse and normalized it for input to the neural network based on the personal maximum and minimum values. We chose the dataset for emotion analysis using physiological (DEAP) signals for the experiment and tested the 1D CNN as a binary classification (high or low valence and arousal), achieving the short-term emotion recognition of 1.1 s with 75.3% and 76.2% valence and arousal accuracies, respectively, on the DEAP data.",2019.0,39.0,55.0,True,"{'url': 'https://www.mdpi.com/2076-3417/9/16/3355/pdf?version=1565854753', 'status': None}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Lee2019FastER,\n author = {M. Lee and Y. Lee and D. Pae and M. Lim and D. W. Kim and Tae-Koo Kang},\n journal = {Applied Sciences},\n title = {Fast Emotion Recognition Based on Single Pulse PPG Signal with Convolutional Neural Network},\n year = {2019}\n}\n'}","[{'authorId': '2109515601', 'name': 'M. Lee'}, {'authorId': '84115032', 'name': 'Y. Lee'}, {'authorId': '9212384', 'name': 'D. Pae'}, {'authorId': '145553301', 'name': 'M. Lim'}, {'authorId': '38113894', 'name': 'D. W. Kim'}, {'authorId': '2603654', 'name': 'Tae-Koo Kang'}]"
2279,c58e151aca1f5f4a4247c5dfdde427aac9d00c3c,A comparison of the discrete and dimensional models of emotion in music,"The primary aim of the present study was to systematically compare perceived emotions in music using two different theoretical frameworks: the discrete emotion model, and the dimensional model of affect. A secondary aim was to introduce a new, improved set of stimuli for the study of music-mediated emotions. A large pilot study established a set of 110 film music excerpts, half were moderately and highly representative examples of five discrete emotions (anger, fear, sadness, happiness and tenderness), and the other half moderate and high examples of the six extremes of three bipolar dimensions (valence, energy arousal and tension arousal). These excerpts were rated in a listening experiment by 116 non-musicians. All target emotions of highly representative examples in both conceptual sets were discriminated by self-ratings. Linear mapping techniques between the discrete and dimensional models revealed a high correspondence along two central dimensions that can be labelled as valence and arousal, and the three dimensions could be reduced to two without significantly reducing the goodness of fit. The major difference between the discrete and categorical models concerned the poorer resolution of the discrete model in characterizing emotionally ambiguous examples. The study offers systematically structured and rich stimulus material for exploring emotional processing.",2011.0,86.0,591.0,False,,"{'volume': '39', 'pages': '18 - 49', 'name': 'Psychology of Music'}","{'bibtex': '@Article{Eerola2011ACO,\n author = {T. Eerola and J. Vuoskoski},\n journal = {Psychology of Music},\n pages = {18 - 49},\n title = {A comparison of the discrete and dimensional models of emotion in music},\n volume = {39},\n year = {2011}\n}\n'}","[{'authorId': '2804198', 'name': 'T. Eerola'}, {'authorId': '6178537', 'name': 'J. Vuoskoski'}]"
2280,c5937393fff1305b19b393d31cac7a02ba22eba3,Bias-Corrected Bootstrap and Model Uncertainty,"The bootstrap has become a popular method for exploring model (structure) uncertainty. Our experiments with artificial and real-world data demonstrate that the graphs learned from bootstrap samples can be severely biased towards too complex graphical models. Accounting for this bias is hence essential, e.g., when exploring model uncertainty. We find that this bias is intimately tied to (well-known) spurious dependences induced by the bootstrap. The leading-order bias-correction equals one half of Akaike's penalty for model complexity. We demonstrate the effect of this simple bias-correction in our experiments. We also relate this bias to the bias of the plug-in estimator for entropy, as well as to the difference between the expected test and training errors of a graphical model, which asymptotically equals Akaike's penalty (rather than one half).",2003.0,15.0,48.0,False,,{'pages': '521-528'},"{'bibtex': '@Inproceedings{Steck2003BiasCorrectedBA,\n author = {H. Steck and T. Jaakkola},\n pages = {521-528},\n title = {Bias-Corrected Bootstrap and Model Uncertainty},\n year = {2003}\n}\n'}","[{'authorId': '2454529', 'name': 'H. Steck'}, {'authorId': '35132120', 'name': 'T. Jaakkola'}]"
2281,c59a66e3f5a284d7ecfb9a8304aca6de5dd9ea56,The effects of social story interventions on preschool age children with and without disabilities,"This study compared the effects of a social story-only intervention with the effects of a social story-plus practices session intervention as implemented with preschool age children with disabilities (n = 16) and without disabilities (n = 16) in an inclusive preschool setting. The social story interventions were implemented with groups of four children in order to examine the impact of the intervention on the children's prosocial and antisocial skills. The findings of the study differ from previous research in that the social story interventions were not found to be an effective intervention. The significance of these findings, limitations of the study, and future research suggestions are discussed.",2013.0,84.0,18.0,True,"{'url': 'https://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=1235&context=thesesdissertations', 'status': None}","{'volume': '183', 'pages': '1 - 16', 'name': 'Early Child Development and Care'}","{'bibtex': '@Article{More2013TheEO,\n author = {Cori M. More and Nancy M. Sileo and Kyle Higgins and R. Tandy and Michelle T. Tannock},\n journal = {Early Child Development and Care},\n pages = {1 - 16},\n title = {The effects of social story interventions on preschool age children with and without disabilities},\n volume = {183},\n year = {2013}\n}\n'}","[{'authorId': '113642907', 'name': 'Cori M. More'}, {'authorId': '66258304', 'name': 'Nancy M. Sileo'}, {'authorId': '48127974', 'name': 'Kyle Higgins'}, {'authorId': '40012209', 'name': 'R. Tandy'}, {'authorId': '118026986', 'name': 'Michelle T. Tannock'}]"
2282,c5bbbd24da123f3eb4f00bcfa7fcc0ad11ace39f,Mood avatar: automatic text-driven head motion synthesis,"Natural head motion is an indispensable part of realistic facial animation. This paper presents a novel approach to synthesize natural head motion automatically based on grammatical and prosodic features, which are extracted by the text analysis part of a Chinese Text-to-Speech (TTS) system. A two-layer clustering method is proposed to determine elementary head motion patterns from a multimodal database which covers six emotional states. The mapping problem between textual information and elementary head motion patterns is modeled by Classification and Regression Trees (CART). With the emotional state specified by users, results from text analysis are utilized to drive corresponding CART model to create emotional head motion sequence. Then, the generated sequence is interpolated by spineand us ed to drive a Chinese text-driven avatar. The comparison experiment indicates that this approach provides a better head motion and an engaging human-computer comparing to random or none head motion.",2010.0,8.0,7.0,False,,{'pages': '37:1-37:4'},"{'bibtex': '@Inproceedings{Mu2010MoodAA,\n author = {Kaihui Mu and J. Tao and Jianfeng Che and Minghao Yang},\n pages = {37:1-37:4},\n title = {Mood avatar: automatic text-driven head motion synthesis},\n year = {2010}\n}\n'}","[{'authorId': '3295988', 'name': 'Kaihui Mu'}, {'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '2061534506', 'name': 'Jianfeng Che'}, {'authorId': '2740129', 'name': 'Minghao Yang'}]"
2283,c5bc0e4faf7050465063c4831f9a4521b2a97bb6,Real-time Collision-free Path Planning of Robot Manipulators using Neural Network Approaches,"In this paper, a novel neural network approach to real-time collision-free path planning of robot manipulators in a nonstationary environment is proposed, which is based on a biologically inspired neural network model for dynamic trajectory generation of a point mobile robot. The state space of the proposed neural network is the joint space of the robot manipulators, where the dynamics of each neuron is characterized by a shunting equation or an additive equation. The real-time robot path is planned through the varying neural activity landscape that represents the dynamic environment. The proposed model for robot path planning with safety consideration is capable of planning a real-time “comfortable” path without suffering from the “too close” nor “too far” problems. The model algorithm is computationally efficient. The computational complexity is linearly dependent on the neural network size. The effectiveness and efficiency are demonstrated through simulation studies.",1999.0,42.0,44.0,False,,"{'volume': '9', 'pages': '27-39', 'name': 'Autonomous Robots'}","{'bibtex': '@Article{Yang1999RealtimeCP,\n author = {Simon X. Yang and M. Meng},\n journal = {Autonomous Robots},\n pages = {27-39},\n title = {Real-time Collision-free Path Planning of Robot Manipulators using Neural Network Approaches},\n volume = {9},\n year = {1999}\n}\n'}","[{'authorId': '98726631', 'name': 'Simon X. Yang'}, {'authorId': '144517997', 'name': 'M. Meng'}]"
2284,c5bd9b18841df795fb1ec0404a34c5332ca6fb8b,Studies on gesture expressivity for a virtual agent,,2009.0,59.0,151.0,False,,"{'volume': '51', 'pages': '630-639', 'name': 'Speech Commun.'}","{'bibtex': '@Article{Pelachaud2009StudiesOG,\n author = {C. Pelachaud},\n journal = {Speech Commun.},\n pages = {630-639},\n title = {Studies on gesture expressivity for a virtual agent},\n volume = {51},\n year = {2009}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2285,c5da2e2978408cb90bd3423abbe15f2285ba4ba1,A Serious Game for Learning Social Networking Literacy by Flaming Experiences,,2016.0,4.0,4.0,False,,{'pages': '23-33'},"{'bibtex': '@Inproceedings{Sumi2016ASG,\n author = {Kaoru Sumi and K. Kasai},\n pages = {23-33},\n title = {A Serious Game for Learning Social Networking Literacy by Flaming Experiences},\n year = {2016}\n}\n'}","[{'authorId': '145441214', 'name': 'Kaoru Sumi'}, {'authorId': '20224257', 'name': 'K. Kasai'}]"
2286,c5dd41405b8495edea69351f46ea4176b2286daf,Psychological and biological differences in touch avoidance,The present study investigated the influence of psychological and biological gender on touch avoidance. Additionally of interest was the relationship between touch avoidance with the communication trait unwillingness to communicate. Results revealed that males are more same‐sex touch avoidant but do not differ from females in opposite‐sex touch avoidance. Sex‐role differences existed for opposite‐sex touch avoidance. The results of this study support the importance of looking at psychological gender.,1993.0,20.0,17.0,False,,"{'volume': '10', 'pages': '141-147', 'name': 'Communication Research Reports'}","{'bibtex': '@Article{Martin1993PsychologicalAB,\n author = {Matthew M. Martin and C. M. Anderson},\n journal = {Communication Research Reports},\n pages = {141-147},\n title = {Psychological and biological differences in touch avoidance},\n volume = {10},\n year = {1993}\n}\n'}","[{'authorId': '32945699', 'name': 'Matthew M. Martin'}, {'authorId': '49852536', 'name': 'C. M. Anderson'}]"
2287,c5e2e4866ccabc904bf05ddb70c95fe263e9500e,Too Much Humanness for Human-Robot Interaction: Exposure to Highly Humanlike Robots Elicits Aversive Responding in Observers,"People tend to anthropomorphize agents that look and/or act human, and further, they tend to evaluate such agents more positively. This, in turn, has motivated the development of robotic agents that are humanlike in appearance and/or behavior. Yet, some agents -- often those with highly humanlike appearances -- have been found to elicit the opposite, wherein they are evaluated more negatively than their less humanlike counterparts. These trends are captured by Masahiro Mori's uncanny valley hypothesis, which describes a (uncanny) valley in emotional responding - a switch from affinity to dislike - elicited by agents that are ``too humanlike'. However, while the valley phenomenon has been repeatedly observed via subjective measures, it remains unknown as to whether such evaluations reflect a potential impact to a person's behavior (i.e., aversion). We attempt to address this gap in the literature via a novel experimental paradigm employing both traditional subjective ratings, as well as measures of peoples' behavioral and phsyiological responding. The results show that not only do people rate highly humanlike robots as uncanny, but moreover, they exhibit greater avoidance of such encounters than encounters with less humanlike and human agents. Thus, the findings not only support Mori's hypothesis, but further, they indicate the valley should be taken as a serious consideration for peoples' interactions with humanlike agents.",2015.0,46.0,58.0,False,,{'name': 'Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Strait2015TooMH,\n author = {M. Strait and Lara Vujovic and Victoria Floerke and Matthias Scheutz and Heather L. Urry},\n journal = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},\n title = {Too Much Humanness for Human-Robot Interaction: Exposure to Highly Humanlike Robots Elicits Aversive Responding in Observers},\n year = {2015}\n}\n'}","[{'authorId': '2615963', 'name': 'M. Strait'}, {'authorId': '2895902', 'name': 'Lara Vujovic'}, {'authorId': '3079073', 'name': 'Victoria Floerke'}, {'authorId': '1793014', 'name': 'Matthias Scheutz'}, {'authorId': '2074197', 'name': 'Heather L. Urry'}]"
2288,c5fa83d7fb825eebad2c88c4a61b14634c51ba47,Agent-Human Interactions in the Continuous Double Auction,"The Continuous Double Auction (CDA) is the dominant market institution for real-world trading of equities, commodities, derivatives, etc. We describe a series of laboratory experiments that, for the first time, allow human subjects to interact with software bidding agents in a CDA. Our bidding agents use strategies based on extensions of the Gjerstad-Dickhaut and Zero-Intelligence-Plus algorithms. We find that agents consistently obtain significantly larger gains from trade than their human counterparts. This was unexpected because both humans and agents have approached theoretically perfect efficiency in prior all-human or allagent CDA experiments. Another unexpected finding is persistent far-from-equilibrium trading, in sharp contrast to the robust convergence observed in previous all-human or all-agent experiments. We consider possible explanations for our empirical findings, and speculate on the implications for future agent-human interactions in electronic markets.",2001.0,10.0,280.0,False,,{'pages': '1169-1187'},"{'bibtex': '@Inproceedings{Das2001AgentHumanII,\n author = {Rajarshi Das and James E. Hanson and J. Kephart and G. Tesauro},\n pages = {1169-1187},\n title = {Agent-Human Interactions in the Continuous Double Auction},\n year = {2001}\n}\n'}","[{'authorId': '143863023', 'name': 'Rajarshi Das'}, {'authorId': '144353288', 'name': 'James E. Hanson'}, {'authorId': '1721327', 'name': 'J. Kephart'}, {'authorId': '1699108', 'name': 'G. Tesauro'}]"
2289,c605011eeffc9fa32bdb34e16a82b72e17c3be3d,Design and evaluation of expressive gesture synthesis for embodied conversational agents,"To increase the believability and life-likeness of Embodied Conversational Agents (ECAs), we introduce a behavior synthesis technique for the generation of expressive gesturing. A small set of dimensions of expressivity is used to characterize individual variability of movement. We empirically evaluate our implementation in two separate user studies. The results suggest that our approach works well for a subset of expressive behavior. However, animation fidelity is not high enough to realize subtle changes. Interaction effects between different parameters need to be studied further.",2005.0,8.0,85.0,False,,{'pages': '1095-1096'},"{'bibtex': '@Inproceedings{Hartmann2005DesignAE,\n author = {Bjoern Hartmann and M. Mancini and S. Buisine and C. Pelachaud},\n pages = {1095-1096},\n title = {Design and evaluation of expressive gesture synthesis for embodied conversational agents},\n year = {2005}\n}\n'}","[{'authorId': '28226629', 'name': 'Bjoern Hartmann'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1742939', 'name': 'S. Buisine'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2290,c60c5d79782ec737b7f5ee04cb647489f5b1fdf2,Storytelling in Virtual Reality,,2020.0,11.0,7.0,False,,{'name': 'Encyclopedia of Computer Graphics and Games'},"{'bibtex': '@Article{Bertrand2020StorytellingIV,\n author = {S. Bertrand and Martha Vassiliadi and G. Papagiannakis},\n journal = {Encyclopedia of Computer Graphics and Games},\n title = {Storytelling in Virtual Reality},\n year = {2020}\n}\n'}","[{'authorId': '2066622153', 'name': 'S. Bertrand'}, {'authorId': '80264147', 'name': 'Martha Vassiliadi'}, {'authorId': '2896538', 'name': 'G. Papagiannakis'}]"
2291,c67c231eecd6b476e8e4e3e3031dae24a9de0e05,Walking in Another's Virtual Shoes: Do 360-Degree Video News Stories Generate Empathy in Viewers?,,2018.0,35.0,57.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Archer2018WalkingIA,\n author = {D. Archer and K. Finger},\n title = {Walking in Another's Virtual Shoes: Do 360-Degree Video News Stories Generate Empathy in Viewers?},\n year = {2018}\n}\n""}","[{'authorId': '103505039', 'name': 'D. Archer'}, {'authorId': '118463994', 'name': 'K. Finger'}]"
2292,c681b4dbd705db71d9668e32e471eeeadfa1b939,The Ripple Effect: Emotional Contagion and its Influence on Group Behavior,"Group emotional contagion, the transfer of moods among people in a group, and its influence on work group dynamics was examined in a laboratory study of managerial decision making using multiple, convergent measures of mood, individual attitudes, behavior, and group-level dynamics. Using a 2 times 2 experimental design, with a trained confederate enacting mood conditions, the predicted effect of emotional contagion was found among group members, using both outside coders' ratings of participants' mood and participants' self-reported mood. No hypothesized differences in contagion effects due to the degree of pleasantness of the mood expressed and the energy level with which it was conveyed were found. There was a significant influence of emotional contagion on individual-level attitudes and group processes. As predicted, the positive emotional contagion group members experienced improved cooperation, decreased conflict, and increased perceived task performance. Theoretical implications and practical ramifications of emotional contagion in groups and organizations are discussed.",2002.0,173.0,2860.0,True,"{'url': 'http://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Affect/Barsade_2002_The_ripple_effect.pdf', 'status': None}","{'volume': '47', 'pages': '644 - 675', 'name': 'Administrative Science Quarterly'}","{'bibtex': '@Article{Barsade2002TheRE,\n author = {Sigal G. Barsade},\n journal = {Administrative Science Quarterly},\n pages = {644 - 675},\n title = {The Ripple Effect: Emotional Contagion and its Influence on Group Behavior},\n volume = {47},\n year = {2002}\n}\n'}","[{'authorId': '1838029', 'name': 'Sigal G. Barsade'}]"
2294,c6a1534ccada6f09e0b5ad29241da555574aee48,Remembering Emotional Experiences: The Contribution of Valence and Arousal,"Emotional experiences can be described by two factors: valence (how negative or positive) and arousal (how calming or exciting). Although both dimensions appear to influence memory, they may do so via distinct mechanisms. The amygdala likely plays a specific role in modulating memory for arousing experiences, whereas non-amygdalar networks may be instrumental in enhancing memory for non-arousing positive or negative events.",2004.0,84.0,487.0,False,,"{'volume': '15', 'pages': '241 - 252', 'name': 'Reviews in the Neurosciences'}","{'bibtex': '@Article{Kensinger2004RememberingEE,\n author = {E. Kensinger},\n journal = {Reviews in the Neurosciences},\n pages = {241 - 252},\n title = {Remembering Emotional Experiences: The Contribution of Valence and Arousal},\n volume = {15},\n year = {2004}\n}\n'}","[{'authorId': '2922446', 'name': 'E. Kensinger'}]"
2295,c6a2c40110efa0ab53f1762f47ef5779d85b7a9a,PUPPET: a virtual environment for children to act and direct interactive narratives,"This paper presents findings from an evaluation of an autonomous agent populated virtual environment called PUPPET, that allows children to play multiple roles in the creation of an interactive narrative: audience, actor, scriptwriter, and editor. The speech of children playing with the PUPPET system was analysed to determine their ability to understand the behaviour and motives of the autonomous agents, to take on the role of an avatar character, to script dialogue for the characters, and to reflect upon and edit the recorded dialogue.",2002.0,5.0,42.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Marshall2002PUPPETAV,\n author = {P. Marshall and Y. Rogers and M. Scaife},\n title = {PUPPET: a virtual environment for children to act and direct interactive narratives},\n year = {2002}\n}\n'}","[{'authorId': '143679313', 'name': 'P. Marshall'}, {'authorId': '1685816', 'name': 'Y. Rogers'}, {'authorId': '118334943', 'name': 'M. Scaife'}]"
2296,c6b4759d454104d6e71b61b3ead267f132cf039a,Suicidality in adjustment disorder--clinical characteristics of adolescent outpatients.,"OBJECTIVE
Although a remarkable proportion of adolescents suffering from adjustment disorder (AD) are suicidal, few studies have documented the characteristics of suicidal AD patients. We examined background, psychopathology and treatment-related factors among suicidal adolescent AD outpatients.


METHOD
Data on 302 consecutively referred psychiatric outpatient adolescents, aged 12-22 years, were collected. DSM-III-R diagnoses were assigned at the end of treatment based on all available data. Of the patients 89 received a diagnosis of AD, 25% of whom showed suicide attempts, suicidal threats or ideation.


RESULTS
Compared with non-suicidal AD patients, suicidal AD patients were characterized by previous psychiatric treatment (OR = 6.1), poor psychosocial functioning at treatment entry (OR = 16.2), suicide as a stressor (OR = 33.3), dysphoric mood (OR = 6.9) and psychomotor restlessness (OR = 3.7).


CONCLUSIONS
Common risk factors for suicidality in major psychiatric disorders characterized suicidal AD patients. Psychiatric assessment of AD patients should include careful monitoring of both symptomatology and exposure to suicide of significant others.",2005.0,39.0,30.0,False,,"{'volume': '14 3', 'pages': '\n          174-80\n        ', 'name': 'European child & adolescent psychiatry'}","{'bibtex': '@Article{Pelkonen2005SuicidalityIA,\n author = {M. Pelkonen and M. Marttunen and M. Henriksson and J. Lönnqvist},\n journal = {European child & adolescent psychiatry},\n pages = {\n          174-80\n        },\n title = {Suicidality in adjustment disorder--clinical characteristics of adolescent outpatients.},\n volume = {14 3},\n year = {2005}\n}\n'}","[{'authorId': '5333763', 'name': 'M. Pelkonen'}, {'authorId': '2994815', 'name': 'M. Marttunen'}, {'authorId': '4675078', 'name': 'M. Henriksson'}, {'authorId': '2088959', 'name': 'J. Lönnqvist'}]"
2297,c6b773631a8bfb9bb7d5c39e9af66bce3b488376,Relationship context and emotion regulation across the life span.,"A growing body of literature points to the important role that context plays in emotion regulation. One dimension of context that has significance for emotion regulation is the nature of the relationship between interactive partners. This review provides an organized account of existing empirical evidence assessing emotion regulation within close relationships across the life span. Specifically, the reviewed research includes studies examining parent-child relationships, sibling relationships, friendships, and romantic relationships in relation to emotion regulation. The review highlights evidence concerning how relationship processes influence emotion regulation. Based on the current state of the literature, future directions for research in this area are recommended. This review seeks to advance a more nuanced approach to the study of the social processes associated with emotion regulation. An argument is made for how building upon research concerning the relationship context as a basis for emotion regulation can further elucidate theorizing on the determinants of emotion regulation. (PsycINFO Database Record (c) 2020 APA, all rights reserved).",2020.0,30.0,24.0,False,,"{'volume': '20 1', 'pages': '\n          59-62\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Lindsey2020RelationshipCA,\n author = {Eric W. Lindsey},\n journal = {Emotion},\n pages = {\n          59-62\n        },\n title = {Relationship context and emotion regulation across the life span.},\n volume = {20 1},\n year = {2020}\n}\n'}","[{'authorId': '7020927', 'name': 'Eric W. Lindsey'}]"
2298,c6bf764d9c80c0273ec5ff3a2f0fa152f5616d2a,Toward affect-sensitive virtual human tutors: The influence of facial expressions on learning and emotion,"Affective support can play a central role in adaptive learning environments. Although virtual human tutors hold significant promise for providing affective support, a key open question is how a tutor's facial expressions can influence learners' performance. In this paper, we report on a study to examine the influence of a human tutor agent's facial expressions on learners' performance and emotions during learning. Results from the study suggest that learners' performance is significantly better when a human tutor agent facially expresses emotions that are congruent with the content relevancy. Results also suggest that learners facially express significantly more confusion when the human tutor agent provides incongruent facial expressions. These results can inform the design of virtual humans as pedagogical agents can inform the design of virtual humans as pedagogical agents and designing intelligent learner-agent interactions.",2017.0,14.0,10.0,False,,"{'name': '2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)', 'pages': '184-189'}","{'bibtex': '@Article{Mudrick2017TowardAV,\n author = {Nicholas V. Mudrick and M. Taub and R. Azevedo and Jonathan P. Rowe and James C. Lester},\n booktitle = {Affective Computing and Intelligent Interaction},\n journal = {2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {184-189},\n title = {Toward affect-sensitive virtual human tutors: The influence of facial expressions on learning and emotion},\n year = {2017}\n}\n'}","[{'authorId': '3408438', 'name': 'Nicholas V. Mudrick'}, {'authorId': '37057683', 'name': 'M. Taub'}, {'authorId': '145394858', 'name': 'R. Azevedo'}, {'authorId': '34971293', 'name': 'Jonathan P. Rowe'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
2299,c6c0a69c9cee330093b0aae014ceaca9ba7eff15,The Hidden Dimension,,1970.0,0.0,6860.0,False,,"{'volume': '21', 'pages': '353', 'name': 'British Journal of Sociology'}","{'bibtex': '@Article{Lipman1970TheHD,\n author = {Alan Lipman and E. Hall},\n journal = {British Journal of Sociology},\n pages = {353},\n title = {The Hidden Dimension},\n volume = {21},\n year = {1970}\n}\n'}","[{'authorId': '2252548890', 'name': 'Alan Lipman'}, {'authorId': '1422357475', 'name': 'E. Hall'}]"
2303,c6e17abd83bf8ca7f66b7da5e72c514d07fe6194,Circumplex Model of Affect: A Measure of Pleasure and Arousal During Virtual Reality Distraction Analgesia,"Abstract Objective: Immersive virtual reality (VR) distraction provides clinically effective pain relief and increases subjective reports of “fun” in medical settings of procedural pain. The goal of this study was to better describe the variable of “fun” associated with VR distraction analgesia using the circumplex model (pleasure/arousal) of affect. Materials and Methods: Seventy-four healthy volunteers (mean age, 29 years; 37 females) received a standardized, 18-minute, multimodal pain sequence (alternating thermal heat and electrical stimulation to distal extremities) while receiving immersive, interactive VR distraction. Subjects rated both their subjective pain intensity and fun using 0–10 Graphic Rating Scales, as well as the pleasantness of their emotional valence and their state of arousal on 9-point scales. Results: Compared with pain stimulation in the control (baseline, no VR) condition, immersive VR distraction significantly reduced subjective pain intensity (P < 0.001). During VR distraction,...",2016.0,31.0,43.0,True,"{'url': 'https://europepmc.org/articles/pmc4931759?pdf=render', 'status': None}","{'volume': '', 'name': 'Games for health journal'}","{'bibtex': '@Article{ShararSam2016CircumplexMO,\n author = {R. ShararSam and AlamdariAva and HofferChristine and G. HoffmanHunter and P. JensenMark and R. PattersonDavid},\n journal = {Games for health journal},\n title = {Circumplex Model of Affect: A Measure of Pleasure and Arousal During Virtual Reality Distraction Analgesia},\n year = {2016}\n}\n'}","[{'authorId': '116158613', 'name': 'R. ShararSam'}, {'authorId': '117253791', 'name': 'AlamdariAva'}, {'authorId': '115722920', 'name': 'HofferChristine'}, {'authorId': '114941212', 'name': 'G. HoffmanHunter'}, {'authorId': '115699001', 'name': 'P. JensenMark'}, {'authorId': '115522050', 'name': 'R. PattersonDavid'}]"
2304,c6f1e684a49a32cfe1db8906fe8e3299a8024a25,Natural interaction with culturally adaptive virtual characters,,2012.0,30.0,69.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/45671/45671.pdf', 'status': None}","{'volume': '6', 'pages': '39-47', 'name': 'Journal on Multimodal User Interfaces'}","{'bibtex': '@Article{Kistler2012NaturalIW,\n author = {Felix Kistler and Birgit Lugrin and Ionut Damian and C. Dang and E. André},\n journal = {Journal on Multimodal User Interfaces},\n pages = {39-47},\n title = {Natural interaction with culturally adaptive virtual characters},\n volume = {6},\n year = {2012}\n}\n'}","[{'authorId': '2844803', 'name': 'Felix Kistler'}, {'authorId': '2158172', 'name': 'Birgit Lugrin'}, {'authorId': '3048626', 'name': 'Ionut Damian'}, {'authorId': '2040306', 'name': 'C. Dang'}, {'authorId': '1742930', 'name': 'E. André'}]"
2305,c70707df51ff55956ef580a9cc4035f2f572df28,Linking Maternal Warmth and Responsiveness to Children's Self‐regulation,"The present study demonstrated that a more differentiated view of positive parenting practices is necessary in the study of children's acquisition of self‐regulation. Here, the unique contributions of maternal warmth and responsiveness to distress to children's self‐regulation were tested in a sample of 102 German mothers and their kindergarten children (51 girls and 51 boys). Behavior regulation and internalization of rules of conduct were examined as specific components of children's self‐regulation. As expected, maternal warmth was positively related to the child's behavior regulation. Responsiveness to distress was positively linked to the child's internalization of rules of conduct. No significant interactions between maternal parenting and either the child's gender or effortful control were found. The results are discussed with regard to the unique functions that different parenting practices have for children's self‐regulation.",2011.0,83.0,112.0,True,"{'url': 'https://lirias.kuleuven.be/bitstream/123456789/461856/1/Suchodoletz%2c%20Trommsdorff%2c%20%26%20Heikamp%2c%202011.pdf', 'status': None}","{'volume': '20', 'pages': '486-503', 'name': 'Social Development'}","{'bibtex': ""@Article{Suchodoletz2011LinkingMW,\n author = {A. Suchodoletz and G. Trommsdorff and Tobias Heikamp},\n journal = {Social Development},\n pages = {486-503},\n title = {Linking Maternal Warmth and Responsiveness to Children's Self‐regulation},\n volume = {20},\n year = {2011}\n}\n""}","[{'authorId': '3851939', 'name': 'A. Suchodoletz'}, {'authorId': '50059736', 'name': 'G. Trommsdorff'}, {'authorId': '5187275', 'name': 'Tobias Heikamp'}]"
2306,c717eb4e913c3249eac18d0fba13a1aa02d60dad,A Multidimensional Approach to Individual Differences in Empathy,"The development of a multidimensional individual difference measure of empathy is described. The final version of the instrument consists of four seven-item subscales, each of which taps a separate aspect of the global concept ""empathy."" One scale, the perspective-taking scale, contains items which assess spontaneous attempts to adopt the perspectives of other people and see things from their point of view. Items on the fantasy scale measure the tendency to identify with characters in movies, novels, plays and other fictional situations. The other two subscales explicitly tap respondents' chronic emotional reactions to the negative experiences of others. The empathic concern scale inquires about respondents' feelings of warmth, compassion, and concern for others, while the personal distress scale measures the personal feelings of anxiety and discomfort that result from observing another's negative experience. The factor structure underlying these scales is the same for both sexes, and emerged in two independent samples. Test-retest and internal reliabilities of all four scales were substantial. The pattern of sex differences and the intercorrelations of these four scales are discussed in terms of recent theoretical treatments of the development of empathy (Hoffman, 1976). It is concluded that the new measure has considerable potential for investigations of the multidimensional nature of empathy.",1980.0,28.0,4988.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Davis1980AMA,\n author = {Mark H. Davis and Miles P. Davis and M. Davis and Matthew Davis and Mark Davis and Mm Davis and M. Davis and F. Davis and H. Davis and I. W. Davis},\n title = {A Multidimensional Approach to Individual Differences in Empathy},\n year = {1980}\n}\n'}","[{'authorId': '47994338', 'name': 'Mark H. Davis'}, {'authorId': '1575959158', 'name': 'Miles P. Davis'}, {'authorId': '2107723533', 'name': 'M. Davis'}, {'authorId': '2110853467', 'name': 'Matthew Davis'}, {'authorId': '2110853313', 'name': 'Mark Davis'}, {'authorId': '2110745785', 'name': 'Mm Davis'}, {'authorId': '2107723533', 'name': 'M. Davis'}, {'authorId': '145544155', 'name': 'F. Davis'}, {'authorId': '47215691', 'name': 'H. Davis'}, {'authorId': '118016670', 'name': 'I. W. Davis'}]"
2307,c74084d7a77a7732115dcab68b3c2dc9b100748a,Handbook of Emotion Regulation,"emotion regulation and present a common framework for understanding emotion regulation, the process model of emoHandbook of emotion regulation. 2nd. problems with emotion and emotion regulation (estimates range from 40% to more 2007, in Handbook of Emotion Regulation (p. 10), J. J. Gross (Ed.), New. Reviews the book, The Handbook of Emotion Regulation (2nd Ed.) edited by James J. Gross (see record 2013-44085-000 ). The scientific field of emotion. Adapted from Gross &Thompson. Handbook of Emotion Regulation. Emotions... • ...arise when one attends to situations relevant (meaning) to one's goals. ABSTRACT Emotion regulation is not always deliberate, but can also operate on nonconscious or implicit levels. From an action control perspective, there.",2007.0,0.0,1218.0,False,,"{'volume': '298', 'pages': '1805-1810', 'name': 'JAMA'}","{'bibtex': '@Article{Lambert2007HandbookOE,\n author = {K. Lambert},\n journal = {JAMA},\n pages = {1805-1810},\n title = {Handbook of Emotion Regulation},\n volume = {298},\n year = {2007}\n}\n'}","[{'authorId': '34961032', 'name': 'K. Lambert'}]"
2308,c765eb0a31849361d829b24e173a37bab0919892,Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings,"depressed individuals recalled fewer positive words than did their taken from the Affective Norms for English. Words list (ANEW, Bradley Affective norms for English words (ANEW): Instruction manual and affective ratings (pp. 1–45). Publication » Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings. Affective norms. English words (ANEW): Stimuli, instruction manual and affective ratings. Technical report. The Center for Research in Psychophysiology.",1999.0,10.0,2645.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Bradley1999AffectiveNF,\n author = {M. Bradley and P. Lang},\n title = {Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings},\n year = {1999}\n}\n'}","[{'authorId': '2007419', 'name': 'M. Bradley'}, {'authorId': '143853826', 'name': 'P. Lang'}]"
2309,c784671a78d78090192e14f9961bcf96be991c79,Recognizing gaze aversion gestures in embodied conversational discourse,"Eye gaze offers several key cues regarding conversational discourse during face-to-face interaction between people. While a large body of research results exist to document the use of gaze in human-to-human interaction, and in animating realistic embodied avatars, recognition of conversational eye gestures - distinct eye movement patterns relevant to discourse - has received less attention. We analyze eye gestures during interaction with an animated embodied agent and propose a non-intrusive vision-based approach to estimate eye gaze and recognize eye gestures. In our user study, human participants avert their gaze (i.e. with ""look-away"" or ""thinking"" gestures) during periods of cognitive load. Using our approach, an agent can visually differentiate whether a user is thinking about a response or is waiting for the agent or robot to take its turn.",2006.0,39.0,57.0,False,,{'pages': '287-294'},"{'bibtex': '@Inproceedings{Morency2006RecognizingGA,\n author = {Louis-Philippe Morency and C. M. Christoudias and Trevor Darrell},\n pages = {287-294},\n title = {Recognizing gaze aversion gestures in embodied conversational discourse},\n year = {2006}\n}\n'}","[{'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '1761495', 'name': 'C. M. Christoudias'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}]"
2310,c78475b9450c42764c94bf28abfbace01893ef6a,Introduction to Data Mining,"Chapter Objectives ✓ To learn about the concepts of data mining. ✓ To understand the need for, and the applications of data mining ✓ To differentiate between data mining and machine learning ✓ To understand the process of data mining. ✓ To understand the difference between data mining and machine learning. Introduction to Data Mining In the age of information, an enormous amount of data is available in different industries and organizations. The availability of this massive data is of no use unless it is transformed into valuable information. Otherwise, we are sinking in data, but starving for knowledge. The solution to this problem is data mining which is the extraction of useful information from the huge amount of data that is available. Data mining is defined as follows: ‘Data mining is a collection of techniques for efficient automated discovery of previously unknown, valid, novel, useful and understandable patterns in large databases. The patterns must be actionable so they may be used in an enterprise's decision making.’ From this definition, the important take aways are: • Data mining is a process of automated discovery of previously unknown patterns in large volumes of data. • This large volume of data is usually the historical data of an organization known as the data warehouse. • Data mining deals with large volumes of data, in Gigabytes or Terabytes of data and sometimes as much as Zetabytes of data (in case of big data). • Patterns must be valid, novel, useful and understandable. • Data mining allows businesses to determine historical patterns to predict future behaviour. • Although data mining is possible with smaller amounts of data, the bigger the data the better the accuracy in prediction. • There is considerable hype about data mining at present, and the Gartner Group has listed data mining as one of the top ten technologies to watch. Need of Data Mining Data mining is a recent buzz word in the field of Computer Science. It is a computing process that uses intelligent mathematical algorithms to extract the relevant data and computes the probability of future actions. It is also known as Knowledge Discovery in Data (KDD).",2005.0,71.0,4907.0,False,,{'name': 'Principles of Data Mining'},"{'bibtex': '@Article{Larose2005IntroductionTD,\n author = {D. Larose},\n journal = {Principles of Data Mining},\n title = {Introduction to Data Mining},\n year = {2005}\n}\n'}","[{'authorId': '2944823', 'name': 'D. Larose'}]"
2311,c787a3156bc3d20d4d505a831d463892d764f537,The Significance of Textures for Affective Interfaces,,2005.0,35.0,14.0,True,"{'url': 'http://www.cs.bath.ac.uk/~jjb/ftp/iva05pme.pdf', 'status': None}",{'pages': '394-404'},"{'bibtex': '@Inproceedings{Ellis2005TheSO,\n author = {Paula M. Ellis and J. Bryson},\n pages = {394-404},\n title = {The Significance of Textures for Affective Interfaces},\n year = {2005}\n}\n'}","[{'authorId': '2059629695', 'name': 'Paula M. Ellis'}, {'authorId': '145315445', 'name': 'J. Bryson'}]"
2312,c7ec687b34759b189251d8fd46aabf3e826de3cf,Influence of Hand Tracking as a Way of Interaction in Virtual Reality on User Experience,"With the rising interest in Virtual Reality and the fast development and improvement of available devices, new features of interactions are becoming available. One of them that is becoming very popular is hand tracking, as the idea to replace controllers for interactions in virtual worlds. This experiment aims to compare different interaction types in VR using either controllers or hand tracking. Participants had to play two simple VR games with various types of tasks in those games — grabbing objects or typing numbers. While playing, they were using interactions with different visualizations of hands and controllers. The focus of this study was to investigate user experience of varying interactions (controller vs. hand tracking) for those two simple tasks. Results show that different interaction types statistically significantly influence reported emotions with Self-Assessment Manikin (SAM), where for hand tracking participants were feeling higher valence, but lower arousal and dominance. Additionally, task type of grabbing was reported to be more realistic, and participants experienced a higher presence. Surprisingly, participants rated the interaction type with controllers where both where hands and controllers were visualized as statistically most preferred. Finally, hand tracking for both tasks was rated with the System Usability Scale (SUS) scale, and hand tracking for the task typing was rated as statistically significantly more usable. These results can drive further research and, in the long term, contribute to help selecting the most matching interaction modality for a task.",2020.0,17.0,35.0,True,"{'url': 'https://arxiv.org/pdf/2004.12642', 'status': None}","{'pages': '1-4', 'name': '2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)'}","{'bibtex': '@Article{Voigt-Antons2020InfluenceOH,\n author = {Jan-Niklas Voigt-Antons and Tanja Kojić and Danish Ali and S. Möller},\n journal = {2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)},\n pages = {1-4},\n title = {Influence of Hand Tracking as a Way of Interaction in Virtual Reality on User Experience},\n year = {2020}\n}\n'}","[{'authorId': '1390123460', 'name': 'Jan-Niklas Voigt-Antons'}, {'authorId': '51293010', 'name': 'Tanja Kojić'}, {'authorId': '2064469770', 'name': 'Danish Ali'}, {'authorId': '145733288', 'name': 'S. Möller'}]"
2314,c8089943935fcdbd486279f3205914ddbe4fe396,Investigating the relationship between the personality of a robotic TV assistant and the level of user control,"This paper describes the design and evaluation of a robotic TV assistant that helps users find a TV-programme that fits their interests. Questions that were addressed include: What personality do users prefer for the robotic TV-assistant? What level of control do they prefer? How do personality and the level of control relate to each other? Four prototypes were developed by combining two personalities and two levels of user control. In the high control condition, a speech-based command-and-control interaction style was used, whereas the interaction style in the low control condition consisted of speech-based system-initiative natural language dialogue. The results demonstrated an interaction between the effects of personality and level of control on user preferences. Overall, the most preferred combination was an extravert and friendly personality with low user control. Additionally, it was found that perceived level of control was influenced by the robot's personality. This suggests that the robot's personality can be used as a means to increase the amount of control that users perceive",2006.0,28.0,17.0,False,,"{'pages': '404-410', 'name': 'ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication'}","{'bibtex': '@Article{Meerbeek2006InvestigatingTR,\n author = {B. Meerbeek and J. Hoonhout and P. Bingley and J. Terken},\n journal = {ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication},\n pages = {404-410},\n title = {Investigating the relationship between the personality of a robotic TV assistant and the level of user control},\n year = {2006}\n}\n'}","[{'authorId': '1729155', 'name': 'B. Meerbeek'}, {'authorId': '2163126', 'name': 'J. Hoonhout'}, {'authorId': '49317857', 'name': 'P. Bingley'}, {'authorId': '1745774', 'name': 'J. Terken'}]"
2315,c83153089aded7999c4979958f8aae27dfef7ab3,Mirror mirror on the wall: Is there mimicry in you all?,"Future Intelligent Environments will feature fixed and mobile display screens with socially-aware virtual embodied agents. This paper addresses the potential of virtual embodied agents to generate a social connection with the inhabitants of Intelligent Environments. The goal of the study is to explore to what extent users mimic the behavior of an interactive agent. An experiment is conducted in which participants interact verbally with a virtual embodied agent. During the interaction, both the vocal pitch and the affective facial expressions of the agent are locally manipulated and the consecutive vocal and facial expressions of the participants registered. Computational analyses of the recorded expressions reveal vocal and facial mimicry as a sign of unconscious affect recognition and social connection. The implications of these results regarding the design of future Intelligent Environments are discussed.",2015.0,46.0,10.0,False,,"{'volume': '7', 'pages': '121-132', 'name': 'J. Ambient Intell. Smart Environ.'}","{'bibtex': '@Article{Mattheij2015MirrorMO,\n author = {R.J.H. Mattheij and M. Postma and E. Postma},\n journal = {J. Ambient Intell. Smart Environ.},\n pages = {121-132},\n title = {Mirror mirror on the wall: Is there mimicry in you all?},\n volume = {7},\n year = {2015}\n}\n'}","[{'authorId': '153696301', 'name': 'R.J.H. Mattheij'}, {'authorId': '36365492', 'name': 'M. Postma'}, {'authorId': '1729457', 'name': 'E. Postma'}]"
2316,c87397a52917c0f83ce4ba43ca876fc5bceae6c0,Avatar based interaction therapy: A potential therapeutic approach for children with Autism,"Autism is a neurodevelopment disorder characterized by severe deficiency in social interaction and communication skills. In this study, we investigated response levels of 5 healthy children to a robotic-avatar therapeutic system specially designed for children with Autism, and compared it to a pre-programmed robot designed to interact with autistic child and conventional interactive therapy conducted by a therapist. Our preliminary results show that our proposed avatar robot can increase the response and the interaction time of the child, thus increasing the attention span. On the other hand, our system can also automate and facilitate measuring the progress of interaction. The avatar robot can replicate the therapist's presence, mimicking his/her motion, transferring his/her voice, as well as, delivering feedbacks to the therapist with visuals and audio from the child environment.",2017.0,22.0,11.0,False,,"{'pages': '480-484', 'name': '2017 IEEE International Conference on Mechatronics and Automation (ICMA)'}","{'bibtex': '@Article{Alahbabi2017AvatarBI,\n author = {M. Alahbabi and Fatima Almazroei and Mariam Almarzoqi and Aysha Almeheri and Mariam Alkabi and A. Nuaimi and M. Cappuccio and F. Alnajjar},\n journal = {2017 IEEE International Conference on Mechatronics and Automation (ICMA)},\n pages = {480-484},\n title = {Avatar based interaction therapy: A potential therapeutic approach for children with Autism},\n year = {2017}\n}\n'}","[{'authorId': '50760108', 'name': 'M. Alahbabi'}, {'authorId': '23561991', 'name': 'Fatima Almazroei'}, {'authorId': '23593561', 'name': 'Mariam Almarzoqi'}, {'authorId': '23527485', 'name': 'Aysha Almeheri'}, {'authorId': '23565368', 'name': 'Mariam Alkabi'}, {'authorId': '3205373', 'name': 'A. Nuaimi'}, {'authorId': '5412626', 'name': 'M. Cappuccio'}, {'authorId': '1746689', 'name': 'F. Alnajjar'}]"
2317,c882fe3b02e84462292517b1f824ce2a7b6c2525,Adaptive Music Therapy for Alzheimer's Disease Using Virtual Reality,,2020.0,17.0,8.0,False,,{'pages': '214-219'},"{'bibtex': ""@Inproceedings{Byrns2020AdaptiveMT,\n author = {A. Byrns and H. Abdessalem and M. Cuesta and M. Bruneau and S. Belleville and C. Frasson},\n pages = {214-219},\n title = {Adaptive Music Therapy for Alzheimer's Disease Using Virtual Reality},\n year = {2020}\n}\n""}","[{'authorId': '68990793', 'name': 'A. Byrns'}, {'authorId': '28987363', 'name': 'H. Abdessalem'}, {'authorId': '47258254', 'name': 'M. Cuesta'}, {'authorId': '34277926', 'name': 'M. Bruneau'}, {'authorId': '145580293', 'name': 'S. Belleville'}, {'authorId': '1788058', 'name': 'C. Frasson'}]"
2318,c89c71dbe5617bea44383585b58cd0cbc37bf79a,General Game Playing: Overview of the AAAI Competition,"A general game playing system is one that can accept a formal description of a game and play the game effectively without human intervention. Unlike specialized game players, such as Deep Blue, general game players do not rely on algorithms designed in advance for specific games; and, unlike Deep Blue, they are able to play different kinds of games. In order to promote work in this area, the AAAI is sponsoring an open competition at this summer's Twentieth National Conference on Artificial Intelligence. This article is an overview of the technical issues and logistics associated with this summer's competition, as well as the relevance of general game playing to the long range-goals of artificial intelligence.",2005.0,6.0,552.0,False,,"{'volume': '26', 'pages': '62-72', 'name': 'AI Mag.'}","{'bibtex': '@Article{Genesereth2005GeneralGP,\n author = {M. Genesereth and Nathaniel Love and B. Pell},\n journal = {AI Mag.},\n pages = {62-72},\n title = {General Game Playing: Overview of the AAAI Competition},\n volume = {26},\n year = {2005}\n}\n'}","[{'authorId': '4940444', 'name': 'M. Genesereth'}, {'authorId': '38372561', 'name': 'Nathaniel Love'}, {'authorId': '145044563', 'name': 'B. Pell'}]"
2319,c89ca850c24675d83386c345c32e5fbbe74c78ea,Building a Generative Space of Facial Expressions of Emotions Using Psychological Data-driven Methods,"To engage their human users, socially interactive virtual agents must be equipped with the ability to communicate emotions using facial expressions. Therefore, a main goal is to build a generative model that can produce the range of realistic dynamic facial expressions of emotion that occur across social life. We contribute to this goal by building a psychologically valid generative model of facial expressions directly from subjective human perception using a novel psychology-based approach. First, we build a valence-arousal space of face movements by identifying the specific face movements that convey valence (positive/negative) and arousal (excited/calm) in 40 individual participants. We then tested the capacity of the valence-arousal space to generate a broad range of facial expressions of emotion including the six classic emotions and complex emotions. By cross-correlating a large set of facial expressions of basic and complex emotions with the valence-arousal space, we show that our model can successfully represent a wide range of emotions. We anticipate that our psychologically valid facial expression generation model will enhance the emotion signalling capabilities of virtual agents.",2020.0,22.0,3.0,False,,{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Liu2020BuildingAG,\n author = {Meng Liu and Y. Duan and Robin A. A. Ince and Chaona Chen and Oliver G. B. Garrod and P. Schyns and Rachael E. Jack},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Building a Generative Space of Facial Expressions of Emotions Using Psychological Data-driven Methods},\n year = {2020}\n}\n'}","[{'authorId': None, 'name': 'Meng Liu'}, {'authorId': '2341660', 'name': 'Y. Duan'}, {'authorId': '2054557', 'name': 'Robin A. A. Ince'}, {'authorId': '6416348', 'name': 'Chaona Chen'}, {'authorId': '48522841', 'name': 'Oliver G. B. Garrod'}, {'authorId': '2287417', 'name': 'P. Schyns'}, {'authorId': '2143019', 'name': 'Rachael E. Jack'}]"
2320,c8b191bbd9965e6cef6c85a761b4dbf36892c7cb,Social skills training for schizophrenia?,"To the Editor. — Hogarty and colleagues 1 have conducted an extremely important study on the treatment of schizophrenia. Their results shed considerable light on the potential impact of psychosocial interventions, and underscore the need for longitudinal evaluations of outcome. We find little to fault in the research design and data analysis; however, we disagree with what appears to be the overly pessimistic conclusion 1(p346) that the effects of psychosocial treatments in general, and social skills training (SST) in particular, dissolve once treatment ends. Based solely on examination of the final point in their 2-year survival analysis, SST does appear to provide little more than medication alone. However, as eloquently pointed out by Hogarty et al, this analysis provides a limited and misleading view of the overall effects of the intervention. The SST condition was as effective as either of the family treatment conditions until month 21 of the intervention. Had",1992.0,5.0,97.0,False,,"{'volume': '49 1', 'pages': '\n          76-7\n        ', 'name': 'Archives of general psychiatry'}","{'bibtex': '@Article{Bellack1992SocialST,\n author = {A. Bellack and K. Mueser},\n journal = {Archives of general psychiatry},\n pages = {\n          76-7\n        },\n title = {Social skills training for schizophrenia?},\n volume = {49 1},\n year = {1992}\n}\n'}","[{'authorId': '4338201', 'name': 'A. Bellack'}, {'authorId': '6109291', 'name': 'K. Mueser'}]"
2321,c8b1fab8774a02c0ab2971eca9002953da496f2b,Serious Game for Autism Children: Review of Literature,"Abstract—Autism Spectrum Disorder (ASD) is a pervasive 
developmental disorder which affects individuals with varying degrees of impairment. Currently, there has been ample research done in serious game for autism children. Although serious games are traditionally associated with software developments, developing them in the autism field involves studying the associated technology and paying attention to aspects related to interaction with the game. 
Serious Games for autism cover matters related to education, therapy for communication, psychomotor treatment and social behavior enhancement. In this paper, a systematic review sets out the lines of development and research currently being conducted into serious games which pursue some form of benefit in the field of autism. This 
paper includes a literature review of relevant serious game 
developments since in year 2007 and examines new trends.",2012.0,39.0,85.0,False,,"{'volume': '6', 'pages': '554-559', 'name': 'World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering'}","{'bibtex': '@Article{Noor2012SeriousGF,\n author = {H. Noor and F. Shahbodin and N. C. Pee},\n journal = {World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering},\n pages = {554-559},\n title = {Serious Game for Autism Children: Review of Literature},\n volume = {6},\n year = {2012}\n}\n'}","[{'authorId': '70516010', 'name': 'H. Noor'}, {'authorId': '3357134', 'name': 'F. Shahbodin'}, {'authorId': '3447302', 'name': 'N. C. Pee'}]"
2322,c8d756dab66e1f07bb83821a2c992e84da6fd137,Appraisal Determinants of Emotions: Constructing a More Accurate and Comprehensive Theory,"In order to move toward a more accurate, complete, and integrative theory of the causes of emotions, empirical evidence relevant to a recently proposed appraisal theory was examined, and hypotheses from several alternative appraisal theories were compared and tested. Given questions that focused on the cognitive causes of emotions rather than their phenomenological contents, 182 subjects rated the appraisal determinants of emotion experiences that they recalled. Results suggest that appraisals of unexpectedness (not unexpected/unexpected), situational state (motive-inconsistent/motiveconsistent), motivational state (aversive/appetitive), probability (uncertain/ certain), control potential (low/high), problem source (non-characterological/characterological factors), and agency (circumstances/other person/self), differentiate a large number of widely-discussed emotions. These results are used to formulate a revised, empirically grounded, and more comprehensive model that specifies which appraisals cause 17 ...",1996.0,52.0,921.0,False,,"{'volume': '10', 'pages': '241-278', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Roseman1996AppraisalDO,\n author = {Ira J. Roseman},\n journal = {Cognition & Emotion},\n pages = {241-278},\n title = {Appraisal Determinants of Emotions: Constructing a More Accurate and Comprehensive Theory},\n volume = {10},\n year = {1996}\n}\n'}","[{'authorId': '6784016', 'name': 'Ira J. Roseman'}]"
2323,c90b4d970b6c036f28e66a2cb2fe129fe0705063,Guaranteed Collision Avoidance for Autonomous Systems with Acceleration Constraints and Sensing Uncertainties,,2016.0,45.0,30.0,False,,"{'volume': '168', 'pages': '1014-1038', 'name': 'Journal of Optimization Theory and Applications'}","{'bibtex': '@Article{Rodríguez-Seda2016GuaranteedCA,\n author = {Erick J. Rodríguez-Seda and D. Stipanović and M. Spong},\n journal = {Journal of Optimization Theory and Applications},\n pages = {1014-1038},\n title = {Guaranteed Collision Avoidance for Autonomous Systems with Acceleration Constraints and Sensing Uncertainties},\n volume = {168},\n year = {2016}\n}\n'}","[{'authorId': '1384137264', 'name': 'Erick J. Rodríguez-Seda'}, {'authorId': '2377539', 'name': 'D. Stipanović'}, {'authorId': '145963824', 'name': 'M. Spong'}]"
2324,c939317b385303018ae0cce13988347ba1a26535,Promoting motivation with virtual agents and avatars: role of visual presence and appearance,"Anthropomorphic virtual agents can serve as powerful technological mediators to impact motivational outcomes such as self-efficacy and attitude change. Such anthropomorphic agents can be designed as simulated social models in the Bandurian sense, providing social influence as virtual ‘role models’. Of particular value is the capacity for designing such agents as optimized social models for a target audience and context. Importantly, the visual presence and appearance of such agents can have a major impact on motivation and affect regardless of the underlying technical sophistication. Empirical results of different instantiations of agent presence and appearance are reviewed for both autonomous virtual agents and avatars that represent a user.",2009.0,54.0,223.0,True,"{'url': 'https://europepmc.org/articles/pmc2781889?pdf=render', 'status': None}","{'volume': '364', 'pages': '3559 - 3565', 'name': 'Philosophical Transactions of the Royal Society B: Biological Sciences'}","{'bibtex': '@Article{Baylor2009PromotingMW,\n author = {A. L. Baylor},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n pages = {3559 - 3565},\n title = {Promoting motivation with virtual agents and avatars: role of visual presence and appearance},\n volume = {364},\n year = {2009}\n}\n'}","[{'authorId': '25550816', 'name': 'A. L. Baylor'}]"
2328,c9442568ff8d64c4d55ad770abbf8d658002a862,Blood pressure and heart rate responses to an intrusion on personal space,"Abstract:Yaezawa and Yoshida's (1981) ﬁndings on the effects of an intrusion on personal space were reinvestigated. Thirty-ﬁve female students were confronted with the approach of a male stranger, and blood pressure (BP) and heart rate (HR) were monitored. Throughout the model's approach, HR showed a signiﬁcant triphasic change (an initial decrease, a subsequent increase, and then a secondary decrease), whereas subjective feelings of anxiety and tension showed signiﬁcant, gradual increases. These trends were similar to those of Yaezawa and Yoshida’s. Nonetheless, their explanation that the triphasic change in HR reﬂected once hightened and then relieved tension, which was incongruent with the subjective ratings, seemed questionable. As the BP elevated to a moderate degree in spite of the modest HR changes, total peripheral resistance must have been increasing during the model's approach. Blood pressure elevations via this sort of hemodynamic pressor mechanisms have often been reported when a person can only tolerate passively during exposure to stress. This seems to be the case in an intrusion on personal space.",2003.0,15.0,25.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdf/10.1111/1468-5884.t01-2-00039', 'status': None}","{'volume': '45', 'pages': '115-121', 'name': 'Japanese Psychological Research'}","{'bibtex': '@Article{Sawada2003BloodPA,\n author = {Y. Sawada},\n journal = {Japanese Psychological Research},\n pages = {115-121},\n title = {Blood pressure and heart rate responses to an intrusion on personal space},\n volume = {45},\n year = {2003}\n}\n'}","[{'authorId': '49770907', 'name': 'Y. Sawada'}]"
2329,c95aa2d69a24dd021c68963bad062dc410acf860,Empathic Mixed Reality: Sharing What You Feel and Interacting with What You See,"Empathic Computing is a research field that aims to use technology to create deeper shared understanding or empathy between people. At the same time, Mixed Reality (MR) technology provides an immersive experience that can make an ideal interface for collaboration. In this paper, we present some of our research into how MR technology can be applied to creating Empathic Computing experiences. This includes exploring how to share gaze in a remote collaboration between Augmented Reality (AR) and Virtual Reality (VR) environments, using physiological signals to enhance collaborative VR, and supporting interaction through eye-gaze in VR. Early outcomes indicate that as we design collaborative interfaces to enhance empathy between people, this could also benefit the personal experience of the individual interacting with the interface.",2017.0,9.0,47.0,False,,"{'pages': '38-41', 'name': '2017 International Symposium on Ubiquitous Virtual Reality (ISUVR)'}","{'bibtex': '@Article{Piumsomboon2017EmpathicMR,\n author = {Thammathip Piumsomboon and Youngho Lee and Gun A. Lee and Arindam Dey and M. Billinghurst},\n journal = {2017 International Symposium on Ubiquitous Virtual Reality (ISUVR)},\n pages = {38-41},\n title = {Empathic Mixed Reality: Sharing What You Feel and Interacting with What You See},\n year = {2017}\n}\n'}","[{'authorId': '2297177', 'name': 'Thammathip Piumsomboon'}, {'authorId': '144588775', 'name': 'Youngho Lee'}, {'authorId': '48534381', 'name': 'Gun A. Lee'}, {'authorId': '152168867', 'name': 'Arindam Dey'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}]"
2330,c997832c0ee12467dad8efed4e89a1fdd9b827e5,High school students involved and not involved in MMORPG: Creativity and innovativeness,"The paper presents a theoretical and empirical analysis of involvement phenomenon in massively multiplayer online role-playing games among high school students. The characteristics of the virtual world are analyzed; its role in the life and activity of modern people is substantiated. The main features of the games that make them the most attractive to users and contribute to their active involvement in the game process are highlighted. The advantages of mass multiplayer online role-playing games are substantiated. On the basis of the theoretical analysis was formulated the aim of the study: to identify differences in the manifestations of innovativeness and creativity in high school students involved and not involved in MMORPG. Hypotheses about the existence of significant connections and differences in the manifestations of innovativeness and creativity in those involved and not involved in this type of games are formulated. The study involved 120 students of 10-11th forms and was based on the following methods: 1) questionnaire to assess the degree of enthusiasm in role-playing computer games; 2) questionnaire for the study of gaming activity, experience and gaming genre preferences of the individual; 3) self-assessment scale of personal innovative traits; 4) a multidimensional questionnaire “Innovativeness of a personality” - MQIP; 5) “Creativity” test. As a result of the study those involved in computer games are characterized by higher originality, imagination and creative thinking than their peers not playing massive multiplayer online role-playing games. The article presents a number of recommendations on the use of the plot potential of multiplayer online role-playing games for the development of high school students’ personality in modern teaching practice.",2019.0,20.0,3.0,True,"{'url': 'https://scindeks-clanci.ceon.rs/data/pdf/2334-847X/2019/2334-847X1902029M.pdf', 'status': None}",{'name': 'International Journal of Cognitive Research in Science Engineering and Education'},"{'bibtex': '@Article{Mikhailova2019HighSS,\n author = {Olga V. Mikhailova},\n journal = {International Journal of Cognitive Research in Science Engineering and Education},\n title = {High school students involved and not involved in MMORPG: Creativity and innovativeness},\n year = {2019}\n}\n'}","[{'authorId': '2130432298', 'name': 'Olga V. Mikhailova'}]"
2331,c9ab662270b8fa115323443fb95bb328aa0ec483,Bioinformatics Algorithms: An Active Learning Approach,Where in the genome does DNA replication begin? -- How do we sequence antibiotics? -- Which DNA patterns play the role of molecular clocks? -- How do we assemble genomes? -- How do we compare biological sequences? -- Are there fragile regions in the human genome? -- How do we locate disease-causing mutations?.,2014.0,0.0,43.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Compeau2014BioinformaticsAA,\n author = {Phillip E. C. Compeau and P. Pevzner},\n title = {Bioinformatics Algorithms: An Active Learning Approach},\n year = {2014}\n}\n'}","[{'authorId': '2249981', 'name': 'Phillip E. C. Compeau'}, {'authorId': '1779993', 'name': 'P. Pevzner'}]"
2332,c9b5d487e0aff4a25de0c73276a7584beba53f40,The Influence of robot personality on the development of uncanny feelings,,2021.0,79.0,27.0,True,"{'url': 'https://uu.diva-portal.org/smash/get/diva2:1464376/FULLTEXT01', 'status': None}","{'volume': '120', 'pages': '106756', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Paetzel-Prüsmann2021TheIO,\n author = {Maike Paetzel-Prüsmann and G. Perugia and Ginevra Castellano},\n journal = {Comput. Hum. Behav.},\n pages = {106756},\n title = {The Influence of robot personality on the development of uncanny feelings},\n volume = {120},\n year = {2021}\n}\n'}","[{'authorId': '2047241817', 'name': 'Maike Paetzel-Prüsmann'}, {'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
2333,c9c5b4e22be1af958adb9fe7445ddc9d039bfad3,Self-attachment: A Holistic Approach to Computational Psychiatry,,2017.0,109.0,22.0,True,"{'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/74080/2/self-attachment-f.pdf', 'status': None}","{'volume': '', 'pages': '273-314', 'name': ''}","{'bibtex': '@Inproceedings{Edalat2017SelfattachmentAH,\n author = {A. Edalat},\n pages = {273-314},\n title = {Self-attachment: A Holistic Approach to Computational Psychiatry},\n year = {2017}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}]"
2336,c9ca8870825330298a7230919a1dd381fa050202,An Approach to Analyze User’s Emotion in HCI Experiments Using Psychophysiological Measures,"Emotional experiences have aroused HCI researchers’ interest once these types of experience involve many parts of our body, such as muscles, body postures, and psychophysiological measures. Hedonic experiences give us pleasure and good emotions, and this paper focuses on it. Some psychophysiological measures have already been correlated with both valence and arousal, the main dimensions of emotion. However, a consensus has not been reached on which psychophysiological measure better represents the emotion’s dimensions. In this paper, three combined non-invasive psychophysiological measures were used to verify which of them represents the emotion’s dimensions. Besides that, an approach to studying the tendency of user’s emotion is presented, assisting HCI researchers in HCI experiments. An experiment was conducted using quantitative and qualitative data analysis, and the results show important correlations that were used in the proposed approach.",2019.0,27.0,12.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08668689.pdf', 'status': None}","{'volume': '7', 'pages': '36471-36480', 'name': 'IEEE Access'}","{'bibtex': '@Article{Maia2019AnAT,\n author = {Camila Loiola Brito Maia and E. Furtado},\n journal = {IEEE Access},\n pages = {36471-36480},\n title = {An Approach to Analyze User’s Emotion in HCI Experiments Using Psychophysiological Measures},\n volume = {7},\n year = {2019}\n}\n'}","[{'authorId': '2055670111', 'name': 'Camila Loiola Brito Maia'}, {'authorId': '1755605', 'name': 'E. Furtado'}]"
2337,c9ec92da00669e9a1fa1dc33cebd1420c11cb768,Never Alone in the Crowd: A Microscopic Crowd Model Based on Emotional Contagion,"This paper presents a system designed to create crisis-simulation that shows the emergence of crowd behavior from individual behaviors, based on the emotional contagion phenomenon. Many studies from psychology and sociology mention this phenomenon but very little was found about what parameters determine it. This paper proposes a model of emotional contagion based on individual personality and relationships. A key contribution of this work is describing a computational mapping from OCEAN personality traits to the strength of, and susceptibility to, emotional contagion. This model is implemented into a multi-agent system where everyone is represented by an emotional, social and cognitive agent.",2011.0,18.0,25.0,False,,"{'volume': '2', 'pages': '89-92', 'name': '2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology'}","{'bibtex': '@Article{Lhommet2011NeverAI,\n author = {Margot Lhommet and D. Lourdeaux and J. Barthès},\n journal = {2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology},\n pages = {89-92},\n title = {Never Alone in the Crowd: A Microscopic Crowd Model Based on Emotional Contagion},\n volume = {2},\n year = {2011}\n}\n'}","[{'authorId': '1930380', 'name': 'Margot Lhommet'}, {'authorId': '1790872', 'name': 'D. Lourdeaux'}, {'authorId': '2084784', 'name': 'J. Barthès'}]"
2338,ca43ed7c7fb969d034eb6d13af3d290f1cd7dd5b,Intelligent Virtual Agents,"Emotional expression is a key requirement for intelligent virtual agents. In order for an agent to produce dynamic spoken content speech synthesis is required. However, despite substantial work with pre-recorded prompts, very little work has explored the combined effect of high quality emotional speech synthesis and facial expression. In this paper we offer a baseline evaluation of the naturalness and emotional range available by combining the freely available SmartBody component of the Virtual Human Toolkit (VHTK) with CereVoice text to speech (TTS) system. Results echo previous work using pre-recorded prompts, the visual modality is dominant and the modalities do not interact. This allows the speech synthesis to add gradual changes to the perceived emotion both in terms of valence and activation. The naturalness reported is good, 3.54 on a 5 point MOS scale.",2008.0,13.0,75.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Potard2008IntelligentVA,\n author = {B. Potard and M. Aylett and David A. Baude},\n title = {Intelligent Virtual Agents},\n year = {2008}\n}\n'}","[{'authorId': '1762616', 'name': 'B. Potard'}, {'authorId': '1702205', 'name': 'M. Aylett'}, {'authorId': '48317415', 'name': 'David A. Baude'}]"
2339,ca520a78baed5d93834377f150c1a56717e33cee,FACe! 3D Facial Animation System based on FACS,"In this paper we present a 3D facial animation system named FACe! It is able to generate different expressions of the face throughout punctual and combined activation of Action Units, defined by Facial Acting Coding System(FACS). This system is implemented on a 3D human head controlled by bones, riggers and skinning to deform the 
geometry. The bone system is implemented in order to move single or combined Action Units, so that they can implement superior layers such as expressions, phonemes, words, emotions and the synchronization of all them 
together.",2009.0,13.0,23.0,False,,"{'volume': '', 'pages': '203-209', 'name': ''}","{'bibtex': '@Inproceedings{Villagrasa2009FACe3F,\n author = {Sergi Villagrasa and Antoni Susín Sánchez},\n pages = {203-209},\n title = {FACe! 3D Facial Animation System based on FACS},\n year = {2009}\n}\n'}","[{'authorId': '3275137', 'name': 'Sergi Villagrasa'}, {'authorId': '144883071', 'name': 'Antoni Susín Sánchez'}]"
2340,ca642f0448a305dc35071e1160b5b7952ba081c7,The Roles of Animated Pedagogical Agents' Presence and Nonverbal Communication in Multimedia Learning Environments,We examined how the presence and nonverbal communication of an animated pedagogical agent affects students’ perceptions and learning. College students learned about astronomy either without an agen...,2010.0,50.0,66.0,False,,"{'volume': '22', 'pages': '61-72', 'name': 'J. Media Psychol. Theor. Methods Appl.'}","{'bibtex': ""@Article{Frechette2010TheRO,\n author = {Casey Frechette and R. Moreno},\n journal = {J. Media Psychol. Theor. Methods Appl.},\n pages = {61-72},\n title = {The Roles of Animated Pedagogical Agents' Presence and Nonverbal Communication in Multimedia Learning Environments},\n volume = {22},\n year = {2010}\n}\n""}","[{'authorId': '2445038', 'name': 'Casey Frechette'}, {'authorId': '144006457', 'name': 'R. Moreno'}]"
2341,ca6587d319c317cef0753546e9d738022c551cd2,Evidence for Altruism: Toward a Pluralism of Prosocial Motives,"Psychologists have long assumed that the motivation for all intentional action, including all action intended to benefit others, is egoistic. People benefit others because, ultimately, to do so benefits themselves. The empathy-altruism hypothesis challenges this assumption. It claims that empathic emotion evokes truly altruistic motivation, motivation with an ultimate goal of benefiting not the self but the person for whom empathy is felt. Logical and psychological distinctions between egoism and altruism are reviewed, providing a conceptualframeworkfor empirical tests for the existence of altruism. Results of empirical tests to date are summarized; these results provide impressive support for the empathy-altruism hypothesis. We conclude that the popular and parsimonious explanation of prosocial motivation in terms of universal egoism must give way to a pluralistic explanation that includes altruism as well as egoism. Implications of such a pluralism are briefly noted, not only for our understanding of prosocial motivation but also for our understanding of human nature and of the emotion-motivation link. We humans devote much time and energy to helping others. We send money to rescue famine victims halfway around the world. We work to save whales. We stay up all night to comfort a friend who has just suffered a broken relationship. We stop on a busy highway to help a stranded motorist change a flat.",1991.0,100.0,1078.0,False,,"{'volume': '2', 'pages': '107-122', 'name': 'Psychological Inquiry'}","{'bibtex': '@Article{Batson1991EvidenceFA,\n author = {C. Batson and Laura L. Shaw},\n journal = {Psychological Inquiry},\n pages = {107-122},\n title = {Evidence for Altruism: Toward a Pluralism of Prosocial Motives},\n volume = {2},\n year = {1991}\n}\n'}","[{'authorId': '32526876', 'name': 'C. Batson'}, {'authorId': '145911430', 'name': 'Laura L. Shaw'}]"
2342,ca6b3dda45a82093453aa4d3ea0b3293b59bfad9,Facial Expressions in Hollywood's Portrayal of Emotion,"Much theory and research on emotion are based on the facial expressions of amateurs asked to pose for still photographs. The theory of facial affect programs (FAPs; P. Ekman, 1972) was proposed to account for the resulting expressions, most of which are patterns consisting of distinguishab le parts. In the present study, 4 Hollywood films noted for fine acting and realism were examined for the facial expressions that accompany a basic emotion. In keeping with the theory of FAPs, professional actors judged as happy were found smiling in 97% (Duchenne smiling in 74%) of cases. In contrast, actors judged as surprised, afraid, angry, disgusted, or sad rarely showed the predicted pattern (found in 0 to 31% of cases). Typically, they used one or two parts from the full pattern. If these films represent real life, these findings favor a theory that assumes separable parts (e.g., components theory) over the older theory of FAPs.",1997.0,54.0,195.0,False,,"{'volume': '72', 'pages': '164-176', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': ""@Article{Carroll1997FacialEI,\n author = {James M. Carroll and J. Russell},\n journal = {Journal of Personality and Social Psychology},\n pages = {164-176},\n title = {Facial Expressions in Hollywood's Portrayal of Emotion},\n volume = {72},\n year = {1997}\n}\n""}","[{'authorId': '3024196', 'name': 'James M. Carroll'}, {'authorId': '46367714', 'name': 'J. Russell'}]"
2343,ca988237c817d77630ce37dd8da0cbdfc87f4fe4,Towards a narrative theory of virtual reality,,2003.0,39.0,132.0,True,"{'url': 'http://www.macs.hw.ac.uk/~ruth/Papers/narrative/VRTowardsNarrativeTheory.pdf', 'status': None}","{'volume': '7', 'pages': '2-9', 'name': 'Virtual Reality'}","{'bibtex': '@Article{Aylett2003TowardsAN,\n author = {R. Aylett and S. Louchart},\n journal = {Virtual Reality},\n pages = {2-9},\n title = {Towards a narrative theory of virtual reality},\n volume = {7},\n year = {2003}\n}\n'}","[{'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '2910576', 'name': 'S. Louchart'}]"
2344,ca9c2a8dd5bdc4ea258357faafcb1e69a0c1c116,When the User Is Instrumental to Robot Goals: First Try – Agent Uses Agent,"To create a robot with a mind of its own, we extended a formalized version of a model that explains affect-driven interaction with mechanisms for goal-directed behavior. We ran simulation experiments with intelligent software agents and found that agents preferred affect-driven decision options to rational decision options in situations where choices for low expected utility are irrational. This behavior counters current models in decision making, which generally have a hedonic bias and always select the option with the highest expected utility.",2008.0,19.0,21.0,False,,"{'volume': '2', 'pages': '296-301', 'name': '2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology'}","{'bibtex': '@Article{Hoorn2008WhenTU,\n author = {J. Hoorn and M. Pontier and G. F. Siddiqui},\n journal = {2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},\n pages = {296-301},\n title = {When the User Is Instrumental to Robot Goals: First Try – Agent Uses Agent},\n volume = {2},\n year = {2008}\n}\n'}","[{'authorId': '71825175', 'name': 'J. Hoorn'}, {'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}]"
2345,cad578558e66cba8afbd20fd0514035a02b153f1,Asymmetric facial expressions: revealing richer emotions for embodied conversational agents,"In this paper, we propose a method to achieve effective facial emotional expressivity for embodied conversational agents by considering two types of asymmetry when exploiting the valence–arousal–dominance representation of emotions. Indeed, the asymmetry of facial expressions helps to convey complex emotional feelings such as conflicting and/or hidden emotions due to social conventions. To achieve such a higher degree of facial expression in a generic way, we propose a new model for mapping the valence–arousal–dominance emotion model onto a set of 12 scalar facial part actions built mostly by combining pairs of antagonist action units from the Facial Action Coding System. The proposed linear model can automatically drive a large number of autonomous virtual humans or support the interactive design of complex facial expressions over time. By design, our approach produces symmetric facial expressions, as expected for most of the emotional spectrum. However, more complex ambivalent feelings can be produced when differing emotions are applied on the left and right sides of the face. We conducted an experiment on static images produced by our approach to compare the expressive power of symmetric and asymmetric facial expressions for a set of eight basic and complex emotions. Results confirm both the pertinence of our general mapping for expressing basic emotions and the significant improvement brought by asymmetry for expressing ambivalent feelings. Copyright © 2013 John Wiley & Sons, Ltd.",2013.0,51.0,11.0,True,"{'url': 'http://infoscience.epfl.ch/record/187597/files/Ahn_AsymFace_preprint.pdf', 'status': None}","{'volume': '24', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Ahn2013AsymmetricFE,\n author = {Junghyun Ahn and S. Gobron and D. Thalmann and R. Boulic},\n journal = {Computer Animation and Virtual Worlds},\n title = {Asymmetric facial expressions: revealing richer emotions for embodied conversational agents},\n volume = {24},\n year = {2013}\n}\n'}","[{'authorId': '1683972', 'name': 'Junghyun Ahn'}, {'authorId': '1696846', 'name': 'S. Gobron'}, {'authorId': '2223622395', 'name': 'D. Thalmann'}, {'authorId': '1696973', 'name': 'R. Boulic'}]"
2346,cb13e29fb8af6cfca568c6dc523da04d1db1fff5,"A Survey of Automatic Facial Micro-Expression Analysis: Databases, Methods, and Challenges","Over the last few years, automatic facial micro-expression analysis has garnered increasing attention from experts across different disciplines because of its potential applications in various fields such as clinical diagnosis, forensic investigation and security systems. Advances in computer algorithms and video acquisition technology have rendered machine analysis of facial micro-expressions possible today, in contrast to decades ago when it was primarily the domain of psychiatrists where analysis was largely manual. Indeed, although the study of facial micro-expressions is a well-established field in psychology, it is still relatively new from the computational perspective with many interesting problems. In this survey, we present a comprehensive review of state-of-the-art databases and methods for micro-expressions spotting and recognition. Individual stages involved in the automation of these tasks are also described and reviewed at length. In addition, we also deliberate on the challenges and future directions in this growing field of automatic facial micro-expression analysis.",2018.0,141.0,112.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01128/pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Oh2018ASO,\n author = {Yee-Hui Oh and John See and A. Ngo and R. Phan and Vishnu Monn Baskaran},\n journal = {Frontiers in Psychology},\n title = {A Survey of Automatic Facial Micro-Expression Analysis: Databases, Methods, and Challenges},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '2154760', 'name': 'Yee-Hui Oh'}, {'authorId': '143937986', 'name': 'John See'}, {'authorId': '35256518', 'name': 'A. Ngo'}, {'authorId': '145016295', 'name': 'R. Phan'}, {'authorId': '34287833', 'name': 'Vishnu Monn Baskaran'}]"
2347,cb3d65e8f91d204b687a8187240c96bffa88d352,Teaching Facial Expression Production in Autism: The Serious Game JEMImE,"Background: Children with autism spectrum disorder (ASD) show impairment in producing facial expressions adapted to social contexts. Several serious games have been computed to help them dealing with facial expression recognition but very few focused on facial expression production adapted to a given social context. Method: JEMImE is a new serious game which aims to help the player to learn how to produce happiness, anger and sadness in a 3D virtual environment with social situations that should be resolved by producing the correct facial expression. He is guided in the game thanks to facial expression feedback and gauges that help him evaluating the quality of his/her production in real time. The feedbacks on the children productions are timely given by a facial expression recognition algorithm integrated in JEMImE architecture. Specific attention was paid to the visual and motivational aspects of the game. Using a brief feasibility study with children with ASD (N = 23), we evaluated the impression of the players on the game aspect and the possibility to insert algorithmic feedbacks in real time inside JEMImE. Results: During the training phase, children with ASD showed a significant progression during training for facial expression production after algorithmic autonomous feedbacks. This means children understand the challenge and that the algorithmic feedbacks are transparent enough to allow gaming. They expressed an overall good subjective experience with JEMImE in terms of ergonomics, playability, visual aspect and motivation. Conclusion: We conclude that the beta-version of JEMImE shows promising potential and that research should proceed on computing more games and scenarios to offer a longer game exposure to children to allow adequate clinical validation.",2019.0,30.0,8.0,True,,{'name': 'Creative Education'},"{'bibtex': '@Article{Grossard2019TeachingFE,\n author = {Charline Grossard and S. Hun and Arnaud Dapogny and Estelle Juillet and Fanny Hamel and Heidy Jean-Marie and J. Bourgeois and Hugues Pellerin and Pierre Foulon and S. Serret and O. Grynszpan and Kévin Bailly and David Cohen},\n journal = {Creative Education},\n title = {Teaching Facial Expression Production in Autism: The Serious Game JEMImE},\n year = {2019}\n}\n'}","[{'authorId': '8756234', 'name': 'Charline Grossard'}, {'authorId': '7737732', 'name': 'S. Hun'}, {'authorId': '3190846', 'name': 'Arnaud Dapogny'}, {'authorId': '146618116', 'name': 'Estelle Juillet'}, {'authorId': '2074178175', 'name': 'Fanny Hamel'}, {'authorId': '1484356416', 'name': 'Heidy Jean-Marie'}, {'authorId': '50075632', 'name': 'J. Bourgeois'}, {'authorId': '40866522', 'name': 'Hugues Pellerin'}, {'authorId': '48223216', 'name': 'Pierre Foulon'}, {'authorId': '6312012', 'name': 'S. Serret'}, {'authorId': '2791712', 'name': 'O. Grynszpan'}, {'authorId': '2521061', 'name': 'Kévin Bailly'}, {'authorId': '2115016309', 'name': 'David Cohen'}]"
2348,cb3dd836eb28a064896e13fd4a2f0d2aeccede5e,Usability evaluation of an immersive virtual reality platform for self-attachment psychotherapy,"Virtual Reality (VR) is the state-of-the-art human-computer interface; it uses computer graphics to create a realistic-looking virtual world that the user can interact with in real-time. Recent advances in VR have shown promise in the pursuit of devising new techniques to combat mental disorder(s). Har-nessing the power of VR, we have developed a customised immersive virtual reality platform to practise protocols of self-attachment psychotherapy. Consumer-level VR is a recent phenomenon; for wide scale adaptation of such platforms it is important that they are built taking into account usability engineering principles speciﬁc to virtual environments(VE). In this work, we share our experience applying systematic heuristic and formative evaluations to our VR platform to make it more usable. The participants who evaluated our platform were asked (via a follow-up questionnaire) to rate their level-of-immersion, learn-ability and overall usability of the platform. Insights from our usability evaluation could help developers build better and more usable psycho-therapeutic VR platforms in the future.",2019.0,17.0,7.0,False,,,"{'bibtex': '@Inproceedings{Ghaznavi2019UsabilityEO,\n author = {I. Ghaznavi and Usman Jehanzeb and Duncan Gillies},\n title = {Usability evaluation of an immersive virtual reality platform for self-attachment psychotherapy},\n year = {2019}\n}\n'}","[{'authorId': '2485535', 'name': 'I. Ghaznavi'}, {'authorId': '2101444684', 'name': 'Usman Jehanzeb'}, {'authorId': '146493111', 'name': 'Duncan Gillies'}]"
2350,cb8ca0655b0ab1ef3f05d80e7260b9c361dc126a,Tag it!: AR annotation using wearable sensors,"In this paper we describe a wearable system that allows people to place and interact with 3D virtual tags placed around them. This uses two wearable technologies: a head-worn wearable computer (Google Glass) and a chest-worn depth sensor (Tango). The Google Glass is used to generate and display virtual information to the user, while the Tango is used to provide robust indoor position tracking for the Glass. The Tango enables spatial awareness of the surrounding world using various motion sensors including 3D depth sensing, an accelerometer and a motion tracking camera. Using these systems together allows users to create a virtual tag via voice input and then register this tag to a physical object or position in 3D space as an augmented annotation. We describe the design and implementation of the system, user feedback, research implications, and directions for future work.",2015.0,4.0,28.0,False,,{'name': 'SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications'},"{'bibtex': '@Article{Nassani2015TagIA,\n author = {Alaeddin Nassani and Huidong Bai and Gun A. Lee and M. Billinghurst},\n journal = {SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications},\n title = {Tag it!: AR annotation using wearable sensors},\n year = {2015}\n}\n'}","[{'authorId': '2363053', 'name': 'Alaeddin Nassani'}, {'authorId': '1759034', 'name': 'Huidong Bai'}, {'authorId': '48534381', 'name': 'Gun A. Lee'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}]"
2351,cbb29e3008cba2266a3a3e017fab60000878ab84,Facial emotion recognition using multi-modal information,"Facial emotion recognition will become vitally important in future multi-cultural visual communication systems, for emotion translation between cultures, which may be considered analogous to speech translation. However so far the recognition of facial emotions is mainly addressed by computer vision researchers, based on facial display. Also detection of vocal expressions of emotions can be found in research work done by acoustic researchers. Most of these research paradigms are devoted purely to visual or purely to auditory human emotion detection. However we found that it is very interesting to consider both these auditory and visual information together, for processing, since we hope this kind of multi-modal information processing will become a datum of information processing in future multimedia era. By several intensive subjective evaluation studies we found that human beings recognise anger, happiness, surprise and dislike by their visual appearance, compared to voice only detection. When the audio track of each emotion clip is dubbed with a different type of auditory emotional expression, still anger, happiness and surprise were video dominant. However the dislike emotion gave mixed responses to different speakers. In both studies we found that sadness and fear emotions were audio dominant. As a conclusion, we propose a method of facial emotion detection by using a hybrid approach, which uses multi-modal information for facial emotion recognition.",1997.0,12.0,233.0,False,,"{'volume': '1', 'pages': '397-401 vol.1', 'name': 'Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat.'}","{'bibtex': '@Article{Silva1997FacialER,\n author = {L. C. D. Silva and T. Miyasato and R. Nakatsu},\n journal = {Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat.},\n pages = {397-401 vol.1},\n title = {Facial emotion recognition using multi-modal information},\n volume = {1},\n year = {1997}\n}\n'}","[{'authorId': '2220211943', 'name': 'L. C. D. Silva'}, {'authorId': '2407080', 'name': 'T. Miyasato'}, {'authorId': '2458123', 'name': 'R. Nakatsu'}]"
2352,cc11380ded972a25976e184e3d6d434a16612a40,Making Them Remember—Emotional Virtual Characters with Memory,"Research on virtual characters has been ongoing for the past 20 years. Early efforts focused mostly on making the characters move and speak that is, on body and facial animation. Simultaneously, researchers worked on making characters look convincing by adding animation and rendering hair, clothes, and muscles. The next step was to increase artists' interactive control over characters so that it was easier to create convincing video games and cinema.",2009.0,20.0,105.0,True,"{'url': 'https://infoscience.epfl.ch/record/199429/files/510.pdf', 'status': None}","{'volume': '29', 'pages': '20-29', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Kasap2009MakingTR,\n author = {Zerrin Kasap and M. B. Moussa and P. Chaudhuri and N. Magnenat-Thalmann},\n journal = {IEEE Computer Graphics and Applications},\n pages = {20-29},\n title = {Making Them Remember—Emotional Virtual Characters with Memory},\n volume = {29},\n year = {2009}\n}\n'}","[{'authorId': '2671891', 'name': 'Zerrin Kasap'}, {'authorId': '2497958', 'name': 'M. B. Moussa'}, {'authorId': '32319566', 'name': 'P. Chaudhuri'}, {'authorId': '1387241200', 'name': 'N. Magnenat-Thalmann'}]"
2353,cc3b557cd80a9c36083769c4e370a4b10567c073,ANVIL - a generic annotation tool for multimodal dialogue,"Anvil is a tool for the annotation of audiovisual material containing multimodal dialogue. Annotation takes place on freely definable, multiple layers (tracks) by inserting time-anchored elements that hold a number of typed attribute-value pairs. Higher-level elements (suprasegmental) consist of a sequence of elements. Attributes contain symbols or cross-level links to arbitrary other elements. Anvil is highly generic (usable with different annotation schemes), platform-independent, XMLbased and fitted with an intuitive graphical user interface. For project integration, Anvil offers the import of speech transcription and export of text and table data for further statistical processing.",2001.0,11.0,651.0,False,,{'pages': '1367-1370'},"{'bibtex': '@Inproceedings{Kipp2001ANVILA,\n author = {Michael Kipp},\n pages = {1367-1370},\n title = {ANVIL - a generic annotation tool for multimodal dialogue},\n year = {2001}\n}\n'}","[{'authorId': '145616714', 'name': 'Michael Kipp'}]"
2354,cc4c0205dafea88e7b8349ed26cefca95970da8a,Engagement Modeling in Dyadic Interaction,"In the recent years, engagement modeling has gained increasing attention due the important role it plays in human-agent interaction. The agent should be able to detect, in real time, the engagement level of the user in order to react accordingly. In this context, our goal is to develop a computational model to predict engagement level of the user in real time. Relying on previous findings, we use facial expressions, head movements and gaze direction as predictive features. Moreover, engagement is not only measured from single cues, but from the combination of several cues that arise over a certain time window. Thus, for better engagement prediction, we consider the variation of multimodal behaviors over time. To this end, we rely on LSTM that can jointly model the temporality and the sequentiality of multimodal behaviors.",2019.0,26.0,23.0,False,,{'name': '2019 International Conference on Multimodal Interaction'},"{'bibtex': '@Article{Dermouche2019EngagementMI,\n author = {Soumia Dermouche and C. Pelachaud},\n journal = {2019 International Conference on Multimodal Interaction},\n title = {Engagement Modeling in Dyadic Interaction},\n year = {2019}\n}\n'}","[{'authorId': '8447202', 'name': 'Soumia Dermouche'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2355,cc6f1228a42e005777f0cb05c010916f96b70535,Towards Empathic Virtual and Robotic Tutors,,2013.0,16.0,92.0,False,,{'pages': '733-736'},"{'bibtex': '@Inproceedings{Castellano2013TowardsEV,\n author = {Ginevra Castellano and Ana Paiva and Arvid Kappas and R. Aylett and H. Hastie and W. Barendregt and F. Nabais and S. Bull},\n pages = {733-736},\n title = {Towards Empathic Virtual and Robotic Tutors},\n year = {2013}\n}\n'}","[{'authorId': '39540970', 'name': 'Ginevra Castellano'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '1742554', 'name': 'Arvid Kappas'}, {'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '1691444', 'name': 'H. Hastie'}, {'authorId': '2431058', 'name': 'W. Barendregt'}, {'authorId': '3191258', 'name': 'F. Nabais'}, {'authorId': '145681472', 'name': 'S. Bull'}]"
2357,cc78b1b04f69aab8e5ebd250da1d9eb35f2ab986,Understanding age differences in PDA acceptance and performance,,2007.0,39.0,339.0,False,,"{'volume': '23', 'pages': '2904-2927', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Arning2007UnderstandingAD,\n author = {K. Arning and M. Ziefle},\n journal = {Comput. Hum. Behav.},\n pages = {2904-2927},\n title = {Understanding age differences in PDA acceptance and performance},\n volume = {23},\n year = {2007}\n}\n'}","[{'authorId': '1756885', 'name': 'K. Arning'}, {'authorId': '1727090', 'name': 'M. Ziefle'}]"
2358,cc8f8d9b897d4d0928126741d8797298743c93e8,User Modeling,,2009.0,0.0,35.0,False,,{'pages': '1-19'},"{'bibtex': '@Inproceedings{Adams2009UserM,\n author = {R. Adams},\n pages = {1-19},\n title = {User Modeling},\n year = {2009}\n}\n'}","[{'authorId': '2142225701', 'name': 'R. Adams'}]"
2359,ccab4cc81387d1b1f095ce4fe74aad5ed4f73305,DEVELOPMENT AND EVALUATION OF AN INTERACTIVE ENGLISH CONVERSATION LEARNING SYSTEM WITH A MOBILE DEVICE USING TOPICS BASED ON THE LIFE OF THE LEARNER,"Motivating Japanese EFL (English as a foreign language) learners is essential in order for them to learn English conversation effectively. We developed an English conversation mobile learning system based on a heuristic model of variables influencing the concept of “willing to communicate” by MacIntyre et al. The system has three features: an application that learners can use anywhere and anytime, topics based on the interests and lives of learners, and pseudo-interactive and agreeable English conversation. The results of an experiment and analysis revealed that the topics based on the interests and lives of learners might be effective for talking in English with relaxed from the beginning and for talking with motivation, while a pseudo-interactive and agreeable English conversation style might work well in helping learners evaluate themselves to speak more fluently, express themselves better, and speak in a more relaxed manner as they continue to practice speaking.",2013.0,26.0,9.0,False,,,"{'bibtex': '@Inproceedings{Nakaya2013DEVELOPMENTAE,\n author = {Kae Nakaya and M. Murota},\n title = {DEVELOPMENT AND EVALUATION OF AN INTERACTIVE ENGLISH CONVERSATION LEARNING SYSTEM WITH A MOBILE DEVICE USING TOPICS BASED ON THE LIFE OF THE LEARNER},\n year = {2013}\n}\n'}","[{'authorId': '7545906', 'name': 'Kae Nakaya'}, {'authorId': '1775359', 'name': 'M. Murota'}]"
2360,ccab7135aa1410744d62830955d8c4c2d2bc7350,"Darwin, Deception, and Facial Expression","Abstract: Darwin did not focus on deception. Only a few sentences in his book mentioned the issue. One of them raised the very interesting question of whether it is difficult to voluntarily inhibit the emotional expressions that are most difficult to voluntarily fabricate. Another suggestion was that it would be possible to unmask a fabricated expression by the absence of the difficult‐to‐voluntarily‐generate facial actions. Still another was that during emotion body movements could be more easily suppressed than facial expression. Research relevant to each of Darwin's suggestions is reviewed, as is other research on deception that Darwin did not foresee.",2003.0,61.0,566.0,False,,"{'volume': '1000', 'name': 'Annals of the New York Academy of Sciences'}","{'bibtex': '@Article{Ekman2003DarwinDA,\n author = {P. Ekman},\n journal = {Annals of the New York Academy of Sciences},\n title = {Darwin, Deception, and Facial Expression},\n volume = {1000},\n year = {2003}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}]"
2361,ccb03a53ce4a6384a75cfb623a2ac9e8cd0a0b21,Implicit Bias in Crowdsourced Knowledge Graphs,"Collaborative creation of knowledge is an approach which has been successfully demonstrated by crowdsourcing project like Wikipedia. Similar techniques have recently been adopted for the creation of collaboratively generated Knowledge Graphs like, for example, Wikidata. While such an approach enables the creation of high quality structured content, it also comes with the challenge of introducing contributors’ implicit bias in the generated Knowledge Graph. In this paper, we investigate how paid crowdsourcing can be used to understand contributor bias for controversial facts to be included into collaborative Knowledge Graphs. We propose methods to trace the provenance of crowdsourced fact checking thus enabling bias transparency rather than aiming at eliminating bias from the Knowledge Graph.",2019.0,24.0,17.0,False,,{'name': 'Companion Proceedings of The 2019 World Wide Web Conference'},"{'bibtex': '@Article{Demartini2019ImplicitBI,\n author = {Gianluca Demartini},\n journal = {Companion Proceedings of The 2019 World Wide Web Conference},\n title = {Implicit Bias in Crowdsourced Knowledge Graphs},\n year = {2019}\n}\n'}","[{'authorId': '1694274', 'name': 'Gianluca Demartini'}]"
2362,ccb7344488be239decf07430267176a5e3d609ed,Tactile brush: drawing on skin with a tactile grid display,"Tactile Brush is an algorithm that produces smooth, two-dimensional tactile moving strokes with varying frequency, intensity, velocity and direction of motion. The design of the algorithm is derived from the results of psychophysical investigations of two tactile illusions -- apparent tactile mo-tion and phantom sensations. Combined together they allow for the design of high-density two-dimensional tactile displays using sparse vibrotactile arrays. In a series of experiments and evaluations we demonstrate that Tactile Brush is robust and can reliably generate a wide variety of moving tactile sensations for a broad range of applications.",2011.0,37.0,281.0,False,,{'name': 'Proceedings of the SIGCHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Israr2011TactileBD,\n author = {A. Israr and I. Poupyrev},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Tactile brush: drawing on skin with a tactile grid display},\n year = {2011}\n}\n'}","[{'authorId': '1769549', 'name': 'A. Israr'}, {'authorId': '1736819', 'name': 'I. Poupyrev'}]"
2363,ccdabcf81bab920e16e84163ba92507eb7cb7bf9,A Foundational Architecture for Artificial General Intelligence,"Implementing and fleshing out a number of psychological and neuroscience theories of cognition, the LIDA conceptual model aims at being a cognitive “theory of everything.” With modules or processes for perception, working memory, episodic memories, “consciousness,” procedural memory, action selection, perceptual learning, episodic learning, deliberation, volition, and non-routine problem solving, the LIDA model is ideally suited to provide a working ontology that would allow for the discussion, design, and comparison of AGI systems. The LIDA architecture is based on the LIDA cognitive cycle, a sort of “cognitive atom.” The more elementary cognitive modules and processes play a role in each cognitive cycle. Higher-level processes are performed over multiple cycles. In addition to giving a quick overview of the LIDA conceptual model, and its underlying computational technology, we argue for the LIDA architecture's role as a foundational architecture for an AGI. Finally, lessons For AGI researchers drawn from the model and its architecture are discussed.",2007.0,72.0,64.0,False,,{'pages': '36-54'},"{'bibtex': '@Inproceedings{Franklin2007AFA,\n author = {S. Franklin},\n pages = {36-54},\n title = {A Foundational Architecture for Artificial General Intelligence},\n year = {2007}\n}\n'}","[{'authorId': '145796793', 'name': 'S. Franklin'}]"
2364,ccdbc666f2b82c8fb4530db1a9df247f06c6655d,All PTSD symptoms are highly associated with general distress: ramifications for the dysphoria symptom cluster.,"This study used longitudinal data collected from two trauma-exposed samples, survivors of community violence (N = 294) and wildfire evacuees (N = 234), to examine a key claim underlying a proposed reformulation of the symptom structure of posttraumatic stress disorder (PTSD). This theory, which we term the PTSD-dysphoria model, posits that 8 of 17 symptoms of PTSD reflect dysphoria or general psychological distress and might be deemphasized to improve the utility of the PTSD construct (Simms, Watson, & Doebbeling, 2002). For each sample, we analyzed PTSD symptoms and measures of general distress administered at 2 time points. A consistent pattern of findings was observed across assessments for each sample: All 17 PTSD symptoms were highly associated with measures of general distress. Moreover, we found no evidence that dysphoria symptoms were more highly correlated than PTSD-specific symptoms with general distress. Results call into question both the conceptual basis and the clinical utility of differentiating between symptoms that appear to be relatively specific to PTSD and those that seem more broadly characteristic of general psychological distress.",2010.0,48.0,91.0,True,"{'url': 'https://europepmc.org/articles/pmc2871669?pdf=render', 'status': None}","{'volume': '119 1', 'pages': '\n          126-35\n        ', 'name': 'Journal of abnormal psychology'}","{'bibtex': '@Article{Marshall2010AllPS,\n author = {G. Marshall and Terry L. Schell and J. Miles},\n journal = {Journal of abnormal psychology},\n pages = {\n          126-35\n        },\n title = {All PTSD symptoms are highly associated with general distress: ramifications for the dysphoria symptom cluster.},\n volume = {119 1},\n year = {2010}\n}\n'}","[{'authorId': '35204425', 'name': 'G. Marshall'}, {'authorId': '10712652', 'name': 'Terry L. Schell'}, {'authorId': '7792934', 'name': 'J. Miles'}]"
2365,ccfa7e011aa23b2477d11f6c4f779f998db382ac,Expressive Copying Behavior for Social Agents: A Perceptual Analysis,"Successful human interaction commonly involves prototypical exchanges where interactors are engaged, synchronized, and harmonious in their behaviors. The copying of aspects of the other's behavior, at different levels, seems central to establishing and maintaining such empathic connections. Yet, many questions remain unanswered, particularly how it is possible to reflect the same affective content back to the other when the actual motion itself is not exactly the same as theirs. This paper presents a perceptual study in which emotional gestures conducted by an actor were mapped onto synthesized versions generated by an embodied virtual agent. Copying is at the expressive level, where qualities such as the fluidity or expansiveness of gestures are considered, rather than exact low-level motion matching. Participants were later asked to rate the emotional content of video recordings of both the original and the synthesized gestures. A statistical analysis shows that, in most cases, participants associated the emotional content of the agent's gestures with that intended to be expressed by the original actor. The results suggest that a combination of the type of movement performed and its quality is important for successfully communicating emotions.",2012.0,55.0,52.0,True,"{'url': 'https://www.openaccessrepository.it/record/21596/files/fulltext.pdf', 'status': None}","{'volume': '42', 'pages': '776-783', 'name': 'IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans'}","{'bibtex': '@Article{Castellano2012ExpressiveCB,\n author = {Ginevra Castellano and M. Mancini and Christopher E. Peters and P. McOwan},\n journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},\n pages = {776-783},\n title = {Expressive Copying Behavior for Social Agents: A Perceptual Analysis},\n volume = {42},\n year = {2012}\n}\n'}","[{'authorId': '39540970', 'name': 'Ginevra Castellano'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '2803283', 'name': 'P. McOwan'}]"
2366,cd0a0648572ccf2d350a8cb9a0bf9aacaa12942c,SOAR: An Architecture for General Intelligence,,1987.0,97.0,2952.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Soar_an_architecture_for_general_intelligence/6609584/1/files/12101702.pdf', 'status': None}","{'volume': '33', 'pages': '1-64', 'name': 'Artif. Intell.'}","{'bibtex': '@Article{Laird1987SOARAA,\n author = {J. Laird and A. Newell and P. Rosenbloom},\n journal = {Artif. Intell.},\n pages = {1-64},\n title = {SOAR: An Architecture for General Intelligence},\n volume = {33},\n year = {1987}\n}\n'}","[{'authorId': '1715438', 'name': 'J. Laird'}, {'authorId': '48603437', 'name': 'A. Newell'}, {'authorId': '1749322', 'name': 'P. Rosenbloom'}]"
2367,cd2dd4c17e42c3de1681a1c9834803e99740db1e,Nonverbal Behavior Generator for Embodied Conversational Agents,,2006.0,22.0,239.0,False,,{'pages': '243-255'},"{'bibtex': '@Inproceedings{Lee2006NonverbalBG,\n author = {Jina Lee and S. Marsella},\n pages = {243-255},\n title = {Nonverbal Behavior Generator for Embodied Conversational Agents},\n year = {2006}\n}\n'}","[{'authorId': '9174234', 'name': 'Jina Lee'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
2370,cd2e1ac003d8b7904cde6a647c6110324e73df0e,Fractionating theory of mind: A meta-analysis of functional brain imaging studies,,2014.0,209.0,1183.0,True,,"{'volume': '42', 'pages': '9-34', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Schurz2014FractionatingTO,\n author = {M. Schurz and J. Raduà and M. Aichhorn and F. Richlan and J. Perner},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {9-34},\n title = {Fractionating theory of mind: A meta-analysis of functional brain imaging studies},\n volume = {42},\n year = {2014}\n}\n'}","[{'authorId': '2737576', 'name': 'M. Schurz'}, {'authorId': '2811620', 'name': 'J. Raduà'}, {'authorId': '1946019', 'name': 'M. Aichhorn'}, {'authorId': '2511893', 'name': 'F. Richlan'}, {'authorId': '2274473', 'name': 'J. Perner'}]"
2371,cd94d69c7f30ab3add8ae62ab753c18cf60c9d1b,Creation of a new set of dynamic virtual reality faces for the assessment and training of facial emotion recognition ability,,2014.0,57.0,36.0,False,,"{'name': 'Virtual Reality', 'pages': '61-71', 'volume': '18'}","{'bibtex': '@Article{Gutiérrez-Maldonado2014CreationOA,\n author = {J. Gutiérrez-Maldonado and M. Rus-Calafell and Joan González-Conde},\n booktitle = {Virtual Reality},\n journal = {Virtual Reality},\n pages = {61-71},\n title = {Creation of a new set of dynamic virtual reality faces for the assessment and training of facial emotion recognition ability},\n volume = {18},\n year = {2014}\n}\n'}","[{'authorId': '1398030059', 'name': 'J. Gutiérrez-Maldonado'}, {'authorId': '1404488371', 'name': 'M. Rus-Calafell'}, {'authorId': '1406405598', 'name': 'Joan González-Conde'}]"
2372,cda4cfadf25c6bef41d9db0a3a98001c1b42493b,Hand and Mind: What Gestures Reveal About Thought.,"The argument of this original and difficult book is that “gestures are an integral part of language as much as are words, phrases and sentences-gestures and language are one system” (p. 2) . Gestures are instantaneous, imagistic, analog, holistic expressions of the same thought that speech renders in hierarchical, linear, digital, analytic form. David McNeill credits Adam Kendon (1972, 1980) with discovering the link between, and essential unity of, speech sounds and gestural movements; his own work elaborates this insight at the higher linguistic levels of semantics and pragmatics. The topic of the book, then, is gestures that accompany speech, the left-hand end of what McNeill calls “ K e n h i ’ s coiitiiiiiiim: Gesticulation + Language-like gestures + Pantomimes 3 Emblems + Sign languages” (p. 37). The continuum ranges from the informal, spontaneous, idiosyncratic movements of the hands and arms that often accompany speech, to the socially-regulated, standardized, linguistic forms of a sign language, with its arbitrary (non-iconic) lexicon. Between these poles the obligatory presence of speech declines and the linguistic properties of gestures increase. “Language-like gestures” are grammatically integrated into an utterance, as when a speaker, asked about the weather on his vacation, replies: “Well, it was [oscillating hand gesture]”, where the “so-so” gesture replaces an adjectival predicate. “Pantomime” conveys its full meaning in silence or, at most, with inarticulate onomatopoeia; also, in pantomime, sequences of gestures can form a unit, as they can in a sign language, but cannot in gesticulation. “Emblems” conform to standards of wellformedness, a language-like property that gesticulation and pantomime lack: in England, the palm-front V-sign is Churchill’s “Victory!”, the palm-back V-sign is a sexual insult. (For an amusing cross-class confusion in emblem dialects, see Collett, Marsh, and O’Shaughnessy, 1979, p. 229, where Margaret Thatcher appears in an Associated Press Photo, making the palm-back V-sign at a moment of electoral triumph.) The contrast between the two ends of Kendon’s continuum, between spontaneous gesture and conventional sign, epitomizes McNeill’s notion of the process by which an utterance evolves in a speaker’s mind. Spontaneous gesture reveals the primitive stage of an utterance, global, unsegmented, non-hierarchical, from which its conventional representation in speech unfolds: hierarchical, segmented, linear. The inner symbols of the primitive stage are private, idiosyncratic, closed to social influence; the end stage is public, grammatical, socially regulated. McNeill supposes that the primitive",1994.0,10.0,2688.0,False,,"{'volume': '37', 'pages': '203 - 209', 'name': 'Language and Speech'}","{'bibtex': '@Article{Studdert-Kennedy1994HandAM,\n author = {M. Studdert-Kennedy},\n journal = {Language and Speech},\n pages = {203 - 209},\n title = {Hand and Mind: What Gestures Reveal About Thought.},\n volume = {37},\n year = {1994}\n}\n'}","[{'authorId': '1403941699', 'name': 'M. Studdert-Kennedy'}]"
2374,cdcee1355981de99b93608ab61b09a249da728b6,A perception‐based emotion contagion model in crowd emergent evacuation simulation,"With the increasing number of emergencies, the crowd simulation technology has attracted wide attention in the recent years. Existing emergencies have shown that individuals are easy to be influenced by others' emotion during the evacuation. This will make it easier for people to aggregate together and increase security risks. Some of the existing evacuation models without considering emotion are therefore not suitable for describing crowd behaviors in emergencies. We propose a perception‐based emotion contagion model and use multiagent technology to simulate crowd behaviors. Navigation points are introduced to guide the movement of the agents. Based on the proposed model, a prototype simulation system for crowd emotion contagion is developed. The comparative simulation experiments verify that the model can effectively deduct the evacuation time and crowd emotion contagion. The proposed model could be an assistant analysis method for crowd management in emergencies.",2018.0,34.0,18.0,True,,"{'volume': '29', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Liu2018APE,\n author = {Zhen Liu and Tingting Liu and M. Ma and Hui-Huang Hsu and Zhongrui Ni and Yanjie Chai},\n journal = {Computer Animation and Virtual Worlds},\n title = {A perception‐based emotion contagion model in crowd emergent evacuation simulation},\n volume = {29},\n year = {2018}\n}\n'}","[{'authorId': '2109341502', 'name': 'Zhen Liu'}, {'authorId': '91436120', 'name': 'Tingting Liu'}, {'authorId': '145877966', 'name': 'M. Ma'}, {'authorId': '1679560', 'name': 'Hui-Huang Hsu'}, {'authorId': '115478092', 'name': 'Zhongrui Ni'}, {'authorId': '9398597', 'name': 'Yanjie Chai'}]"
2375,ce19ccea3c4d8f4ba794d96d5e3f2e35029d4984,Development of Computational Models of Emotions for Autonomous Agents: A Review,,2014.0,0.0,2.0,False,,"{'volume': '6', 'pages': '351 - 375', 'name': 'Cognitive Computation'}","{'bibtex': '@Article{Rodríguez2014DevelopmentOC,\n author = {Luis-Felipe Rodríguez and Félix F. Ramos},\n journal = {Cognitive Computation},\n pages = {351 - 375},\n title = {Development of Computational Models of Emotions for Autonomous Agents: A Review},\n volume = {6},\n year = {2014}\n}\n'}","[{'authorId': '40428623', 'name': 'Luis-Felipe Rodríguez'}, {'authorId': '145956015', 'name': 'Félix F. Ramos'}]"
2376,ce3d844959ea83024e7f744b4d07160bd165b0b4,With Us or Against Us: Simulated Social Touch by Virtual Agents in a Cooperative or Competitive Setting,,2014.0,23.0,19.0,True,"{'url': 'https://ris.utwente.nl/ws/files/285167465/Huisman_2014_with.pdf', 'status': None}",{'pages': '204-213'},"{'bibtex': '@Inproceedings{Huisman2014WithUO,\n author = {Gijs Huisman and Jan Kolkmeier and D. Heylen},\n pages = {204-213},\n title = {With Us or Against Us: Simulated Social Touch by Virtual Agents in a Cooperative or Competitive Setting},\n year = {2014}\n}\n'}","[{'authorId': '145248077', 'name': 'Gijs Huisman'}, {'authorId': '1847835', 'name': 'Jan Kolkmeier'}, {'authorId': '1678537', 'name': 'D. Heylen'}]"
2377,ce6ec9438323f1441b0f06f7522f641baa39d1c1,Perceiving emotion: towards a realistic understanding of the task,"A decade ago, perceiving emotion was generally equated with taking a sample (a still photograph or a few seconds of speech) that unquestionably signified an archetypal emotional state, and attaching the appropriate label. Computational research has shifted that paradigm in multiple ways. Concern with realism is key. Emotion generally colours ongoing action and interaction: describing that colouring is a different problem from categorizing brief episodes of relatively pure emotion. Multiple challenges flow from that. Describing emotional colouring is a challenge in itself. One approach is to use everyday categories describing states that are partly emotional and partly cognitive. Another approach is to use dimensions. Both approaches need ways to deal with gradual changes over time and mixed emotions. Attaching target descriptions to a sample poses problems of both procedure and validation. Cues are likely to be distributed both in time and across modalities, and key decisions may depend heavily on context. The usefulness of acted data is limited because it tends not to reproduce these features. By engaging with these challenging issues, research is not only achieving impressive results, but also offering a much deeper understanding of the problem.",2009.0,109.0,55.0,True,"{'url': 'https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2009.0139', 'status': None}","{'volume': '364', 'pages': '3515 - 3525', 'name': 'Philosophical Transactions of the Royal Society B: Biological Sciences'}","{'bibtex': '@Article{Cowie2009PerceivingET,\n author = {R. Cowie},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n pages = {3515 - 3525},\n title = {Perceiving emotion: towards a realistic understanding of the task},\n volume = {364},\n year = {2009}\n}\n'}","[{'authorId': '153537672', 'name': 'R. Cowie'}]"
2378,ce73fe2ac764e8ef5ef5c9dcc6d576a369ed775f,Playing with virtual peers: bootstrapping contingent discourse in children with autism,"In this paper, we describe an intervention for children with social and communication deficits, such as autism, based on the use of a virtual peer that can engage in tightly collaborative narrative. We present a study in which children with autism engage in collaborative narrative with both a virtual and a human peer, and the use of contingent discourse is compared. Our findings suggest that contingent discourse increased over the course of interaction with a virtual peer, but not a human peer. Furthermore, topic management, such as introducing new topics or maintaining the current topic, was more likely to occur with the virtual peer than with the human peer. We discuss general implications of our work for understanding the role of peer interactions in learning.",2008.0,30.0,154.0,False,,{'pages': '382-389'},"{'bibtex': '@Inproceedings{Tartaro2008PlayingWV,\n author = {A. Tartaro and Justine Cassell},\n pages = {382-389},\n title = {Playing with virtual peers: bootstrapping contingent discourse in children with autism},\n year = {2008}\n}\n'}","[{'authorId': '34956386', 'name': 'A. Tartaro'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]"
2379,ce91afdf69694bf661ad55f85f2911461ef8e932,Character-Based Interactive Storytelling,"Interactive storytelling is a privileged application of intelligent visual actor technology. The authors introduce their character-based interactive storytelling prototype that uses hierarchical task network planning techniques, which support story generation and any-time user intervention.",2002.0,14.0,387.0,True,"{'url': 'https://research.tees.ac.uk/files/6477970/58294.pdf', 'status': None}","{'volume': '17', 'pages': '17-24', 'name': 'IEEE Intell. Syst.'}","{'bibtex': '@Article{Cavazza2002CharacterBasedIS,\n author = {M. Cavazza and Fred Charles and Steven J. Mead},\n journal = {IEEE Intell. Syst.},\n pages = {17-24},\n title = {Character-Based Interactive Storytelling},\n volume = {17},\n year = {2002}\n}\n'}","[{'authorId': '1696638', 'name': 'M. Cavazza'}, {'authorId': '144553087', 'name': 'Fred Charles'}, {'authorId': '1788038', 'name': 'Steven J. Mead'}]"
2381,cea1f5e97696ccf3ebe39de041b460236bda10b6,Sentiment detection in social networks and in collaborative learning environments,,2015.0,30.0,40.0,False,,"{'volume': '51', 'pages': '1061-1067', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Colace2015SentimentDI,\n author = {F. Colace and L. Casaburi and M. D. Santo and L. Greco},\n journal = {Comput. Hum. Behav.},\n pages = {1061-1067},\n title = {Sentiment detection in social networks and in collaborative learning environments},\n volume = {51},\n year = {2015}\n}\n'}","[{'authorId': '1732822', 'name': 'F. Colace'}, {'authorId': '2770785', 'name': 'L. Casaburi'}, {'authorId': '143695813', 'name': 'M. D. Santo'}, {'authorId': '143601251', 'name': 'L. Greco'}]"
2382,cea4fb5e46aee36ff77ac5d4f0014cd8cb1bee30,First Impressions,"People often draw trait inferences from the facial appearance of other people. We investigated the minimal conditions under which people make such inferences. In five experiments, each focusing on a specific trait judgment, we manipulated the exposure time of unfamiliar faces. Judgments made after a 100-ms exposure correlated highly with judgments made in the absence of time constraints, suggesting that this exposure time was sufficient for participants to form an impression. In fact, for all judgments—attractiveness, likeability, trustworthiness, competence, and aggressiveness—increased exposure time did not significantly increase the correlations. When exposure time increased from 100 to 500 ms, participants' judgments became more negative, response times for judgments decreased, and confidence in judgments increased. When exposure time increased from 500 to 1,000 ms, trait judgments and response times did not change significantly (with one exception), but confidence increased for some of the judgments; this result suggests that additional time may simply boost confidence in judgments. However, increased exposure time led to more differentiated person impressions.",2006.0,21.0,1573.0,False,,"{'volume': '17', 'pages': '592 - 598', 'name': 'Psychological Science'}","{'bibtex': '@Article{Willis2006FirstI,\n author = {Janine Willis and A. Todorov},\n journal = {Psychological Science},\n pages = {592 - 598},\n title = {First Impressions},\n volume = {17},\n year = {2006}\n}\n'}","[{'authorId': '46716544', 'name': 'Janine Willis'}, {'authorId': '145441940', 'name': 'A. Todorov'}]"
2383,cea58679f2294c19f3f6b37823e1250a6f1cb015,Social Stories™ and Young Children,"Social Stories are becoming a popular intervention used to improve the social skills of children with disabilities. This article examines the use of Social Stories with young children with disabilities. Social Stories are described, creation guidelines are recommended, and strategies for Social Story implementation in the classroom are discussed.",2012.0,28.0,16.0,False,,"{'volume': '47', 'pages': '167 - 174', 'name': 'Intervention in School and Clinic'}","{'bibtex': '@Article{More2012SocialSA,\n author = {Cori M. More},\n journal = {Intervention in School and Clinic},\n pages = {167 - 174},\n title = {Social Stories™ and Young Children},\n volume = {47},\n year = {2012}\n}\n'}","[{'authorId': '113642907', 'name': 'Cori M. More'}]"
2384,cea690881d7ac0f222e83348525f52a20bc53308,"Sentiment, emotion, purpose, and style in electoral tweets",,2015.0,89.0,234.0,False,,"{'volume': '51', 'pages': '480-499', 'name': 'Inf. Process. Manag.'}","{'bibtex': '@Article{Mohammad2015SentimentEP,\n author = {Saif M. Mohammad and Xiao-Dan Zhu and S. Kiritchenko and Joel D. Martin},\n journal = {Inf. Process. Manag.},\n pages = {480-499},\n title = {Sentiment, emotion, purpose, and style in electoral tweets},\n volume = {51},\n year = {2015}\n}\n'}","[{'authorId': '143880621', 'name': 'Saif M. Mohammad'}, {'authorId': '1854999', 'name': 'Xiao-Dan Zhu'}, {'authorId': '2886725', 'name': 'S. Kiritchenko'}, {'authorId': '145900862', 'name': 'Joel D. Martin'}]"
2385,ceb03a229088540a3512d2c77ec193d4c754cb76,ggplot2,,2019.0,0.0,13149.0,False,,{'name': 'Introduction to Data Science'},"{'bibtex': '@Article{Irizarry2019ggplot2,\n author = {R. Irizarry},\n journal = {Introduction to Data Science},\n title = {ggplot2},\n year = {2019}\n}\n'}","[{'authorId': '2441164', 'name': 'R. Irizarry'}]"
2386,cece22d3854b3c4fe0ad8ef2205cb1fc4aa71adb,Development and validation of the Interpersonal Emotion Management Scale,"Interpersonal Emotion Management (IEM) strategies represent behaviours targeted at managing negative emotions in others. This paper describes the development and validation of the four-dimensional IEM strategies scale. Four studies were conducted to assess the psychometric properties of the scale, including content, discriminant, and criterion validity. Results provided strong support for the four-dimensional measure of IEM strategies, distinct from conceptually related constructs, and predictive of subordinates’ trust in their supervisor.",2012.0,41.0,88.0,False,,"{'volume': '85', 'pages': '407-420', 'name': 'Journal of Occupational and Organizational Psychology'}","{'bibtex': '@Article{Little2012DevelopmentAV,\n author = {L. Little and Donald H. Kluemper and D. Nelson and Janaki Gooty},\n journal = {Journal of Occupational and Organizational Psychology},\n pages = {407-420},\n title = {Development and validation of the Interpersonal Emotion Management Scale},\n volume = {85},\n year = {2012}\n}\n'}","[{'authorId': '31562204', 'name': 'L. Little'}, {'authorId': '3268907', 'name': 'Donald H. Kluemper'}, {'authorId': '145783663', 'name': 'D. Nelson'}, {'authorId': '115087587', 'name': 'Janaki Gooty'}]"
2387,ceee3829a1f663b3c996823e1a2ef59975cc3860,Perception and Automatic Recognition of Laughter from Whole-Body Motion: Continuous and Categorical Perspectives,"Despite its importance in social interactions, laughter remains little studied in affective computing. Intelligent virtual agents are often blind to users’ laughter and unable to produce convincing laughter themselves. Respiratory, auditory, and facial laughter signals have been investigated but laughter-related body movements have received less attention. The aim of this study is threefold. First, to probe human laughter perception by analyzing patterns of categorisations of natural laughter animated on a minimal avatar. Results reveal that a low dimensional space can describe perception of laughter “types”. Second, to investigate observers’ perception of laughter (hilarious, social, awkward, fake, and non-laughter) based on animated avatars generated from natural and acted motion-capture data. Significant differences in torso and limb movements are found between animations perceived as laughter and those perceived as non-laughter. Hilarious laughter also differs from social laughter. Different body movement features were indicative of laughter in sitting and standing avatar postures. Third, to investigate automatic recognition of laughter to the same level of certainty as observers’ perceptions. Results show recognition rates of the Random Forest model approach human rating levels. Classification comparisons and feature importance analyses indicate an improvement in recognition of social laughter when localized features and nonlinear models are used.",2015.0,63.0,24.0,True,"{'url': 'https://pureadmin.qub.ac.uk/ws/files/16059153/Griffin_et_al.pdf', 'status': None}","{'volume': '6', 'pages': '165-178', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Griffin2015PerceptionAA,\n author = {H. Griffin and Min S. H. Aung and Bernadino Romera-Paredes and Ciaran K McLoughlin and G. McKeown and W. Curran and N. Bianchi-Berthouze},\n journal = {IEEE Transactions on Affective Computing},\n pages = {165-178},\n title = {Perception and Automatic Recognition of Laughter from Whole-Body Motion: Continuous and Categorical Perspectives},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '2940869', 'name': 'H. Griffin'}, {'authorId': '2263254995', 'name': 'Min S. H. Aung'}, {'authorId': '2119220411', 'name': 'Bernadino Romera-Paredes'}, {'authorId': '40467548', 'name': 'Ciaran K McLoughlin'}, {'authorId': '2228246', 'name': 'G. McKeown'}, {'authorId': '144165854', 'name': 'W. Curran'}, {'authorId': '1398541310', 'name': 'N. Bianchi-Berthouze'}]"
2388,cf08954f2433149a6e198423597ec8add84d278c,All Together Now - Introducing the Virtual Human Toolkit,,2013.0,52.0,190.0,False,,"{'volume': '418 6897', 'pages': '\n          465\n        ', 'name': 'Nature'}","{'bibtex': '@Article{Hartholt2013AllTN,\n author = {Arno Hartholt and D. Traum and S. Marsella and Ari Shapiro and Giota Stratou and A. Leuski and Louis-Philippe Morency and J. Gratch},\n journal = {Nature},\n pages = {\n          465\n        },\n title = {All Together Now - Introducing the Virtual Human Toolkit},\n volume = {418 6897},\n year = {2013}\n}\n'}","[{'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '145109163', 'name': 'Ari Shapiro'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '3201827', 'name': 'A. Leuski'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2390,cf1f0dddacd263c62dc079b9ef09478098c2d6f6,How real should virtual characters be?,"In recent years 3D virtual characters have become more common in desktop interfaces, particularly in gaming and entertainment applications. In this paper we describe how augmented reality (AR) technology can be used to bring virtual characters into the real world and compare AR characters to other types of virtual characters. We have developed a handheld AR educational application in which a virtual character teaches users about art history. We present results from a user study that explores how realistic the character needs to be for it to be an effective and engaging educational tool and if augmented reality offers benefits for this type of application.",2006.0,23.0,69.0,False,,{'pages': '57'},"{'bibtex': '@Inproceedings{Wagner2006HowRS,\n author = {Daniel Wagner and M. Billinghurst and D. Schmalstieg},\n pages = {57},\n title = {How real should virtual characters be?},\n year = {2006}\n}\n'}","[{'authorId': '144184131', 'name': 'Daniel Wagner'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}, {'authorId': '1742819', 'name': 'D. Schmalstieg'}]"
2391,cf2725b1b376ff842cb6ae890b6156fff2f8f4fe,Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection,"Emotion detection in dialogues is challenging as it often requires the identification of thematic topics underlying a conversation, the relevant commonsense knowledge, and the intricate transition patterns between the affective states. In this paper, we propose a Topic-Driven Knowledge-Aware Transformer to handle the challenges above. We firstly design a topic-augmented language model (LM) with an additional layer specialized for topic detection. The topic-augmented LM is then combined with commonsense statements derived from a knowledge base based on the dialogue contextual information. Finally, a transformer-based encoder-decoder architecture fuses the topical and commonsense information, and performs the emotion label sequence prediction. The model has been experimented on four datasets in dialogue emotion detection, demonstrating its superiority empirically over the existing state-of-the-art approaches. Quantitative and qualitative results show that the model can discover topics which help in distinguishing emotion categories.",2021.0,43.0,67.0,True,"{'url': 'https://aclanthology.org/2021.acl-long.125.pdf', 'status': None}",{'pages': '1571-1582'},"{'bibtex': '@Inproceedings{Zhu2021TopicDrivenAK,\n author = {Lixing Zhu and Gabriele Pergola and Lin Gui and Deyu Zhou and Yulan He},\n pages = {1571-1582},\n title = {Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection},\n year = {2021}\n}\n'}","[{'authorId': '2131133148', 'name': 'Lixing Zhu'}, {'authorId': '46922295', 'name': 'Gabriele Pergola'}, {'authorId': '145096580', 'name': 'Lin Gui'}, {'authorId': '1725992', 'name': 'Deyu Zhou'}, {'authorId': '1390509967', 'name': 'Yulan He'}]"
2392,cf8476cc415bc23bc4e4720518dcd832b6bca477,La adicción a los videojuegos en el DSM-5,,2014.0,22.0,61.0,True,"{'url': 'https://www.adicciones.es/index.php/adicciones/article/download/10/11', 'status': None}","{'volume': '26', 'pages': '91-95', 'name': 'Adicciones'}","{'bibtex': '@Article{Carbonell2014LaAA,\n author = {Xavier Carbonell},\n journal = {Adicciones},\n pages = {91-95},\n title = {La adicción a los videojuegos en el DSM-5},\n volume = {26},\n year = {2014}\n}\n'}","[{'authorId': '49057504', 'name': 'Xavier Carbonell'}]"
2393,cf91085c85202178f1e3b5d821c5b0e6562d7862,Gaze fixation and the neural circuitry of face processing in autism,,2005.0,24.0,1486.0,True,"{'url': 'https://europepmc.org/articles/pmc4337787?pdf=render', 'status': None}","{'volume': '8', 'pages': '519-526', 'name': 'Nature Neuroscience'}","{'bibtex': '@Article{Dalton2005GazeFA,\n author = {K. Dalton and Brendon M. Nacewicz and T. Johnstone and Hillary S. Schaefer and M. Gernsbacher and H. Goldsmith and Andrew L. Alexander and Richard J. Davidson},\n journal = {Nature Neuroscience},\n pages = {519-526},\n title = {Gaze fixation and the neural circuitry of face processing in autism},\n volume = {8},\n year = {2005}\n}\n'}","[{'authorId': '2713204', 'name': 'K. Dalton'}, {'authorId': '2878453', 'name': 'Brendon M. Nacewicz'}, {'authorId': '30361732', 'name': 'T. Johnstone'}, {'authorId': '34897071', 'name': 'Hillary S. Schaefer'}, {'authorId': '2087502', 'name': 'M. Gernsbacher'}, {'authorId': '2252509287', 'name': 'H. Goldsmith'}, {'authorId': '2238962699', 'name': 'Andrew L. Alexander'}, {'authorId': '2247343381', 'name': 'Richard J. Davidson'}]"
2394,cfef9aac22acd2c7c932a93736cdac2e4aed1949,Real-time Emotion Detection System using Speech: Multi-modal Fusion of Different Timescale Features,"The goal of this work is to build a real-time emotion detection system which utilizes multi-modal fusion of different timescale features of speech. Conventional spectral and prosody features are used for intra-frame and supra-frame features respectively, and a new information fusion algorithm which takes care of the characteristics of each machine learning algorithm is introduced. In this framework, the proposed system can be associated with additional features, such as lexical or discourse information, in later steps. To verify the realtime system performance, binary decision tasks on angry and neutral emotion are performed using concatenated speech signal simulating realtime conditions.",2007.0,19.0,102.0,False,,"{'pages': '48-51', 'name': '2007 IEEE 9th Workshop on Multimedia Signal Processing'}","{'bibtex': '@Article{Kim2007RealtimeED,\n author = {Samuel Kim and P. Georgiou and Sungbok Lee and Shrikanth S. Narayanan},\n journal = {2007 IEEE 9th Workshop on Multimedia Signal Processing},\n pages = {48-51},\n title = {Real-time Emotion Detection System using Speech: Multi-modal Fusion of Different Timescale Features},\n year = {2007}\n}\n'}","[{'authorId': '2110026741', 'name': 'Samuel Kim'}, {'authorId': '1765829', 'name': 'P. Georgiou'}, {'authorId': '2108057415', 'name': 'Sungbok Lee'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
2395,d0189e3984b4cddf1e3a5dbe2d4876389fbf333a,Virtual reality prototype for measurement of expression characteristics in emotional situations,,2009.0,17.0,23.0,False,,"{'volume': '39 2', 'pages': '\n          173-9\n        ', 'name': 'Computers in biology and medicine'}","{'bibtex': '@Article{Han2009VirtualRP,\n author = {Kiwan Han and J. Ku and K. Kim and H. Jang and Junyoung Park and Jae-Jin Kim and Chan-Hyung Kim and Min-Hyung Choi and I. Kim and Sun I. Kim},\n journal = {Computers in biology and medicine},\n pages = {\n          173-9\n        },\n title = {Virtual reality prototype for measurement of expression characteristics in emotional situations},\n volume = {39 2},\n year = {2009}\n}\n'}","[{'authorId': '2148824601', 'name': 'Kiwan Han'}, {'authorId': '143720898', 'name': 'J. Ku'}, {'authorId': '1973742', 'name': 'K. Kim'}, {'authorId': '3287618', 'name': 'H. Jang'}, {'authorId': '2109372535', 'name': 'Junyoung Park'}, {'authorId': '2145449477', 'name': 'Jae-Jin Kim'}, {'authorId': '2897323', 'name': 'Chan-Hyung Kim'}, {'authorId': '1708692', 'name': 'Min-Hyung Choi'}, {'authorId': '2219074220', 'name': 'I. Kim'}, {'authorId': '1455996091', 'name': 'Sun I. Kim'}]"
2396,d019b9ce4e86234898a23389e9bc3ad96f585728,ADAPT: The Agent Developmentand Prototyping Testbed,"We present ADAPT, a flexible platform for designing and authoring functional, purposeful human characters in a rich virtual environment. Our framework incorporates character animation, navigation, and behavior with modular interchangeable components to produce narrative scenes. The animation system provides locomotion, reaching, gaze tracking, gesturing, sitting, and reactions to external physical forces, and can easily be extended with more functionality due to a decoupled, modular structure. The navigation component allows characters to maneuver through a complex environment with predictive steering for dynamic obstacle avoidance. Finally, our behavior framework allows a user to fully leverage a character's animation and navigation capabilities when authoring both individual decision-making and complex interactions between actors using a centralized, event-driven model.",2013.0,65.0,60.0,True,"{'url': 'https://repository.upenn.edu/cgi/viewcontent.cgi?article=1165&context=hms', 'status': None}","{'volume': '20', 'pages': '1035-1047', 'name': 'IEEE Transactions on Visualization and Computer Graphics'}","{'bibtex': '@Article{Shoulson2013ADAPTTA,\n author = {Alexander Shoulson and N. Marshak and Mubbasir Kapadia and N. Badler},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {1035-1047},\n title = {ADAPT: The Agent Developmentand Prototyping Testbed},\n volume = {20},\n year = {2013}\n}\n'}","[{'authorId': '2483632', 'name': 'Alexander Shoulson'}, {'authorId': '2463776', 'name': 'N. Marshak'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}, {'authorId': '1699200', 'name': 'N. Badler'}]"
2397,d02f6c1238e9e3d9d5d0980f3277143f6669f27f,CROSS-CORPUS EEG-BASED EMOTION RECOGNITION,Lack of generalization is a common problem in automatic emotion recognition. The present study aims to explore the suitability of the existing EEG features for emotion recognition and investigate the performance of emotion recognition methods across different corpora. We introduce a novel dataset which includes spontaneous emotions and was analyzed in addition to the existing datasets for cross-corpus evaluation. We demonstrate that the performance of the existing methods significantly decreases when evaluated across different corpora. The best results are obtained by a convolutional neural network fed by spectral topography maps from different bands. We provide some evidence that stimuli-related sensory information is learned by machine learning models for emotion recognition using EEG signals.,2018.0,25.0,32.0,False,,"{'pages': '1-6', 'name': '2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)'}","{'bibtex': '@Article{Rayatdoost2018CROSSCORPUSEE,\n author = {Soheil Rayatdoost and M. Soleymani},\n journal = {2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)},\n pages = {1-6},\n title = {CROSS-CORPUS EEG-BASED EMOTION RECOGNITION},\n year = {2018}\n}\n'}","[{'authorId': '8142030', 'name': 'Soheil Rayatdoost'}, {'authorId': '152714397', 'name': 'M. Soleymani'}]"
2398,d033a28bedf5b41a4a2e80778f6f790f9a0c16e9,Expressive Agents: Non-verbal Communication in Collaborative Virtual Environments,"The premise of this paper is that agent technology in collaborative virtual environments (CVEs) may be enriched by incorporating an emotional channel alongside the conventional informational content, and that this would be best achieved through an associated visual human embodiment or avatar. Since humans express emotion in face-to-face encounters primarily through facial expression, an investigation was undertaken in order to establish how such expressions might be effectively and efficiently captured and represented in an avatar. The study involved consulting socio-psychological research relating to face-to-face encounters, followed by a controlled experiment to investigate user ability to interpret the faces of the avatars pre-prepared to express specific emotions. Effectiveness was demonstrated through good recognition rates for all but one of the emotion categories, and efficiency was established since a reduced feature set was found to be sufficient to build the successfully recognised core set of avatar facial expressions",2002.0,46.0,41.0,False,,,"{'bibtex': '@Inproceedings{M2002ExpressiveAN,\n author = {Fabri M and Moore Dj and Hobbs Dj},\n title = {Expressive Agents: Non-verbal Communication in Collaborative Virtual Environments},\n year = {2002}\n}\n'}","[{'authorId': '2263196603', 'name': 'Fabri M'}, {'authorId': '2223875267', 'name': 'Moore Dj'}, {'authorId': '81839805', 'name': 'Hobbs Dj'}]"
2399,d0573284bcb9287947edd6806d6dda88b4a78bd8,Emotional Mimicry as Social Regulation,"Emotional mimicry is the imitation of the emotional expressions of others. According to the classic view on emotional mimicry (the Matched Motor Hypothesis), people mimic the specific facial movements that comprise a discrete emotional expression. However, little evidence exists for the mimicry of discrete emotions; rather, the extant evidence supports only valence-based mimicry. We propose an alternative Emotion Mimicry in Context view according to which emotional mimicry is not based on mere perception but rather on the interpretation of signals as emotional intentions in a specific context. We present evidence for the idea that people mimic contextualized emotions rather than simply expressive muscle movements. Our model postulates that (implicit or explicit) contextual information is needed for emotional mimicry to take place. It takes into account the relationship between observer and expresser, and suggests that emotional mimicry depends on this relationship and functions as a social regulator.",2013.0,131.0,456.0,False,,"{'volume': '17', 'pages': '142 - 157', 'name': 'Personality and Social Psychology Review'}","{'bibtex': '@Article{Hess2013EmotionalMA,\n author = {U. Hess and A. Fischer},\n journal = {Personality and Social Psychology Review},\n pages = {142 - 157},\n title = {Emotional Mimicry as Social Regulation},\n volume = {17},\n year = {2013}\n}\n'}","[{'authorId': '3067657', 'name': 'U. Hess'}, {'authorId': '7444483', 'name': 'A. Fischer'}]"
2400,d05a81be26726604844009f2e3129d40933351a8,The Influence of Positive Affect and Visual Access on the Discovery of Integrative Solutions in Bilateral Negotiation,,1986.0,25.0,748.0,True,"{'url': 'http://deepblue.lib.umich.edu/bitstream/2027.42/26263/1/0000344.pdf', 'status': None}","{'volume': '37', 'pages': '1-13', 'name': 'Organizational Behavior and Human Decision Processes'}","{'bibtex': '@Article{Carnevale1986TheIO,\n author = {P. Carnevale and Alice M. Isen},\n journal = {Organizational Behavior and Human Decision Processes},\n pages = {1-13},\n title = {The Influence of Positive Affect and Visual Access on the Discovery of Integrative Solutions in Bilateral Negotiation},\n volume = {37},\n year = {1986}\n}\n'}","[{'authorId': '48755211', 'name': 'P. Carnevale'}, {'authorId': '3865216', 'name': 'Alice M. Isen'}]"
2401,d08eb1f6b4317e0b43e2cd79fa946726f3118dd6,Evaluating the Sensitivity to Virtual Characters Facial Asymmetry in Emotion Synthesis,"ABSTRACT The use of expressive Virtual Characters is an effective complementary means of communication for social networks offering multi-user 3D-chatting environment. In such contexts, the facial expression channel offers a rich medium to translate the ongoing emotions conveyed by the text-based exchanges. However, until recently, only purely symmetric facial expressions have been considered for that purpose. In this article we examine human sensitivity to facial asymmetry in the expression of both basic and complex emotions. The rationale for introducing asymmetry in the display of facial expressions stems from two well-established observations in cognitive neuroscience: first that the expression of basic emotions generally displays a small asymmetry, second that more complex emotions such as ambivalent feeling may reflect in the partial display of different, potentially opposite, emotions on each side of the face. A frequent occurrence of this second case results from the conflict between the truly felt emotion and the one that should be displayed due to social conventions. Our main hypothesis is that a much larger expressive and emotional space can only be automatically synthesized by means of facial asymmetry when modeling emotions with a general Valence-Arousal-Dominance dimensional approach. Besides, we want also to explore the general human sensitivity to the introduction of a small degree of asymmetry into the expression of basic emotions. We conducted an experiment by presenting 64 pairs of static facial expressions, one symmetric and one asymmetric, illustrating eight emotions (three basic and five complex ones) alternatively for a male and a female character. Each emotion was presented four times by swapping the symmetric and asymmetric positions and by mirroring the asymmetrical expression. Participants were asked to grade, on a continuous scale, the correctness of each facial expression with respect to a short definition. Results confirm the potential of introducing facial asymmetry for a subset of the complex emotions. Guidelines are proposed for designers of embodied conversational agent and emotionally reflective avatars.",2017.0,28.0,1.0,True,"{'url': 'https://infoscience.epfl.ch/record/227463/files/postprint_evaluating-sensitivity-virtual-characters-facial-asymmetry.pdf', 'status': 'GREEN'}","{'name': 'Applied Artificial Intelligence', 'pages': '103 - 118', 'volume': '31'}","{'bibtex': '@Article{Wang2017EvaluatingTS,\n author = {Nan Wang and Junghyun Ahn and R. Boulic},\n booktitle = {Applied Artificial Intelligence},\n journal = {Applied Artificial Intelligence},\n pages = {103 - 118},\n title = {Evaluating the Sensitivity to Virtual Characters Facial Asymmetry in Emotion Synthesis},\n volume = {31},\n year = {2017}\n}\n'}","[{'authorId': '144457723', 'name': 'Nan Wang'}, {'authorId': '1683972', 'name': 'Junghyun Ahn'}, {'authorId': '1696973', 'name': 'R. Boulic'}]"
2402,d09cfa55f26bafaad715a779ba9fe9b0e30fdb85,"The Social Regulation of Emotion: An Integrative, Cross-Disciplinary Model",,2016.0,149.0,185.0,True,"{'url': 'https://europepmc.org/articles/pmc5937233?pdf=render', 'status': None}","{'volume': '20', 'pages': '47-63', 'name': 'Trends in Cognitive Sciences'}","{'bibtex': '@Article{Reeck2016TheSR,\n author = {C. Reeck and D. Ames and K. Ochsner},\n journal = {Trends in Cognitive Sciences},\n pages = {47-63},\n title = {The Social Regulation of Emotion: An Integrative, Cross-Disciplinary Model},\n volume = {20},\n year = {2016}\n}\n'}","[{'authorId': '3018957', 'name': 'C. Reeck'}, {'authorId': '20618378', 'name': 'D. Ames'}, {'authorId': '2669604', 'name': 'K. Ochsner'}]"
2403,d0c0bccc2b4820310260ffbcb9a347fc54feee7a,The bases of social power.,,1959.0,31.0,6830.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{French1959TheBO,\n author = {J. R. French and B. Raven},\n title = {The bases of social power.},\n year = {1959}\n}\n'}","[{'authorId': '2052330889', 'name': 'J. R. French'}, {'authorId': '104041475', 'name': 'B. Raven'}]"
2404,d0ce831d9a56928fa88b810c4d1f68a6c432509c,Architectural Styles for Augmented Reality in Smartphones (,"In this paper we briefly examine the architecture of augmented reality in smartphone applications. While the architecture is fairly consistent across AR browsers / SDKs, there are some important differences. Appreciating these differences will help developers choose a framework or browser implementation that best meets their needs. Understanding the architecture of these systems will also expose the gaps in current implementations and help us to think clearly about the likely evolution of augmented reality browsers over the next few years. Thomas Reicher's "" Framework For Dynamically Adaptable Augmented Reality Systems "" thesis [1, 2] provides a reference architecture for comparing different augmented reality frameworks and this is a good starting point for our discussion. An illustration of Reicher's reference architecture is shown below. (from Asa MacWilliams[4]) In this model, the augmented reality system is organized into six logical subsystems. A thorough explanation of these subsystems is given by MacWillaims [4]. For convenience below is a brief summary.",,6.0,12.0,False,,,"{'bibtex': '@Misc{None,\n author = {Ben Butchart},\n title = {Architectural Styles for Augmented Reality in Smartphones (}\n}\n'}","[{'authorId': '2032112', 'name': 'Ben Butchart'}]"
2405,d15bdf485f3a64abb59e4d0d1d1b18a9fc652bf9,Effects of color on emotions.,"Emotional reactions to color hue, saturation, and brightness (Munsell color system and color chips) were investigated using the Pleasure-Arousal-Dominance emotion model. Saturation (S) and brightness (B) evidenced strong and consistent effects on emotions. Regression equations for standardized variables were; Pleasure = .69B + .22S, Arousal = -.31B + .60S, Dominance = -.76B + .32S. Brightness effects were nearly the same for chromatic and achromatic colors. Blue, blue-green, green, red-purple, purple, and purple-blue were the most pleasant hues, whereas yellow and green-yellow were the least pleasant. Green-yellow, blue-green, and green were the most arousing, whereas purple-blue and yellow-red were the least arousing. Green-yellow induced greater dominance than red-purple.",1994.0,45.0,1174.0,False,,"{'volume': '123 4', 'pages': '\n          394-409\n        ', 'name': 'Journal of experimental psychology. General'}","{'bibtex': '@Article{Valdez1994EffectsOC,\n author = {Patricia Valdez and A. Mehrabian},\n journal = {Journal of experimental psychology. General},\n pages = {\n          394-409\n        },\n title = {Effects of color on emotions.},\n volume = {123 4},\n year = {1994}\n}\n'}","[{'authorId': '1580348834', 'name': 'Patricia Valdez'}, {'authorId': '144102217', 'name': 'A. Mehrabian'}]"
2406,d1ad9690e5c9118352032ca569c7abfc45771f6d,Mirroring People: The Science of Empathy and How We Connect With Others.,,2013.0,4.0,186.0,False,,"{'volume': '4', 'pages': '287 - 292', 'name': 'Partner Abuse'}","{'bibtex': '@Article{Iacoboni2013MirroringPT,\n author = {M. Iacoboni},\n journal = {Partner Abuse},\n pages = {287 - 292},\n title = {Mirroring People: The Science of Empathy and How We Connect With Others.},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '1770382', 'name': 'M. Iacoboni'}]"
2407,d1b0e07cd93332b64541118e66e5fb32ecd214c3,Understanding the Predictability of Gesture Parameters from Speech and their Perceptual Importance,"Gesture behavior is a natural part of human conversation. Much work has focused on removing the need for tedious hand-animation to create embodied conversational agents by designing speech-driven gesture generators. However, these generators often work in a black-box manner, assuming a general relationship between input speech and output motion. As their success remains limited, we investigate in more detail how speech may relate to different aspects of gesture motion. We determine a number of parameters characterizing gesture, such as speed and gesture size, and explore their relationship to the speech signal in a two-fold manner. First, we train multiple recurrent networks to predict the gesture parameters from speech to understand how well gesture attributes can be modeled from speech alone. We find that gesture parameters can be partially predicted from speech, and some parameters, such as path length, being predicted more accurately than others, like velocity. Second, we design a perceptual study to assess the importance of each gesture parameter for producing motion that people perceive as appropriate for the speech. Results show that a degradation in any parameter was viewed negatively, but some changes, such as hand shape, are more impactful than others. A video summarization can be found at https://youtu.be/aw6-_5kmLjY.",2020.0,41.0,13.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3383652.3423882', 'status': None}",{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Ferstl2020UnderstandingTP,\n author = {Ylva Ferstl and Michael Neff and R. Mcdonnell},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Understanding the Predictability of Gesture Parameters from Speech and their Perceptual Importance},\n year = {2020}\n}\n'}","[{'authorId': '3430725', 'name': 'Ylva Ferstl'}, {'authorId': '143687087', 'name': 'Michael Neff'}, {'authorId': '145795454', 'name': 'R. Mcdonnell'}]"
2408,d1b6231de691383ebe2acde07328048ba3198d5b,"Group-Based Emotions: The Impact of Social Identity on Appraisals, Emotions, and Behaviors","Because group-based emotions are rooted in the social identity of the perceiver, we propose that group-based emotions should be sensitive to changes in this social identity. In three experiments, young women reported feeling more anger, fear, and disgust toward Muslims when their identity as women had been made salient, in comparison with various control conditions where their identity as young adults, as social sciences students, their personal identity, or no identity had been made salient. These effects were mediated by appraisals of intergroup threats. In Experiment 3, the salience of the woman social identity also increased intentions to avoid Muslims.",2012.0,55.0,41.0,False,,"{'volume': '34', 'pages': '20 - 33', 'name': 'Basic and Applied Social Psychology'}","{'bibtex': '@Article{Kuppens2012GroupBasedET,\n author = {T. Kuppens and V. Yzerbyt},\n journal = {Basic and Applied Social Psychology},\n pages = {20 - 33},\n title = {Group-Based Emotions: The Impact of Social Identity on Appraisals, Emotions, and Behaviors},\n volume = {34},\n year = {2012}\n}\n'}","[{'authorId': '1986623', 'name': 'T. Kuppens'}, {'authorId': '4779221', 'name': 'V. Yzerbyt'}]"
2409,d1bde81d5bad2f06e0f2033ee45c50ff373a625a,Emotion-related self-regulation and its relation to children's maladjustment.,"The development of children's emotion-related self-regulation appears to be related to, and likely involved in, many aspects of children's development. In this review, the distinction between effortful self-regulatory processes and those that are somewhat less voluntary is discussed, and literature on the former capacities is reviewed. Emotion-related self-regulation develops rapidly in the early years of life and improves more slowly into adulthood. Individual differences in children's self-regulation are fairly stable after the first year or two of life. Such individual differences are inversely related to at least some types of externalizing problems. Findings for internalizing problems are less consistent and robust, although emotion-related self-regulation appears to be inversely related to internalizing problems after the early years. Self-regulatory capacities have been related to both genetic and environmental factors and their interaction. Some interventions designed to foster self-regulation and, hence, reduce maladjustment, have proved to be at least partially effective.",2010.0,200.0,905.0,True,"{'url': 'https://europepmc.org/articles/pmc3018741?pdf=render', 'status': None}","{'volume': '6', 'pages': '\n          495-525\n        ', 'name': 'Annual review of clinical psychology'}","{'bibtex': ""@Article{Eisenberg2010EmotionrelatedSA,\n author = {N. Eisenberg and Tracy L. Spinrad and Natalie D. Eggum},\n journal = {Annual review of clinical psychology},\n pages = {\n          495-525\n        },\n title = {Emotion-related self-regulation and its relation to children's maladjustment.},\n volume = {6},\n year = {2010}\n}\n""}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}, {'authorId': '6138798', 'name': 'Tracy L. Spinrad'}, {'authorId': '6149978', 'name': 'Natalie D. Eggum'}]"
2410,d20838945496292b9dd1245350f90e45900f58e5,I Can Help You Change! An Empathic Virtual Agent Delivers Behavior Change Health Interventions,"We discuss our approach to developing a novel modality for the computer-delivery of Brief Motivational Interventions (BMIs) for behavior change in the form of a personalized On-Demand VIrtual Counselor (ODVIC), accessed over the internet. ODVIC is a multimodal Embodied Conversational Agent (ECA) that empathically delivers an evidence-based behavior change intervention by adapting, in real-time, its verbal and nonverbal communication messages to those of the user’s during their interaction. We currently focus our work on excessive alcohol consumption as a target behavior, and our approach is adaptable to other target behaviors (e.g., overeating, lack of exercise, narcotic drug use, non-adherence to treatment). We based our current approach on a successful existing patient-centered brief motivational intervention for behavior change---the Drinker’s Check-Up (DCU)---whose computer-delivery with a text-only interface has been found effective in reducing alcohol consumption in problem drinkers. We discuss the results of users’ evaluation of the computer-based DCU intervention delivered with a text-only interface compared to the same intervention delivered with two different ECAs (a neutral one and one with some empathic abilities). Users rate the three systems in terms of acceptance, perceived enjoyment, and intention to use the system, among other dimensions. We conclude with a discussion of how our positive results encourage our long-term goals of on-demand conversations, anytime, anywhere, with virtual agents as personal health and well-being helpers.",2013.0,111.0,192.0,False,,"{'volume': '4', 'pages': '19:1-19:28', 'name': 'ACM Trans. Manag. Inf. Syst.'}","{'bibtex': '@Article{Lisetti2013ICH,\n author = {C. Lisetti and R. Amini and Ugan Yasavur and N. Rishe},\n journal = {ACM Trans. Manag. Inf. Syst.},\n pages = {19:1-19:28},\n title = {I Can Help You Change! An Empathic Virtual Agent Delivers Behavior Change Health Interventions},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '1779199', 'name': 'C. Lisetti'}, {'authorId': '1809087', 'name': 'R. Amini'}, {'authorId': '2671668', 'name': 'Ugan Yasavur'}, {'authorId': '1719172', 'name': 'N. Rishe'}]"
2411,d21792b581d5dd504c6c6344cbba417155f7aa55,A Process Model of Empathy For Virtual Agents,"For more than a century, empathy has been a central topic in the study of human emotion. It plays a crucial role in our everyday social life, having implications for the survival of the species. In the case of agents that inhabit virtual worlds and interact socially among each other and with humans, empathy has also been considered to be an important mechanism to promote engaging and believable interactions. However, creating empathic agents, until recently, has been accomplished mostly through the implementation of specific empathic behaviors or by using domain-dependent empirical models. In this article, we propose a generic computational model of empathy that is grounded on recent psychological theories about empathy. The proposed model treats empathy as a process in which the intensity of the empathic response is modulated by a set of factors that involve the relationship between the agents of the empathic interaction, namely, the similarity and affective link, as well as some characteristics of the empathizer agent, such as mood and personality. This model was implemented into an affective agent architecture, which was then used in an evaluation that had 77 participants. The results indicate that our empathy model, when used to simulate a social scenario with a small group of agents, significantly changed the way that the users perceived and described the interactions between those agents.",2015.0,54.0,32.0,False,,"{'volume': '27', 'pages': '371-391', 'name': 'Interact. Comput.'}","{'bibtex': '@Article{Rodrigues2015APM,\n author = {Sérgio Hortas Rodrigues and S. Mascarenhas and João Dias and Ana Paiva},\n journal = {Interact. Comput.},\n pages = {371-391},\n title = {A Process Model of Empathy For Virtual Agents},\n volume = {27},\n year = {2015}\n}\n'}","[{'authorId': '2997654', 'name': 'Sérgio Hortas Rodrigues'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
2415,d24e0f179e38dcc44825d5ad36a13df957afe219,Emotion recognition in borderline personality disorder-a review of the literature.,"Borderline personality disorder (BPD) is characterized by distinct impairments in emotion regulation, resulting in affective instability especially in the social context. It has been suggested that impaired social cognitive functioning such as impaired facial emotion recognition contributes to the social disturbances in BPD. In accordance with this notion, a number of behavioral studies have revealed a pattern of alterations in facial emotion recognition associated with BPD: subtle impairments in basic emotion recognition, a negativity or anger bias, and a heightened sensitivity to the detection of negative emotions. Furthermore, there is increasing evidence for structural and functional changes in the neural networks underlying affective dysregulation and emotional hyperreactivity in BPD. Merging these lines of evidence, we propose that emotional hyperreactivity interferes with the cognitive processes of facial emotion recognition, thereby contributing to the specific pattern of altered emotion recognition in BPD. Suggestions for future research and clinical implications are discussed.",2009.0,47.0,346.0,True,"{'url': 'http://www.psychologie.uni-freiburg.de/abteilungen/psychobio/team/publikationen/2009Domes2009_JPD.pdf', 'status': None}","{'volume': '23 1', 'pages': '\n          6-19\n        ', 'name': 'Journal of personality disorders'}","{'bibtex': '@Article{Domes2009EmotionRI,\n author = {G. Domes and L. Schulze and S. Herpertz},\n journal = {Journal of personality disorders},\n pages = {\n          6-19\n        },\n title = {Emotion recognition in borderline personality disorder-a review of the literature.},\n volume = {23 1},\n year = {2009}\n}\n'}","[{'authorId': '4369513', 'name': 'G. Domes'}, {'authorId': '118330773', 'name': 'L. Schulze'}, {'authorId': '2955508', 'name': 'S. Herpertz'}]"
2416,d250dd49e148bf6dd98e38c7b7600783a8429e1d,Emotion recognition based on EEG feature maps through deep learning network,,2021.0,82.0,89.0,True,,"{'volume': '', 'name': 'Engineering Science and Technology, an International Journal'}","{'bibtex': '@Article{Topic2021EmotionRB,\n author = {Ante Topic and M. Russo},\n journal = {Engineering Science and Technology, an International Journal},\n title = {Emotion recognition based on EEG feature maps through deep learning network},\n year = {2021}\n}\n'}","[{'authorId': '2071880704', 'name': 'Ante Topic'}, {'authorId': '2476711', 'name': 'M. Russo'}]"
2417,d2589e79f5e390eb2b72b0490099940bdd876722,The Expression of the Emotions in Man and Animals,"Acknowledgments List of Illustrations Figures Plates Preface to the Anniversary Edition by Paul Ekman Preface to the Third Edition by Paul Ekman Preface to the Second Edition by Francis Darwin Introduction to the Third Edition by Paul Ekman The Expression of the Emotions in Man and Animals Introduction to the First Edition 1. General Principles of Expression 2. General Principles of Expression -- continued 3. General Principles of Expression -- continued 4. Means of Expression in Animals 5. Special Expressions of Animals 6. Special Expressions of Man: Suffering and Weeping 7. Low Spirits, Anxiety, Grief, Dejection, Despair 8. Joy, High Spirits, Love, Tender Feelings, Devotion 9. Reflection - Meditation - Ill-temper - Sulkiness - Determination 10. Hatred and Anger 11. Disdain - Contempt - Disgust - Guilt - Pride, Etc. - Helplessness - Patience - Affirmation and Negation 12. Surprise - Astonishment - Fear - Horror 13. Self-attention - Shame - Shyness - Modesty: Blushing 14. Concluding Remarks and Summary Afterword, by Paul Ekman APPENDIX I: Charles Darwin's Obituary, by T. H. Huxley APPENDIX II: Changes to the Text, by Paul Ekman APPENDIX III: Photography and The Expression of the Emotions, by Phillip Prodger APPENDIX IV: A Note on the Orientation of the Plates, by Phillip Prodger and Paul Ekman APPENDIX V: Concordance of Illustrations, by Phillip Prodger APPENDIX VI: List of Head Words from the Index to the First Edition NOTES NOTES TO THE COMMENTARIES INDEX",1956.0,8.0,8719.0,True,"{'url': 'https://babel.hathitrust.org/cgi/imgsrv/download/pdf?id=chi.18738997;orient=0;size=100;seq=5;attachment=0', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Darwin1956TheEO,\n author = {C. Darwin},\n title = {The Expression of the Emotions in Man and Animals},\n year = {1956}\n}\n'}","[{'authorId': '115299156', 'name': 'C. Darwin'}]"
2418,d25fee01197f1210c94658b39652fa55f2321e65,Empathy for Pain Involves the Affective but not Sensory Components of Pain,"Our ability to have an experience of another's pain is characteristic of empathy. Using functional imaging, we assessed brain activity while volunteers experienced a painful stimulus and compared it to that elicited when they observed a signal indicating that their loved one—present in the same room—was receiving a similar pain stimulus. Bilateral anterior insula (AI), rostral anterior cingulate cortex (ACC), brainstem, and cerebellum were activated when subjects received pain and also by a signal that a loved one experienced pain. AIand ACC activation correlated with individual empathy scores. Activity in the posterior insula/secondary somatosensory cortex, the sensorimotor cortex (SI/MI), and the caudal ACC was specific to receiving pain. Thus, a neural response in AIand rostral ACC, activated in common for “self” and “other” conditions, suggests that the neural substrate for empathic experience does not involve the entire “pain matrix.” We conclude that only that part of the pain network associated with its affective qualities, but not its sensory qualities, mediates empathy.",2004.0,68.0,3576.0,True,"{'url': 'https://pure.mpg.de/pubman/item/item_2614253_3/component/file_2622702/RD_Empathy_2004.pdf', 'status': None}","{'volume': '303', 'pages': '1157 - 1162', 'name': 'Science'}","{'bibtex': '@Article{Singer2004EmpathyFP,\n author = {T. Singer and B. Seymour and J. O’Doherty and H. Kaube and R. Dolan and C. Frith},\n journal = {Science},\n pages = {1157 - 1162},\n title = {Empathy for Pain Involves the Affective but not Sensory Components of Pain},\n volume = {303},\n year = {2004}\n}\n'}","[{'authorId': '47272511', 'name': 'T. Singer'}, {'authorId': '145324953', 'name': 'B. Seymour'}, {'authorId': '101096038', 'name': 'J. O’Doherty'}, {'authorId': '3084123', 'name': 'H. Kaube'}, {'authorId': '2231343', 'name': 'R. Dolan'}, {'authorId': '144155759', 'name': 'C. Frith'}]"
2419,d26770838402eb548ca6f4b2ae0b4bdff7e6f566,Capacity of strong attractor patterns to model behavioural and cognitive prototypes,"We solve the mean field equations for a stochastic Hopfield network with temperature (noise) in the presence of strong, i.e., multiply stored, patterns, and use this solution to obtain the storage capacity of such a network. Our result provides for the first time a rigorous solution of the mean filed equations for the standard Hopfield model and is in contrast to the mathematically unjustifiable replica technique that has been used hitherto for this derivation. We show that the critical temperature for stability of a strong pattern is equal to its degree or multiplicity, when the sum of the squares of degrees of the patterns is negligible compared to the network size. In the case of a single strong pattern, when the ratio of the number of all stored pattens and the network size is a positive constant, we obtain the distribution of the overlaps of the patterns with the mean field and deduce that the storage capacity for retrieving a strong pattern exceeds that for retrieving a simple pattern by a multiplicative factor equal to the square of the degree of the strong pattern. This square law property provides justification for using strong patterns to model attachment types and behavioural prototypes in psychology and psychotherapy.",2013.0,35.0,11.0,False,,{'pages': '2661-2669'},"{'bibtex': '@Inproceedings{Edalat2013CapacityOS,\n author = {A. Edalat},\n pages = {2661-2669},\n title = {Capacity of strong attractor patterns to model behavioural and cognitive prototypes},\n year = {2013}\n}\n'}","[{'authorId': '1694989', 'name': 'A. Edalat'}]"
2420,d290f540ae13ad94ef0a2fc61898c21cfdefb349,Managing Chronic Conditions with a Smartphone-based Conversational Virtual Agent,"When deployed on mobile devices, virtual agents have the potential to deliver advice regarding medical conditions, as well as provide a ubiquitous channel for health education and behavior change for a variety of chronic health conditions. We describe design guidelines for mobile agent dialogues to support chronic disease management, a general-purpose smartphone-based architecture for a conversational virtual agent that simulates face-to-face health counseling conversations with patients, and an initial agent implementation that provides counseling to patients with the chronic heart condition atrial fibrillation in conjunction with a mobile heart rhythm monitor that is attached to the back of the phone. Preliminary results from a randomized trial with 120 patients with atrial fibrillation indicate that the agent results in significant improvements in self-reported quality of life relative to a standard of care control group.",2018.0,21.0,35.0,False,,{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Bickmore2018ManagingCC,\n author = {T. Bickmore and Everlyne Kimani and H. Trinh and Alexandra M Pusateri and M. Paasche-Orlow and J. Magnani},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {Managing Chronic Conditions with a Smartphone-based Conversational Virtual Agent},\n year = {2018}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '3489930', 'name': 'Everlyne Kimani'}, {'authorId': '144902406', 'name': 'H. Trinh'}, {'authorId': '150027283', 'name': 'Alexandra M Pusateri'}, {'authorId': '1397166245', 'name': 'M. Paasche-Orlow'}, {'authorId': '3490149', 'name': 'J. Magnani'}]"
2421,d29cccbde0fed6031c48dd6e4294b3a1b46672ea,submitted): Modeling Embodied Feedback With Virtual Humans,,,0.0,82.0,False,,,"{'bibtex': '@Misc{None,\n title = {submitted): Modeling Embodied Feedback With Virtual Humans}\n}\n'}",[]
2422,d2c267141a394777485ab96d202c939aca81df00,TeachAR: An Interactive Augmented Reality Tool for Teaching Basic English to Non-native Children,"TeachAR is an Augmented Reality (AR) tool for teaching English colors, shapes, and spatial relationships to young children aged 4 to 6 years old who are non-native speakers of English. TeachAR utilizes the ARToolkit plugin for the Unity game engine for square marker tracking and game development. The Microsoft Kinect's microphone and speech API is used for isolated word speech recognition, a webcam for image capturing and a desktop monitor for viewing the AR scene. Previous language learning AR applications usually use audio output, however TeachAR uses speech as input for language learning. This paper describes the TeachAR demonstration and user experience with the application.",2016.0,18.0,53.0,False,,"{'pages': '344-345', 'name': '2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)'}","{'bibtex': '@Article{Dalim2016TeachARAI,\n author = {C. Dalim and Arindam Dey and Thammathip Piumsomboon and M. Billinghurst and M. S. Sunar},\n journal = {2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)},\n pages = {344-345},\n title = {TeachAR: An Interactive Augmented Reality Tool for Teaching Basic English to Non-native Children},\n year = {2016}\n}\n'}","[{'authorId': '8842641', 'name': 'C. Dalim'}, {'authorId': '152168867', 'name': 'Arindam Dey'}, {'authorId': '2297177', 'name': 'Thammathip Piumsomboon'}, {'authorId': '1684805', 'name': 'M. Billinghurst'}, {'authorId': '2036992', 'name': 'M. S. Sunar'}]"
2423,d2d886eff14325caa9adb368f2bbd8e8ed99c4a5,Unmasking the Face: A Guide to Recognizing Emotions From Facial Expressions,"unmasking the face a guide to recognizing emotions from unmasking the face a guide to recognizing emotions from >>download unmasking the face: a guide to recognizing unmasking the face: a guide to recognizing emotions from unmasking the facea guide to recognizing emotions from free download unmasking the face: a guide to recognizing unmasking the face a guide to recognizing emotions from books on nonverbal communication hrdi home paul ekman, wallace v. friesen facial expression paul ekman a new pan-cultural facial expression of emotion 1 book reviews springer unmasking the face a to recognizing emotions from facial unmasking the face a guide to recognizing emotions from unmasking the face ebookdigz media bias through facial expressions on local las vegas guide to facial micro expressions beaconac kinesics : encyclopedia of communication theory the role of the eyes and mouth in facial emotions guide to facial micro expressions ojaa lnai 6895 expressing emotions on robotic companions with environmental science chapter 8 test fbtest free download here pdfsdocuments2 expressing emotions on robotic companions with limited war at the end of world totte free kindle unmasking the face ebooks download firebase the paralanguage of behavior intelligence forecasting 6e emotional approach of foreign vowel acquisition tools and methods for pollution prevention louduk historias de ko y mana aadver how the human genome work hsandc taxonomy 1 systematics and morphology xciii darwin and facial expression: a century of research in review",1975.0,0.0,520.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ekman1975UnmaskingTF,\n author = {P. Ekman and Wallace V. Friesen},\n title = {Unmasking the Face: A Guide to Recognizing Emotions From Facial Expressions},\n year = {1975}\n}\n'}","[{'authorId': '21451088', 'name': 'P. Ekman'}, {'authorId': '37652085', 'name': 'Wallace V. Friesen'}]"
2424,d32c12a11a3b5f36b85a25e3c7d1fc453097fdf4,Are Women the More Emotional Sex? Evidence From Emotional Experiences in Social Context,"The present study examined whether sex differences in emotion are related to the social context and addressed differences between global, retrospective, and on-line, momentary self-descriptions of ...",1998.0,52.0,376.0,True,"{'url': 'https://mdsoar.org/bitstream/11603/4020/1/FBRobinetal98.pdf', 'status': None}","{'volume': '12', 'pages': '555-578', 'name': 'Cognition & Emotion'}","{'bibtex': '@Article{Barrett1998AreWT,\n author = {L. F. Barrett and L. Robin and P. Pietromonaco and Kristen M. Eyssell},\n journal = {Cognition & Emotion},\n pages = {555-578},\n title = {Are Women the More Emotional Sex? Evidence From Emotional Experiences in Social Context},\n volume = {12},\n year = {1998}\n}\n'}","[{'authorId': '1731779', 'name': 'L. F. Barrett'}, {'authorId': '153444389', 'name': 'L. Robin'}, {'authorId': '4148925', 'name': 'P. Pietromonaco'}, {'authorId': '14217652', 'name': 'Kristen M. Eyssell'}]"
2425,d3336e951eaef94df864f6c514a7757a5a76ef41,Selective aging of the human cerebral cortex observed in vivo: differential vulnerability of the prefrontal gray matter.,"In a prospective cross-sectional study, we used computerized volumetry of magnetic resonance images to examine the patterns of brain aging in 148 healthy volunteers. The most substantial age-related decline was found in the volume of the prefrontal gray matter. Smaller age-related differences were observed in the volume of the fusiform, inferior temporal and superior parietal cortices. The effects of age on the hippocampal formation, the postcentral gyrus, prefrontal white matter and superior parietal white matter were even weaker. No significant age-related differences were observed in the parahippocampal and anterior cingulate gyri, inferior parietal lobule, pericalcarine gray matter, the precentral gray and white matter, postcentral white matter and inferior parietal white matter. The volume of the total brain volume and the hippocampal formation was larger in men than in women even after adjustment for height. Inferior temporal cortex showed steeper aging trend in men. Small but consistent rightward asymmetry was found in the whole cerebral hemispheres, superior parietal, fusiform and orbito-frontal cortices, postcentral and prefrontal white matter. The left side was larger than the right in the dorsolateral prefrontal, parahippocampal, inferior parietal and pericalcarine cortices, and in the parietal white matter. However, there were no significant differences in age trends between the hemispheres.",1997.0,120.0,1259.0,True,"{'url': 'https://academic.oup.com/cercor/article-pdf/7/3/268/9752575/070268.pdf', 'status': None}","{'volume': '7 3', 'pages': '\n          268-82\n        ', 'name': 'Cerebral cortex'}","{'bibtex': '@Article{Raz1997SelectiveAO,\n author = {N. Raz and F. Gunning and Denise Head and James H. Dupuis and John McQuain and S. Briggs and W. Loken and Allen E. Thornton and J. Acker},\n journal = {Cerebral cortex},\n pages = {\n          268-82\n        },\n title = {Selective aging of the human cerebral cortex observed in vivo: differential vulnerability of the prefrontal gray matter.},\n volume = {7 3},\n year = {1997}\n}\n'}","[{'authorId': '145349986', 'name': 'N. Raz'}, {'authorId': '3568698', 'name': 'F. Gunning'}, {'authorId': '2228866873', 'name': 'Denise Head'}, {'authorId': '2228182200', 'name': 'James H. Dupuis'}, {'authorId': '4019199', 'name': 'John McQuain'}, {'authorId': '4803270', 'name': 'S. Briggs'}, {'authorId': '144995692', 'name': 'W. Loken'}, {'authorId': '2228364354', 'name': 'Allen E. Thornton'}, {'authorId': '5080944', 'name': 'J. Acker'}]"
2426,d360dd1cae4d5ce895e01bd02913c3231990b5d1,"Emotion on the Road - Necessity, Acceptance, and Feasibility of Affective Computing in the Car","Besides reduction of energy consumption, which implies alternate actuation and light construction, the main research domain in automobile development in the near future is dominated by driver assistance and natural driver-car communication. The ability of a car to understand natural speech and provide a human-like driver assistance system can be expected to be a factor decisive for market success on par with automatic driving systems. Emotional factors and affective states are thereby crucial for enhanced safety and comfort. This paper gives an extensive literature overview on work related to influence of emotions on driving safety and comfort, automatic recognition, control of emotions, and improvement of in-car interfaces by affect sensitive technology. Various use-case scenarios are outlined as possible applications for emotion-oriented technology in the vehicle. The possible acceptance of such future technology by drivers is assessed in a Wizard-Of-Oz user study, and feasibility of automatically recognising various driver states is demonstrated by an example system for monitoring driver attentiveness. Thereby an accuracy of 91.3% is reported for classifying in real-time whether the driver is attentive or distracted.",2010.0,96.0,168.0,True,"{'url': 'https://downloads.hindawi.com/journals/ahci/2010/263593.pdf', 'status': None}","{'volume': '2010', 'pages': '263593:1-263593:17', 'name': 'Adv. Hum. Comput. Interact.'}","{'bibtex': '@Article{Eyben2010EmotionOT,\n author = {F. Eyben and M. Wöllmer and T. Poitschke and Björn Schuller and C. Blaschke and B. Färber and Nhu Nguyen-Thien},\n journal = {Adv. Hum. Comput. Interact.},\n pages = {263593:1-263593:17},\n title = {Emotion on the Road - Necessity, Acceptance, and Feasibility of Affective Computing in the Car},\n volume = {2010},\n year = {2010}\n}\n'}","[{'authorId': '1751126', 'name': 'F. Eyben'}, {'authorId': '2103575', 'name': 'M. Wöllmer'}, {'authorId': '2272779', 'name': 'T. Poitschke'}, {'authorId': '145411696', 'name': 'Björn Schuller'}, {'authorId': '152934979', 'name': 'C. Blaschke'}, {'authorId': '2723594', 'name': 'B. Färber'}, {'authorId': '1403875780', 'name': 'Nhu Nguyen-Thien'}]"
2427,d39683d3d326d5a78bab73cc27d1767083af6d7c,Aging and emotion recognition: not just a losing matter.,"Past studies on emotion recognition and aging have found evidence of age-related decline when emotion recognition was assessed by having participants detect single emotions depicted in static images of full or partial (e.g., eye region) faces. These tests afford good experimental control but do not capture the dynamic nature of real-world emotion recognition, which is often characterized by continuous emotional judgments and dynamic multimodal stimuli. Research suggests that older adults often perform better under conditions that better mimic real-world social contexts. We assessed emotion recognition in young, middle-aged, and older adults using two traditional methods (single emotion judgments of static images of faces and eyes) and an additional method in which participants made continuous emotion judgments of dynamic, multimodal stimuli (videotaped interactions between young, middle-aged, and older couples). Results revealed an Age × Test interaction. Largely consistent with prior research, we found some evidence that older adults performed worse than young adults when judging single emotions from images of faces (for sad and disgust faces only) and eyes (for older eyes only), with middle-aged adults falling in between. In contrast, older adults did better than young adults on the test involving continuous emotion judgments of dyadic interactions, with middle-aged adults falling in between. In tests in which target stimuli differed in age, emotion recognition was not facilitated by an age match between participant and target. These findings are discussed in terms of theoretical and methodological implications for the study of aging and emotional processing.",2012.0,98.0,98.0,True,"{'url': 'https://europepmc.org/articles/pmc3746016?pdf=render', 'status': None}","{'volume': '27 4', 'pages': '\n          940-950\n        ', 'name': 'Psychology and aging'}","{'bibtex': '@Article{Sze2012AgingAE,\n author = {Jocelyn A Sze and Madeleine S. Goodkind and Anett Gyurak and R. Levenson},\n journal = {Psychology and aging},\n pages = {\n          940-950\n        },\n title = {Aging and emotion recognition: not just a losing matter.},\n volume = {27 4},\n year = {2012}\n}\n'}","[{'authorId': '4773810', 'name': 'Jocelyn A Sze'}, {'authorId': '25574636', 'name': 'Madeleine S. Goodkind'}, {'authorId': '6307176', 'name': 'Anett Gyurak'}, {'authorId': '2001910', 'name': 'R. Levenson'}]"
2428,d39ab1a5f531068516fe093c3e524bc3ce63eed5,Synthesis of Emotion Vector and Expression Vector for Virtual Human,"Face emotion expression of virtual human is an interesting research area for many scholars. The former research laid much stress on the acquirement of human face data and creation of the local movement on face, there is no general mathematics model for emotion synthesis. First, the concept of emotion vector was proposed and the emotion state of virtual human could be transformed to an emotion vector calculated by the basic emotion vector in emotion vector space. Second, the concept of expression vector was established and the expression of virtual human could be transformed to expression vector calculated by the basic expression vector in expression vector space. Third, the emotion mapping was set up from emotion vector space to expression vector space and emotion state and the emotion mapping implemented expression animation. Finally, a preliminary experiment was carried on microcomputer and the emotion synthesis was calculated by six basic emotions.",2006.0,0.0,4.0,False,,"{'volume': '', 'name': 'Computer Simulation'}","{'bibtex': '@Article{Zhen2006SynthesisOE,\n author = {Liu Zhen},\n journal = {Computer Simulation},\n title = {Synthesis of Emotion Vector and Expression Vector for Virtual Human},\n year = {2006}\n}\n'}","[{'authorId': '2059085302', 'name': 'Liu Zhen'}]"
2429,d3dff3ab84054f26ce54d90bd1a0bf4dcc8ba850,The Effects of Interpersonal Attitude of a Group of Agents on User’s Presence and Proxemics Behavior,"In the everyday world people form small conversing groups where social interaction takes place, and much of the social behavior takes place through managing interpersonal space (i.e., proxemics) and group formation, signaling their attentio to others (i.e., through gaze behavior), and expressing certain attitudes, for example, friendliness, by smiling, getting close through increased engagement and intimacy, and welcoming newcomers. Many real-time interactive systems feature virtual anthropomorphic characters in order to simulate conversing groups and add plausibility and believability to the simulated environments. However, only a few have dealt with autonomous behavior generation, and in those cases, the agents’ exhibited behavior should be evaluated by users in terms of appropriateness, believability, and conveyed meaning (e.g., attitudes). In this article we present an integrated intelligent interactive system for generating believable nonverbal behavior exhibited by virtual agents in small simulated group conversations. The produced behavior supports group formation management and the expression of interpersonal attitudes (friendly vs. unfriendly) both among the agents in the group (i.e., in-group attitude) and towards an approaching user in an avatar-based interaction (out-group attitude). A user study investigating the effects of these attitudes on users’ social presence evaluation and proxemics behavior (with their avatar) in a three-dimensional virtual city environment is presented. We divided the study into two trials according to the task assigned to users, that is, joining a conversing group and reaching a target destination behind the group. Results showed that the out-group attitude had a major impact on social presence evaluations in both trials, whereby friendly groups were perceived as more socially rich. The user’s proxemics behavior depended on both out-group and in-group attitudes expressed by the agents. Implications of these results for the design and implementation of similar intelligent interactive systems for the autonomous generation of agents’ multimodal behavior are briefly discussed.",2016.0,80.0,26.0,False,,"{'volume': '6', 'pages': '12:1-12:33', 'name': 'ACM Trans. Interact. Intell. Syst.'}","{'bibtex': '@Article{Cafaro2016TheEO,\n author = {Angelo Cafaro and Brian Ravenet and M. Ochs and H. Vilhjálmsson and C. Pelachaud},\n journal = {ACM Trans. Interact. Intell. Syst.},\n pages = {12:1-12:33},\n title = {The Effects of Interpersonal Attitude of a Group of Agents on User’s Presence and Proxemics Behavior},\n volume = {6},\n year = {2016}\n}\n'}","[{'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '1682486', 'name': 'Brian Ravenet'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2430,d438b558e9fde05e252315ece0554b358a8cec32,Theory of mind and autism: A review,,2000.0,89.0,566.0,False,,"{'volume': '23', 'pages': '169-184', 'name': 'International Review of Research in Mental Retardation'}","{'bibtex': '@Article{Baron-Cohen2000TheoryOM,\n author = {S. Baron-Cohen},\n journal = {International Review of Research in Mental Retardation},\n pages = {169-184},\n title = {Theory of mind and autism: A review},\n volume = {23},\n year = {2000}\n}\n'}","[{'authorId': '1390019127', 'name': 'S. Baron-Cohen'}]"
2431,d43d3507b85ad0f911173f48fa2d5ee765bf707d,Exploring emotional and imitational android-based interactions in autistic spectrum disorders,"1 Interdepartmental Research Center “E. Piaggio”, University of Pisa, Italy 2 Scientific Institute Stella Maris (IRCCS), Pisa, Italy Individuals with Autistic Spectrum Disorders (ASDs) have impairments in processing of social and emotional information. To widen emotive responsiveness, the employment of robotic systems to engage proactive interactive responses in children with ASDs has been recently suggested. Understanding and teaching the processing of socio-emotional abilities is the inspiring principle of this novel approach and could be of tremendous clinical significance. Encouraging studies with robotic dolls, mobile robots and humanoids acting as social mediators have provided important insights and demonstrate the necessity of long term studies. In this study we report on a series of experiments on four subjects affected by ASDs as they interact with a biomimetic android. We assessed both their spontaneous behavior and reactions to therapist presses in correlation with the time course of the physiological and behavioral data, as well as the focusing of attention towards the android’s eye movements and the spontaneous ability to imitate gesture and facial expressions. Overall, subjects demonstrated a decrease in dysfunction in the areas of social communication, implying a marked improvement in these areas after interacting with the android. EXPLORING EMOTIONAL AND IMITATIONAL ANDROID-BASED INTERACTIONS IN AUTISTIC SPECTRUM DISORDERS",2008.0,34.0,48.0,False,,"{'volume': '1', 'pages': '49-62', 'name': ''}","{'bibtex': '@Inproceedings{Pioggia2008ExploringEA,\n author = {G. Pioggia and R. Igliozzi and M. L. Sica and M. Ferro and F. Muratori and A. Ahluwalia and D. Rossi},\n pages = {49-62},\n title = {Exploring emotional and imitational android-based interactions in autistic spectrum disorders},\n volume = {1},\n year = {2008}\n}\n'}","[{'authorId': '144917392', 'name': 'G. Pioggia'}, {'authorId': '1757598', 'name': 'R. Igliozzi'}, {'authorId': '144343793', 'name': 'M. L. Sica'}, {'authorId': '33930522', 'name': 'M. Ferro'}, {'authorId': '1793447', 'name': 'F. Muratori'}, {'authorId': '144958801', 'name': 'A. Ahluwalia'}, {'authorId': '145210650', 'name': 'D. Rossi'}]"
2432,d442da81ee10a3872aac513be648afee1fe2fab5,Recent trends in human computer interface to analysis the cognitive skill of students based on user interface,"In this research work, focuses the cognitive skill of knowledge by the category of logical Reasoning, Numerical Ability and Perceptual Speed of ability can be analyzed by GOMS model, Keystroke-level model and brain dominance can be analyzed based on Fuzzy FP Tree Association rule mining technique. Apart from the academic performance of the students, the cognitive skill analysis will stimulate their attitude and skill to motivate them for their higher studies and career. This research is to offer inclusive model hypothetically by conducting offline test based on the cognitive model through Human Computer Interface.",2017.0,16.0,3.0,False,,"{'pages': '1-7', 'name': '2017 4th International Conference on Advanced Computing and Communication Systems (ICACCS)'}","{'bibtex': '@Article{Mayilvaganan2017RecentTI,\n author = {M. Mayilvaganan and D. Kalpanadevi},\n journal = {2017 4th International Conference on Advanced Computing and Communication Systems (ICACCS)},\n pages = {1-7},\n title = {Recent trends in human computer interface to analysis the cognitive skill of students based on user interface},\n year = {2017}\n}\n'}","[{'authorId': '49707301', 'name': 'M. Mayilvaganan'}, {'authorId': '9438235', 'name': 'D. Kalpanadevi'}]"
2433,d46e9ea18c80b33a3edf473a035784636b2ed0b8,Socially Anxious People Reveal More Personal Information with Virtual Counselors That Talk about Themselves using Intimate Human Back Stories,"In this paper, we describe our findings from research designed to explore the effect of virtual human counselors' self-disclosure using intimate human back stories on real human clients' social responses in psychological counseling sessions. To investigate this subject, we designed an experiment involving two conditions of the counselors' self-disclosure: human back stories and computer back stories. We then measured socially anxious users' verbal self-disclosure. The results demonstrated that highly anxious users revealed personal information more than less anxious users when they interacted with virtual counselors who disclosed intimate information about themselves using human back stories. Furthermore, we found that greater inclination toward facilitated self-disclosure from highly anxious users following interaction with virtual counselors who employed human back stories rather than computer back stories. In addition, a further analysis of socially anxious users' feelings of rapport demonstrated that virtual counselors elicited more rapport with highly anxious users than less anxious users when interacting with counselors who employed human back stories. This outcome was not found in the users' interactions with counselors who employed computer back stories.",2012.0,13.0,35.0,False,,"{'volume': '181', 'pages': '\n          202-6\n        ', 'name': 'Studies in health technology and informatics'}","{'bibtex': '@Article{Kang2012SociallyAP,\n author = {Sin-Hwa Kang and J. Gratch},\n journal = {Studies in health technology and informatics},\n pages = {\n          202-6\n        },\n title = {Socially Anxious People Reveal More Personal Information with Virtual Counselors That Talk about Themselves using Intimate Human Back Stories},\n volume = {181},\n year = {2012}\n}\n'}","[{'authorId': '34728215', 'name': 'Sin-Hwa Kang'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2434,d4ad611e3a39f55c420dd843f28a23f017a639ed,Conversational Agents and Mental Health: Theory-Informed Assessment of Language and Affect,"A study deployed the mental health Relational Frame Theory as grounding for an analysis of sentiment dynamics in human-language dialogs. The work takes a step towards enabling use of conversational agents in mental health settings. Sentiment tendencies and mirroring behaviors in 11k human-human dialogs were compared with behaviors when humans interacted with conversational agents in a similar-sized collection. The study finds that human sentiment-related interaction norms persist in human-agent dialogs, but that humans are twice as likely to respond negatively when faced with a negative utterance by a robot than in a comparable situation with humans. Similarly, inhibition towards use of obscenity is greatly reduced. We introduce a new Affective Neural Net implementation that specializes in analyzing sentiment in real time.",2016.0,36.0,53.0,False,,{'name': 'Proceedings of the Fourth International Conference on Human Agent Interaction'},"{'bibtex': '@Article{Miner2016ConversationalAA,\n author = {Adam S. Miner and A. Chow and Sarah Adler and Ilia Zaitsev and P. Tero and Alison M Darcy and A. Paepcke},\n journal = {Proceedings of the Fourth International Conference on Human Agent Interaction},\n title = {Conversational Agents and Mental Health: Theory-Informed Assessment of Language and Affect},\n year = {2016}\n}\n'}","[{'authorId': '3819917', 'name': 'Adam S. Miner'}, {'authorId': '5014723', 'name': 'A. Chow'}, {'authorId': '46949721', 'name': 'Sarah Adler'}, {'authorId': '2065204644', 'name': 'Ilia Zaitsev'}, {'authorId': '113547125', 'name': 'P. Tero'}, {'authorId': '6120000', 'name': 'Alison M Darcy'}, {'authorId': '1750481', 'name': 'A. Paepcke'}]"
2435,d4b02f3b8ef1d7f15d574d285b6ba66ad7120343,Improvement in social competence in patients with schizophrenia: a pilot study using a performance‐based measure using virtual reality,"The objective of this study was to explore the possibility of the use of Virtual Reality Functional Skills Assessment (VRFSA) in a future regular clinical trial, as well as to report a preliminary result about effectiveness of atypical antipsychotics to social competence in schizophrenia.",2009.0,35.0,24.0,False,,"{'volume': '24', 'name': 'Human Psychopharmacology: Clinical and Experimental'}","{'bibtex': '@Article{Park2009ImprovementIS,\n author = {Kyung-Min Park and J. Ku and I. Park and Ji-Yeon Park and Sun I. Kim and Jae-Jin Kim},\n journal = {Human Psychopharmacology: Clinical and Experimental},\n title = {Improvement in social competence in patients with schizophrenia: a pilot study using a performance‐based measure using virtual reality},\n volume = {24},\n year = {2009}\n}\n'}","[{'authorId': '2152042882', 'name': 'Kyung-Min Park'}, {'authorId': '143720898', 'name': 'J. Ku'}, {'authorId': '2324506', 'name': 'I. Park'}, {'authorId': '2124232695', 'name': 'Ji-Yeon Park'}, {'authorId': '2109684864', 'name': 'Sun I. Kim'}, {'authorId': '2145449477', 'name': 'Jae-Jin Kim'}]"
2436,d4b99c2af5158ecd42d483ea4b3775a2c8e0767a,Detection and Computational Analysis of Psychological Signals Using a Virtual Human Interviewing Agent,"It has long been recognized that facial expressions, body posture/gestures and vocal parameters play an important role in human communication and the implicit signalling of emotion. Recent advances in low cost computer vision and behavioral sensing technologies can now be applied to the process of making meaningful inferences as to user state when a person interacts with a computational device. Effective use of this additive information could serve to promote human interaction with virtual human (VH) agents that may enhance diagnostic assessment. The same technology could also be leveraged to improve engagement in teletherapy approaches between remote patients and care providers. This paper will focus on our current research in these areas within the DARPA-funded “Detection and Computational Analysis of Psychological Signals” project, with specific attention to the SimSensei application use case. SimSensei is a virtual human interaction platform that is able to sense and interpret real-time audiovisual behavioral signals from users interacting with the system. It is specifically designed for health care support and leverages years of virtual human research and development at USC-ICT. The platform enables an engaging face-to-face interaction where the virtual human automatically reacts to the state and inferred intent of the user through analysis of behavioral signals gleaned from facial expressions, body gestures and vocal parameters. Akin to how non-verbal behavioral signals have an impact on human to human interaction and communication, SimSensei aims to capture and infer from user non-verbal communication to improve engagement between a VH and a user. The system can also quantify and interpret sensed behavioral signals longitudinally that can be used to inform diagnostic assessment within a clinical context.",2014.0,46.0,29.0,False,,"{'name': '', 'volume': ''}","{'bibtex': '@Inproceedings{Rizzo2014DetectionAC,\n author = {A. Rizzo and Stefan Scherer and D. DeVault and J. Gratch and Ron Artstein and Arno Hartholt and Gale M. Lucas and S. Marsella and Fabrizio Morbini and Angela Nazarian and Giota Stratou and D. Traum and Rachel Wood and Jill Boberg and Louis-Philippe Morency},\n title = {Detection and Computational Analysis of Psychological Signals Using a Virtual Human Interviewing Agent},\n year = {2014}\n}\n'}","[{'authorId': '32775508', 'name': 'A. Rizzo'}, {'authorId': '2072545325', 'name': 'Stefan Scherer'}, {'authorId': '144662324', 'name': 'D. DeVault'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2038490', 'name': 'Ron Artstein'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2223582', 'name': 'Fabrizio Morbini'}, {'authorId': '2551269', 'name': 'Angela Nazarian'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '2072346682', 'name': 'Rachel Wood'}, {'authorId': '6349590', 'name': 'Jill Boberg'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2437,d4d08a95ff480e21b1b2b4277a966cfa1ba160f4,Affect recognition based on physiological changes during the watching of music videos,"Assessing emotional states of users evoked during their multimedia consumption has received a great deal of attention with recent advances in multimedia content distribution technologies and increasing interest in personalized content delivery. Physiological signals such as the electroencephalogram (EEG) and peripheral physiological signals have been less considered for emotion recognition in comparison to other modalities such as facial expression and speech, although they have a potential interest as alternative or supplementary channels. This article presents our work on: (1) constructing a dataset containing EEG and peripheral physiological signals acquired during presentation of music video clips, which is made publicly available, and (2) conducting binary classification of induced positive/negative valence, high/low arousal, and like/dislike by using the aforementioned signals. The procedure for the dataset acquisition, including stimuli selection, signal acquisition, self-assessment, and signal processing is described in detail. Especially, we propose a novel asymmetry index based on relative wavelet entropy for measuring the asymmetry in the energy distribution of EEG signals, which is used for EEG feature extraction. Then, the classification systems based on EEG and peripheral physiological signals are presented. Single-trial and single-run classification results indicate that, on average, the performance of the EEG-based classification outperforms that of the peripheral physiological signals. However, the peripheral physiological signals can be considered as a good alternative to EEG signals in the case of assessing a user's preference for a given music video clip (like/dislike) since they have a comparable performance to EEG signals while being more easily measured.",2012.0,56.0,39.0,False,,"{'volume': '2', 'pages': '7:1-7:26', 'name': 'ACM Trans. Interact. Intell. Syst.'}","{'bibtex': '@Article{Yazdani2012AffectRB,\n author = {A. Yazdani and Jong-Seok Lee and J. Vesin and T. Ebrahimi},\n journal = {ACM Trans. Interact. Intell. Syst.},\n pages = {7:1-7:26},\n title = {Affect recognition based on physiological changes during the watching of music videos},\n volume = {2},\n year = {2012}\n}\n'}","[{'authorId': '40131608', 'name': 'A. Yazdani'}, {'authorId': '48173549', 'name': 'Jong-Seok Lee'}, {'authorId': '145346974', 'name': 'J. Vesin'}, {'authorId': '1681498', 'name': 'T. Ebrahimi'}]"
2438,d4f5ef88dd2e8f028d47ea89fe68e09c4d40bd6c,A Comparative study for sentiment analysis of raw and translated text,"Sentiment analysis is a type of opinion mining study analyzing people's thoughts, feelings, and assessments evaluations of society things such as products, services, and institutions individuals, organizations, events and etc. This paper focuses on an effective machine learning model, Recurrent Neural Network (RNN), for sentiment analysis of both Bengali and English text. For sentiment analysis of Bengali text, we construct a novel dataset accumulated from different open source sites and social media. The dataset comprises over 17,000 texts, which are labelled as neutral, positive, and negative. Our study provides a rigorous comparative analysis on the performance of RNN in terms of sentiment analysis of both raw text and corresponding translated text (for both English and Bengali language). In summary, we achieve 82.9% and 84.5% accuracies for sentiment analysis of Bengali and English text respectively using RNN.",2021.0,15.0,3.0,False,,"{'volume': '2021', 'pages': '220-231', 'name': 'The 2nd International Conference on Distributed Sensing and Intelligent Systems (ICDSIS 2021)'}","{'bibtex': '@Article{Monjoor2021ACS,\n author = {S. N. Monjoor and O. Faruk and K. M. Mahmudul Haque and F. Iqbal and M. A. Mitu and M. A. Islam and M. Mukta},\n journal = {The 2nd International Conference on Distributed Sensing and Intelligent Systems (ICDSIS 2021)},\n pages = {220-231},\n title = {A Comparative study for sentiment analysis of raw and translated text},\n volume = {2021},\n year = {2021}\n}\n'}","[{'authorId': '2154835144', 'name': 'S. N. Monjoor'}, {'authorId': '12831464', 'name': 'O. Faruk'}, {'authorId': '2154837478', 'name': 'K. M. Mahmudul Haque'}, {'authorId': '2151951107', 'name': 'F. Iqbal'}, {'authorId': '2050712775', 'name': 'M. A. Mitu'}, {'authorId': '2110034858', 'name': 'M. A. Islam'}, {'authorId': '79335343', 'name': 'M. Mukta'}]"
2439,d5020b0925ffb5a8503f8b079442eeba408b83b3,A path planning algorithm for intelligent virtual agent,"This paper focuses on how to give the intelligent virtual agent (IVA) behaviors with personalized features. It takes full account of the impact of personality and emotion factor on IVA's behavior, and proposes a path planning algorithm influenced by personality parameters - PD* (Personality D*) algorithm, which is improved on the basis of D* algorithm. PD* algorithm set different level of dangerous coefficient which is associated with IVA's personality, and adopts Heuristic search function based on energy to realize path planning with personality characteristic. The algorithm was tested and applied to an IVA in a Smart Home.",2012.0,11.0,0.0,False,,"{'name': '2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM)', 'pages': '581-584'}","{'bibtex': '@Article{Lin2012APP,\n author = {Shi Lin and Li Zhigang},\n booktitle = {IEEE Symposium on Electrical & Electronics Engineering},\n journal = {2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM)},\n pages = {581-584},\n title = {A path planning algorithm for intelligent virtual agent},\n year = {2012}\n}\n'}","[{'authorId': '2108833763', 'name': 'Shi Lin'}, {'authorId': '46644542', 'name': 'Li Zhigang'}]"
2440,d5179ec6bd5fa0b8752a1d6cf3a992c08df306bb,"Department for Children, Schools and Families","Department for Children, Schools and Families and Schools home page. The Department for Children, Schools and Families leads work across Government to ensure that all children and young people stay healthy and safe; secure an excellent education and the highest possible standards of achievement; enjoy their childhood; make a positive contribution to society and the economy and have lives full of opportunity, free from the effects of poverty.",2007.0,0.0,1994.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Families.2007DepartmentFC,\n author = {Families.},\n title = {Department for Children, Schools and Families},\n year = {2007}\n}\n'}","[{'authorId': '52007025', 'name': 'Families.'}]"
2441,d51f4c193dc322b3cb93e227d168c63ee0637332,"Virtual Social Interactions in Social Anxiety - The Impact of Sex, Gaze, and Interpersonal Distance","In social interactions, interpersonal distance between interaction partners plays an important role in determining the status of the relationship. Interpersonal distance is an important nonverbal behavior, and is used to regulate personal space in a complex interplay with other nonverbal behaviors such as eye gaze. In social anxiety, studies regarding the impact of interpersonal distance on within-situation avoidance behavior are so far rare. Thus the present study aimed to scrutinize the relationship between gaze direction, sex, interpersonal distance, and social anxiety in social interactions. Social interactions were modeled in a virtual-reality (VR) environment, where 20 low and 19 high socially anxious women were confronted with approaching male and female characters, who stopped in front of the participant, either some distance away or close to them, and displayed either a direct or an averted gaze. Gaze and head movements, as well as heart rate, were measured as indices of avoidance behavior and fear reactions. High socially anxious participants showed a complex pattern of avoidance behavior: when the avatar was standing farther away, high socially anxious women avoided gaze contact with male avatars showing a direct gaze. Furthermore, they showed avoidance behavior (backward head movements) in response to male avatars showing a direct gaze, regardless of the interpersonal distance. Overall, the current study proved that VR social interactions might be a very useful tool for investigating avoidance behavior of socially anxious individuals in highly controlled situations. This might also be the first step in using VR social interactions in clinical protocols for the therapy of social anxiety disorder.",2010.0,48.0,85.0,False,,"{'volume': '13 5', 'pages': '\n          547-54\n        ', 'name': 'Cyberpsychology, behavior and social networking'}","{'bibtex': '@Article{Wieser2010VirtualSI,\n author = {M. Wieser and P. Pauli and Miriam Grosseibl and Ina Molzow and A. Mühlberger},\n journal = {Cyberpsychology, behavior and social networking},\n pages = {\n          547-54\n        },\n title = {Virtual Social Interactions in Social Anxiety - The Impact of Sex, Gaze, and Interpersonal Distance},\n volume = {13 5},\n year = {2010}\n}\n'}","[{'authorId': '34439843', 'name': 'M. Wieser'}, {'authorId': '145825010', 'name': 'P. Pauli'}, {'authorId': '3020847', 'name': 'Miriam Grosseibl'}, {'authorId': '3104492', 'name': 'Ina Molzow'}, {'authorId': '1684604', 'name': 'A. Mühlberger'}]"
2442,d55b664b8353cce40c1a93fb40314eaf64ea1662,Patient adherence with treatment.,,2007.0,1.0,8.0,False,,"{'volume': '56 5', 'pages': '\n          892\n        ', 'name': 'Journal of the American Academy of Dermatology'}","{'bibtex': '@Article{Rothstein2007PatientAW,\n author = {M. S. Rothstein},\n journal = {Journal of the American Academy of Dermatology},\n pages = {\n          892\n        },\n title = {Patient adherence with treatment.},\n volume = {56 5},\n year = {2007}\n}\n'}","[{'authorId': '48864362', 'name': 'M. S. Rothstein'}]"
2443,d588bfb109693795ad4d9e3d57fa3e13f649c903,Advantages and challenges associated with augmented reality for education : A systematic review of the literature,,2017.0,78.0,1081.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Akçay2017AdvantagesAC,\n author = {Murat Akçay},\n title = {Advantages and challenges associated with augmented reality for education : A systematic review of the literature},\n year = {2017}\n}\n'}","[{'authorId': '2071582721', 'name': 'Murat Akçay'}]"
2444,d5c870988bc490dc87d4a06ee0e6342a5b165187,Greta: an interactive expressive ECA system,"We have developed a general purpose use and modular architecture of an Embodied Conversational Agent (ECA) called Greta. Our 3D agent is able to communicate using verbal and nonverbal channels like gaze, head and torso movements, facial expressions and gestures. It follows the SAIBA framework [10] and the MPEG4 [6] standards. Our system is optimized to be used in interactive applications.",2009.0,10.0,146.0,False,,{'pages': '1399-1400'},"{'bibtex': '@Inproceedings{Niewiadomski2009GretaAI,\n author = {Radoslaw Niewiadomski and Elisabetta Bevacqua and M. Mancini and C. Pelachaud},\n pages = {1399-1400},\n title = {Greta: an interactive expressive ECA system},\n year = {2009}\n}\n'}","[{'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2446,d5ca5efdecba2707aab57d4cb2df008a7ecdd0dd,Animated Pedagogical Agents: Face-to-Face Interaction in Interactive Learning Environments,"Recent years have witnessed the birth of a new paradigm for learning environments: animated pedagogical agents. These lifelike autonomous characters cohabit learning environments with students to create rich, face-to-face learning interactions. This opens up exciting new possibilities; for example, agents can demonstrate complex tasks, employ locomotion and gesture to focus students' attention on the most salient aspect of the task at hand, and convey emotional responses to the tutorial situation. Animated pedagogical agents offer great promise for broadening the bandwidth of tutorial communication and increasing learning environments' ability to engage and motivate students. This article sets forth the motivations behind animated pedagogical agents, describes the key capabilities they offer, and discusses the technical issues they raise. The discussion is illustrated with descriptions of a number of animated agents that represent the current state of the art.",2000.0,87.0,1152.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Johnson2000AnimatedPA,\n author = {W. Johnson and J. Rickel and James C. Lester},\n title = {Animated Pedagogical Agents: Face-to-Face Interaction in Interactive Learning Environments},\n year = {2000}\n}\n'}","[{'authorId': '145834590', 'name': 'W. Johnson'}, {'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '1717955', 'name': 'James C. Lester'}]"
2450,d5f799ebc283e399f1b13516f28588c1a8fadb32,The USC CreativeIT database of multimodal dyadic interactions: from speech and full body motion capture to continuous emotional annotations,,2016.0,60.0,55.0,False,,"{'volume': '50', 'pages': '497-521', 'name': 'Language Resources and Evaluation'}","{'bibtex': '@Article{Metallinou2016TheUC,\n author = {A. Metallinou and Zhaojun Yang and Chi-Chun Lee and C. Busso and S. Carnicke and Shrikanth S. Narayanan},\n journal = {Language Resources and Evaluation},\n pages = {497-521},\n title = {The USC CreativeIT database of multimodal dyadic interactions: from speech and full body motion capture to continuous emotional annotations},\n volume = {50},\n year = {2016}\n}\n'}","[{'authorId': '47851995', 'name': 'A. Metallinou'}, {'authorId': '3161887', 'name': 'Zhaojun Yang'}, {'authorId': '2467369', 'name': 'Chi-Chun Lee'}, {'authorId': '2106794', 'name': 'C. Busso'}, {'authorId': '2090211', 'name': 'S. Carnicke'}, {'authorId': '145254843', 'name': 'Shrikanth S. Narayanan'}]"
2451,d60d6f42b98c390d64bae95fc0538f62b27bca0c,Decision Model for a Virtual Agent that can Touch and be Touched,"Touch is an essential sense to the social development and well-being of individuals, acting as a communicative channel for emotions and empathy. Our overall objective is to enhance the ability of embod-ied conversational agents (ECAs) to bond with humans. To reach such an objective, we have endowed an ECA with the capacity to touch and be touched in a social interaction with a human in an immersive environment. By drawing inspiration from literature on human-human social touch and related works on human-agent tactile interactions, we have developed a framework for a touching ECA able to perceive when and how a user touches it and decide when and how to respond accordingly. This paper focuses on going beyond a simple bi-directional touch interaction through a decision model that actually adapts its behaviour to the content of the interaction, the level of rapport and the human’s touch avoidance sensibility. This enables an actual interactive loop between the agent and the human.",2021.0,57.0,3.0,False,,{'pages': '232-241'},"{'bibtex': '@Article{Boucaud2021DecisionMF,\n author = {Fabien Boucaud and C. Pelachaud and I. Thouvenin},\n booktitle = {Adaptive Agents and Multi-Agent Systems},\n pages = {232-241},\n title = {Decision Model for a Virtual Agent that can Touch and be Touched},\n year = {2021}\n}\n'}","[{'authorId': '90192992', 'name': 'Fabien Boucaud'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2933446', 'name': 'I. Thouvenin'}]"
2452,d621786b597687f555fae83dc1a021fd21713d90,Intelligent agents: theory and practice,"Abstract The concept of an agent has become important in both artificial intelligence (AT) and mainstream computer science. Our aim in this paper is to point the reader at what we perceive to be the most important theoretical and practical issues associated with the design and construction of intelligent agents. For convenience, we divide these issues into three areas (though as the reader will see, the divisions are at times somewhat arbitrary). Agent theory is concerned with the question of what an agent is, and the use of mathematical formalisms for representing and reasoning about the properties of agents. Agent architectures can be thought of as software engineering models of agents; researchers in this area are primarily concerned with the problem of designing software or hardware systems that will satisfy the properties specified by agent theorists. Finally, agent languages are software systems for programming and experimenting with agents; these languages may embody principles proposed by theorists. The paper is not intended to serve as a tutorial introduction to all the issues mentioned; we hope instead simply to identify the most important issues, and point to work that elaborates on them. The article includes a short review of current and potential applications of agent technology.",1995.0,233.0,7126.0,True,"{'url': 'https://eprints.soton.ac.uk/252102/1/ker95-scanned.pdf', 'status': None}","{'volume': '10', 'pages': '115 - 152', 'name': 'The Knowledge Engineering Review'}","{'bibtex': '@Article{Wooldridge1995IntelligentAT,\n author = {M. Wooldridge and N. Jennings},\n journal = {The Knowledge Engineering Review},\n pages = {115 - 152},\n title = {Intelligent agents: theory and practice},\n volume = {10},\n year = {1995}\n}\n'}","[{'authorId': '48106342', 'name': 'M. Wooldridge'}, {'authorId': '144626042', 'name': 'N. Jennings'}]"
2453,d6229e53c84030895393441a67f8985514b94007,Advancing psychotherapy and evidence‐based psychological interventions,"Psychological models of mental disorders guide research into psychological and environmental factors that elicit and maintain mental disorders as well as interventions to reduce them. This paper addresses four areas. (1) Psychological models of mental disorders have become increasingly transdiagnostic, focusing on core cognitive endophenotypes of psychopathology from an integrative cognitive psychology perspective rather than offering explanations for unitary mental disorders. It is argued that psychological interventions for mental disorders will increasingly target specific cognitive dysfunctions rather than symptom‐based mental disorders as a result. (2) Psychotherapy research still lacks a comprehensive conceptual framework that brings together the wide variety of findings, models and perspectives. Analysing the state‐of‐the‐art in psychotherapy treatment research, “component analyses” aiming at an optimal identification of core ingredients and the mechanisms of change is highlighted as the core need towards improved efficacy and effectiveness of psychotherapy, and improved translation to routine care. (3) In order to provide more effective psychological interventions to children and adolescents, there is a need to develop new and/or improved psychotherapeutic interventions on the basis of developmental psychopathology research taking into account knowledge of mediators and moderators. Developmental neuroscience research might be instrumental to uncover associated aberrant brain processes in children and adolescents with mental health problems and to better examine mechanisms of their correction by means of psychotherapy and psychological interventions. (4) Psychotherapy research needs to broaden in terms of adoption of large‐scale public health strategies and treatments that can be applied to more patients in a simpler and cost‐effective way. Increased research on efficacy and moderators of Internet‐based treatments and e‐mental health tools (e.g. to support “real time” clinical decision‐making to prevent treatment failure or relapse) might be one promising way forward. Copyright © 2013 John Wiley & Sons, Ltd.",2014.0,241.0,158.0,True,"{'url': 'https://europepmc.org/articles/pmc6878277?pdf=render', 'status': None}","{'volume': '23', 'name': 'International Journal of Methods in Psychiatric Research'}","{'bibtex': '@Article{Emmelkamp2014AdvancingPA,\n author = {P. Emmelkamp and D. David and T. Beckers and P. Muris and P. Cuijpers and W. Lutz and G. Andersson and R. Araya and R. B. Baños Rivera and M. Barkham and M. Berking and T. Berger and C. Botella and P. Carlbring and F. Colom and C. Essau and D. Hermans and S. Hofmann and S. Knappe and T. Ollendick and F. Raes and W. Rief and H. Riper and S. van der Oord and B. Vervliet},\n journal = {International Journal of Methods in Psychiatric Research},\n title = {Advancing psychotherapy and evidence‐based psychological interventions},\n volume = {23},\n year = {2014}\n}\n'}","[{'authorId': '2282500', 'name': 'P. Emmelkamp'}, {'authorId': '144000444', 'name': 'D. David'}, {'authorId': '2244688', 'name': 'T. Beckers'}, {'authorId': '6624399', 'name': 'P. Muris'}, {'authorId': '1802487', 'name': 'P. Cuijpers'}, {'authorId': '143615959', 'name': 'W. Lutz'}, {'authorId': '2282640', 'name': 'G. Andersson'}, {'authorId': '144746475', 'name': 'R. Araya'}, {'authorId': '7587167', 'name': 'R. B. Baños Rivera'}, {'authorId': '3044613', 'name': 'M. Barkham'}, {'authorId': '2581311', 'name': 'M. Berking'}, {'authorId': '153666408', 'name': 'T. Berger'}, {'authorId': '145945543', 'name': 'C. Botella'}, {'authorId': '2538572', 'name': 'P. Carlbring'}, {'authorId': '5604702', 'name': 'F. Colom'}, {'authorId': '3615665', 'name': 'C. Essau'}, {'authorId': '145065355', 'name': 'D. Hermans'}, {'authorId': '2699703', 'name': 'S. Hofmann'}, {'authorId': '47214161', 'name': 'S. Knappe'}, {'authorId': '4641092', 'name': 'T. Ollendick'}, {'authorId': '3672570', 'name': 'F. Raes'}, {'authorId': '3435893', 'name': 'W. Rief'}, {'authorId': '3850886', 'name': 'H. Riper'}, {'authorId': '2493881', 'name': 'S. van der Oord'}, {'authorId': '4605632', 'name': 'B. Vervliet'}]"
2454,d62ce6d0a131781d538fa8cb2c8781a3a567a7fd,ROBOTS WITH HEART.,,2015.0,0.0,18.0,False,,"{'volume': '313 5', 'pages': '\n          60-3\n        ', 'name': 'Scientific American'}","{'bibtex': '@Article{Fung2015ROBOTSWH,\n author = {Pascale Fung},\n journal = {Scientific American},\n pages = {\n          60-3\n        },\n title = {ROBOTS WITH HEART.},\n volume = {313 5},\n year = {2015}\n}\n'}","[{'authorId': '1683412', 'name': 'Pascale Fung'}]"
2455,d63addfd508a7273bb9bf98f48883256ff12b46f,Psychology as a mother of invention,"Important progress has been made in the methodology for making computer systems easier to use. Highlights are the ""Wizard-of-Oz"" technique and rapid iterative developmental testing. It is argued that more fundamental advances, inventions of truly new and useful computer-based cognitive tools, will result from deeper behavioral analysis of the capabilities and limitations of human performance. Three such analysis methods are described; failure analysis, individual difference analysis, and time profile analysis. A few dramatic success stories are recounted. Promising targets for ""synthesis by analysis"" are proposed. The reason for this meeting is a shared desire to make computers better tools for people to use in the pursuit of their goals. I 'm going to talk about how to go about doing that. First I'll review what I believe to be highlights of what's been learned so far about how to do our business. Then I'll propose some ways in which I think we can make our future efforts have even broader and more profound effects. As a group, the members of the sponsoring organizations and the audience combine psychology, the study of behavior, with computer science and design, disciplines of invention and construction. It's clear enough why both interests are engaged by the task of building computer tools for human use. But it has not always been obvious how to produce an effective merger of the two. Memory is only too fresh of the days in which programmers programmed only for other programmers, and psychologists only carped. Not long enough gone is the time when human factors specialists were called in to bless a system shortly before it was marketed, and if allowed to do an evaluation at all, took so long and learned so little as to be classified as an expense. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ©1987 ACM-0-89791-213-6/87/0004/0333 $00.75 In the last 5 years we have come a long way. There has been a sea change in attitudes. Designers and programmers have inscribed the words ""user friendly"" on their doorposts, while whole divisions of Fortune 500 companies have focused their efforts on usability. Tools ""such as user interface management systems have been developed to make it easier to focus on the issue, and a number of user-oriented inventions like windows, mice and icons have actually found their way into wide use. Methods for informing the design and development process have also improved dramatically. The most effective improvements have come from the introduction of techniques by which new ideas can be tried and tested for usability quickly, cheaply, and very early in the development cycle. In one, the ""Wizard-of-Oz"" method pioneered by John Gould (Gould, Conti and Hovanyecz, 1983), new system functions or features are evaluated before anything at all is built by having a hidden human play the role of the would-be computer. Another extremely effective methodology that is being applied with increasing frequency and benefit is rapid iterative user testing during development. Feedback from tests of small numbers of representative users suggests modifications of an early prototype which are quickly made, similarly tested, loop. An exemplary application is described by Good, Whiteside and Wixon (1984), who obtained a manyfold reduction in user difficulties by iteratively redesigning an interface on the basis of experience with a prototype installed in a shopping center test facility. Still another promising technique has been the development of approximate computational models of users that allow ""ballpark"" evaluations of certain aspects of interfaces during the design phase itself (Card, Moran and Newell, 1983; Kieras and Polson, 1985) Also, of course, there has been a considerable accumulation of art and wisdom on the part of both human factors people and designers who have been paying attention to these matters, and much of it has been capttlred in compendia of design guidelines (e.g. Smith and Mosier, 1984), and is even beginning to be frozen into requirements and standards. What's next? I believe there are important opportunities for a deeper synergy between behavioral analysis and the powerful techniques of computer science for realizing systems that help with intellectual tasks, I believe that we should broaden the conception of our role as workers",1986.0,11.0,50.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/30851.275653', 'status': None}",{'pages': '333-335'},"{'bibtex': '@Inproceedings{Landauer1986PsychologyAA,\n author = {T. Landauer},\n pages = {333-335},\n title = {Psychology as a mother of invention},\n year = {1986}\n}\n'}","[{'authorId': '1836606', 'name': 'T. Landauer'}]"
2456,d659cd681c27e464d9afb1e659336eaa7f93f712,INFLUENCE OF AUTONOMIC SIGNALS ON PERCEPTION OF EMOTIONS IN EMBODIED AGENTS,"Specific patterns of autonomic activity have been reported when people experience emotions. Typical autonomic signals that change with emotion are wrinkles, blushing, sweating, tearing, and respiration. This article explores whether these signals can also influence the perception of emotion in embodied agents. The article first reviews the literature on specific autonomic signal patterns associated with certain affective states. Next, it proceeds to describe a real-time model for wrinkles, blushing, sweating, tearing, and respiration that is capable of implementing those patterns. Two studies are then described. In the first, subjects compare surprise, sadness, anger, shame, pride, and fear expressed in an agent with or without blushing, wrinkles, sweating, or tears. In the second, subjects compare excitement, relaxation, focus, pain, relief, boredom, anger, fear, panic, disgust, surprise, startle, sadness, and joy expressed in an agent with or without typical respiration patterns. The first study shows a statistically significant positive effect on perception of surprise, sadness, anger, shame, and fear. The second study shows a statistically significant positive effect on perception of excitement, pain, relief, boredom, anger, fear, panic, disgust, and startle. The relevance of these results to artificial intelligence and intelligent virtual agents is discussed.",2010.0,73.0,17.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/08839514.2010.492159?needAccess=true&role=button', 'status': None}","{'volume': '24', 'pages': '494 - 509', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Melo2010INFLUENCEOA,\n author = {C. D. Melo and Patrick G. Kenny and J. Gratch},\n journal = {Applied Artificial Intelligence},\n pages = {494 - 509},\n title = {INFLUENCE OF AUTONOMIC SIGNALS ON PERCEPTION OF EMOTIONS IN EMBODIED AGENTS},\n volume = {24},\n year = {2010}\n}\n'}","[{'authorId': '1977901', 'name': 'C. D. Melo'}, {'authorId': '3181776', 'name': 'Patrick G. Kenny'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2457,d65e6b99059292cd145b00ecdea947dad89dae91,Multi-Disciplinary Paths to Actor-Centric Non-Player Character Emotion Models,"Video game non-player characters (NPCs) are a type of agent that often inherits emotion models and functions from ancestor virtual agents. Few emotion models have been designed for NPCs explicitly, and therefore do not approach the expressive possibilities available to live-action performing actors nor hand-crafted animated characters. With distinct perspectives on emotion generation from multiple fields within narratology and computational cognitive psychology, the architecture of NPC emotion systems can reflect the theories and practices of performing artists. This chapter argues that the deployment of virtual agent emotion models applied to NPCs can constrain the performative aesthetic properties of NPCs. An actor-centric emotion model can accommodate creative processes for actors and may reveal what features emotion model architectures should have that are most useful for contemporary game production of photorealistic NPCs that achieve cinematic acting styles and robust narrative design.",2021.0,31.0,0.0,False,,"{'name': '', 'pages': '17-42', 'volume': ''}","{'bibtex': '@Inproceedings{Schiffer2021MultiDisciplinaryPT,\n author = {Sheldon Schiffer},\n pages = {17-42},\n title = {Multi-Disciplinary Paths to Actor-Centric Non-Player Character Emotion Models},\n year = {2021}\n}\n'}","[{'authorId': '144812758', 'name': 'Sheldon Schiffer'}]"
2458,d674763a31eaa14c5d0425a694ea71669fedbc4e,Mechanisms of Age Cognition Relations in Adulthood,Contents: The Phenomenon and the Methods to Be Used in Its Investigation. Working Memory as a Potential Mediator. Processing Speed as a Potential Mediator. Summary.,1992.0,0.0,223.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Salthouse1992MechanismsOA,\n author = {T. Salthouse},\n title = {Mechanisms of Age Cognition Relations in Adulthood},\n year = {1992}\n}\n'}","[{'authorId': '3344407', 'name': 'T. Salthouse'}]"
2459,d696912be0427bd5dade666658b05652a7a0c8ee,Virtual Agent Behavior Modeling in Case of a Risky Situation in a Virtual Electrical Substation,": In this paper, the behavior of a realistically represented intelligent virtual agent (IVA) that accompanies students during their visit to a virtual electrical substation is modeled. The choice of technologies for modeling the agent and the task environment is considered. The properties of the task environment are discussed. The agent’s behavior when a risky situation occurs is investigated. For this purpose, an IVA behavior model, based on psychological theories of motivation, emotions, and power is proposed. A change in the IVA priorities and, as a consequence, a change in its goal is modeled. Results of a survey, studying the trust, which the IVA receives from the students, are presented. To have a more realistic IVA, the model includes knowledge of the environment, the shortest evacuation route learning, visitor training locations, priorities, emotions, social power strategy, set goals, abilities to learn, abilities to change priorities and goals when a risk occurs, and a role of a specialist – electrician.",2023.0,58.0,0.0,True,,{'pages': '189-198'},"{'bibtex': '@Article{Budakova2023VirtualAB,\n author = {D. Budakova and V. Vasilev and L. Dakovski and Stanimir Stefanov},\n booktitle = {International Conference on Agents and Artificial Intelligence},\n pages = {189-198},\n title = {Virtual Agent Behavior Modeling in Case of a Risky Situation in a Virtual Electrical Substation},\n year = {2023}\n}\n'}","[{'authorId': '1799528', 'name': 'D. Budakova'}, {'authorId': '1717047753', 'name': 'V. Vasilev'}, {'authorId': '1753312', 'name': 'L. Dakovski'}, {'authorId': '2210749260', 'name': 'Stanimir Stefanov'}]"
2460,d69f14d9fb44ef57a04d93cfb93f1e717a69868d,You Spin Me Right Round: Cross-Relationship Variability in Interpersonal Emotion Regulation,"Individuals use a range of interpersonal emotion regulation strategies to influence the feelings of others, e.g., friends, family members, romantic partners, work colleagues. But little is known about whether people vary their strategy use across these different relational contexts. We characterize and measure this variability as “spin,” i.e., the extent of dispersion in a person’s interpersonal emotion regulation strategy use across different relationships, and focus on two key questions. First, is spin adaptive or maladaptive with regard to personal well-being and relationship quality? Second, do personality traits that are considered important for interpersonal functioning (i.e., empathy, attachment style) predict spin? The data used in this study is drawn from a large online survey. A key contribution of this study is to reveal that people who varied the type of strategies they used across relationships (i.e., those with high spin) had lower positive mood, higher emotional exhaustion, and less close relationships. A further key contribution is to show that spin was associated with low empathic concern and perspective taking and high anxious attachment style. High variability in interpersonal emotion regulation strategies across relationships therefore appears to be maladaptive both personally and socially.",2012.0,56.0,36.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00394/pdf', 'status': None}","{'volume': '3', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Niven2012YouSM,\n author = {Karen Niven and Ian A. Macdonald and D. Holman},\n journal = {Frontiers in Psychology},\n title = {You Spin Me Right Round: Cross-Relationship Variability in Interpersonal Emotion Regulation},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '145276844', 'name': 'Karen Niven'}, {'authorId': '120563236', 'name': 'Ian A. Macdonald'}, {'authorId': '78063653', 'name': 'D. Holman'}]"
2461,d6a91824391371f0a560cd7bf615b55f01f97c3e,A study of how immersion and interactivity drive VR learning,,2022.0,61.0,50.0,True,,"{'volume': '179', 'pages': '104429', 'name': 'Comput. Educ.'}","{'bibtex': '@Article{Petersen2022ASO,\n author = {G. Petersen and Giorgos Petkakis and G. Makransky},\n journal = {Comput. Educ.},\n pages = {104429},\n title = {A study of how immersion and interactivity drive VR learning},\n volume = {179},\n year = {2022}\n}\n'}","[{'authorId': '1962373', 'name': 'G. Petersen'}, {'authorId': '2148704426', 'name': 'Giorgos Petkakis'}, {'authorId': '4274170', 'name': 'G. Makransky'}]"
2462,d6b05edd2fd4948e03248473f644ebb9a1b64f59,Galvanic Skin Response Data Classification for Emotion Detection,"Emotion detection is a very exhausting job and needs a complicated process; moreover, these processes also require the proper data training and appropriate algorithm. The process involves the experimental research in psychological experiment and classification methods. This paper describes a method on detection emotion using Galvanic Skin Response (GSR) data. We used the Positive and Negative Affect Schedule (PANAS) method to get a good data training. Furthermore, Support Vector Machine and a correct preprocessing are performed to classify the GSR data. To validate the proposed approach, Receiver Operating Characteristic (ROC) curve, and accuracy measurement are used. Our method shows that the accuracy is about 75.65% while ROC is about 0.8019. It means that the emotion detection can be done satisfactorily and well performed.",2018.0,42.0,25.0,True,"{'url': 'http://ijece.iaescore.com/index.php/IJECE/article/download/11645/9590', 'status': None}",{'name': 'International Journal of Electrical and Computer Engineering (IJECE)'},"{'bibtex': '@Article{Setyohadi2018GalvanicSR,\n author = {D. Setyohadi and Sri Kusrohmaniah and Sebastian Bagya Gunawan and P. Pranowo and A. S. Prabuwono},\n journal = {International Journal of Electrical and Computer Engineering (IJECE)},\n title = {Galvanic Skin Response Data Classification for Emotion Detection},\n year = {2018}\n}\n'}","[{'authorId': '2640945', 'name': 'D. Setyohadi'}, {'authorId': '2095143395', 'name': 'Sri Kusrohmaniah'}, {'authorId': '150296666', 'name': 'Sebastian Bagya Gunawan'}, {'authorId': '9746009', 'name': 'P. Pranowo'}, {'authorId': '1751633', 'name': 'A. S. Prabuwono'}]"
2463,d6c4ed037f8b0dbe14ac7dfc94ea9c9b60bc73ca,A General Chinese Chatbot Based on Deep Learning and Its’ Application for Children with ASD,"Commercial chatbots such as Apple’s Siri, Microsoft’s XiaoIce, Amazon’s Alexa, Jingdong’s JIMI, and Alibaba’s Alime, have some great prospective in applications such as hosting programs, writing poetry, providing pre-sale consulting and after-sales service in E-commerce, and providing virtual shopping guidance. However, in most cases, existed chatbots in the world are neither designed specifically for children, nor suitable for children, especially for children with ASD (autism spectrum disorder). In order to develop chatbots that are suitable for children with ASD, the present study firstly adopted an open source chatting corpus containing more than 1.7 million question-and-answer Chinese sentences of chatting histories involving children in many cases, and screened out more than 400,000 ideal chatting sentences for model training. Then a generative-based method combing Bi-LSTM and attention mechanism with word embedding based on deep neural network was adopted to build a general Chinese chatbot. The quality evaluation results indicated that our chatbot can successfully intrigue participants’ interest and made them understand it well. The chatbot also showed its’ great potential for using in the conversation-mediated intervention for Chinese children with ASD.",2020.0,37.0,10.0,True,"{'url': 'http://www.ijmlc.org/vol10/967-AM4006.pdf', 'status': None}","{'volume': '10', 'pages': '519-526', 'name': 'International Journal of Machine Learning and Computing'}","{'bibtex': '@Article{Li2020AGC,\n author = {Xuan Li and Huixin Zhong and Bin Zhang and Jiaming Zhang},\n journal = {International Journal of Machine Learning and Computing},\n pages = {519-526},\n title = {A General Chinese Chatbot Based on Deep Learning and Its’ Application for Children with ASD},\n volume = {10},\n year = {2020}\n}\n'}","[{'authorId': '2108262941', 'name': 'Xuan Li'}, {'authorId': '37234765', 'name': 'Huixin Zhong'}, {'authorId': '2119454939', 'name': 'Bin Zhang'}, {'authorId': '2108454268', 'name': 'Jiaming Zhang'}]"
2464,d7077b579a3b8352ae59d00deec94c99b64ac06b,Empathy as a driver of prosocial behaviour: highly conserved neurobehavioural mechanisms across species,"Empathy reflects the natural ability to perceive and be sensitive to the emotional states of others, coupled with a motivation to care for their well-being. It has evolved in the context of parental care for offspring, as well as within kinship bonds, to help facilitate group living. In this paper, we integrate the perspectives of evolution, animal behaviour, developmental psychology, and social and clinical neuroscience to elucidate our understanding of the proximate mechanisms underlying empathy. We focus, in particular, on processing of signals of distress and need, and their relation to prosocial behaviour. The ability to empathize, both in animals and humans, mediates prosocial behaviour when sensitivity to others' distress is paired with a drive towards their welfare. Disruption or atypical development of the neural circuits that process distress cues and integrate them with decision value leads to callous disregard for others, as is the case in psychopathy. The realization that basic forms of empathy exist in non-human animals is crucial for gaining new insights into the underlying neurobiological and genetic mechanisms of empathy, enabling translation towards therapeutic and pharmacological interventions.",2016.0,132.0,400.0,True,"{'url': 'https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2015.0077', 'status': None}","{'volume': '371', 'name': 'Philosophical Transactions of the Royal Society B: Biological Sciences'}","{'bibtex': '@Article{Decety2016EmpathyAA,\n author = {J. Decety and I. Bartal and F. Uzefovsky and A. Knafo-Noam},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n title = {Empathy as a driver of prosocial behaviour: highly conserved neurobehavioural mechanisms across species},\n volume = {371},\n year = {2016}\n}\n'}","[{'authorId': '3235030', 'name': 'J. Decety'}, {'authorId': '4141534', 'name': 'I. Bartal'}, {'authorId': '3983316', 'name': 'F. Uzefovsky'}, {'authorId': '1382527236', 'name': 'A. Knafo-Noam'}]"
2465,d72622e04349f847cde3888560dc7e5550ccd29a,Towards a Methodology for Validation of Centrality Measures in Complex Networks,"Background Living systems are associated with Social networks — networks made up of nodes, some of which may be more important in various aspects as compared to others. While different quantitative measures labeled as “centralities” have previously been used in the network analysis community to find out influential nodes in a network, it is debatable how valid the centrality measures actually are. In other words, the research question that remains unanswered is: how exactly do these measures perform in the real world? So, as an example, if a centrality of a particular node identifies it to be important, is the node actually important? Purpose The goal of this paper is not just to perform a traditional social network analysis but rather to evaluate different centrality measures by conducting an empirical study analyzing exactly how do network centralities correlate with data from published multidisciplinary network data sets. Method We take standard published network data sets while using a random network to establish a baseline. These data sets included the Zachary's Karate Club network, dolphin social network and a neural network of nematode Caenorhabditis elegans. Each of the data sets was analyzed in terms of different centrality measures and compared with existing knowledge from associated published articles to review the role of each centrality measure in the determination of influential nodes. Results Our empirical analysis demonstrates that in the chosen network data sets, nodes which had a high Closeness Centrality also had a high Eccentricity Centrality. Likewise high Degree Centrality also correlated closely with a high Eigenvector Centrality. Whereas Betweenness Centrality varied according to network topology and did not demonstrate any noticeable pattern. In terms of identification of key nodes, we discovered that as compared with other centrality measures, Eigenvector and Eccentricity Centralities were better able to identify important nodes.",2014.0,35.0,87.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0090283&type=printable', 'status': None}","{'volume': '9', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Batool2014TowardsAM,\n author = {Komal Batool and M. Niazi},\n journal = {PLoS ONE},\n title = {Towards a Methodology for Validation of Centrality Measures in Complex Networks},\n volume = {9},\n year = {2014}\n}\n'}","[{'authorId': '4026257', 'name': 'Komal Batool'}, {'authorId': '1795560', 'name': 'M. Niazi'}]"
2466,d731ff4de66c38580ccb6e8a92d093766a194878,Integration of emotion and cognition in the lateral prefrontal cortex,"We used functional MRI to test the hypothesis that emotional states can selectively influence cognition-related neural activity in lateral prefrontal cortex (PFC), as evidence for an integration of emotion and cognition. Participants (n = 14) watched short videos intended to induce emotional states (pleasant/approach related, unpleasant/withdrawal related, or neutral). After each video, the participants were scanned while performing a 3-back working memory task having either words or faces as stimuli. Task-related neural activity in bilateral PFC showed a predicted pattern: an Emotion × Stimulus crossover interaction, with no main effects, with activity predicting task performance. This highly specific result indicates that emotion and higher cognition can be truly integrated, i.e., at some point of processing, functional specialization is lost, and emotion and cognition conjointly and equally contribute to the control of thought and behavior. Other regions in lateral PFC showed hemispheric specialization for emotion and for stimuli separately, consistent with a hierarchical and hemisphere-based mechanism of integration.",2002.0,64.0,759.0,True,,"{'volume': '99', 'pages': '4115 - 4120', 'name': 'Proceedings of the National Academy of Sciences of the United States of America'}","{'bibtex': '@Article{Gray2002IntegrationOE,\n author = {J. Gray and T. Braver and M. Raichle},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {4115 - 4120},\n title = {Integration of emotion and cognition in the lateral prefrontal cortex},\n volume = {99},\n year = {2002}\n}\n'}","[{'authorId': '2556954', 'name': 'J. Gray'}, {'authorId': '2723253', 'name': 'T. Braver'}, {'authorId': '2057029', 'name': 'M. Raichle'}]"
2467,d7383e4d77c270fb52d263fb487b6377f0613ef6,Tool-body assimilation model considering grasping motion through deep learning,,2017.0,40.0,30.0,True,,"{'volume': '91', 'pages': '115-127', 'name': 'Robotics Auton. Syst.'}","{'bibtex': '@Article{Takahashi2017ToolbodyAM,\n author = {K. Takahashi and Kitae Kim and T. Ogata and S. Sugano},\n journal = {Robotics Auton. Syst.},\n pages = {115-127},\n title = {Tool-body assimilation model considering grasping motion through deep learning},\n volume = {91},\n year = {2017}\n}\n'}","[{'authorId': '50608286', 'name': 'K. Takahashi'}, {'authorId': '2110778317', 'name': 'Kitae Kim'}, {'authorId': '50527812', 'name': 'T. Ogata'}, {'authorId': '2023682', 'name': 'S. Sugano'}]"
2468,d7482fa49be14224dbe5297ee6b428810b589741,Embodied conversational agents,"Embodied conversational agents are computer-generated cartoonlike characters that demonstrate many of the same properties as humans in face-to-face conversation, including the ability to produce and respond to verbal and nonverbal communication. They constitute a type of (a) multimodal interface where the modalities are those natural to human conversation: speech, facial displays, hand gestures, and body stance; (b) software agent, insofar as they represent the computer in an interaction with a human or represent their human users in a computational environment (as avatars, for example); and (c) dialogue system where both verbal and nonverbal devices advance and regulate the dialogue between the user and the computer. With an embodied conversational agent, the visual dimension of interacting with an animated character on a screen plays an intrinsic role. Not just pretty pictures, the graphics display visual features of conversation in the same way that the face and hands do in face-to-face conversation among humans.This book describes research in all aspects of the design, implementation, and evaluation of embodied conversational agents as well as details of specific working systems. Many of the chapters are written by multidisciplinary teams of psychologists, linguists, computer scientists, artists, and researchers in interface design. The authors include Elisabeth Andre, Norm Badler, Gene Ball, Justine Cassell, Elizabeth Churchill, James Lester, Dominic Massaro, Cliff Nass, Sharon Oviatt, Isabella Poggi, Jeff Rickel, and Greg Sanders.",2000.0,0.0,1042.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cassell2000EmbodiedCA,\n author = {Justine Cassell},\n title = {Embodied conversational agents},\n year = {2000}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}]"
2472,d778baf82269d66d9155066e916007868b132827,A sociable robot to encourage social interaction among the elderly,"In this paper, we present evidence that although current models for introduction of robotic companions stress individual encounters, a social community alternative is promising. This argument emerges from an experiment we conducted with a small interactive robot at two local nursing homes. Here we give a brief introduction to the robot and our experience at the homes. We compare the robot used to a semi-robotic toy whose use initially suggested to us the benefits of social community models in the presentation of robotics to the elderly. We find that even where individual encounters are significant, sensitivity to social dimensions improve the benefits of these encounters",2006.0,13.0,347.0,False,,"{'pages': '3972-3976', 'name': 'Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.'}","{'bibtex': '@Article{Kidd2006ASR,\n author = {Cory D. Kidd and Will Taggart and S. Turkle},\n journal = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.},\n pages = {3972-3976},\n title = {A sociable robot to encourage social interaction among the elderly},\n year = {2006}\n}\n'}","[{'authorId': '34704262', 'name': 'Cory D. Kidd'}, {'authorId': '144779703', 'name': 'Will Taggart'}, {'authorId': '2264591', 'name': 'S. Turkle'}]"
2473,d789dd7659e43306fa9e28ab8a0b033f257d0a27,Virtual Humans for the Study of Rapport in Cross Cultural Settings,"As an increasing part of the Army’s mission involves establishing rapport with diverse populations, training interpersonal skills becomes critically important. Here we describe a “Rapport Agent” that senses and responds to a speaker’s nonverbal behavior and provide empirical evidence that it increases speaker fluency and engagement. We argue such agent technology has potential, both as a training system to enhance communication skills, and to assess the key factors that influence rapport in face-to-face interactions. We conclude by discussing ways the nonverbal correlates of rapport vary between Arabic and English speakers and discuss the potential of such technology to advance research and training into rapport in cross-cultural settings.",2006.0,41.0,3.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Gratch2006VirtualHF,\n author = {J. Gratch and A. Okhmatovskaia and S. Duncan},\n title = {Virtual Humans for the Study of Rapport in Cross Cultural Settings},\n year = {2006}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1947943', 'name': 'A. Okhmatovskaia'}, {'authorId': '144346436', 'name': 'S. Duncan'}]"
2474,d78a6acfc145c0ad599c3c6ba542657f488caa01,Heart Rate Synchrony in Psychological Counseling: A Case Study,"The present study examined interpersonal synchrony during psychological counseling, focusing on heart rate synchrony. In psychological counseling and psychotherapy, embodied synchrony is considered an important factor related to building rapport and empathy. Recent interpersonal synchrony/coordination studies have addressed this issue, not only at the behavioral level but also at the neurological (brain activity) and physiological (cardiac activity) levels. However, there is little known literature on heart rate synchrony in a psychological counseling context. Therefore, we conducted a single exploratory case study to ascertain whether heart rate synchrony was observed in a counseling session and how it related to therapeutic processes and psychological issues. One male university student and one male clinical psychologist participated in our experiment. The student had a counseling session for 50 minutes. Video data were recorded and two wearable sensors were attached to the chests of both participants to collect heart rate data. We applied nonlinear time series analyses, based on a recurrence analysis, to the heart rate data to quantitatively assess heart rate synchrony. A qualitative analysis was also conducted by three clinical psychologists, based on video data from the viewpoints of clinical psychology and psychotherapy. The results show that the heart rate synchrony between client and therapist was observed and changed dynamically during the session. The present study suggests that heart rate synchrony may occur in some clinically important scenes and reflect psychological factors (e.g., building rapport and empathy) and social relationships (e.g., leader-follower). The present study shows the applicability of recurrence-based analyses to complex heart rate data during psychological counseling, as explored in other interpersonal synchrony studies. Further examinations using more data from multiple viewpoints are expected to support our findings and cast light on the relationship between embodied synchrony and psychological issues in the context of psychological counseling and psychotherapy.",2018.0,43.0,19.0,True,"{'url': 'http://www.scirp.org/journal/PaperDownload.aspx?paperID=86168', 'status': None}","{'volume': '09', 'pages': '1858-1874', 'name': 'Psychology'}","{'bibtex': '@Article{Kodama2018HeartRS,\n author = {Kentaro Kodama and Shintaro Tanaka and Daichi Shimizu and Kyoko Hori and H. Matsui},\n journal = {Psychology},\n pages = {1858-1874},\n title = {Heart Rate Synchrony in Psychological Counseling: A Case Study},\n volume = {09},\n year = {2018}\n}\n'}","[{'authorId': '35086651', 'name': 'Kentaro Kodama'}, {'authorId': '50053878', 'name': 'Shintaro Tanaka'}, {'authorId': '2065065', 'name': 'Daichi Shimizu'}, {'authorId': '2053009209', 'name': 'Kyoko Hori'}, {'authorId': '2018593731', 'name': 'H. Matsui'}]"
2475,d792562462dbb687015954805d31620240db57a1,Episodic and semantic memory,,1972.0,0.0,4356.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Tulving1972EpisodicAS,\n author = {E. Tulving},\n title = {Episodic and semantic memory},\n year = {1972}\n}\n'}","[{'authorId': '2083280282', 'name': 'E. Tulving'}]"
2477,d7ae21f2f22f391e3c782fbffd5353a8f11151d4,Silicon Coppélia: Integrating Three Affect-Related Models for Establishing Richer Agent Interaction,"Affect modeling plays a vital role in faithfully simulating human emotion and in emotionally evocative technology. Current affect models are still strong simplifications compared to human affective complexity. To establish richer agent interaction, we integrated three affect-related models: CoMERG, IPEFiC ADM and EMA. These models partly overlap, and where distinct, they complement one another. The integrated model called Silicon Coppélia was implemented and simulation experiments were performed to test the behavior of the model. These experiments show that the model can simulate richer agent behaviors than any of the models could have done alone.",2009.0,11.0,10.0,False,,"{'volume': '2', 'pages': '279-284', 'name': '2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology'}","{'bibtex': '@Article{Pontier2009SiliconCI,\n author = {M. Pontier and G. F. Siddiqui},\n journal = {2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology},\n pages = {279-284},\n title = {Silicon Coppélia: Integrating Three Affect-Related Models for Establishing Richer Agent Interaction},\n volume = {2},\n year = {2009}\n}\n'}","[{'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '3347943', 'name': 'G. F. Siddiqui'}]"
2479,d7b5bfe116ff3a8607a1b7d88574c6490f39a0e8,The effect and mechanisms of self-transcendence values on durable happiness,": Values play a guiding role during an individual’s development and values are closely related to well-being. If a person focuses egocentrically on self-enhancement values, the consequence may be fluctuating happiness in forms of the alternation of transitory pleasure and afflictive effects. In constrast, if a person endorses values of self-transcendence in terms of caring for the well-being of others, the outcome may be durable happiness, which is characterized by a state of enduring contentment and inner peace. As far as the mechanism is concerned, an individual who endorses on self-transcendence values displays fewer defensive responses to self-threatening information as well as experiences more socially engaging emotions such as empathy, love and compassion, and he or she also exhibits more prosocial behaviors. Overall, through these three paths, individuals who endorsed the values of self-transcendence may experience durable happiness. A variety of methods and means should be used to investigate the effect of values of self-transcendence on durable happiness. In addition, other potential mechanisms between the two variables can be studied. Also, education about values of self-transcendence should be carried out to cultivate a healthy social mentality.",2022.0,78.0,3.0,True,"{'url': 'https://www.sciengine.com/doi/pdf/A573D00AFB90463288BC19593FE83BCB', 'status': None}",{'name': 'Advances in Psychological Science'},"{'bibtex': '@Article{Liu2022TheEA,\n author = {Ping-Chin Liu and Rongwei Zhang and Dan Li},\n journal = {Advances in Psychological Science},\n title = {The effect and mechanisms of self-transcendence values on durable happiness},\n year = {2022}\n}\n'}","[{'authorId': '152814531', 'name': 'Ping-Chin Liu'}, {'authorId': '152692052', 'name': 'Rongwei Zhang'}, {'authorId': '2150382063', 'name': 'Dan Li'}]"
2480,d7d0bc213119e930833a7f40005b2fd111399957,RCS: A cognitive architecture for intelligent multi-agent systems,,2005.0,32.0,73.0,False,,"{'volume': '29', 'pages': '87-99', 'name': 'Annu. Rev. Control.'}","{'bibtex': '@Article{Albus2005RCSAC,\n author = {J. Albus and A. Barbera},\n journal = {Annu. Rev. Control.},\n pages = {87-99},\n title = {RCS: A cognitive architecture for intelligent multi-agent systems},\n volume = {29},\n year = {2005}\n}\n'}","[{'authorId': '3259367', 'name': 'J. Albus'}, {'authorId': '145667472', 'name': 'A. Barbera'}]"
2481,d7f05e0e7d45b539188dbf0dd1648fd03565c185,Mind Reading: The Interactive Guide to Emotions,"Simon Baron-Cohen, Professor of Developmental Psychopathology at the University of Cambridge has long been known for his work with autism and, as we all know, children with autism have quite remarkable deficiencies in their ability to use or read the social cues and emotions of everyday life. In this remarkable set of CDs he has taken up the challenge of teaching these skills in a unique manner. 
 
Once installed, the child or youth (and even adults) signs on their unique identifier and enters one of three main centres: Emotions Library, Learning Center, and Games Zone. The material is graded into 6 levels of complexity, and various forms of help (e.g. a happy robot ‘Emoto’, somewhat like a talking MicroSoft Office Assistant) are easily available allowing even young children to explore on their own. 
 
In the Emotions Library, 412 emotions are arranged in 24 groups. Once the child picks a group, she or he can click on an emotion in that group and see actors (6 different ones representing various ages, cultures and both sexes) in a brief video with a narrator describing the emotion and what to watch for. In addition, there are sample story lines illustrating the emotion (at the younger levels, clicking on a line leads to the narrator speaking it), sample voice expressions of the emotion and information about the emotion (definition, whether it is seen as positive or negative, notes about how others usually react to it). Students get a chance to make and keep notes under their log-on name. 
 
In the Learning Center, the emotions groups are similar to the library but the structure is more conducive to learning and exploration, again with videos, stories and vocal expressions separately. The lessons contain test questions and give students a chance to concentrate on the beginners 100 or top 20 along with questions and rewards. The quizzes give a chance to find faces with specific emotions, match emotional statements and faces, match statements with people in a picture. 
 
Rewards are built into much of the practice and include hundreds of objects with a variety of information or movement. Objects include flags, butterflies, trains, birds, objects of the universe and more. If all the train cars are collected, it can be assembled to drive around a track. Other objects can be enlarged under a microscope, time lapse movies can be constructed and, my favourite, band instruments play–the more instruments collected, the more interesting the music that can be constructed. One reward is building up time to spend in the Games Zone. 
 
The Games Zone includes matching games, hand-eye coordination games, real world face games and the opportunity to control Daniel Radcliffe (aka Harry Potter) in a variety of emotions. 
 
It is not enough merely to teach the emotions, make the lessons fun, earn rewards and play games. Behind the whole set-up is Mind Reading Manager. This sets the parameters for a number of components of the three major sections thus allowing parents, teachers or professionals to track progress of a child, limit time in games, set limits on emotions (e.g. removing the ‘romantic’ emotions from beginner levels for children), fix levels and more. It is possible to track students’ overall engagement with different components, lists of emotions completed, average scores and more. 
 
My own delay in forwarding a book review was that I wanted a chance to test it out for real with a day treatment service (age groups 5 to 9, 10 to 12 and 13 to 18 years). Attendees included those with disruptive behavioural disorders, depression, anxiety and pervasive developmental disorders. The program was particularly suited to group work with children with developmental disorders, but our staff used it for anger management training, social skills training and reward time for children and teens. When it can be used as a reward, you can learn one more important item, this program is fun! The final word from staff and children was that they were so pleased that separate orders for additional CDs were made and for other mental health programs that came to demonstrations. 
 
The CDs or DVD can be installed on notebook computers, desk top computers, or, our favourite, connected to an LCD projector for group work. Technical support is available and it has proven helpful for us (a couple of minor questions). The cost is reasonable and the quality of the production, directing and acting is all excellent. 
 
My overall conclusion is to support the staff I work with; Simon Baron-Cohen and team have done excellent work for children, youth and mental health professionals everywhere. Thank-you Dr. Baron-Cohen!",2007.0,0.0,291.0,False,,"{'volume': '16', 'pages': '182-183', 'name': ""Journal de l'Académie canadienne de psychiatrie de l'enfant et de l'adolescent""}","{'bibtex': ""@Article{Junek2007MindRT,\n author = {W. Junek},\n journal = {Journal de l'Académie canadienne de psychiatrie de l'enfant et de l'adolescent},\n pages = {182-183},\n title = {Mind Reading: The Interactive Guide to Emotions},\n volume = {16},\n year = {2007}\n}\n""}","[{'authorId': '31864525', 'name': 'W. Junek'}]"
2482,d8326c457c1036d12f2c85033ddfcff0229c6b6e,Development of a Human-Agent Interaction System including Norm and Emotion in an Evacuation Situation (Student Abstract),"Agent-based modeling and simulation can provide a powerful test environment for crisis management scenarios. Human agent interaction has limitations in representing norms issued by an agent to a human agent that has emotions. In this study, we present an approach to the interaction between a virtual normative agent and a human agent in an evacuation scenario. Through simulation comparisons, it is shown that the method used in this study can more fully simulate the real-life out come of an emergency situation and also improves the au thenticity of the agent interaction.",2023.0,7.0,0.0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/27025/26797', 'status': 'GOLD'}",{'pages': '16330-16331'},"{'bibtex': '@Article{Pagou2023DevelopmentOA,\n author = {E. Pagou and V. Kamla and I. Tchappi and A. Najjar},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {16330-16331},\n title = {Development of a Human-Agent Interaction System including Norm and Emotion in an Evacuation Situation (Student Abstract)},\n year = {2023}\n}\n'}","[{'authorId': '66280130', 'name': 'E. Pagou'}, {'authorId': '10394930', 'name': 'V. Kamla'}, {'authorId': '51221370', 'name': 'I. Tchappi'}, {'authorId': '2297347', 'name': 'A. Najjar'}]"
2483,d8384f7ef288d2d5cb267128471c5427fc98b54b,An Introduction to Variable and Feature Selection,"Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.",2003.0,57.0,15328.0,False,,"{'volume': '3', 'pages': '1157-1182', 'name': 'J. Mach. Learn. Res.'}","{'bibtex': '@Article{Guyon2003AnIT,\n author = {Isabelle M Guyon and A. Elisseeff},\n journal = {J. Mach. Learn. Res.},\n pages = {1157-1182},\n title = {An Introduction to Variable and Feature Selection},\n volume = {3},\n year = {2003}\n}\n'}","[{'authorId': '1743797', 'name': 'Isabelle M Guyon'}, {'authorId': '1766703', 'name': 'A. Elisseeff'}]"
2484,d83921fab4ed59492bc34019e1e61f94bd462308,The role of emotion in believable agents,". Abstract Arti(cid:12)cial intelligence researchers attempting to create engaging, apparently living creatures may (cid:12)nd important insight in the work of artists who have explored the idea of believable character. In particular, appropriately timed and clearly expressed emotion is a central requirement for believable characters. We discuss these ideas and suggest how they may apply to believable interactive characters, which we call \believable agents."" This work was supported in part by Fujitsu Laboratories and Mitsubishi Electric Research Laboratories. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the o(cid:14)cial policies, either expressed or implied, of any other parties.",1994.0,12.0,1384.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/176789.176803', 'status': None}","{'volume': '37', 'pages': '122-125', 'name': 'Commun. ACM'}","{'bibtex': '@Article{Bates1994TheRO,\n author = {J. Bates},\n journal = {Commun. ACM},\n pages = {122-125},\n title = {The role of emotion in believable agents},\n volume = {37},\n year = {1994}\n}\n'}","[{'authorId': '145207410', 'name': 'J. Bates'}]"
2486,d860cf64a846ee234c7b97cb50189b29c6dce829,A personality based adaptive approach for information systems,,2015.0,43.0,25.0,False,,"{'volume': '44', 'pages': '156-165', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Capuano2015APB,\n author = {N. Capuano and Giuseppe D’aniello and Angelo Gaeta and Sergio Miranda},\n journal = {Comput. Hum. Behav.},\n pages = {156-165},\n title = {A personality based adaptive approach for information systems},\n volume = {44},\n year = {2015}\n}\n'}","[{'authorId': '1705430', 'name': 'N. Capuano'}, {'authorId': '81500320', 'name': 'Giuseppe D’aniello'}, {'authorId': '1848126', 'name': 'Angelo Gaeta'}, {'authorId': '144602007', 'name': 'Sergio Miranda'}]"
2487,d868fbf872df338aafd3d5e282f444c5e7a94d98,The role of pupil size in communication.,,1975.0,0.0,160.0,False,,"{'volume': '233 5', 'pages': '\n          110-2, 116-9\n        ', 'name': 'Scientific American'}","{'bibtex': '@Article{Hess1975TheRO,\n author = {E. Hess},\n journal = {Scientific American},\n pages = {\n          110-2, 116-9\n        },\n title = {The role of pupil size in communication.},\n volume = {233 5},\n year = {1975}\n}\n'}","[{'authorId': '37589220', 'name': 'E. Hess'}]"
2488,d86e245dd09aa5b1a7956ad680e110fae074de4b,Virtual reality compared with in vivo exposure in the treatment of social anxiety disorder: A three-arm randomised controlled trial,"Background People with social anxiety disorder (SAD) fear social interactions and may be reluctant to seek treatments involving exposure to social situations. Social exposure conducted in virtual reality (VR), embedded in individual cognitive–behavioural therapy (CBT), could be an answer. Aims To show that conducting VR exposure in CBT for SAD is effective and is more practical for therapists than conducting exposure in vivo. Method Participants were randomly assigned to either VR exposure (n = 17), in vivo exposure (n = 22) or waiting list (n = 20). Participants in the active arms received individual CBT for 14 weekly sessions and outcome was assessed with questionnaires and a behaviour avoidance test. (Trial registration number ISRCTN99747069.) Results Improvements were found on the primary (Liebowitz Social Anxiety Scale) and all five secondary outcome measures in both CBT groups compared with the waiting list. Conducting exposure in VR was more effective at post-treatment than in vivo on the primary outcome measure and on one secondary measure. Improvements were maintained at the 6-month follow-up. VR was significantly more practical for therapists than in vivo exposure. Conclusions Using VR can be advantageous over standard CBT as a potential solution for treatment avoidance and as an efficient, cost-effective and practical medium of exposure.",2017.0,53.0,224.0,True,"{'url': 'https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D541B09E2FF234FA82A7001AB44E3989/S0007125000281129a.pdf/div-class-title-virtual-reality-compared-with-span-class-italic-in-vivo-span-exposure-in-the-treatment-of-social-anxiety-disorder-a-three-arm-randomised-controlled-trial-div.pdf', 'status': None}","{'volume': '210', 'pages': '276 - 283', 'name': 'British Journal of Psychiatry'}","{'bibtex': '@Article{Bouchard2017VirtualRC,\n author = {S. Bouchard and Stéphanie Dumoulin and Geneviève Robillard and Tanya Guitard and E. Klinger and H. Forget and C. Loranger and F. Roucaut},\n journal = {British Journal of Psychiatry},\n pages = {276 - 283},\n title = {Virtual reality compared with in vivo exposure in the treatment of social anxiety disorder: A three-arm randomised controlled trial},\n volume = {210},\n year = {2017}\n}\n'}","[{'authorId': '144981172', 'name': 'S. Bouchard'}, {'authorId': '49883239', 'name': 'Stéphanie Dumoulin'}, {'authorId': '35912970', 'name': 'Geneviève Robillard'}, {'authorId': '2065916', 'name': 'Tanya Guitard'}, {'authorId': '2319174', 'name': 'E. Klinger'}, {'authorId': '3841722', 'name': 'H. Forget'}, {'authorId': '7908884', 'name': 'C. Loranger'}, {'authorId': '7832131', 'name': 'F. Roucaut'}]"
2489,d87d864a05805c4eafe74df8959c1c4644f8c22e,Affective Body Expression Perception and Recognition: A Survey,"Thanks to the decreasing cost of whole-body sensing technology and its increasing reliability, there is an increasing interest in, and understanding of, the role played by body expressions as a powerful affective communication channel. The aim of this survey is to review the literature on affective body expression perception and recognition. One issue is whether there are universal aspects to affect expression perception and recognition models or if they are affected by human factors such as culture. Next, we discuss the difference between form and movement information as studies have shown that they are governed by separate pathways in the brain. We also review psychological studies that have investigated bodily configurations to evaluate if specific features can be identified that contribute to the recognition of specific affective states. The survey then turns to automatic affect recognition systems using body expressions as at least one input modality. The survey ends by raising open questions on data collecting, labeling, modeling, and setting benchmarks for comparing automatic recognition systems.",2013.0,191.0,541.0,False,,"{'volume': '4', 'pages': '15-33', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Kleinsmith2013AffectiveBE,\n author = {A. Kleinsmith and N. Bianchi-Berthouze},\n journal = {IEEE Transactions on Affective Computing},\n pages = {15-33},\n title = {Affective Body Expression Perception and Recognition: A Survey},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '2870739', 'name': 'A. Kleinsmith'}, {'authorId': '1398541310', 'name': 'N. Bianchi-Berthouze'}]"
2490,d8a77815f38bc5d21b591efbaa23cb6975e88766,The affective component of the secure base schema: affective priming with representations of attachment security.,"Using an affective priming procedure (S. T. Murphy & R. B. Zajonc, 1993), 7 studies examined the effects of the contextual activation of representations of attachment security (secure base schema) on the evaluation of neutral stimuli under either neutral or stressful contexts. In all the studies, participants also reported on their attachment style. Results indicated that the subliminal priming of secure base representations led to more positive affective reactions to neutral stimuli than did the subliminal priming of neutral or no pictures under both neutral and stressful contexts. Although the subliminal priming of positively valued, attachment-unrelated representations heightened positive evaluations under neutral contexts, it failed to elicit positive affect under stressful contexts. The results also revealed interesting effects of attachment style. The discussion focuses on the affective component of the secure base schema.",2001.0,48.0,312.0,False,,"{'volume': '81 2', 'pages': '\n          305-21\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Mikulincer2001TheAC,\n author = {M. Mikulincer and Gilad Hirschberger and Orit Nachmias and Omri Gillath},\n journal = {Journal of personality and social psychology},\n pages = {\n          305-21\n        },\n title = {The affective component of the secure base schema: affective priming with representations of attachment security.},\n volume = {81 2},\n year = {2001}\n}\n'}","[{'authorId': '4021295', 'name': 'M. Mikulincer'}, {'authorId': '2367107', 'name': 'Gilad Hirschberger'}, {'authorId': '2229885721', 'name': 'Orit Nachmias'}, {'authorId': '5605945', 'name': 'Omri Gillath'}]"
2491,d8cf6275e610c797b7a433d5ac9acb7c4de9ec30,"The Big Three Health Behaviors and Mental Health and Well-Being Among Young Adults: A Cross-Sectional Investigation of Sleep, Exercise, and Diet","Background Sleep, physical activity, and diet have been associated with mental health and well-being individually in young adults. However, which of these “big three” health behaviors most strongly predicts mental health and well-being, and their higher-order relationships in predictive models, is less known. This study investigated the differential and higher-order associations between sleep, physical activity, and dietary factors as predictors of mental health and well-being in young adults. Method In a cross-sectional survey design, 1,111 young adults (28.4% men) ages 18–25 from New Zealand and the United States answered an online survey measuring typical sleep quantity and quality; physical activity; and consumption of raw and processed fruit and vegetables, fast food, sweets, and soda, along with extensive covariates (including demographics, socioeconomic status, body mass index, alcohol use, smoking, and health conditions) and the outcome measures of depressive symptoms [measured by the Center for Epidemiological Depression Scale (CES-D)] and well-being (measured by the Flourishing Scale). Results Controlling for covariates, sleep quality was the strongest predictor of depressive symptoms and well-being, followed by sleep quantity and physical activity. Only one dietary factor—raw fruit and vegetable consumption—predicted greater well-being but not depressive symptoms when controlling for covariates. There were some higher-order interactions among health behaviors in predicting the outcomes, but these did not survive cross-validation. Conclusion Sleep quality is an important predictor of mental health and well-being in young adults, whereas physical activity and diet are secondary but still significant factors. Although strictly correlational, these patterns suggest that future interventions could prioritize sleep quality to maximize mental health and well-being in young adults.",2020.0,70.0,52.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2020.579205/pdf', 'status': None}","{'volume': '11', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Wickham2020TheBT,\n author = {Shay-Ruby Wickham and Natasha A. Amarasekara and A. Bartonicek and Tamlin S. Conner},\n journal = {Frontiers in Psychology},\n title = {The Big Three Health Behaviors and Mental Health and Well-Being Among Young Adults: A Cross-Sectional Investigation of Sleep, Exercise, and Diet},\n volume = {11},\n year = {2020}\n}\n'}","[{'authorId': '2034055971', 'name': 'Shay-Ruby Wickham'}, {'authorId': '1485669084', 'name': 'Natasha A. Amarasekara'}, {'authorId': '1708253966', 'name': 'A. Bartonicek'}, {'authorId': '4856780', 'name': 'Tamlin S. Conner'}]"
2492,d8f8d0e5c33fc153ef8ea514749721b7abd81563,Emerging Literacy: Young Children Learn to Read and Write,"The contributors to this volume share practical ideas for day-care workers, teachers and curriculum specialists. The illustrated format features ideas you can use with two- to eight-year-olds in the classroom.",1989.0,0.0,251.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Strickland1989EmergingLY,\n author = {Dorothy S. Strickland and L. Morrow},\n title = {Emerging Literacy: Young Children Learn to Read and Write},\n year = {1989}\n}\n'}","[{'authorId': '2062240', 'name': 'Dorothy S. Strickland'}, {'authorId': '20479937', 'name': 'L. Morrow'}]"
2493,d91c273c6b0cf2c7de5cdf85ec0fedcde300d522,Cognitive Load Theory and the Format of Instruction,"Cognitive load theory suggests that effective instructional material facilitates learning by directing cognitive resources toward activities that are relevant to learning rather than toward preliminaries to learning. One example of ineffective instruction occurs if learners unnecessarily are required to mentally integrate disparate sources of mutually referring information such as separate text and diagrams. Such split-source information may generate a heavy cognitive load, because material must be mentally integrated before learning can commence. This article reports findings from six experiments testing the consequences of split-source and integrated information using electrical engineering and biology instructional materials. Experiment 1 was designed to compare conventional instructions with integrated instructions over a period of several months in an industrial training setting. The materials chosen were unintelligible without mental integration. Results favored integrated instructions throughout th...",1991.0,14.0,2660.0,True,"{'url': 'https://ro.uow.edu.au/cgi/viewcontent.cgi?article=1133&context=edupapers', 'status': None}","{'volume': '8', 'pages': '293-332', 'name': 'Cognition and Instruction'}","{'bibtex': '@Article{Chandler1991CognitiveLT,\n author = {Paul Chandler and J. Sweller},\n journal = {Cognition and Instruction},\n pages = {293-332},\n title = {Cognitive Load Theory and the Format of Instruction},\n volume = {8},\n year = {1991}\n}\n'}","[{'authorId': '145760137', 'name': 'Paul Chandler'}, {'authorId': '2479443', 'name': 'J. Sweller'}]"
2494,d9826086072de7b5c33aa6aad0bb7f74c73d3770,A situational touch: How touch affects people's decision behavior,"While the majority of previous findings have shown that interpersonal touch positively affects human interactions (e.g., cooperation), it is unclear whether touch truly is only positively rather than negatively received, and which situations might influence this differential effect. The present research argued and demonstrated that in a competitive situation touch negatively affects cooperative interactions between the persons involved. Specifically, we showed that in a competitive rather than a supportive environment interpersonal touch on the shoulder will reduce helping behavior towards the person invoking the touch. The first author is a doctoral fellow of the Agency for Innovation by Science and Technology in Flanders (IWT). This work was supported by STRT1/10/013TBA from the Research Fund of the KULeuven.",2013.0,46.0,19.0,False,,"{'volume': '8', 'pages': '237 - 250', 'name': 'Social Influence'}","{'bibtex': ""@Article{Camps2013AST,\n author = {Jeroen Camps and Chloé Tuteleers and J. Stouten and Jill Nelissen},\n journal = {Social Influence},\n pages = {237 - 250},\n title = {A situational touch: How touch affects people's decision behavior},\n volume = {8},\n year = {2013}\n}\n""}","[{'authorId': '30777660', 'name': 'Jeroen Camps'}, {'authorId': '114578725', 'name': 'Chloé Tuteleers'}, {'authorId': '4883175', 'name': 'J. Stouten'}, {'authorId': '114568272', 'name': 'Jill Nelissen'}]"
2495,d98dde779dc311908b768704b7688c1770ed1794,Alternation and interference of feelings.,,,0.0,11.0,True,"{'url': 'https://zenodo.org/record/2468789/files/article.pdf', 'status': None}","{'volume': '18', 'name': 'The Psychological Monographs'}","{'bibtex': '@Misc{None,\n author = {C. Kellogg},\n journal = {The Psychological Monographs},\n title = {Alternation and interference of feelings.},\n volume = {18}\n}\n'}","[{'authorId': '103468824', 'name': 'C. Kellogg'}]"
2496,d997919c30fa6711bc5c25cf8c8aea34fac27b91,OpenFace: An open source facial behavior analysis toolkit,"Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding. We present OpenFace - an open source tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis. OpenFace is the first open source tool capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. The computer vision algorithms which represent the core of OpenFace demonstrate state-of-the-art results in all of the above mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware. Finally, OpenFace allows for easy integration with other applications and devices through a lightweight messaging system.",2016.0,75.0,1207.0,True,"{'url': 'https://www.repository.cam.ac.uk/bitstreams/38d96efd-7698-4aea-825f-bda08c664807/download', 'status': None}","{'pages': '1-10', 'name': '2016 IEEE Winter Conference on Applications of Computer Vision (WACV)'}","{'bibtex': '@Article{Baltrušaitis2016OpenFaceAO,\n author = {T. Baltrušaitis and P. Robinson and Louis-Philippe Morency},\n journal = {2016 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {1-10},\n title = {OpenFace: An open source facial behavior analysis toolkit},\n year = {2016}\n}\n'}","[{'authorId': '1756344', 'name': 'T. Baltrušaitis'}, {'authorId': '2149814967', 'name': 'P. Robinson'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2497,d9a6d795eb46a022935228e23e72a8a099cc1d2f,Extracting Social Meaning: Identifying Interactional Style in Spoken Conversation,"Automatically extracting social meaning and intention from spoken dialogue is an important task for dialogue systems and social computing. We describe a system for detecting elements of interactional style: whether a speaker is awkward, friendly, or flirtatious. We create and use a new spoken corpus of 991 4-minute speed-dates. Participants rated their interlocutors for these elements of style. Using rich dialogue, lexical, and prosodic features, we are able to detect flirtatious, awkward, and friendly styles in noisy natural conversational data with up to 75% accuracy, compared to a 50% baseline. We describe simple ways to extract relatively rich dialogue features, and analyze which features performed similarly for men and women and which were gender-specific.",2009.0,32.0,90.0,True,"{'url': 'http://dl.acm.org/ft_gateway.cfm?id=1620847&type=pdf', 'status': None}",{'pages': '638-646'},"{'bibtex': '@Inproceedings{Jurafsky2009ExtractingSM,\n author = {Dan Jurafsky and R. Ranganath and Daniel A. McFarland},\n pages = {638-646},\n title = {Extracting Social Meaning: Identifying Interactional Style in Spoken Conversation},\n year = {2009}\n}\n'}","[{'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '2615814', 'name': 'R. Ranganath'}, {'authorId': '100525940', 'name': 'Daniel A. McFarland'}]"
2498,d9a9e1f7fa29978890b98c11fc1f9271fa3a55ef,Using Temporal Association Rules for the Synthesis of Embodied Conversational Agents with a Specific Stance,,2016.0,31.0,17.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-03181846/file/2016INVI3765.pdf', 'status': None}",{'pages': '175-189'},"{'bibtex': '@Inproceedings{Janssoone2016UsingTA,\n author = {Thomas Janssoone and C. Clavel and Kévin Bailly and G. Richard},\n pages = {175-189},\n title = {Using Temporal Association Rules for the Synthesis of Embodied Conversational Agents with a Specific Stance},\n year = {2016}\n}\n'}","[{'authorId': '2775420', 'name': 'Thomas Janssoone'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '2521061', 'name': 'Kévin Bailly'}, {'authorId': '145793390', 'name': 'G. Richard'}]"
2499,d9b46096fc5e17b855c6ff6936c8969f185047e2,An Animated Pedagogical Agent to Support Problem-Based Learning,"Problem-based learning (PBL) is a learning theory that emphasizes collaboration and teamwork to solve a problem. However, a problem that frequently occurs in the implementation of PBL is the presence of passive students who usually have difficulty working in teams or who are unmotivated during the process of teaching and learning. An aspect that can positively influence the implementation process of the PBL is the recommendation of context-sensitive learning objects (LOs). Thus, this paper presents an approach based on an animated pedagogical agent and three other agents for the detection of passive students and for the recommendation of LOs in accordance with the students' context to improve the learning process of PBL.",2013.0,33.0,4.0,False,,"{'volume': '8', 'pages': '56-63', 'name': 'IEEE Revista Iberoamericana de Tecnologias del Aprendizaje'}","{'bibtex': '@Article{Fontes2013AnAP,\n author = {L. M. D. O. Fontes and F. M. Neto and Fábio Abrantes Diniz and Danilo Gomes Carlos and L. J. Júnior and L. C. N. D. Silva},\n journal = {IEEE Revista Iberoamericana de Tecnologias del Aprendizaje},\n pages = {56-63},\n title = {An Animated Pedagogical Agent to Support Problem-Based Learning},\n volume = {8},\n year = {2013}\n}\n'}","[{'authorId': '2047872270', 'name': 'L. M. D. O. Fontes'}, {'authorId': '152893198', 'name': 'F. M. Neto'}, {'authorId': '2054578618', 'name': 'Fábio Abrantes Diniz'}, {'authorId': '2062611363', 'name': 'Danilo Gomes Carlos'}, {'authorId': '2053310264', 'name': 'L. J. Júnior'}, {'authorId': '2110910744', 'name': 'L. C. N. D. Silva'}]"
2500,d9c7784977296d48a586e40b0cc9b0f5b9d65de0,A Review of the Development of Embodied Presentation Agents and Their Application Fields,,2004.0,60.0,56.0,True,"{'url': 'http://mm-werkstatt.informatik.uni-augsburg.de/files/publications/87/prendinger-2.pdf', 'status': None}",{'pages': '377-404'},"{'bibtex': '@Inproceedings{Rist2004ARO,\n author = {T. Rist and E. André and Stephan Baldes and Patrick Gebhard and Martin Klesen and Michael Kipp and P. Rist and Markus Schmitt},\n pages = {377-404},\n title = {A Review of the Development of Embodied Presentation Agents and Their Application Fields},\n year = {2004}\n}\n'}","[{'authorId': '144984483', 'name': 'T. Rist'}, {'authorId': '1742930', 'name': 'E. André'}, {'authorId': '1990470', 'name': 'Stephan Baldes'}, {'authorId': '48785659', 'name': 'Patrick Gebhard'}, {'authorId': '2922093', 'name': 'Martin Klesen'}, {'authorId': '145616714', 'name': 'Michael Kipp'}, {'authorId': '2208081', 'name': 'P. Rist'}, {'authorId': '2052615340', 'name': 'Markus Schmitt'}]"
2501,d9c8d4dde4772e06bdb88a2d88c28cee0533d880,KANSEI ENGINEERING CONCEPT IN E-COMMERCE WEBSITE,"In the early days of e-Commerce, web designers follow their intuition of how the website should look like. Further development of web design have seen for instance Nielsen's heuristic, which resulted designers to focus mainly on cognitive functionality and usability. However, as technology advances and e-Commerce matures, the affective quality has become important than ever. Affect has been proven to influence human cognitive judgments, and human first impression or primary affective responses to a website is seen to influence cognitive quality and higher order affect, such as Perceived Usefulness and Perceived Ease of Use. The study focuses at human Perceived Affective Quality, which looks at both valence and arousal dimension of affect, in the measurement of affective responses to an e-Commerce website. Kansei Engineering is a technique that is seen to enable the measurement and assimilation of the affective responses into perceptual design element. This paper presents the concept and framework of Kansei Engineering in e-Commerce websites. The framework provides systematic method of evaluating consumer's subjective emotional responses and ways to determine correlation of emotional responses with website design. Further research with empirical studies will enable to formulate guideline to design affective quality website. Result of such studies will help to increase understanding between web designers and users, and improve affective quality of a website. The design of affective quality website will result a paradigm shift from WYSIWYG to WYSIWYD.",2006.0,39.0,32.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lokman2006KANSEIEC,\n author = {A. Lokman},\n title = {KANSEI ENGINEERING CONCEPT IN E-COMMERCE WEBSITE},\n year = {2006}\n}\n'}","[{'authorId': '2980650', 'name': 'A. Lokman'}]"
2502,d9eeabdd4a7ea23c72a9d11aa00792d16a71f76d,How design characteristics of robots determine evaluation and uncanny valley related responses,,2014.0,89.0,142.0,False,,"{'volume': '36', 'pages': '422-439', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Pütten2014HowDC,\n author = {A. V. D. Pütten and N. Krämer},\n journal = {Comput. Hum. Behav.},\n pages = {422-439},\n title = {How design characteristics of robots determine evaluation and uncanny valley related responses},\n volume = {36},\n year = {2014}\n}\n'}","[{'authorId': '3065464', 'name': 'A. V. D. Pütten'}, {'authorId': '1750852', 'name': 'N. Krämer'}]"
2503,d9f0f7a34f18644efb0eca3a72704da28d5d0084,Age-specific usability issues of software interfaces,"The aim of the present study was to identify shortcomings of electronic interface designs for older users. Beyond general ergonomic factors, the study focused primarily on visual and language aspects of interface design. By means of a multi-method approach, combining cognitive walkthrough procedures with a usability test, age-specific problems and requirements of older computer users were examined. In the cognitive walkthrough shortcomings of a sample application were analyzed. In the usability test the navigation performance of older users (aged 55+) was contrasted to a young adult group, to identify usability problems, which are age-exclusive (interaction difficulties only for older users) and age-specific (general problems that are more pronounced in the older group).",2009.0,28.0,36.0,False,,,"{'bibtex': '@Inproceedings{Wirtz2009AgespecificUI,\n author = {S. Wirtz and E. Jakobs and M. Ziefle},\n title = {Age-specific usability issues of software interfaces},\n year = {2009}\n}\n'}","[{'authorId': '122035392', 'name': 'S. Wirtz'}, {'authorId': '2654230', 'name': 'E. Jakobs'}, {'authorId': '1727090', 'name': 'M. Ziefle'}]"
2504,da108ef0726b52c7339e2c5cfdc57e34d2bc2e34,Study on Emotion Model Building and Virtual Feeling Robot,"Based on artificial psychology and common emotion theory,combined with personality and OCC model in 3-dimension emotion space,this paper builds an emotion model and adopts the model as feeling kernel,realizes a virtual feeling robot by the application software tools of VB,ViaVoice,KeDaXunFei,TalkingShow.The virtual feeling robot not only has the ability of study and memory,but also has the ability of emotion exchange.",2007.0,0.0,4.0,False,,"{'volume': '', 'name': 'Computer Engineering'}","{'bibtex': '@Article{Chao2007StudyOE,\n author = {Wang Chao},\n journal = {Computer Engineering},\n title = {Study on Emotion Model Building and Virtual Feeling Robot},\n year = {2007}\n}\n'}","[{'authorId': '2054523158', 'name': 'Wang Chao'}]"
2505,da1626cc8306c988dd2ae695233faa98db21301f,Estimating Emotion with Biological Information for Robot Interaction,,2017.0,10.0,35.0,True,,{'pages': '1589-1600'},"{'bibtex': '@Inproceedings{Ikeda2017EstimatingEW,\n author = {Y. Ikeda and Ryota Horie and Midori Sugaya},\n pages = {1589-1600},\n title = {Estimating Emotion with Biological Information for Robot Interaction},\n year = {2017}\n}\n'}","[{'authorId': '3424122', 'name': 'Y. Ikeda'}, {'authorId': '37310260', 'name': 'Ryota Horie'}, {'authorId': '145094033', 'name': 'Midori Sugaya'}]"
2506,da2c7189b9f0e927d97a1afcfdab5eb4109ff52a,Nonverbal cues for depression.,"Sixty-seven psychology faculty, graduates and undergraduates, were presented a silent videotape film of 5 depressed and 5 nondepressed psychiatric patients and were asked to identify which patients appeared depressed on the basis of nonverbal cues alone. Ratings of frequency and duration of eye contact were made by 2 raters independent of the investigator. Results showed depressed patients maintained eye contact for only about one-fourth the time that nondepressed patients did. In addition to the identification of eye conact as a nonverbal cue in depression, the mouth and angle of neck were also identified as salient nonverbal cues. Discussion focused on the value of nonverbal cues as a source of diagnostic information.",1974.0,7.0,108.0,False,,"{'volume': '83 3', 'pages': '\n          319-22\n        ', 'name': 'Journal of abnormal psychology'}","{'bibtex': '@Article{Waxer1974NonverbalCF,\n author = {P. Waxer},\n journal = {Journal of abnormal psychology},\n pages = {\n          319-22\n        },\n title = {Nonverbal cues for depression.},\n volume = {83 3},\n year = {1974}\n}\n'}","[{'authorId': '47421976', 'name': 'P. Waxer'}]"
2507,da51344c09418aa79efb70a0ed3003faf722d71f,Effects of Moral Concerns on Negotiations,"Effects of Moral Concerns on Negotiations Eunkyung Kim (eunkyung@usc.edu) 1 , Morteza Dehghani (mdehghan@usc.edu) 1 , Yoo Kyoung Kim (yookyouk@usc.edu) 2 , Peter J. Carnevale (peter.carnevale@marshall.usc.edu) 2 , Jonathan Gratch (gratch@ict.usc.edu) 3 Brain Creativity Institute, University of Southern California, Los Angeles, CA 90089 USA Marshall School of Business, University of Southern California, Los Angeles, CA 90089 Institute for Creative Technologies, University of Southern California, Playa Vista, CA 90094 Abstract There is now considerable evidence that emotion plays an important role in negotiation. Emotions, such as anger and happiness, affect concession-making, not only in human vs. human negotiations but also in human vs. agent negotiations. Recent research has demonstrated the impact of emotional expressions in morally-charged negotiations. Thus, taking people’s moral concerns into account is crucial for building agents that operate in morally sensitive domains. This paper explores the interplay between people’s moral concerns, emotional expressions and concession-making during a morally charged negotiation. Our results demonstrate that participants who had stronger concerns for the Individualizing foundations (Harm and Fairness) make greater concessions for sacred negotiation items when faced with a sad opponent than an angry opponent. Also, we find that participants who had high Binding foundations (In-group, Authority and Purity) are more sensitive to social status, and make greater concessions in scenarios that involve agents in a higher social status. Keywords: Emotion; Moral Foundations Theory; Sacred values; Negotiation; Agent Modeling. Introduction With the growing interest in understanding the role of emotional expressions in negotiation (e.g., Barry, Fulmer & Goates, 2006; Van Kleef et al., 2010), many studies have investigated how emotional expression affects negotiation processes and outcomes (Ames & Johar, 2009; Choi et al., 2012; de Melo et al., 2014). For instance, negotiators concede more when their opponent expresses anger instead of happiness (Van Kleef, De Dreu & Manstead, 2004a, 2004b). Sinaceur & Tiedens (2006) further reveal that the effect of anger on concession works only when anger recipients have poor alternatives. The past works on emotional expression suggest that emotion plays an important role as a signal (e.g., anger indicates a negotiator’s dissatisfaction with his opponent’s offer). Furthermore, negotiators respond to emotional expressions depending on their own conditions (e.g., alternatives). Thus, it is important to understand what moderates a negotiator’s reaction to emotional expression. Past studies have shown that positive moods in negotiation foster concession-making (e.g., Carnevale & Isen, 1986). Mood effects may be mediated by expression of positive emotion, for example, a positive-mood induction procedure may lead negotiators to smile more and this smiling may have an impact on perceptions and concession- making. Regardless, the possible interaction of emotion and other variables, for example, cognition as in decision frame (Carnevale, 2008), or motivation as in moral concerns, is a domain highly worthy of inquiry. Although some studies have tried to understand how people’s innate personality interacts with their emotion during negotiation games (Bolton, Katok, & Zwick, 1998; Batson & Moran, 1999), little research has paid attention to how moral concerns impact reactions to emotional expressions and affect concession-making. Our recent research demonstrates that emotional expressions can potentially shift moral concerns during a negotiation, such that displays of anger would backfire if the negotiator associates moral significance to the objects of the negotiation, whereas displays of sadness promote higher concession-making (Dehghani, Gratch and Carnevale, 2012). Because morality significantly influences decision- making (e.g., Sjoberg & Winroth, 1986; Gintis et al., 2003), the present research aims to examine the role of people’s moral concerns on how they react to emotional expressions and make concessions. Adapting the Moral Foundations Theory (Haidt & Graham, 2007; Haidt & Joseph, 2007; Graham, 2013), we examine effects of two different types of foundations (i.e., Individualizing foundations and Binding foundations) on concession-making. We predict that people who have stronger Individualizing foundations would react more to emotional expressions because the Individualizing foundations indicate the tendency to care about other people’s emotions (whether others are emotionally or physically suffering, or being treated fairly) and therefore, that would effect their concession-making. On the other hand, we predict that people with stronger Binding foundations be more sensitive to their negotiation partner’s social status because Binding foundations indicate concern about other people’s roles in the group (whether negotiation partner is their boss or co-worker). Understanding the interaction between moral concerns and emotion are crucial in designing autonomous decision- making agents that operate in morally sensitive domains. Progress in agent research has enabled us to work closely with software agents in morally sensitive situations where agents’ actions may lead to significant results, such as loss of life (Tambe, 2011; Dehghani et al., 2013). Therefore, it is important to better understand the interactions between people’s moral concerns, emotion and agent decision- making strategies. Our results suggest that incorporating",2014.0,26.0,4.0,False,,"{'volume': '36', 'name': 'Cognitive Science'}","{'bibtex': '@Article{Kim2014EffectsOM,\n author = {Eunkyung Kim and Morteza Dehghani and Y. Kim and P. Carnevale and J. Gratch},\n journal = {Cognitive Science},\n title = {Effects of Moral Concerns on Negotiations},\n volume = {36},\n year = {2014}\n}\n'}","[{'authorId': '47056370', 'name': 'Eunkyung Kim'}, {'authorId': '145707560', 'name': 'Morteza Dehghani'}, {'authorId': '17837204', 'name': 'Y. Kim'}, {'authorId': '48755211', 'name': 'P. Carnevale'}, {'authorId': '145438097', 'name': 'J. Gratch'}]"
2508,da58d554b6f7cc1bbe2e081d7d050733c79a90f8,Minds Made for Sharing: Initiating Joint Attention Recruits Reward-related Neurocircuitry,"Abstract The ability and motivation to share attention is a unique aspect of human cognition. Despite its significance, the neural basis remains elusive. To investigate the neural correlates of joint attention, we developed a novel, interactive research paradigm in which participants' gaze behavior—as measured by an eye tracking device—was used to contingently control the gaze of a computer-animated character. Instructed that the character on screen was controlled by a real person outside the scanner, 21 participants interacted with the virtual other while undergoing fMRI. Experimental variations focused on leading versus following the gaze of the character when fixating one of three objects also shown on the screen. In concordance with our hypotheses, results demonstrate, firstly, that following someone else's gaze to engage in joint attention resulted in activation of anterior portion of medial prefrontal cortex (MPFC) known to be involved in the supramodal coordination of perceptual and cognitive processes. Secondly, directing someone else's gaze toward an object activated the ventral striatum which—in light of ratings obtained from participants—appears to underlie the hedonic aspects of sharing attention. The data, therefore, support the idea that other-initiated joint attention relies upon recruitment of MPFC previously related to the “meeting of minds.” In contrast, self-initiated joint attention leads to a differential increase of neural activity in reward-related brain areas, which might contribute to the uniquely human motivation to engage in the sharing of experiences.",2010.0,58.0,372.0,False,,"{'volume': '22', 'pages': '2702-2715', 'name': 'Journal of Cognitive Neuroscience'}","{'bibtex': '@Article{Schilbach2010MindsMF,\n author = {L. Schilbach and M. Wilms and S. Eickhoff and S. Romanzetti and R. Tepest and G. Bente and N. Shah and G. Fink and K. Vogeley},\n journal = {Journal of Cognitive Neuroscience},\n pages = {2702-2715},\n title = {Minds Made for Sharing: Initiating Joint Attention Recruits Reward-related Neurocircuitry},\n volume = {22},\n year = {2010}\n}\n'}","[{'authorId': '2127424', 'name': 'L. Schilbach'}, {'authorId': '2746496', 'name': 'M. Wilms'}, {'authorId': '1717616', 'name': 'S. Eickhoff'}, {'authorId': '2307453', 'name': 'S. Romanzetti'}, {'authorId': '1871335', 'name': 'R. Tepest'}, {'authorId': '2487649', 'name': 'G. Bente'}, {'authorId': '108357144', 'name': 'N. Shah'}, {'authorId': '38644159', 'name': 'G. Fink'}, {'authorId': '2051580', 'name': 'K. Vogeley'}]"
2509,da60301803b1511f94349c8f371c29e347d12866,Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition,"Conversational emotion recognition (CER) has attracted increasing interests in the natural language processing (NLP) community. Different from the vanilla emotion recognition, effective speaker-sensitive utterance representation is one major challenge for CER. In this paper, we exploit speaker identification (SI) as an auxiliary task to enhance the utterance representation in conversations. By this method, we can learn better speaker-aware contextual representations from the additional SI corpus. Experiments on two benchmark datasets demonstrate that the proposed architecture is highly effective for CER, obtaining new state-of-the-art results on two datasets.",2020.0,26.0,19.0,False,,"{'volume': 'abs/2003.01478', 'name': 'ArXiv'}","{'bibtex': '@Article{Li2020MultiTaskLW,\n author = {Jingye Li and Meishan Zhang and Donghong Ji and Yijiang Liu},\n journal = {ArXiv},\n title = {Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition},\n volume = {abs/2003.01478},\n year = {2020}\n}\n'}","[{'authorId': '2000217741', 'name': 'Jingye Li'}, {'authorId': '2678094', 'name': 'Meishan Zhang'}, {'authorId': '145628086', 'name': 'Donghong Ji'}, {'authorId': '47909394', 'name': 'Yijiang Liu'}]"
2510,da9b342b1c7a72d2f404128d87d8ab72a74d899a,The Role of Movement in Face Recognition,"The movement of the face may provide information that facilitates recognition. However, in mostsituations people who are very familiar to us can be recognized easily from a single typical view of the face and the presence of further information derived from movement would not be expected to improve performance. Here the effects of movement on face recognition are investigated for faces presented under non-optimal conditions. Subjects were required to identify moving or still videotaped faces of famous and unknown people. Faces were presented in negative, a manipulation which preserved the two-dimensional shape and configuration of the face and facial features, while degrading face recognition performance. Results indicated that moving faces were significantly better recognized than still faces. It was proposed that movement may provide evidence about the three-dimensional structure of the face and allow the recognition of characteristic facial gestures. When the faces were inverted, no significant effect ...",1997.0,17.0,252.0,False,,"{'volume': '4', 'pages': '265-273', 'name': 'Visual Cognition'}","{'bibtex': '@Article{Knight1997TheRO,\n author = {B. Knight and A. Johnston},\n journal = {Visual Cognition},\n pages = {265-273},\n title = {The Role of Movement in Face Recognition},\n volume = {4},\n year = {1997}\n}\n'}","[{'authorId': '1576036019', 'name': 'B. Knight'}, {'authorId': '41211372', 'name': 'A. Johnston'}]"
2512,dab735dc0c0023cdc28715ab20257970e966bb46,“I can feel it too!”: Emergent empathic reactions between synthetic characters,"Empathy is often seen as the capacity to perceive, understand and experience others' emotions. This concept has been incorporated in virtual agents to achieve better believability, social interaction and user engagement. However, this has been mostly done to achieve empathic relations with the users. Instead, in this article we focus on empathy between synthetic characters and propose an analytical approach that consists in a generic computational model of empathy, supported by recent neuropsychological studies. The proposed model of empathy was implemented into an affective agent architecture. To evaluate the implementation a small scenario was defined and we asked a group of users to visualize it with the empathy model and another group to visualize it without the model. The results obtained confirmed that our model was capable of producing significant effects in the perception of the emergent empathic responses.",2009.0,17.0,50.0,False,,"{'pages': '1-7', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Rodrigues2009ICF,\n author = {Sérgio Hortas Rodrigues and S. Mascarenhas and João Dias and Ana Paiva},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-7},\n title = {“I can feel it too!”: Emergent empathic reactions between synthetic characters},\n year = {2009}\n}\n'}","[{'authorId': '2997654', 'name': 'Sérgio Hortas Rodrigues'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
2513,dad5698954e962c010aaa837049aa4a771e78e92,Validation of Enhanced Emotion Enabled Cognitive Agent Using Virtual Overlay Multi-Agent System Approach,"Making roads safer by avoiding road collisions is one of the main reasons for inventing Autonomous vehicles (AVs). In this context, designing agent-based collision avoidance components of AVs which truly represent human cognition and emotions look is a more feasible approach as agents can replace human drivers. However, to the best of our knowledge, very few human emotion and cognition-inspired agent-based studies have previously been conducted in this domain. Furthermore, these agent-based solutions have not been validated using any key validation technique. Keeping in view this lack of validation practices, we have selected state-of-the-art Emotion Enabled Cognitive Agent (EEC_Agent), which was proposed to avoid lateral collisions between semi-AVs. The architecture of EEC_Agent has been revised using Exploratory Agent Based Modeling (EABM) level of the Cognitive Agent Based Computing (CABC) framework and real-time fear emotion generation mechanism using the Ortony, Clore & Collins (OCC) model has also been introduced. Then the proposed fear generation mechanism has been validated using the Validated Agent Based Modeling level of CABC framework using a Virtual Overlay MultiAgent System (VOMAS). Extensive simulation and practical experiments demonstrate that the Enhanced EEC_Agent exhibits the capability to feel different levels of fear, according to different traffic situations and also needs a smaller Stopping Sight Distance (SSD) and Overtaking Sight Distance (OSD) as compared to human drivers.",2017.0,34.0,0.0,False,,"{'name': 'ArXiv', 'volume': 'abs/1708.01628'}","{'bibtex': '@Article{Riaz2017ValidationOE,\n author = {F. Riaz and M. Niazi},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Validation of Enhanced Emotion Enabled Cognitive Agent Using Virtual Overlay Multi-Agent System Approach},\n volume = {abs/1708.01628},\n year = {2017}\n}\n'}","[{'authorId': '40611071', 'name': 'F. Riaz'}, {'authorId': '1795560', 'name': 'M. Niazi'}]"
2514,dae5c4c765e34332d8de9ad122eab79acf3bdcbe,Sentiment Analysis: From Opinion Mining to Human-Agent Interaction,"The opinion mining and human-agent interaction communities are currently addressing sentiment analysis from different perspectives that comprise, on the one hand, disparate sentiment-related phenomena and computational representations, and on the other hand, different detection and dialog management methods. In this paper we identify and discuss the growing opportunities for cross-disciplinary work that may increase individual advances. Sentiment/opinion detection methods used in human-agent interaction are indeed rare and, when they are employed, they are not different from the ones used in opinion mining and consequently not designed for socio-affective interactions (timing constraint of the interaction, sentiment analysis as an input and an output of interaction strategies). To support our claims, we present a comparative state of the art which analyzes the sentiment-related phenomena and the sentiment detection methods used in both communities and makes an overview of the goals of socio-affective human-agent strategies. We propose then different possibilities for mutual benefit, specifying several research tracks and discussing the open questions and prospects. To show the feasibility of the general guidelines proposed we also approach them from a specific perspective by applying them to the case of the Greta embodied conversational agents platform and discuss the way they can be used to make a more significative sentiment analysis for human-agent interactions in two different use cases: job interviews and dialogs with museum visitors.",2016.0,212.0,131.0,False,,"{'volume': '7', 'pages': '74-93', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Clavel2016SentimentAF,\n author = {C. Clavel and Zoraida Callejas Carrión},\n journal = {IEEE Transactions on Affective Computing},\n pages = {74-93},\n title = {Sentiment Analysis: From Opinion Mining to Human-Agent Interaction},\n volume = {7},\n year = {2016}\n}\n'}","[{'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '3346603', 'name': 'Zoraida Callejas Carrión'}]"
2515,dae68fe1d3c27a8b112e5fee54f0e436ca126825,Evaluating Anthropomorphic Product Recommendation Agents: A Social Relationship Perspective to Designing Information Systems,"In online shopping environments, the product-advising function originally performed by salespeople is being increasingly taken over by software-based product recommendation agents (PRAs). However, the literature has mostly focused on the functionality design and utilitarian value of such decision support systems, mostly ignoring the potential social influence they could exert on their users. The objective of this study is to apply a social relationship perspective to the design of interfaces for PRAs. We investigate the effects of applying anthropomorphic interfaces—namely, humanoid embodiment and voice output—on users' perceived social relationship with a technological and software-based artifact designed for electronic commerce contexts. The findings from a laboratory experiment indicate that using humanoid embodiment and human voice-based communication significantly influences users' perceptions of social presence, which in turn enhances users' trusting beliefs, perceptions of enjoyment, and ultimately, their intentions to use the agent as a decision aid. These results extend the applicability of theories concerning traditional shopper-salesperson relationships to customers' interactions with technological artifacts residing on Web sites—that is, the recommendation agent software—and provide practitioners with guidelines on how to design Internet stores with the goal of building social relationships with online shoppers and enhancing their overall shopping experiences.",2009.0,136.0,500.0,False,,"{'volume': '25', 'pages': '145 - 182', 'name': 'Journal of Management Information Systems'}","{'bibtex': '@Article{Qiu2009EvaluatingAP,\n author = {Lingyun Qiu and I. Benbasat},\n journal = {Journal of Management Information Systems},\n pages = {145 - 182},\n title = {Evaluating Anthropomorphic Product Recommendation Agents: A Social Relationship Perspective to Designing Information Systems},\n volume = {25},\n year = {2009}\n}\n'}","[{'authorId': '1714338', 'name': 'Lingyun Qiu'}, {'authorId': '1732947', 'name': 'I. Benbasat'}]"
2517,daea41a951a68f5815b380291d64514cb266ebb2,Teaching Negotiation Skills through Practice and Reflection with Virtual Humans,"Although the representation of physical environments and behaviors will continue to play an important role in simulation-based training, an emerging challenge is the representation of virtual humans with rich mental models (e.g., including emotions, trust) that interact through conversational as well as physical behaviors. The motivation for such simulations is training soft skills such as leadership, cultural awareness, and negotiation, where the majority of actions are conversational, and the problem solving involves consideration of the emotions, attitudes, and desires of others.The educational power of such simulations can be enhanced by the integration of an intelligent tutoring system to support learners' understanding of the effect of their actions on virtual humans and how they might improve their performance. In this paper, we discuss our efforts to build such virtual humans, along with an accompanying intelligent tutor, for the domain of negotiation and cultural awareness.",2006.0,41.0,134.0,False,,"{'volume': '82', 'pages': '685 - 701', 'name': 'Simulation'}","{'bibtex': '@Article{Core2006TeachingNS,\n author = {Mark G. Core and D. Traum and H. Lane and W. Swartout and J. Gratch and M. Lent and S. Marsella},\n journal = {Simulation},\n pages = {685 - 701},\n title = {Teaching Negotiation Skills through Practice and Reflection with Virtual Humans},\n volume = {82},\n year = {2006}\n}\n'}","[{'authorId': '3122851', 'name': 'Mark G. Core'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '144445231', 'name': 'H. Lane'}, {'authorId': '1684040', 'name': 'W. Swartout'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '3153325', 'name': 'M. Lent'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
2518,db01283ce203a53914b833e65c8c608e17b3501e,The hybrid agent MARCO: a multimodal autonomous robotic chess opponent,"This paper introduces MARCO, a hybrid, chess playing agent equipped with a custom-built robotic arm and an emotionally expressive, virtual face presented on a small, servo-controlled display. MARCO was built to investigate the hypothesis that hybrid systems capable of displaying emotions make playing chess more personal and enjoyable. In addition, it is our aim to realize emotional contagion between man and machine in that the agent has the power to influence the human player on an emotional level and vice versa. The hardware components consist of eight Dynamixel servos, an Arduino-based control board, a 5.6 inch display, and a DGT chessboard. The software components run concurrently as separate processes. The main components are the virtual agent framework MARC, the WASABI Affect Simulation architecture, and the TSCP chess engine.",2014.0,8.0,8.0,False,,{'name': 'Proceedings of the second international conference on Human-agent interaction'},"{'bibtex': '@Article{Becker-Asano2014TheHA,\n author = {C. Becker-Asano and Eduardo A. L. Meneses and Nicolas Riesterer and J. Hué and C. Dornhege and B. Nebel},\n journal = {Proceedings of the second international conference on Human-agent interaction},\n title = {The hybrid agent MARCO: a multimodal autonomous robotic chess opponent},\n year = {2014}\n}\n'}","[{'authorId': '1403827243', 'name': 'C. Becker-Asano'}, {'authorId': '121893527', 'name': 'Eduardo A. L. Meneses'}, {'authorId': '2123331', 'name': 'Nicolas Riesterer'}, {'authorId': '2828438', 'name': 'J. Hué'}, {'authorId': '2573148', 'name': 'C. Dornhege'}, {'authorId': '145304209', 'name': 'B. Nebel'}]"
2519,db097eac96dd0ce5b7874f9ae74306fac5b0b2df,"Intention, Plans, and Practical Reason",1. Introduction 2. On the way to the planning theory 3. Plans and practical reasoning 4. Agent rationality: toward a general theory 5. Reconsideration and rationality 6. Agent rationality: the historical theory 7. Commitment revisited 8. Two faces of intention 9. Acting with an intention 10. Intention and expected side effects 11. Conclusion Bibliography Notes Index.,1991.0,3.0,2767.0,True,"{'url': 'http://external.dandelon.com/download/attachments/dandelon/ids/CH001DB72E0F0DD630A43C1257B9C00369D85.pdf', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mccann1991IntentionPA,\n author = {Hugh Mccann and M. Bratman},\n title = {Intention, Plans, and Practical Reason},\n year = {1991}\n}\n'}","[{'authorId': '49774672', 'name': 'Hugh Mccann'}, {'authorId': '70049329', 'name': 'M. Bratman'}]"
2520,db1cfc3f32baab36f3705d94656fb9e3882a6d12,Using video and static pictures to improve learning of procedural contents,,2009.0,45.0,186.0,False,,"{'volume': '25', 'pages': '354-359', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Arguel2009UsingVA,\n author = {A. Arguel and Eric Jamet},\n journal = {Comput. Hum. Behav.},\n pages = {354-359},\n title = {Using video and static pictures to improve learning of procedural contents},\n volume = {25},\n year = {2009}\n}\n'}","[{'authorId': '2896194', 'name': 'A. Arguel'}, {'authorId': '35123248', 'name': 'Eric Jamet'}]"
2521,db268406b2e4ea4064dd3bcb8a33b60d78c6231c,The Effects of Sensory Design on Autistic Children,"Autism is a lifelong handicap that affects their social skills, repetitive behaviors, speech, and nonverbal communication, as well as by unique strengths and differences. Knowing them as a unique person, designated learning environment should consider the sensory issues to overcome their needs. However, designers are lack of awareness in terms of sensory design during their design stage. The objective is to identify the sensory design of the classroom environment, while the paper aims to develop the Design Criteria Checklist of sensory design for Autism Centre. The result of the study highlighted factors that relate to the quality physical learning environment.Keywords: Autism; sensory design, physical learning environment; design criteria checklist;eISSN 2398-4295 © 2018. The Authors. Published for AMER ABRA cE-Bs by e-International Publishing House, Ltd., UK. This is an open-access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Peer–review under responsibility of AMER (Association of Malaysian Environment-Behaviour Researchers), ABRA (Association of Behavioural Researchers on Asians) and cE-Bs (Centre for Environment-Behaviour Studies), Faculty of Architecture, Planning & Surveying, Universiti Teknologi MARA, Malaysia.",2018.0,21.0,9.0,True,,{'name': 'Asian Journal of Behavioural Studies'},"{'bibtex': '@Article{Ghazali2018TheEO,\n author = {R. Ghazali and S. R. M. Sakip and Ismail Samsuddin},\n journal = {Asian Journal of Behavioural Studies},\n title = {The Effects of Sensory Design on Autistic Children},\n year = {2018}\n}\n'}","[{'authorId': '50383188', 'name': 'R. Ghazali'}, {'authorId': '98895091', 'name': 'S. R. M. Sakip'}, {'authorId': '98606292', 'name': 'Ismail Samsuddin'}]"
2522,db549199bf242797dfef3d8b3c8054e904eaacb9,A survey of trust in computer science and the Semantic Web,,2007.0,141.0,794.0,True,"{'url': 'http://isi.edu/~gil/papers/jws-trust-07.pdf', 'status': None}","{'volume': '5', 'pages': '58-71', 'name': 'J. Web Semant.'}","{'bibtex': '@Article{Artz2007ASO,\n author = {D. Artz and Y. Gil},\n journal = {J. Web Semant.},\n pages = {58-71},\n title = {A survey of trust in computer science and the Semantic Web},\n volume = {5},\n year = {2007}\n}\n'}","[{'authorId': '2679929', 'name': 'D. Artz'}, {'authorId': '145526918', 'name': 'Y. Gil'}]"
2523,db7663f19dc5ee7e8cb2c8894ebfe0dee0854a4f,Virtual Reality for Monitor and Control of Electrical Substations.,"This project presents the results obtained from a new strategy based on Virtual Reality techniques, which intends to minimize the operational issues caused in electric power substations due to the lack of spatial and functional information on the traditional operation interfaces. For this purpose, a three-dimensional interactive virtual reality environment was built in a realistic and accurate way regarding an energy supplier substation in Minas Gerais - Brazil and subsequently implanted it in its operation center for tasks related to its functioning. Lastly, tests were applied to operators to obtain results aiming at the contextualized problems.",2021.0,0.0,5.0,True,,"{'volume': '93 1', 'pages': '\n          e20200267\n        ', 'name': 'Anais da Academia Brasileira de Ciencias'}","{'bibtex': '@Article{Silva2021VirtualRF,\n author = {A. C. Silva and Alexandre Cardoso and E. A. Lamounier Júnior and C. L. B. Barreto Junior},\n journal = {Anais da Academia Brasileira de Ciencias},\n pages = {\n          e20200267\n        },\n title = {Virtual Reality for Monitor and Control of Electrical Substations.},\n volume = {93 1},\n year = {2021}\n}\n'}","[{'authorId': '153278538', 'name': 'A. C. Silva'}, {'authorId': '143975385', 'name': 'Alexandre Cardoso'}, {'authorId': '2061579455', 'name': 'E. A. Lamounier Júnior'}, {'authorId': '2061578563', 'name': 'C. L. B. Barreto Junior'}]"
2524,db7cdf9e058412d5f920362731a5d0dafb2b0b82,Emotion Recognition From EEG Signal Focusing on Deep Learning and Shallow Learning Techniques,"Recently, electroencephalogram-based emotion recognition has become crucial in enabling the Human-Computer Interaction (HCI) system to become more intelligent. Due to the outstanding applications of emotion recognition, e.g., person-based decision making, mind-machine interfacing, cognitive interaction, affect detection, feeling detection, etc., emotion recognition has become successful in attracting the recent hype of AI-empowered research. Therefore, numerous studies have been conducted driven by a range of approaches, which demand a systematic review of methodologies used for this task with their feature sets and techniques. It will facilitate the beginners as guidance towards composing an effective emotion recognition system. In this article, we have conducted a rigorous review on the state-of-the-art emotion recognition systems, published in recent literature, and summarized some of the common emotion recognition steps with relevant definitions, theories, and analyses to provide key knowledge to develop a proper framework. Moreover, studies included here were dichotomized based on two categories: i) deep learning-based, and ii) shallow machine learning-based emotion recognition systems. The reviewed systems were compared based on methods, classifier, the number of classified emotions, accuracy, and dataset used. An informative comparison, recent research trends, and some recommendations are also provided for future research directions.",2021.0,0.0,55.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9312710/09462089.pdf', 'status': None}","{'volume': '9', 'pages': '94601-94624', 'name': 'IEEE Access'}","{'bibtex': '@Article{Islam2021EmotionRF,\n author = {M. Islam and M. Moni and Md. Milon Islam and Md. Rashed-Al-Mahfuz and Md. Saiful Islam and Md. Kamrul Hasan and Md. Sabir Hossain and Mohiudding Ahmad and M. S. Uddin and A. Azad and S. Alyami and Md Atiqur Rahman Ahad and P. Lió},\n journal = {IEEE Access},\n pages = {94601-94624},\n title = {Emotion Recognition From EEG Signal Focusing on Deep Learning and Shallow Learning Techniques},\n volume = {9},\n year = {2021}\n}\n'}","[{'authorId': '2302197', 'name': 'M. Islam'}, {'authorId': '145781245', 'name': 'M. Moni'}, {'authorId': '2219047398', 'name': 'Md. Milon Islam'}, {'authorId': '1477941022', 'name': 'Md. Rashed-Al-Mahfuz'}, {'authorId': '2110073437', 'name': 'Md. Saiful Islam'}, {'authorId': '2152077719', 'name': 'Md. Kamrul Hasan'}, {'authorId': '2110865712', 'name': 'Md. Sabir Hossain'}, {'authorId': '2048446792', 'name': 'Mohiudding Ahmad'}, {'authorId': '143606369', 'name': 'M. S. Uddin'}, {'authorId': '2078286521', 'name': 'A. Azad'}, {'authorId': '3490101', 'name': 'S. Alyami'}, {'authorId': '2327468', 'name': 'Md Atiqur Rahman Ahad'}, {'authorId': '48988280', 'name': 'P. Lió'}]"
2525,db8c3cfaae04a14c1209d62953029b6fa53e23c7,Challenges in representation learning: A report on three machine learning contests,,2013.0,25.0,1235.0,True,"{'url': 'https://arxiv.org/pdf/1307.0414.pdf', 'status': None}","{'volume': '64', 'pages': '\n          59-63\n        ', 'name': 'Neural networks : the official journal of the International Neural Network Society'}","{'bibtex': '@Article{Goodfellow2013ChallengesIR,\n author = {I. Goodfellow and D. Erhan and P. Carrier and Aaron C. Courville and Mehdi Mirza and Benjamin Hamner and William J. Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee and Yingbo Zhou and Chetan Ramaiah and Fangxiang Feng and Ruifan Li and Xiaojie Wang and Dimitris Athanasakis and J. Shawe-Taylor and Maxim Milakov and John Park and Radu Tudor Ionescu and M. Popescu and C. Grozea and J. Bergstra and Jingjing Xie and Lukasz Romaszko and Bing Xu and Chuang Zhang and Yoshua Bengio},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          59-63\n        },\n title = {Challenges in representation learning: A report on three machine learning contests},\n volume = {64},\n year = {2013}\n}\n'}","[{'authorId': '153440022', 'name': 'I. Goodfellow'}, {'authorId': '1761978', 'name': 'D. Erhan'}, {'authorId': '153921980', 'name': 'P. Carrier'}, {'authorId': '1760871', 'name': 'Aaron C. Courville'}, {'authorId': '153583218', 'name': 'Mehdi Mirza'}, {'authorId': '3033919', 'name': 'Benjamin Hamner'}, {'authorId': '3155742', 'name': 'William J. Cukierski'}, {'authorId': '34312504', 'name': 'Yichuan Tang'}, {'authorId': '2060512985', 'name': 'David Thaler'}, {'authorId': '2115475379', 'name': 'Dong-Hyun Lee'}, {'authorId': '34872128', 'name': 'Yingbo Zhou'}, {'authorId': '1764124', 'name': 'Chetan Ramaiah'}, {'authorId': '39825530', 'name': 'Fangxiang Feng'}, {'authorId': '2462591', 'name': 'Ruifan Li'}, {'authorId': '38542466', 'name': 'Xiaojie Wang'}, {'authorId': '19998730', 'name': 'Dimitris Athanasakis'}, {'authorId': '1404459229', 'name': 'J. Shawe-Taylor'}, {'authorId': '2449832', 'name': 'Maxim Milakov'}, {'authorId': '2116009470', 'name': 'John Park'}, {'authorId': '1817759', 'name': 'Radu Tudor Ionescu'}, {'authorId': '49006356', 'name': 'M. Popescu'}, {'authorId': '2599036', 'name': 'C. Grozea'}, {'authorId': '32837403', 'name': 'J. Bergstra'}, {'authorId': '2208516000', 'name': 'Jingjing Xie'}, {'authorId': '1743912', 'name': 'Lukasz Romaszko'}, {'authorId': '2113742925', 'name': 'Bing Xu'}, {'authorId': '2118514062', 'name': 'Chuang Zhang'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]"
2526,db9a21ad723986536e514b1c0a5aaba6a5af9a58,Improving Spatial Reference in American Sign Language Animation through Data Collection from Native ASL Signers,,2009.0,24.0,13.0,True,,{'pages': '530-539'},"{'bibtex': '@Inproceedings{Huenerfauth2009ImprovingSR,\n author = {Matt Huenerfauth},\n pages = {530-539},\n title = {Improving Spatial Reference in American Sign Language Animation through Data Collection from Native ASL Signers},\n year = {2009}\n}\n'}","[{'authorId': '1747703', 'name': 'Matt Huenerfauth'}]"
2527,db9bd8f9032dd4ab418199f1c137236acdb0c30d,The relation of affectivity to intelligence in the mental development of the child.,,1962.0,0.0,86.0,False,,"{'volume': '26', 'pages': '\n          129-37\n        ', 'name': 'Bulletin of the Menninger Clinic'}","{'bibtex': '@Article{Piaget1962TheRO,\n author = {J. Piaget},\n journal = {Bulletin of the Menninger Clinic},\n pages = {\n          129-37\n        },\n title = {The relation of affectivity to intelligence in the mental development of the child.},\n volume = {26},\n year = {1962}\n}\n'}","[{'authorId': '48051692', 'name': 'J. Piaget'}]"
2528,dbf5da4c48966333cf999c9c480c150a8f37924a,Friendship: An old concept with a new meaning?,,2013.0,81.0,123.0,False,,"{'volume': '29', 'pages': '33-39', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Amichai-Hamburger2013FriendshipAO,\n author = {Yair Amichai-Hamburger and M. Kingsbury and B. Schneider},\n journal = {Comput. Hum. Behav.},\n pages = {33-39},\n title = {Friendship: An old concept with a new meaning?},\n volume = {29},\n year = {2013}\n}\n'}","[{'authorId': '1399064776', 'name': 'Yair Amichai-Hamburger'}, {'authorId': '2321676', 'name': 'M. Kingsbury'}, {'authorId': '34583723', 'name': 'B. Schneider'}]"
2529,dbfc85b44f3ed66e5a88520ca3ccde50cf931d96,The Gamification of Learning and Instruction: Game-Based Methods and Strategies for Training and Education,DriveGamification in Learning and EducationGamify Your ClassroomGamification of LearningThe Impact of the 4th Industrial Revolution on Engineering EducationThe Gamification of Learning in Virtual WorldsGamification in English Teaching and LearningGamification with MoodleGame Design for LearningActionable GamificationThe Gamification of Learning and Instruction FieldbookGame-Based Learning and the Power of PlayGamification MindsetGamification in Higher EducationGamification in Education: Breakthroughs in Research and PracticeThe Gamification of Learning and InstructionLernen mit Big DataAugmented Reality Games IIDas Design Thinking PlaybookGamify your LifePlay to LearnGamification of Learning and Teaching in SchoolsGamification in Education and BusinessData Analytics Approaches in Educational Games and Gamification SystemsDie Kunst des Game DesignsDie Wirkung von Gamification auf Motivation und LeistungLehrerdämmerungGamificationGamestor mingGamification for Interactive LearningHandbook of Research on Solving Modern Healthcare Challenges With GamificationBesser als die Wirklichkeit!MicrolearningTelekommunikation und FremdsprachenunterrichtTransforming Learning and,2012.0,9.0,1975.0,False,,"{'volume': '4', 'pages': '81-83', 'name': 'Int. J. Gaming Comput. Mediat. Simulations'}","{'bibtex': '@Article{Rice2012TheGO,\n author = {John W. Rice},\n journal = {Int. J. Gaming Comput. Mediat. Simulations},\n pages = {81-83},\n title = {The Gamification of Learning and Instruction: Game-Based Methods and Strategies for Training and Education},\n volume = {4},\n year = {2012}\n}\n'}","[{'authorId': '2067992847', 'name': 'John W. Rice'}]"
2530,dc0930139eeb93b25e03abbc04fa8d7b4127af9a,Spatial Note System Using Virtual Agent to Enhance Family Connection,"—The pace of life is becoming faster. As a result, some people are too busy to communicate with their families. In this paper, we propose an Augmented Reality (AR) system using smartphone. The system allows us to leave emotional notes in the real environment using Virtual-Agent. The crucial part of the system focuses on the emotional short voice message exchange with the Virtual-Agents. Spatial note system is based on two parts, one is the virtual agent services and the other is the AR system. The virtual agent services allow users to make a voice message by recording user’s voice. Then, a Virtual-Agent with the appropriate facial expression is generated. User can also change the facial expressions as he likes. There are 4 emotions of the virtual agents: happy, sorrow, angry and calm. Each emotion has 4 levels to express. The AR system will detect planes from the smartphone view of the real world. Users can put the Virtual- Agent anywhere on a plane.",2019.0,14.0,0.0,False,,,"{'bibtex': '@Inproceedings{Qu2019SpatialNS,\n author = {Puxuan Qu and J. Tanaka},\n title = {Spatial Note System Using Virtual Agent to Enhance Family Connection},\n year = {2019}\n}\n'}","[{'authorId': '2181745962', 'name': 'Puxuan Qu'}, {'authorId': '144705533', 'name': 'J. Tanaka'}]"
2531,dc40dbf8b27ea76ecf3b2284de4ce5748f782598,CASME II: An Improved Spontaneous Micro-Expression Database and the Baseline Evaluation,"A robust automatic micro-expression recognition system would have broad applications in national safety, police interrogation, and clinical diagnosis. Developing such a system requires high quality databases with sufficient training samples which are currently not available. We reviewed the previously developed micro-expression databases and built an improved one (CASME II), with higher temporal resolution (200 fps) and spatial resolution (about 280×340 pixels on facial area). We elicited participants' facial expressions in a well-controlled laboratory environment and proper illumination (such as removing light flickering). Among nearly 3000 facial movements, 247 micro-expressions were selected for the database with action units (AUs) and emotions labeled. For baseline evaluation, LBP-TOP and SVM were employed respectively for feature extraction and classifier with the leave-one-subject-out cross-validation method. The best performance is 63.41% for 5-class classification.",2014.0,28.0,589.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0086041&type=printable', 'status': None}","{'volume': '9', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Yan2014CASMEIA,\n author = {Wen-Jing Yan and Xiaobai Li and Su-Jing Wang and Guoying Zhao and Yong-Jin Liu and Yu-Hsin Chen and Xiaolan Fu},\n journal = {PLoS ONE},\n title = {CASME II: An Improved Spontaneous Micro-Expression Database and the Baseline Evaluation},\n volume = {9},\n year = {2014}\n}\n'}","[{'authorId': '9185305', 'name': 'Wen-Jing Yan'}, {'authorId': '1502872895', 'name': 'Xiaobai Li'}, {'authorId': '134769402', 'name': 'Su-Jing Wang'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}, {'authorId': '46398687', 'name': 'Yong-Jin Liu'}, {'authorId': '2115868127', 'name': 'Yu-Hsin Chen'}, {'authorId': '144054357', 'name': 'Xiaolan Fu'}]"
2532,dc6a5d898996f2c221752806aeab449c24c9b1b7,Emotion Regulation in Adulthood: Timing Is Everything,"Emotions seem to come and go as they please. However, we actually hold considerable sway over our emotions: We influence which emotions we have and how we experience and express these emotions. The process model of emotion regulation described here suggests that how we regulate our emotions matters. Regulatory strategies that act early in the emotion-generative process should have quite different outcomes than strategies that act later. This review focuses on two widely used strategies for down-regulating emotion. The first, reappraisal, comes early in the emotion-generative process. It consists of changing how we think about a situation in order to decrease its emotional impact. The second, suppression, comes later in the emotion-generative process. It involves inhibiting the outward signs of emotion. Theory and research suggest that reappraisal is more effective than suppression. Reappraisal decreases the experience and behavioral expression of emotion, and has no impact on memory. By contrast, suppression decreases behavioral expression, but fails to decrease the experience of emotion, and actually impairs memory. Suppression also increases physiological responding in both the suppressors and their social partners.",2001.0,20.0,1215.0,False,,"{'volume': '10', 'pages': '214 - 219', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Gross2001EmotionRI,\n author = {J. Gross},\n journal = {Current Directions in Psychological Science},\n pages = {214 - 219},\n title = {Emotion Regulation in Adulthood: Timing Is Everything},\n volume = {10},\n year = {2001}\n}\n'}","[{'authorId': '1775321', 'name': 'J. Gross'}]"
2535,dc786d29e27da3604335b04b51c42e9da92df2e0,Emotional Postures for the Humanoid-Robot Nao,,2013.0,36.0,61.0,True,"{'url': 'http://doc.rero.ch/record/315854/files/12369_2013_Article_200.pdf', 'status': None}","{'volume': '5', 'pages': '441-456', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Erden2013EmotionalPF,\n author = {M. S. Erden},\n journal = {International Journal of Social Robotics},\n pages = {441-456},\n title = {Emotional Postures for the Humanoid-Robot Nao},\n volume = {5},\n year = {2013}\n}\n'}","[{'authorId': '145968463', 'name': 'M. S. Erden'}]"
2536,dc80845b7af33701a332d21d4e0649e078e8ee45,Sex Differences in Empathy and Related Capacities,"In this article, the literature on sex differences in empathy (denned as vicarious affective responding to the emotional state of another) and related capacities (affective role taking and decoding of nonverbal cues) was reviewed. The literature was organized and discussed according to method used to assess empathy and affective role taking. Where appropriate, meta-analyses were also computed. In general, sex differences in empathy were a function of the methods used to assess empathy. There was a large sex difference favoring women when the measure of empathy was self-report scales; moderate differences (favoring females) were found for reflexive crying and self-report measures in laboratory situations; and no sex differences were evident when the measure of empathy was either physiological or unobtrusive observations of nonverbal reactions to another's emotional state. Moreover, few sex differences were found for children's affective role taking and decoding abilities. Several possible explanations for the pattern of findings are discussed. Among the characteristics that people attribute more frequently to females than to males is the tendency to empathize. This stereotypic perception has most likely been derived from the broader belief that females are more nurturant and interpersonally oriented than are males—a stereotype that itself is a natural consequence of traditional feminine and masculine roles. Sociological and psychological theorists concerned with social behavior generally have not questioned the veracity of sex-role stereotypes related to empathic reactions. In fact, their conceptualizations are entirely consistent with the notion that females are the more empathic sex. For example, sociologists such as Parsons and Bales (1955) have attributed differences in males' and females' behaviors to variations in the traditional roles of the two sexes. According to Parsons and Bales, in the family unit men typically assume an instrumental role; that is, they serve as a liaison between the family and society and see that the tasks needed for",1983.0,177.0,1251.0,False,,"{'volume': '94', 'pages': '100-131', 'name': 'Psychological Bulletin'}","{'bibtex': '@Article{Eisenberg1983SexDI,\n author = {N. Eisenberg and R. Lennon},\n journal = {Psychological Bulletin},\n pages = {100-131},\n title = {Sex Differences in Empathy and Related Capacities},\n volume = {94},\n year = {1983}\n}\n'}","[{'authorId': '15102546', 'name': 'N. Eisenberg'}, {'authorId': '116844146', 'name': 'R. Lennon'}]"
2537,dc9be0b89945f269fcbb0835dd7e366adbb4ef85,Cooperative Ramp Merging System: Agent-Based Modeling and Simulation Using Game Engine,"Author(s): Wang, Ziran; Wu, Guoyuan; Boriboonsomsin, Kanok; Barth, Matthew J; Han, Kyungtae; Kim, BaekGyu; Tiwari, Prashant",2019.0,33.0,39.0,True,"{'url': 'https://escholarship.org/content/qt7tk855qh/qt7tk855qh.pdf?t=q8s93m', 'status': None}",{'name': 'SAE International Journal of Connected and Automated Vehicles'},"{'bibtex': '@Article{Wang2019CooperativeRM,\n author = {Ziran Wang and Guoyuan Wu and K. Boriboonsomsin and M. Barth and Kyungtae Han and Baekgyu Kim and Prashant Tiwari},\n journal = {SAE International Journal of Connected and Automated Vehicles},\n title = {Cooperative Ramp Merging System: Agent-Based Modeling and Simulation Using Game Engine},\n year = {2019}\n}\n'}","[{'authorId': '4141749', 'name': 'Ziran Wang'}, {'authorId': '2222213', 'name': 'Guoyuan Wu'}, {'authorId': '2871648', 'name': 'K. Boriboonsomsin'}, {'authorId': '1773036', 'name': 'M. Barth'}, {'authorId': '152152987', 'name': 'Kyungtae Han'}, {'authorId': '1771227', 'name': 'Baekgyu Kim'}, {'authorId': '152688641', 'name': 'Prashant Tiwari'}]"
2538,dcac94878ae242b5e0379cac6e85fecb07cf314c,Working memory training in normal and pathological aging: neurocognitive gains and generalization.,"Working memory is one of the cognitive functions that is the most sensitive to normal and pathological age-related effects. In older individuals with a mild cognitive impairment, deficits in working memory are frequent and can precede those of episodic memory, in addition to having a strong prognostic value of evolution toward a dementia of Alzheimer type. Because of its implication in numerous cognitive and cognitive-motor tasks, working memory is called upon in a wide range of daily life activities. Impairment in working memory therefore increases the risk of a loss of autonomy. In the current review, we present different working memory training programs. We show how these training programs are associated with specific effects and to near and far transfers towards other cognitive functions in older adults without cognitive impairment or with mild cognitive impairment, as well as in patients with dementia. We show that the benefits are confirmed by neuronal modifications, suggesting an improvement in the neuronal efficiency of the targeted or related trained processes. Finally, we consider the central question of the generalization of the cognitive gains of working memory training toward ecological situations.",2020.0,0.0,1.0,False,,"{'volume': '18 2', 'pages': '\n          187-195\n        ', 'name': 'Geriatrie et psychologie neuropsychiatrie du vieillissement'}","{'bibtex': '@Article{Saba2020WorkingMT,\n author = {Marine Saba and S. Blanchet},\n journal = {Geriatrie et psychologie neuropsychiatrie du vieillissement},\n pages = {\n          187-195\n        },\n title = {Working memory training in normal and pathological aging: neurocognitive gains and generalization.},\n volume = {18 2},\n year = {2020}\n}\n'}","[{'authorId': '1753261158', 'name': 'Marine Saba'}, {'authorId': '39841320', 'name': 'S. Blanchet'}]"
2539,dcd036f4f3d7279d79014f89711af63232e1ca82,End-to-end joint learning of natural language understanding and dialogue manager,"Natural language understanding and dialogue policy learning are both essential in conversational systems that predict the next system actions in response to a current user utterance. Conventional approaches aggregate separate models of natural language understanding (NLU) and system action prediction (SAP) as a pipeline that is sensitive to noisy outputs of error-prone NLU. To address the issues, we propose an end-to-end deep recurrent neural network with limited contextual dialogue memory by jointly training NLU and SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our proposed model significantly outperforms the state-of-the-art pipeline models for both NLU and SAP, which indicates that our joint model is capable of mitigating the affects of noisy NLU outputs, and NLU model can be refined by error flows backpropagating from the extra supervised signals of system actions.",2016.0,31.0,77.0,True,"{'url': 'https://arxiv.org/pdf/1612.00913', 'status': None}","{'pages': '5690-5694', 'name': '2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","{'bibtex': '@Article{Yang2016EndtoendJL,\n author = {Xuesong Yang and Yun-Nung (Vivian) Chen and Dilek Z. Hakkani-Tür and Paul A. Crook and Xiujun Li and Jianfeng Gao and L. Deng},\n journal = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {5690-5694},\n title = {End-to-end joint learning of natural language understanding and dialogue manager},\n year = {2016}\n}\n'}","[{'authorId': '48520635', 'name': 'Xuesong Yang'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}, {'authorId': '1395813836', 'name': 'Dilek Z. Hakkani-Tür'}, {'authorId': '34963487', 'name': 'Paul A. Crook'}, {'authorId': '47058148', 'name': 'Xiujun Li'}, {'authorId': '1800422', 'name': 'Jianfeng Gao'}, {'authorId': '144718788', 'name': 'L. Deng'}]"
2540,dce799f4f4844828f78969ef0c53d1fbbc9bb370,When the Interface Is a Face,"People behave differently in the presence of other people than they do when they are alone. People also may behave differently when designers introduce more human-like qualities into computer interfaces. In an experimental study we demonstrate that people's responses to a talking-face interface differ from their responses to a text-display interface. They attribute some personality traits to it; they are more aroused by it; they present themselves in a more positive light. We use theories of person perception, social facilitation, and self-presentation to predict and interpret these results. We suggest that as computer interfaces become more ""human-like,"" people who use those interfaces may change their own personas in response to them.",1996.0,54.0,429.0,False,,"{'volume': '11', 'pages': '97-124', 'name': 'Hum. Comput. Interact.'}","{'bibtex': '@Article{Sproull1996WhenTI,\n author = {L. Sproull and M. Subramani and S. Kiesler and Janet H. Walker and Keith Waters},\n journal = {Hum. Comput. Interact.},\n pages = {97-124},\n title = {When the Interface Is a Face},\n volume = {11},\n year = {1996}\n}\n'}","[{'authorId': '2198165', 'name': 'L. Sproull'}, {'authorId': '2080666', 'name': 'M. Subramani'}, {'authorId': '47198673', 'name': 'S. Kiesler'}, {'authorId': '2110484995', 'name': 'Janet H. Walker'}, {'authorId': '150179849', 'name': 'Keith Waters'}]"
2542,dceca8cc8dacc1c4b5cb5be975eadb26e7a1f201,Top 10 Strategic Technology Trends for 2019,,2017.0,9.0,286.0,False,,,"{'bibtex': '@Inproceedings{Jones2017Top1S,\n author = {N. Jones and David Smith and B. Burke and Aruna Chandrasekaran and CK Lu},\n title = {Top 10 Strategic Technology Trends for 2019},\n year = {2017}\n}\n'}","[{'authorId': '48010995', 'name': 'N. Jones'}, {'authorId': '2153153076', 'name': 'David Smith'}, {'authorId': '2055592297', 'name': 'B. Burke'}, {'authorId': '144904419', 'name': 'Aruna Chandrasekaran'}, {'authorId': '2110027742', 'name': 'CK Lu'}]"
2543,dd0b947b7b6c8b88a20cc00cdb5aefb21cbba627,Building Virtual Humans with Back Stories: Training Interpersonal Communication Skills in Medical Students,,2014.0,13.0,21.0,False,,{'pages': '144-153'},"{'bibtex': '@Inproceedings{Cordar2014BuildingVH,\n author = {Andrew Cordar and M. Borish and A. Foster and Benjamin C. Lok},\n pages = {144-153},\n title = {Building Virtual Humans with Back Stories: Training Interpersonal Communication Skills in Medical Students},\n year = {2014}\n}\n'}","[{'authorId': '2127223', 'name': 'Andrew Cordar'}, {'authorId': '2281036', 'name': 'M. Borish'}, {'authorId': '46340075', 'name': 'A. Foster'}, {'authorId': '1708157', 'name': 'Benjamin C. Lok'}]"
2544,dd142a9b8cef8aefa7be73b2158bfb3867a60686,Design and Development of Diagnostic Chabot for supporting Primary Health Care Systems,,2020.0,11.0,20.0,True,,"{'volume': '167', 'pages': '75-84', 'name': 'Procedia Computer Science'}","{'bibtex': '@Article{Kidwai2020DesignAD,\n author = {Bushra Kidwai and R. Nadesh},\n journal = {Procedia Computer Science},\n pages = {75-84},\n title = {Design and Development of Diagnostic Chabot for supporting Primary Health Care Systems},\n volume = {167},\n year = {2020}\n}\n'}","[{'authorId': '80562459', 'name': 'Bushra Kidwai'}, {'authorId': '67341321', 'name': 'R. Nadesh'}]"
2545,dd22e6f27c71c1226e8c6b2d3379d140afe3ebc7,Attention and Orienting : Sensory and Motivational Processes,"Contents: R. Clifton, P. Berman, Preface. P.J. Long, R.F. Simons, M.T.Balaban, Part I:Current Investigations of the Classical Theory of Orienting and Defense. E. Sokolov, J. Cacioppo, Orienting and Defense Reflexes: Vector Coding the Cardiac Response. D. Siddle, O. Lipp, Orienting, Habituation and Information Processing: The Effects of Omission, the Role of Expectancy, and the Problem of Dishabituation. Part II:Biological and Evolutionary Foundations of Orienting, Startle, and Defense: Motivational and Emotional Factors That Modulate Attention. B. Campbell et al., Origins of Orienting and Defensive Responses: An Evolutionary Perspective. M. Davis, The Neurophysiological Basis of Acoustic Startle Modulation: Research on Fear Motivation and Sensory Gating. P. Lang, M. Bradley, B. Cutbert, Motivated Attention: Affect, Activation, and Action. E. Cook, G. Turpin, Differentiating Orienting, Startle, and Defense Responses: The Role of Affect and Its Implications for Psychopathology. A. Ohman, As Fast as the Blink of an Eye: Evolutionary Preparedness for Preattentive Processing of Threat. Part III:Startle Reflex and Electro-Cortical Studies of Attention and Stimulus Gating. H. Hoffman, Attentional Factors in the Elicitation and Modification of the Startle Reaction. S. Hackley, A.J.W. Boelhouwer, The More or Less Startling Effects of Weak Prestimulation -- Revisited: Prepulse Modulation of Multicomponent Blink Reflexes. R.F. Simons, W.M. Perlstein, A Tale of Two Reflexes: An ERP Analysis of Prepulse Inhibition and Orienting. M.E. Dawson, A.M. Schell, N.R. Swerdlow, D.L. Filion, Cognitive, Clinical and Neurophysiological Implications of Startle Modification. C.H.M. Brunia, Gating in Readiness. R. Naatanen, R. Ilmoniemi, K. Alho, Magnetoencephalography in Studies of Attention. Part IV:Studies of Attention, Affect, and Action in Child Development. M. Posner, M.K. Rothbart, G. Gerardi, L. Thomas-Thrapp, Functions of Orienting in Early Infancy. K. Berg, J. Richards, Attention Across Time in Infant Development. M.T. Balaban, N. Snidman, J. Kagan, Attention, Emotion, and Reactivity in Infancy and Early Childhood. J. Campos, R. Kermoian, D. Witherington, H. Chen, Q. Dong, Activity, Attention, and Developmental Transitions in Infancy. F.K. Graham, Afterword: Preattentive Processing and Passive and Active Attention.",1997.0,0.0,1027.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Lang1997AttentionAO,\n author = {P. Lang and R. Simons and M. Balaban},\n title = {Attention and Orienting : Sensory and Motivational Processes},\n year = {1997}\n}\n'}","[{'authorId': '143853826', 'name': 'P. Lang'}, {'authorId': '2567266', 'name': 'R. Simons'}, {'authorId': '39779943', 'name': 'M. Balaban'}]"
2546,dd287421a471025304bcbba1e92a5b55884f211f,"Handbook of attachment : theory, research, and clinical applications","Part 1. Overview of Attachment Theory. Cassidy, The Nature of the Child's Ties. Kobak, Madsen, Disruptions in Attachment Bonds: Implications for Theory, Research, and Clinical Intervention. Shaver, Fraley, Attachment, Loss, and Grief: Bowlby's Views and Current Controversies. Weinfield, Sroufe, Egeland, Carlson, Individual Differences in Infant-caregiver Attachment: Conceptual and Empirical Aspects of Security. Bretherton, Munholland, Internal Working Models in Attachment Relationships: Elaborating a Central Construct in Attachment Theory. Part 2. Biological Perspectives. Simpson, Belsky, Attachment Theory within a Modern Evolutionary Framework. Polan, Hofer, Psychobiological Origins of Infant Attachment and Its Role in Development. Suomi, Attachment in Rhesus Monkeys. Vaughn, Bost, van IJzendoorn, Attachment and Temperament: Additive and Interactive Influences on Behavior, Affect, and Cognition During Infancy and Childhood. Fox, Hane, Studying the Biology of Human Attachment. Coan, Toward a Neuroscience of Attachment. Part 3. Attachment in Infancy and Childhood. Marvin, Britner, Normative Development: The Ontogeny of Attachment. Belsky, Fearon, Precursors of Attachment Security. Howes, Spieker, Attachment Relationships in the Context of Multiple Caregivers. Berlin, Cassidy, Appleyard, The Influence of Early Attachments on Other Relationships. Thompson, Early Attachment and Later Development: Familiar Questions, New Answers. Kerns, Attachment in Middle Childhood. Solomon, George, The Measurement of Attachment Security in Infancy and Early Childhood. Part 4. Attachment in Adolescence and Adulthood. Allen, The Attachment System in Adolescence. Zeifman, Hazan, Pair Bonds as Attachments: Reevaluating the Evidence. Feeney, Adult Romantic Attachment: Developments in the Study of Couple Relationships. Mohr, Same-sex Romantic Attachment. Mikulincer, Shaver, Adult Attachment and Affect Regulation. Magai, Attachment in Middle and Later Life. Hesse, The Adult Attachment Interview: Protocol, Method of Analysis, and Empirical Studies. Crowell, Fraley, Shaver, Measurement of Individual Differences in Adolescent and Adult Attachment. Part 5. Psychopathology and Clinical Applications of Attachment Theory and Research. DeKlyen, Greenberg, Attachment and Psychopathology in Childhood. Lyons-Ruth, Jacobvitz, Attachment Disorganization: Genetic Factors, Parenting Contexts, and Developmental Transformation from Infancy to Adulthood. Dozier, Rutter, Challenges to the Development of Attachment Relationships Faced by Young Children in Foster and Adoptive Care. Dozier, Stovall-McClough, Albus, Attachment and Psychopathology in Adulthood. Berlin, Zeanah, Lieberman, Prevention and Intervention Programs for Supporting Early Attachment Security. Slade, The Implications of Attachment Theory and Research for Adult Psychotherapy: Research and Clinical Perspectives. Fonagy, Gergely, Target, Psychoanalytic Theory from the Viewpoint of Attachment Theory and Research. Johnson, Couple and Family Therapy: An Attachment Perspective. Part 6. Systems, Culture, and Context. George, Solomon, The Caregiving System: A Behavioral Systems Approach to Parenting. K. Grossmann, K. E. Grossmann, Kindler, Zimmermann, A Wider View of Attachment and Exploration: The Influence of Mothers and Fathers on the Development of Psychological Security from Infancy to Young Adulthood. van IJzendoorn, Sagi-Schwartz, Cross-Cultural Patterns of Attachment: Universal and Contextual Dimensions. Granqvist, Kirkpatrick, Attachment and Religious Representations and Behavior. Feeney, Monin, An Attachment-Theoretical Perspective on Divorce. Rutter, Implications of Attachment Theory and Research for Child Care Policy.",1999.0,0.0,2775.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cassidy1999HandbookOA,\n author = {J. Cassidy and P. Shaver},\n title = {Handbook of attachment : theory, research, and clinical applications},\n year = {1999}\n}\n'}","[{'authorId': '35669149', 'name': 'J. Cassidy'}, {'authorId': '4509891', 'name': 'P. Shaver'}]"
2547,dd6826e9520a6e72bcd24d1bdb930e78c1083b31,HapFACS 3.0: FACS-Based Facial Expression Generator for 3D Speaking Virtual Characters,"With the growing number of researchers interested in modeling the inner workings of affective social intelligence, the need for tools to easily model its associated expressions has emerged. The goal of this article is two-fold: 1) we describe HapFACS, a free software and API that we developed to provide the affective computing community with a resource that produces static and dynamic facial expressions for three-dimensional speaking characters; and 2) we discuss results of multiple experiments that we conducted in order to scientifically validate our facial expressions and head animations in terms of the widely accepted Facial Action Coding System (FACS) standard, and its Action Units (AU). The result is that users, without any 3D-modeling nor computer graphics expertise, can animate speaking virtual characters with FACS-based realistic facial expression animations, and embed these expressive characters in their own application(s). The HapFACS software and API can also be used for generating repertoires of realistic FACS-validated facial expressions, useful for testing emotion expression generation theories.",2015.0,69.0,25.0,True,,"{'volume': '6', 'pages': '348-360', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Amini2015HapFACS3F,\n author = {R. Amini and C. Lisetti and Guido Ruiz},\n journal = {IEEE Transactions on Affective Computing},\n pages = {348-360},\n title = {HapFACS 3.0: FACS-Based Facial Expression Generator for 3D Speaking Virtual Characters},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '1809087', 'name': 'R. Amini'}, {'authorId': '1779199', 'name': 'C. Lisetti'}, {'authorId': '2061491374', 'name': 'Guido Ruiz'}]"
2548,dd7a91f079b745032c363ccefaf87a58ce4a0602,Does Treatment Adherence Therapy reduce expense of healthcare use in patients with psychotic disorders? Cost-minimization analysis in a randomized controlled trial,,2011.0,25.0,11.0,False,,"{'volume': '133', 'pages': '47-53', 'name': 'Schizophrenia Research'}","{'bibtex': '@Article{Gilden2011DoesTA,\n author = {J. Gilden and A. Staring and M. Gaag and C. L. Mulder},\n journal = {Schizophrenia Research},\n pages = {47-53},\n title = {Does Treatment Adherence Therapy reduce expense of healthcare use in patients with psychotic disorders? Cost-minimization analysis in a randomized controlled trial},\n volume = {133},\n year = {2011}\n}\n'}","[{'authorId': '1481285389', 'name': 'J. Gilden'}, {'authorId': '5628900', 'name': 'A. Staring'}, {'authorId': '145958551', 'name': 'M. Gaag'}, {'authorId': '2251843505', 'name': 'C. L. Mulder'}]"
2549,ddbdde502c1f8260ed9758bf8462513143a7d8ba,Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial,"Background Web-based cognitive-behavioral therapeutic (CBT) apps have demonstrated efficacy but are characterized by poor adherence. Conversational agents may offer a convenient, engaging way of getting support at any time. Objective The objective of the study was to determine the feasibility, acceptability, and preliminary efficacy of a fully automated conversational agent to deliver a self-help program for college students who self-identify as having symptoms of anxiety and depression. Methods In an unblinded trial, 70 individuals age 18-28 years were recruited online from a university community social media site and were randomized to receive either 2 weeks (up to 20 sessions) of self-help content derived from CBT principles in a conversational format with a text-based conversational agent (Woebot) (n=34) or were directed to the National Institute of Mental Health ebook, “Depression in College Students,” as an information-only control group (n=36). All participants completed Web-based versions of the 9-item Patient Health Questionnaire (PHQ-9), the 7-item Generalized Anxiety Disorder scale (GAD-7), and the Positive and Negative Affect Scale at baseline and 2-3 weeks later (T2). Results Participants were on average 22.2 years old (SD 2.33), 67% female (47/70), mostly non-Hispanic (93%, 54/58), and Caucasian (79%, 46/58). Participants in the Woebot group engaged with the conversational agent an average of 12.14 (SD 2.23) times over the study period. No significant differences existed between the groups at baseline, and 83% (58/70) of participants provided data at T2 (17% attrition). Intent-to-treat univariate analysis of covariance revealed a significant group difference on depression such that those in the Woebot group significantly reduced their symptoms of depression over the study period as measured by the PHQ-9 (F=6.47; P=.01) while those in the information control group did not. In an analysis of completers, participants in both groups significantly reduced anxiety as measured by the GAD-7 (F1,54= 9.24; P=.004). Participants’ comments suggest that process factors were more influential on their acceptability of the program than content factors mirroring traditional therapy. Conclusions Conversational agents appear to be a feasible, engaging, and effective way to deliver CBT.",2017.0,35.0,1075.0,True,"{'url': 'https://mental.jmir.org/2017/2/e19/PDF', 'status': None}","{'volume': '4', 'name': 'JMIR Mental Health'}","{'bibtex': '@Article{Fitzpatrick2017DeliveringCB,\n author = {K. Fitzpatrick and Alison M Darcy and Molly Vierhile},\n journal = {JMIR Mental Health},\n title = {Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial},\n volume = {4},\n year = {2017}\n}\n'}","[{'authorId': '2194363', 'name': 'K. Fitzpatrick'}, {'authorId': '6120000', 'name': 'Alison M Darcy'}, {'authorId': '14061540', 'name': 'Molly Vierhile'}]"
2551,dddb97ae469f9f7319644cfae34f6b06a1006295,Experimental Psychology: A Manual of Laboratory Practice.,,1901.0,0.0,129.0,False,,"{'volume': '10', 'pages': '424', 'name': 'The Philosophical Review'}","{'bibtex': '@Article{Sanford1901ExperimentalPA,\n author = {Edmund C. Sanford and E. Titchener},\n journal = {The Philosophical Review},\n pages = {424},\n title = {Experimental Psychology: A Manual of Laboratory Practice.},\n volume = {10},\n year = {1901}\n}\n'}","[{'authorId': '2250960427', 'name': 'Edmund C. Sanford'}, {'authorId': '8300603', 'name': 'E. Titchener'}]"
2552,dde037402363fde92e5f61c3c1d7f25620e1ef3d,Learning Science in Immersive Virtual Reality,"The goals of the study were (a) to compare the instructional effectiveness of immersive virtual reality (VR) versus a desktop slideshow as media for teaching scientific knowledge, and (b) to examine the efficacy of adding a generative learning strategy to a VR lesson. In Experiment 1, college students viewed a biology lesson about how the human body works either in immersive VR or via a self-directed PowerPoint slideshow on a desktop computer. Based on interest theory, it was predicted that students who learned in immersive VR would report more positive ratings of interest and motivation and would score higher on a posttest covering material in the lesson. In contrast, based on the cognitive theory of multimedia learning, it was predicted that students who learned with a well-designed slideshow would score higher on a posttest, although they might not report higher levels of interest and motivation. The results showed that students who viewed the slideshow performed significantly better on the posttest than the VR group, but reported lower motivation, interest, and engagement ratings. In Experiment 2, students either viewed a segmented VR lesson and produced a written summary after each segment or viewed the original, continuous VR lesson as in Experiment 1. Students who summarized the lesson after each segment performed significantly better on the posttest and the groups did not differ on reported interest, engagement, and motivation. These results support the cognitive theory of multimedia learning and demonstrate the value of generative learning strategies in immersive VR environments.",2018.0,88.0,442.0,True,,"{'volume': '110', 'pages': '785–797', 'name': 'Journal of Educational Psychology'}","{'bibtex': '@Article{Parong2018LearningSI,\n author = {Jocelyn Parong and R. Mayer},\n journal = {Journal of Educational Psychology},\n pages = {785–797},\n title = {Learning Science in Immersive Virtual Reality},\n volume = {110},\n year = {2018}\n}\n'}","[{'authorId': '6214333', 'name': 'Jocelyn Parong'}, {'authorId': '1819200', 'name': 'R. Mayer'}]"
2553,ddfa31cb7e4056b579abbefce25493bf89e51e47,An empirically supported program to prevent suicide in a college student population.,"In the fall of 1984, the University of Illinois instituted a formal program to reduce the rate of suicide among its enrolled students. At the core of the program is a policy that requires any student who threatens or attempts suicide to attend four sessions of professional assessment. The consequences for failing to comply with the program include withdrawal from the university. In the 21 years that the program has been in effect, reports on 2,017 suicide incidents have been submitted to the Suicide Prevention Team. The rate of suicide at locations within Champaign County (where the university is located) have decreased from a rate of 6.91 per 100,000 enrolled students during the 8 years prior to the program's start to a rate of 3.78 during the first 21 years of the program. This represents a reduction of 45.3 percent. This reduction occurred against a backdrop of stable rates of suicide both nationally and among 11 peer institutions within the Big Ten. The implications for programs and policies at institutions of higher education are discussed.",2008.0,43.0,81.0,False,,"{'volume': '38 1', 'pages': '\n          87-103\n        ', 'name': 'Suicide & life-threatening behavior'}","{'bibtex': '@Article{Joffe2008AnES,\n author = {P. Joffe},\n journal = {Suicide & life-threatening behavior},\n pages = {\n          87-103\n        },\n title = {An empirically supported program to prevent suicide in a college student population.},\n volume = {38 1},\n year = {2008}\n}\n'}","[{'authorId': '48433513', 'name': 'P. Joffe'}]"
2554,de0ecb1302996ae70d2f6e3ef47b2a7282d6a0b0,A Feasibility Study with Image-Based Rendered Virtual Reality in Patients with Mild Cognitive Impairment and Dementia,"Virtual Reality (VR) has emerged as a promising tool in many domains of therapy and rehabilitation, and has recently attracted the attention of researchers and clinicians working with elderly people with MCI, Alzheimer’s disease and related disorders. Here we present a study testing the feasibility of using highly realistic image-based rendered VR with patients with MCI and dementia. We designed an attentional task to train selective and sustained attention, and we tested a VR and a paper version of this task in a single-session within-subjects design. Results showed that participants with MCI and dementia reported to be highly satisfied and interested in the task, and they reported high feelings of security, low discomfort, anxiety and fatigue. In addition, participants reported a preference for the VR condition compared to the paper condition, even if the task was more difficult. Interestingly, apathetic participants showed a preference for the VR condition stronger than that of non-apathetic participants. These findings suggest that VR-based training can be considered as an interesting tool to improve adherence to cognitive training in elderly people with cognitive impairment.",2016.0,54.0,154.0,True,"{'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0151487&type=printable', 'status': None}","{'volume': '11', 'name': 'PLoS ONE'}","{'bibtex': '@Article{Manera2016AFS,\n author = {V. Manera and E. Chapoulie and J. Bourgeois and R. Guerchouche and R. David and Jan Ondřej and G. Drettakis and P. Robert},\n journal = {PLoS ONE},\n title = {A Feasibility Study with Image-Based Rendered Virtual Reality in Patients with Mild Cognitive Impairment and Dementia},\n volume = {11},\n year = {2016}\n}\n'}","[{'authorId': '4192721', 'name': 'V. Manera'}, {'authorId': '2650457', 'name': 'E. Chapoulie'}, {'authorId': '50075632', 'name': 'J. Bourgeois'}, {'authorId': '1830025', 'name': 'R. Guerchouche'}, {'authorId': '145768419', 'name': 'R. David'}, {'authorId': '2050262', 'name': 'Jan Ondřej'}, {'authorId': '1721779', 'name': 'G. Drettakis'}, {'authorId': '2053591824', 'name': 'P. Robert'}]"
2555,de16f421b49e5110a1feffcddec2c9ac2f2106a6,"Is It What You Do, or When You Do It? The Roles of Contingency and Similarity in Pro-Social Effects of Imitation","Being imitated has a wide range of pro-social effects, but it is not clear how these effects are mediated. Naturalistic studies of the effects of being imitated have not established whether pro-social outcomes are due to the similarity and/or the contingency between the movements performed by the actor and those of the imitator. Similarity is often assumed to be the active ingredient, but we hypothesized that contingency might also be important, as it produces positive affect in infants and can be detected by phylogenetically ancient mechanisms of associative learning. We manipulated similarity and contingency between performed and observed actions in a computerized task. Similarity had no positive effects; however, contingency resulted in greater enjoyment of the task, reported closeness to others, and helping behavior. These results suggest that the pro-social effects of being imitated may rely on associative mechanisms.",2013.0,32.0,52.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/cogs.12071', 'status': None}","{'volume': '37 8', 'pages': '\n          1541-52\n        ', 'name': 'Cognitive science'}","{'bibtex': '@Article{Catmur2013IsIW,\n author = {C. Catmur and C. Heyes},\n journal = {Cognitive science},\n pages = {\n          1541-52\n        },\n title = {Is It What You Do, or When You Do It? The Roles of Contingency and Similarity in Pro-Social Effects of Imitation},\n volume = {37 8},\n year = {2013}\n}\n'}","[{'authorId': '2441222', 'name': 'C. Catmur'}, {'authorId': '31433567', 'name': 'C. Heyes'}]"
2556,de2997a2521a9564e55a42fd8352ab0a648adf5a,The Virtual Shop: A new immersive virtual reality environment and scenario for the assessment of everyday memory,,2018.0,92.0,72.0,True,,"{'volume': '303', 'pages': '126-135', 'name': 'Journal of Neuroscience Methods'}","{'bibtex': '@Article{Ouellet2018TheVS,\n author = {Émilie Ouellet and Benjamin Boller and N. Corriveau-Lecavalier and Simon Cloutier and S. Belleville},\n journal = {Journal of Neuroscience Methods},\n pages = {126-135},\n title = {The Virtual Shop: A new immersive virtual reality environment and scenario for the assessment of everyday memory},\n volume = {303},\n year = {2018}\n}\n'}","[{'authorId': '7427016', 'name': 'Émilie Ouellet'}, {'authorId': '40589979', 'name': 'Benjamin Boller'}, {'authorId': '1404469831', 'name': 'N. Corriveau-Lecavalier'}, {'authorId': '20817800', 'name': 'Simon Cloutier'}, {'authorId': '145580293', 'name': 'S. Belleville'}]"
2557,de3b1b52b98feb0510d826b3eb7b30116cddf6e2,Worry spreads: Interpersonal transfer of problem-related anxiety,"This paper distinguishes processes potentially contributing to interpersonal anxiety transfer, including object-directed social appraisal, empathic worry, and anxiety contagion, and reviews evidence for their operation. We argue that these anxiety-transfer processes may be exploited strategically when attempting to regulate relationship partners’ emotion. More generally, anxiety may serve as either a warning signal to other people about threat (alerting function) or an appeal for emotional support or practical help (comfort-seeking function). Tensions between these two interpersonal functions may account for mutually incongruent interpersonal responses to expressed anxiety, including mistargeted interpersonal regulation attempts. Because worry waxes and wanes over time as a function of other people's ongoing reactions, interpersonal interventions may help to alleviate some of its maladaptive consequences.",2012.0,80.0,87.0,True,"{'url': 'https://ora.ox.ac.uk/objects/uuid:0ca76759-829a-495f-8585-b2a0e104e084/download_file?safe_filename=worry%2Bspreads%2Bfinal%2Bsubmission.pdf&file_format=application%2Fpdf&type_of_work=Journal+article', 'status': None}","{'volume': '26', 'pages': '462 - 479', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Parkinson2012WorrySI,\n author = {B. Parkinson and G. Simons},\n journal = {Cognition and Emotion},\n pages = {462 - 479},\n title = {Worry spreads: Interpersonal transfer of problem-related anxiety},\n volume = {26},\n year = {2012}\n}\n'}","[{'authorId': '144603514', 'name': 'B. Parkinson'}, {'authorId': '48350755', 'name': 'G. Simons'}]"
2558,de421bf1b6ea1330b3a214cc20f3f2bb804669e8,Perspective: Narrative Storyliving in Virtual Reality Design,"The development and relative affordability of Virtual Reality in recent years have provided opportunities to experience representations of both concrete and abstract situations; from nuclear engineering to particle physics, art galleries to three-dimensional prehistoric paintings, person-to-person communication to artificial agent collaboration, and 360-degree journalism to animated movies. Yet, it still remains challenging for participants to create personal narratives within a virtual world beyond that structured by its original designers. Setting aside technological considerations, we attribute this limitation largely to a restricted conceptualization of time and space that is fixed to present events, emotions and experiences. Consequently, Virtual Reality scenarios, as immersive and plausible as they might be, are nonetheless prone to a thin and static view of the (virtual) world where growth and experiential learning are not always possible or privileged. In this Perspective we propose a recasting of Virtual Reality that combines novelistic storytelling in the physical world with “narrative storyliving” as a mechanism for meaning-making within and across large dialogic arenas. This involves us drawing on ideas from the Russian philosopher and theorist, Mikhail Bakhtin, relating to the literary artistic chronotope. Ultimately, we intend to advance the discourse about what Virtual Reality is at present, and where it could go as seen through a critical literary lens.",2022.0,36.0,8.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frvir.2022.779148/pdf', 'status': 'GOLD'}",{'volume': '3'},"{'bibtex': '@Article{Vallance2022PerspectiveNS,\n author = {M. Vallance and P. Towndrow},\n booktitle = {Frontiers in Virtual Reality},\n title = {Perspective: Narrative Storyliving in Virtual Reality Design},\n volume = {3},\n year = {2022}\n}\n'}","[{'authorId': '1849706', 'name': 'M. Vallance'}, {'authorId': '2097212', 'name': 'P. Towndrow'}]"
2559,de4b9bc12ddb6b9f6090c032ef5c6290bd64ef36,Artificial Intelligence,,2017.0,27.0,3299.0,True,,{'volume': '823'},"{'bibtex': '@Inproceedings{Verheij2017ArtificialI,\n author = {Bart Verheij and M. Wiering},\n title = {Artificial Intelligence},\n volume = {823},\n year = {2017}\n}\n'}","[{'authorId': '1697177', 'name': 'Bart Verheij'}, {'authorId': '32239759', 'name': 'M. Wiering'}]"
2560,de53ec6f806982a4940452428f9f6ea94a85ae68,Micro-Facial Movement Detection Using Individualised Baselines and Histogram-Based Descriptors,Detecting micro-facial movements in a video sequence is the first step in realising a system that can pick out rapid movements automatically as a person is being recorded. This paper proposes a new method of micro-movement detection by applying Histogram of Oriented Gradients as a feature descriptor on our in-house high-speed video dataset of spontaneous micro facial movements. Firstly the algorithm aligns and crops faces for each video using automatic facial point detection and affine transformation. Then a de-noising algorithm is applied to each video before splitting them into blocks where the Histogram of Oriented Gradient features are calculated for each frame in every video block. The Chi-Squared distance measure is then used to calculate dissimilarity in the spatial appearance between frames at a set interval. The final feature vector is calculated after normalisation of the raw distance values and peak detection is applied to 'spot' micro-facial movements. An individualised baseline threshold is used to determine the value a peak must exceed to be classed as a movement. The result is compared with a benchmark algorithm - feature difference analysis techniques for micro-facial movements using Local Binary Patterns. Results indicate the proposed method achieves higher Recall of 0.8429 and F1-measure of 0.7672.,2015.0,29.0,45.0,False,,"{'pages': '1864-1869', 'name': '2015 IEEE International Conference on Systems, Man, and Cybernetics'}","{'bibtex': '@Article{Davison2015MicroFacialMD,\n author = {A. K. Davison and Moi Hoon Yap and Cliff Lansley},\n journal = {2015 IEEE International Conference on Systems, Man, and Cybernetics},\n pages = {1864-1869},\n title = {Micro-Facial Movement Detection Using Individualised Baselines and Histogram-Based Descriptors},\n year = {2015}\n}\n'}","[{'authorId': '36059631', 'name': 'A. K. Davison'}, {'authorId': '3125772', 'name': 'Moi Hoon Yap'}, {'authorId': '1887380', 'name': 'Cliff Lansley'}]"
2561,de597d639ef2b887fa2a7002be5b6013b31f5a7b,What Are We Modeling When We Model Emotion?,"The past 15 years have witnessed a rapid growth in computational modeling of emotion and cognitiveaffective architectures. Architectures are being built both to elucidate mechanisms of emotions, and to enhance believability and effectiveness of synthetic agents and robots. Yet in spite of the many emotion models developed to date, there is a lack of consistency, and clarity, regarding what exactly it means to ‘model emotions’. The purpose of this paper is to attempt to deconstruct the vague term ‘emotion modeling’ by (1) suggesting that we view emotion models in terms of two fundamental categories of processes: emotion generation and emotion effects; and (2) identifying some of the fundamental computational tasks necessary to implement these processes. These ‘model building blocks’ can then provide a basis for the development of more systematic guidelines for the theoretical and data requirements, and the representational and reasoning alternatives, in emotion modeling. Identification of a set of generic computational tasks is also a good starting point for a systematic comparison of alternative approaches.",2008.0,50.0,43.0,False,,{'pages': '52-59'},"{'bibtex': '@Inproceedings{Hudlicka2008WhatAW,\n author = {E. Hudlicka},\n pages = {52-59},\n title = {What Are We Modeling When We Model Emotion?},\n year = {2008}\n}\n'}","[{'authorId': '2348728', 'name': 'E. Hudlicka'}]"
2562,de8c2dbcaddc299d4a7e7ad8482e964cea05f4b1,How Emotions Regulate Social Life,"The idea that emotions regulate social interaction is increasingly popular. But exactly how do emotions do this? To address this question, I draw on research on the interpersonal effects of emotions on behavior in personal relationships, parent–child interactions, conflict, negotiation, and leadership, and propose a new framework that can account for existing findings and guide future research: the emotions as social information (EASI) model. I demonstrate that emotional expressions affect observers' behavior by triggering inferential processes and/or affective reactions in them. The predictive strength of these two processes—which may inspire different behaviors—depends on the observer's information processing and on social-relational factors. Examples of moderators that determine the relative predictive strength of inferences and affective reactions include power, need for cognitive closure, time pressure, display rules, and the appropriateness and target of the emotional expression, which are all discussed.",2009.0,26.0,995.0,True,"{'url': 'https://pure.uva.nl/ws/files/1119982/75196_309689.pdf', 'status': None}","{'volume': '18', 'pages': '184 - 188', 'name': 'Current Directions in Psychological Science'}","{'bibtex': '@Article{Kleef2009HowER,\n author = {Gerben A. van Kleef},\n journal = {Current Directions in Psychological Science},\n pages = {184 - 188},\n title = {How Emotions Regulate Social Life},\n volume = {18},\n year = {2009}\n}\n'}","[{'authorId': '5980688', 'name': 'Gerben A. van Kleef'}]"
2563,dea8bb5933e5463569fcfc505b97f6de5899d73e,Emotion Recognition from EEG and Facial Expressions: a Multimodal Approach,"The understanding of a psychological phenomena such as emotion is of paramount importance for psychologists, since it allows to recognize a pathology and to prescribe a due treatment for a patient. While approaching this problem, mathematicians and computational science engineers have proposed different unimodal techniques for emotion recognition from voice, electroencephalography, facial expression, and physiological data. It is also well known that identifying emotions is a multimodal process. The main goal in this work is to train a computer to do so. In this paper we will present our first approach to a multimodal emotion recognition via data fusion of Electroencephalography and facial expressions. The selected strategy was a feature-level fusion of both Electroencephalography and facial microexpressions, and the classification schemes used were a neural network model and a random forest classifier. Experimental set up was out with the balanced multimodal database MAHNOB-HCI. Results are promising compared to results from other authors with a 97% of accuracy. The feature-level fusion approach used in this work improves our unimodal techniques up to 12% per emotion. Therefore, we may conclude that our simple but effective approach improves the overall results of accuracy.",2018.0,22.0,12.0,False,,"{'pages': '530-533', 'name': '2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)'}","{'bibtex': '@Article{Chaparro2018EmotionRF,\n author = {Valentina Chaparro and A. Gómez and Alejandro Salgado and O. Quintero and N. López and L. F. Villa},\n journal = {2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},\n pages = {530-533},\n title = {Emotion Recognition from EEG and Facial Expressions: a Multimodal Approach},\n year = {2018}\n}\n'}","[{'authorId': '2089434119', 'name': 'Valentina Chaparro'}, {'authorId': '20454483', 'name': 'A. Gómez'}, {'authorId': '2057264524', 'name': 'Alejandro Salgado'}, {'authorId': '145529510', 'name': 'O. Quintero'}, {'authorId': '2052445928', 'name': 'N. López'}, {'authorId': '34818810', 'name': 'L. F. Villa'}]"
2564,deaed631b1f6e3cf3e77f1d300d71afc176582a5,Touching Virtual Agents: Embodiment and Mind,,2013.0,115.0,20.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-642-55143-7_5.pdf', 'status': None}",{'pages': '114-138'},"{'bibtex': '@Inproceedings{Huisman2013TouchingVA,\n author = {Gijs Huisman and Merijn Bruijnes and Jan Kolkmeier and Merel M. Jung and A. D. Frederiks and Y. Rybarczyk},\n pages = {114-138},\n title = {Touching Virtual Agents: Embodiment and Mind},\n year = {2013}\n}\n'}","[{'authorId': '145248077', 'name': 'Gijs Huisman'}, {'authorId': '2312511', 'name': 'Merijn Bruijnes'}, {'authorId': '1847835', 'name': 'Jan Kolkmeier'}, {'authorId': '1715398', 'name': 'Merel M. Jung'}, {'authorId': '2607514', 'name': 'A. D. Frederiks'}, {'authorId': '2121632', 'name': 'Y. Rybarczyk'}]"
2565,dec4e18ea8e8a45c7d880ef5cca498b3312fc351,Emotional Mimicry in Social Context: The Case of Disgust and Pride,"A recent review on facial mimicry concludes that emotional mimicry is less ubiquitous than has been suggested, and only occurs in interactions that are potentially affiliative (see Hess and Fischer, in revision). We hypothesize that individuals do not mimic facial expressions that can be perceived as offensive, such as disgust, and mimic positive emotion displays, but only when the context is affiliative (i.e., with intimates). Second, we expect that in spontaneous interactions not mimicry, but empathic feelings with the other predict the accurateness of emotion recognition. Data were collected in a pseudo-experimental setting, during an event organized for subscribers of a large Dutch women’s magazine. One woman (expresser) was exposed to two emotional stimuli (i.e., a vile smell, a compliment) in order to evoke disgust and pride respectively. Another woman (observer: intimate or stranger) was sitting opposite of her. We collected self-report measures on emotions and empathy, and coded facial expressions of disgust and smiling on the basis of FACS. The results show that participants do not mimic disgust. In contrast, smiles displayed after the vile smell and the compliment were mimicked, but only among intimates. We also found that self-reported empathy and not mimicry is related to the recognition of disgust. These findings are discussed in the light of a Social Contextual view on emotional mimicry.",2012.0,70.0,66.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00475/pdf', 'status': None}","{'volume': '3', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Fischer2012EmotionalMI,\n author = {A. Fischer and D. Becker and Lotte Veenstra},\n journal = {Frontiers in Psychology},\n title = {Emotional Mimicry in Social Context: The Case of Disgust and Pride},\n volume = {3},\n year = {2012}\n}\n'}","[{'authorId': '7444483', 'name': 'A. Fischer'}, {'authorId': '36863432', 'name': 'D. Becker'}, {'authorId': '3814992', 'name': 'Lotte Veenstra'}]"
2566,ded3d7e3228ebe45ccf9c59ca80abd1cef801763,Emotion Recognition from Physiological Signal Analysis: A Review,,2019.0,82.0,228.0,True,,{'pages': '35-55'},"{'bibtex': '@Inproceedings{Egger2019EmotionRF,\n author = {Maria Egger and Matthias Ley and S. Hanke},\n pages = {35-55},\n title = {Emotion Recognition from Physiological Signal Analysis: A Review},\n year = {2019}\n}\n'}","[{'authorId': '152720029', 'name': 'Maria Egger'}, {'authorId': '119646778', 'name': 'Matthias Ley'}, {'authorId': '80148958', 'name': 'S. Hanke'}]"
2567,dee5aa18c760dfd98fd015e86d3d57c79d174380,Games and Rewards: A Scientometric Study of Rewards in Educational and Serious Games,"In this study we provide a new viewpoint on the body of literature regarding rewards in serious and educational games. The study includes a quantitative bibliometric analysis of literature in this context from 1969 to 2020. The dataset from the Scopus abstract and citation database was analyzed with the Bibliometrix R library. The data set was manually cleaned to contain only the relevant articles and conference papers. The data was then categorized to match the common themes. From the remaining documents, the amount of annual numbers of publications is presented and the most contributing countries are shown. The most frequent terms from the abstracts and keywords set by the authors are presented, and a co-occurrence network is drawn from the same data. The results of this study reveal that the most occurring topics in this dataset are gamification, physical activity, health, game design, and game-based learning. New directions for research are provided as the most commonly used media appear to be video games and mobile devices in addition to the literature being mostly focused on theory and not practical application.",2022.0,36.0,5.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9668973/09737096.pdf', 'status': None}","{'volume': '10', 'pages': '31578-31585', 'name': 'IEEE Access'}","{'bibtex': '@Article{Tyni2022GamesAR,\n author = {Janne Tyni and Anni Tarkiainen and Sonsoles López-Pernas and Mohammed Saqr and J. Kahila and R. Bednarik and M. Tedre},\n journal = {IEEE Access},\n pages = {31578-31585},\n title = {Games and Rewards: A Scientometric Study of Rewards in Educational and Serious Games},\n volume = {10},\n year = {2022}\n}\n'}","[{'authorId': '2159146549', 'name': 'Janne Tyni'}, {'authorId': '2159146047', 'name': 'Anni Tarkiainen'}, {'authorId': '1410416450', 'name': 'Sonsoles López-Pernas'}, {'authorId': '2114571876', 'name': 'Mohammed Saqr'}, {'authorId': '118866790', 'name': 'J. Kahila'}, {'authorId': '67221767', 'name': 'R. Bednarik'}, {'authorId': '144523037', 'name': 'M. Tedre'}]"
2568,deeb9aac2a4d82899e0eaabf19b17fa74c9999b9,"Movement, face processing and schizophrenia: evidence of a differential deficit in expression analysis.","Three dynamic face-processing tasks based on the Bruce & Young (1986) functional model of face processing were presented to 10 schizophrenic and 10 depressed inpatients and to 10 non-patient subjects. Familiar face recognition, facial expression recognition and unfamiliar face matching were examined. Schizophrenic patients' performance was significantly poorer than that of depressed patients and non-patient controls. Significantly lower scores were obtained on the facial expression recognition task than on the familiar face recognition task. There was a differential pattern of group performance on each of the three tasks: schizophrenic and depressed patients were as accurate as non-patient controls on the familiar face recognition task, but significantly less accurate than non-patient controls on the unfamiliar face-matching task. Schizophrenic patients were significantly less accurate than depressed patients and non-patient controls on the facial expression recognition task. The results are contrasted with an analogous static face-processing study.",1994.0,0.0,133.0,False,,"{'volume': '33 ( Pt 4)', 'pages': '\n          517-28\n        ', 'name': 'The British journal of clinical psychology'}","{'bibtex': '@Article{Archer1994MovementFP,\n author = {J. Archer and D. Hay and A. Young},\n journal = {The British journal of clinical psychology},\n pages = {\n          517-28\n        },\n title = {Movement, face processing and schizophrenia: evidence of a differential deficit in expression analysis.},\n volume = {33 ( Pt 4)},\n year = {1994}\n}\n'}","[{'authorId': '50309197', 'name': 'J. Archer'}, {'authorId': '47897735', 'name': 'D. Hay'}, {'authorId': '2087095606', 'name': 'A. Young'}]"
2569,df1ec1bfb66ffa141bca936e8dbf9226378c77d1,Synaptic modification by correlated activity: Hebb's postulate revisited.,"Correlated spiking of pre- and postsynaptic neurons can result in strengthening or weakening of synapses, depending on the temporal order of spiking. Recent findings indicate that there are narrow and cell type-specific temporal windows for such synaptic modification and that the generally accepted input- (or synapse-) specific rule for modification appears not to be strictly adhered to. Spike timing-dependent modifications, together with selective spread of synaptic changes, provide a set of cellular mechanisms that are likely to be important for the development and functioning of neural networks. When an axon of cell A is near enough to excite cell B or repeatedly or consistently takes part in firing it, some growth or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased.",2001.0,183.0,1442.0,False,,"{'volume': '24', 'pages': '\n          139-66\n        ', 'name': 'Annual review of neuroscience'}","{'bibtex': ""@Article{Bi2001SynapticMB,\n author = {G. Bi and M. Poo},\n journal = {Annual review of neuroscience},\n pages = {\n          139-66\n        },\n title = {Synaptic modification by correlated activity: Hebb's postulate revisited.},\n volume = {24},\n year = {2001}\n}\n""}","[{'authorId': '2711974', 'name': 'G. Bi'}, {'authorId': '1823913', 'name': 'M. Poo'}]"
2570,df2b0e26d0599ce3e70df8a9da02e51594e0e992,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",2019.0,63.0,64550.0,False,,{'pages': '4171-4186'},"{'bibtex': '@Inproceedings{Devlin2019BERTPO,\n author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n pages = {4171-4186},\n title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n year = {2019}\n}\n'}","[{'authorId': '39172707', 'name': 'Jacob Devlin'}, {'authorId': '1744179', 'name': 'Ming-Wei Chang'}, {'authorId': '2544107', 'name': 'Kenton Lee'}, {'authorId': '3259253', 'name': 'Kristina Toutanova'}]"
2571,df472adddf97793303d0d234442c0542a51f6d10,Education and the Attribution of Emotion to Facial Expressions,"Certain facial expressions have been proposed to be signals evolved to communicate a single specific emotion. Evidence to support this view is based primarily on university-educated Western adults. In the current study (N=96), university-educated and non-university-educated Americans were asked to label purported facial expressions of happiness, sadness, anger, fear, surprise, and disgust. Participants with no university education were significantly less likely to label the ""fear face"" as scared or the ""disgust face"" as disgusted, but more likely to label the ""anger face"" as angry and the ""sad face"" as sad. Education was also related to overall use of disgusted and angry – an effect that might help explain differences in labeling faces.",2013.0,33.0,20.0,False,,"{'volume': '22', 'pages': '237-247', 'name': 'Psychological topics'}","{'bibtex': '@Article{Trauffer2013EducationAT,\n author = {Nicole M. Trauffer and Sherri C Widen and J. Russell},\n journal = {Psychological topics},\n pages = {237-247},\n title = {Education and the Attribution of Emotion to Facial Expressions},\n volume = {22},\n year = {2013}\n}\n'}","[{'authorId': '31588501', 'name': 'Nicole M. Trauffer'}, {'authorId': '3947094', 'name': 'Sherri C Widen'}, {'authorId': '46367714', 'name': 'J. Russell'}]"
2572,df56e3bfd5cec28463bb0ddd3660f4a98ddf17a7,Disentangling audio content and emotion with adaptive instance normalization for expressive facial animation synthesis,"3D facial animation synthesis from audio has been a focus in recent years. However, most existing literature works are designed to map audio and visual content, providing limited knowledge regarding the relationship between emotion in audio and expressive facial animation. This work generates audio‐matching facial animations with the specified emotion label. In such a task, we argue that separating the content from audio is indispensable—the proposed model must learn to generate facial content from audio content while expressions from the specified emotion. We achieve it by an adaptive instance normalization module that isolates the content in the audio and combines the emotion embedding from the specified label. The joint content‐emotion embedding is then used to generate 3D facial vertices and texture maps. We compare our method with state‐of‐the‐art baselines, including the facial segmentation‐based and voice conversion‐based disentanglement approaches. We also conduct a user study to evaluate the performance of emotion conditioning. The results indicate that our proposed method outperforms the baselines in animation quality and expression categorization accuracy.",2022.0,30.0,5.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cav.2076', 'status': None}","{'volume': '33', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Chang2022DisentanglingAC,\n author = {Che-Jui Chang and Long Zhao and Sen Zhang and Mubbasir Kapadia},\n journal = {Computer Animation and Virtual Worlds},\n title = {Disentangling audio content and emotion with adaptive instance normalization for expressive facial animation synthesis},\n volume = {33},\n year = {2022}\n}\n'}","[{'authorId': '2152342254', 'name': 'Che-Jui Chang'}, {'authorId': '48096253', 'name': 'Long Zhao'}, {'authorId': '2175553614', 'name': 'Sen Zhang'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
2573,df5ad287f2ca8d2cb07071b0c5e28adef85216ff,Nonverbal Encouragement of Participation in a Course: the Effect of Touching,,2004.0,52.0,70.0,False,,"{'volume': '7', 'pages': '89-98', 'name': 'Social Psychology of Education'}","{'bibtex': '@Article{Guéguen2004NonverbalEO,\n author = {N. Guéguen},\n journal = {Social Psychology of Education},\n pages = {89-98},\n title = {Nonverbal Encouragement of Participation in a Course: the Effect of Touching},\n volume = {7},\n year = {2004}\n}\n'}","[{'authorId': '1892904', 'name': 'N. Guéguen'}]"
2574,df7715f0f07b876b7c33160b7485d89645f0f293,Motivational Representations within a Computational Cognitive Architecture,,2009.0,60.0,103.0,True,"{'url': 'http://www.cogsci.rpi.edu/~rsun/folder-files/sun-cogcomp2009.pdf', 'status': None}","{'volume': '1', 'pages': '91-103', 'name': 'Cognitive Computation'}","{'bibtex': '@Article{Sun2009MotivationalRW,\n author = {R. Sun},\n journal = {Cognitive Computation},\n pages = {91-103},\n title = {Motivational Representations within a Computational Cognitive Architecture},\n volume = {1},\n year = {2009}\n}\n'}","[{'authorId': '145966408', 'name': 'R. Sun'}]"
2575,df7f0093291a74d1f6a8cbe6bababa93ca636fb0,Modeling the internet of things: a hybrid modeling approach using complex networks and agent-based models,,2017.0,40.0,54.0,True,"{'url': 'https://casmodeling.springeropen.com/track/pdf/10.1186/s40294-017-0043-1', 'status': None}","{'volume': '5', 'pages': '1-19', 'name': 'Complex Adaptive Systems Modeling'}","{'bibtex': '@Article{Batool2017ModelingTI,\n author = {Komal Batool and M. Niazi},\n journal = {Complex Adaptive Systems Modeling},\n pages = {1-19},\n title = {Modeling the internet of things: a hybrid modeling approach using complex networks and agent-based models},\n volume = {5},\n year = {2017}\n}\n'}","[{'authorId': '4026257', 'name': 'Komal Batool'}, {'authorId': '1795560', 'name': 'M. Niazi'}]"
2576,df9128ffe2e246916060fb3a13d0f5796949b322,Lateral Pre-crash Sensing and Avoidance in Emotion Enabled Cognitive Agent based Vehicle-2-Vehicle Communication System,"A novel inter-vehicle communication system based on emotion enabled cognitive (EEC) agent has been anticipated as an intelligent solution to evade the road catastrophe due to hasty decisions by drivers. An input stimulus is processed in human brain using a short route and a long route during any emergency situation. The proposed EEC agent, mounted inside a vehicle, acts like a human brain and is stirred by short route information processing mechanism of human brain in fear condition. The results are acquired for the decisions made by the proposed approach through the EEC agent using short route and human drivers using long route during urgent situations. A pre crash sensing and avoidance algorithm has been proposed as well to mitigate the lateral or side by side collision using EEC agent.  Experimental findings reveal that by commencing emotions with cognition, and using formulated L-PCSA algorithm, lateral collisions chances can be sensed and avoided to secure the valued lives of passengers. It has been pragmatic that the new approach is very effectual and useful in shunning the lateral road collisions.",2013.0,36.0,12.0,True,"{'url': 'https://www.ijcnis.org/index.php/ijcnis/article/download/355/905', 'status': None}","{'volume': '5', 'name': 'Int. J. Commun. Networks Inf. Secur.'}","{'bibtex': '@Article{Riaz2013LateralPS,\n author = {F. Riaz and Syed Ismail Shah and Muhammad Raees and I. Shafi and Arslan Iqbal},\n journal = {Int. J. Commun. Networks Inf. Secur.},\n title = {Lateral Pre-crash Sensing and Avoidance in Emotion Enabled Cognitive Agent based Vehicle-2-Vehicle Communication System},\n volume = {5},\n year = {2013}\n}\n'}","[{'authorId': '40611071', 'name': 'F. Riaz'}, {'authorId': '1810492', 'name': 'Syed Ismail Shah'}, {'authorId': '145263477', 'name': 'Muhammad Raees'}, {'authorId': '1831811', 'name': 'I. Shafi'}, {'authorId': '2055756798', 'name': 'Arslan Iqbal'}]"
2577,dfa5139ddf3c367e3a8ee8fccff15737f182a1e1,Controllable models of gaze behavior for virtual agents and humanlike robots,"Embodied social agents, through their ability to afford embodied interaction using nonverbal human communicative cues, hold great promise in application areas such as education, training, rehabilitation, and collaborative work. Gaze cues are particularly important for achieving significant social and communicative goals. In this research, I explore how agents - both virtual agents and humanlike robots - might achieve such goals through the use of various gaze mechanisms. To this end, I am developing computational control models of gaze behavior that treat gaze as the output of a system with a number of multimodal inputs. These inputs can be characterized at different levels of interaction, from non-interactive (e.g., physical characteristics of the agent itself) to fully interactive (e.g., speech and gaze behavior of a human interlocutor). This research will result in a number of control models that each focus on a different gaze mechanism, combined into an open-source library of gaze behaviors that will be usable by both human-robot and human-virtual agent interaction designers. System-level evaluations in naturalistic settings will validate this gaze library for its ability to evoke positive social and cognitive responses in human users.",2013.0,14.0,1.0,False,,{'pages': '333-336'},"{'bibtex': '@Inproceedings{Andrist2013ControllableMO,\n author = {Sean Andrist},\n pages = {333-336},\n title = {Controllable models of gaze behavior for virtual agents and humanlike robots},\n year = {2013}\n}\n'}","[{'authorId': '2211183', 'name': 'Sean Andrist'}]"
2578,dfbc99264f55272937b6a3172086d7a48d791acb,LEARNING BY FEELING: EVOKING EMPATHY WITH SYNTHETIC CHARACTERS,"ABSTRACT Virtual environments (VEs) are now becoming a promising new technology to be used in the development of interactive learning environments for children. Perhaps triggered by the success of computer games, VEs are seen as an emergent and engaging new way by which children can learn experimental sciences and other disciplines. Inhabiting these IVEs can be agents or intelligent characters that are responsible for events that happen in the environment and make it not predictive or completely controlled. However, to build such environments, in particular, if populated by synthetic characters, one needs to carefully address the problem of how do the learners respond to the characters in the virtual environment. Do learners like the characters? Do learners identify themselves with characters in virtual environments? This relation between learners and characters in virtual environments can be studied in several perspectives. In this paper, we will focus primarily on the issue of empathy as one desirable aspect of the affective interaction between learners and synthetic characters. In particular, we will defend that in order for such affective relations to happen, characters should be created and designed taking into account what we call the proximity factor. This is based on the fact that children are found to respond more empathically to those that are perceived as similar to the self than those who are perceived as dissimilar (Barnett 1987). This appears to be the case when similarity is defined in terms of a shared characteristic, such as sex (Bryant 1982), race or in terms of shared personal experiences (Bryant 1982). Thus, designing characters aiming at pedagogical empathic interactions, we should carefully address how close the learner will feel with the synthetic characters developed in terms of situation, behavior or even physical appearance. In order to illustrate this factor in eliciting emotional reactions to synthetic characters, we will present a specific system called FearNot!. FearNot! was developed to address the difficult and often devastating problem of bullying in schools. By using role-playing and synthetic characters in a 3D environment, FearNot! allows children from age 8 to 12 to experience a virtual scenario where they can witness (in a third-person perspective) bullying situations. To build empathy into FearNot, we have considered the following components: agent's architecture, the characters' embodiment, the environment itself, and emotionally charged situations. All these elements were built to allow for a stronger proximity with the user and the system. In this paper, we will focus primarily on this problem and report some results achieved in the evaluation executed with 127 children and 95 adults on the system.",2005.0,33.0,190.0,True,"{'url': 'http://uhra.herts.ac.uk/bitstream/2299/6127/1/103265.pdf', 'status': None}","{'volume': '19', 'pages': '235 - 266', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Paiva2005LEARNINGBF,\n author = {Ana Paiva and João Dias and Daniel Sobral and R. Aylett and Sarah N. Woods and L. Hall and Carsten Zoll},\n journal = {Applied Artificial Intelligence},\n pages = {235 - 266},\n title = {LEARNING BY FEELING: EVOKING EMPATHY WITH SYNTHETIC CHARACTERS},\n volume = {19},\n year = {2005}\n}\n'}","[{'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '2151066261', 'name': 'João Dias'}, {'authorId': '2082297527', 'name': 'Daniel Sobral'}, {'authorId': '1732377', 'name': 'R. Aylett'}, {'authorId': '2773308', 'name': 'Sarah N. Woods'}, {'authorId': '144160845', 'name': 'L. Hall'}, {'authorId': '39752702', 'name': 'Carsten Zoll'}]"
2580,e0061f9010ca2b933067b58ce421870fee8afa76,Simulating the Emotion Dynamics of a Multimodal Conversational Agent,,2004.0,20.0,137.0,True,"{'url': 'https://pub.uni-bielefeld.de/download/1607115/2634978/MAX_ADS04_final.pdf', 'status': None}",{'pages': '154-165'},"{'bibtex': '@Inproceedings{Becker2004SimulatingTE,\n author = {Christian Becker and S. Kopp and I. Wachsmuth},\n pages = {154-165},\n title = {Simulating the Emotion Dynamics of a Multimodal Conversational Agent},\n year = {2004}\n}\n'}","[{'authorId': '2068695177', 'name': 'Christian Becker'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
2581,e006b12fd623900ea0db593c638c30e02178e30a,Use of immersive virtual reality to assess episodic memory: A validation study in older adults,"ABSTRACT Virtual reality (VR) allows for the creation of ecological environments that could be used for cognitive assessment and intervention. This study comprises two parts that describe and assess an immersive VR task, the Virtual Shop, which can be used to measure episodic memory. Part 1 addresses its applicability in healthy older adults by measuring presence, motivation, and cybersickness symptoms. Part 2 addresses its construct validity by investigating correlations between performance in the VR task and on a traditional experimental memory task, and by measuring whether the VR task is sensitive to age-related memory differences. Fifty-seven older and 20 younger adults were assessed in the Virtual Shop, in which they memorised and fetched 12 familiar items. Part 1 showed high levels of presence, higher levels of motivation for the VR than for the traditional task, and negligible cybersickness symptoms. Part 2 indicates that memory performance in the VR task is positively correlated with performance on a traditional memory task for both age groups, and age-related differences were found on the VR and traditional memory tasks. Thus, the use of VR is feasible in older adults and the Virtual Shop is a valid task to assess and train episodic memory in this population.",2018.0,53.0,66.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/09602011.2018.1477684?needAccess=true', 'status': None}","{'volume': '30', 'pages': '462 - 480', 'name': 'Neuropsychological Rehabilitation'}","{'bibtex': '@Article{Lecavalier2018UseOI,\n author = {Nick Corriveau Lecavalier and Émilie Ouellet and Benjamin Boller and S. Belleville},\n journal = {Neuropsychological Rehabilitation},\n pages = {462 - 480},\n title = {Use of immersive virtual reality to assess episodic memory: A validation study in older adults},\n volume = {30},\n year = {2018}\n}\n'}","[{'authorId': '48889585', 'name': 'Nick Corriveau Lecavalier'}, {'authorId': '7427016', 'name': 'Émilie Ouellet'}, {'authorId': '40589979', 'name': 'Benjamin Boller'}, {'authorId': '145580293', 'name': 'S. Belleville'}]"
2582,e009942441ac200f7950077d099de47d41d81e2b,Simulating dynamical features of escape panic,,2000.0,36.0,4374.0,True,"{'url': 'https://arxiv.org/pdf/cond-mat/0009448', 'status': None}","{'volume': '407', 'pages': '487-490', 'name': 'Nature'}","{'bibtex': '@Article{Helbing2000SimulatingDF,\n author = {D. Helbing and I. Farkas and T. Vicsek},\n journal = {Nature},\n pages = {487-490},\n title = {Simulating dynamical features of escape panic},\n volume = {407},\n year = {2000}\n}\n'}","[{'authorId': '1768825', 'name': 'D. Helbing'}, {'authorId': '34014051', 'name': 'I. Farkas'}, {'authorId': '1981267', 'name': 'T. Vicsek'}]"
2583,e029c5d0e0600917a5a98b0694d7645c011d77bd,Agents and Affect: Why Embodied Agents Need Affective Systems,,2004.0,23.0,17.0,False,,{'pages': '496-504'},"{'bibtex': '@Inproceedings{Aylett2004AgentsAA,\n author = {R. Aylett},\n pages = {496-504},\n title = {Agents and Affect: Why Embodied Agents Need Affective Systems},\n year = {2004}\n}\n'}","[{'authorId': '1732377', 'name': 'R. Aylett'}]"
2584,e03ea7759c460f2a4b98fc55b523e4d9d8cf307a,Analysis of the Relevance of Posts in Asynchronous Discussions,"This paper presents ForumMiner, a tool for the automatic analysis of students’ posts in asynchronous discussions. ForumMiner uses a text mining system to extract graphs from texts that are given to students as a basis for their discussion. These graphs contain the most relevant terms found in the texts, as well as the relationships between them. By comparing these graphs with the students’ writings, and using other information such as number and structure of posts, the tool is able to assess the relevance of each student’s contributions. A group of 18 teachers was consulted about the most important aspects to be considered in the analysis of posts, and the tool has been built according to these aspects. Results of an experiment involving the analysis of 682 posts showed that the average of the ratings given to these posts by teachers was very close to those provided by the automated tool. Such results demonstrate the tool’s potential to assist teachers in evaluating student participation in asynchronous discussions.",2014.0,30.0,9.0,True,,"{'volume': '10', 'pages': '107-121', 'name': 'Interdisciplinary Journal of e-Skills and Lifelong Learning'}","{'bibtex': '@Article{Azevedo2014AnalysisOT,\n author = {B. Azevedo and Eliseo Reategui and P. Behar},\n journal = {Interdisciplinary Journal of e-Skills and Lifelong Learning},\n pages = {107-121},\n title = {Analysis of the Relevance of Posts in Asynchronous Discussions},\n volume = {10},\n year = {2014}\n}\n'}","[{'authorId': '2075566614', 'name': 'B. Azevedo'}, {'authorId': '144571830', 'name': 'Eliseo Reategui'}, {'authorId': '21827212', 'name': 'P. Behar'}]"
2585,e042f9a2a3612cb4445995ee9376398d7a73f7aa,Expressions of Empathy in ECAs,,2008.0,18.0,46.0,False,,{'pages': '37-44'},"{'bibtex': '@Inproceedings{Niewiadomski2008ExpressionsOE,\n author = {Radoslaw Niewiadomski and M. Ochs and C. Pelachaud},\n pages = {37-44},\n title = {Expressions of Empathy in ECAs},\n year = {2008}\n}\n'}","[{'authorId': '1759118', 'name': 'Radoslaw Niewiadomski'}, {'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2587,e04ced4b298965293fba1f22b74bd3301aeb6540,MAINTAINING ENGAGEMENT IN LONG-TERM INTERVENTIONS WITH RELATIONAL AGENTS,"We discuss issues in designing virtual humans for applications that require long-term voluntary use and the problem of maintaining engagement with users over time. Concepts and theories related to engagement from a variety of disciplines are reviewed. We describe a platform for conducting studies into long-term interactions between humans and virtual agents and present the results of two longitudinal, randomized, controlled experiments in which the effect of manipulations of agent behavior on user engagement was assessed.",2010.0,29.0,205.0,True,"{'url': 'https://europepmc.org/articles/pmc3035950?pdf=render', 'status': None}","{'volume': '24', 'pages': '648 - 666', 'name': 'Applied Artificial Intelligence'}","{'bibtex': '@Article{Bickmore2010MAINTAININGEI,\n author = {T. Bickmore and Daniel Schulman and Langxuan Yin},\n journal = {Applied Artificial Intelligence},\n pages = {648 - 666},\n title = {MAINTAINING ENGAGEMENT IN LONG-TERM INTERVENTIONS WITH RELATIONAL AGENTS},\n volume = {24},\n year = {2010}\n}\n'}","[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '50247170', 'name': 'Daniel Schulman'}, {'authorId': '2721397', 'name': 'Langxuan Yin'}]"
2588,e0520b7b2344786811565dd0dd374e3c716736e0,Adaptation of users² spoken dialogue patterns in a conversational interface,"The design of robust new interfaces that process conversational speech is a challenging research direction largely because users’ spoken language is so variable, which is especially true of children. The present research explored whether children’s response latencies before initiating a conversational turn converge with those heard in the text-to-speech (TTS) of a computer partner. A study was conducted in which twenty-four 7-to-10-year-old children conversed with animated characters that responded with different types of TTS voices during an educational software application. Analyses confirmed that, while interacting with opposite TTS voices, children’s average response latencies adapted 18.4% in the direction of their computer partner’s speech. These adaptations were dynamic, bi-directional, and generalized across different types of users and TTS voices. The long-term goal of this research is the predictive modeling of human-computer communication patterns to guide the design of well synchronized, robust, and adaptive conversational interfaces.",2002.0,15.0,49.0,False,,{'pages': '561-564'},"{'bibtex': '@Inproceedings{Darves2002AdaptationOU,\n author = {Courtney Darves and S. Oviatt},\n pages = {561-564},\n title = {Adaptation of users² spoken dialogue patterns in a conversational interface},\n year = {2002}\n}\n'}","[{'authorId': '3035224', 'name': 'Courtney Darves'}, {'authorId': '2807460', 'name': 'S. Oviatt'}]"
2589,e06a4a5955d1a581a92a17ce5e00edf824e19786,Towards Sentiment and Emotion aided Intent Detection,"Intent detection is one of the crucial Natural Language Understanding(NLU) tasks studied extensively. Misclassification of intents impacts the overall performance of the conversational systems as natural language understanding is the first mean of interaction between a user and a virtual agent. The traditional approach of intent detection is limited only to textual features of user utterances and overlooks other semantic features. The sentiment and emotional state of the speaker are two such semantic features that have essential impacts on intent detection, as they implicitly express user intention conveyed through the user’s message. Depending on the context, these features can help the dialogue agent respond to the same intent with varying degrees of sentiment and emotion. Thus, investigating the role of sentiment and emotion on intent detection is a matter of great interest. The current work investigates the impact of utilizing sentiment and emotion information on intent detection tasks and proposes emotion and sentiment aided intent detection models. We also investigate the impact of sentiment and emotion using three different multitasking frameworks and present a joint model that utilizes the co-relation information across these tasks to correctly identify all these NLU aspects (intent, sentiment, and emotion). The obtained experimental results by the proposed models outperform several baselines and state-of-the-art intent detection models on multiple datasets by a significant margin of 1.8% - 3%, demonstrating the significant role of sentiment and emotion features in intent detection1.",2022.0,24.0,0.0,False,,"{'name': '2022 26th International Conference on Pattern Recognition (ICPR)', 'pages': '2510-2516'}","{'bibtex': '@Article{Trivedi2022TowardsSA,\n author = {Ashutosh Kumar Trivedi and A. Tiwari and S. Saha and Anutosh Maitra and Roshni Ramnani and Shubhashis Sengupta},\n booktitle = {International Conference on Pattern Recognition},\n journal = {2022 26th International Conference on Pattern Recognition (ICPR)},\n pages = {2510-2516},\n title = {Towards Sentiment and Emotion aided Intent Detection},\n year = {2022}\n}\n'}","[{'authorId': '2192841735', 'name': 'Ashutosh Kumar Trivedi'}, {'authorId': '2057810863', 'name': 'A. Tiwari'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '40585053', 'name': 'Anutosh Maitra'}, {'authorId': '3040439', 'name': 'Roshni Ramnani'}, {'authorId': '2062808558', 'name': 'Shubhashis Sengupta'}]"
2590,e07abf28587adb06e7044254b24196ce6cf0204e,Studies in the Way of Words.,"This volume, Grice's first hook, includes the long-delayed publication of his enormously influential 1967 William James Lectures. But there is much, much more in this work. Paul Grice himself has carefully arranged and framed the sequence of essays to emphasize not a certain set of ideas but a habit of mind, a style of philosophizing. Grice has, to be sure, provided philosophy with crucial ideas. His account of speaker-meaning is the standard that others use to define their own minor divergences or future elaborations. His discussion of conversational implicatures has given philosophers an important tool for the investigation of all sorts of problems; it has also laid the foundation for a great deal of work by other philosophers and linguists about presupposition. His metaphysical defense of absolute values is starting to be considered the beginning of a new phase in philosophy. This is a vital book for all who are interested in Anglo-American philosophy.",1989.0,0.0,3172.0,False,,"{'volume': '40', 'pages': '393', 'name': 'The Philosophical Quarterly'}","{'bibtex': '@Article{Burge1989StudiesIT,\n author = {T. Burge and P. Grice},\n journal = {The Philosophical Quarterly},\n pages = {393},\n title = {Studies in the Way of Words.},\n volume = {40},\n year = {1989}\n}\n'}","[{'authorId': '144377810', 'name': 'T. Burge'}, {'authorId': '113023839', 'name': 'P. Grice'}]"
2591,e07da3f8bed9911fd5d2a6909e41abfa42dbd77a,Affective Eye Contact: An Integrative Review,"In recent years, many studies have shown that perceiving other individuals’ direct gaze has robust effects on various attentional and cognitive processes. However, considerably less attention has been devoted to investigating the affective effects triggered by eye contact. This article reviews research concerning the effects of others’ gaze direction on observers’ affective responses. The review focuses on studies in which affective reactions have been investigated in well-controlled laboratory experiments, and in which contextual factors possibly influencing perceivers’ affects have been controlled. Two important themes emerged from this review. First, explicit affective evaluations of seeing another’s direct versus averted gaze have resulted in rather inconsistent findings; some studies report more positive subjective feelings to direct compared to averted gaze, whereas others report the opposite pattern. These contradictory findings may be related, for example, to differences between studies in terms of the capability of direct-gaze stimuli to elicit feelings of self-involvement. Second, studies relying on various implicit measures have reported more consistent results; they indicate that direct gaze increases affective arousal, and more importantly, that eye contact automatically evokes a positively valenced affective reaction. Based on the review, possible psychological mechanisms for the positive affective reactions elicited by eye contact are described.",2018.0,157.0,89.0,True,"{'url': 'https://fjfsdata01prod.blob.core.windows.net/articles/files/372871/pubmed-zip/.versions/1/.package-entries/fpsyg-09-01587/fpsyg-09-01587.pdf?sv=2018-03-28&sr=b&sig=OZNTjKlXmPK%2Bd2bYNa6LoWntJo4xaK%2BiIv5kTy1RdT8%3D&se=2021-02-18T19%3A13%3A02Z&sp=r&rscd=attachment%3B%20filename%2A%3DUTF-8%27%27fpsyg-09-01587.pdf', 'status': None}","{'volume': '9', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Hietanen2018AffectiveEC,\n author = {J. Hietanen},\n journal = {Frontiers in Psychology},\n title = {Affective Eye Contact: An Integrative Review},\n volume = {9},\n year = {2018}\n}\n'}","[{'authorId': '34601273', 'name': 'J. Hietanen'}]"
2592,e0867d523f610b32267fa7ec35a510936b8b595f,DISFA: A Spontaneous Facial Action Intensity Database,"Access to well-labeled recordings of facial expression is critical to progress in automated facial expression recognition. With few exceptions, publicly available databases are limited to posed facial behavior that can differ markedly in conformation, intensity, and timing from what occurs spontaneously. To meet the need for publicly available corpora of well-labeled video, we collected, ground-truthed, and prepared for distribution the Denver intensity of spontaneous facial action database. Twenty-seven young adults were video recorded by a stereo camera while they viewed video clips intended to elicit spontaneous emotion expression. Each video frame was manually coded for presence, absence, and intensity of facial action units according to the facial action unit coding system. Action units are the smallest visibly discriminable changes in facial action; they may occur individually and in combinations to comprise more molar facial expressions. To provide a baseline for use in future research, protocols and benchmarks for automated action unit intensity measurement are reported. Details are given for accessing the database for research in computer vision, machine learning, and affective and behavioral science.",2013.0,76.0,601.0,False,,"{'volume': '4', 'pages': '151-160', 'name': 'IEEE Transactions on Affective Computing'}","{'bibtex': '@Article{Mavadati2013DISFAAS,\n author = {S. Mavadati and M. Mahoor and Kevin Bartlett and Philip Trinh and J. Cohn},\n journal = {IEEE Transactions on Affective Computing},\n pages = {151-160},\n title = {DISFA: A Spontaneous Facial Action Intensity Database},\n volume = {4},\n year = {2013}\n}\n'}","[{'authorId': '3161007', 'name': 'S. Mavadati'}, {'authorId': '145531712', 'name': 'M. Mahoor'}, {'authorId': '2067587629', 'name': 'Kevin Bartlett'}, {'authorId': '2096029932', 'name': 'Philip Trinh'}, {'authorId': '1737918', 'name': 'J. Cohn'}]"
2593,e0a2df1cc4e06c6c337b24eba491dceafad8efe8,Dynamic Face Movement Texture Enhances the Perceived Realism of Facial Expressions of Emotion,"Most socially interactive virtual agents that generate facial expressions lack critical visual features such as expressive wrinkles, which could reduce their realistic appearance. Here, we examined the impact of dynamic facial texture on perceptions of realism of facial expressions of emotion and identified the emotion-specific features that enhance this perception. In a human perceptual judgment task, participants (20 white Westerners, 10 female) viewed pairs of facial expressions of the six classic emotions - happy, surprise, fear, disgust, anger and sad - with and without dynamic textures and selected the most realistic one from the pair. Analysis of participant choices showed that facial expressions with dynamic texture are perceived significantly more often as more realistic for all emotions except sad. Further analysis of the facial expression signals showed that emotion-specific features, such as darker forehead furrows in surprise, unilateral nose wrinkling in disgust, and shade variations around the cheeks in happy, enhanced perceptions of realism. Together, our results highlight the importance of equipping virtual agents with dynamic face movement texture to produce realistic facial expressions of emotion.",2020.0,18.0,4.0,False,,{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Chen2020DynamicFM,\n author = {Chaona Chen and Oliver G. B. Garrod and P. Schyns and Rachael E. Jack},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Dynamic Face Movement Texture Enhances the Perceived Realism of Facial Expressions of Emotion},\n year = {2020}\n}\n'}","[{'authorId': '6416348', 'name': 'Chaona Chen'}, {'authorId': '48522841', 'name': 'Oliver G. B. Garrod'}, {'authorId': '2287417', 'name': 'P. Schyns'}, {'authorId': '2143019', 'name': 'Rachael E. Jack'}]"
2594,e0b162440d1e166d7da93b276ba29866a24e1a1f,Unified Transformer Multi-task Learning for Intent Classification with Entity Recognition,"Intent classification (IC) and Named Entity Recognition (NER) are arguably the two main components needed to build a Natural Language Understanding (NLU) engine, which is a main component of conversational agents. The IC and NER components are closely intertwined and the entities are often connected to the underlying intent. Current research has primarily focused to model IC and NER as two separate units, which results in error propagation, and thus, sub-optimal performance. In this paper, we propose a simple yet effective novel framework for NLU where the parameters of the IC and the NER models are jointly trained in a consolidated parameter space. Text semantic representations are obtained from popular pre-trained contextual language models, which are fine-tuned for our task, and these parameters are propagated to other deep neural layers in our framework leading to a faithful unified modelling of the IC and NER parameters. The overall framework results in a faithful parameter sharing when the training is underway, leading to a more coherent learning. Experiments on two public datasets, ATIS and SNIPS, show that our model outperforms other methods by a noticeable margin. On the SNIPS dataset, we obtain a 1.42% improvement in NER in terms of the F1 score, and 1% improvement in intent accuracy score. On ATIS, we achieve 1.54% improvement in intent accuracy score. We also present qualitative results to showcase the effectiveness of our model.",2021.0,45.0,3.0,True,,"{'volume': 'PP', 'pages': '1-1', 'name': 'IEEE Access'}","{'bibtex': '@Article{Alamos2021UnifiedTM,\n author = {Alberto Jose Benayas Alamos and Reyhaneh Hashempour and D. Rumble and Shoaib Jameel and Renato Cordeiro de Amorim},\n journal = {IEEE Access},\n pages = {1-1},\n title = {Unified Transformer Multi-task Learning for Intent Classification with Entity Recognition},\n volume = {PP},\n year = {2021}\n}\n'}","[{'authorId': '146002215', 'name': 'Alberto Jose Benayas Alamos'}, {'authorId': '1738696028', 'name': 'Reyhaneh Hashempour'}, {'authorId': '102822559', 'name': 'D. Rumble'}, {'authorId': '38797620', 'name': 'Shoaib Jameel'}, {'authorId': '2028807', 'name': 'Renato Cordeiro de Amorim'}]"
2595,e0c4f40917cc632fba6a9e90165cc83f6a735f47,Automatic Nonverbal Behavior Generation from Image Schemas,"One of the main challenges when developing Embodied Conversational Agents is to give them the ability to autonomously produce meaningful and coordinated verbal and nonverbal behaviors. The relation between these means of communication is more complex than a direct mapping that has often been applied in previous models. In this paper, we propose an intermediate mapping approach we apply on metaphoric gestures first but that could be extended to other representational gestures. Leveraging from previous work in text analysis, embodied cognition and co-verbal behavior production, we introduce a framework articulating speech and metaphoric gesture invariants around a common mental representation: Image Schemas. We establish the components of our framework, detailing the different steps leading to the production of the metaphoric gestures, and we present some preliminary results and demonstrations. We end the paper by laying down the perspectives to integrate, evaluate and improve our model.",2018.0,35.0,17.0,False,,{'pages': '1667-1674'},"{'bibtex': '@Inproceedings{Ravenet2018AutomaticNB,\n author = {Brian Ravenet and C. Clavel and C. Pelachaud},\n pages = {1667-1674},\n title = {Automatic Nonverbal Behavior Generation from Image Schemas},\n year = {2018}\n}\n'}","[{'authorId': '1682486', 'name': 'Brian Ravenet'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2596,e0c6abdbdecf04ffac65c440da77fb9d66bb474c,XLNet: Generalized Autoregressive Pretraining for Language Understanding,"With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.",2019.0,47.0,6610.0,False,,{'pages': '5754-5764'},"{'bibtex': '@Inproceedings{Yang2019XLNetGA,\n author = {Zhilin Yang and Zihang Dai and Yiming Yang and J. Carbonell and R. Salakhutdinov and Quoc V. Le},\n pages = {5754-5764},\n title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},\n year = {2019}\n}\n'}","[{'authorId': '2109512754', 'name': 'Zhilin Yang'}, {'authorId': '3422912', 'name': 'Zihang Dai'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '143712374', 'name': 'J. Carbonell'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '2827616', 'name': 'Quoc V. Le'}]"
2597,e0ea20d239c8ae9c4af2ea295baa6a2442ac465d,The Modeling of Virtual Human Emotions Based on HowNet,"Virtual Human and its harmonious interaction technology is one of hot spots in the current information science and life science.Emotional Information Processing is an important field which has been always concerned by the artificial intelligence and cognitive science research.This paper introduces the modeling of the virtual human emotion based on HowNet.This model is a six-dimensional space which is composed of six basic emotions: calm,angry,joy,sorrow,relaxation,and anxiety.It is proved that the model can be good for human emotion simulation.",2008.0,0.0,3.0,False,,"{'volume': '', 'name': 'Techniques of Automation and Applications'}","{'bibtex': '@Article{Yi-xiang2008TheMO,\n author = {Chen Yi-xiang},\n journal = {Techniques of Automation and Applications},\n title = {The Modeling of Virtual Human Emotions Based on HowNet},\n year = {2008}\n}\n'}","[{'authorId': '2073432549', 'name': 'Chen Yi-xiang'}]"
2598,e0f9362543791a3fe9c745dc95f725caff0ea9a9,Virtual reality,"Although the terms cyberspace and virtual reality have been around for years, virtual reality as an industry is in its infancy. The term virtual reality is credited to Jaron Lanier, founder of VPL Research; earlier experimenters, like Myron Krueger in the mid-1970s, used phrases like artificial reality. William Gibson coined cyberspace in his 1984 science fiction novel. Neuromancer. Few technologies in recent years have evoked such fiery discussions in the technical community, and fewer still have sparked such passionate involvement of the humanities and the cultural sector. Maybe the humanities community reacts because the VR interaction is so tightly coupled to the human senses. Perhaps the cultural sector clamours for a role in the evolution of VR because the technology is finally interfacing with the human, rather than the human interfacing with the technology. Whatever the reasons, VR is more a convergence of previously disparate disciplines than a whole new branch of technology. It simply takes a fresh look at human interaction. Evolving from user interface design, flight and visual simulation, and telepresence technologies, VR is unique in its emphasis on the experience of the human participant. VR focuses the user's attention on the experience while suspending disbelief about the method of creating it. We feel that neither the devices used nor the level of interactiveness or fidelity determine whether a system is VR. The quality of the experience is crucial. To stimulate creativity and productivity. the virtual experience must be credible. The reality must both react to the human participants in physically and perceptually appropriate ways, and conform to their personal cognitive representations of the microworld in which they are engrossed. The experience does not necessarily have to be realistic/spl minus/just consistent.<<ETX>>",1994.0,9.0,1785.0,False,,"{'volume': '14', 'pages': '15-16', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Machover1994VirtualR,\n author = {C. Machover and S. Tice},\n journal = {IEEE Computer Graphics and Applications},\n pages = {15-16},\n title = {Virtual reality},\n volume = {14},\n year = {1994}\n}\n'}","[{'authorId': '3275930', 'name': 'C. Machover'}, {'authorId': '51349722', 'name': 'S. Tice'}]"
2599,e10d85e840ecb8e6ce992c6daf668d2629f40305,An Empathic Avatar in a Computer-Aided Learning Program to Encourage and Persuade Learners,"Animated pedagogical agents with characteristics such as facial expressions, gestures, and human emotions, under an interactive user interface are attractive to students and have high potential to promote students’ learning. This study proposes a convenient method to add an embodied empathic avatar into a computer-aided learning program; learners express their emotions by mouse-clicking while reading, and the avatar motivates them accordingly. This study designs empathic responses for avatars to encourage and persuade learners to make greater reading effort. This experiment examines emotional recognition, empathy transformation, and the effect of virtual human encouragement and persuasion. Subjects identify facial expressions of the avatar, especially those expressing positive facial emotions. Compared to the contrast group, the empathic avatar increases learners’ willingness to continue reading and complete exercises.",2012.0,22.0,49.0,False,,"{'volume': '15', 'pages': '62-72', 'name': 'J. Educ. Technol. Soc.'}","{'bibtex': '@Article{Chen2012AnEA,\n author = {Gwo-Dong Chen and Jih-Hsien Lee and Chin-Yeh Wang and Po-Yao Chao and Liang-Yi Li and Tzung-Yi Lee},\n journal = {J. Educ. Technol. Soc.},\n pages = {62-72},\n title = {An Empathic Avatar in a Computer-Aided Learning Program to Encourage and Persuade Learners},\n volume = {15},\n year = {2012}\n}\n'}","[{'authorId': '2108973704', 'name': 'Gwo-Dong Chen'}, {'authorId': '1840910', 'name': 'Jih-Hsien Lee'}, {'authorId': '2388316', 'name': 'Chin-Yeh Wang'}, {'authorId': '1776089', 'name': 'Po-Yao Chao'}, {'authorId': '2145728177', 'name': 'Liang-Yi Li'}, {'authorId': '2110713399', 'name': 'Tzung-Yi Lee'}]"
2600,e12ca95b83a30e3494f8892aa3766e599c3af203,Interactive robotic framework for multi-sensory therapy for children with autism spectrum disorder,"We present an interactive robotic framework that delivers emotional and social behaviors for multi-sensory therapy for children with autism spectrum disorders. Our framework includes emotion-based robotic gestures and facial expressions, as well as vision and audio-based monitoring system for quantitative measurement of the interaction. We also discuss the special aspects of interacting with children with autism with multi-sensory stimuli and the potentials of our approach for personalized therapies for social and behavioral learning.",2016.0,8.0,10.0,False,,"{'pages': '421-422', 'name': '2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Bevill2016InteractiveRF,\n author = {Rachael Bevill and C. Park and Hyung Jung Kim and Jongwon Lee and A. Rennie and M. Jeon and A. Howard},\n journal = {2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {421-422},\n title = {Interactive robotic framework for multi-sensory therapy for children with autism spectrum disorder},\n year = {2016}\n}\n'}","[{'authorId': '48312223', 'name': 'Rachael Bevill'}, {'authorId': '1695172', 'name': 'C. Park'}, {'authorId': '2109608503', 'name': 'Hyung Jung Kim'}, {'authorId': '2108391549', 'name': 'Jongwon Lee'}, {'authorId': '3389828', 'name': 'A. Rennie'}, {'authorId': '2572836', 'name': 'M. Jeon'}, {'authorId': '145065293', 'name': 'A. Howard'}]"
2601,e15cf50aa89fee8535703b9f9512fca5bfc43327,Going deeper with convolutions,"We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.",2014.0,264.0,37972.0,True,"{'url': 'https://arxiv.org/pdf/1409.4842', 'status': None}","{'pages': '1-9', 'name': '2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)'}","{'bibtex': '@Article{Szegedy2014GoingDW,\n author = {Christian Szegedy and Wei Liu and Yangqing Jia and P. Sermanet and Scott E. Reed and Dragomir Anguelov and D. Erhan and Vincent Vanhoucke and Andrew Rabinovich},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1-9},\n title = {Going deeper with convolutions},\n year = {2014}\n}\n'}","[{'authorId': '2574060', 'name': 'Christian Szegedy'}, {'authorId': '2157222093', 'name': 'Wei Liu'}, {'authorId': '39978391', 'name': 'Yangqing Jia'}, {'authorId': '3142556', 'name': 'P. Sermanet'}, {'authorId': '144828948', 'name': 'Scott E. Reed'}, {'authorId': '1838674', 'name': 'Dragomir Anguelov'}, {'authorId': '1761978', 'name': 'D. Erhan'}, {'authorId': '2657155', 'name': 'Vincent Vanhoucke'}, {'authorId': '39863668', 'name': 'Andrew Rabinovich'}]"
2602,e191ec44860ee25c8512cd3d678a2ba78a1205b6,The Handbook of Social Psychology. Gardner Lindzey,,1955.0,0.0,4.0,False,,,"{'bibtex': '@Inproceedings{Cohn1955TheHO,\n author = {T. S. Cohn},\n title = {The Handbook of Social Psychology. Gardner Lindzey},\n year = {1955}\n}\n'}","[{'authorId': '102649579', 'name': 'T. S. Cohn'}]"
2603,e2012e0d0578178de13244eb3efc33a3c8379f71,Micro-expression spotting: A new benchmark,,2020.0,49.0,31.0,True,,"{'volume': '443', 'pages': '356-368', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Tran2020MicroexpressionSA,\n author = {T. Tran and Q. Vo and Xiaopeng Hong and Xiaobai Li and Guoying Zhao},\n journal = {Neurocomputing},\n pages = {356-368},\n title = {Micro-expression spotting: A new benchmark},\n volume = {443},\n year = {2020}\n}\n'}","[{'authorId': '7917586', 'name': 'T. Tran'}, {'authorId': '12581289', 'name': 'Q. Vo'}, {'authorId': '46761465', 'name': 'Xiaopeng Hong'}, {'authorId': '1502872895', 'name': 'Xiaobai Li'}, {'authorId': '1757287', 'name': 'Guoying Zhao'}]"
2604,e205a5a6613421ee818e6b1b98aba4271dc5435d,Cognitive Bias Modification,"Research conducted within the general paradigm of cognitive bias modification (CBM) reveals that emotional biases in attention, interpretation, and memory are not merely associated with emotional disorders but contribute to them. After briefly describing research on both emotional biases and their modification, the authors examine similarities between CBM paradigms and older experimental paradigms used in research on learning and memory. The techniques and goals of CBM research are compared with other approaches to understanding cognition–emotion interactions. From a functional perspective, the CBM tradition reminds us to use experimental tools to evaluate assumptions about clinical phenomena and, more generally, about causal relationships between cognitive processing and emotion.",2011.0,119.0,262.0,False,,"{'volume': '6', 'pages': '521 - 536', 'name': 'Perspectives on Psychological Science'}","{'bibtex': '@Article{Hertel2011CognitiveBM,\n author = {P. Hertel and A. Mathews},\n journal = {Perspectives on Psychological Science},\n pages = {521 - 536},\n title = {Cognitive Bias Modification},\n volume = {6},\n year = {2011}\n}\n'}","[{'authorId': '37228832', 'name': 'P. Hertel'}, {'authorId': '1808296', 'name': 'A. Mathews'}]"
2605,e229fdc16fecc79e61d4b79b819a568ad989198e,Psychometric analysis of the empathy quotient (EQ) scale.,,2006.0,24.0,250.0,False,,"{'volume': '40', 'pages': '1111-1119', 'name': 'Personality and Individual Differences'}","{'bibtex': '@Article{Muncer2006PsychometricAO,\n author = {S. Muncer and J. Ling},\n journal = {Personality and Individual Differences},\n pages = {1111-1119},\n title = {Psychometric analysis of the empathy quotient (EQ) scale.},\n volume = {40},\n year = {2006}\n}\n'}","[{'authorId': '40614066', 'name': 'S. Muncer'}, {'authorId': '50602179', 'name': 'J. Ling'}]"
2606,e2586c490280a932e91cb67e589f97b69c610064,Approaching driver models which integrate models of emotion and risk,"This paper discusses driver models as components of driver assistance systems and driving simulations. The focus is on generating believable and consistent behavior of simulated drivers by using driver models which imitate emotional influence on the human driverpsilas decisions. The designed and implemented simulation intends to build a platform for learning algorithms which will later be used in adaptive driver assistance systems. This work adapts the cognitive appraisal model as described by Orthony, Clore and Collins ill for the imitation of human emotional reactions by integrating it with a model of risk. A system design is presented and discussed. Moreover, a simulation environment is presented and the integration of emotional drivers is shown. The application of the model to a specific driver assistance system is presented.",2008.0,20.0,12.0,False,,"{'pages': '234-239', 'name': '2008 IEEE Intelligent Vehicles Symposium'}","{'bibtex': '@Article{Reichardt2008ApproachingDM,\n author = {D. Reichardt},\n journal = {2008 IEEE Intelligent Vehicles Symposium},\n pages = {234-239},\n title = {Approaching driver models which integrate models of emotion and risk},\n year = {2008}\n}\n'}","[{'authorId': '145130350', 'name': 'D. Reichardt'}]"
2607,e279361ec12587d0a6f3d419671545f45d5fe09a,Modeling culture in intelligent virtual agents,,2016.0,59.0,28.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10458-015-9312-6.pdf', 'status': None}","{'volume': '30', 'pages': '931-962', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Mascarenhas2016ModelingCI,\n author = {S. Mascarenhas and N. Degens and Ana Paiva and R. Prada and G. Hofstede and A. Beulens and R. Aylett},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {931-962},\n title = {Modeling culture in intelligent virtual agents},\n volume = {30},\n year = {2016}\n}\n'}","[{'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '3175881', 'name': 'N. Degens'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '2584600', 'name': 'G. Hofstede'}, {'authorId': '153680364', 'name': 'A. Beulens'}, {'authorId': '1732377', 'name': 'R. Aylett'}]"
2608,e27e6f6d53c77b9dff0a986cd57d08558fad2e1f,Connecting minds and sharing emotions through mimicry: A neurocognitive model of emotional contagion,,2017.0,197.0,229.0,True,,"{'volume': '80', 'pages': '99-114', 'name': 'Neuroscience & Biobehavioral Reviews'}","{'bibtex': '@Article{Prochazkova2017ConnectingMA,\n author = {E. Prochazkova and M. Kret},\n journal = {Neuroscience & Biobehavioral Reviews},\n pages = {99-114},\n title = {Connecting minds and sharing emotions through mimicry: A neurocognitive model of emotional contagion},\n volume = {80},\n year = {2017}\n}\n'}","[{'authorId': '49239080', 'name': 'E. Prochazkova'}, {'authorId': '2512383', 'name': 'M. Kret'}]"
2609,e28be1d444d90c5fea1307a023bee1665d953296,Nonverbal Social Skills and Psychopathology,,2003.0,0.0,45.0,False,,"{'volume': '', 'pages': '17-44', 'name': ''}","{'bibtex': '@Inproceedings{Perez2003NonverbalSS,\n author = {John E. Perez and R. Riggio},\n pages = {17-44},\n title = {Nonverbal Social Skills and Psychopathology},\n year = {2003}\n}\n'}","[{'authorId': '15358519', 'name': 'John E. Perez'}, {'authorId': '39641777', 'name': 'R. Riggio'}]"
2610,e29f0b2ce34403f82f77d3373ac8f5152947df08,Altruism in Humans,Introduction Part I: A Theory of Altruistic Motivation 1. The Empathy-Altruism Hypothesis 2. Antecedents of Empathic Concern 3. Behavioral Consequences of Empathy-Induced Altruism Part II: Empirical Evidence 4. Turning to Experiments 5. Testing the Empathy-Altruism Hypothesis 6. Two Further Challenges to the Empathy-Altruism Hypothesis Part III: Altruism in Action 7. Benefits of Empathy-Induced Altruism 8. Liabilities 9. Toward a Pluralism of Prosocial Motives-and a More Humane Society Summary and Conclusion References,2011.0,0.0,921.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Batson2011AltruismIH,\n author = {C. Batson},\n title = {Altruism in Humans},\n year = {2011}\n}\n'}","[{'authorId': '32526876', 'name': 'C. Batson'}]"
2611,e2c21999756ef8e21cdd931b780ed1a80ca09a2d,Classification of Imbalanced Data: a Review,Classification of data with imbalanced class distribution has encountered a significant drawback of the performance attainable by most standard classifier learning algorithms which assume a relatively balanced class distribution and equal misclassification costs. This paper provides a review of the classification of imbalanced data regarding: the application domains; the nature of the problem; the learning difficulties with standard classifier learning algorithms; the learning objectives and evaluation measures; the reported research solutions; and the class imbalance problem in the presence of multiple classes.,2009.0,74.0,1293.0,False,,"{'volume': '23', 'pages': '687-719', 'name': 'Int. J. Pattern Recognit. Artif. Intell.'}","{'bibtex': '@Article{Sun2009ClassificationOI,\n author = {Yanmin Sun and A. Wong and M. Kamel},\n journal = {Int. J. Pattern Recognit. Artif. Intell.},\n pages = {687-719},\n title = {Classification of Imbalanced Data: a Review},\n volume = {23},\n year = {2009}\n}\n'}","[{'authorId': '3344564', 'name': 'Yanmin Sun'}, {'authorId': '144821969', 'name': 'A. Wong'}, {'authorId': '144851973', 'name': 'M. Kamel'}]"
2612,e2ef4bc659fd0d2badbc26b1fb543aab445955db,"Open Complex Intelligent Systems: Fundamentals, Concepts, Analysis, Design and Implementation",,2008.0,0.0,7.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cao2008OpenCI,\n author = {Longbing Cao and D. Ru-wei},\n title = {Open Complex Intelligent Systems: Fundamentals, Concepts, Analysis, Design and Implementation},\n year = {2008}\n}\n'}","[{'authorId': '2148761004', 'name': 'Longbing Cao'}, {'authorId': '3059035', 'name': 'D. Ru-wei'}]"
2613,e2f4635dd8b1fb0bc4736224f93df435114ae4c3,AVATAR: Implementation of a Human-Computer Interface Based on an Intelligent Virtual Agent,"For several years the use of Information and Communication Technologies (ICT) has been questioned as a reason to diminish the social interaction between people. Although, it is not possible to remove ICT from our lives as we depend on them in many aspects, we can adapt them so that their use allows us to improve our social skills. This is the case of the Human-Computer Interface (HCI) and, especially those that involve emotions in a communication with machines similar to human interaction between peers. In this article, the implementation of an HCI based on an intelligent virtual agent is presented, with the possibility of learning basic information about the interlocutor and maintaining a short interaction on topics of general interest. The implementation was made in open-source software, generating not only a tool, but a development platform for other people to make contributions. The virtual agent was evaluated through short sessions with university students, who, according to a survey conducted, showed their acceptance of the interaction process.",2019.0,28.0,2.0,False,,"{'name': '2019 IEEE Colombian Conference on Communications and Computing (COLCOM)', 'pages': '1-5'}","{'bibtex': '@Conference{Guerrero-Vásquez2019AVATARIO,\n author = {L. F. Guerrero-Vásquez and Paul A. Chasi-Pesántez and Renato Castro-Serrano and V. Robles-Bykbaev and J. Bravo-Torres and M. López-Nores},\n booktitle = {2019 IEEE Colombian Conference on Communications and Computing (COLCOM)},\n journal = {2019 IEEE Colombian Conference on Communications and Computing (COLCOM)},\n pages = {1-5},\n title = {AVATAR: Implementation of a Human-Computer Interface Based on an Intelligent Virtual Agent},\n year = {2019}\n}\n'}","[{'authorId': '1384430360', 'name': 'L. F. Guerrero-Vásquez'}, {'authorId': '1384430152', 'name': 'Paul A. Chasi-Pesántez'}, {'authorId': '1410642144', 'name': 'Renato Castro-Serrano'}, {'authorId': '1403953313', 'name': 'V. Robles-Bykbaev'}, {'authorId': '1398154358', 'name': 'J. Bravo-Torres'}, {'authorId': '1403802069', 'name': 'M. López-Nores'}]"
2614,e30662126c78d1fb7d70f576e04c7bec448f65b3,Combining Incremental Language Generation and Incremental Speech Synthesis for Adaptive Information Presentation,"Participants in a conversation are normally receptive to their surroundings and their interlocutors, even while they are speaking and can, if necessary, adapt their ongoing utterance. Typical dialogue systems are not receptive and cannot adapt while uttering. We present combinable components for incremental natural language generation and incremental speech synthesis and demonstrate the flexibility they can achieve with an example system that adapts to a listener's acoustic understanding problems by pausing, repeating and possibly rephrasing problematic parts of an utterance. In an evaluation, this system was rated as significantly more natural than two systems representing the current state of the art that either ignore the interrupting event or just pause; it also has a lower response time.",2012.0,24.0,56.0,False,,{'pages': '295-303'},"{'bibtex': '@Inproceedings{Buschmeier2012CombiningIL,\n author = {Hendrik Buschmeier and Timo Baumann and Benjamin Dosch and S. Kopp and David Schlangen},\n pages = {295-303},\n title = {Combining Incremental Language Generation and Incremental Speech Synthesis for Adaptive Information Presentation},\n year = {2012}\n}\n'}","[{'authorId': '2849488', 'name': 'Hendrik Buschmeier'}, {'authorId': '8800150', 'name': 'Timo Baumann'}, {'authorId': '3167440', 'name': 'Benjamin Dosch'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1817455', 'name': 'David Schlangen'}]"
2615,e336a7b10b5bc89b66bf7115bd90e30d2045bed9,Expressive Virtual Human: Impact of expressive wrinkles and pupillary size on emotion recognition,"Improving the expressiveness of virtual humans is essential for qualitative interactions and development of an emotional bond. It is certainly indicated for all applications using the user's cognitive processes, such as applications dedicated to training or health. Our study aims to contribute to the design of an expressive virtual human, by identifying and adapting visual factors promoting transcription of emotions. In this paper, we investigate the effect of expressive wrinkles and variation of pupil size. We propose to compare the recognition of basic emotions on a real human and on an expressive virtual human. The virtual human was subject to two different factors: expressive wrinkles and/or pupil size. Our results indicate that emotion recognition rates on the virtual agent are high. Moreover, expressive wrinkles affect emotion recognition. The effect of pupillary size is less significant. However, both are recommended to design an expressive virtual human.",2019.0,24.0,10.0,True,"{'url': 'https://hal.archives-ouvertes.fr/hal-02303880/file/LAMPA_ACM_2019_MILCENT.pdf', 'status': 'GREEN'}",{'name': 'Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Book{Milcent2019ExpressiveVH,\n author = {Anne-Sophie Milcent and Erik Geslin and Abdelmajid Kadri and S. Richir},\n booktitle = {International Conference on Intelligent Virtual Agents},\n journal = {Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents},\n title = {Expressive Virtual Human: Impact of expressive wrinkles and pupillary size on emotion recognition},\n year = {2019}\n}\n'}","[{'authorId': '2079143895', 'name': 'Anne-Sophie Milcent'}, {'authorId': '34861774', 'name': 'Erik Geslin'}, {'authorId': '39792357', 'name': 'Abdelmajid Kadri'}, {'authorId': '2646589', 'name': 'S. Richir'}]"
2616,e33790c21adb5ef82d4cbbed0f2d3ae1286d7ee7,Multimodal fusion framework: A multiresolution approach for emotion classification and recognition from physiological signals,,2014.0,76.0,229.0,False,,"{'volume': '102', 'pages': '162-172', 'name': 'NeuroImage'}","{'bibtex': '@Article{Verma2014MultimodalFF,\n author = {G. Verma and U. Tiwary},\n journal = {NeuroImage},\n pages = {162-172},\n title = {Multimodal fusion framework: A multiresolution approach for emotion classification and recognition from physiological signals},\n volume = {102},\n year = {2014}\n}\n'}","[{'authorId': '35077572', 'name': 'G. Verma'}, {'authorId': '2192568', 'name': 'U. Tiwary'}]"
2617,e34c0ce11535526e3d84fa22e8fa0795fea0573d,The functional significance of social cognition in schizophrenia: a review.,"Deficits in a wide array of functional outcome areas (eg, social functioning, social skills, independent living skills, etc) are marked in schizophrenia. Consequently, much recent research has attempted to identify factors that may contribute to functional outcome; social cognition is one such domain. The purpose of this article is to review research examining the relationship between social cognition and functional outcome. Comprehensive searches of PsycINFO and MEDLINE/PUBMED were conducted to identify relevant published manuscripts to include in the current review. It is concluded that the relationship between social cognition and functional outcome depends on the specific domains of each construct examined; however, it can generally be concluded that there are clear and consistent relationships between aspects of functional outcome and social cognition. These findings are discussed in light of treatment implications for schizophrenia.",2006.0,133.0,1239.0,True,"{'url': 'https://academic.oup.com/schizophreniabulletin/article-pdf/32/suppl_1/S44/5406620/sbl029.pdf', 'status': None}","{'volume': '32 Suppl 1', 'pages': '\n          S44-63\n        ', 'name': 'Schizophrenia bulletin'}","{'bibtex': '@Article{Couture2006TheFS,\n author = {Shannon M. Couture and D. Penn and David L. Roberts},\n journal = {Schizophrenia bulletin},\n pages = {\n          S44-63\n        },\n title = {The functional significance of social cognition in schizophrenia: a review.},\n volume = {32 Suppl 1},\n year = {2006}\n}\n'}","[{'authorId': '3465481', 'name': 'Shannon M. Couture'}, {'authorId': '2451983', 'name': 'D. Penn'}, {'authorId': '2241595917', 'name': 'David L. Roberts'}]"
2618,e35277e5dcb61ac3b4077f3a08b02fba80ccf085,Using real life incidents for creating realistic virtual crowds with data-driven emotion contagion,,2018.0,41.0,26.0,True,"{'url': 'http://repository.bilkent.edu.tr/bitstream/11693/49843/1/Using_real_life_incidents_for_creating_realistic_virtual_crowds_with.pdf', 'status': None}","{'volume': '72', 'pages': '70-81', 'name': 'Comput. Graph.'}","{'bibtex': '@Article{Basak2018UsingRL,\n author = {A. E. Basak and U. Güdükbay and Funda Durupinar},\n journal = {Comput. Graph.},\n pages = {70-81},\n title = {Using real life incidents for creating realistic virtual crowds with data-driven emotion contagion},\n volume = {72},\n year = {2018}\n}\n'}","[{'authorId': '32565728', 'name': 'A. E. Basak'}, {'authorId': '1746035', 'name': 'U. Güdükbay'}, {'authorId': '2643744', 'name': 'Funda Durupinar'}]"
2619,e3569567eb3b2a0ed3b578e9481a140c9223759f,THE EMPATHIC COMPANION: A CHARACTER-BASED INTERFACE THAT ADDRESSES USERS' AFFECTIVE STATES,"ABSTRACT In this paper, we report on our efforts in developing affective character-based interfaces, i.e., interfaces that recognize and measure affective information of the user and address user affect by employing embodied characters. In particular, we describe the Empathic Companion, an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user's affective states in the form of empathic feedback. The Empathic Companion is conceived as an educational agent that supports job seekers preparing for a job interview. We also present results from an exploratory study that aims to evaluate the impact of the Empathic Companion by measuring users' skin conductance and heart rate. While an overall positive effect of the Empathic Companion could not be shown, the outcome of the experiment suggests that empathic feedback has a positive effect on the interviewee's stress level while hearing the interviewer question.",2005.0,30.0,311.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/08839510590910174?needAccess=true&role=button', 'status': None}","{'volume': '19', 'pages': '267 - 285', 'name': 'Applied Artificial Intelligence'}","{'bibtex': ""@Article{Prendinger2005THEEC,\n author = {H. Prendinger and M. Ishizuka},\n journal = {Applied Artificial Intelligence},\n pages = {267 - 285},\n title = {THE EMPATHIC COMPANION: A CHARACTER-BASED INTERFACE THAT ADDRESSES USERS' AFFECTIVE STATES},\n volume = {19},\n year = {2005}\n}\n""}","[{'authorId': '2356111', 'name': 'H. Prendinger'}, {'authorId': '144666118', 'name': 'M. Ishizuka'}]"
2621,e3935d2a52de5db700a8041c4b4bd5833f723afb,Designing a Mobile Serious Game for Raising Awareness of Diabetic Children,"Mobile serious games are very important tools for self-learning, training, and edutainment. They can be used to improve the children’s learning skills to grasp new concepts rapidly in an enjoyable manner. Fun, motivation, and engagement are the most important features in designing attractive serious games. Therefore, designers should always find the best strategies and techniques to keep children playing the game with motivation and enthusiasm. The process is very long and requires different expertise from all the stakeholders. Arcade games are the most played games for fun and amusement in the last decades. Their approach is based on simplicity, easiness, repetitiveness, and soft challenges. The players of arcade games need only to improve their scores in every episode and avoid frustration and hard challenges as in other games. Hence, this arcade-based approach can be used in designing attractive serious games for young children and adolescents. We propose in this research a new serious game for diabetic children to teach them about the disease in a very easy manner. The game uses the arcade approach coupled with useful information about diabetes where the children discover them incrementally during the play. The longer time the child spends on the game, the most she/he can learn and enhance her/his knowledge on the disease. The game success came from its design and implementation with the presence of diabetes children, advisors, and nutritionists. We compare the game with the well-known DEX pet-based game for diabetes awareness on different aspects including user experience, usability, and learning outcomes. The study is conducted on twenty children from a diabetes camp who accepted voluntarily to participate in this research. We evaluate their educational aspects, using an improved version of the MEEGA+ model. We demonstrate the importance of the proposed game in enhancing the children knowledge on diabetes and adopt a new healthy lifestyle.",2020.0,70.0,7.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/09290009.pdf', 'status': None}","{'volume': '8', 'pages': '222876-222889', 'name': 'IEEE Access'}","{'bibtex': '@Article{Moosa2020DesigningAM,\n author = {Alaa Mohammed Moosa and Noor Al-Máadeed and M. Saleh and S. Al-Maadeed and Jihad Mohamed Aljaam},\n journal = {IEEE Access},\n pages = {222876-222889},\n title = {Designing a Mobile Serious Game for Raising Awareness of Diabetic Children},\n volume = {8},\n year = {2020}\n}\n'}","[{'authorId': '51290092', 'name': 'Alaa Mohammed Moosa'}, {'authorId': '10385459', 'name': 'Noor Al-Máadeed'}, {'authorId': '144421159', 'name': 'M. Saleh'}, {'authorId': '31330222', 'name': 'S. Al-Maadeed'}, {'authorId': '1413773342', 'name': 'Jihad Mohamed Aljaam'}]"
2622,e3a472699ae4d2d53b8ff5115c59fb64f428eb93,John Watson - Little Albert,,2011.0,0.0,1.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Watson2011JohnW,\n author = {J. Watson},\n title = {John Watson - Little Albert},\n year = {2011}\n}\n'}","[{'authorId': '145979199', 'name': 'J. Watson'}]"
2623,e3a62233800cd8ed46ce82a856d2fd2df197e705,The Power of a Nod and a Glance: Envelope Vs. Emotional Feedback in Animated Conversational Agents,"In this article we describe results froman experiment of user interaction with autonomous , human - like ( humanoid ) conversational agents . We hypothesize that for embodied conversational agents , nonverbal behaviors related to the process of conversation , what we call envelope feedback, is much more important than other feedback , such as emotional expression . We test this hypothesis by having subjects interact with three autonomous agents , all capable of full - duplex multimodal interaction: able to generate and recognize speech , intonation , facial displays , and gesture . Each agent , however , gave a different kind of feedback: ( 1 ) content - related only , ( 2 ) content + envelope feedback , and ( 3 ) content + emotional . Content-related feedback includes answering questions and executing commands; envelope feedback includes behaviors such as gaze , manual beat gesture , and head movements; emotional feedback includes smiles and looks of puzzlement . Subjects' evaluations of the systemwere c...",1999.0,0.0,451.0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/088395199117360?needAccess=true', 'status': None}","{'volume': '13', 'pages': '519-538', 'name': 'Appl. Artif. Intell.'}","{'bibtex': '@Article{Cassell1999ThePO,\n author = {Justine Cassell and K. Thórisson},\n journal = {Appl. Artif. Intell.},\n pages = {519-538},\n title = {The Power of a Nod and a Glance: Envelope Vs. Emotional Feedback in Animated Conversational Agents},\n volume = {13},\n year = {1999}\n}\n'}","[{'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '1727838', 'name': 'K. Thórisson'}]"
2625,e3e5f4e91fec0ad446041912183471bf1b8d9cd6,Investigating the Effect of User Variables on Perceiving the Emotional Nonverbal Behaviors of an Empathic Virtual Agent,"The present dissertation investigated the effect of individual variables on the perception of emotional nonverbal behaviors of an empathic virtual agent. Prior studies have reported the importance of implementing empathy in virtual agents regarding maximizing the quality of human–agent interactions. As studies in human–human interactions demonstrate, nonverbal behaviors play a significant role in the transfer of meanings and intentions between the interlocutors. Therefore, the aim of this dissertation was to examine how individual variables influence the perception of the nonverbal behaviors of an agent. The nonverbal behaviors were specifically created to express the empathizing intention of the virtual agent. In this regard, three empirical studies have been conducted to investigate the effect of users’ age (Study 1), users’ cultural background (Study 2), and users’ cultural stereotypes toward the agent (Study 3) on the perception of an empathic agent. 
The results of Study 1 provide important insights into the understanding of how users of varying ages perceive an agent’s emotional nonverbal responses. Older users observed to be more sensible to nonverbal behaviors of the agent since they perceived the agent as more empathic compared with younger adults. The higher perception of the older users was based on the agent’s displayed nonverbal behaviors, indicating the importance of implementing emotional nonverbal behaviors specifically for this target group. Moreover, there were differences between older and younger adults with respect to perceiving specific nonverbal behaviors as empathic. 
The culture of the users in Study 2 was also found to have an influence on users’ perception of an agent. Comparing Iranian and German users (as the examples of relatively collectivistic and individualistic cultures) showed differences regarding users’ perception of the agent’s nonverbal behaviors. While Iranian participants rated a wide array of nonverbal behaviors as empathic, their German peers perceived one specific nonverbal behavior only as the most empathic one. This is where the factor of culture becomes a matter of concern. In order for a virtual agent to look more emphatic, users’ culture should be considered while implementing nonverbal behaviors. 
And finally, in Study 3, it was observed that users do not show stereotypical attitudes toward the agent when they are aware that the agent is designed and produced in a different country. Users who were primed about the country of the agent did not show different ratings of empathic behaviors of the agent in the presence of emotional nonverbal behaviors. The findings of this study make valuable contributions to the research in the domain of bias toward the agent. It can be stated that as long as there are no cues in the appearance of the agent representing a different culture, users do not get biased toward its emotional responses. 
Taken together, this dissertation provides insight into understanding that user variables indeed matter and they can influence accurately perceiving the emotional nonverbal behaviors of virtual agents. Since the purpose of designing an empathic agent is to enhance users’ experiences and satisfaction, the factors that have the potential to impact their perception of an empathic agent should be considered when designing a virtual agent.",2020.0,0.0,1.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Ghasabeh2020InvestigatingTE,\n author = {Adineh Hosseinpanah Ghasabeh},\n title = {Investigating the Effect of User Variables on Perceiving the Emotional Nonverbal Behaviors of an Empathic Virtual Agent},\n year = {2020}\n}\n'}","[{'authorId': '2135335482', 'name': 'Adineh Hosseinpanah Ghasabeh'}]"
2626,e3fd3b1be871da6e048adaef4a4e201af282fe8e,Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse,"With the popularity of AI-infused systems, conversational agents (CAs) are becoming essential in diverse areas, offering new functionality and convenience, but simultaneously, suffering misuse and verbal abuse. We examine whether conversational agents' response styles under varying abuse types influence those emotions found to mitigate peoples' aggressive behaviors, involving three verbal abuse types (Insult, Threat, Swearing) and three response styles (Avoidance, Empathy, Counterattacking). Ninety-eight participants were assigned to one of the abuse type conditions, interacted with the three spoken (voice-based) CAs in turn, and reported their feelings about guiltiness, anger, and shame after each session. The results show that the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathy agent than the other two agents. Furthermore, we investigated the current status of commercial CAs' responses to verbal abuse. Our study findings have direct implications for the design of conversational agents.",2020.0,77.0,58.0,False,,{'name': 'Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Chin2020EmpathyIA,\n author = {Hyojin Chin and Lebogang Wame Molefi and M. Yi},\n journal = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},\n title = {Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse},\n year = {2020}\n}\n'}","[{'authorId': '32721006', 'name': 'Hyojin Chin'}, {'authorId': '10775146', 'name': 'Lebogang Wame Molefi'}, {'authorId': '1796342', 'name': 'M. Yi'}]"
2627,e4003dbeaf40c872b2f2346c22a66696c7bd6370,Sentence and Expression Level Annotation of Opinions in User-Generated Discourse,"In this paper, we introduce a corpus of consumer reviews from the rateitall and the eopinions websites annotated with opinion-related information. We present a two-level annotation scheme. In the first stage, the reviews are analyzed at the sentence level for (i) relevancy to a given topic, and (ii) expressing an evaluation about the topic. In the second stage, on-topic sentences containing evaluations about the topic are further investigated at the expression level for pinpointing the properties (semantic orientation, intensity), and the functional components of the evaluations (opinion terms, targets and holders). We discuss the annotation scheme, the inter-annotator agreement for different subtasks and our observations.",2010.0,22.0,145.0,False,,{'pages': '575-584'},"{'bibtex': '@Inproceedings{Toprak2010SentenceAE,\n author = {C. Toprak and Niklas Jakob and Iryna Gurevych},\n pages = {575-584},\n title = {Sentence and Expression Level Annotation of Opinions in User-Generated Discourse},\n year = {2010}\n}\n'}","[{'authorId': '40122420', 'name': 'C. Toprak'}, {'authorId': '1853561', 'name': 'Niklas Jakob'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]"
2628,e40c4a0c8e0b888b6669db4a26d53e115e547901,Mimicry: causes and consequences,,2015.0,65.0,94.0,False,,"{'volume': '3', 'pages': '112-116', 'name': 'Current Opinion in Behavioral Sciences'}","{'bibtex': '@Article{Duffy2015MimicryCA,\n author = {Korrina A. Duffy and T. Chartrand},\n journal = {Current Opinion in Behavioral Sciences},\n pages = {112-116},\n title = {Mimicry: causes and consequences},\n volume = {3},\n year = {2015}\n}\n'}","[{'authorId': '28940714', 'name': 'Korrina A. Duffy'}, {'authorId': '6026289', 'name': 'T. Chartrand'}]"
2629,e4196fc64eb6b9e5b1cfc4e457de6fc112df9a1a,"Cultures and Organizations: Software of the Mind, 3rd ed.",,2010.0,0.0,2820.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Hofstede2010CulturesAO,\n author = {G. Hofstede and G. Hofstede and M. Minkov and McGraw-Hill New},\n title = {Cultures and Organizations: Software of the Mind, 3rd ed.},\n year = {2010}\n}\n'}","[{'authorId': '2584600', 'name': 'G. Hofstede'}, {'authorId': '2584600', 'name': 'G. Hofstede'}, {'authorId': '39708729', 'name': 'M. Minkov'}, {'authorId': '114807699', 'name': 'McGraw-Hill New'}]"
2630,e423265bda7cc1260fe37813facb9b904429aa81,Detecting depression from facial actions and vocal prosody,"Current methods of assessing psychopathology depend almost entirely on verbal report (clinical interview or questionnaire) of patients, their family, or caregivers. They lack systematic and efficient ways of incorporating behavioral observations that are strong indicators of psychological disorder, much of which may occur outside the awareness of either individual. We compared clinical diagnosis of major depression with automatically measured facial actions and vocal prosody in patients undergoing treatment for depression. Manual FACS coding, active appearance modeling (AAM) and pitch extraction were used to measure facial and vocal expression. Classifiers using leave-one-out validation were SVM for FACS and for AAM and logistic regression for voice. Both face and voice demonstrated moderate concurrent validity with depression. Accuracy in detecting depression was 88% for manual FACS and 79% for AAM. Accuracy for vocal prosody was 79%. These findings suggest the feasibility of automatic detection of depression, raise new issues in automated facial image analysis and machine learning, and have exciting implications for clinical theory and practice.",2009.0,50.0,415.0,False,,"{'pages': '1-7', 'name': '2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops'}","{'bibtex': '@Article{Cohn2009DetectingDF,\n author = {J. Cohn and T. S. Kruez and I. Matthews and Ying Yang and Minh Hoai Nguyen and M. T. Padilla and Feng Zhou and F. D. L. Torre},\n journal = {2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops},\n pages = {1-7},\n title = {Detecting depression from facial actions and vocal prosody},\n year = {2009}\n}\n'}","[{'authorId': '1737918', 'name': 'J. Cohn'}, {'authorId': '3306260', 'name': 'T. S. Kruez'}, {'authorId': '1711695', 'name': 'I. Matthews'}, {'authorId': '2118771372', 'name': 'Ying Yang'}, {'authorId': '1698158', 'name': 'Minh Hoai Nguyen'}, {'authorId': '31173734', 'name': 'M. T. Padilla'}, {'authorId': '2114903588', 'name': 'Feng Zhou'}, {'authorId': '143867160', 'name': 'F. D. L. Torre'}]"
2631,e445d42bc7958ffb97f478182cde4c2ea85a550e,Teacher Feedback to Young Children in Formative Assessment: a typology,"L'appreciation formative est un processus essentiel en apprentissage, il sert a juger et a evaluer le travail et les performances pour ensuite aider a enrichir les competences. Cet article donne un apercu du role de la retroaction en classe, de son role dans l'enseignement et dans l'apprentissage, et de sa contribution aux discussions sur les objectifs de rendement",1996.0,20.0,353.0,False,,"{'volume': '22', 'pages': '389-404', 'name': 'British Educational Research Journal'}","{'bibtex': '@Article{Tunstall1996TeacherFT,\n author = {P. Tunstall and Caroline Gsipps},\n journal = {British Educational Research Journal},\n pages = {389-404},\n title = {Teacher Feedback to Young Children in Formative Assessment: a typology},\n volume = {22},\n year = {1996}\n}\n'}","[{'authorId': '12163592', 'name': 'P. Tunstall'}, {'authorId': '117404403', 'name': 'Caroline Gsipps'}]"
2633,e44d334f46465300dbf365e3efc8680481644919,Peers at work: Economic real-effort experiments in the presence of virtual co-workers,"Traditionally, experimental economics uses controlled and incentivized field and lab experiments to analyze economic behavior. However, investigating peer effects in the classic settings is challenging due to the reflection problem: Who is influencing whom? To overcome this, we enlarge the methodological toolbox of these experiments by means of Virtual Reality. After introducing and validating a real-effort sorting task, we embed a virtual agent as peer of a human subject, who independently performs an identical sorting task. We conducted two experiments investigating (a) the subject's productivity adjustment due to peer effects and (b) the incentive effects on competition. Our results indicate a great potential for Virtual-Reality-based economic experiments.",2017.0,3.0,12.0,True,"{'url': 'http://vr.rwth-aachen.de/media/papers/Boensch_PeersAtWork_redSize_Poster.pdf', 'status': None}","{'pages': '301-302', 'name': '2017 IEEE Virtual Reality (VR)'}","{'bibtex': '@Article{Bönsch2017PeersAW,\n author = {A. Bönsch and J. Wendt and H. Overath and Ö. Gürerk and C. Harbring and C. Grund and T. Kittsteiner and T. Kuhlen},\n journal = {2017 IEEE Virtual Reality (VR)},\n pages = {301-302},\n title = {Peers at work: Economic real-effort experiments in the presence of virtual co-workers},\n year = {2017}\n}\n'}","[{'authorId': '3249697', 'name': 'A. Bönsch'}, {'authorId': '39812907', 'name': 'J. Wendt'}, {'authorId': '47973447', 'name': 'H. Overath'}, {'authorId': '66809640', 'name': 'Ö. Gürerk'}, {'authorId': '2536104', 'name': 'C. Harbring'}, {'authorId': '8470293', 'name': 'C. Grund'}, {'authorId': '2856539', 'name': 'T. Kittsteiner'}, {'authorId': '144483066', 'name': 'T. Kuhlen'}]"
2634,e468538b4dd98e04d510023dc4e444c73d6cfdbc,Facial affect recognition and information processing in schizophrenia and bipolar disorder,,1998.0,34.0,472.0,False,,"{'volume': '32', 'pages': '171-181', 'name': 'Schizophrenia Research'}","{'bibtex': '@Article{Addington1998FacialAR,\n author = {J. Addington and D. Addington},\n journal = {Schizophrenia Research},\n pages = {171-181},\n title = {Facial affect recognition and information processing in schizophrenia and bipolar disorder},\n volume = {32},\n year = {1998}\n}\n'}","[{'authorId': '3471676', 'name': 'J. Addington'}, {'authorId': '145650946', 'name': 'D. Addington'}]"
2635,e472904815fbd41453edfaa7aeb51f837987f6c7,Too real for comfort? Uncanny responses to computer generated faces,,2009.0,96.0,446.0,True,"{'url': 'https://scholarworks.iupui.edu/bitstream/1805/10279/1/nihms409675.pdf', 'status': None}","{'volume': '25 3', 'pages': '\n          695-710\n        ', 'name': 'Computers in human behavior'}","{'bibtex': '@Article{Macdorman2009TooRF,\n author = {K. Macdorman and R. Green and Chin-Chang Ho and C. T. Koch},\n journal = {Computers in human behavior},\n pages = {\n          695-710\n        },\n title = {Too real for comfort? Uncanny responses to computer generated faces},\n volume = {25 3},\n year = {2009}\n}\n'}","[{'authorId': '1690354', 'name': 'K. Macdorman'}, {'authorId': '2072877440', 'name': 'R. Green'}, {'authorId': '2472620', 'name': 'Chin-Chang Ho'}, {'authorId': '152439878', 'name': 'C. T. Koch'}]"
2636,e47da704264e880d351f10ebf18325fa39e99b71,Modeling both Context- and Speaker-Sensitive Dependence for Emotion Detection in Multi-speaker Conversations,"Recently, emotion detection in conversations becomes a hot research topic in the Natural Language Processing community. In this paper, we focus on emotion detection in multi-speaker conversations instead of traditional two-speaker conversations in existing studies. Different from non-conversation text, emotion detection in conversation text has one specific challenge in modeling the context-sensitive dependence. Besides, emotion detection in multi-speaker conversations endorses another specific challenge in modeling the speaker-sensitive dependence. To address above two challenges, we propose a conversational graph-based convolutional neural network. On the one hand, our approach represents each utterance and each speaker as a node. On the other hand, the context-sensitive dependence is represented by an undirected edge between two utterances nodes from the same conversation and the speaker-sensitive dependence is represented by an undirected edge between an utterance node and its speaker node. In this way, the entire conversational corpus can be symbolized as a large heterogeneous graph and the emotion detection task can be recast as a classification problem of the utterance nodes in the graph. The experimental results on a multi-modal and multi-speaker conversation corpus demonstrate the great effectiveness of the proposed approach.",2019.0,31.0,135.0,True,"{'url': 'https://www.ijcai.org/proceedings/2019/0752.pdf', 'status': None}",{'pages': '5415-5421'},"{'bibtex': '@Inproceedings{Zhang2019ModelingBC,\n author = {Dong Zhang and Liangqing Wu and Changlong Sun and Shoushan Li and Qiaoming Zhu and Guodong Zhou},\n pages = {5415-5421},\n title = {Modeling both Context- and Speaker-Sensitive Dependence for Emotion Detection in Multi-speaker Conversations},\n year = {2019}\n}\n'}","[{'authorId': '153165260', 'name': 'Dong Zhang'}, {'authorId': '51183249', 'name': 'Liangqing Wu'}, {'authorId': '2060934', 'name': 'Changlong Sun'}, {'authorId': '2109167274', 'name': 'Shoushan Li'}, {'authorId': '7703092', 'name': 'Qiaoming Zhu'}, {'authorId': '143740945', 'name': 'Guodong Zhou'}]"
2637,e4824fb8231d32c5e2532c52b91bf82afe1f4727,"Physical Presence, Social Presence, and Anxiety in Participants with Social Anxiety Disorder During Virtual Cue Exposure","Although social anxiety disorders (SADs) are increasingly treated by means of virtual cue exposure, the mechanisms leading to sufficient anxiety levels and thus to a success of virtual reality exposure therapy are still poorly understood. Also, most studies with SAD participants fail to evaluate social presence, although it may be a more appropriate indicator for virtual social stress scenarios than physical presence. Hence, for the first time, this study sets out to examine the link between social presence, physical presence, and emotional responses to phobogenic virtual social stimuli. A group of n = 12 participants with SAD and n = 12 healthy controls were exposed to three social tasks in an interactive virtual environment (VE). Self-report measures of physical and social presence as well as state anxiety were used alongside heart rate measures to evaluate the virtual experience. Results show significantly higher anxiety levels-both self-report and physiological-in SAD participants than in controls. Also, socially anxious subjects reported to experience more copresence and mutual attention as well as a higher sense of being in the VE than their healthy peers. In sum, social presence experiences may be more predicative of the anxiety response in SAD individuals than physical presence. Especially attentional processes seem to crucially shape the interplay between presence and affective responses.",2019.0,22.0,37.0,True,"{'url': 'https://www.liebertpub.com/doi/pdf/10.1089/cyber.2018.0221', 'status': None}","{'volume': '22 1', 'pages': '\n          46-50\n        ', 'name': 'Cyberpsychology, behavior and social networking'}","{'bibtex': '@Article{Felnhofer2019PhysicalPS,\n author = {A. Felnhofer and H. Hlavacs and Leon Beutl and I. Kryspin-Exner and O. Kothgassner},\n journal = {Cyberpsychology, behavior and social networking},\n pages = {\n          46-50\n        },\n title = {Physical Presence, Social Presence, and Anxiety in Participants with Social Anxiety Disorder During Virtual Cue Exposure},\n volume = {22 1},\n year = {2019}\n}\n'}","[{'authorId': '2144008', 'name': 'A. Felnhofer'}, {'authorId': '1743771', 'name': 'H. Hlavacs'}, {'authorId': '2373231', 'name': 'Leon Beutl'}, {'authorId': '1398005104', 'name': 'I. Kryspin-Exner'}, {'authorId': '3136916', 'name': 'O. Kothgassner'}]"
2638,e4901faa28061fd52ac4e7c64d21dc0085aa5fd3,Design an empathic virtual human to encourage and persuade learners in e-learning systems,"Studies indicate that making learners feel good is important only minor to clear knowledge transformation. Many studies have tried to use virtual humans as a part of interface in learning systems to increase the effect of instructions. Based on social interaction and pedagogical theories, many e-learning systems use animated films or virtual reality to boost human-computer engagement and ease their negative emotions. However, affective learning systems still need much research to improve their functionalities and usability. This study proposed a convenient approach to develop an emotionally interactive learning system; learners can express their emotions by mouse-clicking while learning. A virtual human was created to empathically react to learners in proactive and reactive ways to encourage and persuade them into persistent learning and help achieve their goals. Experimental results show that, averagely, subjects can tell virtual human's emotions and agree to its empathic reactions. Persuasion conducted by virtual human could not increase subjects' learning time, but could significantly increase their completion rate of exercises.",2009.0,23.0,29.0,False,,{'pages': '27-32'},"{'bibtex': '@Inproceedings{Wang2009DesignAE,\n author = {Chin-Yeh Wang and Gwo-Dong Chen and Chen-Chung Liu and Baw-Jhiune Liu},\n pages = {27-32},\n title = {Design an empathic virtual human to encourage and persuade learners in e-learning systems},\n year = {2009}\n}\n'}","[{'authorId': '2388316', 'name': 'Chin-Yeh Wang'}, {'authorId': '2108973704', 'name': 'Gwo-Dong Chen'}, {'authorId': '98694949', 'name': 'Chen-Chung Liu'}, {'authorId': '1797298', 'name': 'Baw-Jhiune Liu'}]"
2639,e4d739ffa79a607008f3a251912083a23ce37607,Linguistic Inquiry and Word Count (LIWC2007),,2007.0,11.0,2368.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Pennebaker2007LinguisticIA,\n author = {J. Pennebaker and R. Booth and Martha E. Francis},\n title = {Linguistic Inquiry and Word Count (LIWC2007)},\n year = {2007}\n}\n'}","[{'authorId': '1854783', 'name': 'J. Pennebaker'}, {'authorId': '48182912', 'name': 'R. Booth'}, {'authorId': '144896996', 'name': 'Martha E. Francis'}]"
2640,e504d9e6195c781b735aca55e7fb6dce3bf13647,Long Lamai Community ICT4D E‐Commerce System Modelling: An Agent Oriented Role‐Based Approach,"This paper presents the post‐mortem report upon completion of the Long Lamai e‐commerce development project. Some weaknesses with regards to the current software modelling approach are identified and an alternative role‐based approach is proposed. We argue that the existing software modelling technique is not suitable for modelling, making it difficult to establish a good contract between stakeholders causing delays in the project delivery. The role‐based approach is able to explicitly highlight the responsibilities among stakeholders, while also forming the contract agreement among them leading towards sustainable ICT4D.",2016.0,18.0,16.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/j.1681-4835.2016.tb00547.x', 'status': None}","{'volume': '75', 'name': 'The Electronic Journal of Information Systems in Developing Countries'}","{'bibtex': '@Article{Cheah2016LongLC,\n author = {W. Cheah and Alfian Abdul Halin and Marlene Lu and Gary CheeWhye},\n journal = {The Electronic Journal of Information Systems in Developing Countries},\n title = {Long Lamai Community ICT4D E‐Commerce System Modelling: An Agent Oriented Role‐Based Approach},\n volume = {75},\n year = {2016}\n}\n'}","[{'authorId': '3078761', 'name': 'W. Cheah'}, {'authorId': '30632706', 'name': 'Alfian Abdul Halin'}, {'authorId': '2236265', 'name': 'Marlene Lu'}, {'authorId': '73734171', 'name': 'Gary CheeWhye'}]"
2641,e5477563a138fa4dcceda35eab4f539408765276,Realistic Visual Speech Synthesis Based on Hybrid Concatenation Method,"This paper presents a realistic visual speech synthesis based on the hybrid concatenation method. Unlike previous methods based on phoneme level unit selection or hidden Markov model (HMM), etc., the hybrid concatenation method uses a frame level-based unit selection method combined with a fused HMM, and is able to generate more expressive and stable facial animations. The fused HMM can be used to explicitly model the loose synchronization of tightly coupled streams, with much better results than a normal HMM for audiovisual mapping. After fused HMM is created, facial animation is generated via the unit selection method at the frame level by using the fused HMM output probabilities. To accelerate the computing efficiency of the unit selection on a large corpus, this paper also proposes a two-layer Viterbi search method in which only the subsets that have been selected in the first layer are further checked in the second layer. Using this idea, the system has been successfully integrated into real-time applications. Furthermore, the paper also proposes a mapping method to generate emotional facial expressions from neutral facial expressions based on Gaussian mixture models (GMMs). Final experiments prove that the method described can output synthesized facial parameters with high quality. Compared with other audiovisual mapping methods, our method has better performance with respect to expressiveness, stability, and system running speed.",2009.0,34.0,24.0,False,,"{'volume': '17', 'pages': '469-477', 'name': 'IEEE Transactions on Audio, Speech, and Language Processing'}","{'bibtex': '@Article{Tao2009RealisticVS,\n author = {J. Tao and Le Xin and Panrong Yin},\n journal = {IEEE Transactions on Audio, Speech, and Language Processing},\n pages = {469-477},\n title = {Realistic Visual Speech Synthesis Based on Hybrid Concatenation Method},\n volume = {17},\n year = {2009}\n}\n'}","[{'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '2070509641', 'name': 'Le Xin'}, {'authorId': '2526255', 'name': 'Panrong Yin'}]"
2642,e5529db6978e4afc46bd03e85e06092f07253624,A macro-level analysis of SRL processes and their relations to the acquisition of a sophisticated mental model of a complex system☆☆☆,,2009.0,80.0,308.0,False,,"{'volume': '34', 'pages': '18-29', 'name': 'Contemporary Educational Psychology'}","{'bibtex': '@Article{Greene2009AMA,\n author = {J. A. Greene and R. Azevedo},\n journal = {Contemporary Educational Psychology},\n pages = {18-29},\n title = {A macro-level analysis of SRL processes and their relations to the acquisition of a sophisticated mental model of a complex system☆☆☆},\n volume = {34},\n year = {2009}\n}\n'}","[{'authorId': '22686353', 'name': 'J. A. Greene'}, {'authorId': '145394858', 'name': 'R. Azevedo'}]"
2643,e5991b24a0375041855b2b4f493a7d6a0094f0ae,Affect-Driven Dialog Generation,"The majority of current systems for end-to-end dialog generation focus on response quality without an explicit control over the affective content of the responses. In this paper, we present an affect-driven dialog system, which generates emotional responses in a controlled manner using a continuous representation of emotions. The system achieves this by modeling emotions at a word and sequence level using: (1) a vector representation of the desired emotion, (2) an affect regularizer, which penalizes neutral words, and (3) an affect sampling method, which forces the neural network to generate diverse words that are emotionally relevant. During inference, we use a re-ranking procedure that aims to extract the most emotionally relevant responses using a human-in-the-loop optimization process. We study the performance of our system in terms of both quantitative (BLEU score and response diversity), and qualitative (emotional appropriateness) measures.",2019.0,31.0,86.0,True,"{'url': 'https://arxiv.org/pdf/1904.02793', 'status': None}","{'volume': 'abs/1904.02793', 'name': 'ArXiv'}","{'bibtex': '@Article{Colombo2019AffectDrivenDG,\n author = {Pierre Colombo and Wojciech Witon and Ashutosh Modi and J. Kennedy and Mubbasir Kapadia},\n journal = {ArXiv},\n title = {Affect-Driven Dialog Generation},\n volume = {abs/1904.02793},\n year = {2019}\n}\n'}","[{'authorId': '46985469', 'name': 'Pierre Colombo'}, {'authorId': '37297179', 'name': 'Wojciech Witon'}, {'authorId': '2477939', 'name': 'Ashutosh Modi'}, {'authorId': '2113614351', 'name': 'J. Kennedy'}, {'authorId': '143980996', 'name': 'Mubbasir Kapadia'}]"
2644,e5b22f37f6d7ac0b0507f4e0caaef24978ec3eaa,Physiological-Based Emotion Detection and Recognition in a Video Game Context,"Affective gaming is a hot field of research that exploits human emotion for the enhancement of player's experience during gameplay. Physiological signal is an effective modality that can provide a better understanding of the emotional states and is very promising to be applied to affective gaming. Most physiological-based affective gaming applications evaluate player's emotion on an overall game fragment. These approaches fail to capture the emotion change in the dynamic game context. In order to achieve a better understanding of psychophysiological response with a better time sensitivity, we present a study that evaluates the psychophysiological responses related to the game events. More specifically, we present a multi-modal database DAG that contains peripheral physiological signals (ECG, EDA, respiration, EMG, temperature), accelerometer signals, facial and screening recordings as well as player's self-reported eventrelated emotion assessment through game playing. We then investigate physiological-based emotion detection and recognition by using machine learning techniques. Common challenges for physiological-based affective model such as signal segmentation, feature normalization, relevant features are addressed. We also discuss factors that influence the performance of the affective models.",2018.0,44.0,25.0,True,"{'url': 'https://hal.sorbonne-universite.fr/hal-01784795/file/PID5336175.pdf', 'status': None}","{'pages': '1-8', 'name': '2018 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Yang2018PhysiologicalBasedED,\n author = {Wenlu Yang and M. Rifqi and C. Marsala and Andrea Pinna},\n journal = {2018 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {Physiological-Based Emotion Detection and Recognition in a Video Game Context},\n year = {2018}\n}\n'}","[{'authorId': '2106320', 'name': 'Wenlu Yang'}, {'authorId': '2922335', 'name': 'M. Rifqi'}, {'authorId': '1991253', 'name': 'C. Marsala'}, {'authorId': '2054772412', 'name': 'Andrea Pinna'}]"
2645,e5eef8a008cbd09a9161587a62aaeb106f3d603c,Wearable Emotion Recognition System based on GSR and PPG Signals,"In recent years, many methods and systems for automated recognition of human emotional states were proposed. Most of them are trying to recognize emotions based on physiological signals such as galvanic skin response (GSR), electrocardiogram (ECG), electroencephalogram (EEG), electromyogram (EMG), photoplethysmogram (PPG), respiration, skin temperature etc. Measuring all these signals is quite impractical for real-life use and in this research, we decided to acquire and analyse only GSR and PPG signals because of its suitability for implementation on a simple wearable device that can collect signals from a person without compromising comfort and privacy. For this purpose, we used the lightweight, small and compact Shimmer3 sensor. We developed complete application with database storage to elicit participant»s emotions using pictures from the Geneva affective picture database (GAPED) database. In the post-processing process, we used typical statistical parameters and power spectral density (PSD) as features and support vector machine (SVM) and k-nearest neighbours (KNN) as classifiers. We built single-user and multi-user emotion classification models to compare the results. As expected, we got better average accuracies on a single-user model than on the multi-user model. Our results also show that a single-user based emotion detection model could potentially be used in real-life scenario considering environments conditions.",2017.0,24.0,83.0,False,,{'name': 'Proceedings of the 2nd International Workshop on Multimedia for Personal Health and Health Care'},"{'bibtex': '@Article{Udovicic2017WearableER,\n author = {G. Udovicic and Jurica Derek and M. Russo and M. Sikora},\n journal = {Proceedings of the 2nd International Workshop on Multimedia for Personal Health and Health Care},\n title = {Wearable Emotion Recognition System based on GSR and PPG Signals},\n year = {2017}\n}\n'}","[{'authorId': '7658539', 'name': 'G. Udovicic'}, {'authorId': '143820536', 'name': 'Jurica Derek'}, {'authorId': '2476711', 'name': 'M. Russo'}, {'authorId': '144733884', 'name': 'M. Sikora'}]"
2646,e609684188c842092ae7bcae81429471e422df4d,Learning Individual Styles of Conversational Gesture,"Human speech is often accompanied by hand and arm gestures. We present a method for cross-modal translation from ""in-the-wild"" monologue speech of a single speaker to their conversational gesture motion. We train on unlabeled videos for which we only have noisy pseudo ground truth from an automatic pose detection system. Our proposed model significantly outperforms baseline methods in a quantitative comparison. To support research toward obtaining a computational understanding of the relationship between gesture and speech, we release a large video dataset of person-specific gestures.",2019.0,49.0,232.0,True,"{'url': 'https://arxiv.org/pdf/1906.04160', 'status': None}","{'pages': '3492-3501', 'name': '2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","{'bibtex': '@Article{Ginosar2019LearningIS,\n author = {Shiry Ginosar and Amir Bar and Gefen Kohavi and Caroline Chan and Andrew Owens and Jitendra Malik},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3492-3501},\n title = {Learning Individual Styles of Conversational Gesture},\n year = {2019}\n}\n'}","[{'authorId': '2361255', 'name': 'Shiry Ginosar'}, {'authorId': '2063958674', 'name': 'Amir Bar'}, {'authorId': '51169014', 'name': 'Gefen Kohavi'}, {'authorId': '50993063', 'name': 'Caroline Chan'}, {'authorId': '144956994', 'name': 'Andrew Owens'}, {'authorId': '143751119', 'name': 'Jitendra Malik'}]"
2647,e65594a323f979d3366b108fa30bddde5a9f8d90,Modeling Psychotherapy Dialogues with Kernelized Hashcode Representations: A Nonparametric Information-Theoretic Approach.,"We propose a novel dialogue modeling framework, the first-ever nonparametric kernel functions based approach for dialogue modeling, which learns kernelized hashcodes as compressed text representations; unlike traditional deep learning models, it handles well relatively small datasets, while also scaling to large ones. We also derive a novel lower bound on mutual information, used as a model-selection criterion favoring representations with better alignment between the utterances of participants in a collaborative dialogue setting, as well as higher predictability of the generated responses. As demonstrated on three real-life datasets, including prominently psychotherapy sessions, the proposed approach significantly outperforms several state-of-art neural network based dialogue systems, both in terms of computational efficiency, reducing training time from days or weeks to hours, and the response quality, achieving an order of magnitude improvement over competitors in frequency of being chosen as the best model by human evaluators.",2018.0,76.0,2.0,False,,"{'volume': '', 'name': 'arXiv: Learning'}","{'bibtex': '@Article{Garg2018ModelingPD,\n author = {S. Garg and I. Rish and G. Cecchi and Palash Goyal and Sarik Ghazarian and Shuyang Gao and G. V. Steeg and A. Galstyan},\n journal = {arXiv: Learning},\n title = {Modeling Psychotherapy Dialogues with Kernelized Hashcode Representations: A Nonparametric Information-Theoretic Approach.},\n year = {2018}\n}\n'}","[{'authorId': '144529280', 'name': 'S. Garg'}, {'authorId': '2109771', 'name': 'I. Rish'}, {'authorId': '40193335', 'name': 'G. Cecchi'}, {'authorId': '3436466', 'name': 'Palash Goyal'}, {'authorId': '3022427', 'name': 'Sarik Ghazarian'}, {'authorId': '3092863', 'name': 'Shuyang Gao'}, {'authorId': '1719898', 'name': 'G. V. Steeg'}, {'authorId': '143728483', 'name': 'A. Galstyan'}]"
2648,e65bc86ac118443a849f526e2142c20bfc9ce933,Age-related differences in emotion recognition ability: a cross-sectional study.,"Experimental studies indicate that recognition of emotions, particularly negative emotions, decreases with age. However, there is no consensus at which age the decrease in emotion recognition begins, how selective this is to negative emotions, and whether this applies to both facial and vocal expression. In the current cross-sectional study, 607 participants ranging in age from 18 to 84 years (mean age = 32.6 +/- 14.9 years) were asked to recognize emotions expressed either facially or vocally. In general, older participants were found to be less accurate at recognizing emotions, with the most distinctive age difference pertaining to a certain group of negative emotions. Both modalities revealed an age-related decline in the recognition of sadness and -- to a lesser degree -- anger, starting at about 30 years of age. Although age-related differences in the recognition of expression of emotion were not mediated by personality traits, 2 of the Big 5 traits, openness and conscientiousness, made an independent contribution to emotion-recognition performance. Implications of age-related differences in facial and vocal emotion expression and early onset of the selective decrease in emotion recognition are discussed in terms of previous findings and relevant theoretical models.",2009.0,83.0,210.0,False,,"{'volume': '9 5', 'pages': '\n          619-30\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Mill2009AgerelatedDI,\n author = {Aire Mill and J. Allik and A. Realo and R. Valk},\n journal = {Emotion},\n pages = {\n          619-30\n        },\n title = {Age-related differences in emotion recognition ability: a cross-sectional study.},\n volume = {9 5},\n year = {2009}\n}\n'}","[{'authorId': '33098563', 'name': 'Aire Mill'}, {'authorId': '3467657', 'name': 'J. Allik'}, {'authorId': '3629800', 'name': 'A. Realo'}, {'authorId': '22334264', 'name': 'R. Valk'}]"
2649,e6834f74b95702987b6c51d3bd88fa394ef6bc51,The measurability and predictability of user experience,"User experience is an emerging research area with a range of issues to be resolved. Among them, the measurability of UX remains contentious. The key argument hinges on the meaningfulness, validity and usefulness of reducing fuzzy experiential qualities such as fun, challenge and trust to numbers. UX people seem ambivalent towards UX measures. In UX empirical studies, qualitative approaches are predominant, though the popular use of questionnaires in these studies suggests that some form of numeric measures is deemed useful or even necessary. The tension between the two camps (i.e. qualitative design-based and quantitative model-based) stimulates scientific discussions to bring the field forward. As measures may enable us to predict, the concomitant issue of UX predictability is explored. Besides, we look into theoretical frameworks that potentially contribute to a deeper understanding of UX. Of particular interest is theory of memory.",2011.0,52.0,127.0,False,,{'pages': '1-10'},"{'bibtex': '@Inproceedings{Law2011TheMA,\n author = {E. Law},\n pages = {1-10},\n title = {The measurability and predictability of user experience},\n year = {2011}\n}\n'}","[{'authorId': '1732194', 'name': 'E. Law'}]"
2650,e6bd15f3483bd2e54533802439864d86f7a307dc,Learning hatching for pen-and-ink illustration of surfaces,"This article presents an algorithm for learning hatching styles from line drawings. An artist draws a single hatching illustration of a 3D object. Her strokes are analyzed to extract the following per-pixel properties: hatching level (hatching, cross-hatching, or no strokes), stroke orientation, spacing, intensity, length, and thickness. A mapping is learned from input geometric, contextual, and shading features of the 3D object to these hatching properties, using classification, regression, and clustering techniques. Then, a new illustration can be generated in the artist's style, as follows. First, given a new view of a 3D object, the learned mapping is applied to synthesize target stroke properties for each pixel. A new illustration is then generated by synthesizing hatching strokes according to the target properties.",2012.0,52.0,572.0,False,,"{'volume': '31', 'pages': '1:1-1:17', 'name': 'ACM Trans. Graph.'}","{'bibtex': '@Article{Kalogerakis2012LearningHF,\n author = {E. Kalogerakis and D. Nowrouzezahrai and Simon Breslav and Aaron Hertzmann},\n journal = {ACM Trans. Graph.},\n pages = {1:1-1:17},\n title = {Learning hatching for pen-and-ink illustration of surfaces},\n volume = {31},\n year = {2012}\n}\n'}","[{'authorId': '2808670', 'name': 'E. Kalogerakis'}, {'authorId': '1795014', 'name': 'D. Nowrouzezahrai'}, {'authorId': '1984863', 'name': 'Simon Breslav'}, {'authorId': '1747779', 'name': 'Aaron Hertzmann'}]"
2651,e6c90f6194a2c2abcf3901c445ddc2af64a0911b,A Game-Based Approach to Examining Students' Conceptual Knowledge of Fractions,,2016.0,31.0,9.0,False,,{'pages': '37-49'},"{'bibtex': ""@Inproceedings{Ninaus2016AGA,\n author = {M. Ninaus and K. Kiili and Jake McMullen and K. Moeller},\n pages = {37-49},\n title = {A Game-Based Approach to Examining Students' Conceptual Knowledge of Fractions},\n year = {2016}\n}\n""}","[{'authorId': '1830315', 'name': 'M. Ninaus'}, {'authorId': '2916835', 'name': 'K. Kiili'}, {'authorId': '50683330', 'name': 'Jake McMullen'}, {'authorId': '3204648', 'name': 'K. Moeller'}]"
2652,e6d09d04fc8737094c193da471e2a50a809f77d4,Manual for the State-Trait Anxiety Inventory,"The STAI serves as an indicator of two types of anxiety, the state and trait anxiety, and measure the severity of the overall anxiety level.The STAI, which is appropriate for those who have at least a sixth grade reading level, contains four-point Likert items. The instrument is divided into two sections, each having twenty questions. Approximately 15 minutes are required for adults to complete the both STAI. The number on the scale is positively correlated to the anxiety related to in the question.",1970.0,0.0,24937.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Spielberger1970ManualFT,\n author = {C. Spielberger and R. Gorsuch and R. Lushene},\n title = {Manual for the State-Trait Anxiety Inventory},\n year = {1970}\n}\n'}","[{'authorId': '118670580', 'name': 'C. Spielberger'}, {'authorId': '5144541', 'name': 'R. Gorsuch'}, {'authorId': '50660087', 'name': 'R. Lushene'}]"
2653,e6d92b5fe5eca7ccfa6c9bd36081a05df9414a05,An Evaluation of WebTwig - A Site Outliner for Handheld Web Access,,1999.0,2.0,306.0,False,,{'pages': '343-345'},"{'bibtex': '@Inproceedings{Jones1999AnEO,\n author = {Matt Jones and G. Buchanan and N. Mohd-Nasir},\n pages = {343-345},\n title = {An Evaluation of WebTwig - A Site Outliner for Handheld Web Access},\n year = {1999}\n}\n'}","[{'authorId': '50604395', 'name': 'Matt Jones'}, {'authorId': '145705027', 'name': 'G. Buchanan'}, {'authorId': '1402145527', 'name': 'N. Mohd-Nasir'}]"
2654,e709201c10a53e55c0a79edef10b866e92cd4453,Facial age affects emotional expression decoding,"Facial expressions convey important information on emotional states of our interaction partners. However, in interactions between younger and older adults, there is evidence for a reduced ability to accurately decode emotional facial expressions. Previous studies have often followed up this phenomenon by examining the effect of the observers' age. However, decoding emotional faces is also likely to be influenced by stimulus features, and age-related changes in the face such as wrinkles and folds may render facial expressions of older adults harder to decode. In this paper, we review theoretical frameworks and empirical findings on age effects on decoding emotional expressions, with an emphasis on age-of-face effects. We conclude that the age of the face plays an important role for facial expression decoding. Lower expressivity, age-related changes in the face, less elaborated emotion schemas for older faces, negative attitudes toward older adults, and different visual scan patterns and neural processing of older than younger faces may lower decoding accuracy for older faces. Furthermore, age-related stereotypes and age-related changes in the face may bias the attribution of specific emotions such as sadness to older faces.",2014.0,104.0,107.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00030/pdf', 'status': None}","{'volume': '5', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Fölster2014FacialAA,\n author = {Mara Fölster and U. Hess and K. Werheid},\n journal = {Frontiers in Psychology},\n title = {Facial age affects emotional expression decoding},\n volume = {5},\n year = {2014}\n}\n'}","[{'authorId': '3510001', 'name': 'Mara Fölster'}, {'authorId': '3067657', 'name': 'U. Hess'}, {'authorId': '5487174', 'name': 'K. Werheid'}]"
2655,e721eec2db17866294bcb55111031a814048a9b0,Evaluation of a psycholinguistically motivated timing model for animations of american sign language,"Using results in the psycholinguistics literature on the speed and timing of American Sign Language (ASL), we built algorithms to calculate the time-duration of signs and the location/length of pauses during an ASL animation. We conducted a study in which native ASL signers evaluated the ASL animations processed by our algorithms, and we found that: (1) adding linguistically motivated pauses and variations in sign-durations improved signers' performance on a comprehension task and (2) these animations were rated as more understandable by ASL signers.",2008.0,21.0,38.0,True,"{'url': 'http://eniac.cs.qc.edu/matt/pubs/huenerfauth-2008-assets.pdf', 'status': None}",{'pages': '129-136'},"{'bibtex': '@Inproceedings{Huenerfauth2008EvaluationOA,\n author = {Matt Huenerfauth},\n pages = {129-136},\n title = {Evaluation of a psycholinguistically motivated timing model for animations of american sign language},\n year = {2008}\n}\n'}","[{'authorId': '1747703', 'name': 'Matt Huenerfauth'}]"
2656,e74d6a2d92e9f14534d9de8d17d6697ec2483f83,"Cognitive appraisal, emotion, and empathy","Contents: Part I:A Theoretical Overview: Cognitive Appraisal, Emotion, and Empathy. Introduction. Empathy. Cognitive Appraisal Theories of Emotions. The Relationship Between Appraisal and Empathy. Part II:Research Addressing Cognitive Appraisal, Emotion, and Empathy. The Generation of Real-Life Descriptions and Examination of Three Sets of Cognitive Appraisals. The Relationships Between Appraisals and Decoding Accuracy and Appraisals and Empathy. Responding to Scenarios. The Relationship Between Emotional Reactions and Memory. Part III:Summary, Theoretical Extensions, and Applications. Summary and Theoretical Discussion. Applications.",1995.0,0.0,129.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Omdahl1995CognitiveAE,\n author = {B. L. Omdahl},\n title = {Cognitive appraisal, emotion, and empathy},\n year = {1995}\n}\n'}","[{'authorId': '3642927', 'name': 'B. L. Omdahl'}]"
2657,e7659c1d3ab3051b7f4c78d878a7dde5c104537a,"A Follow-up Study of the Relationships among Trust, Disclosure, and Interpersonal Solidarity","This study conceptualized perceived trustworthiness of the individual, self-disclosure to the individual, perceived trustworthiness of people in general, and disclosive tendencies to other people in general to be indicants of a broader construct of trust. Self-disclosure and perceived trustworthiness of the individual were found to be related constructs assessing differential aspects of the trust construct. Likewise, self-disclosure and perceived trustworthiness of the individual were found to be criterial attributes of interpersonal solidarity. These communication-related phenomena indicated the solidarity of interpersonal relationships. In the progress of the research, a 20-item measure of perceived interpersonal solidarity was developed as a criterion for assessing the impact of communication-related variables on interpersonal relationships. Other exploratory research issues were investigated.",1978.0,24.0,420.0,False,,"{'volume': '4', 'pages': '143-157', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Wheeless1978AFS,\n author = {Lawrence R. Wheeless},\n journal = {Human Communication Research},\n pages = {143-157},\n title = {A Follow-up Study of the Relationships among Trust, Disclosure, and Interpersonal Solidarity},\n volume = {4},\n year = {1978}\n}\n'}","[{'authorId': '118894644', 'name': 'Lawrence R. Wheeless'}]"
2658,e77a404aad19c1f7197a0dbf986822b3ac6b29ac,EmbraceNet: A robust deep learning architecture for multimodal classification,,2019.0,53.0,89.0,True,"{'url': 'https://arxiv.org/pdf/1904.09078', 'status': None}","{'volume': '51', 'pages': '259-270', 'name': 'Inf. Fusion'}","{'bibtex': '@Article{Choi2019EmbraceNetAR,\n author = {Jun-Ho Choi and Jong-Seok Lee},\n journal = {Inf. Fusion},\n pages = {259-270},\n title = {EmbraceNet: A robust deep learning architecture for multimodal classification},\n volume = {51},\n year = {2019}\n}\n'}","[{'authorId': '150140898', 'name': 'Jun-Ho Choi'}, {'authorId': '2108780415', 'name': 'Jong-Seok Lee'}]"
2659,e78b1370eb38c842b1c280f78e08da04f2702a24,A generalized model of social and biological contagion.,,2005.0,37.0,381.0,True,"{'url': 'https://arxiv.org/pdf/1705.10783', 'status': None}","{'volume': '232 4', 'pages': '\n          587-604\n        ', 'name': 'Journal of theoretical biology'}","{'bibtex': '@Article{Dodds2005AGM,\n author = {P. Dodds and D. Watts},\n journal = {Journal of theoretical biology},\n pages = {\n          587-604\n        },\n title = {A generalized model of social and biological contagion.},\n volume = {232 4},\n year = {2005}\n}\n'}","[{'authorId': '2660575', 'name': 'P. Dodds'}, {'authorId': '1783914', 'name': 'D. Watts'}]"
2660,e7dbd9ba29c59c68a9dae9f40dfc4040476c4624,Feeling and Believing: The Influence of Emotion on Trust,"The authors report results from 5 experiments that describe the influence of emotional states on trust. They found that incidental emotions significantly influence trust in unrelated settings. Happiness and gratitude—emotions with positive valence—increase trust, and anger—an emotion with negative va-lence—decreases trust. Specifically, they found that emotions characterized by other-person control (anger and gratitude) and weak control appraisals (happiness) influence trust significantly more than emotions characterized by personal control (pride and guilt) or situational control (sadness). These findings suggest that emotions are more likely to be misattributed when the appraisals of the emotion are consistent with the judgment task than when the appraisals of the emotion are inconsistent with the judgment task. Emotions do not influence trust when individuals are aware of the source of their emotions or when individuals are very familiar with the trustee.",2005.0,62.0,1128.0,False,,,"{'bibtex': '@Inproceedings{Dunn2005FeelingAB,\n author = {Jennifer R Dunn and M. Schweitzer and Sigal G. Barsade and Rachel Croson and Jack Hershey and Howard C. Kunreuther and Robert Meyer and Nancy Rothbard and Deborah and Bryan Chao and Catherine Marks and Samantha Rudolph and Lauren Sokolowski and Liya and R. Dunn},\n title = {Feeling and Believing: The Influence of Emotion on Trust},\n year = {2005}\n}\n'}","[{'authorId': '49395952', 'name': 'Jennifer R Dunn'}, {'authorId': '1889202', 'name': 'M. Schweitzer'}, {'authorId': '1838029', 'name': 'Sigal G. Barsade'}, {'authorId': '2237804723', 'name': 'Rachel Croson'}, {'authorId': '2252561465', 'name': 'Jack Hershey'}, {'authorId': '2241415470', 'name': 'Howard C. Kunreuther'}, {'authorId': '2252085673', 'name': 'Robert Meyer'}, {'authorId': '2252855176', 'name': 'Nancy Rothbard'}, {'authorId': '2251689914', 'name': 'Deborah'}, {'authorId': '2252182640', 'name': 'Bryan Chao'}, {'authorId': '2252048107', 'name': 'Catherine Marks'}, {'authorId': '2252027618', 'name': 'Samantha Rudolph'}, {'authorId': '2252866335', 'name': 'Lauren Sokolowski'}, {'authorId': '74750104', 'name': 'Liya'}, {'authorId': '2252199027', 'name': 'R. Dunn'}]"
2662,e85d34f6af375d09b5563bb588aae2f9b06e7ff2,Are you convinced? A Wizard of Oz study to test emotional vs. rational persuasion strategies in dialogues,,2016.0,31.0,22.0,False,,"{'volume': '57', 'pages': '75-81', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Adler2016AreYC,\n author = {Rachel F. Adler and Francisco Iacobelli and Yehuda Gutstein},\n journal = {Comput. Hum. Behav.},\n pages = {75-81},\n title = {Are you convinced? A Wizard of Oz study to test emotional vs. rational persuasion strategies in dialogues},\n volume = {57},\n year = {2016}\n}\n'}","[{'authorId': '2685682', 'name': 'Rachel F. Adler'}, {'authorId': '1878195', 'name': 'Francisco Iacobelli'}, {'authorId': '3387186', 'name': 'Yehuda Gutstein'}]"
2663,e87031959451b2d9518a490bfabe308b1e265a62,Modeling pedestrian crowd behavior based on a cognitive model of social comparison theory,,2010.0,42.0,40.0,False,,"{'volume': '16', 'pages': '348-372', 'name': 'Computational and Mathematical Organization Theory'}","{'bibtex': '@Article{Fridman2010ModelingPC,\n author = {N. Fridman and G. Kaminka},\n journal = {Computational and Mathematical Organization Theory},\n pages = {348-372},\n title = {Modeling pedestrian crowd behavior based on\xa0a\xa0cognitive model of social comparison theory},\n volume = {16},\n year = {2010}\n}\n'}","[{'authorId': '144447024', 'name': 'N. Fridman'}, {'authorId': '1725049', 'name': 'G. Kaminka'}]"
2664,e87750d2db2af670833c8029de208920eef03e77,Transactions on Edutainment VI,,2011.0,0.0,11.0,False,,{'volume': '6758'},"{'bibtex': '@Inproceedings{Pan2011TransactionsOE,\n author = {Zhigeng Pan and A. Cheok and Wolfgang Müller},\n title = {Transactions on Edutainment VI},\n volume = {6758},\n year = {2011}\n}\n'}","[{'authorId': '145086315', 'name': 'Zhigeng Pan'}, {'authorId': '143699999', 'name': 'A. Cheok'}, {'authorId': '38477626', 'name': 'Wolfgang Müller'}]"
2665,e8b12467bdc20bde976750b8a28decdb33246d1d,Histograms of oriented gradients for human detection,"We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",2005.0,26.0,32546.0,True,"{'url': 'https://hal.inria.fr/inria-00548512/file/hog_cvpr2005.pdf', 'status': None}","{'volume': '1', 'pages': '886-893 vol. 1', 'name': ""2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)""}","{'bibtex': ""@Article{Dalal2005HistogramsOO,\n author = {Navneet Dalal and B. Triggs},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},\n pages = {886-893 vol. 1},\n title = {Histograms of oriented gradients for human detection},\n volume = {1},\n year = {2005}\n}\n""}","[{'authorId': '48950628', 'name': 'Navneet Dalal'}, {'authorId': '1756114', 'name': 'B. Triggs'}]"
2666,e8fa407b73585881e8af675b23009183ad9ffaac,Emotion regulation in autism: Reappraisal and suppression interactions,"Emotion regulation has been proposed to be a transdiagnostic factor in the development and maintenance of psychopathology in the general population, yet the nature of the relationships between emotion regulation strategy use and psychological well-being has not been comprehensively explored in individuals with autism spectrum disorder (ASD). The aim of this study was to assess how the individual differences in self-reported emotion regulation strategy use relate to levels of both positive and negative psychological well-being. In total, 56 individuals with ASD aged 14–24 years (Mage = 18.15; SDage = 2.30) completed Emotion Regulation Questionnaire, Diagnostic and Statistical Manual of Mental Disorders-5 Generalized Anxiety Disorder Dimensional Scale, Patient Health Questionnaire-9, Warwick-Edinburgh Mental Well-being Scale and Autism-Spectrum Quotient – Short. Individuals were grouped into four clusters based on their Emotion Regulation Questionnaire subscale scores. Individuals in the high suppression and low reappraisal group expressed higher depressive symptoms and lower positive well-being when compared with the low suppression and high reappraisal group. Interestingly, individuals who self-reported using both high suppression and reappraisal expressed relatively high positive well-being and low depression symptoms. We suggest that the maladaptive effect of habitual suppression usage may be buffered by the habitual use of reappraisal, and this interaction between adaptive and maladaptive emotion regulation strategy use has clinical implications.",2019.0,84.0,37.0,False,,"{'volume': '23', 'pages': '737 - 749', 'name': 'Autism'}","{'bibtex': '@Article{Cai2019EmotionRI,\n author = {R. Cai and A. Richdale and C. Dissanayake and J. Trollor and M. Uljarević},\n journal = {Autism},\n pages = {737 - 749},\n title = {Emotion regulation in autism: Reappraisal and suppression interactions},\n volume = {23},\n year = {2019}\n}\n'}","[{'authorId': '11450626', 'name': 'R. Cai'}, {'authorId': '6848517', 'name': 'A. Richdale'}, {'authorId': '4697606', 'name': 'C. Dissanayake'}, {'authorId': '143764000', 'name': 'J. Trollor'}, {'authorId': '5416756', 'name': 'M. Uljarević'}]"
2667,e90d4a805b9ce0c46211bfa971ec757d1148d5f9,On the Dominance of Moral Categories in Impression Formation,"Based on the notion that approach-avoidance underlies impression formation processes and that approach-avoidance is more directly based on appraisals of others' morality (M) than competence (C), we hypothesized that M-related information played a more important role at various phases of global impression formation than C-related information on target persons. In four studies (N = 342 university students), we predicted and found that (a) M traits showed a higher chronic accessibility than C traits; (b) when gathering information to formulate a global impression, perceivers were more interested in M traits than C traits; (c) global impressions of real persons were better predicted from M trait ascriptions than C trait ascriptions, and (d) positivity-negativity of impressions of fictitious persons was decided mainly by the M content of their behavior, whereas C information served as a weak modifier of impression intensity. The dominance of M traits over C traits was more pronounced for female perceivers than for male perceivers.",1998.0,33.0,607.0,False,,"{'volume': '24', 'pages': '1251 - 1263', 'name': 'Personality and Social Psychology Bulletin'}","{'bibtex': '@Article{Wojciszke1998OnTD,\n author = {B. Wojciszke and Róża Bazińska and Marcin Jaworski},\n journal = {Personality and Social Psychology Bulletin},\n pages = {1251 - 1263},\n title = {On the Dominance of Moral Categories in Impression Formation},\n volume = {24},\n year = {1998}\n}\n'}","[{'authorId': '2585858', 'name': 'B. Wojciszke'}, {'authorId': '13512301', 'name': 'Róża Bazińska'}, {'authorId': '20673990', 'name': 'Marcin Jaworski'}]"
2668,e919ade4a292e5f56bdb0a8d753c317edbedda08,Can a Virtual Agent provide good Emotional Support?,"In this study we explore whether an emotional support message sent to an informal carer by a Virtual Agent provides good quality emotional support, compared to the same message sent by a friend or sister with whom they have either a close, medium, or distant relationship. We also explore whether these judgements are affected by personality. Participants recruited from Mechanical Turk rated an emotional support message for Suitability, provided qualitative feedback about their rating and then completed a personality measure. We found that the support message was rated worst when it came from the Computer, Distant-sister and Close-friend. While these were rated worse, they were not rated poorly, implying that support from a computer is valuable. There were three effects for personality which did not vary with the support giver’s Identity: agreeableness and emotional stability had a positive correlation with 3 sub-scales of supportiveness. A thematic analysis of comments revealed that people prefer emotional support from a human; they like empathy; support from close friends means more; they prefer personalised support; and they have higher expectations from family over friends.",2018.0,34.0,7.0,True,"{'url': 'https://www.scienceopen.com/document_file/c6f27818-9750-4bda-ad20-c21f45d27a36/ScienceOpen/BHCI-2018_Smith.pdf', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Smith2018CanAV,\n author = {K. Smith and J. Masthoff},\n title = {Can a Virtual Agent provide good Emotional Support?},\n year = {2018}\n}\n'}","[{'authorId': '1400110905', 'name': 'K. Smith'}, {'authorId': '145428594', 'name': 'J. Masthoff'}]"
2669,e93c7d71074c0d4890915263c7c34711d41b6940,End-to-end learning for music audio,"Content-based music information retrieval tasks have traditionally been solved using engineered features and shallow processing architectures. In recent years, there has been increasing interest in using feature learning and deep architectures instead, thus reducing the required engineering effort and the need for prior knowledge. However, this new approach typically still relies on mid-level representations of music audio, e.g. spectrograms, instead of raw audio signals. In this paper, we investigate whether it is possible to apply feature learning directly to raw audio signals. We train convolutional neural networks using both approaches and compare their performance on an automatic tagging task. Although they do not outperform a spectrogram-based approach, the networks are able to autonomously discover frequency decompositions from raw audio, as well as phase-and translation-invariant feature representations.",2014.0,29.0,357.0,False,,"{'pages': '6964-6968', 'name': '2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","{'bibtex': '@Article{Dieleman2014EndtoendLF,\n author = {S. Dieleman and B. Schrauwen},\n journal = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {6964-6968},\n title = {End-to-end learning for music audio},\n year = {2014}\n}\n'}","[{'authorId': '48373216', 'name': 'S. Dieleman'}, {'authorId': '2621946', 'name': 'B. Schrauwen'}]"
2670,e93c87956c86124be936cfa483e1cb960985db61,Automatic behavior descriptors for psychological disorder analysis,"We investigate the capabilities of automatic nonverbal behavior descriptors to identify indicators of psychological disorders such as depression, anxiety, and post-traumatic stress disorder. We seek to confirm and enrich present state of the art, predominantly based on qualitative manual annotations, with automatic quantitative behavior descriptors. In this paper, we propose four nonverbal behavior descriptors that can be automatically estimated from visual signals. We introduce a new dataset called the Distress Assessment Interview Corpus (DAIC) which includes 167 dyadic interactions between a confederate interviewer and a paid participant. Our evaluation on this dataset shows correlation of our automatic behavior descriptors with specific psychological disorders as well as a generic distress measure. Our analysis also includes a deeper study of self-adaptor and fidgeting behaviors based on detailed annotations of where these behaviors occur.",2013.0,35.0,135.0,True,"{'url': 'https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.373.2333&rep=rep1&type=pdf', 'status': None}","{'pages': '1-8', 'name': '2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)'}","{'bibtex': '@Article{Scherer2013AutomaticBD,\n author = {Stefan Scherer and Giota Stratou and M. Mahmoud and Jill Boberg and J. Gratch and A. Rizzo and Louis-Philippe Morency},\n journal = {2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},\n pages = {1-8},\n title = {Automatic behavior descriptors for psychological disorder analysis},\n year = {2013}\n}\n'}","[{'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '97930679', 'name': 'M. Mahmoud'}, {'authorId': '6349590', 'name': 'Jill Boberg'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2671,e955e0494432192cd815eaff3f5cc3787e272c3e,Recognition of posed and genuine facial expressions of emotion in paranoid and nonparanoid schizophrenia.,"Most previous research reporting emotion-recognition deficits in schizophrenia has used posed facial expressions of emotion and chronic-schizophrenia patients. In contrast, the present research examined the ability of patients with acute paranoid and nonparanoid (disorganized) schizophrenia to recognize genuine as well as posed facial expressions of emotion. Evidence of an emotion-recognition deficit in schizophrenia was replicated, but only when posed facial expressions were used. For genuine expressions of emotion, the paranoid-schizophrenia group was more accurate than controls, nonparanoid-schizophrenia patients, and depressed patients. Future research clearly needs to consider the posed versus genuine nature of the emotional stimuli used and the type of schizophrenia patients examined.",2000.0,27.0,107.0,False,,"{'volume': '109 3', 'pages': '\n          445-50\n        ', 'name': 'Journal of abnormal psychology'}","{'bibtex': '@Article{Davis2000RecognitionOP,\n author = {P. Davis and Melissa G. Gibson},\n journal = {Journal of abnormal psychology},\n pages = {\n          445-50\n        },\n title = {Recognition of posed and genuine facial expressions of emotion in paranoid and nonparanoid schizophrenia.},\n volume = {109 3},\n year = {2000}\n}\n'}","[{'authorId': '49256264', 'name': 'P. Davis'}, {'authorId': '2236343193', 'name': 'Melissa G. Gibson'}]"
2672,e96afe23bd651075504f73bb622aabd9cdc43925,"Multimodal Emotion Expressions of Virtual Agents, Mimic and Vocal Emotion Expressions and Their Effects on Emotion Recognition","Emotional expressions of virtual agents are widely believed to enhance the interaction with the user by utilizing more natural means of communication. However, as a result of the current technology virtual agents are often only able to produce facial expressions to convey emotional meaning. The presented research investigates the effects of unimodal vs. multimodal expressions of emotions on the users' recognition of the respective emotional state. We found that multimodal expressions of emotions yield the highest recognition rates. Additionally, emotionally neutral cues in one modality, when presented together with emotionally relevant cues in the other modality, impair the recognition of the correct emotion category as well as intense emotional states.",2013.0,25.0,15.0,False,,"{'pages': '405-410', 'name': '2013 Humaine Association Conference on Affective Computing and Intelligent Interaction'}","{'bibtex': '@Article{Liebold2013MultimodalEE,\n author = {Benny Liebold and P. Ohler},\n journal = {2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},\n pages = {405-410},\n title = {Multimodal Emotion Expressions of Virtual Agents, Mimic and Vocal Emotion Expressions and Their Effects on Emotion Recognition},\n year = {2013}\n}\n'}","[{'authorId': '2561845', 'name': 'Benny Liebold'}, {'authorId': '2268622', 'name': 'P. Ohler'}]"
2673,e9750c1fba2133c7d8ac35003ba29e84ad78f700,Bodily expression of emotion,,2009.0,0.0,517.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Mortillaro2009BodilyEO,\n author = {M. Mortillaro and K. Scherer},\n title = {Bodily expression of emotion},\n year = {2009}\n}\n'}","[{'authorId': '37837552', 'name': 'M. Mortillaro'}, {'authorId': '2462740', 'name': 'K. Scherer'}]"
2674,e988e0ceb4df785e076d61434b75a5ce3dbcccee,Virtual Reality Cyberspace: Challenges to Communication Studies,"This paper describes the most dramatic development within the new generation of computer-based media currently emerging, that of virtual reality/cyberspace. This discussion presents a number of challenges to the field of communication studies: to deal with the technosphere; to articulate the continuous discontinuity in communication technology; to avoid the threat of the ultimate second reality, and to benefit from the opportunity of the ultimate writing/drawing space.",1995.0,0.0,1.0,True,"{'url': 'https://ijvr.eu/article/download/2597/8655', 'status': None}","{'volume': '1', 'pages': '22-27', 'name': 'Int. J. Virtual Real.'}","{'bibtex': '@Article{Gardiner1995VirtualRC,\n author = {W. Gardiner},\n journal = {Int. J. Virtual Real.},\n pages = {22-27},\n title = {Virtual Reality Cyberspace: Challenges to Communication Studies},\n volume = {1},\n year = {1995}\n}\n'}","[{'authorId': '12595264', 'name': 'W. Gardiner'}]"
2675,e9bec8451b0a3e4a736c9902272a88d3e16dbb54,Achieving affective human–virtual agent communication by enabling virtual agents to imitate positive expressions,,2020.0,49.0,14.0,True,"{'url': 'https://www.nature.com/articles/s41598-020-62870-7.pdf', 'status': 'GOLD'}","{'name': 'Scientific Reports', 'volume': '10'}","{'bibtex': '@Article{Numata2020AchievingAH,\n author = {Takashi Numata and Hiroki Sato and Yasuhiro Asa and T. Koike and Kohei Miyata and E. Nakagawa and M. Sumiya and N. Sadato},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Achieving affective human–virtual agent communication by enabling virtual agents to imitate positive expressions},\n volume = {10},\n year = {2020}\n}\n'}","[{'authorId': '2069073454', 'name': 'Takashi Numata'}, {'authorId': None, 'name': 'Hiroki Sato'}, {'authorId': '2661328', 'name': 'Yasuhiro Asa'}, {'authorId': '2816538', 'name': 'T. Koike'}, {'authorId': '1611005390', 'name': 'Kohei Miyata'}, {'authorId': '38381724', 'name': 'E. Nakagawa'}, {'authorId': '38719428', 'name': 'M. Sumiya'}, {'authorId': '1843699', 'name': 'N. Sadato'}]"
2676,ea0a40e9070e85cefd5e468db645018bb2f573e7,Episodic Memory Assessment and Remediation in Normal and Pathological Aging Using Virtual Reality: A Mini Review,"Life expectancy is constantly increasing in developed countries. Unfortunately, a longer life does not always correspond to a healthier life, as even normal aging is associated with cognitive decline and increased risk factors for neurodegenerative diseases. Episodic memory (EM) is one of the most vulnerable cognitive functions in aging, and its decline is the hallmark of typical Alzheimer’s disease. This memory system is defined as the ability to acquire and recollect personally experienced episodes associated with a specific affective, spatial, and temporal context. However, most of the neuropsychological and experimental tasks currently employed to assess EM consist in learning simple material (e.g., list of words) in highly stereotyped contexts. In the same vein, classical paper-and-pencil or numeric remediation tools have shown their limitations in the transfer of acquired skills to daily life. Virtual reality (VR), thanks to its immersive properties, and the possibility of delivering realistic and complex scenarios, seems a promising tool to address the limitations of the assessment and remediation of EM. Here, we review existing studies employing VR in normal and pathological aging to assess and reeducate EM. Overall, we show that VR has been mainly used via non-immersive systems. Further studies should, therefore, test the impact of different degrees of immersion. Moreover, there is a lack of VR remediation tools specifically targeting EM. We propose that future studies should fill this gap, addressing in particular the adaptivity of VR remediation protocols.",2019.0,43.0,35.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00173/pdf', 'status': None}","{'volume': '10', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Corte2019EpisodicMA,\n author = {V. La Corte and Marco Sperduti and Kouloud Abichou and P. Piolino},\n journal = {Frontiers in Psychology},\n title = {Episodic Memory Assessment and Remediation in Normal and Pathological Aging Using Virtual Reality: A Mini Review},\n volume = {10},\n year = {2019}\n}\n'}","[{'authorId': '88741266', 'name': 'V. La Corte'}, {'authorId': '2876177', 'name': 'Marco Sperduti'}, {'authorId': '5259482', 'name': 'Kouloud Abichou'}, {'authorId': '2395089', 'name': 'P. Piolino'}]"
2677,ea17b18ee2fc5ebfb8495da1891e97c24212ee1c,Enhancing the Perceived Emotional Intelligence of Conversational Agents through Acoustic Cues,"The perceived emotional intelligence of a conversational agent (CA) can significantly impact people’s interaction with the CA. Prior research applies text-based sentiment analysis and emotional response generation to improve CAs’ emotional intelligence. However, acoustic features in speech containing rich contexts are underexploited. In this work, we designed and implemented an emotionally aware CA, called HUE (Heard yoUr Emotion) that stylized responses with emotion regulation strategies and empathetic interjections. We conducted a user study with 75 participants to evaluate their perceived emotional intelligence (PEI) of HUE by having them observe conversations between people and HUE in different emotional scenarios. Our results show that participants’ PEI was significantly higher with the acoustic features than without.",2021.0,47.0,10.0,False,,{'name': 'Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Hu2021EnhancingTP,\n author = {Jiaxiong Hu and Yun Huang and Xiaozhu Hu and Ying-Qing Xu},\n journal = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},\n title = {Enhancing the Perceived Emotional Intelligence of Conversational Agents through Acoustic Cues},\n year = {2021}\n}\n'}","[{'authorId': '3218976', 'name': 'Jiaxiong Hu'}, {'authorId': '2108831382', 'name': 'Yun Huang'}, {'authorId': '2109834302', 'name': 'Xiaozhu Hu'}, {'authorId': '2118669839', 'name': 'Ying-Qing Xu'}]"
2678,ea1f99b89687b040b1753e09b9945e08c2fb144a,A computational model based on Gross’ emotion regulation theory,,2010.0,71.0,67.0,True,"{'url': 'http://www.cs.vu.nl/~wai/Papers/CSR09emreg.pdf', 'status': None}","{'volume': '11', 'pages': '211-230', 'name': 'Cognitive Systems Research'}","{'bibtex': '@Article{Bosse2010ACM,\n author = {T. Bosse and M. Pontier and Jan Treur},\n journal = {Cognitive Systems Research},\n pages = {211-230},\n title = {A computational model based on Gross’ emotion regulation theory},\n volume = {11},\n year = {2010}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '1976147', 'name': 'M. Pontier'}, {'authorId': '1726343', 'name': 'Jan Treur'}]"
2679,ea46dc1d34ad3a4c769f2b12e306eb2cf6b33fe3,A Survey on Databases of Facial Macro-expression and Micro-expression,,2018.0,78.0,7.0,False,,{'pages': '298-325'},"{'bibtex': '@Inproceedings{Weber2018ASO,\n author = {Raphaël Weber and Jingting Li and Catherine Soladié and R. Séguier},\n pages = {298-325},\n title = {A Survey on Databases of Facial Macro-expression and Micro-expression},\n year = {2018}\n}\n'}","[{'authorId': '34363618', 'name': 'Raphaël Weber'}, {'authorId': '49297714', 'name': 'Jingting Li'}, {'authorId': '1704722', 'name': 'Catherine Soladié'}, {'authorId': '1697632', 'name': 'R. Séguier'}]"
2680,ea62f31b963af1639ae655c023f17fee8881c70f,Natural Language Processing and Artificial Intelligence for Enterprise Management in the Era of Industry 4.0,"Introduction: The advances in the digital era have necessitated the adoption of communication as the main channel for modern business. In the past, business negotiations, profiling, seminars, shopping, and agreements were in-person but today everything is almost digitalized. Objectives: The study aims to examine how the Internet of things (IoTs) connects text-object as part of NLP and AI responding to human needs. Also, how precipitated changes in the business environment and modern applications such as NLP and AI embedded with IoTs services have changed business settings. Problem statement: As communication takes lead in the business environment, companies have developed sophisticated applications of NLP that take human desires and fulfill them instantly with the help of text, phone calls, smart records, and chatbots. The ease of communication and interaction has shown a greater influence on customer choice, desires, and needs. Modern service providers now use email, text, phone calls, smart records, and virtual assistants as first contact points for almost all of their dealings, customer inquiries, and most preferred trading channels. Method: The study uses text content as part of NLP and AI to demonstrate how companies capture customers’ insight and how they use IoTs to influence customers’ reactions, responses, and engagement with enterprise management in Industry 4.0. The “Behavior-oriented drive and influential function of IoTs on Customers in Industry 4.0” concept was used in this study to determine the influence of Industry 4.0 on customers. Results: The result indicates the least score of 12 out of 15 grades for all the measurements on a behavior-oriented drive and influential function of IoTs on customers. Conclusion: The study concluded that NLP and AI are the preferred system for enterprise management in the era of Industry 4.0 to understand customers’ demands and achieve customer satisfaction. Therefore, NLP and AI techniques are a necessity to attain business goals.",2022.0,54.0,7.0,True,"{'url': 'https://www.mdpi.com/2076-3417/12/18/9207/pdf?version=1663238856', 'status': None}",{'name': 'Applied Sciences'},"{'bibtex': '@Article{Mah2022NaturalLP,\n author = {Pascal Muam Mah and I. Skalna and John Muzam},\n journal = {Applied Sciences},\n title = {Natural Language Processing and Artificial Intelligence for Enterprise Management in the Era of Industry 4.0},\n year = {2022}\n}\n'}","[{'authorId': '2162544284', 'name': 'Pascal Muam Mah'}, {'authorId': '2126378', 'name': 'I. Skalna'}, {'authorId': '2155036804', 'name': 'John Muzam'}]"
2681,ea65e67fdb5152afd234d0f300be1770144e62b9,Render me real?,"The realistic depiction of lifelike virtual humans has been the goal of many movie makers in the last decade. Recently, films such as Tron: Legacy and The Curious Case of Benjamin Button have produced highly realistic characters. In the real-time domain, there is also a need to deliver realistic virtual characters, with the increase in popularity of interactive drama video games (such as L.A. Noire™ or Heavy Rain™). There have been mixed reactions from audiences to lifelike characters used in movies and games, with some saying that the increased realism highlights subtle imperfections, which can be disturbing. Some developers opt for a stylized rendering (such as cartoon-shading) to avoid a negative reaction [Thompson 2004]. In this paper, we investigate some of the consequences of choosing realistic or stylized rendering in order to provide guidelines for developers for creating appealing virtual characters. We conducted a series of psychophysical experiments to determine whether render style affects how virtual humans are perceived. Motion capture with synchronized eye-tracked data was used throughout to animate custom-made virtual model replicas of the captured actors.",2012.0,26.0,154.0,False,,"{'volume': '31', 'pages': '1 - 11', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Mcdonnell2012RenderMR,\n author = {R. Mcdonnell and M. Breidt and H. Bülthoff},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 11},\n title = {Render me real?},\n volume = {31},\n year = {2012}\n}\n'}","[{'authorId': '145795454', 'name': 'R. Mcdonnell'}, {'authorId': '2016068', 'name': 'M. Breidt'}, {'authorId': '1747836', 'name': 'H. Bülthoff'}]"
2683,ea71c0b845a3eb8c09ee3352d6cd4c26d88981d4,How people anthropomorphize robots,"We explored anthropomorphism in people's reactions to a robot in social context vs. their more considered judgments of robots in the abstract. Participants saw a photo and read transcripts from a health interview by a robot or human interviewer. For half of the participants, the interviewer was polite and for the other half, the interviewer was impolite. Participants then summarized the interactions in their own words and responded true or false to adjectives describing the interviewer. They later completed a post-task survey about whether a robot interviewer would possess moods, attitudes, and feelings. The results showed substantial anthropomorphism in participants' interview summaries and true-false responses, but minimal anthropomorphism in the abstract robot survey. Those who interacted with the robot interviewer tended to anthropomorphize more in the post-task survey, suggesting that as people interact more with robots, their abstract conceptions of them will become more anthropomorphic.",2008.0,32.0,169.0,False,,"{'pages': '145-152', 'name': '2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Fussell2008HowPA,\n author = {Susan R. Fussell and S. Kiesler and Leslie D. Setlock and Victoria Yew},\n journal = {2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {145-152},\n title = {How people anthropomorphize robots},\n year = {2008}\n}\n'}","[{'authorId': '1692772', 'name': 'Susan R. Fussell'}, {'authorId': '47198673', 'name': 'S. Kiesler'}, {'authorId': '3190175', 'name': 'Leslie D. Setlock'}, {'authorId': '2079677', 'name': 'Victoria Yew'}]"
2684,ea8467e1d26f472a5fc8579d0fc8372149283acc,Socially Supported by an Embodied Agent: The Development of a Virtual-Reality Paradigm to Study Social Emotion Regulation,"Social emotion regulation, which can be understood as the intentional efforts by one person to regulate emotions of another person, is something we encounter and benefit from every day, and becomes especially important when a person is unable to handle an emotion or an emotional event by themselves. A paradigm that examines whether someone can perceive and benefit from regulatory efforts by another person, represented here by a virtual agent, would be highly relevant for experimental studies investigating social emotion regulation, as well as for interventions in the clinical and sub-clinical context. Virtual reality (VR) provides perhaps the ideal opportunity to test social interactions and difficulties with them, as it counters typical methodological problems of behavioral experiments, such as the trade-off between ecological validity and experimental control, as well as the difficulty of replicating social situations. The goal of the present methods paper is twofold: to provide a detailed description of the development of a novel paradigm consisting of two scenarios in VR designed to test the efficacy of social emotion regulation, and to present the anticipated results for the target populations of typically developing and autistic youth. Participants are presented with a virtual school environment and take part in two activities with a class of students and a teacher, all of whom are virtual agents. In both scenarios, participants experience a potentially stressful situation and are subsequently offered emotional support by a friendly student. Throughout the experiment, self-reports in the form of virtual smiley scales and psychophysiological measurements are collected as markers of the participants’ emotional states. Pilot results will be discussed in line with anticipated outcomes, to indicate that the experiment will be able to show the efficacy of social support by a virtual agent and provide insight into social emotion regulation for different populations. The school environment and the character of the friendly student also have the potential to be adapted for follow-up experiments on additional aspects of social emotion regulation for a variety of contexts.",2022.0,53.0,0.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frvir.2022.826241/pdf', 'status': 'GOLD'}",{'volume': '3'},"{'bibtex': '@Article{Stallmann2022SociallySB,\n author = {Lina Stallmann and Daniel Dukes and Michel Tran and Valentin Durand de Gevigney and D. Rudrauf and Andrea C. Samson},\n booktitle = {Frontiers in Virtual Reality},\n title = {Socially Supported by an Embodied Agent: The Development of a Virtual-Reality Paradigm to Study Social Emotion Regulation},\n volume = {3},\n year = {2022}\n}\n'}","[{'authorId': '2124332447', 'name': 'Lina Stallmann'}, {'authorId': '39779139', 'name': 'Daniel Dukes'}, {'authorId': '2054039824', 'name': 'Michel Tran'}, {'authorId': '2158785974', 'name': 'Valentin Durand de Gevigney'}, {'authorId': '3090887', 'name': 'D. Rudrauf'}, {'authorId': '38707445', 'name': 'Andrea C. Samson'}]"
2685,ea9e5040ea1a1676774e740c932236baac8fef7d,Human-Centric Preference Modeling for Virtual Agents,"Intelligent virtual agents increasingly use machine learning to model the needs and preferences of their users in order to give personalized support. In this paper we present a vision of ""human-centric modeling"" that moves this practice beyond the automated estimation of users' current preferences based on observable behaviors to a modeling process that a) considers users' hidden characteristics rather than observable behaviors, b) models possible futures rather than users' current state, and c) gives users an opportunity to interactively control this modeling process. This vision focuses on the long-term needs of individual humans and a genuine betterment of society.",2020.0,41.0,1.0,False,,{'name': 'Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Knijnenburg2020HumanCentricPM,\n author = {Bart P. Knijnenburg and N. Hubig},\n journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},\n title = {Human-Centric Preference Modeling for Virtual Agents},\n year = {2020}\n}\n'}","[{'authorId': '2477993', 'name': 'Bart P. Knijnenburg'}, {'authorId': '1999324', 'name': 'N. Hubig'}]"
2686,eae14f22145d2b9a86078da80b24994c0d5e2d11,From motion control to emotion influence: controlling autonomous synthetic characters in a computer game,"This paper discusses the concept of ""influence"", as an alternative to ""direct"" control of game characters, describing how influence can be achieved in computer games. To illustrate the notion of influence we will briefly present a game called FantasyA where players interact with it by influencing the emotions of their semi-autonomous avatars using a tangible interface called SenToy. We show how ""influence"" was built into this game, the role of SenToy as an influencing device, and the reactions of the users to this type of control.",2004.0,5.0,3.0,False,,"{'pages': '1302-1303', 'name': 'Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.'}","{'bibtex': '@Article{Vala2004FromMC,\n author = {M. Vala and Ana Paiva and R. Prada},\n journal = {Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.},\n pages = {1302-1303},\n title = {From motion control to emotion influence: controlling autonomous synthetic characters in a computer game},\n year = {2004}\n}\n'}","[{'authorId': '7306645', 'name': 'M. Vala'}, {'authorId': '145136631', 'name': 'Ana Paiva'}, {'authorId': '143825592', 'name': 'R. Prada'}]"
2687,eafa0467039ebf2aff4409e3627b4dc7875fc76c,Why do children abuse robots,"We found that children sometimes abused a social robot placed in a shopping mall hallway. They verbally abused the robot, repeatedly obstructed its path, and sometimes even kicked and punched the robot. To investigate the reasons for the abuse, we conducted a field study in which we interviewed visiting children who exhibited serious abusive behaviors, including physical contact. We analyzed interview contents to determine whether the children perceived the robot as human-like, why they abused it, and whether they thought that the robot would suffer from their abusive behavior. We obtained valid interviews from 23 children (age range, 5–9 years old) over 13 days of observations. We found that 1) the majority of the children engaged in abuse because they were curious about the robot’s reactions or enjoyed abusing it and considered it human-like, and 2) about half of them believed the robot was capable of perceiving their abusive behaviors.",2016.0,25.0,44.0,False,,"{'volume': '17', 'pages': '347-369', 'name': 'Interaction Studies'}","{'bibtex': '@Article{Nomura2016WhyDC,\n author = {T. Nomura and T. Kanda and Hiroyoshi Kidokoro and Yoshitaka Suehiro and Sachie Yamada},\n journal = {Interaction Studies},\n pages = {347-369},\n title = {Why do children abuse robots},\n volume = {17},\n year = {2016}\n}\n'}","[{'authorId': '1768404', 'name': 'T. Nomura'}, {'authorId': '48309591', 'name': 'T. Kanda'}, {'authorId': '119331208', 'name': 'Hiroyoshi Kidokoro'}, {'authorId': '1814875', 'name': 'Yoshitaka Suehiro'}, {'authorId': '1895054', 'name': 'Sachie Yamada'}]"
2688,eafda8a94e410f1ad53b3e193ec124e80d57d095,Observer-based measurement of facial expression with the Facial Action Coding System.,"to name a few. Because of its importance to the study of emotion, a number of observer-based systems of facial expression measurement have been developed Using FACS and viewing video-recorded facial behavior at frame rate and slow motion, coders can manually code nearly all possible facial expressions, which are decomposed into action units (AUs). Action units, with some qualifications , are the smallest visually discriminable facial movements. By comparison, other systems are less thorough (Malatesta et al., 1989), fail to differentiate between some anatomically distinct movements (Oster, Hegley, & Nagel, 1992), consider movements that are not anatomically distinct as separable (Oster et al., 1992), and often assume a one-to-one mapping between facial expression and emotion (for a review of these systems, see Cohn & Ekman, in press). Unlike systems that use emotion labels to describe expression , FACS explicitly distinguishes between facial actions and inferences about what they mean. FACS itself is descriptive and includes no emotion-specified descriptors. Hypotheses and inferences about the emotional meaning of facial actions are extrinsic to FACS. If one wishes to make emotion based inferences from FACS codes, a variety of related resources exist. These include the FACS Investigators' Guide These resources suggest combination rules for defining emotion-specified expressions from FACS action units, but this inferential step remains extrinsic to FACS. Because of its descriptive power, FACS is regarded by many as the standard measure for facial behavior and is used widely in diverse fields. Beyond emotion science, these include facial neuromuscular disorders",2007.0,93.0,336.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Cohn2007ObserverbasedMO,\n author = {J. Cohn and Z. Ambadar and P. Ekman},\n title = {Observer-based measurement of facial expression with the Facial Action Coding System.},\n year = {2007}\n}\n'}","[{'authorId': '1737918', 'name': 'J. Cohn'}, {'authorId': '2059653', 'name': 'Z. Ambadar'}, {'authorId': '21451088', 'name': 'P. Ekman'}]"
2689,eb08f02249c4cdbc858202fa0d2e38c43fc084c9,Multifaceted Nature of Intrinsic Motivation: The Theory of 16 Basic Desires,"R. W. White (1959) proposed that certain motives, such as curiosity, autonomy, and play (called intrinsic motives, or IMs), have common characteristics that distinguish them from drives. The evidence that mastery is common to IMs is anecdotal, not scientific. The assertion that “intrinsic enjoyment” is common to IMs exaggerates the significance of pleasure in human motivation and expresses the hedonistic fallacy of confusing consequence for cause. Nothing has been shown scientifically to be common to IMs that differentiates them from drives. An empirically testable theory of 16 basic desires is put forth based on psychometric research and subsequent behavior validation. The desires are largely unrelated to each other and may have different evolutionary histories.",2004.0,52.0,529.0,False,,"{'volume': '8', 'pages': '179 - 193', 'name': 'Review of General Psychology'}","{'bibtex': '@Article{Reiss2004MultifacetedNO,\n author = {S. Reiss},\n journal = {Review of General Psychology},\n pages = {179 - 193},\n title = {Multifaceted Nature of Intrinsic Motivation: The Theory of 16 Basic Desires},\n volume = {8},\n year = {2004}\n}\n'}","[{'authorId': '116568668', 'name': 'S. Reiss'}]"
2690,eb27f32ea9b872eae50c16fef9ea35e30384a0d3,"Signs of appeasement: evidence for the distinct displays of embarrassment, amusement, and shame","According to appeasement hypotheses, embarrassment should have a distinct nonverbal display that is more readily perceived when displayed by individuals from lower status groups. The evidence from 5 studies supported these two claims. The nonverbal behavior of embarrassment was distinct from a related emotion (amusement), resembled the temporal pattern of facial expressions of emotion, was uniquely related to self-reports of embarrassment, and was accurately identified by observers who judged the spontaneous displays of various emotions. Across the judgment studies, observers were more accurate and attributed more emotion to the embarrassment displays of female and AfricanAmerican targets than those of male and Caucasian targets. Discussion focused on the universality and appeasement function of the embarrassment display. Since universal facial expressions of a limited set of emotions were first documented (Ekman & Friesen, 1971; Ekman, Sorenson, & Friesen, 1969; Izard, 1971), sparse attention has been given to facial expressions of other emotions. The resulting lacuna in the field—that the emotions with identified displays are fewer (7 to 10) than the states that lay people (Fehr & Russell, 1984) and emotion theorists (Ekman, 1992; Izard, 1977; Tomkins, 1963, 1984) label as emotions—presents intriguing possibilities. Displays of other emotions may be blends of other emotional displays, unidentifiable, or may await discovery.",1995.0,63.0,757.0,False,,"{'volume': '68', 'pages': '441-454', 'name': 'Journal of Personality and Social Psychology'}","{'bibtex': '@Article{Keltner1995SignsOA,\n author = {D. Keltner},\n journal = {Journal of Personality and Social Psychology},\n pages = {441-454},\n title = {Signs of appeasement: evidence for the distinct displays of embarrassment, amusement, and shame},\n volume = {68},\n year = {1995}\n}\n'}","[{'authorId': '3990536', 'name': 'D. Keltner'}]"
2691,eb2f3fa0017c42c7171659f870373b21d17c7889,"A demonstration of the perception system in SimSensei, a virtual human application for healthcare interviews","We present the SimSensei system, a fully automatic virtual agent that conducts interviews to assess indicators of psychological distress. With this demo, we focus our attention on the perception part of the system, a multimodal framework which captures and analyzes user state behavior for both behavioral understanding and interactional purposes. We will demonstrate real-time user state sensing as a part of the SimSensei architecture and discuss how this technology enabled automatic analysis of behaviors related to psychological distress.",2015.0,15.0,18.0,False,,"{'pages': '787-789', 'name': '2015 International Conference on Affective Computing and Intelligent Interaction (ACII)'}","{'bibtex': '@Article{Stratou2015ADO,\n author = {Giota Stratou and Louis-Philippe Morency and D. DeVault and Arno Hartholt and Edward Fast and Margot Lhommet and Gale M. Lucas and Fabrizio Morbini and Kallirroi Georgila and Stefan Scherer and J. Gratch and S. Marsella and D. Traum and A. Rizzo},\n journal = {2015 International Conference on Affective Computing and Intelligent Interaction (ACII)},\n pages = {787-789},\n title = {A demonstration of the perception system in SimSensei, a virtual human application for healthcare interviews},\n year = {2015}\n}\n'}","[{'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '144662324', 'name': 'D. DeVault'}, {'authorId': '1705118', 'name': 'Arno Hartholt'}, {'authorId': '2432742', 'name': 'Edward Fast'}, {'authorId': '1930380', 'name': 'Margot Lhommet'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '2223582', 'name': 'Fabrizio Morbini'}, {'authorId': '3194430', 'name': 'Kallirroi Georgila'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '29861580', 'name': 'A. Rizzo'}]"
2692,eb3e9a585515c2b627c24dfb780e878bcbfcfa32,WITHDRAWN: Case study: Embodied virtual agents: An analysis on reasons for failure,,2012.0,50.0,3.0,True,,"{'volume': '', 'name': 'Journal of Retailing and Consumer Services'}","{'bibtex': '@Article{Mimoun2012WITHDRAWNCS,\n author = {Mohammed Slim Ben Mimoun and Ingrid Poncin and Marion Garnier},\n journal = {Journal of Retailing and Consumer Services},\n title = {WITHDRAWN: Case study: Embodied virtual agents: An analysis on reasons for failure},\n year = {2012}\n}\n'}","[{'authorId': '51137959', 'name': 'Mohammed Slim Ben Mimoun'}, {'authorId': '18163606', 'name': 'Ingrid Poncin'}, {'authorId': '2080261', 'name': 'Marion Garnier'}]"
2693,eb42cf88027de515750f230b23b1a057dc782108,Very Deep Convolutional Networks for Large-Scale Image Recognition,"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",2014.0,43.0,83880.0,False,,"{'volume': 'abs/1409.1556', 'name': 'CoRR'}","{'bibtex': '@Article{Simonyan2014VeryDC,\n author = {K. Simonyan and Andrew Zisserman},\n journal = {CoRR},\n title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},\n volume = {abs/1409.1556},\n year = {2014}\n}\n'}","[{'authorId': '34838386', 'name': 'K. Simonyan'}, {'authorId': '1688869', 'name': 'Andrew Zisserman'}]"
2694,eb5583763621788b6a1c8dfe25091dc20a21e4b1,"An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study","Background A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods.",2018.0,55.0,341.0,True,"{'url': 'https://jmir.org/api/download?alt_name=mhealth_v6i11e12106_app2.pdf', 'status': None}","{'volume': '6', 'name': 'JMIR mHealth and uHealth'}","{'bibtex': '@Article{Inkster2018AnEC,\n author = {B. Inkster and Shubhankar Sarda and V. Subramanian},\n journal = {JMIR mHealth and uHealth},\n title = {An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study},\n volume = {6},\n year = {2018}\n}\n'}","[{'authorId': '46691130', 'name': 'B. Inkster'}, {'authorId': '51961236', 'name': 'Shubhankar Sarda'}, {'authorId': '20764756', 'name': 'V. Subramanian'}]"
2695,eb67f1f49ff5b24886075b1ccf77f423db8bfaf2,Embodied contextual agent in information delivering application,"We aim at building a new human-computer interface for Information Delivering applications: the conversational agent that we have developed is a multimodal believable agent able to converse with the User by exhibiting a synchronized and coherent verbal and nonverbal behavior. The agent is provided with a personality and a social role, that allows her to show her emotion or to refrain from showing it, depending on the context in which the conversation takes place. The agent is provided with a face and a mind. The mind is designed according to a BDI structure that depends on the agent's personality; it evolves dynamically during the conversation, according to the User's dialog moves and to emotions triggered as a consequence of the Interlocutor's move; such cognitive features are then translated into facial behaviors. In this paper, we describe the overall architecture of our system and its various components; in particular, we present our dynamic model of emotions. We illustrate our results with an example of dialog all along the paper. We pay particular attention to the generation of verbal and nonverbal behaviors and to the way they are synchronized and combined with each other. We also discuss how these acts are translated into facial expressions.",2002.0,33.0,139.0,False,,{'pages': '758-765'},"{'bibtex': '@Inproceedings{Pelachaud2002EmbodiedCA,\n author = {C. Pelachaud and V. Carofiglio and B. D. Carolis and F. D. Rosis and I. Poggi},\n pages = {758-765},\n title = {Embodied contextual agent in information delivering application},\n year = {2002}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1694255', 'name': 'V. Carofiglio'}, {'authorId': '1739256', 'name': 'B. D. Carolis'}, {'authorId': '1807752', 'name': 'F. D. Rosis'}, {'authorId': '1802126', 'name': 'I. Poggi'}]"
2696,eba0c2c1c27e63a9bd8b99af38fa7d4ce418917f,The effects of speech-gesture cooperation in animated agents' behavior in multimedia presentations,,2007.0,36.0,55.0,True,"{'url': 'http://hal.inria.fr/docs/00/78/63/43/PDF/LCPI_IWC_2007_BUISINE.pdf', 'status': None}","{'volume': '19', 'pages': '484-493', 'name': 'Interact. Comput.'}","{'bibtex': ""@Article{Buisine2007TheEO,\n author = {S. Buisine and Jean-Claude Martin},\n journal = {Interact. Comput.},\n pages = {484-493},\n title = {The effects of speech-gesture cooperation in animated agents' behavior in multimedia presentations},\n volume = {19},\n year = {2007}\n}\n""}","[{'authorId': '1742939', 'name': 'S. Buisine'}, {'authorId': '2110130919', 'name': 'Jean-Claude Martin'}]"
2697,ebb4c2e0cb5c5aa0ccdf8882f3607c79f3b00fe5,The Distress Analysis Interview Corpus of human and computer interviews,"The Distress Analysis Interview Corpus (DAIC) contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post traumatic stress disorder. The interviews are conducted by humans, human controlled agents and autonomous agents, and the participants include both distressed and non-distressed individuals. Data collected include audio and video recordings and extensive questionnaire responses; parts of the corpus have been transcribed and annotated for a variety of verbal and non-verbal features. The corpus has been used to support the creation of an automated interviewer agent, and for research on the automatic identification of psychological distress.",2014.0,40.0,352.0,False,,{'pages': '3123-3128'},"{'bibtex': '@Inproceedings{Gratch2014TheDA,\n author = {J. Gratch and Ron Artstein and Gale M. Lucas and Giota Stratou and Stefan Scherer and Angela Nazarian and Rachel Wood and Jill Boberg and D. DeVault and S. Marsella and D. Traum and A. Rizzo and Louis-Philippe Morency},\n pages = {3123-3128},\n title = {The Distress Analysis Interview Corpus of human and computer interviews},\n year = {2014}\n}\n'}","[{'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2038490', 'name': 'Ron Artstein'}, {'authorId': '2419453', 'name': 'Gale M. Lucas'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2551269', 'name': 'Angela Nazarian'}, {'authorId': '2072346682', 'name': 'Rachel Wood'}, {'authorId': '6349590', 'name': 'Jill Boberg'}, {'authorId': '144662324', 'name': 'D. DeVault'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '144518646', 'name': 'D. Traum'}, {'authorId': '29861580', 'name': 'A. Rizzo'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2698,ebbbe30fd6536227c401d12b13a602f75af2569e,Task-oriented collaboration with embodied agents in virtual worlds,,2001.0,46.0,218.0,False,,"{'volume': '', 'pages': '95-122', 'name': ''}","{'bibtex': '@Inproceedings{Rickel2001TaskorientedCW,\n author = {J. Rickel and W. Johnson},\n pages = {95-122},\n title = {Task-oriented collaboration with embodied agents in virtual worlds},\n year = {2001}\n}\n'}","[{'authorId': '2019292', 'name': 'J. Rickel'}, {'authorId': '145834590', 'name': 'W. Johnson'}]"
2699,ebc96892b9bcbf007be9a1d7844e4b09fde9d961,YOLOv3: An Incremental Improvement,"We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at this https URL",2018.0,20.0,15261.0,False,,"{'volume': 'abs/1804.02767', 'name': 'ArXiv'}","{'bibtex': '@Article{Redmon2018YOLOv3AI,\n author = {Joseph Redmon and Ali Farhadi},\n journal = {ArXiv},\n title = {YOLOv3: An Incremental Improvement},\n volume = {abs/1804.02767},\n year = {2018}\n}\n'}","[{'authorId': '40497777', 'name': 'Joseph Redmon'}, {'authorId': '143787583', 'name': 'Ali Farhadi'}]"
2700,ebeaeda285793121a04d12f0af2ce123e5213aca,"Why learning environment matters? An analysis on how the learning environment influences the academic motivation, learning strategies and engagement of college students",,2021.0,75.0,18.0,False,,"{'volume': '25', 'pages': '581-599', 'name': 'Learning Environments Research'}","{'bibtex': '@Article{Cayubit2021WhyLE,\n author = {R. F. Cayubit},\n journal = {Learning Environments Research},\n pages = {581-599},\n title = {Why learning environment matters? An analysis on how the learning environment influences the academic motivation, learning strategies and engagement of college students},\n volume = {25},\n year = {2021}\n}\n'}","[{'authorId': '114058348', 'name': 'R. F. Cayubit'}]"
2701,ec273d231800ea3a074438e2195d5b35aa5b03b9,Effects of aging and task difficulty on divided attention performance.,"We report two experiments that compare the performance of young and older adults on perceptual-motor tasks involving division of attention. Previous studies have shown older people to be especially penalized by divided attention situations, but the generality of this finding was recently challenged by Somberg and Salthouse (1982). The present study was conducted to investigate the possibility that age differences in dual-task performance are amplified by an increase in the difficulty of the constituent tasks, where difficulty was manipulated by varying the central, cognitive nature of the tasks (Experiment 1) or the degree of choice involved (Experiment 2). With the present tasks, strong evidence was found for an age-related decrement in divided attention performance. Contrary to our original expectations, however, it does not seem that division of attention presents some especial difficulty to older people. Rather, division of attention is one of several equivalent ways to increase overall task complexity. In turn, age differences are exaggerated as tasks are made more complex.",1988.0,31.0,419.0,False,,"{'volume': '14 2', 'pages': '\n          267-280\n        ', 'name': 'Journal of experimental psychology. Human perception and performance'}","{'bibtex': '@Article{Mcdowd1988EffectsOA,\n author = {J. Mcdowd and F. Craik},\n journal = {Journal of experimental psychology. Human perception and performance},\n pages = {\n          267-280\n        },\n title = {Effects of aging and task difficulty on divided attention performance.},\n volume = {14 2},\n year = {1988}\n}\n'}","[{'authorId': '4759624', 'name': 'J. Mcdowd'}, {'authorId': '2435816', 'name': 'F. Craik'}]"
2702,ec2fd8dc762a2e46c1e91d153f80c9c32587be6e,Situational factors and audience anxiety,"This study examined whether variations in five audience characteristics [size, status, familiarity, similarity, and behavior] were related to audience anxiety as per Buss’ (1980) formulation or Beatty's (1988) formulation. Buss argues that variations in situational factors are sufficient to produce audience anxiety in speakers, while Beatty contends that the effect of situational factors are greatly tempered by an individual's predisposition to respond anxiously. These data support Beatty's contention. The paper concludes with a discussion of the instructional implications of these findings.",1990.0,22.0,41.0,False,,"{'volume': '39', 'pages': '283-291', 'name': 'Communication Education'}","{'bibtex': '@Article{Ayres1990SituationalFA,\n author = {J. Ayres},\n journal = {Communication Education},\n pages = {283-291},\n title = {Situational factors and audience anxiety},\n volume = {39},\n year = {1990}\n}\n'}","[{'authorId': '94372357', 'name': 'J. Ayres'}]"
2703,ec341a8d8840f910447922ad124532383dbcb9ac,Coordinating cognition: The costs and benefits of shared gaze during collaborative search,,2008.0,41.0,317.0,False,,"{'volume': '106', 'pages': '1465-1477', 'name': 'Cognition'}","{'bibtex': '@Article{Brennan2008CoordinatingCT,\n author = {S. Brennan and Xin Chen and Christopher A. Dickinson and M. Neider and G. Zelinsky},\n journal = {Cognition},\n pages = {1465-1477},\n title = {Coordinating cognition: The costs and benefits of shared gaze during collaborative search},\n volume = {106},\n year = {2008}\n}\n'}","[{'authorId': '71463834', 'name': 'S. Brennan'}, {'authorId': '2145229740', 'name': 'Xin Chen'}, {'authorId': '145688063', 'name': 'Christopher A. Dickinson'}, {'authorId': '2184661', 'name': 'M. Neider'}, {'authorId': '1696991', 'name': 'G. Zelinsky'}]"
2704,ec3d052b29c4f0600cff870c160672112ee93bf4,The Role of Virtual Reality in Improving Health Outcomes for Community-Dwelling Older Adults: Systematic Review,"Background Virtual reality (VR) delivered through immersive headsets creates an opportunity to deliver interventions to improve physical, mental, and psychosocial health outcomes. VR app studies with older adults have primarily focused on rehabilitation and physical function including gait, balance, fall prevention, pain management, and cognition. Several systematic reviews have previously been conducted, but much of the extant literature is focused on rehabilitation or other institutional settings, and little is known about the effectiveness of VR apps using immersive headsets to target health outcomes among community-dwelling older adults. Objective The objective of this review was to evaluate the effectiveness of VR apps delivered using commercially available immersive headsets to improve physical, mental, or psychosocial health outcomes in community-dwelling older adults. Methods Peer-reviewed publications that included community-dwelling older adults aged ≥60 years residing in residential aged care settings and nursing homes were included. This systematic review was conducted in accordance with the Joanna Briggs Institute (JBI) methodology for systematic reviews of effectiveness evidence. The title of this review was registered with JBI, and the systematic review protocol was registered with the International Prospective Register of Systematic Reviews. Results In total, 7 studies that specifically included community-dwelling older adults were included in this review. VR apps using a head-mounted display led to improvements in a number of health outcomes, including pain management, posture, cognitive functioning specifically related to Alzheimer disease, and a decreased risk of falls. A total of 6 studies reported a statistically significant difference post VR intervention, and 1 study reported an improvement in cognitive function to reduce navigational errors. Only one study reported on the usability and acceptability of the interventions delivered through VR. While one study used a distraction mechanism for pain management, none of the studies used gaming technology to promote enjoyment. Conclusions Interventions to improve health outcomes through VR have demonstrated potential; however, the ability to synthesize findings by primary outcome for the older adult population is not possible. A number of factors, especially related to frailty, usability, and acceptability, also need to be explored before more substantial recommendations on the effectiveness of VR interventions for older adults can be made. Trial Registration PROSPERO CRD42019143504; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=143504",2020.0,85.0,76.0,True,"{'url': 'https://www.jmir.org/2020/6/e17331/PDF', 'status': None}","{'volume': '22', 'name': 'Journal of Medical Internet Research'}","{'bibtex': '@Article{Dermody2020TheRO,\n author = {Gordana Dermody and L. Whitehead and Graham Wilson and Courtney Glass},\n journal = {Journal of Medical Internet Research},\n title = {The Role of Virtual Reality in Improving Health Outcomes for Community-Dwelling Older Adults: Systematic Review},\n volume = {22},\n year = {2020}\n}\n'}","[{'authorId': '13922334', 'name': 'Gordana Dermody'}, {'authorId': '3763941', 'name': 'L. Whitehead'}, {'authorId': '2070349378', 'name': 'Graham Wilson'}, {'authorId': '1491679969', 'name': 'Courtney Glass'}]"
2705,ec540ca6b6933fdb485d6cf640ddf81990529b09,Agents with faces: the effect of personification,"It is still an open question whether software agents should be personified in the interface. In order to study the effects of faces and facial expressions in the interface a series of experiments was conducted to compare subjects' responses to and evaluation of different faces and facial expressions. The experimental results obtained demonstrate that: (1) personified interfaces help users engage in a task, and are well suited for an entertainment domain; (2) people's impressions of a face in a task are different from ones of the face in isolation. Perceived intelligence of a face is determined not by the agent's appearance but by its competence; (3) there is a dichotomy between user groups which have opposite opinions about personification. Thus, agent-based interfaces should be flexible to support the diversity of users' preferences and the nature of tasks.",1996.0,9.0,226.0,False,,"{'pages': '189-194', 'name': ""Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA""}","{'bibtex': ""@Article{Koda1996AgentsWF,\n author = {Tomoko Koda and P. Maes},\n journal = {Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA},\n pages = {189-194},\n title = {Agents with faces: the effect of personification},\n year = {1996}\n}\n""}","[{'authorId': '2060600', 'name': 'Tomoko Koda'}, {'authorId': '1701876', 'name': 'P. Maes'}]"
2706,ec5e4a406740a5077eb7c3fd3832d02d829e021f,Identification of Endogenous Social Effects: The Reflection Problem,"This paper examines the reflection problem that arises when a researcher observing the distribution of behaviour in a population tries to infer whether the average behaviour in some group influences the behaviour of the individuals that comprise the group. It is found that inference is not possible unless the researcher has prior information specifying the compisition of reference groups. If this information is available, the prospects for inference depend critically on the population relationship between the variables defining reference groups and those directly affecting outcomes. Inference is difficult to implossible if these variables are functionally dependent or are statistically independent. The prospects are better if the variables defining reference groups and those directly affecting outcomes are moderately related in the population.",1993.0,34.0,6242.0,True,"{'url': 'https://ageconsearch.umn.edu/record/292712/files/uwmad-0062.PDF', 'status': None}","{'volume': '60', 'pages': '531-542', 'name': 'The Review of Economic Studies'}","{'bibtex': '@Article{Manski1993IdentificationOE,\n author = {C. Manski},\n journal = {The Review of Economic Studies},\n pages = {531-542},\n title = {Identification of Endogenous Social Effects: The Reflection Problem},\n volume = {60},\n year = {1993}\n}\n'}","[{'authorId': '3210428', 'name': 'C. Manski'}]"
2707,ec914ed9bd50fc89026ec1c4bde73df8c725d995,IrisTK: a statechart-based toolkit for multi-party face-to-face interaction,"In this paper, we present IrisTK - a toolkit for rapid development of real-time systems for multi-party face-to-face interaction. The toolkit consists of a message passing system, a set of modules for multi-modal input and output, and a dialog authoring language based on the notion of statecharts. The toolkit has been applied to a large scale study in a public museum setting, where the back-projected robot head Furhat interacted with the visitors in multi-party dialog.",2012.0,23.0,116.0,False,,{'pages': '69-76'},"{'bibtex': '@Inproceedings{Skantze2012IrisTKAS,\n author = {Gabriel Skantze and S. Moubayed},\n pages = {69-76},\n title = {IrisTK: a statechart-based toolkit for multi-party face-to-face interaction},\n year = {2012}\n}\n'}","[{'authorId': '1711959', 'name': 'Gabriel Skantze'}, {'authorId': '32201536', 'name': 'S. Moubayed'}]"
2708,eca6f0d0c1c58a703ac19488fae17c94b438b30e,The Co-Regulation of Emotions Between Mothers and their Children with Autism,,2009.0,48.0,135.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10803-009-0861-x.pdf', 'status': None}","{'volume': '40', 'pages': '227 - 237', 'name': 'Journal of Autism and Developmental Disorders'}","{'bibtex': '@Article{Gulsrud2009TheCO,\n author = {A. Gulsrud and Laudan B. Jahromi and C. Kasari},\n journal = {Journal of Autism and Developmental Disorders},\n pages = {227 - 237},\n title = {The Co-Regulation of Emotions Between Mothers and their Children with Autism},\n volume = {40},\n year = {2009}\n}\n'}","[{'authorId': '3177708', 'name': 'A. Gulsrud'}, {'authorId': '4879861', 'name': 'Laudan B. Jahromi'}, {'authorId': '2592071', 'name': 'C. Kasari'}]"
2709,ecb5336bf7b54a62109f325e7152bb74c4c7f527,Document Modeling with Gated Recurrent Neural Network for Sentiment Classification,"Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document. To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion. The model first learns sentence representation with convolutional neural network or long short-term memory. Afterwards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network. We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge. Experimental results show that: (1) our neural model shows superior performances over several state-of-the-art algorithms; (2) gated recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification. 1",2015.0,61.0,1349.0,True,,{'pages': '1422-1432'},"{'bibtex': '@Inproceedings{Tang2015DocumentMW,\n author = {Duyu Tang and Bing Qin and Ting Liu},\n pages = {1422-1432},\n title = {Document Modeling with Gated Recurrent Neural Network for Sentiment Classification},\n year = {2015}\n}\n'}","[{'authorId': '39483833', 'name': 'Duyu Tang'}, {'authorId': '152277111', 'name': 'Bing Qin'}, {'authorId': '40282288', 'name': 'Ting Liu'}]"
2710,ecc0c983b75ab02fe1160c39c27cefdcaea57f0b,Axiomatizing Noisy-OR,"The Noisy-OR function is extensively used in probabilistic reasoning, and usually justified with heuristic arguments. This paper investigates sets of conditions that imply the Noisy-OR function.",2004.0,27.0,34.0,False,,{'pages': '979-980'},"{'bibtex': '@Inproceedings{Cozman2004AxiomatizingN,\n author = {Fabio Gagliardi Cozman},\n pages = {979-980},\n title = {Axiomatizing Noisy-OR},\n year = {2004}\n}\n'}","[{'authorId': '7668712', 'name': 'Fabio Gagliardi Cozman'}]"
2711,ecd01fd8de287959a93081526f2825225750529f,An ecological understanding of youth suicide in South Korea,"This article reviews risk factors for youth suicide in South Korea (hereafter referred to as Korea), based on the ecological systems theory. Although youth suicide is a major concern for Korean society, understanding of this phenomenon has been limited since most of the empirical studies address personal characteristics without much consideration to larger environmental contexts for Korean adolescents. This review integrates many empirical findings on Korean adolescents’ suicidal ideation or behaviours within the context of micro-, meso-, exo-, macro-, and chrono-systems that surround an individual. Finally, it draws implications on assessment and intervention strategies for youth suicide that school psychologists and other mental health professionals in Korean schools can utilize.",2010.0,84.0,69.0,False,,"{'volume': '31', 'pages': '531 - 546', 'name': 'School Psychology International'}","{'bibtex': '@Article{Lee2010AnEU,\n author = {Seung-yeon Lee and Jun Sung Hong and D. Espelage},\n journal = {School Psychology International},\n pages = {531 - 546},\n title = {An ecological understanding of youth suicide in South Korea},\n volume = {31},\n year = {2010}\n}\n'}","[{'authorId': '47089910', 'name': 'Seung-yeon Lee'}, {'authorId': '1820847199', 'name': 'Jun Sung Hong'}, {'authorId': '3160025', 'name': 'D. Espelage'}]"
2712,ecdd4731e197f4afda804602f533565c19ffc271,Vision in autism spectrum disorders,,2009.0,450.0,746.0,True,,"{'volume': '49', 'pages': '2705-2739', 'name': 'Vision Research'}","{'bibtex': '@Article{Simmons2009VisionIA,\n author = {D. Simmons and Ashley E. Robertson and Lawrie S. McKay and E. Toal and P. McAleer and F. Pollick},\n journal = {Vision Research},\n pages = {2705-2739},\n title = {Vision in autism spectrum disorders},\n volume = {49},\n year = {2009}\n}\n'}","[{'authorId': '23226369', 'name': 'D. Simmons'}, {'authorId': '40371378', 'name': 'Ashley E. Robertson'}, {'authorId': '3043139', 'name': 'Lawrie S. McKay'}, {'authorId': '12658236', 'name': 'E. Toal'}, {'authorId': '144728689', 'name': 'P. McAleer'}, {'authorId': '2819854', 'name': 'F. Pollick'}]"
2713,ed09074b546ea3e827683415f54a1353ecf901a7,Rules of play: game design fundamentals,"This text offers an introduction to game design and a unified model for looking at all kinds of games, from board games and sports to computer and video games. Also included are concepts, strategies, and methodologies for creating and understanding games.",2003.0,0.0,4723.0,False,,"{'pages': 'I-XV, 1-672'}","{'bibtex': '@Inproceedings{Salen2003RulesOP,\n author = {Katie Salen and Eric Zimmerman},\n pages = {I-XV, 1-672},\n title = {Rules of play: game design fundamentals},\n year = {2003}\n}\n'}","[{'authorId': '2558419', 'name': 'Katie Salen'}, {'authorId': '143665166', 'name': 'Eric Zimmerman'}]"
2714,ed0d30eba5ba1d4c2920d29b78f7979968ae1604,First Impressions in Human--Agent Virtual Encounters,"In greeting encounters, first impressions of personality and attitude are quickly formed and might determine important relational decisions, such as the likelihood and frequency of subsequent encounters. An anthropomorphic user interface is not immune to these judgments, specifically when exhibiting social interaction skills in public spaces. A favorable impression may help engaging users in interaction and attaining acceptance for long-term interactions. We present three studies implementing a model of first impressions for initiating user interactions with an anthropomorphic museum guide agent with socio-relational skills. We focus on nonverbal behavior exhibiting personality and interpersonal attitude. In two laboratory studies, we demonstrate that impressions of an agent's personality are quickly formed based on proximity, whereas interpersonal attitude is conveyed through smile and gaze. We also found that interpersonal attitude has greater impact than personality on the user's decision to spend time with the agent. These findings are then applied to a museum guide agent exhibited at the Boston Museum of Science. In this field study, we show that employing our model increases the number of visitors engaging in interaction.",2016.0,138.0,87.0,True,"{'url': 'https://skemman.is/bitstream/1946/19498/1/Angelo-Cafaro-PhDThesis.pdf', 'status': None}","{'volume': '23', 'pages': '1 - 40', 'name': 'ACM Transactions on Computer-Human Interaction (TOCHI)'}","{'bibtex': '@Article{Cafaro2016FirstII,\n author = {Angelo Cafaro and H. Vilhjálmsson and T. Bickmore},\n journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},\n pages = {1 - 40},\n title = {First Impressions in Human--Agent Virtual Encounters},\n volume = {23},\n year = {2016}\n}\n'}","[{'authorId': '40123315', 'name': 'Angelo Cafaro'}, {'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '1690448', 'name': 'T. Bickmore'}]"
2715,ed32cd837c0824bf444d3cf03be9ec510d868913,e-Learning through distributed virtual environments,"e-learning is one of the emerging needs of the information age. Access to education is going to become crucial for the success of our information society, and therefore a lot of potential is seen in distance learning and distributed virtual environments. The communicative character of the distributed virtual environments would allow students and staff to meet in social shared spaces and engage in on-line real-time seminars and tutorials. Such technologies may mitigate some of the problems of isolation that distance learning brings. This paper presents our work in multi-user distributed virtual environments which are designed and implemented for educational uses in the bounds of the VES project. Furthermore, it presents our proposal for the extensions and reconstruction of the current system in order to create a more efficient system, which can be characterized as a learning virtual environment.",2001.0,26.0,85.0,False,,"{'volume': '24', 'pages': '175-199', 'name': 'J. Netw. Comput. Appl.'}","{'bibtex': '@Article{Bouras2001eLearningTD,\n author = {C. Bouras and A. Philopoulos and T. Tsiatsos},\n journal = {J. Netw. Comput. Appl.},\n pages = {175-199},\n title = {e-Learning through distributed virtual environments},\n volume = {24},\n year = {2001}\n}\n'}","[{'authorId': '1696462', 'name': 'C. Bouras'}, {'authorId': '2577582', 'name': 'A. Philopoulos'}, {'authorId': '1802967', 'name': 'T. Tsiatsos'}]"
2716,ed4208f05fd046f468cff9f3e60d730304509d6d,Avatar-Mediated Networking: Increasing Social Presence and Interpersonal Trust in Net-Based Collaborations,"This study analyzes the influence of avatars on social presence, interpersonal trust, perceived communication quality, nonverbal behavior, and visual attention in Net-based collaborations using a comparative approach. A real-time communication window including a special avatar interface was integrated into a shared collaborative workspace. Communication modes under investigation were text chat, audio, audio-video, and avatar. Significant differences were found between text chat and all other communication modalities in perceived intimateness, co-presence, and emotionally-based trust. Microanalyses of nonverbal activity and visual attention point to similarities between video and avatar modes, both showing higher levels of exposure to the virtual other and visual attention, in particular in the initial phase of interaction as compared to text and audio.",2008.0,101.0,430.0,False,,"{'volume': '34', 'pages': '287-318', 'name': 'Human Communication Research'}","{'bibtex': '@Article{Bente2008AvatarMediatedNI,\n author = {G. Bente and Sabine Rüggenberg and N. Krämer and Felix Eschenburg},\n journal = {Human Communication Research},\n pages = {287-318},\n title = {Avatar-Mediated Networking: Increasing Social Presence and Interpersonal Trust in Net-Based Collaborations},\n volume = {34},\n year = {2008}\n}\n'}","[{'authorId': '2487649', 'name': 'G. Bente'}, {'authorId': '1873542', 'name': 'Sabine Rüggenberg'}, {'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '2508407', 'name': 'Felix Eschenburg'}]"
2717,ed492092ac35aad6e35257ec324a72dcc768b9ce,ELAN: a Professional Framework for Multimodality Research,"Utilization of computer tools in linguistic research has gained importance with the maturation of media frameworks for the handling of digital audio and video. The increased use of these tools in gesture, sign language and multimodal interaction studies has led to stronger requirements on the flexibility, the efficiency and in particular the time accuracy of annotation tools. This paper describes the efforts made to make ELAN a tool that meets these requirements, with special attention to the developments in the area of time accuracy. In subsequent sections an overview will be given of other enhancements in the latest versions of ELAN that makes it a useful tool in multimodality research.",2006.0,3.0,1131.0,False,,{'pages': '1556-1559'},"{'bibtex': '@Inproceedings{Wittenburg2006ELANAP,\n author = {P. Wittenburg and H. Brugman and A. Russel and A. Klassmann and H. Sloetjes},\n pages = {1556-1559},\n title = {ELAN: a Professional Framework for Multimodality Research},\n year = {2006}\n}\n'}","[{'authorId': '1681130', 'name': 'P. Wittenburg'}, {'authorId': '1778610', 'name': 'H. Brugman'}, {'authorId': '143990706', 'name': 'A. Russel'}, {'authorId': '1776920', 'name': 'A. Klassmann'}, {'authorId': '1711769', 'name': 'H. Sloetjes'}]"
2718,ed6c281ed506945dcdcaf30c78b40a842439bf54,Information exchange in negotiation,,1991.0,15.0,418.0,False,,"{'volume': '27', 'pages': '161-179', 'name': 'Journal of Experimental Social Psychology'}","{'bibtex': '@Article{Thompson1991InformationEI,\n author = {L. Thompson},\n journal = {Journal of Experimental Social Psychology},\n pages = {161-179},\n title = {Information exchange in negotiation},\n volume = {27},\n year = {1991}\n}\n'}","[{'authorId': '2032259060', 'name': 'L. Thompson'}]"
2719,edcbb50b93f1e6050550141db950954be19af8dd,The Effects of a Pedagogical Agent for Informal Science Education on Learner Behaviors and Self-efficacy,,2013.0,26.0,54.0,False,,{'pages': '309-318'},"{'bibtex': '@Inproceedings{Lane2013TheEO,\n author = {H. Lane and Clara Cahill and Susan Foutz and Daniel Auerbach and Dan Noren and Catherine Lussenhop and W. Swartout},\n pages = {309-318},\n title = {The Effects of a Pedagogical Agent for Informal Science Education on Learner Behaviors and Self-efficacy},\n year = {2013}\n}\n'}","[{'authorId': '144445231', 'name': 'H. Lane'}, {'authorId': '49324966', 'name': 'Clara Cahill'}, {'authorId': '2649117', 'name': 'Susan Foutz'}, {'authorId': '143961465', 'name': 'Daniel Auerbach'}, {'authorId': '31989292', 'name': 'Dan Noren'}, {'authorId': '2912014', 'name': 'Catherine Lussenhop'}, {'authorId': '1684040', 'name': 'W. Swartout'}]"
2720,ee421d5e7df939466dbea787a37f33644772f1e3,Exercise Psychology: Physical Activity and Sedentary Behavior,,2016.0,0.0,7.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Rhodes2016ExercisePP,\n author = {R. Rhodes and H. Hausenblas},\n title = {Exercise Psychology: Physical Activity and Sedentary Behavior},\n year = {2016}\n}\n'}","[{'authorId': '2006502', 'name': 'R. Rhodes'}, {'authorId': '5191122', 'name': 'H. Hausenblas'}]"
2721,ee43989b0aeebe8b9e6d9311178d5e4b81eb56a7,Pronunciation feedback from real and virtual language teachers,"The aim of this paper is to summarise how pronunciation feedback on the phoneme level should be given in computer-assisted pronunciation training (CAPT) in order to be effective. The study contains a literature survey of feedback in the language classroom, interviews with language teachers and their students about their attitudes towards pronunciation feedback, and observations of how feedback is given in their classrooms. The study was carried out using focus group meetings, individual semi-structured interviews and classroom observations. The feedback strategies that were advocated and observed in the study on pronunciation feedback from human teachers were implemented in a computer-animated language tutor giving articulation feedback. The virtual tutor was subsequently tested in a user trial and evaluated with a questionnaire. The article proposes several feedback strategies that would improve the pedagogical soundness of CAPT systems.",2007.0,37.0,94.0,False,,"{'volume': '20', 'pages': '235 - 262', 'name': 'Computer Assisted Language Learning'}","{'bibtex': '@Article{Engwall2007PronunciationFF,\n author = {Olov Engwall and Olle Bälter},\n journal = {Computer Assisted Language Learning},\n pages = {235 - 262},\n title = {Pronunciation feedback from real and virtual language teachers},\n volume = {20},\n year = {2007}\n}\n'}","[{'authorId': '1898479', 'name': 'Olov Engwall'}, {'authorId': '2557365', 'name': 'Olle Bälter'}]"
2722,ee5230f00d35d3bcee8848981ff6d0eaa373e31c,Mindblindness: An Essay on Autism and Theory of Mind,Mindblindness and mindreading evolutionary psychology and social chess mindreading - nature's choice developing mindreading - the four steps autism and mindblindness how brains read minds the language of the eyes mindreading - back to the future.,1997.0,0.0,4193.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Baron-Cohen1997MindblindnessAE,\n author = {S. Baron-Cohen},\n title = {Mindblindness: An Essay on Autism and Theory of Mind},\n year = {1997}\n}\n'}","[{'authorId': '1390019127', 'name': 'S. Baron-Cohen'}]"
2723,ee5516c94fed6510ef340159280bce97c0a33106,Providing expressive eye movement to virtual agents,"Non-verbal behavior, particularly eye movement, plays a fundamental role in nonverbal communication among people. In order to realize natural and intuitive human-agent interaction, the virtual agents need to employ this communicative channel effectively. Against this background, our research addresses the problem of emotionally expressive eye movement manner by describing a preliminary approach based on the parameters picked from real-time eye movement data (pupil size, blink rate and saccade).",2009.0,12.0,11.0,False,,{'pages': '241-244'},"{'bibtex': '@Inproceedings{Li2009ProvidingEE,\n author = {Zheng Li and Xia Mao and Lei Liu},\n pages = {241-244},\n title = {Providing expressive eye movement to virtual agents},\n year = {2009}\n}\n'}","[{'authorId': '2146248147', 'name': 'Zheng Li'}, {'authorId': '1724834', 'name': 'Xia Mao'}, {'authorId': '2150801616', 'name': 'Lei Liu'}]"
2724,ee5fdc6bd37da622fc1c4756abe47da632b619e2,Interpretation of Social Touch on an Artificial Arm Covered with an EIT-based Sensitive Skin,,2014.0,71.0,65.0,False,,"{'volume': '6', 'pages': '489-505', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Tawil2014InterpretationOS,\n author = {David Silvera Tawil and D. Rye and Mari Velonaki},\n journal = {International Journal of Social Robotics},\n pages = {489-505},\n title = {Interpretation of Social Touch on an Artificial Arm Covered with an EIT-based Sensitive Skin},\n volume = {6},\n year = {2014}\n}\n'}","[{'authorId': '2657549', 'name': 'David Silvera Tawil'}, {'authorId': '35545228', 'name': 'D. Rye'}, {'authorId': '2912327', 'name': 'Mari Velonaki'}]"
2725,ee646260d19e95e3b8e13c4b89280eccc4c119d5,On the Impact of the Dominant Intelligences of Players on Learning Outcome and Game Experience in Educational Games: The TrueBiters Case,,2016.0,17.0,9.0,False,,{'pages': '221-231'},"{'bibtex': '@Inproceedings{Sajjadi2016OnTI,\n author = {Pejman Sajjadi and E. Sayed and Olga De Troyer},\n pages = {221-231},\n title = {On the Impact of the Dominant Intelligences of Players on Learning Outcome and Game Experience in Educational Games: The TrueBiters Case},\n year = {2016}\n}\n'}","[{'authorId': '1869023', 'name': 'Pejman Sajjadi'}, {'authorId': '40548712', 'name': 'E. Sayed'}, {'authorId': '1745846', 'name': 'Olga De Troyer'}]"
2726,ee652f0f63ed5b0cfe0af4cb4ea76b2ecf790c8d,Metacognition and Cognitive Monitoring: A New Area of Cognitive-Developmental Inquiry.,"Preschool and elementary school children were asked to study a set of items until they were sure they could recall them perfectly (Flavell, Friedrichs, & Hoyt, 1970). The older subjects studied for a while, said they were ready, and usually were, that is, they showed perfect recall. The younger children studied for a while, said they were ready, and usually were not. In another study, elementary school children were asked to help the experimenter evaluate the communicative adequacy of verbal instructions, indicating any omissions and obscurities (Markman, 1977). Although the instructions were riddled with blatant omissions and obscurities, the younger subjects were surprisingly poor at detecting them. They incorrectly thought they had understood and could follow the instructions, much as their counterparts in the study by Flavell et al. (1970) incorrectly thought they had memorized and could recall the items. Results such as these have suggested that young children are quite limited in their knowledge and cognition about cognitive phenomena, or in their metacognition, and do relatively little monitoring of their own memory, comprehension, and other cognitive enterprises (see, e.g., Brown, 1978; Flavell, 1978; Flavell & Wellman, 1977; Kreutzer, Leonard, & Flavell, 1975; Flavell, Note 1, Note 2, Note 3; Markman, Note 4). Investigators have recently concluded that metacognition plays an important role in oral communication of information, oral persuasion, oral comprehension, reading comprehension, writing, language acquisition, attention, memory, problem solving, social cognition, and, various types of self-control and self-instruction; there are also clear indications that ideas about metacognition are beginning to make contact with similar ideas in the areas of social learning theory, cognitive behavior modification, personalty development, and education (Flavell, Note 1, Note 2, Note 3). Thus, the nature and de-",1979.0,13.0,8280.0,False,,"{'volume': '34', 'pages': '906-911', 'name': 'American Psychologist'}","{'bibtex': '@Article{Flavell1979MetacognitionAC,\n author = {J. Flavell},\n journal = {American Psychologist},\n pages = {906-911},\n title = {Metacognition and Cognitive Monitoring: A New Area of Cognitive-Developmental Inquiry.},\n volume = {34},\n year = {1979}\n}\n'}","[{'authorId': '153137871', 'name': 'J. Flavell'}]"
2727,ee8daa8cb2417d7473941cd687e18b06a93577be,Deep Learning Classification of Neuro-Emotional Phase Domain Complexity Levels Induced by Affective Video Film Clips,"In the present article, a novel emotional complexity marker is proposed for classification of discrete emotions induced by affective video film clips. Principal Component Analysis (PCA) is applied to full-band specific phase space trajectory matrix (PSTM) extracted from short emotional EEG segment of 6 s, then the first principal component is used to measure the level of local neuronal complexity. As well, Phase Locking Value (PLV) between right and left hemispheres is estimated for in order to observe the superiority of local neuronal complexity estimation to regional neuro-cortical connectivity measurements in clustering nine discrete emotions (fear, anger, happiness, sadness, amusement, surprise, excitement, calmness, disgust) by using Long-Short-Term-Memory Networks as deep learning applications. In tests, two groups (healthy females and males aged between 22 and 33 years old) are classified with the accuracy levels of <inline-formula><tex-math notation=""LaTeX"">$\text{68.52}{\%}$</tex-math></inline-formula> and <inline-formula><tex-math notation=""LaTeX"">$\text{79.36}{\%}$</tex-math></inline-formula> through the proposed emotional complexity markers and and connectivity levels in terms of PLV in amusement. The groups are found to be statistically different (<inline-formula><tex-math notation=""LaTeX"">$p\ll 0.5$</tex-math></inline-formula>) in amusement with respect to both metrics, even if gender difference does not lead to different neuro-cortical functions in any of the other discrete emotional states. The high deep learning classification accuracy of <inline-formula><tex-math notation=""LaTeX"">$\text{98.00}{\%}$</tex-math></inline-formula> is commonly obtained for discrimination of positive emotions from negative emotions through the proposed new complexity markers. Besides, considerable useful classification performance is obtained in discriminating mixed emotions from each other through full-band connectivity features. The results reveal that emotion formation is mostly influenced by individual experiences rather than gender. In detail, local neuronal complexity is mostly sensitive to the affective valance rating, while regional neuro-cortical connectivity levels are mostly sensitive to the affective arousal ratings.",2019.0,103.0,67.0,False,,"{'volume': '24', 'pages': '1695-1702', 'name': 'IEEE Journal of Biomedical and Health Informatics'}","{'bibtex': '@Article{Aydın2019DeepLC,\n author = {S. Aydın},\n journal = {IEEE Journal of Biomedical and Health Informatics},\n pages = {1695-1702},\n title = {Deep Learning Classification of Neuro-Emotional Phase Domain Complexity Levels Induced by Affective Video Film Clips},\n volume = {24},\n year = {2019}\n}\n'}","[{'authorId': '35098633', 'name': 'S. Aydın'}]"
2728,ee9142ddfe1bf24f9b1e804312c9e85b7c393894,Features and benefits of online counselling: Trinity College online mental health community,"ABSTRACT Universities have a responsibility to develop appropriate interventions to respond to the mental health needs of their students. Students’ use of technology is an integral part of how they communicate and relate to the world; it is reasonable to consider engaging the internet and Information and Communication Technologies (ICT) for mental health service delivery. Internet-delivered counselling brings with it many distinct advantages, but also challenges. Investigating the effectiveness of any internet-delivered counselling intervention is important so as to establish a sound evidence-based practice. A unique feature of online delivery is that the internet can facilitate community and therefore allow counselling interventions to act therapeutically for an online community of users. This paper reports on the use of the online counselling service at Trinity College Dublin, including its uptake and usage, the issues and benefits of online counselling to students and whether clients are satisfied with their experience of online counselling. The paper highlights the positive effect of disinhibition and the therapeutic benefit of writing. Single session counselling is discussed as a model that fits the experience of users and the service provider. Users have reported satisfaction with online counselling and the service's impact within the community of users is complementary. The benefits of increasing access, flexibility and on-time and on-demand services are given attention as is the use of online counselling as an element of a stepped care approach to service delivery.",2009.0,63.0,81.0,False,,"{'volume': '37', 'pages': '231 - 242', 'name': 'British Journal of Guidance & Counselling'}","{'bibtex': '@Article{Richards2009FeaturesAB,\n author = {D. Richards},\n journal = {British Journal of Guidance & Counselling},\n pages = {231 - 242},\n title = {Features and benefits of online counselling: Trinity College online mental health community},\n volume = {37},\n year = {2009}\n}\n'}","[{'authorId': '146540561', 'name': 'D. Richards'}]"
2729,ee96f570ffacc8501348220f5972bc66532bd43a,Subtleties of facial expressions in embodied agents,"Our goal is to develop a believable embodied agent able to dialogue with a user. In particular, we aim at making an agent that can also combine facial expressions in a complex and subtle way, just like a human agent does. We first review a taxonomy of communicative functions that our agent is able to express non-verbally; but we point out that, due to the complexity of communication, in some cases different information can be provided at once by different parts and actions of an agent's face. In this paper we are interested in assessing and treating what happens, at the meaning and signal levels of behaviour, when different communicative functions have to be displayed at the same time and necessarily have to make use of the same expressive resources. In some of these cases the complexity of the agent's communication can give rise to conflicts between the parts or movements of the face. In this paper, we propose a way to manage the possible conflicts between different modalities of communication through the tool of belief networks, and we show how this tool allows us to combine facial expressions of different communicative functions and to display complex and subtle expressions. Copyright © 2002 John Wiley & Sons, Ltd.",2002.0,35.0,130.0,False,,"{'volume': '13', 'pages': '301-312', 'name': 'Comput. Animat. Virtual Worlds'}","{'bibtex': '@Article{Pelachaud2002SubtletiesOF,\n author = {C. Pelachaud and I. Poggi},\n journal = {Comput. Animat. Virtual Worlds},\n pages = {301-312},\n title = {Subtleties of facial expressions in embodied agents},\n volume = {13},\n year = {2002}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '1802126', 'name': 'I. Poggi'}]"
2731,eeb08c5e548756250c740e25646d54e6b5aa3a0a,Modeling storytelling to be used in educational video games,,2014.0,23.0,83.0,False,,"{'volume': '31', 'pages': '461-474', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Zea2014ModelingST,\n author = {N. Zea and F. G. Vela and J. R. López-Arcos and A. Abad-Arranz and P. Paderewski},\n journal = {Comput. Hum. Behav.},\n pages = {461-474},\n title = {Modeling storytelling to be used in educational video games},\n volume = {31},\n year = {2014}\n}\n'}","[{'authorId': '3059908', 'name': 'N. Zea'}, {'authorId': '1686923', 'name': 'F. G. Vela'}, {'authorId': '1397836282', 'name': 'J. R. López-Arcos'}, {'authorId': '1405522817', 'name': 'A. Abad-Arranz'}, {'authorId': '1699752', 'name': 'P. Paderewski'}]"
2732,eee8d1d4e725a06e2c0eb9dba97feb497dc3368f,"Video-Based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms","Unlike the conventional facial expressions, micro-expressions are involuntary and transient facial expressions capable of revealing the genuine emotions that people attempt to hide. Therefore, they can provide important information in a broad range of applications such as lie detection, criminal detection, etc. Since micro-expressions are transient and of low intensity, however, their detection and recognition is difficult and relies heavily on expert experiences. Due to its intrinsic particularity and complexity, video-based micro-expression analysis is attractive but challenging, and has recently become an active area of research. Although there have been numerous developments in this area, thus far there has been no comprehensive survey that provides researchers with a systematic overview of these developments with a unified evaluation. Accordingly, in this survey paper, we first highlight the key differences between macro- and micro-expressions, then use these differences to guide our research survey of video-based micro-expression analysis in a cascaded structure, encompassing the neuropsychological basis, datasets, features, spotting algorithms, recognition algorithms, applications and evaluation of state-of-the-art approaches. For each aspect, the basic techniques, advanced developments and major challenges are addressed and discussed. Furthermore, after considering the limitations of existing micro-expression datasets, we present and release a new dataset — called <italic>micro-and-macro expression warehouse</italic> (MMEW) — containing more video samples and more labeled emotion types. We then perform a unified comparison of representative methods on CAS(ME)<inline-formula><tex-math notation=""LaTeX"">$^2$</tex-math><alternatives><mml:math><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=""liu-ieq1-3067464.gif""/></alternatives></inline-formula> for spotting, and on MMEW and SAMM for recognition, respectively. Finally, some potential future research directions are explored and outlined.",2021.0,125.0,109.0,True,"{'url': 'https://arxiv.org/pdf/2201.12728', 'status': None}","{'volume': '44', 'pages': '5826-5846', 'name': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'}","{'bibtex': '@Article{Ben2021VideoBasedFM,\n author = {Xianye Ben and Yi Ren and Junping Zhang and Su-Jing Wang and K. Kpalma and W. Meng and Yong-jin Liu},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {5826-5846},\n title = {Video-Based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms},\n volume = {44},\n year = {2021}\n}\n'}","[{'authorId': '2163652', 'name': 'Xianye Ben'}, {'authorId': '2115243210', 'name': 'Yi Ren'}, {'authorId': '47539666', 'name': 'Junping Zhang'}, {'authorId': '134769402', 'name': 'Su-Jing Wang'}, {'authorId': '1748777', 'name': 'K. Kpalma'}, {'authorId': '5130083', 'name': 'W. Meng'}, {'authorId': '2144470995', 'name': 'Yong-jin Liu'}]"
2733,ef1ecb68b7773501522f1c71a9e69a3c10b960c3,Public Speaking in Virtual Reality: Facing an Audience of Avatars,"What happens when someone talks in public to an audience they know to be entirely computer generated-to an audience of avatars? If the virtual audience seems attentive, well-behaved, and interested, if they show positive facial expressions with complimentary actions such as clapping and nodding, does the speaker infer correspondingly positive evaluations of performance and show fewer signs of anxiety? On the other hand, if the audience seems hostile, disinterested, and visibly bored, if they have negative facial expressions and exhibit reactions such as head-shaking, loud yawning, turning away, falling asleep, and walking out, does the speaker infer correspondingly negative evaluations of performance and show more signs of anxiety? We set out to study this question during the summer of 1998. We designed a virtual public speaking scenario, followed by an experimental study. We wanted mainly to explore the effectiveness of virtual environments (VEs) in psychotherapy for social phobias. Rather than plunge straight in and design a virtual reality therapy tool, we first tackled the question of whether real people's emotional responses are appropriate to the behavior of the virtual people with whom they may interact. The project used DIVE (Distributive Interactive Virtual Environment) as the basis for constructing a working prototype of a virtual public speaking simulation. We constructed as a Virtual Reality Modeling Language (VRML) model, a virtual seminar room that matched the actual seminar room in which subjects completed their various questionnaires and met with the experimenters.",1999.0,5.0,257.0,False,,"{'volume': '19', 'pages': '6-9', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Slater1999PublicSI,\n author = {M. Slater and David-Paul Pertaub and A. Steed},\n journal = {IEEE Computer Graphics and Applications},\n pages = {6-9},\n title = {Public Speaking in Virtual Reality: Facing an Audience of Avatars},\n volume = {19},\n year = {1999}\n}\n'}","[{'authorId': '144931212', 'name': 'M. Slater'}, {'authorId': '1921915', 'name': 'David-Paul Pertaub'}, {'authorId': '143903462', 'name': 'A. Steed'}]"
2734,ef3a96d8f42e8caa1994caba2e53ca98121b4d1f,Plug-and-Play Conversational Models,"There has been considerable progress made towards conversational models that generate coherent and fluent responses; however, this often involves training large language models on large dialogue datasets, such as Reddit. These large conversational models provide little control over the generated responses, and this control is further limited in the absence of annotated conversational datasets for attribute specific generation that can be used for fine-tuning the model. In this paper, we first propose and evaluate plug-and-play methods for controllable response generation, which does not require dialogue specific datasets and does not rely on fine-tuning a large model. While effective, the decoding procedure induces considerable computational overhead, rendering the conversational model unsuitable for interactive usage. To overcome this, we introduce an approach that does not require further computation at decoding time, while also does not require any fine-tuning of a large language model. We demonstrate, through extensive automatic and human evaluation, a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.",2020.0,66.0,46.0,True,"{'url': 'https://www.aclweb.org/anthology/2020.findings-emnlp.219.pdf', 'status': None}","{'volume': 'abs/2010.04344', 'name': 'ArXiv'}","{'bibtex': '@Article{Madotto2020PlugandPlayCM,\n author = {Andrea Madotto and Etsuko Ishii and Zhaojiang Lin and Sumanth Dathathri and Pascale Fung},\n journal = {ArXiv},\n title = {Plug-and-Play Conversational Models},\n volume = {abs/2010.04344},\n year = {2020}\n}\n'}","[{'authorId': '3064807', 'name': 'Andrea Madotto'}, {'authorId': '38524906', 'name': 'Etsuko Ishii'}, {'authorId': '100466830', 'name': 'Zhaojiang Lin'}, {'authorId': '3491117', 'name': 'Sumanth Dathathri'}, {'authorId': '40539650', 'name': 'Pascale Fung'}]"
2735,ef57b243750b9fcb5183638b1db1206a8fdda357,State-of-the-art of virtual reality technologies for children on the autism spectrum,"In the past decade there has been a rapid advance in the use of virtual reality (VR) technologies for leisure, training and education. VR is argued to offer particular benefits for children on the autism spectrum, chiefly because it can offer simulations of authentic real-world situations in a carefully controlled and safe environment. Given the real world social difficulties experienced by children on the spectrum, this technology has therefore been argued to offer distinct advantages and benefits for social and life skills training compared to other approaches. Whilst there has been some progress in testing the relevance and applicability of VR for children on the autism spectrum in educational contexts, there remains a significant challenge in developing robust and usable technologies that can really make a difference in real world classrooms. This article considers the evidence that has been published over the past 10 years to assess how the potential of VR has been explored in practice and reflect on the current state-of-the-art in this field.",2011.0,50.0,302.0,True,,"{'volume': '26', 'pages': '355 - 366', 'name': 'European Journal of Special Needs Education'}","{'bibtex': '@Article{Parsons2011StateoftheartOV,\n author = {S. Parsons and S. Cobb},\n journal = {European Journal of Special Needs Education},\n pages = {355 - 366},\n title = {State-of-the-art of virtual reality technologies for children on the autism spectrum},\n volume = {26},\n year = {2011}\n}\n'}","[{'authorId': '144674468', 'name': 'S. Parsons'}, {'authorId': '20955942', 'name': 'S. Cobb'}]"
2736,ef61d5c346ae770b80e69593ecef499f8dcd5bd6,BiLAT: A Game-Based Environment for Practicing Negotiation in a Cultural Context,"Negotiation skills are essential in everyday life, whether in a professional or personal context. Negotiation enables two parties to address misunderstandings and avoid conflicts through an exchange that depends as much on the interpersonal skills of the negotiators as the tactics employed. Acquiring these skills requires not only sound conceptual knowledge but also practice and mentoring. This paper describes the BiLAT game-based simulation and tutoring system developed to provide students, initially United States Army soldiers, with an environment to practice preparing for and conducting bilateral negotiations. We describe the models that were created to implement BiLAT, with a particular focus on the challenge of designing for and tutoring in the ill-defined domain of negotiation. An initial assessment of the training effectiveness of the system indicates significant situation-judgment gains by novices.",2009.0,29.0,168.0,False,,"{'volume': '19', 'pages': '289-308', 'name': 'Int. J. Artif. Intell. Educ.'}","{'bibtex': '@Article{Kim2009BiLATAG,\n author = {Julia M. Kim and R. Hill and P. Durlach and H. Lane and Eric Forbell and Mark G. Core and S. Marsella and D. Pynadath and John Hart},\n journal = {Int. J. Artif. Intell. Educ.},\n pages = {289-308},\n title = {BiLAT: A Game-Based Environment for Practicing Negotiation in a Cultural Context},\n volume = {19},\n year = {2009}\n}\n'}","[{'authorId': '47964935', 'name': 'Julia M. Kim'}, {'authorId': '1812270', 'name': 'R. Hill'}, {'authorId': '1724385', 'name': 'P. Durlach'}, {'authorId': '144445231', 'name': 'H. Lane'}, {'authorId': '2097330', 'name': 'Eric Forbell'}, {'authorId': '3122851', 'name': 'Mark G. Core'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '1748597', 'name': 'D. Pynadath'}, {'authorId': '2055460171', 'name': 'John Hart'}]"
2737,ef92e15f6704f3dfe8ee7c336990fdb7d59e8a6d,Modelling Emotional Requirements,"The way people feel about a technology can determine whether the technology is embraced or rejected by its intended users. People’s feelings and emotions are particularly important for uptake of socio-technical systems involving social behaviour. For example, a photo sharing web application will not be used if people do not feel engaged or in-touch with their friends and family during use. Considering the feelings of the intended users of a system can uncover new requirements, leading to an improved and more accepted system. We contend that requirements engineering, in developing systems for the new social age, needs modified lightweight practices. In this paper, we propose adapting a requirements engineering methodology to include emotion modelling for socio-technical systems. We extend a set of existing agent oriented lightweight models to consider emotions, describe the process for modelling, and demonstrate both models and process in an example of personal alarm systems for older adults.",2014.0,13.0,8.0,False,,,"{'bibtex': '@Inproceedings{Lopez-Lorca2014ModellingER,\n author = {A. Lopez-Lorca and Tim Miller and S. Pedell and L. Sterling and M. Curumsing},\n title = {Modelling Emotional Requirements},\n year = {2014}\n}\n'}","[{'authorId': '1401292565', 'name': 'A. Lopez-Lorca'}, {'authorId': '144658641', 'name': 'Tim Miller'}, {'authorId': '3199529', 'name': 'S. Pedell'}, {'authorId': '145977411', 'name': 'L. Sterling'}, {'authorId': '3292250', 'name': 'M. Curumsing'}]"
2738,ef9366070fc54155c8540ad6b1e411dcef1ccd44,Immersive virtual environment technology as a basic research tool in psychology,,1999.0,67.0,661.0,True,"{'url': 'https://link.springer.com/content/pdf/10.3758/BF03200735.pdf', 'status': None}","{'volume': '31', 'pages': '557-564', 'name': 'Behavior Research Methods, Instruments, & Computers'}","{'bibtex': '@Article{Loomis1999ImmersiveVE,\n author = {J. Loomis and J. Blascovich and A. Beall},\n journal = {Behavior Research Methods, Instruments, & Computers},\n pages = {557-564},\n title = {Immersive virtual environment technology as a basic research tool in psychology},\n volume = {31},\n year = {1999}\n}\n'}","[{'authorId': '2386187', 'name': 'J. Loomis'}, {'authorId': '2307657', 'name': 'J. Blascovich'}, {'authorId': '40458739', 'name': 'A. Beall'}]"
2739,efa5e81448845fbe34b275647f91107312439846,Towards Emotionally Expressive Virtual Agent to Foster Independent Speaking Tasks: A Preliminary Study,,2022.0,0.0,1.0,False,,{'pages': '12-18'},"{'bibtex': '@Inproceedings{Ayedoun2022TowardsEE,\n author = {Emmanuel Ayedoun and Masataka Tokumaru},\n pages = {12-18},\n title = {Towards Emotionally Expressive Virtual Agent to Foster Independent Speaking Tasks: A Preliminary Study},\n year = {2022}\n}\n'}","[{'authorId': '3350062', 'name': 'Emmanuel Ayedoun'}, {'authorId': '1980261', 'name': 'Masataka Tokumaru'}]"
2740,efb33ee092a51dc08b408b77606bd61dadf2d28b,Evaluation of Presence in Virtual Environments: Haptic Vest and User’s Haptic Skills,"This paper presents the integration of a haptic vest with a multimodal virtual environment, consisting of video, audio, and haptic feedback, with the main objective of determining how users, who interact with the virtual environment, benefit from tactile and thermal stimuli provided by the haptic vest. Some experiments are performed using a game application of a train station after an explosion. The participants of this experiment have to move inside the environment, while receiving several stimuli to check if any improvement in presence or realism in that environment is reflected on the vest. This is done by comparing the experimental results with those similar scenarios, obtained without haptic feedback. These experiments are carried out by three groups of participants who are classified on the basis of their experience in haptics and virtual reality devices. Some differences among the groups have been found, which can be related to the levels of realism and synchronization of all the elements in the multimodal environment that fulfill the expectations and maximum satisfaction level. According to the participants in the experiment, two different levels of requirements are to be defined by the system to comply with the expectations of professional and conventional users.",2018.0,41.0,47.0,True,,"{'volume': '6', 'pages': '7224-7233', 'name': 'IEEE Access'}","{'bibtex': '@Article{García-Valle2018EvaluationOP,\n author = {Gonzalo García-Valle and M. Ferre and Jose Breñosa and David Vargas},\n journal = {IEEE Access},\n pages = {7224-7233},\n title = {Evaluation of Presence in Virtual Environments: Haptic Vest and User’s Haptic Skills},\n volume = {6},\n year = {2018}\n}\n'}","[{'authorId': '1413070897', 'name': 'Gonzalo García-Valle'}, {'authorId': '145126596', 'name': 'M. Ferre'}, {'authorId': '1859767', 'name': 'Jose Breñosa'}, {'authorId': '32183510', 'name': 'David Vargas'}]"
2741,f03da64a082a677bd3281865098f0c5113a49aa8,Investigating voice quality as a speaker-independent indicator of depression and PTSD,"We seek to investigate voice quality characteristics, in particular on a breathy to tense dimension, as an indicator for psychological distress, i.e. depression and post-traumatic stress disorder (PTSD), within semi-structured virtual human interviews. Our evaluation identifies significant differences between the voice quality of psychologically distressed participants and not-distressed participants within this limited corpus. We investigate the capability of automatic algorithms to classify psychologically distressed speech in speaker-independent experiments. Additionally, we examine the impact of the posed questions’ affective polarity, as motivated by findings in the literature on positive stimulus attenuation and negative stimulus potentiation in emotional reactivity of psychologically distressed participants. The experiments yield promising results using standard machine learning algorithms and solely four distinct features capturing the tenseness of the speaker’s voice.",2013.0,27.0,109.0,False,,{'pages': '847-851'},"{'bibtex': '@Inproceedings{Scherer2013InvestigatingVQ,\n author = {Stefan Scherer and Giota Stratou and J. Gratch and Louis-Philippe Morency},\n pages = {847-851},\n title = {Investigating voice quality as a speaker-independent indicator of depression and PTSD},\n year = {2013}\n}\n'}","[{'authorId': '1770312', 'name': 'Stefan Scherer'}, {'authorId': '2624478', 'name': 'Giota Stratou'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2742,f04fb68ec6c202c6601c493a4303ea532370e338,Studying the dynamics of emotional expression using synthesized facial muscle movements.,"Synthetic images of facial expression were used to assess whether judges can correctly recognize emotions exclusively on the basis of configurations of facial muscle movements. A first study showed that static, synthetic images modeled after a series of photographs that are widely used in facial expression research yielded recognition rates and confusion patterns comparable to posed photos. In a second study, animated synthetic images were used to examine whether schematic facial expressions consisting entirely of theoretically postulated facial muscle configurations can be correctly recognized. Recognition rates for the synthetic expressions were far above chance, and the confusion patterns were comparable to those obtained with posed photos. In addition, the effect of static versus dynamic presentation of the expressions was studied. Dynamic presentation increased overall recognition accuracy and reduced confusions between unrelated emotions.",2000.0,61.0,341.0,False,,"{'volume': '78 1', 'pages': '\n          105-19\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Wehrle2000StudyingTD,\n author = {T. Wehrle and S. Kaiser and Susanne Schmidt and Klaus R Scherer},\n journal = {Journal of personality and social psychology},\n pages = {\n          105-19\n        },\n title = {Studying the dynamics of emotional expression using synthesized facial muscle movements.},\n volume = {78 1},\n year = {2000}\n}\n'}","[{'authorId': '1719131', 'name': 'T. Wehrle'}, {'authorId': '10539662', 'name': 'S. Kaiser'}, {'authorId': '2238656881', 'name': 'Susanne Schmidt'}, {'authorId': '2238696921', 'name': 'Klaus R Scherer'}]"
2743,f071c25f775317ce1b16f5f6e25bd66a049e62a8,Behavioral programming of autonomous characters based on probabilistic automata and personality,"This paper presents a system for realistic behavioral programming of virtual characters, based on personality and probabilistic automata. We describe personality by using the Five‐Factor Model and achieve autonomy through a goal‐oriented approach. Each character perceives the surrounding world, decides how to behave and acts on the environment according to its personality and to its goals. The chief idea explored by the proposed approach is that personality has a probabilistic influence on behavior selection instead of a deterministic one. Different behavior sequences available to achieve a goal are modeled using probabilistic automata and making probability dependent on character personality. This leads to non‐repetitive behaviors, whose evolution is not foreseeable. The paper first motivates the approach in the context of cybertherapy. Then, it summarizes related work and illustrates in detail the proposed approach. Finally, it presents obtained results and discusses the main limitations of the implemented system. Copyright © 2004 John Wiley & Sons, Ltd.",2004.0,18.0,49.0,False,,"{'volume': '15', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Chittaro2004BehavioralPO,\n author = {L. Chittaro and Milena Serra},\n journal = {Computer Animation and Virtual Worlds},\n title = {Behavioral programming of autonomous characters based on probabilistic automata and personality},\n volume = {15},\n year = {2004}\n}\n'}","[{'authorId': '1692716', 'name': 'L. Chittaro'}, {'authorId': '2059202546', 'name': 'Milena Serra'}]"
2744,f07ee564a9460a87dccf76f6b5c601efc9bdd330,Perceived Gaze Direction and the Processing of Facial Displays of Emotion,"There is good reason to believe that gaze direction and facial displays of emotion share an information value as signals of approach or avoidance. The combination of these cues in the analysis of social communication, however, has been a virtually neglected area of inquiry. Two studies were conducted to test the prediction that direct gaze would facilitate the processing of facially communicated approach-oriented emotions (e.g., anger and joy), whereas averted gaze would facilitate the processing of facially communicated avoidance-oriented emotions (e.g., fear and sadness). The results of both studies confirmed the central hypothesis and suggest that gaze direction and facial expression are combined in the processing of emotionally relevant facial information.",2003.0,24.0,554.0,False,,"{'volume': '14', 'pages': '644 - 647', 'name': 'Psychological Science'}","{'bibtex': '@Article{Adams2003PerceivedGD,\n author = {R. B. Adams and R. Kleck},\n journal = {Psychological Science},\n pages = {644 - 647},\n title = {Perceived Gaze Direction and the Processing of Facial Displays of Emotion},\n volume = {14},\n year = {2003}\n}\n'}","[{'authorId': '2075454382', 'name': 'R. B. Adams'}, {'authorId': '4170904', 'name': 'R. Kleck'}]"
2745,f09f7b464c89cee948027d84e619ae36568a0ee0,Movement coordination in social interaction: some examples described.,,1970.0,11.0,487.0,False,,"{'volume': '32 2', 'pages': '\n          100-25\n        ', 'name': 'Acta psychologica'}","{'bibtex': '@Article{Kendon1970MovementCI,\n author = {A. Kendon},\n journal = {Acta psychologica},\n pages = {\n          100-25\n        },\n title = {Movement coordination in social interaction: some examples described.},\n volume = {32 2},\n year = {1970}\n}\n'}","[{'authorId': '47985333', 'name': 'A. Kendon'}]"
2747,f0a54b5bb0e19a98f3556d5073f32046c1d397ce,Virtual agent multimodal mimicry of humans,,2007.0,37.0,59.0,False,,"{'volume': '41', 'pages': '367-388', 'name': 'Language Resources and Evaluation'}","{'bibtex': '@Article{Caridakis2007VirtualAM,\n author = {G. Caridakis and A. Raouzaiou and Elisabetta Bevacqua and M. Mancini and K. Karpouzis and Lori Malatesta and C. Pelachaud},\n journal = {Language Resources and Evaluation},\n pages = {367-388},\n title = {Virtual agent multimodal mimicry of humans},\n volume = {41},\n year = {2007}\n}\n'}","[{'authorId': '2001300', 'name': 'G. Caridakis'}, {'authorId': '3346592', 'name': 'A. Raouzaiou'}, {'authorId': '1772136', 'name': 'Elisabetta Bevacqua'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1715144', 'name': 'K. Karpouzis'}, {'authorId': '2185181', 'name': 'Lori Malatesta'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}]"
2748,f0dbe7e0ae00fea02c7ab6de432b8970b9f3ef43,A Social-Cognitive Framework for Pedagogical Agents as Learning Companions,,2006.0,120.0,297.0,False,,"{'volume': '54', 'pages': '569-596', 'name': 'Educational Technology Research and Development'}","{'bibtex': '@Article{Kim2006ASF,\n author = {Yanghee Kim and A. L. Baylor},\n journal = {Educational Technology Research and Development},\n pages = {569-596},\n title = {A Social-Cognitive Framework for Pedagogical Agents as Learning Companions},\n volume = {54},\n year = {2006}\n}\n'}","[{'authorId': '32964910', 'name': 'Yanghee Kim'}, {'authorId': '25550816', 'name': 'A. L. Baylor'}]"
2749,f0e1bd5c0d5af459f561ebcdb09d9cccb801ab17,A novel approach to improve the planning of adaptive and interactive sessions for the treatment of Major Depression,,2016.0,45.0,14.0,True,"{'url': 'https://riunet.upv.es/bitstream/10251/83255/3/A%20Novel%20Approach%20to%20Improve%20the%20Planning%20of%20Adaptive%20and%20Interactive%20Sessions%20for%20the%20treatment%20of%20Major%20Depression%20%28VERSION%20AUTOR%29.pdf', 'status': None}","{'volume': '87', 'pages': '80-91', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': '@Article{Bresó2016ANA,\n author = {A. Bresó and J. Martínez-Miranda and E. Fuster-García and J. M. García-Gómez},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {80-91},\n title = {A novel approach to improve the planning of adaptive and interactive sessions for the treatment of Major Depression},\n volume = {87},\n year = {2016}\n}\n'}","[{'authorId': '3352168', 'name': 'A. Bresó'}, {'authorId': '1398008961', 'name': 'J. Martínez-Miranda'}, {'authorId': '1388884748', 'name': 'E. Fuster-García'}, {'authorId': '1388884721', 'name': 'J. M. García-Gómez'}]"
2750,f0fc78e9891bba1aea87325876b1e44871e0d5e8,Investigating Trust in Interaction with Inconsistent Embodied Virtual Agents,,2021.0,44.0,3.0,False,,"{'volume': '13', 'pages': '2103 - 2118', 'name': 'International Journal of Social Robotics'}","{'bibtex': '@Article{Moradinezhad2021InvestigatingTI,\n author = {R. Moradinezhad and E. Solovey},\n journal = {International Journal of Social Robotics},\n pages = {2103 - 2118},\n title = {Investigating Trust in Interaction with Inconsistent Embodied Virtual Agents},\n volume = {13},\n year = {2021}\n}\n'}","[{'authorId': '9189698', 'name': 'R. Moradinezhad'}, {'authorId': '1751638', 'name': 'E. Solovey'}]"
2751,f106e3afbdd01022962d7a73a847869d0534a036,Hidden Markov model-based speech emotion recognition,In this contribution we introduce speech emotion recognition by use of continuous hidden Markov models. Two methods are propagated and compared throughout the paper. Within the first method a global statistics framework of an utterance is classified by Gaussian mixture models using derived features of the raw pitch and energy contour of the speech signal. A second method introduces increased temporal complexity applying continuous hidden Markov models considering several states using low-level instantaneous features instead of global statistics. The paper addresses the design of working recognition engines and results achieved with respect to the alluded alternatives. A speech corpus consisting of acted and spontaneous emotion samples in German and English language is described in detail. Both engines have been tested and trained using this equivalent speech corpus. Results in recognition of seven discrete emotions exceeded 86% recognition rate. As a basis of comparison the similar judgment of human deciders classifying the same corpus at 79.8% recognition rate was analyzed.,2003.0,6.0,618.0,True,"{'url': 'https://opus.bibliothek.uni-augsburg.de/opus4/files/76935/76935.pdf', 'status': None}","{'volume': '1', 'pages': 'I-401', 'name': ""2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)""}","{'bibtex': ""@Article{Schuller2003HiddenMM,\n author = {Björn Schuller and G. Rigoll and M. Lang},\n journal = {2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)},\n pages = {I-401},\n title = {Hidden Markov model-based speech emotion recognition},\n volume = {1},\n year = {2003}\n}\n""}","[{'authorId': '145411696', 'name': 'Björn Schuller'}, {'authorId': '145512909', 'name': 'G. Rigoll'}, {'authorId': '3130518', 'name': 'M. Lang'}]"
2752,f11be60b2a822e1e20d3d2224245c4222f5ce176,Collecting a Motion-Capture Corpus of American Sign Language for Data-Driven Generation Research,"American Sign Language (ASL) generation software can improve the accessibility of information and services for deaf individuals with low English literacy. The understand-ability of current ASL systems is limited; they have been constructed without the benefit of annotated ASL corpora that encode detailed human movement. We discuss how linguistic challenges in ASL generation can be addressed in a data-driven manner, and we describe our current work on collecting a motion-capture corpus. To evaluate the quality of our motion-capture configuration, calibration, and recording protocol, we conducted an evaluation study with native ASL signers.",2010.0,34.0,48.0,False,,{'pages': '89-97'},"{'bibtex': '@Inproceedings{Lu2010CollectingAM,\n author = {Pengfei Lu and Matt Huenerfauth},\n pages = {89-97},\n title = {Collecting a Motion-Capture Corpus of American Sign Language for Data-Driven Generation Research},\n year = {2010}\n}\n'}","[{'authorId': '39227955', 'name': 'Pengfei Lu'}, {'authorId': '1747703', 'name': 'Matt Huenerfauth'}]"
2753,f11ff0a7e63b2fade0bb62e50057add1fcf4e5e7,"An Investigative Study on the Effects of Pedagogical Agents on Intrinsic, Extraneous and Germane Cognitive Load: Experimental Findings With Dyscalculia and Non-Dyscalculia Learners","Several studies have warranted the need to explore the relationship between pedagogical agents in the learning environment and the cognitive load on the learners, specifically, to study the influence on learner populations with different learning and motivation needs. The present work investigates the effects of the presence of a pedagogical agent in the learning environment on intrinsic, extraneous, and germane cognitive load for the dyscalculia and non- learner population. The proposed system intelligently investigates the learner, recommends an exclusive learning dyscalculia path and after tutoring assesses learning gain, and retention. Learner experience and effects of the pedagogical agent on types of cognitive loads are discussed on basis of post tutoring analysis. Samples of 82 learners have been studied, experimental findings based on research questions have been reported and conclusions discussed. Our assumption that ‘a well-articulated and well-designed instructional design exerts a minimal extraneous cognitive load on learners and facilitates learning gain and retention’ is consistent with the obtained results. The result concludes that pedagogical agent does not add to intrinsic and extraneous cognitive load. An improved Germane Cognitive load and a good amount of knowledge retention are noticed post learning.",2022.0,0.0,5.0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9668973/09548065.pdf', 'status': None}","{'volume': '10', 'pages': '3904-3922', 'name': 'IEEE Access'}","{'bibtex': '@Article{Ahuja2022AnIS,\n author = {N. J. Ahuja and Monika Thapliyal and A. Bisht and Thompson Stephan and R. Kannan and Mabrook S. Al-Rakhami and M. Mahmud},\n journal = {IEEE Access},\n pages = {3904-3922},\n title = {An Investigative Study on the Effects of Pedagogical Agents on Intrinsic, Extraneous and Germane Cognitive Load: Experimental Findings With Dyscalculia and Non-Dyscalculia Learners},\n volume = {10},\n year = {2022}\n}\n'}","[{'authorId': '39494625', 'name': 'N. J. Ahuja'}, {'authorId': '2046976530', 'name': 'Monika Thapliyal'}, {'authorId': '40207965', 'name': 'A. Bisht'}, {'authorId': '49128514', 'name': 'Thompson Stephan'}, {'authorId': '2379062', 'name': 'R. Kannan'}, {'authorId': '3101076', 'name': 'Mabrook S. Al-Rakhami'}, {'authorId': '144774721', 'name': 'M. Mahmud'}]"
2754,f1af714b92372c8e606485a3982eab2f16772ad8,The MUG facial expression database,This paper presents a new extended collection of posed and induced facial expression image sequences. All sequences were captured in a controlled laboratory environment with high resolution and no occlusions. The collection consists of two parts: The first part depicts eighty six subjects performing the six basic expressions according to the “emotion prototypes” as defined in the Investigator's Guide in the FACS manual. The second part contains the same subjects recorded while they were watching an emotion inducing video. Most of the database recordings are available to the scientific community. Beyond the emotion related annotation the database contains also manual and automatic annotation of 80 facial landmark points for a significant number of frames. The database contains sufficient material for the development and the statistical evaluation of facial expression recognition systems using posed and induced expressions.,2010.0,10.0,319.0,False,,"{'pages': '1-4', 'name': '11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10'}","{'bibtex': '@Article{Aifanti2010TheMF,\n author = {Niki Aifanti and Christos Papachristou and A. Delopoulos},\n journal = {11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10},\n pages = {1-4},\n title = {The MUG facial expression database},\n year = {2010}\n}\n'}","[{'authorId': '1795764', 'name': 'Niki Aifanti'}, {'authorId': '2075670585', 'name': 'Christos Papachristou'}, {'authorId': '143685457', 'name': 'A. Delopoulos'}]"
2755,f1ba3f59dad906173020f65d584d81ebc6557536,Excessive use of mobile social networking sites: Negative consequences on individuals,,2016.0,56.0,152.0,False,,"{'volume': '65', 'pages': '65-76', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Zheng2016ExcessiveUO,\n author = {Xiabing Zheng and Matthew K. O. Lee},\n journal = {Comput. Hum. Behav.},\n pages = {65-76},\n title = {Excessive use of mobile social networking sites: Negative consequences on individuals},\n volume = {65},\n year = {2016}\n}\n'}","[{'authorId': '1811712', 'name': 'Xiabing Zheng'}, {'authorId': '152522619', 'name': 'Matthew K. O. Lee'}]"
2756,f1c49d48a5cb99db352e6d204e84e13c4fec42e1,"The impact of virtual, augmented and mixed reality technologies on the customer experience",,2019.0,117.0,556.0,True,,{'name': 'Journal of Business Research'},"{'bibtex': '@Article{Flavián2019TheIO,\n author = {C. Flavián and Sergio Ibáñez-Sánchez and Carlos Orús},\n journal = {Journal of Business Research},\n title = {The impact of virtual, augmented and mixed reality technologies on the customer experience},\n year = {2019}\n}\n'}","[{'authorId': '7751133', 'name': 'C. Flavián'}, {'authorId': '1402689200', 'name': 'Sergio Ibáñez-Sánchez'}, {'authorId': '34568859', 'name': 'Carlos Orús'}]"
2758,f1d225508f1ca51dc00b11a1f9583b80bccdb557,A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition,,2020.0,123.0,86.0,False,,"{'volume': '53', 'pages': '209-221', 'name': 'Inf. Fusion'}","{'bibtex': '@Article{Jiang2020ASR,\n author = {Yingying Jiang and Wei Li and M. S. Hossain and Min Chen and Abdulhameed Alelaiwi and Muneer H. Al-Hammadi},\n journal = {Inf. Fusion},\n pages = {209-221},\n title = {A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition},\n volume = {53},\n year = {2020}\n}\n'}","[{'authorId': '50262107', 'name': 'Yingying Jiang'}, {'authorId': '40400230', 'name': 'Wei Li'}, {'authorId': '2107176546', 'name': 'M. S. Hossain'}, {'authorId': '143874539', 'name': 'Min Chen'}, {'authorId': '2682134', 'name': 'Abdulhameed Alelaiwi'}, {'authorId': '1399838170', 'name': 'Muneer H. Al-Hammadi'}]"
2759,f1d790d9e67f682c38d3574e2642a9d682d72f79,The Expressive Gaze Model: Using Gaze to Express Emotion,"The Expressive Gaze Model is a hierarchical framework for composing simple behaviors into emotionally expressive gaze shifts for virtual characters. Its primary components are the Gaze Warping Transformation, which generates emotionally expressive head and torso movement in a gaze shift, and an eye movement model.",2010.0,16.0,30.0,False,,"{'volume': '30', 'pages': '62-73', 'name': 'IEEE Computer Graphics and Applications'}","{'bibtex': '@Article{Lance2010TheEG,\n author = {Brent Lance and S. Marsella},\n journal = {IEEE Computer Graphics and Applications},\n pages = {62-73},\n title = {The Expressive Gaze Model: Using Gaze to Express Emotion},\n volume = {30},\n year = {2010}\n}\n'}","[{'authorId': '145417478', 'name': 'Brent Lance'}, {'authorId': '1788771', 'name': 'S. Marsella'}]"
2761,f211a64d0cda39172d21d80cbde0565ff3a80adf,"CASA, WASA, and the dimensions of us",,2010.0,80.0,25.0,False,,"{'volume': '26', 'pages': '1761-1771', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Wisniewski2010CASAWA,\n author = {P. Wisniewski and M. Prietula},\n journal = {Comput. Hum. Behav.},\n pages = {1761-1771},\n title = {CASA, WASA, and the dimensions of us},\n volume = {26},\n year = {2010}\n}\n'}","[{'authorId': '34966245', 'name': 'P. Wisniewski'}, {'authorId': '8121434', 'name': 'M. Prietula'}]"
2762,f216ea6fc4a77ffdfb40c4d9aabd095aabcc7dfb,Does the Goal Matter? Emotion Recognition Tasks Can Change the Social Value of Facial Mimicry Towards Artificial Agents,"In this paper, we present a study aimed at understanding whether the embodiment and humanlikeness of an artificial agent can affect people’s spontaneous and instructed mimicry of its facial expressions. The study followed a mixed experimental design and revolved around an emotion recognition task. Participants were randomly assigned to one level of humanlikeness (between-subject variable: humanlike, characterlike, or morph facial texture of the artificial agents) and observed the facial expressions displayed by three artificial agents differing in embodiment (within-subject variable: video-recorded robot, physical robot, and virtual agent) and a human (control). To study both spontaneous and instructed facial mimicry, we divided the experimental sessions into two phases. In the first phase, we asked participants to observe and recognize the emotions displayed by the agents. In the second phase, we asked them to look at the agents’ facial expressions, replicate their dynamics as closely as possible, and then identify the observed emotions. In both cases, we assessed participants’ facial expressions with an automated Action Unit (AU) intensity detector. Contrary to our hypotheses, our results disclose that the agent that was perceived as the least uncanny, and most anthropomorphic, likable, and co-present, was the one spontaneously mimicked the least. Moreover, they show that instructed facial mimicry negatively predicts spontaneous facial mimicry. Further exploratory analyses revealed that spontaneous facial mimicry appeared when participants were less certain of the emotion they recognized. Hence, we postulate that an emotion recognition goal can flip the social value of facial mimicry as it transforms a likable artificial agent into a distractor. Further work is needed to corroborate this hypothesis. Nevertheless, our findings shed light on the functioning of human-agent and human-robot mimicry in emotion recognition tasks and help us to unravel the relationship between facial mimicry, liking, and rapport.",2021.0,88.0,0.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frobt.2021.699090/pdf', 'status': 'GOLD'}","{'name': 'Frontiers in Robotics and AI', 'volume': '8'}","{'bibtex': '@Article{Perugia2021DoesTG,\n author = {G. Perugia and Maike Paetzel-Prüsmann and I. Hupont and G. Varni and M. Chetouani and Christopher E. Peters and Ginevra Castellano},\n booktitle = {Frontiers in Robotics and AI},\n journal = {Frontiers in Robotics and AI},\n title = {Does the Goal Matter? Emotion Recognition Tasks Can Change the Social Value of Facial Mimicry Towards Artificial Agents},\n volume = {8},\n year = {2021}\n}\n'}","[{'authorId': '1556566185', 'name': 'G. Perugia'}, {'authorId': '2047241817', 'name': 'Maike Paetzel-Prüsmann'}, {'authorId': '2321433', 'name': 'I. Hupont'}, {'authorId': '1958033', 'name': 'G. Varni'}, {'authorId': '1680828', 'name': 'M. Chetouani'}, {'authorId': '144687810', 'name': 'Christopher E. Peters'}, {'authorId': '39540970', 'name': 'Ginevra Castellano'}]"
2763,f22d304e0c22bd29206600d9fc4ec8f234a57641,My science tutor: A conversational multimedia virtual tutor for elementary school science,"This article describes My Science Tutor (MyST), an intelligent tutoring system designed to improve science learning by students in 3rd, 4th, and 5th grades (7 to 11 years old) through conversational dialogs with a virtual science tutor. In our study, individual students engage in spoken dialogs with the virtual tutor Marni during 15 to 20 minute sessions following classroom science investigations to discuss and extend concepts embedded in the investigations. The spoken dialogs in MyST are designed to scaffold learning by presenting open-ended questions accompanied by illustrations or animations related to the classroom investigations and the science concepts being learned. The focus of the interactions is to elicit self-expression from students. To this end, Marni applies some of the principles of Questioning the Author, a proven approach to classroom conversations, to challenge students to think about and integrate new concepts with prior knowledge to construct enriched mental models that can be used to explain and predict scientific phenomena. In this article, we describe how spoken dialogs using Automatic Speech Recognition (ASR) and natural language processing were developed to stimulate students' thinking, reasoning and self explanations. We describe the MyST system architecture and Wizard of Oz procedure that was used to collect data from tutorial sessions with elementary school students. Using data collected with the procedure, we present evaluations of the ASR and semantic parsing components. A formal evaluation of learning gains resulting from system use is currently being conducted. This paper presents survey results of teachers' and children's impressions of MyST.",2011.0,91.0,98.0,False,,"{'volume': '7', 'pages': '18:1-18:29', 'name': 'ACM Trans. Speech Lang. Process.'}","{'bibtex': '@Article{Ward2011MyST,\n author = {Wayne H. Ward and R. Cole and Daniel Bolaños and Cindy Buchenroth-Martin and Edward Svirsky and Sarel van Vuuren and T. Weston and Jing Zheng and Lee Becker},\n journal = {ACM Trans. Speech Lang. Process.},\n pages = {18:1-18:29},\n title = {My science tutor: A conversational multimedia virtual tutor for elementary school science},\n volume = {7},\n year = {2011}\n}\n'}","[{'authorId': '1866226', 'name': 'Wayne H. Ward'}, {'authorId': '8089863', 'name': 'R. Cole'}, {'authorId': '144667246', 'name': 'Daniel Bolaños'}, {'authorId': '1403911433', 'name': 'Cindy Buchenroth-Martin'}, {'authorId': '2083251271', 'name': 'Edward Svirsky'}, {'authorId': '145037594', 'name': 'Sarel van Vuuren'}, {'authorId': '3035147', 'name': 'T. Weston'}, {'authorId': '2145106857', 'name': 'Jing Zheng'}, {'authorId': '2065398554', 'name': 'Lee Becker'}]"
2764,f234fc9706195a9fa884c3a49e14d7931be749ea,Modelling multimodal expression of emotion in a virtual agent,"Over the past few years we have been developing an expressive embodied conversational agent system. In particular, we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature, the model of complex expressions, follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically, typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation, we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.",2009.0,77.0,137.0,True,"{'url': 'https://europepmc.org/articles/pmc2781894?pdf=render', 'status': None}","{'volume': '364', 'pages': '3539 - 3548', 'name': 'Philosophical Transactions of the Royal Society B: Biological Sciences'}","{'bibtex': '@Article{Pelachaud2009ModellingME,\n author = {Catherine Pelachaud},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n pages = {3539 - 3548},\n title = {Modelling multimodal expression of emotion in a virtual agent},\n volume = {364},\n year = {2009}\n}\n'}","[{'authorId': '2250548269', 'name': 'Catherine Pelachaud'}]"
2767,f23a67ed6ccb43ba95731bb5867709271ffa7cc8,A first look at individuals' affective ratings of vibrations,"Affective response may dominate users' reactions to the synthesized tactile sensations that are proliferating in today's handheld and gaming devices, yet it is largely unmeasured, modeled or characterized. A better understanding of user perception will aid the design of tactile behavior that engages touch, with an experience that satisfies rather than intrudes. We measured 30 subjects' affective response to vibrations varying in rhythm and frequency, then examined how differences in demographic, everyday use of touch, and tactile processing abilities contribute to variations in affective response. To this end, we developed five affective and sensory rating scales and two tactile performance tasks, and also employed a published `Need for Touch' (NFT) questionnaire. Subjects' ratings, aggregated, showed significant correlations among the five scales and significant effect of the signal content (rhythm and frequency). Ratings varied considerably among subjects, but this variation did not coincide with demographic, NFT score or tactile task performance. The linkages found among the rating scales confirm this as a promising approach. The next step towards a comprehensive picture of individuals' patterns of affective response to tactile sensations entails pruning, integration and redundancy reduction of these scales, then their formal validation.",2013.0,24.0,54.0,False,,"{'pages': '605-610', 'name': '2013 World Haptics Conference (WHC)'}","{'bibtex': ""@Article{Seifi2013AFL,\n author = {H. Seifi and Karon E Maclean},\n journal = {2013 World Haptics Conference (WHC)},\n pages = {605-610},\n title = {A first look at individuals' affective ratings of vibrations},\n year = {2013}\n}\n""}","[{'authorId': '35750547', 'name': 'H. Seifi'}, {'authorId': '1796517', 'name': 'Karon E Maclean'}]"
2768,f25baf281c13207c2459b0264aa3fa30212ab5e8,Crowdsourcing-based Annotation of Emotions in Filipino and English Tweets,"The automatic analysis of emotions conveyed in social media content, e.g., tweets, has many beneficial applications. In the Philippines, one of the most disaster-prone countries in the world, such methods could potentially enable first responders to make timely decisions despite the risk of data deluge. However, recognising emotions expressed in Philippine-generated tweets, which are mostly written in Filipino, English or a mix of both, is a non-trivial task. In order to facilitate the development of natural language processing (NLP) methods that will automate such type of analysis, we have built a corpus of tweets whose predominant emotions have been manually annotated by means of crowdsourcing. Defining measures ensuring that only high-quality annotations were retained, we have produced a gold standard corpus of 1,146 emotion-labelled Filipino and English tweets. We validate the value of this manually produced resource by demonstrating that an automatic emotion-prediction method based on the use of a publicly available word-emotion association lexicon was unable to reproduce the labels assigned via crowdsourcing. While we are planning to make a few extensions to the corpus in the near future, its current version has been made publicly available in order to foster the development of emotion analysis methods based on advanced Filipino and English NLP.",2016.0,19.0,10.0,False,,{'pages': '74-82'},"{'bibtex': '@Inproceedings{Lapitan2016CrowdsourcingbasedAO,\n author = {F. Lapitan and R. Batista-Navarro and E. Albacea},\n pages = {74-82},\n title = {Crowdsourcing-based Annotation of Emotions in Filipino and English Tweets},\n year = {2016}\n}\n'}","[{'authorId': '35645750', 'name': 'F. Lapitan'}, {'authorId': '1400900759', 'name': 'R. Batista-Navarro'}, {'authorId': '2674576', 'name': 'E. Albacea'}]"
2769,f2743cb3cd26bad5a36fabaeb82fd86166e93b53,Automatic facial expression analysis: a survey,,2003.0,86.0,1991.0,True,"{'url': 'http://publications.idiap.ch/attachments/reports/1999/rr99-19.pdf', 'status': None}","{'volume': '36', 'pages': '259-275', 'name': 'Pattern Recognit.'}","{'bibtex': '@Article{Fasel2003AutomaticFE,\n author = {B. Fasel and J. Luettin},\n journal = {Pattern Recognit.},\n pages = {259-275},\n title = {Automatic facial expression analysis: a survey},\n volume = {36},\n year = {2003}\n}\n'}","[{'authorId': '8745904', 'name': 'B. Fasel'}, {'authorId': '1678373', 'name': 'J. Luettin'}]"
2770,f2831b3142925e73175686f1226c9388669463ca,"The media equation - how people treat computers, television, and new media like real people and places",Part I. Introduction: 1. The media equation Part II. Media and Manners: 2. Politeness 3. Interpersonal distance 4. Flattery 5. Judging others and ourselves Part III. Media and Personality: 6. Personality of characters 7. Personality of interfaces 8. Imitating a personality Part IV. Media and emotion: 9. Good versus bad 10. Negativity 11. Arousal Part V. Media and Social Roles: 12. Specialists 13. Teammates 14. Gender 15. Voices 16. Source orientation Part VI. Media and Form: 17. Image size 18. Fidelity 19. Synchrony 20. Motion 21. Scene changes 22. Subliminal images Part VII. Final Words: 23. Conclusions about the media equation References.,1996.0,0.0,5059.0,False,,"{'pages': 'I-XIII, 1-305'}","{'bibtex': '@Inproceedings{Reeves1996TheME,\n author = {Byron Reeves and C. Nass},\n pages = {I-XIII, 1-305},\n title = {The media equation - how people treat computers, television, and new media like real people and places},\n year = {1996}\n}\n'}","[{'authorId': '143923082', 'name': 'Byron Reeves'}, {'authorId': '2029850', 'name': 'C. Nass'}]"
2774,f2847dfe542ba81485161fe727a89ffc7cd850fd,Modeling adaptive perception system of virtual agent with emotion based on Q-learning,"Human make behavior by perception, modeling believable perception for a virtual agent is a meaningful topic in computer games. A model of adaptive perception of a virtual agent with emotion is proposed based on Q-learning method; the formulas of emotion value are presented. A demo system is realized on PC; an agent with the model can dynamically control the range of the perception according to virtual environment, and express believable emotions.",2010.0,7.0,0.0,False,,"{'name': '2010 International Conference on Audio, Language and Image Processing', 'pages': '941-944'}","{'bibtex': '@Conference{Hong2010ModelingAP,\n author = {Yuan Hong and Zhen Liu},\n booktitle = {International Conferences on Audio, Language and Image Processing},\n journal = {2010 International Conference on Audio, Language and Image Processing},\n pages = {941-944},\n title = {Modeling adaptive perception system of virtual agent with emotion based on Q-learning},\n year = {2010}\n}\n'}","[{'authorId': '2115377494', 'name': 'Yuan Hong'}, {'authorId': '2109341502', 'name': 'Zhen Liu'}]"
2775,f288805630dbd6637d23e6dde1fba1344297f42e,Personalizing e-Learning. The Social Effects of Pedagogical Agents,,2010.0,112.0,120.0,False,,"{'volume': '22', 'pages': '71-87', 'name': 'Educational Psychology Review'}","{'bibtex': '@Article{Krämer2010PersonalizingET,\n author = {N. Krämer and G. Bente},\n journal = {Educational Psychology Review},\n pages = {71-87},\n title = {Personalizing e-Learning. The Social Effects of Pedagogical Agents},\n volume = {22},\n year = {2010}\n}\n'}","[{'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '2487649', 'name': 'G. Bente'}]"
2776,f2c10a0ca0e10f9e68fad85ea77ad75636abde18,Interpersonal Emotion Regulation Questionnaire (IERQ): Scale Development and Psychometric Characteristics,,2016.0,59.0,132.0,True,"{'url': 'https://europepmc.org/articles/pmc4864994?pdf=render', 'status': None}","{'volume': '40', 'pages': '341-356', 'name': 'Cognitive Therapy and Research'}","{'bibtex': '@Article{Hofmann2016InterpersonalER,\n author = {S. Hofmann and Joseph K. Carpenter and Joshua E. Curtiss},\n journal = {Cognitive Therapy and Research},\n pages = {341-356},\n title = {Interpersonal Emotion Regulation Questionnaire (IERQ): Scale Development and Psychometric Characteristics},\n volume = {40},\n year = {2016}\n}\n'}","[{'authorId': '2699703', 'name': 'S. Hofmann'}, {'authorId': '32200813', 'name': 'Joseph K. Carpenter'}, {'authorId': '46627773', 'name': 'Joshua E. Curtiss'}]"
2777,f2d257625e8029f6f4998deb6279f97e07e2893c,MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations,"Emotion recognition in conversations is a challenging task that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at http://affective-meld.github.io.",2018.0,35.0,576.0,True,"{'url': 'https://www.aclweb.org/anthology/P19-1050.pdf', 'status': None}","{'volume': 'abs/1810.02508', 'name': 'ArXiv'}","{'bibtex': '@Article{Poria2018MELDAM,\n author = {Soujanya Poria and Devamanyu Hazarika and Navonil Majumder and Gautam Naik and E. Cambria and Rada Mihalcea},\n journal = {ArXiv},\n title = {MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations},\n volume = {abs/1810.02508},\n year = {2018}\n}\n'}","[{'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '2064937904', 'name': 'Gautam Naik'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}]"
2778,f2e08db0b87a1034586a3dcb4bf967fb9a0e019d,EBDI: an architecture for emotional agents,"Most of the research on multiagent systems has focused on the development of rational utility-maximizing agents. However, research shows that emotions have a strong effect on peoples' physical states, motivations, beliefs, and desires. By introducing primary and secondary emotion into BDI architecture, we present a generic architecture for an emotional agent, EBDI, which can merge various emotion theories with an agent's reasoning process. It implements practical reasoning techniques separately from the specific emotion mechanism. The separation allows us to plug in emotional models as needed or upgrade the agent's reasoning engine independently.",2007.0,32.0,128.0,False,,{'pages': '11'},"{'bibtex': '@Inproceedings{Jiang2007EBDIAA,\n author = {Hong Jiang and J. Vidal and M. Huhns},\n pages = {11},\n title = {EBDI: an architecture for emotional agents},\n year = {2007}\n}\n'}","[{'authorId': '2158159744', 'name': 'Hong Jiang'}, {'authorId': '104832894', 'name': 'J. Vidal'}, {'authorId': '1744170', 'name': 'M. Huhns'}]"
2779,f2f5238a5bde1d389f1bee5749e1fe44938c7564,Theory of Mind Profiles in Children With Autism Spectrum Disorder: Adaptive/Social Skills and Pragmatic Competence,"Theory of Mind (ToM) is one of the most relevant concepts in the field of social cognition, particularly in the case of Autism Spectrum Disorders (ASD). Literature showing that individuals with ASD display deficits in ToM is extensive and robust. However, some related issues deserve more research: the heterogeneous profile of ToM abilities in children with ASD and the association between different levels of ToM development and social, pragmatic, and adaptive behaviors in everyday life. The first objective of this study was to identify profiles of children with ASD without intellectual disability (ID), based on explicit and applied ToM knowledge, and compare these profiles with a group of children with typical development (TD). A second objective was to determine differences in symptom severity, adaptive/social behavior, and pragmatic abilities between the profiles identified. Fifty-two children with a clinical diagnosis of ASD without ID and 37 children with TD performed neuropsychological ToM tasks and two vocabulary and memory tests. In addition, all of their mothers completed different questionnaires about applied ToM abilities, severity of ASD symptoms, adaptive/social skills, and pragmatic competence. Two subgroups were identified in the cluster analysis carried out with explicit and applied ToM indicators. The “Lower ToM abilities” profile obtained significantly lower scores than the “Higher ToM abilities” profile on all the ToM measures. Furthermore, the analysis of covariance, controlling for vocabulary and working memory (ANCOVAs), showed statistically significant differences in applied ToM abilities between the two groups of children with ASD without ID and the group with TD. However, only the group with “Higher ToM abilities” achieved similar performance to the TD group on the verbal task of explicit ToM knowledge. Finally, the “Lower ToM abilities” cluster obtained significantly higher scores on autism symptoms (social and communication domains) and lower scores on adaptive behavior and pragmatic skills than the cluster with “Higher ToM abilities.” Taken together, these findings have implications for understanding the heterogeneity in ToM skills in children with ASD without ID, and their differential impact on social, communicative, and adaptive behaviors.",2020.0,100.0,33.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2020.567401/pdf', 'status': None}","{'volume': '11', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Roselló2020TheoryOM,\n author = {B. Roselló and C. Berenguer and Inmaculada Baixauli and Rosa García and A. Miranda},\n journal = {Frontiers in Psychology},\n title = {Theory of Mind Profiles in Children With Autism Spectrum Disorder: Adaptive/Social Skills and Pragmatic Competence},\n volume = {11},\n year = {2020}\n}\n'}","[{'authorId': '145285000', 'name': 'B. Roselló'}, {'authorId': '4993500', 'name': 'C. Berenguer'}, {'authorId': '3706833', 'name': 'Inmaculada Baixauli'}, {'authorId': '2109682486', 'name': 'Rosa García'}, {'authorId': '46871263', 'name': 'A. Miranda'}]"
2780,f318c892091974adb06a4d70ec2b5c5558acde4a,Nonverbal behavior and the theory of emotion: the facial feedback hypothesis.,"The facial feedback hypothesis, that skeletal muscle feedback from facial expressions plays a causal role in regulating emotional experience and behavior, is an important part of several contemporary theories of emotion. A review of relevant research indicates that studies reporting support for this hypothesis have, without exception, used within-subjects designs and that therefore only a restricted version of the hypothesis has been tested. Also, the results of some of these studies must be questioned due to demand characteristics and other problems. It is suggested that visceral feedback may make a more direct contribution to emotional processes than facial feedback does and that the ""readout"" functions of facial expressions are more important than any feedback functions.",1980.0,58.0,329.0,False,,"{'volume': '38 5', 'pages': '\n          811-24\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Buck1980NonverbalBA,\n author = {R. Buck},\n journal = {Journal of personality and social psychology},\n pages = {\n          811-24\n        },\n title = {Nonverbal behavior and the theory of emotion: the facial feedback hypothesis.},\n volume = {38 5},\n year = {1980}\n}\n'}","[{'authorId': '33400830', 'name': 'R. Buck'}]"
2781,f31df4527959a6e522efb2c2115dc8d0e3d29d49,The role of the amygdala in human fear: Automatic detection of threat,,2005.0,39.0,377.0,False,,"{'volume': '30', 'pages': '953-958', 'name': 'Psychoneuroendocrinology'}","{'bibtex': '@Article{Öhman2005TheRO,\n author = {A. Öhman},\n journal = {Psychoneuroendocrinology},\n pages = {953-958},\n title = {The role of the amygdala in human fear: Automatic detection of threat},\n volume = {30},\n year = {2005}\n}\n'}","[{'authorId': '2276310', 'name': 'A. Öhman'}]"
2782,f357cffffca307e290d113ef450db47a31115172,Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data,"Emotion recognition has become a popular topic of interest, especially in the field of human computer interaction. Previous works involve unimodal analysis of emotion, while recent efforts focus on multimodal emotion recognition from vision and speech. In this paper, we propose a new method of learning about the hidden representations between just speech and text data using convolutional attention networks. Compared to the shallow model which employs simple concatenation of feature vectors, the proposed attention model performs much better in classifying emotion from speech and text data contained in the CMU-MOSEI dataset.",2018.0,20.0,66.0,True,"{'url': 'https://www.aclweb.org/anthology/W18-3304.pdf', 'status': None}","{'volume': 'abs/1805.06606', 'name': 'ArXiv'}","{'bibtex': '@Article{Lee2018ConvolutionalAN,\n author = {C. Lee and Kyu Ye Song and Jihoon Jeong and W. Choi},\n journal = {ArXiv},\n title = {Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data},\n volume = {abs/1805.06606},\n year = {2018}\n}\n'}","[{'authorId': '2120818109', 'name': 'C. Lee'}, {'authorId': '35287507', 'name': 'Kyu Ye Song'}, {'authorId': '2115679080', 'name': 'Jihoon Jeong'}, {'authorId': '2115123897', 'name': 'W. Choi'}]"
2783,f35bed4a04d3d0cef445574bbb7303afde8a47e4,"Introduction to Data Mining, (First Edition)",,2005.0,0.0,1609.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Tan2005IntroductionTD,\n author = {P. Tan and M. Steinbach and Vipin Kumar},\n title = {Introduction to Data Mining, (First Edition)},\n year = {2005}\n}\n'}","[{'authorId': '39900740', 'name': 'P. Tan'}, {'authorId': '1707756', 'name': 'M. Steinbach'}, {'authorId': '2107978997', 'name': 'Vipin Kumar'}]"
2784,f39d53555872d83f42ac2385e2ae8e4f5e2d0282,Fully Automatic Facial Action Unit Detection and Temporal Analysis,"In this work we report on the progress of building a system that enables fully automated fast and robust facial expression recognition from face video. We analyse subtle changes in facial expression by recognizing facial muscle action units (AUs) and analysing their temporal behavior. By detecting AUs from face video we enable the analysis of various facial communicative signals including facial expressions of emotion, attitude and mood. For an input video picturing a facial expression we detect per frame whether any of 15 different AUs is activated, whether that facial action is in the onset, apex, or offset phase, and what the total duration of the activation in question is. We base this process upon a set of spatio-temporal features calculated from tracking data for 20 facial fiducial points. To detect these 20 points of interest in the first frame of an input face video, we utilize a fully automatic, facial point localization method that uses individual feature GentleBoost templates built from Gabor wavelet features. Then, we exploit a particle filtering scheme that uses factorized likelihoods and a novel observation model that combines a rigid and a morphological model to track the facial points. The AUs displayed in the input video and their temporal segments are recognized finally by Support Vector Machines trained on a subset of most informative spatio-temporal features selected by AdaBoost. For Cohn-Kanade andMMI databases, the proposed system classifies 15 AUs occurring alone or in combination with other AUs with a mean agreement rate of 90.2% with human FACS coders.",2006.0,21.0,374.0,True,"{'url': 'http://spiral.imperial.ac.uk/bitstream/10044/1/5726/1/Pantic-CVPR06-2.pdf', 'status': None}","{'pages': '149-149', 'name': ""2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)""}","{'bibtex': ""@Article{Valstar2006FullyAF,\n author = {M. Valstar and M. Pantic},\n journal = {2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)},\n pages = {149-149},\n title = {Fully Automatic Facial Action Unit Detection and Temporal Analysis},\n year = {2006}\n}\n""}","[{'authorId': '1795528', 'name': 'M. Valstar'}, {'authorId': '145387780', 'name': 'M. Pantic'}]"
2785,f3b7307bb964366ffb9d104789ca017db774397c,Spontaneous Facial Micro-Expression Recognition using 3D Spatiotemporal Convolutional Neural Networks,"Facial expression recognition in videos is an active area of research in computer vision. However, fake facial expressions are difficult to be recognized even by humans. On the other hand, facial micro-expressions generally represent the actual emotion of a person, as it is a spontaneous reaction expressed through human face. Despite of a few attempts made for recognizing micro-expressions, still the problem is far from being a solved problem, which is depicted by the poor rate of accuracy shown by the state-of-the-art methods. A few CNN based approaches are found in the literature to recognize micro-facial expressions from still images. Whereas, a spontaneous microexpression video contains multiple frames that have to be processed together to encode both spatial and temporal information. This paper proposes two 3D-CNN methods: MicroExpSTCNN and MicroExpFuseNet, for spontaneous facial micro-expression recognition by exploiting the spatiotemporal information in CNN framework. The MicroExpSTCNN considers the full spatial information, whereas the MicroExpFuseNet is based on the 3D-CNN feature fusion of the eyes and mouth regions. The experiments are performed over CAS(ME)2 and SMIC microb expression databases. The proposed MicroExpSTCNN model outperforms the state-of-the-art methods.",2019.0,49.0,68.0,True,"{'url': 'http://arxiv.org/pdf/1904.01390', 'status': None}","{'pages': '1-8', 'name': '2019 International Joint Conference on Neural Networks (IJCNN)'}","{'bibtex': '@Article{Reddy2019SpontaneousFM,\n author = {S. Reddy and Surya Teja Karri and S. Dubey and Snehasis Mukherjee},\n journal = {2019 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {Spontaneous Facial Micro-Expression Recognition using 3D Spatiotemporal Convolutional Neural Networks},\n year = {2019}\n}\n'}","[{'authorId': '145565387', 'name': 'S. Reddy'}, {'authorId': '90520607', 'name': 'Surya Teja Karri'}, {'authorId': '34992579', 'name': 'S. Dubey'}, {'authorId': '34356161', 'name': 'Snehasis Mukherjee'}]"
2786,f43fa6f5a00246958e19d3ab8fa9cd5dbb511e33,Empath: Understanding Topic Signals in Large-Scale Text,"Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like ""bleed"" and ""punch"" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r=0.906) with similar categories in LIWC.",2016.0,49.0,336.0,True,"{'url': 'https://arxiv.org/pdf/1602.06979', 'status': None}",{'name': 'Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems'},"{'bibtex': '@Article{Fast2016EmpathUT,\n author = {Ethan Fast and Binbin Chen and Michael S. Bernstein},\n journal = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},\n title = {Empath: Understanding Topic Signals in Large-Scale Text},\n year = {2016}\n}\n'}","[{'authorId': '2660071', 'name': 'Ethan Fast'}, {'authorId': '1592064987', 'name': 'Binbin Chen'}, {'authorId': '145879842', 'name': 'Michael S. Bernstein'}]"
2787,f458561ff791beee73f9dcba1d287c4ed2eec21e,Sensor-based fuzzy navigation of an autonomous mobile robot in an indoor environment,,2000.0,20.0,66.0,False,,"{'volume': '8', 'pages': '757-768', 'name': 'Control Engineering Practice'}","{'bibtex': '@Article{Maaref2000SensorbasedFN,\n author = {H. Maaref and C. Barret},\n journal = {Control Engineering Practice},\n pages = {757-768},\n title = {Sensor-based fuzzy navigation of an autonomous mobile robot in an indoor environment},\n volume = {8},\n year = {2000}\n}\n'}","[{'authorId': '2059583', 'name': 'H. Maaref'}, {'authorId': '69466176', 'name': 'C. Barret'}]"
2788,f45c260db90378c4d6dcee623ecd444b001050a5,Electroencephalography Based Fusion Two-Dimensional (2D)-Convolution Neural Networks (CNN) Model for Emotion Recognition System,"The purpose of this study is to improve human emotional classification accuracy using a convolution neural networks (CNN) model and to suggest an overall method to classify emotion based on multimodal data. We improved classification performance by combining electroencephalogram (EEG) and galvanic skin response (GSR) signals. GSR signals are preprocessed using by the zero-crossing rate. Sufficient EEG feature extraction can be obtained through CNN. Therefore, we propose a suitable CNN model for feature extraction by tuning hyper parameters in convolution filters. The EEG signal is preprocessed prior to convolution by a wavelet transform while considering time and frequency simultaneously. We use a database for emotion analysis using the physiological signals open dataset to verify the proposed process, achieving 73.4% accuracy, showing significant performance improvement over the current best practice models.",2018.0,40.0,120.0,True,"{'url': 'https://www.mdpi.com/1424-8220/18/5/1383/pdf?version=1525350358', 'status': None}","{'volume': '18', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Kwon2018ElectroencephalographyBF,\n author = {Yea-Hoon Kwon and Sae-Byuk Shin and Shin-Dug Kim},\n journal = {Sensors (Basel, Switzerland)},\n title = {Electroencephalography Based Fusion Two-Dimensional (2D)-Convolution Neural Networks (CNN) Model for Emotion Recognition System},\n volume = {18},\n year = {2018}\n}\n'}","[{'authorId': '150349599', 'name': 'Yea-Hoon Kwon'}, {'authorId': '71457620', 'name': 'Sae-Byuk Shin'}, {'authorId': '70332916', 'name': 'Shin-Dug Kim'}]"
2789,f47d1a2fa6303de9af4636b7eddf7ed585cab567,Emotion and Cognition.,,1987.0,0.0,159.0,False,,"{'volume': '20', 'pages': '127-205', 'name': 'Communication and Cognition. Monographies'}","{'bibtex': '@Article{Boekaerts1987EmotionAC,\n author = {M. Boekaerts and S. Maes},\n journal = {Communication and Cognition. Monographies},\n pages = {127-205},\n title = {Emotion and Cognition.},\n volume = {20},\n year = {1987}\n}\n'}","[{'authorId': '69866536', 'name': 'M. Boekaerts'}, {'authorId': '100780648', 'name': 'S. Maes'}]"
2790,f481dee2dd82b73c49f2db4230b35fa1e081a3f8,Quantifying Behavioral Mimicry by Automatic Detection of Nonverbal Cues from Body Motion,"Effective leadership can increase team performance, however the underlying micro-level behaviors that support team performance are still unclear. At the same time, traditional behavioral observation methods rely on manual video annotation which is a time consuming and costly process. In this work, we employ wearable motion sensors to automatically extract nonverbal cues from body motion. We utilize activity recognition methods to detect relevant nonverbal cues such as head nodding, gesticulating and posture changes. Further, we combine the detected individual cues to quantify behavioral mimicry between interaction partners. We evaluate our methods on data that was acquired during a psychological experiment in which 55 groups of three persons worked on a decision-making task. Group leaders were instructed to either lead with individual consideration orin an authoritarian way. We demonstrate that nonverbal cues can be detected with a F1-measure between 56% and 100%. Moreover, we show how our methods can highlight nonverbal behavioral differences of the two leadership styles. Our findings suggest that individually considerate leaders mimic head nods of their followers twice as often and that their face touches are mimicked three times as often by their followers when compared with authoritarian leaders.",2012.0,17.0,35.0,False,,"{'pages': '520-525', 'name': '2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing'}","{'bibtex': '@Article{Feese2012QuantifyingBM,\n author = {S. Feese and B. Arnrich and G. Tröster and Bertolt Meyer and K. Jonas},\n journal = {2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing},\n pages = {520-525},\n title = {Quantifying Behavioral Mimicry by Automatic Detection of Nonverbal Cues from Body Motion},\n year = {2012}\n}\n'}","[{'authorId': '3043165', 'name': 'S. Feese'}, {'authorId': '2798136', 'name': 'B. Arnrich'}, {'authorId': '144119654', 'name': 'G. Tröster'}, {'authorId': '46738324', 'name': 'Bertolt Meyer'}, {'authorId': '3220899', 'name': 'K. Jonas'}]"
2791,f48ae425e2567be2d993efcaaf74c2274fc9d7c5,COMET: Commonsense Transformers for Automatic Knowledge Graph Construction,"We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",2019.0,38.0,678.0,True,"{'url': 'https://www.aclweb.org/anthology/P19-1470.pdf', 'status': None}",{'pages': '4762-4779'},"{'bibtex': '@Inproceedings{Bosselut2019COMETCT,\n author = {Antoine Bosselut and Hannah Rashkin and Maarten Sap and Chaitanya Malaviya and Asli Celikyilmaz and Yejin Choi},\n pages = {4762-4779},\n title = {COMET: Commonsense Transformers for Automatic Knowledge Graph Construction},\n year = {2019}\n}\n'}","[{'authorId': '2691021', 'name': 'Antoine Bosselut'}, {'authorId': '2516777', 'name': 'Hannah Rashkin'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '8805254', 'name': 'Chaitanya Malaviya'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]"
2792,f48fecb84242c1bbc6a059b061692ce7e002fba0,The development of Messenger bots for teaching and learning and accounting students' experience of the use thereof,"This study reports on the development of two Messenger bots, designed to facilitate the learning of introductory and intermediate accounting. The Messenger bots were developed using a visual development environment that requires no coding knowledge. A thick description of the development of the Messenger bots is provided to encourage replication. It is submitted that instructors, rather than programmers, should take ownership of developing Messenger bots for teaching and learning. Preliminary exploration of the students' satisfaction yielded positive results. Suggestions are made for specific applications of Messenger bots in teaching and learning and for further research exploring the use of Messenger bots in teaching and learning. Practitioner NotesWhat is already known about this topicMobile instant messaging (MIM) applications (apps) have potential to facilitate effective social constructivist‐based collaborative learning.Students extensively use MIM apps.There is reluctance from instructors to engage in after hours MIM student consultation.Messenger bots can deliver content on demand, using inter alia text, images and video, and the effective use thereof in teaching and learning has not yet been explored.What this paper addsInstructors, without coding knowledge, are enabled to develop Messenger bots for teaching and learning.Social constructivist‐based suggestions for specific teaching and learning applications of Messenger bots are provided.Preliminary evidence suggests students positively experienced the use of Messenger bots in their learning.Implications for practice and/or policyMessenger bots may support instruction in large classes.Messenger bots may be suited to supplemental instruction rather than replacing face‐to‐face instruction.Specific teaching and learning applications of Messenger bots should be implemented and the effectiveness thereof explored. [ABSTRACT FROM AUTHOR] uracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)",2019.0,41.0,23.0,True,"{'url': 'https://repository.up.ac.za/bitstream/2263/74133/1/Schmulian_Development_2019.pdf', 'status': None}","{'volume': '50', 'pages': '2751-2777', 'name': 'Br. J. Educ. Technol.'}","{'bibtex': ""@Article{Schmulian2019TheDO,\n author = {Astrid Schmulian and S. Coetzee},\n journal = {Br. J. Educ. Technol.},\n pages = {2751-2777},\n title = {The development of Messenger bots for teaching and learning and accounting students' experience of the use thereof},\n volume = {50},\n year = {2019}\n}\n""}","[{'authorId': '75163006', 'name': 'Astrid Schmulian'}, {'authorId': '80762598', 'name': 'S. Coetzee'}]"
2793,f492e48796bcdd9a37763a563f2230a9654603cc,Rasa: Open Source Language Understanding and Dialogue Management,"We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source python libraries for building conversational software. Their purpose is to make machine-learning based dialogue management and language understanding accessible to non-specialist software developers. In terms of design philosophy, we aim for ease of use, and bootstrapping from minimal (or no) initial training data. Both packages are extensively documented and ship with a comprehensive suite of tests. The code is available at this https URL",2017.0,15.0,318.0,False,,"{'volume': 'abs/1712.05181', 'name': 'ArXiv'}","{'bibtex': '@Article{Bocklisch2017RasaOS,\n author = {Tom Bocklisch and Joe Faulkner and Nick Pawlowski and Alan Nichol},\n journal = {ArXiv},\n title = {Rasa: Open Source Language Understanding and Dialogue Management},\n volume = {abs/1712.05181},\n year = {2017}\n}\n'}","[{'authorId': '8719864', 'name': 'Tom Bocklisch'}, {'authorId': '147062331', 'name': 'Joe Faulkner'}, {'authorId': '39034356', 'name': 'Nick Pawlowski'}, {'authorId': '2058816675', 'name': 'Alan Nichol'}]"
2794,f4b518c73de023803c9c610d4cac8e9b3516434a,Physiological ResPonses to ViRtual selVes and ViRtual otheRs,"Previous research indicates that photorealistic virtual representations (i.e., agents and avatars) of the self can influence attitude and behavior change. this study was designed to test participants’ physiological reactions to exercising or still agents that resembled the self or a stranger. a within-subjects experiment tested participants’ (n = 10) skin conductance in response to running and loitering virtual selves (created from participants’ photographs) and virtual others. Participants entered a fully immersive virtual environment and observed the agents as their physiological response was measured. arousal was greatest when exposed to a running virtual self or a loitering virtual other. the finding that the virtual self causes physiological arousal may explain why a running virtual self has been shown in previous research to increase exercise behavior after exposure. implications for the development of Virtual Reality exercise treatments and other virtual therapies are discussed.",2012.0,20.0,29.0,False,,,"{'bibtex': '@Inproceedings{Fox2012PhysiologicalRT,\n author = {Jesse Fox and J. Bailenson and T. Ricciardi},\n title = {Physiological ResPonses to ViRtual selVes and ViRtual otheRs},\n year = {2012}\n}\n'}","[{'authorId': '143619505', 'name': 'Jesse Fox'}, {'authorId': '1737161', 'name': 'J. Bailenson'}, {'authorId': '95101383', 'name': 'T. Ricciardi'}]"
2795,f4fc65dcd1789d6300bccd7fa390bfeeb8853b47,Cognition and Multi-Agent Interaction: The CLARION Cognitive Architecture: Extending Cognitive Modeling to Social Simulation,,2005.0,0.0,204.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Sun2005CognitionAM,\n author = {R. Sun},\n title = {Cognition and Multi-Agent Interaction: The CLARION Cognitive Architecture: Extending Cognitive Modeling to Social Simulation},\n year = {2005}\n}\n'}","[{'authorId': '145966408', 'name': 'R. Sun'}]"
2797,f59c8ad5a1527df51ad51d74bd02fdacf5910df4,Synthesizing multimodal utterances for conversational agents,"Conversational agents are supposed to combine speech with non‐verbal modalities for intelligible multimodal utterances. In this paper, we focus on the generation of gesture and speech from XML‐based descriptions of their overt form. An incremental production model is presented that combines the synthesis of synchronized gestural, verbal, and facial behaviors with mechanisms for linking them in fluent utterances with natural co‐articulation and transition effects. In particular, an efficient kinematic approach for animating hand gestures from shape specifications is presented, which provides fine adaptation to temporal constraints that are imposed by cross‐modal synchrony. Copyright © 2004 John Wiley & Sons, Ltd.",2004.0,24.0,283.0,True,"{'url': 'http://www.techfak.uni-bielefeld.de/~skopp/download/JCAVW.pdf', 'status': None}","{'volume': '15', 'name': 'Computer Animation and Virtual Worlds'}","{'bibtex': '@Article{Kopp2004SynthesizingMU,\n author = {S. Kopp and I. Wachsmuth},\n journal = {Computer Animation and Virtual Worlds},\n title = {Synthesizing multimodal utterances for conversational agents},\n volume = {15},\n year = {2004}\n}\n'}","[{'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}]"
2798,f5af862bfabeb4fbafffc29d8d202bce0272086f,The Role of Gesture in Learning: Do Children Use Their Hands to Change Their Minds?,"Adding gesture to spoken instructions makes those instructions more effective. The question we ask here is why. A group of 49 third and fourth grade children were given instruction in mathematical equivalence with gesture or without it. Children given instruction that included a correct problem-solving strategy in gesture were significantly more likely to produce that strategy in their own gestures during the same instruction period than children not exposed to the strategy in gesture. Those children were then significantly more likely to succeed on a posttest than children who did not produce the strategy in gesture. Gesture during instruction encourages children to produce gestures of their own, which, in turn, leads to learning. Children may be able to use their hands to change their minds.",2006.0,51.0,282.0,False,,"{'volume': '7', 'pages': '211 - 232', 'name': 'Journal of Cognition and Development'}","{'bibtex': '@Article{Cook2006TheRO,\n author = {S. Cook and S. Goldin‐Meadow},\n journal = {Journal of Cognition and Development},\n pages = {211 - 232},\n title = {The Role of Gesture in Learning: Do Children Use Their Hands to Change Their Minds?},\n volume = {7},\n year = {2006}\n}\n'}","[{'authorId': '2995580', 'name': 'S. Cook'}, {'authorId': '115377287', 'name': 'S. Goldin‐Meadow'}]"
2799,f5c903a49bf6c97db58e8fe5ee010fc92ef07ef9,Learning From Real-Life Experiences : A Data-Driven Emotion Contagion Approach Towards More Realistic Virtual,"We propose a data-driven approach for measuring, validating and optimizing crowd simulation systems by learning parameters from real-life videos. We discuss the common traits of incidents and their video footage suitable for the learning step. We then demonstrate the learning process in a real-life incident that happened in 2015, Ankara, Turkey. We reanimate the incident with an existing emotion contagion and crowd simulation framework and optimize the parameters that take role in defining agent behavior with respect to the data extracted from the video footage of the incident.",2017.0,25.0,1.0,False,,,"{'bibtex': '@Inproceedings{Basak2017LearningFR,\n author = {A. E. Basak},\n title = {Learning From Real-Life Experiences : A Data-Driven Emotion Contagion Approach Towards More Realistic Virtual},\n year = {2017}\n}\n'}","[{'authorId': '32565728', 'name': 'A. E. Basak'}]"
2800,f5db81872b51e00c1e74e8bf5da08309c6434d02,"Modelling collective decision making in groups and crowds: Integrating social contagion and interacting emotions, beliefs and intentions",,2013.0,59.0,139.0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10458-012-9201-1.pdf', 'status': None}","{'volume': '27', 'pages': '52-84', 'name': 'Autonomous Agents and Multi-Agent Systems'}","{'bibtex': '@Article{Bosse2013ModellingCD,\n author = {T. Bosse and M. Hoogendoorn and M. Klein and Jan Treur and C. N. V. D. Wal and A. V. Wissen},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {52-84},\n title = {Modelling collective decision making in groups and crowds: Integrating social contagion and interacting emotions, beliefs and intentions},\n volume = {27},\n year = {2013}\n}\n'}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '144074133', 'name': 'M. Hoogendoorn'}, {'authorId': '144038398', 'name': 'M. Klein'}, {'authorId': '1726343', 'name': 'Jan Treur'}, {'authorId': '1881843', 'name': 'C. N. V. D. Wal'}, {'authorId': '1809908', 'name': 'A. V. Wissen'}]"
2803,f5e4f0671bc755620aa12bd11071160132d4468c,Adherence to medication.,,2005.0,0.0,3919.0,False,,"{'volume': '353 18', 'pages': '\n          1972-4; author reply 1972-4\n        ', 'name': 'The New England journal of medicine'}","{'bibtex': '@Article{Lippman2005AdherenceTM,\n author = {A. Lippman},\n journal = {The New England journal of medicine},\n pages = {\n          1972-4; author reply 1972-4\n        },\n title = {Adherence to medication.},\n volume = {353 18},\n year = {2005}\n}\n'}","[{'authorId': '96232643', 'name': 'A. Lippman'}]"
2804,f5e61ef588ad90ec1d6349d23c8af8d00eaf457a,Integrating Empathy and Interpersonal Emotion Regulation.,"When individuals experience empathy, they often seek to bolster others' well-being. But what do empathizers want others to feel? Though psychologists have studied empathy and prosociality for decades, this question has yet to be clearly addressed. This is because virtually all existing research focuses on a model under which improving others' well-being also comprises heightening their positive affect or decreasing their negative affect and helping them reach their own emotional goals. In this review, I argue that real-life empathic goals encompass a broader range-including sometimes worsening targets' affect or contravening their wishes in order to improve their well-being-that can be productively integrated into the framework of interpersonal emotion regulation (IER). I review the empathic IER spectrum in a number of contexts, including close relationships, professional caregiving, and group-based emotions. Integrating empathy and IER provides a synthetic and generative way to ask new questions about how social emotions produce prosocial actions. Expected final online publication date for the Annual Review of Psychology, Volume 71 is January 4, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",2020.0,154.0,87.0,False,,{'name': 'Annual review of psychology'},"{'bibtex': '@Article{Zaki2020IntegratingEA,\n author = {Jamil Zaki},\n journal = {Annual review of psychology},\n title = {Integrating Empathy and Interpersonal Emotion Regulation.},\n year = {2020}\n}\n'}","[{'authorId': '2268731', 'name': 'Jamil Zaki'}]"
2805,f5fa683bfaf0fbb41030e10326dce01b74d3b609,What is the Truth of Simulation?,"To understand the epistemological meaning of simulation, it does not suffice to interpret simulation practice and theory in the framework of philosophy of science alone. Theory, experiment, measurement and observation are important activities of the scientific method. But what regards an epistemological interpretation of simulation, philosophical truth theories allow gaining additional insights. This paper discusses philosophical truth theories â€“ e.g. the correspondence, coherence and consensus theory â€“ and relates them to simulation practice and methodology, focussing on validation.",2005.0,0.0,50.0,False,,"{'volume': '8', 'name': 'J. Artif. Soc. Soc. Simul.'}","{'bibtex': '@Article{Schmid2005WhatIT,\n author = {A. Schmid},\n journal = {J. Artif. Soc. Soc. Simul.},\n title = {What is the Truth of Simulation?},\n volume = {8},\n year = {2005}\n}\n'}","[{'authorId': '71304100', 'name': 'A. Schmid'}]"
2806,f61b5b5b66670b1ae468743ec56b7f9e7b165320,A randomized waitlist‐controlled trial of cognitive behavior therapy to improve emotion regulation in children with autism,"Background Mental health problems are common among individuals with autism spectrum disorder (ASD), and difficulties with emotion regulation processes may underlie these issues. Cognitive behavior therapy (CBT) is considered an efficacious treatment for anxiety in children with ASD. Additional research is needed to examine the efficacy of a transdiagnostic treatment approach, whereby the same treatment can be applied to multiple emotional problems, beyond solely anxiety. The purpose of the present study was to examine the efficacy of a manualized and individually delivered 10‐session, transdiagnostic CBT intervention, aimed at improving emotion regulation and mental health difficulties in children with ASD. Methods Sixty‐eight children (M age = 9.75, SD = 1.27) and their parents participated in the study, randomly allocated to either a treatment immediate (n = 35) or waitlist control condition (n = 33) (ISRCTN #67079741). Parent‐, child‐, and clinician‐reported measures of emotion regulation and mental health were administered at baseline, postintervention/postwaitlist, and at 10‐week follow‐up. Results Children in the treatment immediate condition demonstrated significant improvements on measures of emotion regulation (i.e., emotionality, emotion regulation abilities with social skills) and aspects of psychopathology (i.e., a composite measure of internalizing and externalizing symptoms, adaptive behaviors) compared to those in the waitlist control condition. Treatment gains were maintained at follow‐up. Conclusions This study is the first transdiagnostic CBT efficacy trial for children with ASD. Additional investigations are needed to further establish its relative efficacy compared to more traditional models of CBT for children with ASD and other neurodevelopmental conditions.",2018.0,80.0,95.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jcpp.12915', 'status': None}","{'volume': '59', 'pages': '1180 - 1191', 'name': 'Journal of Child Psychology and Psychiatry, and Allied Disciplines'}","{'bibtex': '@Article{Weiss2018ARW,\n author = {J. Weiss and K. Thomson and Priscilla Burnham Riosa and C. Albaum and Victoria Chan and Andrea L. Maughan and P. Tablon and Karen R. Black},\n journal = {Journal of Child Psychology and Psychiatry, and Allied Disciplines},\n pages = {1180 - 1191},\n title = {A randomized waitlist‐controlled trial of cognitive behavior therapy to improve emotion regulation in children with autism},\n volume = {59},\n year = {2018}\n}\n'}","[{'authorId': '2150018495', 'name': 'J. Weiss'}, {'authorId': '34628583', 'name': 'K. Thomson'}, {'authorId': '4079867', 'name': 'Priscilla Burnham Riosa'}, {'authorId': '40974129', 'name': 'C. Albaum'}, {'authorId': '2057710352', 'name': 'Victoria Chan'}, {'authorId': '31412592', 'name': 'Andrea L. Maughan'}, {'authorId': '5550702', 'name': 'P. Tablon'}, {'authorId': '36172799', 'name': 'Karen R. Black'}]"
2807,f637fe5fd1aeb081c3514c3ef1fcba1686693c96,A Dancing Virtual Agent to Evoke Human Emotions,"This paper presents an experimental study investigating the impact of dancing IVAs on human emotions. The results showed that watching a dancing IVA depicting different emotions significantly influenced human emotions. Additionally, the participant's anger, sadness and happiness were significantly dependent on which dancing character's emotion they watched. Moreover, the results of the study showed that while most of the participants were able to recognize the emotions depicted by the dancing IVA, correct recognition of the dancing IVAs' emotions was not necessary to have the intended influence on human emotions. These results suggest that some of the benefits associated with dancing, such as dance therapy, could be achieved just by watching an IVA.",2015.0,9.0,1.0,False,,{'pages': '1701-1702'},"{'bibtex': '@Article{Richards2015ADV,\n author = {Deborah Richards and Jon Cedric Roxas and A. Bilgin and Nader Hanna},\n booktitle = {Adaptive Agents and Multi-Agent Systems},\n pages = {1701-1702},\n title = {A Dancing Virtual Agent to Evoke Human Emotions},\n year = {2015}\n}\n'}","[{'authorId': '144037536', 'name': 'Deborah Richards'}, {'authorId': '2768530', 'name': 'Jon Cedric Roxas'}, {'authorId': '36367022', 'name': 'A. Bilgin'}, {'authorId': '50561368', 'name': 'Nader Hanna'}]"
2808,f63a0a19fa4dec1f0eefbaf7d995858a79457c9d,A pilot study on evaluating children with autism spectrum disorder using computer games,,2019.0,50.0,44.0,False,,"{'volume': '90', 'pages': '204-214', 'name': 'Comput. Hum. Behav.'}","{'bibtex': '@Article{Chen2019APS,\n author = {Jingying Chen and Guangshuai Wang and Kun Zhang and Guanghai Wang and Leyuan Liu},\n journal = {Comput. Hum. Behav.},\n pages = {204-214},\n title = {A pilot study on evaluating children with autism spectrum disorder using computer games},\n volume = {90},\n year = {2019}\n}\n'}","[{'authorId': '4118522', 'name': 'Jingying Chen'}, {'authorId': '35208531', 'name': 'Guangshuai Wang'}, {'authorId': '2119016639', 'name': 'Kun Zhang'}, {'authorId': '2152584776', 'name': 'Guanghai Wang'}, {'authorId': '47967898', 'name': 'Leyuan Liu'}]"
2809,f6636139599cabcc73940c4aa28a82d6ed47f0b7,LARNet: Real-Time Detection of Facial Micro Expression Using Lossless Attention Residual Network,"Facial micro expressions are brief, spontaneous, and crucial emotions deep inside the mind, reflecting the actual thoughts for that moment. Humans can cover their emotions on a large scale, but their actual intentions and emotions can be extracted at a micro-level. Micro expressions are organic when compared with macro expressions, posing a challenge to both humans, as well as machines, to identify. In recent years, detection of facial expressions are widely used in commercial complexes, hotels, restaurants, psychology, security, offices, and education institutes. The aim and motivation of this paper are to provide an end-to-end architecture that accurately detects the actual expressions at the micro-scale features. However, the main research is to provide an analysis of the specific parts that are crucial for detecting the micro expressions from a face. Many states of the art approaches have been trained on the micro facial expressions and compared with our proposed Lossless Attention Residual Network (LARNet) approach. However, the main research on this is to provide analysis on the specific parts that are crucial for detecting the micro expressions from a face. Many CNN-based approaches extracts the features at local level which digs much deeper into the face pixels. However, the spatial and temporal information extracted from the face is encoded in LARNet for a feature fusion extraction on specific crucial locations, such as nose, cheeks, mouth, and eyes regions. LARNet outperforms the state-of-the-art methods with a slight margin by accurately detecting facial micro expressions in real-time. Lastly, the proposed LARNet becomes accurate and better by training with more annotated data.",2021.0,58.0,13.0,True,"{'url': 'https://www.mdpi.com/1424-8220/21/4/1098/pdf?version=1612690729', 'status': None}","{'volume': '21', 'name': 'Sensors (Basel, Switzerland)'}","{'bibtex': '@Article{Hashmi2021LARNetRD,\n author = {Mohammad Farukh Hashmi and B. Ashish and Vivek Sharma and A. Keskar and N. Bokde and J. Yoon and Z. Geem},\n journal = {Sensors (Basel, Switzerland)},\n title = {LARNet: Real-Time Detection of Facial Micro Expression Using Lossless Attention Residual Network},\n volume = {21},\n year = {2021}\n}\n'}","[{'authorId': '38986955', 'name': 'Mohammad Farukh Hashmi'}, {'authorId': '71501260', 'name': 'B. Ashish'}, {'authorId': '50633800', 'name': 'Vivek Sharma'}, {'authorId': '144197980', 'name': 'A. Keskar'}, {'authorId': '3430682', 'name': 'N. Bokde'}, {'authorId': '2304191', 'name': 'J. Yoon'}, {'authorId': '2309195', 'name': 'Z. Geem'}]"
2810,f663f5eb76d4e1860d1ef6be9fbae1121ec67423,A Multitask Multimodal Ensemble Model for Sentiment- and Emotion-Aided Tweet Act Classification,"Speech act classification determining the communicative intent of an utterance has been studied widely over the years as an independent task. This holds true for discussion in any for a, including social media platforms such as Twitter. However, the tweeter’s emotional state has a huge impact on its pragmatic content because communication is fundamentally characterized and mediated by direct emotions. Sentiment as a human behavior often has a strong relation to emotion, and one helps to understand the other better. We hypothesize that the association between emotion and sentiment will provide a clearer understanding of the tweeter’s state of mind, aiding the identification of tweet acts (speech acts in Twitter, TAs). As the first step, we create a new multimodal, emotion-TA, EmoTA dataset collected from the open-source Twitter dataset. To incorporate these multiple aspects, we propose a multitask ensemble adversarial learning framework for multimodal TA classification (TAC). In addition, we also incorporate a joint embedding network, with bidirectional constraints to capture and efficiently integrate the shared semantic relationships across modalities and learn generalized features across multiple tasks. Experimental results indicate that the proposed framework boosts the performance of the primary task, TAC, by benefiting from the two secondary tasks, i.e., sentiment and emotion analyses compared to its unimodal and single-task TAC variants.",2022.0,0.0,18.0,False,,"{'volume': '9', 'pages': '508-517', 'name': 'IEEE Transactions on Computational Social Systems'}","{'bibtex': '@Article{Saha2022AMM,\n author = {Tulika Saha and Apoorva Upadhyaya and S. Saha and P. Bhattacharyya},\n journal = {IEEE Transactions on Computational Social Systems},\n pages = {508-517},\n title = {A Multitask Multimodal Ensemble Model for Sentiment- and Emotion-Aided Tweet Act Classification},\n volume = {9},\n year = {2022}\n}\n'}","[{'authorId': '52219377', 'name': 'Tulika Saha'}, {'authorId': '2000036680', 'name': 'Apoorva Upadhyaya'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}]"
2811,f669a3fe78d0405899dc572e7622fc020b71b317,KQML as an agent communication language,"This paper describes the design of and experimentation with the Knowledge Query and Manipulation Language (KQML), a new language and protocol for exchanging information and knowledge. This work is part of a larger effort, the ARPA Knowledge Sharing Effort which is aimed at developing techniques and methodology for building large-scale knowledge bases which are sharable and reusable. KQML is both a message format and a message-handling protocol to support run-time knowledge sharing among agents. KQML focuses on an extensible set of performatives, which defines the permissible “speech acts” agents may use and comprise a substrate on which to develop higher-level models of interagent interaction such as contract nets and negotiation. In addition, KQML provides a basic architecture for knowledge sharing through a special class of agent called communication facilitors which coordinate the interactions of other agents. The ideas which underlie the evolving design of KQML are currently being explored through experimental prototype systems which are being used to support several testbeds in such areas as concurrent engineering, intelligent design and intelligent planning and scheduling.",1994.0,37.0,2599.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/191246.191322', 'status': None}",{'pages': '456-463'},"{'bibtex': '@Inproceedings{Finin1994KQMLAA,\n author = {Timothy W. Finin and R. Fritzson and D. McKay and R. McEntire},\n pages = {456-463},\n title = {KQML as an agent communication language},\n year = {1994}\n}\n'}","[{'authorId': '144121212', 'name': 'Timothy W. Finin'}, {'authorId': '1910723', 'name': 'R. Fritzson'}, {'authorId': '39552279', 'name': 'D. McKay'}, {'authorId': '144568707', 'name': 'R. McEntire'}]"
2812,f66ca043c9fffccd3e1ea82687d04aa868ae51f1,A meta-analysis of emotional reactivity in major depressive disorder.,,2008.0,122.0,768.0,False,,"{'volume': '28 4', 'pages': '\n          676-91\n        ', 'name': 'Clinical psychology review'}","{'bibtex': '@Article{Bylsma2008AMO,\n author = {Lauren M. Bylsma and B. Morris and J. Rottenberg},\n journal = {Clinical psychology review},\n pages = {\n          676-91\n        },\n title = {A meta-analysis of emotional reactivity in major depressive disorder.},\n volume = {28 4},\n year = {2008}\n}\n'}","[{'authorId': '3822686', 'name': 'Lauren M. Bylsma'}, {'authorId': '6953013', 'name': 'B. Morris'}, {'authorId': '6141636', 'name': 'J. Rottenberg'}]"
2813,f6957dfccf90254e970fa6da834649457fd1cd79,An Affective Virtual Agent for Natural Human-Agent Interaction,"Figure 1: The affect model used by the agent Through simulations, we tested these models for internal consistency and were successful in establishing the relationships among the factors as suggested by the earlier user studies [3]. We confronted our agent system with real users to check whether users recognize that our agents function in similar ways as humans do. Through a structured questionnaire, users informed us that they recognized that our agents evaluated the user's aesthetics and moral stance while building up a level of involvement with the user and a degree of willingness to interact with the user again [4]. In future research, we plan to focus on more factors, such as affordances and realism, compare the performance of several emotion models with each other and a Wizard of Oz condition of human-human interaction, which allows for making stronger claims to the behavioral fidelity of an agent’s affective response mechanisms.",2010.0,4.0,0.0,False,,"{'name': '', 'volume': ''}","{'bibtex': '@Inproceedings{Pontier2010AnAV,\n author = {Pontier and M. Otte and J. Hoorn and Vũ and F. Wetenschappen},\n title = {An Affective Virtual Agent for Natural Human-Agent Interaction},\n year = {2010}\n}\n'}","[{'authorId': '118596324', 'name': 'Pontier'}, {'authorId': '20751226', 'name': 'M. Otte'}, {'authorId': '71825175', 'name': 'J. Hoorn'}, {'authorId': '2060285239', 'name': 'Vũ'}, {'authorId': '51967394', 'name': 'F. Wetenschappen'}]"
2814,f696ac49c6ef4fec6c8a572ebf02f0d54f09f400,Decoding Emotional Experience through Physiological Signal Processing,"There is an increasing consensus among re- searchers that making a computer emotionally intelligent with the ability to decode human affective states would allow a more meaningful and natural way of human-computer interactions (HCIs). One unobtrusive and non-invasive way of recognizing human affective states entails the exploration of how physiological signals vary under different emotional experiences. In particular, this paper explores the correlation between autonomically-mediated changes in multimodal body signals and discrete emotional states. In order to fully exploit the information in each modality, we have provided an innovative classification approach for three specific physiological signals including Electromyogram (EMG), Blood Volume Pressure (BVP) and Galvanic Skin Response (GSR). These signals are analyzed as inputs to an emotion recognition paradigm based on fusion of a series of weak learners. Our proposed classification approach showed 88.1% recognition accuracy, which outperformed the conventional Support Vector Machine (SVM) classifier with 17% accuracy improvement. Furthermore, in order to avoid information redundancy and the resultant over-fitting, a feature reduction method is proposed based on a correlation analysis to optimize the number of features required for training and validating each weak learner. Results showed that despite the feature space dimensionality reduction from 27 to 18 features, our methodology preserved the recognition accuracy of about 85.0%. This reduction in complexity will get us one step closer towards embedding this human emotion encoder in the wireless and wearable HCI platforms.",2016.0,32.0,15.0,False,,"{'volume': 'abs/1606.00370', 'name': 'ArXiv'}","{'bibtex': '@Article{Perez-Rosero2016DecodingEE,\n author = {Maria S. Perez-Rosero and B. Rezaei and M. Akçakaya and S. Ostadabbas},\n journal = {ArXiv},\n title = {Decoding Emotional Experience through Physiological Signal Processing},\n volume = {abs/1606.00370},\n year = {2016}\n}\n'}","[{'authorId': '1414180052', 'name': 'Maria S. Perez-Rosero'}, {'authorId': '3421983', 'name': 'B. Rezaei'}, {'authorId': '38709326', 'name': 'M. Akçakaya'}, {'authorId': '2225783', 'name': 'S. Ostadabbas'}]"
2815,f69ed437c21c30ba7992b0f95380bddace1d4e4a,Group-based Emotions in Teams of Humans and Robots,"Providing social robots an internal model of emotions can help them guide their behaviour in a more humane manner by simulating the ability to feel empathy towards others. Furthermore, the growing interest in creating robots that are capable of collaborating with other humans in team settings provides an opportunity to explore another side of human emotion, namely, group-based emotions. This paper contributes with the first model on group-based emotions in social robotic partners. We defined a model of group-based emotions for social robots that allowed us to create two distinct robotic characters that express either individual or group-based emotions. This paper also contributes with a user study where two autonomous robots embedded the previous characters, and formed two human-robot teams to play a competitive game. Our results showed that participants perceived the robot that expresses group-based emotions as more likeable and attributed higher levels of group identification and group trust towards their teams, when compared to the robotic partner that expresses individual-based emotions.",2018.0,50.0,65.0,False,,"{'pages': '261-269', 'name': '2018 13th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Correia2018GroupbasedEI,\n author = {Filipa Correia and S. Mascarenhas and R. Prada and Francisco S. Melo and Ana Paiva},\n journal = {2018 13th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {261-269},\n title = {Group-based Emotions in Teams of Humans and Robots},\n year = {2018}\n}\n'}","[{'authorId': '144106225', 'name': 'Filipa Correia'}, {'authorId': '145689493', 'name': 'S. Mascarenhas'}, {'authorId': '143825592', 'name': 'R. Prada'}, {'authorId': '145125979', 'name': 'Francisco S. Melo'}, {'authorId': '145136631', 'name': 'Ana Paiva'}]"
2816,f6c6ae791bf0696a4053e171fd27918e8fc17ab3,Continuum crowds,"We present a real-time crowd model based on continuum dynamics. In our model, a dynamic potential field simultaneously integrates global navigation with moving obstacles such as other people, efficiently solving for the motion of large crowds without the need for explicit collision avoidance. Simulations created with our system run at interactive rates, demonstrate smooth flow under a variety of conditions, and naturally exhibit emergent phenomena that have been observed in real crowds.",2006.0,40.0,947.0,False,,{'name': 'ACM SIGGRAPH 2006 Papers'},"{'bibtex': '@Article{Treuille2006ContinuumC,\n author = {Adrien Treuille and Seth Cooper and Zoran Popovic},\n journal = {ACM SIGGRAPH 2006 Papers},\n title = {Continuum crowds},\n year = {2006}\n}\n'}","[{'authorId': '3064395', 'name': 'Adrien Treuille'}, {'authorId': '145442343', 'name': 'Seth Cooper'}, {'authorId': '1986848', 'name': 'Zoran Popovic'}]"
2817,f6cfe53eb436df75fa2883c9cf9130621fbb28e0,SCALABLE AND FLEXIBLE APPRAISAL MODELS FOR VIRTUAL AGENTS,"Computational models of emotion are useful in a variety of domains, including games, virtual realty training and HCI to name a few. Many of these models are inspired by appraisal theory. Most appraisal theories share with virtual agents the assumption that beliefs, desires and intentions are the basis of reasoning and thus of the emotional evaluation of the agent's situation. Consequently most computational models of emotion are deeply embedded into the agent model. In this paper we address the problem of how to emotionally instrument a system in a modular and extensible way, so that emotional sophistication can be added incrementally to a system. We propose a solution based on a modular, signalbased approach to computational emotions that allows us to develop scalable appraisal models that are easily added to non-emotional systems. Our approach allows runtime tradeoff between emotional quality and performance, which makes it particularly useful in domains in which available computation time is unknown, like the gaming domain. We present experimental results that back-up our approach.",2005.0,13.0,35.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Broekens2005SCALABLEAF,\n author = {J. Broekens},\n title = {SCALABLE AND FLEXIBLE APPRAISAL MODELS FOR VIRTUAL AGENTS},\n year = {2005}\n}\n'}","[{'authorId': '1735303', 'name': 'J. Broekens'}]"
2818,f6ed2e59d7dbd451e12e609344a1f0a35879eeb9,A Parameterized Action Representation for Virtual Human Agents,"We describe a Parameterized Action Representation (PAR) designed to bridge the gap between natural language instructions and the virtual agents who are to carry them out. The PAR is therefore constructed based jointly on implemented motion capabilities of virtual human figures and linguistic requirements for instruction interpretation. We will illustrate PAR and a real-time execution architecture controlling 3D animated virtual human avatars. Comments Postprint version. Published in American Association for Artificial Intelligence, Spring Synposium, 2000. Author(s) Norman I. Badler, Ramamani Bindiganavale, Juliet C. Bourne, Martha Palmer, Jianping Shi, and William Schuler This journal article is available at ScholarlyCommons: http://repository.upenn.edu/hms/26 A Parameterized Action Representation for Virtual Human Agents Norman Badler, Rama Bindiganavale, Juliet Bourne Martha Palmer, Jianping Shi, William Schuler Center for Human Modeling and Simulation Computer and Information Science Department University of Pennsylvania Philadelphia, PA 19104-6389",2001.0,16.0,187.0,True,"{'url': 'https://repository.upenn.edu/bitstreams/3ef8bc75-9430-4702-b6ea-36568b6aefce/download', 'status': None}","{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Badler2001APA,\n author = {N. Badler and R. Bindiganavale and J. Allbeck and William Schuler and Liwei Zhao and Martha Palmer},\n title = {A Parameterized Action Representation for Virtual Human Agents},\n year = {2001}\n}\n'}","[{'authorId': '1699200', 'name': 'N. Badler'}, {'authorId': '1936110', 'name': 'R. Bindiganavale'}, {'authorId': '1855748', 'name': 'J. Allbeck'}, {'authorId': '1747648', 'name': 'William Schuler'}, {'authorId': '2427954', 'name': 'Liwei Zhao'}, {'authorId': '145755155', 'name': 'Martha Palmer'}]"
2819,f700b901d0575f781ed144d33fae11e545854dc8,Emotion recognition employing ECG and GSR signals as markers of ANS,"Change in GSR and ECG signals are expression of Autonomic Nervous System response to change in environment and physiological system. In this study, we evaluate the effectiveness of GSR and ECG in emotional state recognition. We took into account three mutually exclusive emotional stateshappy, sad and neutral and three different approaches to recognize these emotional states. The results indicate that to classify opposite valence emotion (happy and sad) GSR solely is capable of recognizing emotions with enhanced accuracy with a minimum accuracy of 99.44%. However, in classifying emotionally active state (happy or sad) in reference to neutral state, combined feature set of both ECG and GSR is more effective, especially the combination of PSD features and SVM classifier, providing a high accuracy for classifying all three emotional states.",2016.0,27.0,46.0,False,,"{'pages': '37-42', 'name': '2016 Conference on Advances in Signal Processing (CASP)'}","{'bibtex': '@Article{Das2016EmotionRE,\n author = {Priyanka Das and A. Khasnobish and D. Tibarewala},\n journal = {2016 Conference on Advances in Signal Processing (CASP)},\n pages = {37-42},\n title = {Emotion recognition employing ECG and GSR signals as markers of ANS},\n year = {2016}\n}\n'}","[{'authorId': '2114942112', 'name': 'Priyanka Das'}, {'authorId': '1717521', 'name': 'A. Khasnobish'}, {'authorId': '145915837', 'name': 'D. Tibarewala'}]"
2820,f7034bcd3f6addd7b2801f289cd17c6acd3e1835,"Descartes' error: emotion, reason, and the human brain. avon books","Descartes' Error offers the scientific basis for ending the division between mind and body. Antonio Damasio contends that rational decisions are not the product of logic alone - they require the support of emotion and feeling. Drawing on his experience with neurological patients affected with brain damage, Dr Damasio shows how absence of emotions and feelings can break down rationality. He also offers a new perspective on what emotions and feelings actually are: a direct view of our own body states; a link between the body and its survival-oriented regulation on the one hand, and consciousness on the other. Written as a conversation between the author and an imaginary listener, Descartes' Error leads us to conclude that human organisms are endowed from their very beginning with a spirited passion for making choices, which the social mind can then use to build rational behaviour.",1994.0,0.0,5530.0,False,,"{'volume': '', 'name': ''}","{'bibtex': ""@Inproceedings{Damasio1994DescartesEE,\n author = {A. Damasio},\n title = {Descartes' error: emotion, reason, and the human brain. avon books},\n year = {1994}\n}\n""}","[{'authorId': '2656777', 'name': 'A. Damasio'}]"
2821,f7113e72260f51d29a2d4269a97bdb8ffcc63fc6,Behavioral / Systems / Cognitive Selective Visual Attention to Emotion,"Harald T. Schupp,1 Jessica Stockburger,1 Maurizio Codispoti,2 Markus Junghöfer,3 Almut I. Weike,4 and Alfons O. Hamm4 1Department of Psychology, University of Konstanz, 78457 Konstanz, Germany, 2Department of Psychology, University of Bologna, 40127 Bologna, Italy, 3Institute for Biomagnetism and Biosignalanalysis, University of Münster, 48149 Münster, Germany, and 4Department of Psychology, University of Greifswald, 17487 Greifswald, Germany",2007.0,50.0,497.0,False,,,"{'bibtex': '@Inproceedings{Schupp2007BehavioralS,\n author = {H. Schupp and Jessica Stockburger and M. Codispoti and M. Junghöfer and A. Weike and A. Hamm},\n title = {Behavioral / Systems / Cognitive Selective Visual Attention to Emotion},\n year = {2007}\n}\n'}","[{'authorId': '2436479', 'name': 'H. Schupp'}, {'authorId': '2656869', 'name': 'Jessica Stockburger'}, {'authorId': '3355595', 'name': 'M. Codispoti'}, {'authorId': '3258242', 'name': 'M. Junghöfer'}, {'authorId': '4377282', 'name': 'A. Weike'}, {'authorId': '2337585', 'name': 'A. Hamm'}]"
2822,f720bcb159559acacdcf77a705b1d57f30023be2,Productive Failure,"There is now a substantive body of research that demonstrates the effectiveness of Productive Failure (PF) for learning novel concepts across STEM domains. I will start by describing what PF is, and situate the case for PF both theoretically and empirically. I will then delineate boundary conditions for how, when and why PF succeeds, ending with implications for teaching and learning.",2006.0,69.0,732.0,False,,{'name': 'Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1'},"{'bibtex': '@Article{Kapur2006ProductiveF,\n author = {Manu Kapur},\n journal = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},\n title = {Productive Failure},\n year = {2006}\n}\n'}","[{'authorId': '2465316', 'name': 'Manu Kapur'}]"
2823,f731b6745d829241941307c3ebf163e90e200318,Active Shape Models-Their Training and Application,"!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN.",1995.0,19.0,8148.0,False,,"{'volume': '61', 'pages': '38-59', 'name': 'Comput. Vis. Image Underst.'}","{'bibtex': '@Article{Cootes1995ActiveSM,\n author = {Tim Cootes and C. Taylor and D. Cooper and J. Graham},\n journal = {Comput. Vis. Image Underst.},\n pages = {38-59},\n title = {Active Shape Models-Their Training and Application},\n volume = {61},\n year = {1995}\n}\n'}","[{'authorId': '7205190', 'name': 'Tim Cootes'}, {'authorId': '144482985', 'name': 'C. Taylor'}, {'authorId': '32250556', 'name': 'D. Cooper'}, {'authorId': '47581828', 'name': 'J. Graham'}]"
2824,f742f7e0394b36faf456818a718e11f35db0ae2b,"Decision Forests for Classification, Regression, Density Estimation, Manifold Learning and Semi-Supervised Learning","This paper presents a unified, efficient model of random decision forests which can be applied to a number of machine learning, computer vision and medical image analysis tasks. Our model extends existing forest-based techniques as it unifies classification, regression, density estimation, manifold learning, semi-supervised learning and active learning under the same decision forest framework. This means that the core implementation needs be written and optimized only once, and can then be applied to many diverse tasks. The proposed model may be used both in a generative or discriminative way and may be applied to discrete or continuous, labelled or unlabelled data. The main contributions of this paper are: 1) proposing a single, probabilistic and efficient model for a variety of learning tasks; 2) demonstrating margin-maximizing properties of classification forests; 3) introducing density forests for learning accurate probability density functions; 4) proposing efficient algorithms for sampling from the forest generative model; 5) introducing manifold forests for non-linear embedding and dimensionality reduction; 6) proposing new and efficient forest-based algorithms for transductive and active learning. We discuss how alternatives such as random ferns and extremely randomized trees stem from our more general model. This paper is directed at both students who wish to learn the basics of decision forests, as well as researchers interested in our new contributions. It presents both fundamental and novel concepts in a structured way, with many illustrative examples and real-world applications. Thorough comparisons with state of the art algorithms such as support vector machines, boosting and Gaussian processes are presented and relative advantages and disadvantages discussed.The many synthetic examples and existing commercial applications demonstrate the validity of the proposed model and its flexibility. Powerpoint slides (with many examples and animations) are also available from http://research.microsoft.com/groups/vision/decisionforests.aspx",2011.0,108.0,325.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Criminisi2011DecisionFF,\n author = {A. Criminisi and E. Konukoglu and J. Shotton},\n title = {Decision Forests for Classification, Regression, Density Estimation, Manifold Learning and Semi-Supervised Learning},\n year = {2011}\n}\n'}","[{'authorId': '1716777', 'name': 'A. Criminisi'}, {'authorId': '1796918', 'name': 'E. Konukoglu'}, {'authorId': '143774737', 'name': 'J. Shotton'}]"
2825,f74ecf9935e26007daaacf971fa95273701df42b,Break the Habit! Designing an e-Therapy Intervention Using a Virtual Coach in Aid of Smoking Cessation,,2006.0,20.0,74.0,True,"{'url': 'https://ris.utwente.nl/ws/files/5290087/fulltext%5B1%5D.pdf', 'status': None}",{'pages': '133-141'},"{'bibtex': '@Inproceedings{Grolleman2006BreakTH,\n author = {J. Grolleman and B. V. Dijk and A. Nijholt and A. V. Emst},\n pages = {133-141},\n title = {Break the Habit! Designing an e-Therapy Intervention Using a Virtual Coach in Aid of Smoking Cessation},\n year = {2006}\n}\n'}","[{'authorId': '2054281', 'name': 'J. Grolleman'}, {'authorId': '1727902', 'name': 'B. V. Dijk'}, {'authorId': '144483472', 'name': 'A. Nijholt'}, {'authorId': '118628265', 'name': 'A. V. Emst'}]"
2826,f77ec14eb931a4629bd3bc671d58ed4d5c4759fb,"Is There a ""Language of the Eyes""? Evidence from Normal Adults, and Adults with Autism or Asperger Syndrome","Previous work suggests that a range of mental states can be read from facial expressions, beyond the “basic emotions”. Experiment 1 tested this in more detail, by using a standardized method, and by testing the role of face parts (eyes vs. mouth vs. the whole face). Adult subjects were shown photographs of an actress posing 10 basic emotions (happy, sad, angry, afraid, etc.) and 10 complex mental states (scheme, admire, interest, thoughtfulness, etc.). For each mental state, each subject was shown the whole face, the eyes alone, or the mouth alone, and were given a forced choice of two mental state terms. Results indicated that: (1) Subjects show remarkable agreement in ascribing a wide range of mental states to facial expressions, (2) for the basic emotions, the whole face is more informative than either the eyes or the mouth, (3) for the complex mental states, seeing the eyes alone produced significantly better performance than seeing the mouth alone, and was as informative as the whole face. In Experim...",1997.0,55.0,954.0,False,,"{'volume': '4', 'pages': '311-331', 'name': 'Visual Cognition'}","{'bibtex': '@Article{Baron-Cohen1997IsTA,\n author = {S. Baron-Cohen and S. Wheelwright and T. Jolliffe},\n journal = {Visual Cognition},\n pages = {311-331},\n title = {Is There a ""Language of the Eyes""? Evidence from Normal Adults, and Adults with Autism or Asperger Syndrome},\n volume = {4},\n year = {1997}\n}\n'}","[{'authorId': '1390019127', 'name': 'S. Baron-Cohen'}, {'authorId': '3159706', 'name': 'S. Wheelwright'}, {'authorId': '5646383', 'name': 'T. Jolliffe'}]"
2827,f79e849a6cd26f338400ea9501f57d96c972c3b2,Bodily Communication,"yet it is a compassionate and sensitive work that abounds in current useful information. It projects a positive and realistic approach to issues confronting disabled people and their families. The lives and aspirations of the disabled are discussed in an easily readable style, which includes such topics as: labeling, accessibility, institutionalization, relationships with the medical field, and representation in the media and technology. Special People is not written for the professional who requires extensive information on a specific topic or exceptionality. Rather, it is a short book (172 pages) that brings together knowledge and thought from several disciplines to deal with the everyday problems of coping. Doctors, clergymen, parents, older students, relatives, and the general reader will find Special People useful and informative. One of the strongest aspects of this book is the author's ability to relate her personal experiences and feelings. She is sensitive to the adjustment problems of the nonhandicapped and helps them to understand their own reactions by sharing hers. For example, after realizing that a particular child had Downs' Syndrome, Ms. Cohen relates, ""The shock stayed with me all afternoon. Even though I had known that this was a program for retarded infants, I hadn't been prepared. I was still plagued by my stereotypes"" (p. 117). There are pertinent references throughout the text to professional articles, books for adults, and some for children that expound upon the topics discussed. Regular classroom teachers may be interested in reading, ""Don't Feel Sorry for Paul,"" which describes the life of a physically handicapped child. Parents may chose to read, ""About Handicaps,"" to children who are afraid of ""catching handicap germs."" There are also several accounts of innovative programs, such as Sweden's consideration of blind, physically, and mentally handicapped persons when traffic patterns were changed. This was done because ""they are passengers ... they are pedestrians ... they are part of the world around the driver .... "" There are several excerpts from autobiographies of disabled people, transcripts of conversations with parents, and reactions of children. Helen Jones describes inconsistencies in the airlines' willingness to accept disabled passengers: her statement is especially piognant for those who organize service companies for the public. The parent of a physically handicapped child expresses appreciation for a sequence on the ""Mr. Rogers"" television show, which included disabled children. Shirley Cohen does not leave her reader uninvolved. One chapter, entitled ""And Now You,"" presents situations for selfinquiry as well as for discussion. While the general reader and the disabled themselves are asked to think about their own behaviors and feelings, the professional team member can re-examine his own beliefs regarding the equality and worthiness of the people he serves. This chapter is quite short and could be expanded. One possible criticism is Ms. Cohen's introduction as it later relates to her text on public education. Although the ""Right to Education"" is discussed in accordance",1978.0,0.0,567.0,False,,"{'volume': '72', 'pages': '111 - 112', 'name': 'Journal of Visual Impairment & Blindness'}","{'bibtex': '@Article{Rosenberg1978BodilyC,\n author = {Shelley Masion Rosenberg},\n journal = {Journal of Visual Impairment & Blindness},\n pages = {111 - 112},\n title = {Bodily Communication},\n volume = {72},\n year = {1978}\n}\n'}","[{'authorId': '2124146851', 'name': 'Shelley Masion Rosenberg'}]"
2829,f7fa89c90d8539ab4e5b3ed8b6fd9df58af123b2,Smile and the world will smile with you - The effects of a virtual agent's smile on users' evaluation and behavior,,2013.0,100.0,86.0,False,,"{'volume': '71', 'pages': '335-349', 'name': 'Int. J. Hum. Comput. Stud.'}","{'bibtex': ""@Article{Krämer2013SmileAT,\n author = {N. Krämer and S. Kopp and C. Becker-Asano and Nicole Sommer},\n journal = {Int. J. Hum. Comput. Stud.},\n pages = {335-349},\n title = {Smile and the world will smile with you - The effects of a virtual agent's smile on users' evaluation and behavior},\n volume = {71},\n year = {2013}\n}\n""}","[{'authorId': '1750852', 'name': 'N. Krämer'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '1403827243', 'name': 'C. Becker-Asano'}, {'authorId': '2071068301', 'name': 'Nicole Sommer'}]"
2831,f8027359391974074c9a4c00d486733766abcb53,Improving Depression Level Estimation by Concurrently Learning Emotion Intensity,"Depression is considered a serious medical condition and a large number of people around the world are suffering from it. Within this context, a lot of studies have been proposed to estimate the degree of depression based on different features and modalities, specific to depression. Supported by medical studies that show how depression is a disorder of impaired emotion regulation, we propose a different approach, which relies on the rationale that the estimation of depression level can benefit from the concurrent learning of emotion intensity. To test this hypothesis, we design different attention-based multi-task architectures that concurrently regress/classify both depression level and emotion intensity using text data. Experiments based on two benchmark datasets, namely, the Distress Analysis Interview Corpus - a Wizard of Oz (DAIC-WOZ), and the CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) show that substantial performance improvements can be achieved when compared to emotion-unaware single-task and multitask approaches.",2020.0,41.0,23.0,False,,"{'volume': '15', 'pages': '47-59', 'name': 'IEEE Computational Intelligence Magazine'}","{'bibtex': '@Article{Qureshi2020ImprovingDL,\n author = {Syed Arbaaz Qureshi and G. Dias and Mohammed Hasanuzzaman and S. Saha},\n journal = {IEEE Computational Intelligence Magazine},\n pages = {47-59},\n title = {Improving Depression Level Estimation by Concurrently Learning Emotion Intensity},\n volume = {15},\n year = {2020}\n}\n'}","[{'authorId': '102701933', 'name': 'Syed Arbaaz Qureshi'}, {'authorId': '143673279', 'name': 'G. Dias'}, {'authorId': '144231505', 'name': 'Mohammed Hasanuzzaman'}, {'authorId': '145470045', 'name': 'S. Saha'}]"
2832,f82f152244b1cb861db0f290d55302011aee28dc,Development and validation of brief measures of positive and negative affect: the PANAS scales.,"In recent studies of the structure of affect, positive and negative affect have consistently emerged as two dominant and relatively independent dimensions. A number of mood scales have been created to measure these factors; however, many existing measures are inadequate, showing low reliability or poor convergent or discriminant validity. To fill the need for reliable and valid Positive Affect and Negative Affect scales that are also brief and easy to administer, we developed two 10-item mood scales that comprise the Positive and Negative Affect Schedule (PANAS). The scales are shown to be highly internally consistent, largely uncorrelated, and stable at appropriate levels over a 2-month time period. Normative data and factorial and external evidence of convergent and discriminant validity for the scales are also presented.",1988.0,50.0,35829.0,False,,"{'volume': '54 6', 'pages': '\n          1063-70\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Watson1988DevelopmentAV,\n author = {D. Watson and L. Clark and A. Tellegen},\n journal = {Journal of personality and social psychology},\n pages = {\n          1063-70\n        },\n title = {Development and validation of brief measures of positive and negative affect: the PANAS scales.},\n volume = {54 6},\n year = {1988}\n}\n'}","[{'authorId': '145213999', 'name': 'D. Watson'}, {'authorId': '10034636', 'name': 'L. Clark'}, {'authorId': '116114697', 'name': 'A. Tellegen'}]"
2837,f84d468be4825adad39e436bff858a63583939d5,"Presence: concept, determinants, and measurement","The concept of presence, i.e. the sensation of 'being there' in a mediated environment, has received substantial attention from the virtual reality community, and is becoming increasingly relevant both to broadcasters and display developers. Although research into presence is still at an early stage of development, there is a consensus that presence has multiple determinants. To identify and test which parameters affect presence, a reliable, robust and valid means of measuring presence is required. In this paper, we describe the categories of factors thought to have an impact on presence. Furthermore, we present an overview of various approaches taken to measuring presence, which can be divided into two general categories: subjective measures and objective corroborative measures. Since presence is a subjective experience, the most direct way of assessment is through users' subjective report. This approach has serious limitations however, and should be used judiciously. Objective measures, such as postural, physiological or social responses to media, can be used to corroborate subjective measures, thereby overcoming some of their limitations. At present, the most promising direction for presence measurement is to develop and use an aggregate measure of presence that is comprised of both subjective and objective components, tailored to the specific medium under study.",2000.0,58.0,617.0,False,,{'volume': '3959'},"{'bibtex': '@Inproceedings{Ijsselsteijn2000PresenceCD,\n author = {W. Ijsselsteijn and H. Ridder and J. Freeman and S. Avons},\n title = {Presence: concept, determinants, and measurement},\n volume = {3959},\n year = {2000}\n}\n'}","[{'authorId': '1679478', 'name': 'W. Ijsselsteijn'}, {'authorId': '1712892', 'name': 'H. Ridder'}, {'authorId': '48770354', 'name': 'J. Freeman'}, {'authorId': '1962204', 'name': 'S. Avons'}]"
2838,f8988146c0317ca93f5cd06ced85f673318e5958,Combining Facial Expressions and Electroencephalography to Enhance Emotion Recognition,"Emotion recognition plays an essential role in human–computer interaction. Previous studies have investigated the use of facial expression and electroencephalogram (EEG) signals from single modal for emotion recognition separately, but few have paid attention to a fusion between them. In this paper, we adopted a multimodal emotion recognition framework by combining facial expression and EEG, based on a valence-arousal emotional model. For facial expression detection, we followed a transfer learning approach for multi-task convolutional neural network (CNN) architectures to detect the state of valence and arousal. For EEG detection, two learning targets (valence and arousal) were detected by different support vector machine (SVM) classifiers, separately. Finally, two decision-level fusion methods based on the enumerate weight rule or an adaptive boosting technique were used to combine facial expression and EEG. In the experiment, the subjects were instructed to watch clips designed to elicit an emotional response and then reported their emotional state. We used two emotion datasets—a Database for Emotion Analysis using Physiological Signals (DEAP) and MAHNOB-human computer interface (MAHNOB-HCI)—to evaluate our method. In addition, we also performed an online experiment to make our method more robust. We experimentally demonstrated that our method produces state-of-the-art results in terms of binary valence/arousal classification, based on DEAP and MAHNOB-HCI data sets. Besides this, for the online experiment, we achieved 69.75% accuracy for the valence space and 70.00% accuracy for the arousal space after fusion, each of which has surpassed the highest performing single modality (69.28% for the valence space and 64.00% for the arousal space). The results suggest that the combination of facial expressions and EEG information for emotion recognition compensates for their defects as single information sources. The novelty of this work is as follows. To begin with, we combined facial expression and EEG to improve the performance of emotion recognition. Furthermore, we used transfer learning techniques to tackle the problem of lacking data and achieve higher accuracy for facial expression. Finally, in addition to implementing the widely used fusion method based on enumerating different weights between two models, we also explored a novel fusion method, applying boosting technique.",2019.0,20.0,57.0,True,"{'url': 'https://www.mdpi.com/1999-5903/11/5/105/pdf?version=1556781569', 'status': None}","{'volume': '11', 'pages': '105', 'name': 'Future Internet'}","{'bibtex': '@Article{Huang2019CombiningFE,\n author = {Yongrui Huang and Jianhao Yang and Siyu Liu and Jiahui Pan},\n journal = {Future Internet},\n pages = {105},\n title = {Combining Facial Expressions and Electroencephalography to Enhance Emotion Recognition},\n volume = {11},\n year = {2019}\n}\n'}","[{'authorId': '49866167', 'name': 'Yongrui Huang'}, {'authorId': '2109746852', 'name': 'Jianhao Yang'}, {'authorId': '2108640313', 'name': 'Siyu Liu'}, {'authorId': '7588999', 'name': 'Jiahui Pan'}]"
2839,f8a78b016bc6c45a0c1cecab2fe459c226bde467,Submissive behaviour and psychopathology.,"OBJECTIVES
A variety of behaviours have been identified as submissive (Buss & Craik, 1986). These are believed to be associated with vulnerability to psychopathology. This paper explores the construct and measurement of submissive behaviours and their association with psychopathology.


DESIGN
Two self-report scales were designed to measure the frequencies of (a) typical submissive behaviours (SBS) and (b) passive/withdrawal and affiliative strategies focused on conflict de-escalation (CDS). The association of these scales with psychopathology was explored in a series of questionnaire studies.


METHODS
Study 1 assessed the SBS using a student sample (N = 332) and a mixed clinical group (N = 136). Of these, 177 students and 66 patients also completed the SCL-90-R. In Studies 2 and 3, the CDS and its association with depressive symptoms were assessed using a student sample (N = 154) and a depressed patient group (N = 60).


RESULTS
The SBS and CDS appeared reliable. There was a positive relationship between the SBS and the SCL-90-R, including interpersonal sensitivity and unexpressed hostility. The passive/withdrawal subscale of the CDS was associated with depressive symptoms. Evidence was obtained for sex differences with the affiliative subscale.


CONCLUSIONS
Some forms of submissive behaviour, especially those associated with passive/withdrawal and inhibition, are associated with a wide range of psychological problems.",1997.0,0.0,278.0,False,,"{'volume': '36 ( Pt 4)', 'pages': '\n          467-88\n        ', 'name': 'The British journal of clinical psychology'}","{'bibtex': '@Article{Allan1997SubmissiveBA,\n author = {S. Allan and Paul Gilbert},\n journal = {The British journal of clinical psychology},\n pages = {\n          467-88\n        },\n title = {Submissive behaviour and psychopathology.},\n volume = {36 ( Pt 4)},\n year = {1997}\n}\n'}","[{'authorId': '9722254', 'name': 'S. Allan'}, {'authorId': '2239275654', 'name': 'Paul Gilbert'}]"
2840,f8aa92ba3efd9d1d0ea0ac64ab521947b9648a44,Moderators of Social Facilitation Effect in Virtual Reality: Co-presence and Realism of Virtual Agents,"Social facilitation has been researched for decades, but in the face of the development of virtual reality technology, new questions arise regarding the possibility of its occurrence in this environment —in the presence of computer-generated agents. Past research provided inconclusive answers: several experiments confirmed this possibility, but several others disagreed. On the other hand, previous studies have shown the important role of VR characteristics, such as realism or co-presence, in evoking other psychological phenomena. However, no study has investigated the interplay between the presence of computer-generated agents and perceived social realism in evoking social facilitation in virtual reality. To this end, the present randomized control study was conducted. The sample consisted of professional firefighters (N = 48), divided into an experimental group with virtual bystanders and a control group without them. Subjects were instructed to perform a rescue procedure in a virtual reality headset. The performance of participants was logged and they completed questionnaires regarding sense of presence in the virtual environment, perceived realism of the environment and perceived co-presence of virtual agents. The obtained results confirmed the role of social realism as a moderator of the occurrence of social facilitation in the presence of computer-generated agents. At the same time, the main effect of facilitation was not confirmed. These results support predictions that the subjective feeling of being in a realistic company of others may be more important in evoking social facilitation than objective facts. Furthermore, the results contribute to the debate regarding the mechanism of social facilitation, suggesting that simple augmentation of the environment with social distractors is not always enough, thus questioning the attentional explanation of the effect. Taken together, our results extend previous findings on social facilitation and open up new possibilities for designing effective virtual environments.",2020.0,54.0,14.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2020.01252/pdf', 'status': None}","{'volume': '11', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Strojny2020ModeratorsOS,\n author = {P. Strojny and N. Dużmańska-Misiarczyk and N. Lipp and A. Strojny},\n journal = {Frontiers in Psychology},\n title = {Moderators of Social Facilitation Effect in Virtual Reality: Co-presence and Realism of Virtual Agents},\n volume = {11},\n year = {2020}\n}\n'}","[{'authorId': '11243838', 'name': 'P. Strojny'}, {'authorId': '1750919958', 'name': 'N. Dużmańska-Misiarczyk'}, {'authorId': '1392603230', 'name': 'N. Lipp'}, {'authorId': '3620328', 'name': 'A. Strojny'}]"
2841,f8badb03517d812176a7ba982fb81a0aa05edd54,Cathexis: a computational model of emotions,,1997.0,9.0,85.0,False,,{'pages': '518-519'},"{'bibtex': '@Inproceedings{Velásquez1997CathexisAC,\n author = {J. Velásquez and P. Maes},\n pages = {518-519},\n title = {Cathexis: a computational model of emotions},\n year = {1997}\n}\n'}","[{'authorId': '2095517457', 'name': 'J. Velásquez'}, {'authorId': '1701876', 'name': 'P. Maes'}]"
2842,f8c61e9308eec8125cf57735d36b1c8a0133ba3f,Do Not Invade: A Virtual-Reality-Framework to Study Personal Space,The bachelor thesis’ aim was to develop a framework allowing to design and conduct virtual-reality-based user studies gaining insight into the concept of personal space.,2017.0,4.0,1.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Schnathmeier2017DoNI,\n author = {Jan Schnathmeier and U. Habel and T. Kuhlen and A. Bönsch and Sina Radke and H. Overath},\n title = {Do Not Invade: A Virtual-Reality-Framework to Study Personal Space},\n year = {2017}\n}\n'}","[{'authorId': '66298470', 'name': 'Jan Schnathmeier'}, {'authorId': '2782974', 'name': 'U. Habel'}, {'authorId': '144483066', 'name': 'T. Kuhlen'}, {'authorId': '3249697', 'name': 'A. Bönsch'}, {'authorId': '145880611', 'name': 'Sina Radke'}, {'authorId': '47973447', 'name': 'H. Overath'}]"
2843,f8d72d1e2848ee9e51bab0535d197c113b1fcc02,Touch perception and emotional appraisal for a virtual agent,Building virtual agents that are able to perceive and appraise touch increase the lifelikeness and interaction possibilities in human computer interaction. In this paper we introduce work on how a sense of touch was realized for the virtual human Max and how he can emotionally react to it by appraising the different kinds of tactile sensation.,2007.0,9.0,16.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Nguyen2007TouchPA,\n author = {Nhung Nguyen and I. Wachsmuth and S. Kopp},\n title = {Touch perception and emotional appraisal for a virtual agent},\n year = {2007}\n}\n'}","[{'authorId': '46672463', 'name': 'Nhung Nguyen'}, {'authorId': '1721018', 'name': 'I. Wachsmuth'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
2844,f8e1fc3f05345bf8eb0e2b7bc88bfaa3d725b912,We learn better together: enhancing eLearning with emotional characters,"In this paper we explore a new direction for pedagogical computer characters, which we believe will maximize students' learning gains and enjoyment. To the traditional scenario where students interact primarily with a single coach or tutor character on-screen, we introduce the addition of both a social, animate colearner, and the student's own avatar character. Variations of the colearner's attributes, informed by research literature on human partners, are explored through an online testbed application of English language idioms. Results from an experimental study with 76 Japanese college students reveal that cooperative colearners have a positive impact on students' performance and experience, as well as increasing perceptions of the character's intelligence and credibility. Findings provide grounding for a fruitful new direction for pedagogical characters, where students learn alongside emotional companions.",2005.0,38.0,98.0,False,,{'pages': '408-417'},"{'bibtex': '@Inproceedings{Maldonado2005WeLB,\n author = {Heidy Maldonado and Jong-Eun Roselyn Lee and Scott Brave and C. Nass and H. Nakajima and Ryota Yamada and Kimihiko Iwamura and Yasunori Morishima},\n pages = {408-417},\n title = {We learn better together: enhancing eLearning with emotional characters},\n year = {2005}\n}\n'}","[{'authorId': '145904305', 'name': 'Heidy Maldonado'}, {'authorId': '2108367283', 'name': 'Jong-Eun Roselyn Lee'}, {'authorId': '2739604', 'name': 'Scott Brave'}, {'authorId': '2029850', 'name': 'C. Nass'}, {'authorId': '16845205', 'name': 'H. Nakajima'}, {'authorId': '2071316348', 'name': 'Ryota Yamada'}, {'authorId': '10605736', 'name': 'Kimihiko Iwamura'}, {'authorId': '2402842', 'name': 'Yasunori Morishima'}]"
2845,f8e8b3fd2b8eb91eec9a5507671a5dffe295bf59,Examining the associations between interpersonal emotion regulation and psychosocial adjustment in emerging adulthood,,2021.0,67.0,9.0,False,,"{'volume': '45', 'pages': '652 - 662', 'name': 'Cognitive Therapy and Research'}","{'bibtex': '@Article{Chan2021ExaminingTA,\n author = {Samantha Chan and J. Rawana},\n journal = {Cognitive Therapy and Research},\n pages = {652 - 662},\n title = {Examining the associations between interpersonal emotion regulation and psychosocial adjustment in emerging adulthood},\n volume = {45},\n year = {2021}\n}\n'}","[{'authorId': '34987625', 'name': 'Samantha Chan'}, {'authorId': '3834933', 'name': 'J. Rawana'}]"
2846,f8f9e47deaf537fa8532664906049fc7afe8d5ad,Robot mood is contagious: effects of robot body language in the imitation game,"Mood contagion is an automatic mechanism that induces a congruent mood state by means of the observation of another person's emotional expression. In this paper, we address the question whether robot mood displayed during an imitation game can (a) be recognized by participants and (b) produce contagion effects. Robot mood was displayed by applying a generic framework for mood expression using body language. By modulating the set of available behavior parameters in this framework for controlling pose and motion dynamics, the gestures performed by the humanoid robot NAO were adjusted to display either a positive or negative mood. In the study performed, we varied both mood as well as task difficulty. Our results show that participants are able to differentiate between positive and negative robot mood. Moreover, self-reported mood matches the mood of the robot in the easy task condition. Additional evidence for mood contagion is provided by the fact that we were able to replicate an expected effect of negative mood on task performance: in the negative mood condition participants performed better on difficult tasks than in the positive mood condition, even though participants' self-reported mood did not match that of the robot.",2014.0,41.0,48.0,False,,{'pages': '973-980'},"{'bibtex': '@Inproceedings{Xu2014RobotMI,\n author = {Junchao Xu and J. Broekens and K. Hindriks and Mark Antonius Neerincx},\n pages = {973-980},\n title = {Robot mood is contagious: effects of robot body language in the imitation game},\n year = {2014}\n}\n'}","[{'authorId': '34859885', 'name': 'Junchao Xu'}, {'authorId': '1735303', 'name': 'J. Broekens'}, {'authorId': '1751831', 'name': 'K. Hindriks'}, {'authorId': '1784286', 'name': 'Mark Antonius Neerincx'}]"
2848,f910751bac74490ce48f7f24a0759fbce81cb7c7,The dynamic architecture of emotion: Evidence for the component process model,"Emotion is conceptualised as an emergent, dynamic process based on an individual's subjective appraisal of significant events. It is argued that theoretical models of emotion need to propose an architecture that reflects the essential nature and functions of emotion as a psychobiological and cultural adaptation mechanism. One proposal for such a model and its underlying dynamic architecture, the component process model, is briefly sketched and compared with some of its major competitors. Recent empirical evidence in support of the model is reviewed. Special emphasis is given to the dynamic aspect of emotion processes, in particular the sequence of appraisal checks and the synchronisation of response systems, as well as the capacity of the model to predict individual differences in emotional responding.",2009.0,135.0,893.0,False,,"{'volume': '23', 'pages': '1307 - 1351', 'name': 'Cognition and Emotion'}","{'bibtex': '@Article{Scherer2009TheDA,\n author = {K. Scherer},\n journal = {Cognition and Emotion},\n pages = {1307 - 1351},\n title = {The dynamic architecture of emotion: Evidence for the component process model},\n volume = {23},\n year = {2009}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}]"
2849,f910b8f9e9336f04b21a5b878cc871be3fff21c2,The communication of emotion via touch.,"The study of emotional communication has focused predominantly on the facial and vocal channels but has ignored the tactile channel. Participants in the current study were allowed to touch an unacquainted partner on the whole body to communicate distinct emotions. Of interest was how accurately the person being touched decoded the intended emotions without seeing the tactile stimulation. The data indicated that anger, fear, disgust, love, gratitude, and sympathy were decoded at greater than chance levels, as well as happiness and sadness, 2 emotions that have not been shown to be communicated by touch to date. Moreover, fine-grained coding documented specific touch behaviors associated with different emotions. The findings are discussed in terms of their contribution to the study of emotion-related communication.",2009.0,39.0,454.0,False,,"{'volume': '9 4', 'pages': '\n          566-73\n        ', 'name': 'Emotion'}","{'bibtex': '@Article{Hertenstein2009TheCO,\n author = {Matthew J. Hertenstein and Rachel Holmes and Margaret E. McCullough and D. Keltner},\n journal = {Emotion},\n pages = {\n          566-73\n        },\n title = {The communication of emotion via touch.},\n volume = {9 4},\n year = {2009}\n}\n'}","[{'authorId': '4793351', 'name': 'Matthew J. Hertenstein'}, {'authorId': '2071784124', 'name': 'Rachel Holmes'}, {'authorId': '40108102', 'name': 'Margaret E. McCullough'}, {'authorId': '3990536', 'name': 'D. Keltner'}]"
2850,f913f2b4856289360a1e4a15911dae69afea5549,The Neural Basis of Economic Decision-Making in the Ultimatum Game,"The nascent field of neuroeconomics seeks to ground economic decisionmaking in the biological substrate of the brain. We used functional magnetic resonance imaging of Ultimatum Game players to investigate neural substrates of cognitive and emotional processes involved in economic decision-making. In this game, two players split a sum of money;one player proposes a division and the other can accept or reject this. We scanned players as they responded to fair and unfair proposals. Unfair offers elicited activity in brain areas related to both emotion (anterior insula) and cognition (dorsolateral prefrontal cortex). Further, significantly heightened activity in anterior insula for rejected unfair offers suggests an important role for emotions in decision-making.",2003.0,58.0,3183.0,False,,"{'volume': '300', 'pages': '1755 - 1758', 'name': 'Science'}","{'bibtex': '@Article{Sanfey2003TheNB,\n author = {A. Sanfey and J. Rilling and J. Aronson and L. Nystrom and J. Cohen},\n journal = {Science},\n pages = {1755 - 1758},\n title = {The Neural Basis of Economic Decision-Making in the Ultimatum Game},\n volume = {300},\n year = {2003}\n}\n'}","[{'authorId': '2080922', 'name': 'A. Sanfey'}, {'authorId': '1830680', 'name': 'J. Rilling'}, {'authorId': '27458355', 'name': 'J. Aronson'}, {'authorId': '2100648', 'name': 'L. Nystrom'}, {'authorId': '153564781', 'name': 'J. Cohen'}]"
2851,f9182ba1d9046aea8abb4571eef3eb89e5702fd5,The predictive validity of the PTSD Checklist in a nonclinical sample of combat-exposed National Guard troops.,"After returning from an extended combat deployment to Iraq, 348 National Guard soldiers were administered the PTSD Checklist (PCL-M), and the Beck Depression Inventory II (BDI-II) followed, on average, 3 months later by structured diagnostic interviews including the Clinician-Administered PTSD Scale (CAPS) for the Diagnostic and Statistical Manual of Mental Disorders (4th ed.). There were 6.5% of the soldiers who met diagnostic criteria for posttraumatic stress disorder (PTSD) based on structured interview. The predictive validity of the PCL was examined and contrasted with the predictive validity of the BDI-II in identifying soldiers meeting CAPS diagnosis for PTSD. The best identified PCL cut scores produced between 65% and 76% false positive errors when used as the sole source for identification of enduring PTSD. Comparison of prediction between the PCL and the BDI-II in identifying PTSD suggested that both instruments may be operating through tapping generalized distress rather than specific aspects of the disorder.",2012.0,0.0,63.0,False,,"{'volume': '24 4', 'pages': '\n          1034-40\n        ', 'name': 'Psychological assessment'}","{'bibtex': '@Article{Arbisi2012ThePV,\n author = {P. Arbisi and M. Kaler and S. Kehle-Forbes and Christopher R. Erbes and Melissa A. Polusny and P. Thuras},\n journal = {Psychological assessment},\n pages = {\n          1034-40\n        },\n title = {The predictive validity of the PTSD Checklist in a nonclinical sample of combat-exposed National Guard troops.},\n volume = {24 4},\n year = {2012}\n}\n'}","[{'authorId': '3979253', 'name': 'P. Arbisi'}, {'authorId': '5187410', 'name': 'M. Kaler'}, {'authorId': '1398898634', 'name': 'S. Kehle-Forbes'}, {'authorId': '5092239', 'name': 'Christopher R. Erbes'}, {'authorId': '5159096', 'name': 'Melissa A. Polusny'}, {'authorId': '3725454', 'name': 'P. Thuras'}]"
2852,f983648ebf9f277eaaff74045a9bf67782ba639b,Recognition of Facial Emotions in Neuropsychiatric Disorders,"ABSTRACT Recognition of facial emotions represents an important aspect of interpersonal communication and is governed by select neural substrates. We present data on emotion recognition in healthy young adults utilizing a novel set of color photographs of evoked universal emotions. In addition, we review the recent literature on emotion recognition in psychiatric and neurologic disorders, and studies that compare different disorders.",2004.0,82.0,107.0,False,,"{'volume': '9', 'pages': '267 - 274', 'name': 'CNS Spectrums'}","{'bibtex': '@Article{Kohler2004RecognitionOF,\n author = {C. Kohler and T. Turner and R. Gur and R. Gur},\n journal = {CNS Spectrums},\n pages = {267 - 274},\n title = {Recognition of Facial Emotions in Neuropsychiatric Disorders},\n volume = {9},\n year = {2004}\n}\n'}","[{'authorId': '31936404', 'name': 'C. Kohler'}, {'authorId': '144898011', 'name': 'T. Turner'}, {'authorId': '2406788', 'name': 'R. Gur'}, {'authorId': '144762538', 'name': 'R. Gur'}]"
2853,f9878350aec52f5d25b43889d7696b226c28cd98,Peripersonal and interpersonal space in virtual and real environments: Effects of gender and age,,2016.0,64.0,176.0,False,,"{'volume': '45', 'pages': '154-164', 'name': 'Journal of Environmental Psychology'}","{'bibtex': '@Article{Iachini2016PeripersonalAI,\n author = {T. Iachini and Y. Coello and F. Frassinetti and V. P. Senese and F. Galante and G. Ruggiero},\n journal = {Journal of Environmental Psychology},\n pages = {154-164},\n title = {Peripersonal and interpersonal space in virtual and real environments: Effects of gender and age},\n volume = {45},\n year = {2016}\n}\n'}","[{'authorId': '1902889', 'name': 'T. Iachini'}, {'authorId': '3200187', 'name': 'Y. Coello'}, {'authorId': '2903600', 'name': 'F. Frassinetti'}, {'authorId': '2593233', 'name': 'V. P. Senese'}, {'authorId': '2072423', 'name': 'F. Galante'}, {'authorId': '3352149', 'name': 'G. Ruggiero'}]"
2855,f987f4190d0ba8a0a433c0f3feb3f24e11a94e41,Experiential Avoidance and Emotion Regulation in Borderline Personality Disorder,,2011.0,80.0,72.0,False,,"{'volume': '29', 'pages': '35-52', 'name': 'Journal of Rational-Emotive & Cognitive-Behavior Therapy'}","{'bibtex': '@Article{Chapman2011ExperientialAA,\n author = {A. Chapman and K. Dixon-Gordon and Kristy N. Walters},\n journal = {Journal of Rational-Emotive & Cognitive-Behavior Therapy},\n pages = {35-52},\n title = {Experiential Avoidance and Emotion Regulation in Borderline Personality Disorder},\n volume = {29},\n year = {2011}\n}\n'}","[{'authorId': '5761913', 'name': 'A. Chapman'}, {'authorId': '1398166516', 'name': 'K. Dixon-Gordon'}, {'authorId': '4306587', 'name': 'Kristy N. Walters'}]"
2856,f99f8c9923c668c205126d4066838a42b5ce064a,"Music therapy and Alzheimer's disease: Cognitive, psychological, and behavioural effects",,2017.0,40.0,103.0,True,,"{'volume': '32', 'pages': '300-308', 'name': 'Neurologia'}","{'bibtex': ""@Article{Gallego2017MusicTA,\n author = {M. G. Gallego and J. García},\n journal = {Neurologia},\n pages = {300-308},\n title = {Music therapy and Alzheimer's disease: Cognitive, psychological, and behavioural effects},\n volume = {32},\n year = {2017}\n}\n""}","[{'authorId': '2055572295', 'name': 'M. G. Gallego'}, {'authorId': '2118739294', 'name': 'J. García'}]"
2857,f9b406efae1a81c0f0329811c335a2605b4095b0,Playful or Gameful?: creating delightful user experiences,,2014.0,6.0,91.0,False,,"{'volume': '21', 'pages': '34-39', 'name': 'Interactions'}","{'bibtex': '@Article{Lucero2014PlayfulOG,\n author = {A. Lucero and E. Karapanos and Juha Arrasvuori and Hannu Korhonen},\n journal = {Interactions},\n pages = {34-39},\n title = {Playful or Gameful?: creating delightful user experiences},\n volume = {21},\n year = {2014}\n}\n'}","[{'authorId': '143659789', 'name': 'A. Lucero'}, {'authorId': '1766666', 'name': 'E. Karapanos'}, {'authorId': '1806670', 'name': 'Juha Arrasvuori'}, {'authorId': '2076196158', 'name': 'Hannu Korhonen'}]"
2858,f9b62b5be4791b65d4fa30dece2ea0af0321d597,"The Relationships of Trait Anxiety, Audience Nonverbal Feedback, and Attributions to Public Speaking State Anxiety","This study investigated the relationships among trait anxiety, audience nonverbal feedback, attributions, and public speaking state anxiety. Fifty-nine (N = 59) undergraduate students randomly assigned to either a positive or negative condition of audience nonverbal feedback delivered an impromptu speech and completed a trait anxiety measure, state anxiety scale, and attributional questionnaire about audience nonverbal feedback. The results provided some support for a path model indicating that negative nonverbal feedback increased external attributions, which, in turn, increased state anxiety. Trait anxiety was not more predictive of state anxiety than nonverbal feedback.",2009.0,23.0,3.0,False,,"{'volume': '26', 'pages': '237 - 246', 'name': 'Communication Research Reports'}","{'bibtex': '@Article{Hsu2009TheRO,\n author = {Chia-Fang (Sandy) Hsu},\n journal = {Communication Research Reports},\n pages = {237 - 246},\n title = {The Relationships of Trait Anxiety, Audience Nonverbal Feedback, and Attributions to Public Speaking State Anxiety},\n volume = {26},\n year = {2009}\n}\n'}","[{'authorId': '1685702669', 'name': 'Chia-Fang (Sandy) Hsu'}]"
2859,f9d87835ce5027ac326765d8509e4d7239fee615,Changes in applied force to a touchpad during pointing tasks,,2002.0,20.0,55.0,False,,"{'volume': '29', 'pages': '171-182', 'name': 'International Journal of Industrial Ergonomics'}","{'bibtex': '@Article{Akamatsu2002ChangesIA,\n author = {M. Akamatsu and I. MacKenzie},\n journal = {International Journal of Industrial Ergonomics},\n pages = {171-182},\n title = {Changes in applied force to a touchpad during pointing tasks},\n volume = {29},\n year = {2002}\n}\n'}","[{'authorId': '3141475', 'name': 'M. Akamatsu'}, {'authorId': '2085861095', 'name': 'I. MacKenzie'}]"
2860,f9e8d5c52de83cadbe422ae46f6dea3b4baf2ba3,A personality-based emotional model for embodied conversational agents: Effects on perceived social presence and game experience of users,,2019.0,44.0,30.0,False,,"{'volume': '32', 'name': 'Entertain. Comput.'}","{'bibtex': '@Article{Sajjadi2019APE,\n author = {Pejman Sajjadi and Laura Hoffmann and P. Cimiano and S. Kopp},\n journal = {Entertain. Comput.},\n title = {A personality-based emotional model for embodied conversational agents: Effects on perceived social presence and game experience of users},\n volume = {32},\n year = {2019}\n}\n'}","[{'authorId': '1869023', 'name': 'Pejman Sajjadi'}, {'authorId': '3689632', 'name': 'Laura Hoffmann'}, {'authorId': '1748977', 'name': 'P. Cimiano'}, {'authorId': '5864138', 'name': 'S. Kopp'}]"
2861,fa0dcaae23392fe54c534a85c1e7c430146580af,Computational Analysis of Gaze Behavior in Autism During Interaction with Virtual Agents,"Individuals with Autism spectrum disorder (ASD) are known to have significantly impaired social interaction and communication abilities. These impairments are characterized by their difficulties in using and perceiving non-verbal cues, such as facial expressions. The difficulty in processing communicators facial expressions is often attributed to the atypical gaze patterns in individuals with ASD. We present a computational study of gaze behavior in adolescents with ASD during their interaction with virtual agents (avatars) in a virtual reality based social communication platform. We study the implications on the subjects pupil response (pupil diameter changes) and looking pattern (fixation coordinates and duration) when exposed to the avatars demonstrating context-relevant emotional expressions. The data related to fixation and pupil response is collected using a commercial eye-tracker for subjects with and without ASD during their interactions with the avatars. This data is analyzed to investigate how the pupil response dynamics and fixation patterns of the ASD group differ from their typically developing peers. Our results indicate that communicators facial expressions can significantly affect the gaze behavior of the ASD subjects. We also observe reduced complexity in the pupil response dynamics, and lower synchrony between pupil response and fixation pattern in the ASD group.",2019.0,28.0,4.0,True,"{'url': 'http://wrap.warwick.ac.uk/114069/1/WRAP-computational-analysis-gaze-behavior-interaction-Guha-2019.pdf', 'status': None}","{'pages': '1075-1079', 'name': 'ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","{'bibtex': '@Article{Akhtar2019ComputationalAO,\n author = {Zeeshan Akhtar and T. Guha},\n journal = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {1075-1079},\n title = {Computational Analysis of Gaze Behavior in Autism During Interaction with Virtual Agents},\n year = {2019}\n}\n'}","[{'authorId': '2067177722', 'name': 'Zeeshan Akhtar'}, {'authorId': '1720741', 'name': 'T. Guha'}]"
2862,fa3fa79e49430e156a7cc6cc86045e952883257e,Hybrid multi-agent architecture as a real-time problem-solving model,,2008.0,46.0,113.0,False,,"{'volume': '34', 'pages': '2-17', 'name': 'Expert Syst. Appl.'}","{'bibtex': '@Article{Carrascosa2008HybridMA,\n author = {C. Carrascosa and J. Bajo and V. Julián and J. Corchado and V. Botti},\n journal = {Expert Syst. Appl.},\n pages = {2-17},\n title = {Hybrid multi-agent architecture as a real-time problem-solving model},\n volume = {34},\n year = {2008}\n}\n'}","[{'authorId': '143747701', 'name': 'C. Carrascosa'}, {'authorId': '1722104', 'name': 'J. Bajo'}, {'authorId': '144890090', 'name': 'V. Julián'}, {'authorId': '1729096', 'name': 'J. Corchado'}, {'authorId': '1686926', 'name': 'V. Botti'}]"
2863,fa41901489654b1f3292ebb1821187c77f1c9470,Emotion and the Framing of Risky Choice,,2008.0,97.0,343.0,False,,"{'volume': '30', 'pages': '297-321', 'name': 'Political Behavior'}","{'bibtex': '@Article{Druckman2008EmotionAT,\n author = {J. Druckman and R. McDermott},\n journal = {Political Behavior},\n pages = {297-321},\n title = {Emotion and the Framing of Risky Choice},\n volume = {30},\n year = {2008}\n}\n'}","[{'authorId': '4106384', 'name': 'J. Druckman'}, {'authorId': '153592028', 'name': 'R. McDermott'}]"
2865,fa55b0b6c37558c985331f05a98f320449e8f9d7,Gesture: Visible Action as Utterance,"1. The domain of gesture 2. Visible action as gesture 3. Western interest in gesture from classical antiquity to the eighteenth century 4. Four contributions from the nineteenth century: Andrea de Jorio, Edward Tylor, Garrick Mallery and Wilhelm Wundt 5. Gesture studies in the twentieth century: recession and return 6. Classifying gestures 7. Gesture units, gesture phrases and speech 8. Deployments of gesture in the utterance 9. Gesture and speech in semantic interaction 10. Gesture and referential meaning 11. On pointing 12. Gestures of the 'precision-grip': topic, comment and question markers 13. Two gesture families of the open hand 14. Gesture without speech: the emergence of kinesic codes 15. Gesture and sign on common ground 16. Gesture, culture and the communication economy 17. The status of gesture Appendix I. Transcription conventions Appendix II. The recordings.",2004.0,0.0,2552.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Kendon2004GestureVA,\n author = {A. Kendon},\n title = {Gesture: Visible Action as Utterance},\n year = {2004}\n}\n'}","[{'authorId': '47985333', 'name': 'A. Kendon'}]"
2866,fa56a969b9fe56d1bd494611ecc2c6d8586549dd,Fostering social agency in multimedia learning: Examining the impact of an animated agent’s voice ☆,,2005.0,26.0,309.0,False,,"{'volume': '30', 'pages': '117-139', 'name': 'Contemporary Educational Psychology'}","{'bibtex': '@Article{Atkinson2005FosteringSA,\n author = {R. Atkinson and R. Mayer and M. M. Merrill},\n journal = {Contemporary Educational Psychology},\n pages = {117-139},\n title = {Fostering social agency in multimedia learning: Examining the impact of an animated agent’s voice ☆},\n volume = {30},\n year = {2005}\n}\n'}","[{'authorId': '1737845', 'name': 'R. Atkinson'}, {'authorId': '1819200', 'name': 'R. Mayer'}, {'authorId': '69435153', 'name': 'M. M. Merrill'}]"
2867,fad58dc0c336d7ff73127328f6659eb2872fc954,Personality Analysis of Embodied Conversational Agents,"People tend to personify machines. Giving machines the ability to actually produce social information can help improve human-machine interactions. Embodied Conversational Agents (ECAs) are virtual software agents that can process and produce speech, facial expressions, gestures and eye gaze, enabling natural, multimodal, human-machine communication. On the one hand, the field of personality psychology provides insights into how we could describe and measure the virtual personality of ECAs. On the other hand, ECAs provide a method to systematically examine how different factors affect the perception of personality. This paper shows that standardized, validated personality questionnaires can be used to evaluate ECAs psychologically, and that state of the art ECAs can manipulate their perceived personality through appearance and behavior.",2018.0,24.0,12.0,False,,{'name': 'Proceedings of the 18th International Conference on Intelligent Virtual Agents'},"{'bibtex': '@Article{Castillo2018PersonalityAO,\n author = {Susana Castillo and Philipp Hahn and K. Legde and D. Cunningham},\n journal = {Proceedings of the 18th International Conference on Intelligent Virtual Agents},\n title = {Personality Analysis of Embodied Conversational Agents},\n year = {2018}\n}\n'}","[{'authorId': '145649261', 'name': 'Susana Castillo'}, {'authorId': '2057924984', 'name': 'Philipp Hahn'}, {'authorId': '3081238', 'name': 'K. Legde'}, {'authorId': '1790148', 'name': 'D. Cunningham'}]"
2868,fadd4f195bc231b55deee6fe5a199af6379b2ef5,"Descartes’ Error: Emotion, Reason and the Human Brain",,1995.0,1.0,1240.0,False,,"{'volume': '36', 'pages': '151-153', 'name': 'Psychosomatics'}","{'bibtex': '@Article{Fricchione1995DescartesEE,\n author = {G. Fricchione},\n journal = {Psychosomatics},\n pages = {151-153},\n title = {Descartes’ Error: Emotion, Reason and the Human Brain},\n volume = {36},\n year = {1995}\n}\n'}","[{'authorId': '5778922', 'name': 'G. Fricchione'}]"
2869,fb19d28f3b0d96e65036fde8a0adc9bf1c4bbe46,Modeling the role of salience in the allocation of overt visual attention,,2002.0,82.0,1448.0,True,,"{'volume': '42', 'pages': '107-123', 'name': 'Vision Research'}","{'bibtex': '@Article{Parkhurst2002ModelingTR,\n author = {Derrick J. Parkhurst and Klinton Law and E. Niebur},\n journal = {Vision Research},\n pages = {107-123},\n title = {Modeling the role of salience in the allocation of overt visual attention},\n volume = {42},\n year = {2002}\n}\n'}","[{'authorId': '2401039', 'name': 'Derrick J. Parkhurst'}, {'authorId': '27685226', 'name': 'Klinton Law'}, {'authorId': '3271571', 'name': 'E. Niebur'}]"
2870,fb8007d427c192d8c953890862dcce62ff944dbf,Dynamics of affective states during complex learning,,2012.0,102.0,648.0,False,,"{'volume': '22', 'pages': '145-157', 'name': 'Learning and Instruction'}","{'bibtex': '@Article{D’Mello2012DynamicsOA,\n author = {S. D’Mello and A. Graesser},\n journal = {Learning and Instruction},\n pages = {145-157},\n title = {Dynamics of affective states during complex learning},\n volume = {22},\n year = {2012}\n}\n'}","[{'authorId': '1383996606', 'name': 'S. D’Mello'}, {'authorId': '1769251', 'name': 'A. Graesser'}]"
2871,fb981c30d1de57c37df9714305893329fa53f07d,Motivation and Personality,Perspectives on Sexuality Sex Research - an Overview Part 1. Biological Perspectives: Sexual Anatomy 1. Sexual Physiology 2. Human Reproduction 3. Birth Control 4. Abortion Part 2. Developmental Perspectives: Childhood Sexuality 5. Adolescent Sexuality 6. Adult Sexuality 7. Gender Roles Part 3. Psychological Perspectives: Loving and Being Loved 8. Intimacy and Communication Skills 9. Enhancing your Sexual Relationships 10. Sexual Orientation 11. Sexual Behaviour 12. Sexual Variations 13. Coercive Sex - the Varieties of Sexual Assault Part 4. Sexual Health Perspectives: Sexually Transmitted Diseases and Sexual Infections 14. HIV Infection and AIDS 15. Sexual Dysfunctions and Sex Therapy 16. Sexual Disorders and Sexual Health Part 5 Cultural Perspectives: Sex and the Law 17. Religious and Ethical Perspectives and Sexuality,1954.0,0.0,21615.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Maslow1954MotivationAP,\n author = {A. Maslow},\n title = {Motivation and Personality},\n year = {1954}\n}\n'}","[{'authorId': '48713852', 'name': 'A. Maslow'}]"
2872,fbb671eaf936e0ccf5fde68ab40f31251e2e919e,Attending to the Big Picture: Mood and Global Versus Local Processing of Visual Information,"Two experiments employed image-based tasks to test the hypothesis that happier moods promote a greater focus on the forest and sadder moods a greater focus on the trees. The hypothesis was based on the idea that in task situations, affective cues may be experienced as task-relevant information, which then influences global versus local attention. Using a serial-reproduction paradigm, Experiment 1 showed that individuals in sad moods were less likely than those in happier moods to use an accessible global concept to guide attempts to reproduce a drawing from memory. Experiment 2 investigated the same hypothesis by assessing the use of global and local attributes to classify geometric figures. As predicted, individuals in sad moods were less likely than those in happier moods to classify figures on the basis of global features.",2002.0,35.0,1065.0,False,,"{'volume': '13', 'pages': '34 - 40', 'name': 'Psychological Science'}","{'bibtex': '@Article{Gasper2002AttendingTT,\n author = {Karen Gasper and G. Clore},\n journal = {Psychological Science},\n pages = {34 - 40},\n title = {Attending to the Big Picture: Mood and Global Versus Local Processing of Visual Information},\n volume = {13},\n year = {2002}\n}\n'}","[{'authorId': '5443453', 'name': 'Karen Gasper'}, {'authorId': '31458494', 'name': 'G. Clore'}]"
2873,fbbaca478fb74e5f35c8594be1d1e3840927db8a,"Social Supports, and Social Relation-ships",,1990.0,0.0,263.0,False,,"{'volume': '', 'pages': '205-226', 'name': ''}","{'bibtex': '@Inproceedings{Antonucci1990SocialSA,\n author = {T. Antonucci},\n pages = {205-226},\n title = {Social Supports, and Social Relation-ships},\n year = {1990}\n}\n'}","[{'authorId': '114052485', 'name': 'T. Antonucci'}]"
2874,fbe23d8cbabff474d064b3c859b0fcf62a69b405,An Ingroup Advantage for Confidence in Emotion Recognition Judgments: The Moderating Effect of Familiarity With the Expressions of Outgroup Members,"The confidence we have in our assessment of an interaction partner's emotional state can have important consequences for the quality of the interaction. Two studies assessed the hypothesis that immigrants are more confident in their judgment of others' emotional facial expressions if the expresser is a member of their cultural ingroup rather than a member of the host community or another cultural group. In addition, the effects of the perceived familiarity with the type of expression, the length of residence in the host country, the quality of cross-cultural contact, the level of acculturation, and the intensity of the facial expressions were assessed. Overall, the results revealed an ingroup advantage effect for confidence ratings as well as support for the notion that individuals are more confident when judging expressions that they consider as more frequently displayed in everyday life. Furthermore, individuals were more confident when judging happiness expressions as well as more intense expressions in general.",2006.0,39.0,91.0,False,,"{'volume': '32', 'pages': '16 - 26', 'name': 'Personality and Social Psychology Bulletin'}","{'bibtex': '@Article{Beaupré2006AnIA,\n author = {Martin G. Beaupré and U. Hess},\n journal = {Personality and Social Psychology Bulletin},\n pages = {16 - 26},\n title = {An Ingroup Advantage for Confidence in Emotion Recognition Judgments: The Moderating Effect of Familiarity With the Expressions of Outgroup Members},\n volume = {32},\n year = {2006}\n}\n'}","[{'authorId': '5868984', 'name': 'Martin G. Beaupré'}, {'authorId': '3067657', 'name': 'U. Hess'}]"
2875,fbe2ba616d50dcbb629357483516af28c21175a7,An Eye Tracking Evaluation of a Virtual Pediatric Patient Training System for Nurses,,2014.0,23.0,7.0,False,,{'pages': '329-338'},"{'bibtex': '@Inproceedings{Bloodworth2014AnET,\n author = {Toni Bloodworth and Lauren Cairco and L. Hodges and N. Meehan and Arlene Johnson},\n pages = {329-338},\n title = {An Eye Tracking Evaluation of a Virtual Pediatric Patient Training System for Nurses},\n year = {2014}\n}\n'}","[{'authorId': '2179460', 'name': 'Toni Bloodworth'}, {'authorId': '2725134', 'name': 'Lauren Cairco'}, {'authorId': '1710833', 'name': 'L. Hodges'}, {'authorId': '2165018', 'name': 'N. Meehan'}, {'authorId': '14476154', 'name': 'Arlene Johnson'}]"
2876,fc1761014d643028a29b7223fc4b6ac04d07805c,Children's Trust in Technological and Human Informants,"Children understand early in development that different people know different things, and they are adept at using this information to select appropriate sources of information (Lutz & Keil, 2002). However, in the current digital age, information may be gathered from both humans and technological sources that select and present information as humans do. Using methods designed to study epistemic trust in human informants (e.g., Koenig, Clement, & Harris, 2004), the current study investigates children’s and adults’ selective trust in a technological and human informant. Children (ages 4 and 5) and adults were presented with queries designed to probe their willingness to seek out and accept information from human versus technological informants. The results demonstrate that 4-year-olds prefer to seek information from a human informant, but by age 5, children show an increasing preference for the technological informant. The relationship between children’s trust and their experience with technology is also discussed.",2015.0,18.0,9.0,False,,"{'volume': '', 'name': 'Cognitive Science'}","{'bibtex': ""@Article{Noles2015ChildrensTI,\n author = {Nicholaus S. Noles and Judith H. Danovitch and Patrick Shafto},\n journal = {Cognitive Science},\n title = {Children's Trust in Technological and Human Informants},\n year = {2015}\n}\n""}","[{'authorId': '2218550', 'name': 'Nicholaus S. Noles'}, {'authorId': '3196314', 'name': 'Judith H. Danovitch'}, {'authorId': '3210220', 'name': 'Patrick Shafto'}]"
2877,fc1c1c3e263449ae5b3ed807160af0fd225e792f,Exploring EEG Features in Cross-Subject Emotion Recognition,"Recognizing cross-subject emotions based on brain imaging data, e.g., EEG, has always been difficult due to the poor generalizability of features across subjects. Thus, systematically exploring the ability of different EEG features to identify emotional information across subjects is crucial. Prior related work has explored this question based only on one or two kinds of features, and different findings and conclusions have been presented. In this work, we aim at a more comprehensive investigation on this question with a wider range of feature types, including 18 kinds of linear and non-linear EEG features. The effectiveness of these features was examined on two publicly accessible datasets, namely, the dataset for emotion analysis using physiological signals (DEAP) and the SJTU emotion EEG dataset (SEED). We adopted the support vector machine (SVM) approach and the “leave-one-subject-out” verification strategy to evaluate recognition performance. Using automatic feature selection methods, the highest mean recognition accuracy of 59.06% (AUC = 0.605) on the DEAP dataset and of 83.33% (AUC = 0.904) on the SEED dataset were reached. Furthermore, using manually operated feature selection on the SEED dataset, we explored the importance of different EEG features in cross-subject emotion recognition from multiple perspectives, including different channels, brain regions, rhythms, and feature types. For example, we found that the Hjorth parameter of mobility in the beta rhythm achieved the best mean recognition accuracy compared to the other features. Through a pilot correlation analysis, we further examined the highly correlated features, for a better understanding of the implications hidden in those features that allow for differentiating cross-subject emotions. Various remarkable observations have been made. The results of this paper validate the possibility of exploring robust EEG features in cross-subject emotion recognition.",2018.0,39.0,219.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fnins.2018.00162/pdf', 'status': None}","{'volume': '12', 'name': 'Frontiers in Neuroscience'}","{'bibtex': '@Article{Li2018ExploringEF,\n author = {Xiang Li and D. Song and Peng Zhang and Yazhou Zhang and Yuexian Hou and B. Hu},\n journal = {Frontiers in Neuroscience},\n title = {Exploring EEG Features in Cross-Subject Emotion Recognition},\n volume = {12},\n year = {2018}\n}\n'}","[{'authorId': '2144439454', 'name': 'Xiang Li'}, {'authorId': '48437245', 'name': 'D. Song'}, {'authorId': '33623312', 'name': 'Peng Zhang'}, {'authorId': '5715280', 'name': 'Yazhou Zhang'}, {'authorId': '1785922', 'name': 'Yuexian Hou'}, {'authorId': '144010725', 'name': 'B. Hu'}]"
2878,fc27d95c7875813f23e3150bfcd512bbd069a00b,The interpersonal effects of anger and happiness in negotiations.,"Three experiments investigated the interpersonal effects of anger and happiness in negotiations. In the course of a computer-mediated negotiation, participants received information about the emotional state (anger, happiness, or none) of their opponent. Consistent with a strategic-choice perspective, Experiment 1 showed that participants conceded more to an angry opponent than to a happy one. Experiment 2 showed that this effect was caused by tracking--participants used the emotion information to infer the other's limit, and they adjusted their demands accordingly. However, this effect was absent when the other made large concessions. Experiment 3 examined the interplay between experienced and communicated emotion and showed that angry communications (unlike happy ones) induced fear and thereby mitigated the effect of the opponent's experienced emotion. These results suggest that negotiators are especially influenced by their opponent's emotions when they are motivated and able to consider them.",2004.0,112.0,757.0,False,,"{'volume': '86 1', 'pages': '\n          57-76\n        ', 'name': 'Journal of personality and social psychology'}","{'bibtex': '@Article{Kleef2004TheIE,\n author = {Gerben A. van Kleef and C. D. De Dreu and A. Manstead},\n journal = {Journal of personality and social psychology},\n pages = {\n          57-76\n        },\n title = {The interpersonal effects of anger and happiness in negotiations.},\n volume = {86 1},\n year = {2004}\n}\n'}","[{'authorId': '5980688', 'name': 'Gerben A. van Kleef'}, {'authorId': '8494133', 'name': 'C. D. De Dreu'}, {'authorId': '92736978', 'name': 'A. Manstead'}]"
2879,fc5cfedfcfcc89006706655a2b4685d686aebd2f,Mapping the demographics of virtual humans,"This paper presents a census of 147 virtual agents, by examining and reporting on their physical and demographical characteristics. The study shows that the vast majority of agents developed are from a white ethnic background. Overall, female agents tend to be more photo realistic than their male counterparts who are more cartoon like. These findings highlight current stereotypes in relation to agents and contribute to a deeper understanding of virtual worlds.",2007.0,17.0,12.0,True,"{'url': 'https://www.scienceopen.com/document_file/2bfb3802-80ba-4e39-8a1b-4355c8512083/ScienceOpen/001_Khan.pdf', 'status': None}",{'pages': '149-152'},"{'bibtex': '@Inproceedings{Khan2007MappingTD,\n author = {R. Khan and A. D. Angeli},\n pages = {149-152},\n title = {Mapping the demographics of virtual humans},\n year = {2007}\n}\n'}","[{'authorId': '153914091', 'name': 'R. Khan'}, {'authorId': '34919047', 'name': 'A. D. Angeli'}]"
2880,fc85d88ed4f8d2b1c6bc99e424b7f052244e8708,Towards building a virtual counselor: modeling nonverbal behavior during intimate self-disclosure,"Nonverbal behavior is considered critical for indicating intimacy and is important when designing a social virtual agent such as a counselor. One key research question is how to properly express intimate self-disclosure. In this paper we present an extensive study of human nonverbal behavior during intimate self-disclosure. This is an important milestone in creating a virtual counselor. A study of video interactions between human participants demonstrated that people display more head tilts and pauses when they revealed highly intimate information about themselves; they presented more head nods and eye gazes during less intimate sharing. An implementation of these behaviors in a virtual agent suggests that people tend to perceive head tilts, pauses and gaze aversion by the agent as conveying intimate self-disclosure. These findings are important for future research with virtual counselors and other social agents.",2012.0,32.0,45.0,False,,{'pages': '63-70'},"{'bibtex': '@Inproceedings{Kang2012TowardsBA,\n author = {Sin-Hwa Kang and J. Gratch and C. Sidner and Ron Artstein and Lixing Huang and Louis-Philippe Morency},\n pages = {63-70},\n title = {Towards building a virtual counselor: modeling nonverbal behavior during intimate self-disclosure},\n year = {2012}\n}\n'}","[{'authorId': '34728215', 'name': 'Sin-Hwa Kang'}, {'authorId': '145438097', 'name': 'J. Gratch'}, {'authorId': '2668280', 'name': 'C. Sidner'}, {'authorId': '2038490', 'name': 'Ron Artstein'}, {'authorId': '2110799090', 'name': 'Lixing Huang'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]"
2882,fc926d019e454e156ad078fc52f0f5c4d42d9198,Emotion recognition in human-computer interaction,,2012.0,0.0,310.0,False,,,"{'bibtex': '@Inproceedings{Hay2012EmotionRI,\n author = {Mann Oo. Hay},\n title = {Emotion recognition in human-computer interaction},\n year = {2012}\n}\n'}","[{'authorId': '100949613', 'name': 'Mann Oo. Hay'}]"
2883,fca426351c90693a879e7b230fded3aab9d7edab,The Behavior Markup Language: Recent Developments and Challenges,,2007.0,14.0,262.0,True,"{'url': 'https://research.utwente.nl/files/232516676/Vilhj_lmsson2007behavior.pdf', 'status': None}",{'pages': '99-111'},"{'bibtex': '@Inproceedings{Vilhjálmsson2007TheBM,\n author = {H. Vilhjálmsson and Nathan Cantelmo and Justine Cassell and Nicolas Ech Chafai and Michael Kipp and S. Kopp and M. Mancini and S. Marsella and Andrew N. Marshall and C. Pelachaud and Z. Ruttkay and K. Thórisson and H. V. Welbergen and R. J. V. D. Werf},\n pages = {99-111},\n title = {The Behavior Markup Language: Recent Developments and Challenges},\n year = {2007}\n}\n'}","[{'authorId': '2451989', 'name': 'H. Vilhjálmsson'}, {'authorId': '15955933', 'name': 'Nathan Cantelmo'}, {'authorId': '145431806', 'name': 'Justine Cassell'}, {'authorId': '3021356', 'name': 'Nicolas Ech Chafai'}, {'authorId': '145616714', 'name': 'Michael Kipp'}, {'authorId': '5864138', 'name': 'S. Kopp'}, {'authorId': '2169958', 'name': 'M. Mancini'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2979549', 'name': 'Andrew N. Marshall'}, {'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '66484736', 'name': 'Z. Ruttkay'}, {'authorId': '1727838', 'name': 'K. Thórisson'}, {'authorId': '3251916', 'name': 'H. V. Welbergen'}, {'authorId': '2015385', 'name': 'R. J. V. D. Werf'}]"
2884,fca83bc9c768ca236f178ad59a57f07bd56b6875,A Dynamical System Modelling Approach to Gross' Model of Emotion Regulation,"This paper introduces a computational model for emotion regulation formalising the model informally described by Gross (1998). The model has been constructed using a highlevel modelling language, and integrates both quantitative aspects (such as levels of emotional response) and qualitative aspects (such as decisions to regulate one’s emotion). A number of simulation experiments have been performed, demonstrating that the computational model successfully reflects the model as described by Gross.",2007.0,21.0,40.0,False,,"{'volume': '', 'pages': '187-192', 'name': ''}","{'bibtex': ""@Inproceedings{Bosse2007ADS,\n author = {T. Bosse and Pontier and Jan Treur},\n pages = {187-192},\n title = {A Dynamical System Modelling Approach to Gross' Model of Emotion Regulation},\n year = {2007}\n}\n""}","[{'authorId': '145518106', 'name': 'T. Bosse'}, {'authorId': '118596324', 'name': 'Pontier'}, {'authorId': '1726343', 'name': 'Jan Treur'}]"
2886,fcd377802681d9e70296eba90d520e170f2d3a0b,"Your Robot Therapist Will See You Now: Ethical Implications of Embodied Artificial Intelligence in Psychiatry, Psychology, and Psychotherapy","Background Research in embodied artificial intelligence (AI) has increasing clinical relevance for therapeutic applications in mental health services. With innovations ranging from ‘virtual psychotherapists’ to social robots in dementia care and autism disorder, to robots for sexual disorders, artificially intelligent virtual and robotic agents are increasingly taking on high-level therapeutic interventions that used to be offered exclusively by highly trained, skilled health professionals. In order to enable responsible clinical implementation, ethical and social implications of the increasing use of embodied AI in mental health need to be identified and addressed. Objective This paper assesses the ethical and social implications of translating embodied AI applications into mental health care across the fields of Psychiatry, Psychology and Psychotherapy. Building on this analysis, it develops a set of preliminary recommendations on how to address ethical and social challenges in current and future applications of embodied AI. Methods Based on a thematic literature search and established principles of medical ethics, an analysis of the ethical and social aspects of currently embodied AI applications was conducted across the fields of Psychiatry, Psychology, and Psychotherapy. To enable a comprehensive evaluation, the analysis was structured around the following three steps: assessment of potential benefits; analysis of overarching ethical issues and concerns; discussion of specific ethical and social issues of the interventions. Results From an ethical perspective, important benefits of embodied AI applications in mental health include new modes of treatment, opportunities to engage hard-to-reach populations, better patient response, and freeing up time for physicians. Overarching ethical issues and concerns include: harm prevention and various questions of data ethics; a lack of guidance on development of AI applications, their clinical integration and training of health professionals; ‘gaps’ in ethical and regulatory frameworks; the potential for misuse including using the technologies to replace established services, thereby potentially exacerbating existing health inequalities. Specific challenges identified and discussed in the application of embodied AI include: matters of risk-assessment, referrals, and supervision; the need to respect and protect patient autonomy; the role of non-human therapy; transparency in the use of algorithms; and specific concerns regarding long-term effects of these applications on understandings of illness and the human condition. Conclusions We argue that embodied AI is a promising approach across the field of mental health; however, further research is needed to address the broader ethical and societal concerns of these technologies to negotiate best research and medical practices in innovative mental health care. We conclude by indicating areas of future research and developing recommendations for high-priority areas in need of concrete ethical guidance.",2018.0,102.0,221.0,True,,"{'volume': '21', 'name': 'Journal of Medical Internet Research'}","{'bibtex': '@Article{Fiske2018YourRT,\n author = {A. Fiske and P. Henningsen and A. Buyx},\n journal = {Journal of Medical Internet Research},\n title = {Your Robot Therapist Will See You Now: Ethical Implications of Embodied Artificial Intelligence in Psychiatry, Psychology, and Psychotherapy},\n volume = {21},\n year = {2018}\n}\n'}","[{'authorId': '46217950', 'name': 'A. Fiske'}, {'authorId': '6743130', 'name': 'P. Henningsen'}, {'authorId': '5648439', 'name': 'A. Buyx'}]"
2887,fd0431df6e48db94b35a498b9488611568022df1,"Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice",,2016.0,11.0,663.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Plutchik2016HumanEH,\n author = {R. Plutchik},\n title = {Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice},\n year = {2016}\n}\n'}","[{'authorId': '84527386', 'name': 'R. Plutchik'}]"
2888,fd1afcaa3d66c5d31d33910a4dcca26ebe49b23f,"For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1988","The aim of this paper is to review data from my laboratory, which were collected in an attempt to determine whether the facial EMG response is a general component of the emotional reaction. 
 
 
 
In a number of studies it was found that facial reactions: first, are spontaneously elicited and differ according to the kind of emotional stimuli to which sunjects are exposed; second, are sensitive to learning; third, are consistent with how the subject perceive the stimuli and their own specific emotions; fourth, are congruent with autonomic responses; fifth, are more pronoanced for females than for males; and finally, differ among subjects with specific fears. 
 
 
 
These data converge to indicate that facial muscle activity is a general component of the emotional reaction and demonstrate that the facial EMG technique is a sensitve too for measuring emotional ractions.",1990.0,41.0,189.0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1469-8986.1990.tb01962.x', 'status': None}","{'volume': '27', 'pages': '481-494', 'name': 'Psychophysiology'}","{'bibtex': '@Article{Dimberg1990ForDE,\n author = {U. Dimberg},\n journal = {Psychophysiology},\n pages = {481-494},\n title = {For Distinguished Early Career Contribution to Psychophysiology: Award Address, 1988},\n volume = {27},\n year = {1990}\n}\n'}","[{'authorId': '4583182', 'name': 'U. Dimberg'}]"
2889,fd324bb169f8776e32f7ae76c24abdd6e7511b7c,Measuring Presence in Virtual Environments: A Presence Questionnaire,"The effectiveness of virtual environments (VEs) has often been linked to the sense of presence reported by users of those VEs. (Presence is defined as the subjective experience of being in one place or environment, even when one is physically situated in another.) We believe that presence is a normal awareness phenomenon that requires directed attention and is based in the interaction between sensory stimulation, environmental factors that encourage involvement and enable immersion, and internal tendencies to become involved. Factors believed to underlie presence were described in the premier issue of Presence: Teleoperators and Virtual Environments. We used these factors and others as the basis for a presence questionnaire (PQ) to measure presence in VEs. In addition we developed an immersive tendencies questionnaire (ITQ) to measure differences in the tendencies of individuals to experience presence. These questionnaires are being used to evaluate relationships among reported presence and other research variables. Combined results from four experiments lead to the following conclusions: the PQ and ITQ are internally consistent measures with high reliability; there is a weak but consistent positive relation between presence and task performance in VEs; individual tendencies as measured by the ITQ predict presence as measured by the PQ; and individuals who report more simulator sickness symptoms in VE report less presence than those who report fewer symptoms.",1998.0,40.0,5222.0,False,,"{'volume': '7', 'pages': '225-240', 'name': 'Presence'}","{'bibtex': '@Article{Witmer1998MeasuringPI,\n author = {B. Witmer and M. Singer},\n journal = {Presence},\n pages = {225-240},\n title = {Measuring Presence in Virtual Environments: A Presence Questionnaire},\n volume = {7},\n year = {1998}\n}\n'}","[{'authorId': '66831741', 'name': 'B. Witmer'}, {'authorId': '2066654042', 'name': 'M. Singer'}]"
2890,fd4ff5e76e17766a0a1ef8c5daba6170d398accc,Identifying units in interaction: Reactive tokens in Korean and English conversations,"Reactive tokens are conversational resources by which a listener co-constructs a speaker's turn at talk. The resources that are available include the forms of the reactive tokens themselves, their duration, and their placement by the listener in the current speaker's turn. The present paper is a contrastive study of the use of these resources by Americans in English, and by Koreans in their native language and in English, and in it we show the ecological relationship between the resources that a language provides and their use in constructing active listenership. Although previous research on English has found listeners use reactive tokens to pass up the opportunity for a full turn at talk, we show that, in Korean, reactive tokens are often elicited by the current speaker and the listener is obligated to provide them. We present evidence that Korean bilinguals transfer some conversational resources from their native language when they take part in conversation in English.",2004.0,44.0,59.0,False,,"{'volume': '8', 'pages': '380-407', 'name': 'Journal of Sociolinguistics'}","{'bibtex': '@Article{Young2004IdentifyingUI,\n author = {R. Young and Jina Lee},\n journal = {Journal of Sociolinguistics},\n pages = {380-407},\n title = {Identifying units in interaction: Reactive tokens in Korean and English conversations},\n volume = {8},\n year = {2004}\n}\n'}","[{'authorId': '2087260302', 'name': 'R. Young'}, {'authorId': '9174234', 'name': 'Jina Lee'}]"
2891,fd9a7f5041d7d346777e8692666505b6e1b26413,Interventions to Improve Antipsychotic Medication Adherence: Review of Recent Literature,"Antipsychotic nonadherence is an important barrier to the successful treatment of schizophrenia and can lead to clinical and economic burdens. Interventions capable of significantly improving medication adherence in patients with schizophrenia would be beneficial in maximizing treatment outcomes with antipsychotics. This article reviews recent literature reporting interventions designed to improve antipsychotic adherence in patients with schizophrenia. We searched the Medline, Healthstar, and PsycInfo electronic databases for articles published since 1980 on interventions to improve medication adherence in schizophrenia. Twenty-one studies met our selection criteria. In this review, educational, behavioral, affective, or a combination of these approaches to improve adherence were exammed. A total of 23 interventions were tested, as 2 studies investigated more than 1 intervention. While study design and adherence measures varied across the trials reviewed, medication adherence was noted to moderately improve with 15 of the 23 interventions tested. Interventions of a purely educational nature were the least successful at improving antipsychotic adherence. The greatest improvement in adherence was seen with interventions employing combinations of educational, behavioral, and affective strategies with which improvements in adherence were noted in 8 out of 12 studies, with additional secondary gains such as: reduced relapse, decreased hospitalization, decreased psychopathology, improved social function, gains in medication knowledge, and improved insight into the need for treatment. Longer interventions and an alliance with therapists also appeared important for successful outcomes. The continuing development and study of successful interventions to improve medication adherence are necessary to maximize the usefulness of pharmacologic treatment of schizophrenia.",2003.0,33.0,222.0,False,,"{'volume': '23', 'pages': '389-399', 'name': 'Journal of Clinical Psychopharmacology'}","{'bibtex': '@Article{Dolder2003InterventionsTI,\n author = {Christian R. Dolder and J. Lacro and S. Leckband and D. Jeste},\n journal = {Journal of Clinical Psychopharmacology},\n pages = {389-399},\n title = {Interventions to Improve Antipsychotic Medication Adherence: Review of Recent Literature},\n volume = {23},\n year = {2003}\n}\n'}","[{'authorId': '5969840', 'name': 'Christian R. Dolder'}, {'authorId': '6367536', 'name': 'J. Lacro'}, {'authorId': '4652667', 'name': 'S. Leckband'}, {'authorId': '74263382', 'name': 'D. Jeste'}]"
2892,fddf060c19051aa194be40be5a337d032c90929f,Automatically Assessing Personality from Speech,"In this paper, we present first results on applying a personality assessment paradigm to speech input, and comparing human and automatic performance on this task. We cue a professional speaker to produce speech using different personality profiles and encode the resulting vocal personality impressions in terms of the ""Big Five"" NEO-FFI personality traits. We then have human raters, who do not know the speaker, estimate the five factors. We analyze the recordings using signal-based acoustic and prosodic methods and observe high consistency between the acted personalities, the raters' assessments, and initial automatic classification results. This presents a first step towards being able to handle personality traits in speech, which we envision will be used in future voice-based communication between humans and machines.",2010.0,13.0,85.0,True,"{'url': 'https://figshare.com/articles/journal_contribution/Automatically_Assessing_Personality_from_Speech/6473081/1/files/11902601.pdf', 'status': None}","{'pages': '134-140', 'name': '2010 IEEE Fourth International Conference on Semantic Computing'}","{'bibtex': '@Article{Polzehl2010AutomaticallyAP,\n author = {Tim Polzehl and S. Möller and Florian Metze},\n journal = {2010 IEEE Fourth International Conference on Semantic Computing},\n pages = {134-140},\n title = {Automatically Assessing Personality from Speech},\n year = {2010}\n}\n'}","[{'authorId': '1912566', 'name': 'Tim Polzehl'}, {'authorId': '145733288', 'name': 'S. Möller'}, {'authorId': '1740721', 'name': 'Florian Metze'}]"
2893,fdeefc701b62c6e2a6e407757e81ccc473fe950a,What Makes Great Teaching? Review of the Underpinning Research.,This report reviews over 200 pieces of research to identify the elements of teaching with the strongest evidence of improving attainment. It finds some common practices can be harmful to learning and have no grounding in research. Specific practices which are supported by good evidence of their effectiveness are also examined and six key factors that contribute to great teaching are identified. The report also analyses different methods of evaluating teaching including: using ‘value-added’ results from student test scores; observing classroom teaching; and getting students to rate the quality of their teaching.,2014.0,89.0,342.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Coe2014WhatMG,\n author = {R. Coe and Cesare Aloisi and S. Higgins and L. Major},\n title = {What Makes Great Teaching? Review of the Underpinning Research.},\n year = {2014}\n}\n'}","[{'authorId': '31710008', 'name': 'R. Coe'}, {'authorId': '117934075', 'name': 'Cesare Aloisi'}, {'authorId': '145966100', 'name': 'S. Higgins'}, {'authorId': '114277639', 'name': 'L. Major'}]"
2894,fdfe996e24772ac8b48fc0f7b72140d0d2f366c1,Emotion regulation in Asperger's syndrome and high-functioning autism.,"It is generally thought that individuals with Asperger's syndrome and high-functioning autism (AS/HFA) have deficits in theory of mind. These deficits have been previously linked to problems with social cognition. However, we reasoned that AS/HFA individuals' Theory of Mind deficits also might lead to problems with emotion regulation. To assess emotional functioning in AS/HFA, 27 AS/HFA adults (16 women) and 27 age-, gender-, and education-matched typically developing (TD) participants completed a battery of measures of emotion experience, labeling, and regulation. With respect to emotion experience, individuals with AS/HFA reported higher levels of negative emotions, but similar levels of positive emotions, compared with TD individuals. With respect to emotion labeling, individuals with AS/HFA had greater difficulties identifying and describing their emotions, with approximately two-thirds exceeding the cutoff for alexithymia. With respect to emotion regulation, individuals with AS/HFA used reappraisal less frequently than TD individuals and reported lower levels of reappraisal self-efficacy. Although AS/HFA individuals used suppression more frequently than TD individuals, no difference in suppression self-efficacy was found. It is important to note that these differences in emotion regulation were evident even when controlling for emotion experience and labeling. Implications of these deficits are discussed, and future research directions are proposed.",2012.0,56.0,295.0,False,,"{'volume': '12 4', 'pages': '\n          659-65\n        ', 'name': 'Emotion'}","{'bibtex': ""@Article{Samson2012EmotionRI,\n author = {Andrea C. Samson and O. Huber and J. Gross},\n journal = {Emotion},\n pages = {\n          659-65\n        },\n title = {Emotion regulation in Asperger's syndrome and high-functioning autism.},\n volume = {12 4},\n year = {2012}\n}\n""}","[{'authorId': '38707445', 'name': 'Andrea C. Samson'}, {'authorId': '48474585', 'name': 'O. Huber'}, {'authorId': '1775321', 'name': 'J. Gross'}]"
2895,fdfffbae1fb2408152458485e4f6cd3d17cdb5ff,Computational Model of Believable Conversational Agents,,2003.0,36.0,103.0,False,,{'pages': '300-317'},"{'bibtex': '@Inproceedings{Pelachaud2003ComputationalMO,\n author = {C. Pelachaud and Massimo Bilvi},\n pages = {300-317},\n title = {Computational Model of Believable Conversational Agents},\n year = {2003}\n}\n'}","[{'authorId': '1703084', 'name': 'C. Pelachaud'}, {'authorId': '2832483', 'name': 'Massimo Bilvi'}]"
2896,fe10d7e580a675c9ef67107366ee084a3da52d33,Keeping your distance: attentional withdrawal in individuals who show physiological signs of social discomfort,,2015.0,50.0,22.0,False,,"{'volume': '70', 'pages': '462-467', 'name': 'Neuropsychologia'}","{'bibtex': '@Article{Szpak2015KeepingYD,\n author = {Ancrêt Szpak and T. Loetscher and O. Churches and N. Thomas and C. Spence and M. Nicholls},\n journal = {Neuropsychologia},\n pages = {462-467},\n title = {Keeping your distance: attentional withdrawal in individuals who show physiological signs of social discomfort},\n volume = {70},\n year = {2015}\n}\n'}","[{'authorId': '40486665', 'name': 'Ancrêt Szpak'}, {'authorId': '3248174', 'name': 'T. Loetscher'}, {'authorId': '4886405', 'name': 'O. Churches'}, {'authorId': '2262597', 'name': 'N. Thomas'}, {'authorId': '46582609', 'name': 'C. Spence'}, {'authorId': '143991815', 'name': 'M. Nicholls'}]"
2897,fe1c93fb98fe2fc89e3e17b3c95877b0326ad35b,M-learning and Augmented Reality: A Review of the Scientific Literature on the WoS Repository,"Augmented reality emerges as a tool, on which it is necessary to examine its real educational value. This paper shows the results of a bibliometric analysis performed on documents collected from the Web of Science repository, an Internet service that concentrates bibliographic information from more than 7,000 institutions. Our analysis included an overall universe of 12,000 indexed journals and 148,000 conference proceedings. From those, we selected a sample targeting the terms “mobile-learning” or “m-learning” and “augmented reality” as descriptors or components of titles of scientific works. The analysis on journals (n=741)",2017.0,62.0,30.0,False,,,"{'bibtex': '@Inproceedings{Fombona2017MlearningAA,\n author = {Dr. Javier Fombona and Dr. Maria-Angeles Pascual-Sevillano and Dr. MariCarmen González-Videgaray},\n title = {M-learning and Augmented Reality: A Review of the Scientific Literature on the WoS Repository},\n year = {2017}\n}\n'}","[{'authorId': '2265886730', 'name': 'Dr. Javier Fombona'}, {'authorId': '2265887271', 'name': 'Dr. Maria-Angeles Pascual-Sevillano'}, {'authorId': '2265887269', 'name': 'Dr. MariCarmen González-Videgaray'}]"
2898,fe332edfd08a8393696834a69c2d60d38fc896e9,RESEARCH ON THE REGULATION OF MULTI-AGENT'S EMOTION BASED ON MULTI-AGENT'S HETEROGENEOUS GAME PREFERENCE AND BILATERAL PARTNER'S PREFERENCE,"
 
 
 The development of virtual enterprise is inseparable from the support of partners. Due to information asymmetry, the choice of virtual enterprise partners is blind, and simple matching formula is difficult to meet. At the same time, the psychology of the matching subject is based on the maximization of its own interests rather than the maximization of collective interests. There are interest contradictions and conflicts between subjects, and they may eventually fall into a “prisoner's dilemma”. Therefore, how to carry out the research on emotion regulation based on multi-agent heterogeneous game preference and bilateral partner preference is very important.
 
 
 
 Aiming at the contradictions and interest conflicts between subjects in the process of virtual enterprise partner matching, combined with the basic characteristics of subject language preference evaluation, the game idea is introduced into the process of virtual enterprise partner bilateral matching analysis, a bilateral matching game model of heterogeneous multi-attribute preference and subjects' psychological behavior is proposed, and the influence of the changes of subjects' psychological behavior on the evolution law of bilateral matching game system is analyzed, The Nash equilibrium strategy of bilateral matching is discussed. In order to verify the impact of the algorithm on emotion, this study uses relevant scales to investigate. (1) Positive emotion scale. The Panas emotion scale developed by Watson et al. Is widely used to measure emotion. The scale includes two dimensions: positive emotion and negative emotion. There are 6 questions in this dimension, and Likert scores 5 points (1 means “very inconsistent”, 5 means “very consistent”, the same below). The Cronbach coefficient of this questionnaire is 0.90. (2) Motivation. The problem of measuring motivation is mainly the motivation scale compiled by Phan, which has 8 questions and is scored with Likert 5 points. (3) Social support scale. The scale is adapted from the social support scale compiled by Ye Yuemei et al. It has eight questions, using Likert's five points scoring method. Clonbach α the coefficient of the scale is 0.87. (4) Behavioral propensity scale. Propensity dimension in intention measurement. The scale has 6 questions, and Likert scores 5 points. The clonbach coefficient of the scale is 0.95.
 
 
 
 The results of case analysis show that the model can make full use of the multi-attribute preference information of heterogeneous subjects, describe the mechanism of psychological behavior affecting the evolution of game system, and help virtual enterprises match business partners; This has important value and significance for the establishment of virtual enterprises and their industrial agglomeration effect. In the influence process of cooperative anxiety, emotional response plays an intermediary role, psychological elasticity plays a regulatory role, and emotional response to life events plays an intermediary role. That is, the higher the psychological elasticity, the higher the excessive coping style of the game, and vice versa.
 
 
 
 Various stable matching solutions can be obtained by solving the model, and the conclusion is more suitable for the matching decision-making process of both parties in the actual process, which makes the model can be applied to various scenarios, such as the selection of battery suppliers of new energy vehicles and smart phone screen suppliers, which has greater practical value and significance. It should be pointed out that there are some deficiencies in the setting conditions of the model method, mainly because some individuals in the group cooperate to form an alliance, so as to form a community of interests. In the process of game, the individual experience in the group is constrained by more conditions, which makes the results of the model deviate.
 
 
 
 Zhejiang Provincial Natural Science Foundation (No. LQ20G010005), Zhejiang Provincial Statistical Science Research Project (NO. 21TJQN15) and Natural Science Fund Project of Huzhou City (No. 2018YZ13)
",2022.0,0.0,0.0,True,"{'url': 'https://academic.oup.com/ijnp/article-pdf/25/Supplement_1/A57/44558559/pyac032.079.pdf', 'status': 'GOLD'}",{'name': 'International Journal of Neuropsychopharmacology'},"{'bibtex': ""@Article{Xiao2022RESEARCHOT,\n author = {Hanjie Xiao and Shuyan Bao and Liang Wu and Honglei Tang and Guosong Wu and Jianhua Zhou and Jianxin Xu},\n booktitle = {International Journal of Neuropsychopharmacology},\n journal = {International Journal of Neuropsychopharmacology},\n title = {RESEARCH ON THE REGULATION OF MULTI-AGENT'S EMOTION BASED ON MULTI-AGENT'S HETEROGENEOUS GAME PREFERENCE AND BILATERAL PARTNER'S PREFERENCE},\n year = {2022}\n}\n""}","[{'authorId': '93408810', 'name': 'Hanjie Xiao'}, {'authorId': '104449167', 'name': 'Shuyan Bao'}, {'authorId': '2167863602', 'name': 'Liang Wu'}, {'authorId': '2112779703', 'name': 'Honglei Tang'}, {'authorId': '2153300143', 'name': 'Guosong Wu'}, {'authorId': '1750047336', 'name': 'Jianhua Zhou'}, {'authorId': '2175623845', 'name': 'Jianxin Xu'}]"
2899,fe6215fa06cc12f2ce776483c8da2996df7efb2e,"Appraisal processes in emotion: Theory, methods, research.","Appraisal theory has become one of the most active aproaches in the domain of emotion psychology. The appraisal process consists of the subjective evaluation that occurs during the individual's encounter with significant events in the environment, thus determining the nature of the emotional reaction and experience. The organism's interpretation of events and situations elicits and differentiates its emotional responses, although the exact processes involved and the limits of the theory are still a matter of debate and are currently the object of active research. This volume is intended to become the primary source of information on appraisal for all those interested in emotion, from beginning graduate students to accomplished researchers in emotion psychology.",2001.0,1.0,1784.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Scherer2001AppraisalPI,\n author = {K. Scherer and A. Schorr and T. Johnstone},\n title = {Appraisal processes in emotion: Theory, methods, research.},\n year = {2001}\n}\n'}","[{'authorId': '2462740', 'name': 'K. Scherer'}, {'authorId': '35649425', 'name': 'A. Schorr'}, {'authorId': '30361732', 'name': 'T. Johnstone'}]"
2901,fe68040b7132b9ae7118fdd517986d13beba4f56,A Study of Emotional Contagion with Virtual Characters,,2012.0,22.0,47.0,False,,{'pages': '81-88'},"{'bibtex': '@Inproceedings{Tsai2012ASO,\n author = {J. Tsai and E. Bowring and S. Marsella and Wendy Wood and Milind Tambe},\n pages = {81-88},\n title = {A Study of Emotional Contagion with Virtual Characters},\n year = {2012}\n}\n'}","[{'authorId': '145009779', 'name': 'J. Tsai'}, {'authorId': '1740910', 'name': 'E. Bowring'}, {'authorId': '1788771', 'name': 'S. Marsella'}, {'authorId': '2059157982', 'name': 'Wendy Wood'}, {'authorId': '143736701', 'name': 'Milind Tambe'}]"
2906,fe9cd9ab8bcc110847a8a4792134e4917fd7e933,Using collaborative filtering to weave an information tapestry,"The Tapestry experimental mail system developed at the Xerox Palo Alto Research Center is predicated on the belief that information filtering can be more effective when humans are involved in the filtering process. Tapestry was designed to support both content-based filtering and collaborative filtering, which entails people collaborating to help each other perform filtering by recording their reactions to documents they read. The reactions are called annotations; they can be accessed by other people’s filters. Tapestry is intended to handle any incoming stream of electronic documents and serves both as a mail filter and repository; its components are the indexer, document store, annotation store, filterer, little box, remailer, appraiser and reader/browser. Tapestry’s client/server architecture, its various components, and the Tapestry query language are described.",1992.0,20.0,4280.0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/138859.138867', 'status': None}","{'volume': '35', 'pages': '61-70', 'name': 'Commun. ACM'}","{'bibtex': '@Article{Goldberg1992UsingCF,\n author = {David Goldberg and D. Nichols and B. Oki and D. Terry},\n journal = {Commun. ACM},\n pages = {61-70},\n title = {Using collaborative filtering to weave an information tapestry},\n volume = {35},\n year = {1992}\n}\n'}","[{'authorId': '38111918', 'name': 'David Goldberg'}, {'authorId': '152473861', 'name': 'D. Nichols'}, {'authorId': '1724602', 'name': 'B. Oki'}, {'authorId': '1680763', 'name': 'D. Terry'}]"
2907,feac5438d27765f0bda00257f9ce510c3f476438,Major depression: behavioral parameters of depression and recovery.,"This paper reports on an ethological study of 11 depressed hospitalized subjects. Major depression and recovery are described in terms of general behavioral traits, i.e., behavior parameters. The hypothesis, that the primary behavioral feature of major depression is a reduction of social interaction and that secondary features are reduced self occupation and body mobility (posture flexibility) is tested. The behavioral patterns of depression and recovery are described and elucidated by 12 defined behavioral parameters, eight of which show significant changes between the first and the last hospital week. Findings from six of the parameters are consistent with the hypothesis and demonstrate social inhibition during depression; interactions between depression and nonverbal behavior are particularly striking. Findings also confirm that, during depression, self occupation and body mobility are reduced to a less significant degree than social inhibition. Possible relationships between findings and agitated forms of major depression are discussed. A final section examines findings in an evolutionary context and emphasizes their clinical implications.",1998.0,24.0,53.0,False,,"{'volume': '186 3', 'pages': '\n          141-9\n        ', 'name': 'The Journal of nervous and mental disease'}","{'bibtex': '@Article{Schelde1998MajorDB,\n author = {Jens Tyge Mørk Schelde},\n journal = {The Journal of nervous and mental disease},\n pages = {\n          141-9\n        },\n title = {Major depression: behavioral parameters of depression and recovery.},\n volume = {186 3},\n year = {1998}\n}\n'}","[{'authorId': '2227379792', 'name': 'Jens Tyge Mørk Schelde'}]"
2908,fed2ae5acc2fd9d0795621de3438ee1f08365220,A Conversational Agent Framework with Multi-modal Personality Expression,"Consistently exhibited personalities are crucial elements of realistic, engaging, and behavior-rich conversational virtual agents. Both nonverbal and verbal cues help convey these agents’ unseen psychological states, contributing to our effective communication with them. We introduce a comprehensive framework to design conversational agents that express personality through non-verbal behaviors like body movement and facial expressions, as well as verbal behaviors like dialogue selection and voice transformation. We use the OCEAN personality model, which defines personality as a combination of five orthogonal factors of openness, conscientiousness, extraversion, agreeableness, and neuroticism. The framework combines existing personality expression methods with novel ones such as new algorithms to convey Laban Shape and Effort qualities. We perform Amazon Mechanical Turk studies to analyze how different communication modalities influence our perception of virtual agent personalities and compare their individual and combined effects on each personality dimension. The results indicate that our personality-based modifications are perceived as natural, and each additional modality improves perception accuracy, with the best performance achieved when all the modalities are present. We also report some correlations for the perception of conscientiousness with neuroticism and openness with extraversion.",2021.0,98.0,24.0,True,"{'url': 'http://repository.bilkent.edu.tr/bitstream/11693/76892/1/A_conversational_agent_framework_with_multi_modal_personality_expression.pdf', 'status': None}","{'volume': '40', 'pages': '1 - 16', 'name': 'ACM Transactions on Graphics (TOG)'}","{'bibtex': '@Article{Sonlu2021ACA,\n author = {Sinan Sonlu and U. Güdükbay and Funda Durupinar},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 16},\n title = {A Conversational Agent Framework with Multi-modal Personality Expression},\n volume = {40},\n year = {2021}\n}\n'}","[{'authorId': '1752928392', 'name': 'Sinan Sonlu'}, {'authorId': '1746035', 'name': 'U. Güdükbay'}, {'authorId': '2643744', 'name': 'Funda Durupinar'}]"
2909,fed404f61d4d6f23ba71a494597db5ce04140d5d,Data-driven crowd evacuation: A reinforcement learning method,,2019.0,51.0,37.0,False,,"{'volume': '366', 'pages': '314-327', 'name': 'Neurocomputing'}","{'bibtex': '@Article{Yao2019DatadrivenCE,\n author = {Zhenzhen Yao and Guijuan Zhang and Dianjie Lu and Hong Liu},\n journal = {Neurocomputing},\n pages = {314-327},\n title = {Data-driven crowd evacuation: A reinforcement learning method},\n volume = {366},\n year = {2019}\n}\n'}","[{'authorId': '2113322333', 'name': 'Zhenzhen Yao'}, {'authorId': '3172102', 'name': 'Guijuan Zhang'}, {'authorId': '7382513', 'name': 'Dianjie Lu'}, {'authorId': '2118902760', 'name': 'Hong Liu'}]"
2910,fede6fe5b167164039762ef44840210dddba991c,Emotional speech synthesis: a review,"Attempts to add emotion effects to synthesised speech have existed for more than a decade now. Several prototypes and fully operational systems have been built based on different synthesis techniques, and quite a number of smaller studies have been conducted. This paper aims to give an overview of what has been done in this field, pointing out the inherent properties of the various synthesis techniques used, summarising the prosody rules employed, and taking a look at the evaluation paradigms. Finally, an attempt is made to discuss interesting directions for future development.",2001.0,29.0,424.0,False,,{'pages': '561-564'},"{'bibtex': '@Inproceedings{Schröder2001EmotionalSS,\n author = {M. Schröder},\n pages = {561-564},\n title = {Emotional speech synthesis: a review},\n year = {2001}\n}\n'}","[{'authorId': '144951065', 'name': 'M. Schröder'}]"
2911,ff0c61dee4df7d73e22b2a6fbc1ea3f7f6241b8b,"Treatment Adjustment and Medication Adherence for Complex Patients With Diabetes, Heart Disease, and Depression: A Randomized Controlled Trial","PURPOSE Medication nonadherence, inconsistent patient self-monitoring, and inadequate treatment adjustment exacerbate poor disease control. In a collaborative, team-based, care management program for complex patients (TEAMcare), we assessed patient and physician behaviors (medication adherence, self-monitoring, and treatment adjustment) in achieving better outcomes for diabetes, coronary heart disease, and depression. METHODS A randomized controlled trial was conducted (2007–2009) in 14 primary care clinics among 214 patients with poorly controlled diabetes (glycated hemoglobin [HbA1c] ≥8.5%) or coronary heart disease (blood pressure >140/90 mm Hg or low-density lipoprotein cholesterol >130 mg/dL) with coexisting depression (Patient Health Questionnaire-9 score ≥10). In the TEAMcare program, a nurse care manager collaborated closely with primary care physicians, patients, and consultants to deliver a treat-to-target approach across multiple conditions. Measures included medication initiation, adjustment, adherence, and disease self-monitoring. RESULTS Pharmacotherapy initiation and adjustment rates were sixfold higher for antidepressants (relative rate [RR] = 6.20; P <.001), threefold higher for insulin (RR = 2.97; P <.001), and nearly twofold higher for antihypertensive medications (RR = 1.86, P <.001) among TEAMcare relative to usual care patients. Medication adherence did not differ between the 2 groups in any of the 5 therapeutic classes examined at 12 months. TEAMcare patients monitored blood pressure (RR = 3.20; P <.001) and glucose more frequently (RR = 1.28; P = .006). CONCLUSIONS Frequent and timely treatment adjustment by primary care physicians, along with increased patient self-monitoring, improved control of diabetes, depression, and heart disease, with no change in medication adherence rates. High baseline adherence rates may have exerted a ceiling effect on potential improvements in medication adherence.",2012.0,57.0,145.0,True,"{'url': 'http://www.annfammed.org/content/10/1/6.full.pdf', 'status': None}","{'volume': '10', 'pages': '14 - 6', 'name': 'The Annals of Family Medicine'}","{'bibtex': '@Article{Lin2012TreatmentAA,\n author = {E. Lin and M. Von Korff and P. Ciechanowski and Do Peterson and E. Ludman and C. Rutter and Malia M Oliver and B. Young and J. Gensichen and M. McGregor and D. Mcculloch and E. Wagner and W. Katon},\n journal = {The Annals of Family Medicine},\n pages = {14 - 6},\n title = {Treatment Adjustment and Medication Adherence for Complex Patients With Diabetes, Heart Disease, and Depression: A Randomized Controlled Trial},\n volume = {10},\n year = {2012}\n}\n'}","[{'authorId': '32312471', 'name': 'E. Lin'}, {'authorId': '88587665', 'name': 'M. Von Korff'}, {'authorId': '48449305', 'name': 'P. Ciechanowski'}, {'authorId': '3486905', 'name': 'Do Peterson'}, {'authorId': '3409526', 'name': 'E. Ludman'}, {'authorId': '144296725', 'name': 'C. Rutter'}, {'authorId': '34285343', 'name': 'Malia M Oliver'}, {'authorId': '2429446', 'name': 'B. Young'}, {'authorId': '6487701', 'name': 'J. Gensichen'}, {'authorId': '144203643', 'name': 'M. McGregor'}, {'authorId': '114319232', 'name': 'D. Mcculloch'}, {'authorId': '30885802', 'name': 'E. Wagner'}, {'authorId': '7278840', 'name': 'W. Katon'}]"
2912,ff0deb44c3d88ca36b8bd67a3ba5cbf1b2613d6d,An Evacuation Route Model of Crowd Based on Emotion and Geodesic,"Making unconventional emergent plan for dense crowd is one of the critical issues of evacuation simulations. In order to make the behavior of crowd more believable, we present a real-time evacuation route approach based on emotion and geodesic under the influence of individual emotion and multi-hazard circumstances. The proposed emotion model can reflect the dynamic process of individual in group on three factors: individual emotion, perilous field, and crowd emotion. Specifically, we first convert the evacuation scene to Delaunay triangulation representations. Then, we use the optimization-driven geodesic approach to calculate the best evacuation path with user-specified geometric constraints, such as crowd density, obstacle information, and perilous field. Finally, the Smooth Particle Hydrodynamics method is used for local avoidance of collisions with nearby agents in real-time simulation. Extensive experimental results show that our algorithm is efficient and well suited for real-time simulations of crowd evacuation.",2018.0,43.0,14.0,True,,{'name': 'Mathematical Problems in Engineering'},"{'bibtex': '@Article{Liu2018AnER,\n author = {Bangquan Liu and Z. Liu and Dechao Sun and Chunyue Bi},\n journal = {Mathematical Problems in Engineering},\n title = {An Evacuation Route Model of Crowd Based on Emotion and Geodesic},\n year = {2018}\n}\n'}","[{'authorId': '3236564', 'name': 'Bangquan Liu'}, {'authorId': '46270580', 'name': 'Z. Liu'}, {'authorId': '2865576', 'name': 'Dechao Sun'}, {'authorId': '66052862', 'name': 'Chunyue Bi'}]"
2913,ff3ac9352702bdf355511edaa1e633273d448dba,The impact of perception and presence on emotional reactions: a review of research in virtual reality,"Virtual reality (VR) has made its way into mainstream psychological research in the last two decades. This technology, with its unique ability to simulate complex, real situations and contexts, offers researchers unprecedented opportunities to investigate human behavior in well controlled designs in the laboratory. One important application of VR is the investigation of pathological processes in mental disorders, especially anxiety disorders. Research on the processes underlying threat perception, fear, and exposure therapy has shed light on more general aspects of the relation between perception and emotion. Being by its nature virtual, i.e., simulation of reality, VR strongly relies on the adequate selection of specific perceptual cues to activate emotions. Emotional experiences in turn are related to presence, another important concept in VR, which describes the user’s sense of being in a VR environment. This paper summarizes current research into perception of fear cues, emotion, and presence, aiming at the identification of the most relevant aspects of emotional experience in VR and their mutual relations. A special focus lies on a series of recent experiments designed to test the relative contribution of perception and conceptual information on fear in VR. This strand of research capitalizes on the dissociation between perception (bottom–up input) and conceptual information (top-down input) that is possible in VR. Further, we review the factors that have so far been recognized to influence presence, with emotions (e.g., fear) being the most relevant in the context of clinical psychology. Recent research has highlighted the mutual influence of presence and fear in VR, but has also traced the limits of our current understanding of this relationship. In this paper, the crucial role of perception on eliciting emotional reactions is highlighted, and the role of arousal as a basic dimension of emotional experience is discussed. An interoceptive attribution model of presence is suggested as a first step toward an integrative framework for emotion research in VR. Gaps in the current literature and future directions are outlined.",2015.0,65.0,597.0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00026/pdf', 'status': None}","{'volume': '6', 'name': 'Frontiers in Psychology'}","{'bibtex': '@Article{Diemer2015TheIO,\n author = {J. Diemer and G. Alpers and Henrik M. Peperkorn and Y. Shiban and A. Mühlberger},\n journal = {Frontiers in Psychology},\n title = {The impact of perception and presence on emotional reactions: a review of research in virtual reality},\n volume = {6},\n year = {2015}\n}\n'}","[{'authorId': '1760586', 'name': 'J. Diemer'}, {'authorId': '2711307', 'name': 'G. Alpers'}, {'authorId': '2195636', 'name': 'Henrik M. Peperkorn'}, {'authorId': '2545799', 'name': 'Y. Shiban'}, {'authorId': '1684604', 'name': 'A. Mühlberger'}]"
2914,ff74143e26278521e6090fba542d224739ab3e3a,Designing adaptive interfaces for children : a preliminary study on the effect of age and gender on children’s interaction in the context of dialoguing with computers,................................................................................................................................... ii Preface ..................................................................................................................................... iv Table of,2011.0,77.0,2.0,False,,"{'volume': '', 'name': ''}","{'bibtex': '@Inproceedings{Rajamanickam2011DesigningAI,\n author = {M. Rajamanickam},\n title = {Designing adaptive interfaces for children : a preliminary study on the effect of age and gender on children’s interaction in the context of dialoguing with computers},\n year = {2011}\n}\n'}","[{'authorId': '2113750', 'name': 'M. Rajamanickam'}]"
2915,ff948365684d3aa1a834deb49f326e264b56677a,"Animal, but not human, faces engage the distributed face network in adolescents with autism.","Multiple hypotheses have been offered to explain the impaired face-processing behavior and the accompanying underlying disruptions in neural circuitry among individuals with autism. We explored the specificity of atypical face-processing activation and potential alterations to fusiform gyrus (FG) morphology as potential underlying mechanisms. Adolescents with high functioning autism (HFA) and age-matched typically developing (TD) adolescents were scanned with sMRI and fMRI as they observed human and animal faces. In spite of exhibiting comparable face recognition behavior, the HFA adolescents evinced hypo-activation throughout the face-processing system in response to unfamiliar human, but not animal, faces. They also exhibited greater activation in affective regions of the face-processing network in response to animal, but not human, faces. Importantly, this atypical pattern of activation in response to human faces was not related to atypical structural properties of the FG. This atypical neural response to human faces in autism may stem from abnormalities in the ability to represent the reward value of social (i.e. conspecific) stimuli.",2016.0,60.0,41.0,False,,"{'volume': '19 2', 'pages': '\n          306-17\n        ', 'name': 'Developmental science'}","{'bibtex': '@Article{Whyte2016AnimalBN,\n author = {Elisabeth M. Whyte and M. Behrmann and N. Minshew and Natalie V. Garcia and K. S. Scherf},\n journal = {Developmental science},\n pages = {\n          306-17\n        },\n title = {Animal, but not human, faces engage the distributed face network in adolescents with autism.},\n volume = {19 2},\n year = {2016}\n}\n'}","[{'authorId': '6100221', 'name': 'Elisabeth M. Whyte'}, {'authorId': '2788357', 'name': 'M. Behrmann'}, {'authorId': '3701869', 'name': 'N. Minshew'}, {'authorId': '29747330', 'name': 'Natalie V. Garcia'}, {'authorId': '2228855309', 'name': 'K. S. Scherf'}]"
2916,ffac85f2e5fae6ccc7e8ae9499b7bba3394e0155,Benchmarking Multimodal Sentiment Analysis,,2017.0,29.0,50.0,True,"{'url': 'https://arxiv.org/pdf/1707.09538', 'status': None}","{'volume': 'abs/1707.09538', 'name': 'ArXiv'}","{'bibtex': '@Article{Cambria2017BenchmarkingMS,\n author = {E. Cambria and Devamanyu Hazarika and Soujanya Poria and A. Hussain and R. Subramanyam},\n journal = {ArXiv},\n title = {Benchmarking Multimodal Sentiment Analysis},\n volume = {abs/1707.09538},\n year = {2017}\n}\n'}","[{'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '8223433', 'name': 'Devamanyu Hazarika'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}, {'authorId': '144664815', 'name': 'A. Hussain'}, {'authorId': '144923692', 'name': 'R. Subramanyam'}]"
2917,fff34f247a7bbf5c86ea49b5c202bc90df836356,RAGE Architecture for Reusable Serious Gaming Technology Components,"For seizing the potential of serious games, the RAGE project—funded by the Horizon-2020 Programme of the European Commission—will make available an interoperable set of advanced technology components software assets that support game studios at serious game development. This paper describes the overall software architecture and design conditions that are needed for the easy integration and reuse of such software assets in existing game platforms. Based on the component-based software engineering paradigm the RAGE architecture takes into account the portability of assets to different operating systems, different programming languages, and different game engines. It avoids dependencies on external software frameworks and minimises code that may hinder integration with game engine code. Furthermore it relies on a limited set of standard software patterns and well-established coding practices. The RAGE architecture has been successfully validated by implementing and testing basic software assets in four major programming languages C#, C++, Java, and TypeScript/JavaScript, resp.. Demonstrator implementation of asset integration with an existing game engine was created and validated. The presented RAGE architecture paves the way for large scale development and application of cross-engine reusable software assets for enhancing the quality and diversity of serious gaming.",2016.0,40.0,51.0,True,"{'url': 'https://downloads.hindawi.com/journals/ijcgt/2016/5680526.pdf', 'status': None}","{'volume': '2016', 'pages': '5680526:1-5680526:10', 'name': 'Int. J. Comput. Games Technol.'}","{'bibtex': '@Article{Vegt2016RAGEAF,\n author = {W. V. D. Vegt and W. Westera and E. Nyamsuren and A. Georgiev and I. Martínez-Ortiz},\n journal = {Int. J. Comput. Games Technol.},\n pages = {5680526:1-5680526:10},\n title = {RAGE Architecture for Reusable Serious Gaming Technology Components},\n volume = {2016},\n year = {2016}\n}\n'}","[{'authorId': '66808672', 'name': 'W. V. D. Vegt'}, {'authorId': '3235367', 'name': 'W. Westera'}, {'authorId': '3260155', 'name': 'E. Nyamsuren'}, {'authorId': '145703318', 'name': 'A. Georgiev'}, {'authorId': '1398833087', 'name': 'I. Martínez-Ortiz'}]"
2918,fff6f505aa01e8fe5b27694c80d469458430d203,Sacrifice One For the Good of Many? People Apply Different Moral Norms to Human and Robot Agents,"Moral norms play an essential role in regulating human interaction. With the growing sophistication and proliferation of robots, it is important to understand how ordinary people apply moral norms to robot agents and make moral judgments about their behavior. We report the first comparison of people's moral judgments (of permissibility, wrongness, and blame) about human and robot agents. Two online experiments (total N =316) found that robots, compared with human agents, were more strongly expected to take an action that sacrifices one person for the good of many (a “utilitarian” choice), and they were blamed more than their human counterparts when they did not make that choice. Though the utilitarian sacrifice was generally seen as permissible for human agents, they were blamed more for choosing this option than for doing nothing. These results provide a first step toward a new field of Moral HRI, which is well placed to help guide the design of social robots. Categories and Subject Descriptors I.2.9 [Artificial Intelligence] Robotics K.4.1 [Computers and Society] Public Policy Issues, Ethics",2015.0,52.0,237.0,False,,"{'pages': '117-124', 'name': '2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)'}","{'bibtex': '@Article{Malle2015SacrificeOF,\n author = {B. Malle and Matthias Scheutz and Thomas Arnold and John Voiklis and Corey J. Cusimano},\n journal = {2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {117-124},\n title = {Sacrifice One For the Good of Many? People Apply Different Moral Norms to Human and Robot Agents},\n year = {2015}\n}\n'}","[{'authorId': '1854509', 'name': 'B. Malle'}, {'authorId': '1793014', 'name': 'Matthias Scheutz'}, {'authorId': '2053868213', 'name': 'Thomas Arnold'}, {'authorId': '2195142', 'name': 'John Voiklis'}, {'authorId': '3391293', 'name': 'Corey J. Cusimano'}]"
2919,,The neural correlates of regulating another person's emotions: an exploratory fMRI study,,2014.0,,,,,,,[]
